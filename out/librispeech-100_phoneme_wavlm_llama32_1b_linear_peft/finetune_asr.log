[2024-12-16 01:03:32,590][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': True, 'save_embedding': True}
[2024-12-16 01:03:32,590][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-16 01:03:32,590][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-16 01:03:32,591][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'librispeech-100_phoneme_wavlm_llama32_1b_linear_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-12-16_01-03-32.txt', 'log_interval': 5}
[2024-12-16 01:03:57,996][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-16 01:04:03,642][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-16 01:04:03,644][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-16 01:04:03,647][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-16 01:04:03,648][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-12-16 01:05:04,830][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': True, 'save_embedding': True}
[2024-12-16 01:05:04,831][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-16 01:05:04,831][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-16 01:05:04,831][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'librispeech-100_phoneme_wavlm_llama32_1b_linear_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-12-16_01-05-04.txt', 'log_interval': 5}
[2024-12-16 01:05:27,817][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-16 01:05:33,889][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-16 01:05:33,894][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-16 01:05:33,896][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-16 01:05:33,897][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-12-16 01:05:39,336][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-16 01:05:39,338][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-12-16 01:05:39,338][slam_llm.models.slam_model][INFO] - setup peft...
[2024-12-16 01:05:39,664][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-16 01:05:39,666][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-12-16 01:05:39,788][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-12-16 01:05:39,788][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2024-12-16 01:05:39,788][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-12-16 01:05:39,793][slam_llm.utils.train_utils][INFO] - --> asr has 20.320256 Million params

[2024-12-16 01:05:42,338][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100_phoneme/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100_phoneme/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-12-16 01:05:44,362][root][INFO] - --> Training Set Length = 28539
[2024-12-16 01:05:44,395][root][INFO] - --> Validation Set Length = 2703
[2024-12-16 01:05:44,395][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-16 01:05:44,396][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-16 01:13:59,557][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': True, 'save_embedding': True}
[2024-12-16 01:13:59,558][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-16 01:13:59,558][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-16 01:13:59,558][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'librispeech-100_phoneme_wavlm_llama32_1b_linear_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-12-16_01-13-59.txt', 'log_interval': 5}
[2024-12-16 01:14:20,078][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-16 01:14:25,235][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-16 01:14:25,237][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-16 01:14:25,239][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-16 01:14:25,240][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-12-16 01:14:29,426][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-16 01:14:29,428][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-12-16 01:14:29,428][slam_llm.models.slam_model][INFO] - setup peft...
[2024-12-16 01:14:29,715][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-16 01:14:29,717][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-12-16 01:14:29,818][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-12-16 01:14:29,818][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2024-12-16 01:14:29,819][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-12-16 01:14:29,823][slam_llm.utils.train_utils][INFO] - --> asr has 20.320256 Million params

[2024-12-16 01:14:31,581][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100_phoneme/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100_phoneme/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-12-16 01:14:32,590][root][INFO] - --> Training Set Length = 28539
[2024-12-16 01:14:32,605][root][INFO] - --> Validation Set Length = 2703
[2024-12-16 01:14:32,606][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-16 01:14:32,606][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-17 03:30:43,181][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': True, 'save_embedding': False}
[2024-12-17 03:30:43,181][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-17 03:30:43,181][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-17 03:30:43,181][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'librispeech-100_phoneme_wavlm_llama32_1b_linear_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-12-17_03-30-42.txt', 'log_interval': 5}
[2024-12-17 03:31:03,899][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-17 03:31:09,312][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-17 03:31:09,313][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-17 03:31:09,316][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-17 03:31:09,317][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-12-17 03:31:13,674][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-17 03:31:13,675][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-12-17 03:31:13,675][slam_llm.models.slam_model][INFO] - setup peft...
[2024-12-17 03:31:13,992][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-17 03:31:13,994][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-12-17 03:31:14,099][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-12-17 03:31:14,099][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2024-12-17 03:31:14,100][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-12-17 03:31:14,104][slam_llm.utils.train_utils][INFO] - --> asr has 20.320256 Million params

[2024-12-17 03:31:16,016][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100_phoneme/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100_phoneme/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-12-17 03:31:16,943][root][INFO] - --> Training Set Length = 28539
[2024-12-17 03:31:16,966][root][INFO] - --> Validation Set Length = 2703
[2024-12-17 03:31:16,966][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-17 03:31:16,967][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-17 03:31:18,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:19,852][numexpr.utils][INFO] - Note: NumExpr detected 28 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2024-12-17 03:31:20,761][root][INFO] - Training Epoch: 1/2, step 0/7134 completed (loss: 4.121769905090332, acc: 0.23625557124614716)
[2024-12-17 03:31:20,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:21,319][root][INFO] - Training Epoch: 1/2, step 1/7134 completed (loss: 4.174968242645264, acc: 0.19944211840629578)
[2024-12-17 03:31:21,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:21,928][root][INFO] - Training Epoch: 1/2, step 2/7134 completed (loss: 4.062264442443848, acc: 0.2543507218360901)
[2024-12-17 03:31:22,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:22,397][root][INFO] - Training Epoch: 1/2, step 3/7134 completed (loss: 4.178169250488281, acc: 0.23687580227851868)
[2024-12-17 03:31:22,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:22,910][root][INFO] - Training Epoch: 1/2, step 4/7134 completed (loss: 4.065652847290039, acc: 0.23192359507083893)
[2024-12-17 03:31:23,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:23,372][root][INFO] - Training Epoch: 1/2, step 5/7134 completed (loss: 3.9802818298339844, acc: 0.255076140165329)
[2024-12-17 03:31:23,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:23,838][root][INFO] - Training Epoch: 1/2, step 6/7134 completed (loss: 4.127389907836914, acc: 0.26966291666030884)
[2024-12-17 03:31:23,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:24,322][root][INFO] - Training Epoch: 1/2, step 7/7134 completed (loss: 4.26764440536499, acc: 0.20797011256217957)
[2024-12-17 03:31:24,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:24,808][root][INFO] - Training Epoch: 1/2, step 8/7134 completed (loss: 4.046030521392822, acc: 0.2434663027524948)
[2024-12-17 03:31:25,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:25,313][root][INFO] - Training Epoch: 1/2, step 9/7134 completed (loss: 4.143399238586426, acc: 0.25581395626068115)
[2024-12-17 03:31:25,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:25,816][root][INFO] - Training Epoch: 1/2, step 10/7134 completed (loss: 4.078188419342041, acc: 0.2446657121181488)
[2024-12-17 03:31:25,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:26,306][root][INFO] - Training Epoch: 1/2, step 11/7134 completed (loss: 4.182393550872803, acc: 0.21200750768184662)
[2024-12-17 03:31:26,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:26,811][root][INFO] - Training Epoch: 1/2, step 12/7134 completed (loss: 3.7792775630950928, acc: 0.2880215346813202)
[2024-12-17 03:31:26,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:27,284][root][INFO] - Training Epoch: 1/2, step 13/7134 completed (loss: 3.9633007049560547, acc: 0.26134800910949707)
[2024-12-17 03:31:27,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:27,764][root][INFO] - Training Epoch: 1/2, step 14/7134 completed (loss: 4.105426788330078, acc: 0.2521008551120758)
[2024-12-17 03:31:27,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:28,215][root][INFO] - Training Epoch: 1/2, step 15/7134 completed (loss: 3.956753969192505, acc: 0.2788296043872833)
[2024-12-17 03:31:28,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:28,709][root][INFO] - Training Epoch: 1/2, step 16/7134 completed (loss: 3.972155809402466, acc: 0.25609755516052246)
[2024-12-17 03:31:28,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:29,159][root][INFO] - Training Epoch: 1/2, step 17/7134 completed (loss: 4.337803840637207, acc: 0.20270270109176636)
[2024-12-17 03:31:29,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:29,631][root][INFO] - Training Epoch: 1/2, step 18/7134 completed (loss: 3.7901265621185303, acc: 0.2769886255264282)
[2024-12-17 03:31:29,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:30,084][root][INFO] - Training Epoch: 1/2, step 19/7134 completed (loss: 3.9737987518310547, acc: 0.25517240166664124)
[2024-12-17 03:31:30,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:30,534][root][INFO] - Training Epoch: 1/2, step 20/7134 completed (loss: 3.882462978363037, acc: 0.24868421256542206)
[2024-12-17 03:31:30,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:31,008][root][INFO] - Training Epoch: 1/2, step 21/7134 completed (loss: 3.6308236122131348, acc: 0.2706185579299927)
[2024-12-17 03:31:31,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:31,470][root][INFO] - Training Epoch: 1/2, step 22/7134 completed (loss: 3.6792478561401367, acc: 0.2780979871749878)
[2024-12-17 03:31:31,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:31,912][root][INFO] - Training Epoch: 1/2, step 23/7134 completed (loss: 3.597965955734253, acc: 0.28940218687057495)
[2024-12-17 03:31:32,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:32,356][root][INFO] - Training Epoch: 1/2, step 24/7134 completed (loss: 3.722297430038452, acc: 0.28551530838012695)
[2024-12-17 03:31:32,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:32,842][root][INFO] - Training Epoch: 1/2, step 25/7134 completed (loss: 3.635659694671631, acc: 0.27272728085517883)
[2024-12-17 03:31:32,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:33,304][root][INFO] - Training Epoch: 1/2, step 26/7134 completed (loss: 3.7314565181732178, acc: 0.2743362784385681)
[2024-12-17 03:31:33,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:33,745][root][INFO] - Training Epoch: 1/2, step 27/7134 completed (loss: 3.7200987339019775, acc: 0.2895125448703766)
[2024-12-17 03:31:33,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:34,216][root][INFO] - Training Epoch: 1/2, step 28/7134 completed (loss: 3.6629679203033447, acc: 0.26867470145225525)
[2024-12-17 03:31:34,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:34,690][root][INFO] - Training Epoch: 1/2, step 29/7134 completed (loss: 3.6023757457733154, acc: 0.2960340082645416)
[2024-12-17 03:31:34,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:35,178][root][INFO] - Training Epoch: 1/2, step 30/7134 completed (loss: 3.620908737182617, acc: 0.27005648612976074)
[2024-12-17 03:31:35,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:35,630][root][INFO] - Training Epoch: 1/2, step 31/7134 completed (loss: 3.6316580772399902, acc: 0.26483049988746643)
[2024-12-17 03:31:35,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:36,119][root][INFO] - Training Epoch: 1/2, step 32/7134 completed (loss: 3.5934884548187256, acc: 0.2639791965484619)
[2024-12-17 03:31:36,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:36,527][root][INFO] - Training Epoch: 1/2, step 33/7134 completed (loss: 3.790196657180786, acc: 0.26095616817474365)
[2024-12-17 03:31:36,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:37,013][root][INFO] - Training Epoch: 1/2, step 34/7134 completed (loss: 3.5748870372772217, acc: 0.27667057514190674)
[2024-12-17 03:31:37,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:37,547][root][INFO] - Training Epoch: 1/2, step 35/7134 completed (loss: 3.410796880722046, acc: 0.28934967517852783)
[2024-12-17 03:31:37,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:38,059][root][INFO] - Training Epoch: 1/2, step 36/7134 completed (loss: 3.4655723571777344, acc: 0.297502726316452)
[2024-12-17 03:31:38,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:38,548][root][INFO] - Training Epoch: 1/2, step 37/7134 completed (loss: 3.561622381210327, acc: 0.2715894877910614)
[2024-12-17 03:31:38,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:38,988][root][INFO] - Training Epoch: 1/2, step 38/7134 completed (loss: 3.6997499465942383, acc: 0.247023805975914)
[2024-12-17 03:31:39,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:39,451][root][INFO] - Training Epoch: 1/2, step 39/7134 completed (loss: 3.5633392333984375, acc: 0.2719891667366028)
[2024-12-17 03:31:39,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:39,890][root][INFO] - Training Epoch: 1/2, step 40/7134 completed (loss: 3.867623805999756, acc: 0.26233184337615967)
[2024-12-17 03:31:40,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:40,324][root][INFO] - Training Epoch: 1/2, step 41/7134 completed (loss: 3.556128978729248, acc: 0.2801664471626282)
[2024-12-17 03:31:40,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:40,791][root][INFO] - Training Epoch: 1/2, step 42/7134 completed (loss: 3.572618007659912, acc: 0.260869562625885)
[2024-12-17 03:31:40,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:41,218][root][INFO] - Training Epoch: 1/2, step 43/7134 completed (loss: 3.48209810256958, acc: 0.27483871579170227)
[2024-12-17 03:31:41,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:41,670][root][INFO] - Training Epoch: 1/2, step 44/7134 completed (loss: 3.512408971786499, acc: 0.2917197346687317)
[2024-12-17 03:31:41,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:42,194][root][INFO] - Training Epoch: 1/2, step 45/7134 completed (loss: 3.3458287715911865, acc: 0.29360780119895935)
[2024-12-17 03:31:42,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:42,684][root][INFO] - Training Epoch: 1/2, step 46/7134 completed (loss: 3.460139036178589, acc: 0.2893333435058594)
[2024-12-17 03:31:42,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:43,176][root][INFO] - Training Epoch: 1/2, step 47/7134 completed (loss: 3.350029230117798, acc: 0.31313130259513855)
[2024-12-17 03:31:43,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:43,690][root][INFO] - Training Epoch: 1/2, step 48/7134 completed (loss: 3.289809226989746, acc: 0.2898876368999481)
[2024-12-17 03:31:43,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:44,175][root][INFO] - Training Epoch: 1/2, step 49/7134 completed (loss: 3.4610846042633057, acc: 0.25788751244544983)
[2024-12-17 03:31:44,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:44,702][root][INFO] - Training Epoch: 1/2, step 50/7134 completed (loss: 3.3934741020202637, acc: 0.2883506417274475)
[2024-12-17 03:31:44,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:45,129][root][INFO] - Training Epoch: 1/2, step 51/7134 completed (loss: 3.3645291328430176, acc: 0.31091371178627014)
[2024-12-17 03:31:45,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:45,617][root][INFO] - Training Epoch: 1/2, step 52/7134 completed (loss: 3.4678971767425537, acc: 0.2959349453449249)
[2024-12-17 03:31:45,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:46,099][root][INFO] - Training Epoch: 1/2, step 53/7134 completed (loss: 3.3761448860168457, acc: 0.2821522355079651)
[2024-12-17 03:31:46,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:46,588][root][INFO] - Training Epoch: 1/2, step 54/7134 completed (loss: 3.2895212173461914, acc: 0.3095512092113495)
[2024-12-17 03:31:46,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:47,070][root][INFO] - Training Epoch: 1/2, step 55/7134 completed (loss: 3.335803747177124, acc: 0.2791878283023834)
[2024-12-17 03:31:47,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:47,545][root][INFO] - Training Epoch: 1/2, step 56/7134 completed (loss: 3.4678287506103516, acc: 0.2964285612106323)
[2024-12-17 03:31:47,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:48,027][root][INFO] - Training Epoch: 1/2, step 57/7134 completed (loss: 3.294645071029663, acc: 0.29316771030426025)
[2024-12-17 03:31:48,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:48,525][root][INFO] - Training Epoch: 1/2, step 58/7134 completed (loss: 3.2747573852539062, acc: 0.29705506563186646)
[2024-12-17 03:31:48,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:48,986][root][INFO] - Training Epoch: 1/2, step 59/7134 completed (loss: 3.1312220096588135, acc: 0.32505911588668823)
[2024-12-17 03:31:49,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:49,475][root][INFO] - Training Epoch: 1/2, step 60/7134 completed (loss: 3.3742988109588623, acc: 0.2698863744735718)
[2024-12-17 03:31:49,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:49,936][root][INFO] - Training Epoch: 1/2, step 61/7134 completed (loss: 3.231189012527466, acc: 0.29865360260009766)
[2024-12-17 03:31:50,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:50,393][root][INFO] - Training Epoch: 1/2, step 62/7134 completed (loss: 3.2528717517852783, acc: 0.28589579463005066)
[2024-12-17 03:31:50,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:50,860][root][INFO] - Training Epoch: 1/2, step 63/7134 completed (loss: 3.1413629055023193, acc: 0.30386051535606384)
[2024-12-17 03:31:50,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:51,347][root][INFO] - Training Epoch: 1/2, step 64/7134 completed (loss: 3.2052161693573, acc: 0.2782258093357086)
[2024-12-17 03:31:51,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:51,852][root][INFO] - Training Epoch: 1/2, step 65/7134 completed (loss: 3.3408043384552, acc: 0.24692875146865845)
[2024-12-17 03:31:51,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:52,348][root][INFO] - Training Epoch: 1/2, step 66/7134 completed (loss: 3.4476778507232666, acc: 0.24193547666072845)
[2024-12-17 03:31:52,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:52,842][root][INFO] - Training Epoch: 1/2, step 67/7134 completed (loss: 3.2019729614257812, acc: 0.2888889014720917)
[2024-12-17 03:31:52,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:53,285][root][INFO] - Training Epoch: 1/2, step 68/7134 completed (loss: 3.239471912384033, acc: 0.2541935443878174)
[2024-12-17 03:31:53,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:53,746][root][INFO] - Training Epoch: 1/2, step 69/7134 completed (loss: 3.117025852203369, acc: 0.2793017327785492)
[2024-12-17 03:31:53,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:54,201][root][INFO] - Training Epoch: 1/2, step 70/7134 completed (loss: 3.2636139392852783, acc: 0.2824561297893524)
[2024-12-17 03:31:54,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:54,665][root][INFO] - Training Epoch: 1/2, step 71/7134 completed (loss: 3.2212765216827393, acc: 0.28711485862731934)
[2024-12-17 03:31:54,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:55,139][root][INFO] - Training Epoch: 1/2, step 72/7134 completed (loss: 3.174389362335205, acc: 0.2762148380279541)
[2024-12-17 03:31:55,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:55,556][root][INFO] - Training Epoch: 1/2, step 73/7134 completed (loss: 3.214075803756714, acc: 0.25679346919059753)
[2024-12-17 03:31:55,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:56,012][root][INFO] - Training Epoch: 1/2, step 74/7134 completed (loss: 3.1662206649780273, acc: 0.30083566904067993)
[2024-12-17 03:31:56,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:56,510][root][INFO] - Training Epoch: 1/2, step 75/7134 completed (loss: 3.183755397796631, acc: 0.29147982597351074)
[2024-12-17 03:31:56,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:57,005][root][INFO] - Training Epoch: 1/2, step 76/7134 completed (loss: 3.014307737350464, acc: 0.29596978425979614)
[2024-12-17 03:31:57,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:57,505][root][INFO] - Training Epoch: 1/2, step 77/7134 completed (loss: 2.978236198425293, acc: 0.32581454515457153)
[2024-12-17 03:31:57,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:57,971][root][INFO] - Training Epoch: 1/2, step 78/7134 completed (loss: 3.09198260307312, acc: 0.28773584961891174)
[2024-12-17 03:31:58,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:58,429][root][INFO] - Training Epoch: 1/2, step 79/7134 completed (loss: 3.1090095043182373, acc: 0.3086419701576233)
[2024-12-17 03:31:58,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:58,883][root][INFO] - Training Epoch: 1/2, step 80/7134 completed (loss: 2.991886854171753, acc: 0.296875)
[2024-12-17 03:31:59,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:59,361][root][INFO] - Training Epoch: 1/2, step 81/7134 completed (loss: 2.9641506671905518, acc: 0.31675392389297485)
[2024-12-17 03:31:59,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:59,841][root][INFO] - Training Epoch: 1/2, step 82/7134 completed (loss: 2.882733106613159, acc: 0.34229138493537903)
[2024-12-17 03:31:59,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:00,315][root][INFO] - Training Epoch: 1/2, step 83/7134 completed (loss: 2.950021505355835, acc: 0.31233933568000793)
[2024-12-17 03:32:00,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:00,783][root][INFO] - Training Epoch: 1/2, step 84/7134 completed (loss: 2.982916831970215, acc: 0.3108808398246765)
[2024-12-17 03:32:00,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:01,197][root][INFO] - Training Epoch: 1/2, step 85/7134 completed (loss: 3.2015810012817383, acc: 0.2720763683319092)
[2024-12-17 03:32:01,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:01,641][root][INFO] - Training Epoch: 1/2, step 86/7134 completed (loss: 3.0079689025878906, acc: 0.3165137469768524)
[2024-12-17 03:32:01,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:02,149][root][INFO] - Training Epoch: 1/2, step 87/7134 completed (loss: 2.824287176132202, acc: 0.34508076310157776)
[2024-12-17 03:32:02,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:02,615][root][INFO] - Training Epoch: 1/2, step 88/7134 completed (loss: 2.9988458156585693, acc: 0.2697095572948456)
[2024-12-17 03:32:02,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:03,094][root][INFO] - Training Epoch: 1/2, step 89/7134 completed (loss: 2.8715872764587402, acc: 0.33119383454322815)
[2024-12-17 03:32:03,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:03,546][root][INFO] - Training Epoch: 1/2, step 90/7134 completed (loss: 3.0174081325531006, acc: 0.2902098000049591)
[2024-12-17 03:32:03,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:03,995][root][INFO] - Training Epoch: 1/2, step 91/7134 completed (loss: 3.0194573402404785, acc: 0.27142858505249023)
[2024-12-17 03:32:04,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:04,483][root][INFO] - Training Epoch: 1/2, step 92/7134 completed (loss: 2.9050683975219727, acc: 0.316970556974411)
[2024-12-17 03:32:04,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:04,960][root][INFO] - Training Epoch: 1/2, step 93/7134 completed (loss: 2.8315563201904297, acc: 0.32231405377388)
[2024-12-17 03:32:05,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:05,323][root][INFO] - Training Epoch: 1/2, step 94/7134 completed (loss: 3.002131462097168, acc: 0.31322506070137024)
[2024-12-17 03:32:05,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:05,804][root][INFO] - Training Epoch: 1/2, step 95/7134 completed (loss: 2.845947027206421, acc: 0.3090452253818512)
[2024-12-17 03:32:05,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:06,181][root][INFO] - Training Epoch: 1/2, step 96/7134 completed (loss: 2.975749969482422, acc: 0.2942271828651428)
[2024-12-17 03:32:06,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:06,602][root][INFO] - Training Epoch: 1/2, step 97/7134 completed (loss: 3.0988221168518066, acc: 0.27710843086242676)
[2024-12-17 03:32:06,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:07,111][root][INFO] - Training Epoch: 1/2, step 98/7134 completed (loss: 2.864652156829834, acc: 0.28155338764190674)
[2024-12-17 03:32:07,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:07,562][root][INFO] - Training Epoch: 1/2, step 99/7134 completed (loss: 2.7340357303619385, acc: 0.33761468529701233)
[2024-12-17 03:32:07,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:08,067][root][INFO] - Training Epoch: 1/2, step 100/7134 completed (loss: 2.7036423683166504, acc: 0.3461538553237915)
[2024-12-17 03:32:08,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:08,503][root][INFO] - Training Epoch: 1/2, step 101/7134 completed (loss: 2.8097496032714844, acc: 0.29111841320991516)
[2024-12-17 03:32:08,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:08,953][root][INFO] - Training Epoch: 1/2, step 102/7134 completed (loss: 2.7049756050109863, acc: 0.3589743673801422)
[2024-12-17 03:32:09,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:09,372][root][INFO] - Training Epoch: 1/2, step 103/7134 completed (loss: 2.794983148574829, acc: 0.30666667222976685)
[2024-12-17 03:32:09,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:09,860][root][INFO] - Training Epoch: 1/2, step 104/7134 completed (loss: 2.7258028984069824, acc: 0.317220538854599)
[2024-12-17 03:32:10,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:10,352][root][INFO] - Training Epoch: 1/2, step 105/7134 completed (loss: 2.5391030311584473, acc: 0.384991854429245)
[2024-12-17 03:32:10,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:10,827][root][INFO] - Training Epoch: 1/2, step 106/7134 completed (loss: 2.5840389728546143, acc: 0.3538268506526947)
[2024-12-17 03:32:10,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:11,269][root][INFO] - Training Epoch: 1/2, step 107/7134 completed (loss: 2.6811416149139404, acc: 0.35243552923202515)
[2024-12-17 03:32:11,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:11,782][root][INFO] - Training Epoch: 1/2, step 108/7134 completed (loss: 2.457747220993042, acc: 0.3764987885951996)
[2024-12-17 03:32:11,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:12,199][root][INFO] - Training Epoch: 1/2, step 109/7134 completed (loss: 2.6359546184539795, acc: 0.33088234066963196)
[2024-12-17 03:32:12,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:12,676][root][INFO] - Training Epoch: 1/2, step 110/7134 completed (loss: 2.464083194732666, acc: 0.3842538297176361)
[2024-12-17 03:32:12,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:13,116][root][INFO] - Training Epoch: 1/2, step 111/7134 completed (loss: 2.531243085861206, acc: 0.3588850200176239)
[2024-12-17 03:32:13,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:13,535][root][INFO] - Training Epoch: 1/2, step 112/7134 completed (loss: 2.5503745079040527, acc: 0.3482280373573303)
[2024-12-17 03:32:13,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:13,983][root][INFO] - Training Epoch: 1/2, step 113/7134 completed (loss: 2.39115571975708, acc: 0.37848100066185)
[2024-12-17 03:32:14,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:14,440][root][INFO] - Training Epoch: 1/2, step 114/7134 completed (loss: 2.5791683197021484, acc: 0.351458877325058)
[2024-12-17 03:32:14,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:14,802][root][INFO] - Training Epoch: 1/2, step 115/7134 completed (loss: 2.5281364917755127, acc: 0.35433071851730347)
[2024-12-17 03:32:14,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:15,322][root][INFO] - Training Epoch: 1/2, step 116/7134 completed (loss: 2.5744311809539795, acc: 0.343934029340744)
[2024-12-17 03:32:15,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:15,776][root][INFO] - Training Epoch: 1/2, step 117/7134 completed (loss: 2.5446617603302, acc: 0.35595569014549255)
[2024-12-17 03:32:15,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:16,285][root][INFO] - Training Epoch: 1/2, step 118/7134 completed (loss: 2.426302433013916, acc: 0.37627550959587097)
[2024-12-17 03:32:16,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:16,760][root][INFO] - Training Epoch: 1/2, step 119/7134 completed (loss: 2.5156755447387695, acc: 0.36077481508255005)
[2024-12-17 03:32:16,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:17,206][root][INFO] - Training Epoch: 1/2, step 120/7134 completed (loss: 2.4923908710479736, acc: 0.3433813750743866)
[2024-12-17 03:32:17,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:17,658][root][INFO] - Training Epoch: 1/2, step 121/7134 completed (loss: 2.4153356552124023, acc: 0.3778071403503418)
[2024-12-17 03:32:17,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:18,133][root][INFO] - Training Epoch: 1/2, step 122/7134 completed (loss: 2.324453830718994, acc: 0.382781445980072)
[2024-12-17 03:32:18,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:18,545][root][INFO] - Training Epoch: 1/2, step 123/7134 completed (loss: 2.4671547412872314, acc: 0.3588588535785675)
[2024-12-17 03:32:18,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:18,966][root][INFO] - Training Epoch: 1/2, step 124/7134 completed (loss: 2.5412492752075195, acc: 0.3534482717514038)
[2024-12-17 03:32:19,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:19,460][root][INFO] - Training Epoch: 1/2, step 125/7134 completed (loss: 2.4059371948242188, acc: 0.36172565817832947)
[2024-12-17 03:32:19,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:19,934][root][INFO] - Training Epoch: 1/2, step 126/7134 completed (loss: 2.4447646141052246, acc: 0.3479999899864197)
[2024-12-17 03:32:20,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:20,422][root][INFO] - Training Epoch: 1/2, step 127/7134 completed (loss: 2.3639752864837646, acc: 0.3888888955116272)
[2024-12-17 03:32:20,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:20,929][root][INFO] - Training Epoch: 1/2, step 128/7134 completed (loss: 2.3408641815185547, acc: 0.37485581636428833)
[2024-12-17 03:32:21,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:21,412][root][INFO] - Training Epoch: 1/2, step 129/7134 completed (loss: 2.437361478805542, acc: 0.3578431308269501)
[2024-12-17 03:32:21,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:21,871][root][INFO] - Training Epoch: 1/2, step 130/7134 completed (loss: 2.3526806831359863, acc: 0.3526315689086914)
[2024-12-17 03:32:22,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:22,348][root][INFO] - Training Epoch: 1/2, step 131/7134 completed (loss: 2.265836477279663, acc: 0.38947367668151855)
[2024-12-17 03:32:22,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:22,808][root][INFO] - Training Epoch: 1/2, step 132/7134 completed (loss: 2.3978235721588135, acc: 0.3599419593811035)
[2024-12-17 03:32:22,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:23,264][root][INFO] - Training Epoch: 1/2, step 133/7134 completed (loss: 2.48165225982666, acc: 0.3344425857067108)
[2024-12-17 03:32:23,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:23,741][root][INFO] - Training Epoch: 1/2, step 134/7134 completed (loss: 2.3939619064331055, acc: 0.3769911527633667)
[2024-12-17 03:32:23,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:24,221][root][INFO] - Training Epoch: 1/2, step 135/7134 completed (loss: 2.2943923473358154, acc: 0.35555556416511536)
[2024-12-17 03:32:24,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:24,673][root][INFO] - Training Epoch: 1/2, step 136/7134 completed (loss: 2.2947630882263184, acc: 0.36917561292648315)
[2024-12-17 03:32:24,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:25,141][root][INFO] - Training Epoch: 1/2, step 137/7134 completed (loss: 2.3857760429382324, acc: 0.3480934798717499)
[2024-12-17 03:32:25,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:25,628][root][INFO] - Training Epoch: 1/2, step 138/7134 completed (loss: 2.3025245666503906, acc: 0.36283186078071594)
[2024-12-17 03:32:25,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:26,127][root][INFO] - Training Epoch: 1/2, step 139/7134 completed (loss: 2.327230453491211, acc: 0.38235294818878174)
[2024-12-17 03:32:26,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:26,617][root][INFO] - Training Epoch: 1/2, step 140/7134 completed (loss: 2.3901078701019287, acc: 0.3552238941192627)
[2024-12-17 03:32:26,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:27,064][root][INFO] - Training Epoch: 1/2, step 141/7134 completed (loss: 2.2894673347473145, acc: 0.3832547068595886)
[2024-12-17 03:32:27,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:27,577][root][INFO] - Training Epoch: 1/2, step 142/7134 completed (loss: 2.351421356201172, acc: 0.3546592593193054)
[2024-12-17 03:32:27,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:28,045][root][INFO] - Training Epoch: 1/2, step 143/7134 completed (loss: 2.2371938228607178, acc: 0.3820078372955322)
[2024-12-17 03:32:28,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:28,510][root][INFO] - Training Epoch: 1/2, step 144/7134 completed (loss: 2.2261884212493896, acc: 0.3956594467163086)
[2024-12-17 03:32:28,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:28,967][root][INFO] - Training Epoch: 1/2, step 145/7134 completed (loss: 2.365396499633789, acc: 0.3718309998512268)
[2024-12-17 03:32:29,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:29,439][root][INFO] - Training Epoch: 1/2, step 146/7134 completed (loss: 2.2785792350769043, acc: 0.3917378783226013)
[2024-12-17 03:32:29,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:29,888][root][INFO] - Training Epoch: 1/2, step 147/7134 completed (loss: 2.3100368976593018, acc: 0.3656845688819885)
[2024-12-17 03:32:30,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:30,323][root][INFO] - Training Epoch: 1/2, step 148/7134 completed (loss: 2.2929294109344482, acc: 0.38051044940948486)
[2024-12-17 03:32:30,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:30,800][root][INFO] - Training Epoch: 1/2, step 149/7134 completed (loss: 2.17209792137146, acc: 0.39741936326026917)
[2024-12-17 03:32:30,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:31,272][root][INFO] - Training Epoch: 1/2, step 150/7134 completed (loss: 2.3364837169647217, acc: 0.3703208565711975)
[2024-12-17 03:32:31,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:31,734][root][INFO] - Training Epoch: 1/2, step 151/7134 completed (loss: 2.2686989307403564, acc: 0.39140811562538147)
[2024-12-17 03:32:31,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:32,209][root][INFO] - Training Epoch: 1/2, step 152/7134 completed (loss: 2.2230212688446045, acc: 0.3906605839729309)
[2024-12-17 03:32:32,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:32,657][root][INFO] - Training Epoch: 1/2, step 153/7134 completed (loss: 2.3049516677856445, acc: 0.3589385449886322)
[2024-12-17 03:32:32,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:33,127][root][INFO] - Training Epoch: 1/2, step 154/7134 completed (loss: 2.291592836380005, acc: 0.3860182464122772)
[2024-12-17 03:32:33,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:33,591][root][INFO] - Training Epoch: 1/2, step 155/7134 completed (loss: 2.2239019870758057, acc: 0.3935064971446991)
[2024-12-17 03:32:33,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:34,061][root][INFO] - Training Epoch: 1/2, step 156/7134 completed (loss: 2.175762414932251, acc: 0.40490081906318665)
[2024-12-17 03:32:34,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:34,541][root][INFO] - Training Epoch: 1/2, step 157/7134 completed (loss: 2.1883249282836914, acc: 0.3987951874732971)
[2024-12-17 03:32:34,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:35,022][root][INFO] - Training Epoch: 1/2, step 158/7134 completed (loss: 2.1652371883392334, acc: 0.3989431858062744)
[2024-12-17 03:32:35,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:35,501][root][INFO] - Training Epoch: 1/2, step 159/7134 completed (loss: 2.2037241458892822, acc: 0.40692639350891113)
[2024-12-17 03:32:35,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:35,896][root][INFO] - Training Epoch: 1/2, step 160/7134 completed (loss: 2.280557632446289, acc: 0.35020244121551514)
[2024-12-17 03:32:36,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:36,274][root][INFO] - Training Epoch: 1/2, step 161/7134 completed (loss: 2.2073347568511963, acc: 0.39534884691238403)
[2024-12-17 03:32:36,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:36,636][root][INFO] - Training Epoch: 1/2, step 162/7134 completed (loss: 2.330911159515381, acc: 0.3324808180332184)
[2024-12-17 03:32:36,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:37,139][root][INFO] - Training Epoch: 1/2, step 163/7134 completed (loss: 2.1562469005584717, acc: 0.40915805101394653)
[2024-12-17 03:32:37,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:37,531][root][INFO] - Training Epoch: 1/2, step 164/7134 completed (loss: 2.196326494216919, acc: 0.4382978677749634)
[2024-12-17 03:32:37,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:37,947][root][INFO] - Training Epoch: 1/2, step 165/7134 completed (loss: 2.226470947265625, acc: 0.4114832580089569)
[2024-12-17 03:32:38,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:38,282][root][INFO] - Training Epoch: 1/2, step 166/7134 completed (loss: 2.039318561553955, acc: 0.4746268689632416)
[2024-12-17 03:32:38,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:38,745][root][INFO] - Training Epoch: 1/2, step 167/7134 completed (loss: 2.3790383338928223, acc: 0.36185383796691895)
[2024-12-17 03:32:38,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:39,093][root][INFO] - Training Epoch: 1/2, step 168/7134 completed (loss: 2.642319679260254, acc: 0.30588236451148987)
[2024-12-17 03:32:39,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:39,494][root][INFO] - Training Epoch: 1/2, step 169/7134 completed (loss: 2.4087719917297363, acc: 0.37535014748573303)
[2024-12-17 03:32:39,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:39,900][root][INFO] - Training Epoch: 1/2, step 170/7134 completed (loss: 2.3590047359466553, acc: 0.3795066475868225)
[2024-12-17 03:32:40,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:40,280][root][INFO] - Training Epoch: 1/2, step 171/7134 completed (loss: 2.2284529209136963, acc: 0.3928571343421936)
[2024-12-17 03:32:40,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:40,726][root][INFO] - Training Epoch: 1/2, step 172/7134 completed (loss: 2.405787467956543, acc: 0.36185818910598755)
[2024-12-17 03:32:40,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:41,110][root][INFO] - Training Epoch: 1/2, step 173/7134 completed (loss: 2.320399522781372, acc: 0.3451327383518219)
[2024-12-17 03:32:41,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:41,557][root][INFO] - Training Epoch: 1/2, step 174/7134 completed (loss: 2.3460137844085693, acc: 0.35915493965148926)
[2024-12-17 03:32:41,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:42,025][root][INFO] - Training Epoch: 1/2, step 175/7134 completed (loss: 2.344897985458374, acc: 0.3327272832393646)
[2024-12-17 03:32:42,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:42,498][root][INFO] - Training Epoch: 1/2, step 176/7134 completed (loss: 2.3589425086975098, acc: 0.34057971835136414)
[2024-12-17 03:32:42,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:42,929][root][INFO] - Training Epoch: 1/2, step 177/7134 completed (loss: 2.315207004547119, acc: 0.385185182094574)
[2024-12-17 03:32:43,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:43,333][root][INFO] - Training Epoch: 1/2, step 178/7134 completed (loss: 2.3650527000427246, acc: 0.39922481775283813)
[2024-12-17 03:32:43,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:43,760][root][INFO] - Training Epoch: 1/2, step 179/7134 completed (loss: 2.1838176250457764, acc: 0.41199225187301636)
[2024-12-17 03:32:43,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:44,244][root][INFO] - Training Epoch: 1/2, step 180/7134 completed (loss: 2.424874782562256, acc: 0.3457583487033844)
[2024-12-17 03:32:44,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:44,696][root][INFO] - Training Epoch: 1/2, step 181/7134 completed (loss: 2.2539632320404053, acc: 0.37812912464141846)
[2024-12-17 03:32:44,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:45,189][root][INFO] - Training Epoch: 1/2, step 182/7134 completed (loss: 2.239654064178467, acc: 0.40537241101264954)
[2024-12-17 03:32:45,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:45,687][root][INFO] - Training Epoch: 1/2, step 183/7134 completed (loss: 2.2265541553497314, acc: 0.3760218024253845)
[2024-12-17 03:32:45,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:46,117][root][INFO] - Training Epoch: 1/2, step 184/7134 completed (loss: 2.1435751914978027, acc: 0.4285714328289032)
[2024-12-17 03:32:46,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:46,546][root][INFO] - Training Epoch: 1/2, step 185/7134 completed (loss: 2.09869384765625, acc: 0.40772533416748047)
[2024-12-17 03:32:46,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:47,021][root][INFO] - Training Epoch: 1/2, step 186/7134 completed (loss: 2.26853084564209, acc: 0.3717948794364929)
[2024-12-17 03:32:47,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:47,474][root][INFO] - Training Epoch: 1/2, step 187/7134 completed (loss: 2.2236127853393555, acc: 0.3910614550113678)
[2024-12-17 03:32:47,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:47,920][root][INFO] - Training Epoch: 1/2, step 188/7134 completed (loss: 2.149735689163208, acc: 0.3791666626930237)
[2024-12-17 03:32:48,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:48,319][root][INFO] - Training Epoch: 1/2, step 189/7134 completed (loss: 2.2829666137695312, acc: 0.36538460850715637)
[2024-12-17 03:32:48,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:48,780][root][INFO] - Training Epoch: 1/2, step 190/7134 completed (loss: 2.1891603469848633, acc: 0.3993759751319885)
[2024-12-17 03:32:48,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:49,240][root][INFO] - Training Epoch: 1/2, step 191/7134 completed (loss: 2.2965896129608154, acc: 0.3739316165447235)
[2024-12-17 03:32:49,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:49,743][root][INFO] - Training Epoch: 1/2, step 192/7134 completed (loss: 2.1401448249816895, acc: 0.38831615447998047)
[2024-12-17 03:32:49,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:50,186][root][INFO] - Training Epoch: 1/2, step 193/7134 completed (loss: 2.1593077182769775, acc: 0.37852349877357483)
[2024-12-17 03:32:50,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:50,666][root][INFO] - Training Epoch: 1/2, step 194/7134 completed (loss: 2.2371089458465576, acc: 0.3644189238548279)
[2024-12-17 03:32:50,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:51,106][root][INFO] - Training Epoch: 1/2, step 195/7134 completed (loss: 2.2510316371917725, acc: 0.3613445460796356)
[2024-12-17 03:32:51,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:51,590][root][INFO] - Training Epoch: 1/2, step 196/7134 completed (loss: 2.171757936477661, acc: 0.4064171016216278)
[2024-12-17 03:32:51,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:52,073][root][INFO] - Training Epoch: 1/2, step 197/7134 completed (loss: 2.147414445877075, acc: 0.43019944429397583)
[2024-12-17 03:32:52,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:52,549][root][INFO] - Training Epoch: 1/2, step 198/7134 completed (loss: 2.145219326019287, acc: 0.398207426071167)
[2024-12-17 03:32:52,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:53,007][root][INFO] - Training Epoch: 1/2, step 199/7134 completed (loss: 2.252443790435791, acc: 0.36781609058380127)
[2024-12-17 03:32:53,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:53,485][root][INFO] - Training Epoch: 1/2, step 200/7134 completed (loss: 2.0972588062286377, acc: 0.4161073863506317)
[2024-12-17 03:32:53,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:53,932][root][INFO] - Training Epoch: 1/2, step 201/7134 completed (loss: 2.1778855323791504, acc: 0.391853928565979)
[2024-12-17 03:32:54,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:54,396][root][INFO] - Training Epoch: 1/2, step 202/7134 completed (loss: 2.112851619720459, acc: 0.4193103313446045)
[2024-12-17 03:32:54,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:54,913][root][INFO] - Training Epoch: 1/2, step 203/7134 completed (loss: 2.1594696044921875, acc: 0.39393940567970276)
[2024-12-17 03:32:55,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:55,400][root][INFO] - Training Epoch: 1/2, step 204/7134 completed (loss: 2.1256508827209473, acc: 0.39209726452827454)
[2024-12-17 03:32:55,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:55,852][root][INFO] - Training Epoch: 1/2, step 205/7134 completed (loss: 2.127901315689087, acc: 0.39197930693626404)
[2024-12-17 03:32:56,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:56,339][root][INFO] - Training Epoch: 1/2, step 206/7134 completed (loss: 2.112663984298706, acc: 0.3948635756969452)
[2024-12-17 03:32:56,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:56,799][root][INFO] - Training Epoch: 1/2, step 207/7134 completed (loss: 2.0984771251678467, acc: 0.4112628102302551)
[2024-12-17 03:32:56,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:57,248][root][INFO] - Training Epoch: 1/2, step 208/7134 completed (loss: 2.2273874282836914, acc: 0.36666667461395264)
[2024-12-17 03:32:57,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:57,717][root][INFO] - Training Epoch: 1/2, step 209/7134 completed (loss: 2.2430672645568848, acc: 0.3484455943107605)
[2024-12-17 03:32:57,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:58,220][root][INFO] - Training Epoch: 1/2, step 210/7134 completed (loss: 2.0854668617248535, acc: 0.42497000098228455)
[2024-12-17 03:32:58,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:58,583][root][INFO] - Training Epoch: 1/2, step 211/7134 completed (loss: 2.171823501586914, acc: 0.3970588147640228)
[2024-12-17 03:32:58,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:59,023][root][INFO] - Training Epoch: 1/2, step 212/7134 completed (loss: 2.1859054565429688, acc: 0.3801652789115906)
[2024-12-17 03:32:59,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:59,481][root][INFO] - Training Epoch: 1/2, step 213/7134 completed (loss: 2.063236951828003, acc: 0.42556634545326233)
[2024-12-17 03:32:59,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:59,887][root][INFO] - Training Epoch: 1/2, step 214/7134 completed (loss: 2.1518993377685547, acc: 0.39743590354919434)
[2024-12-17 03:33:00,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:00,334][root][INFO] - Training Epoch: 1/2, step 215/7134 completed (loss: 2.120330572128296, acc: 0.4479166567325592)
[2024-12-17 03:33:00,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:00,756][root][INFO] - Training Epoch: 1/2, step 216/7134 completed (loss: 2.0584607124328613, acc: 0.43194442987442017)
[2024-12-17 03:33:00,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:01,279][root][INFO] - Training Epoch: 1/2, step 217/7134 completed (loss: 1.9393202066421509, acc: 0.4533333480358124)
[2024-12-17 03:33:01,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:01,744][root][INFO] - Training Epoch: 1/2, step 218/7134 completed (loss: 1.992138147354126, acc: 0.442748099565506)
[2024-12-17 03:33:01,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:02,188][root][INFO] - Training Epoch: 1/2, step 219/7134 completed (loss: 2.1837587356567383, acc: 0.40545809268951416)
[2024-12-17 03:33:02,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:02,617][root][INFO] - Training Epoch: 1/2, step 220/7134 completed (loss: 2.0236990451812744, acc: 0.4330543875694275)
[2024-12-17 03:33:02,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:03,097][root][INFO] - Training Epoch: 1/2, step 221/7134 completed (loss: 2.0611484050750732, acc: 0.41940298676490784)
[2024-12-17 03:33:03,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:03,598][root][INFO] - Training Epoch: 1/2, step 222/7134 completed (loss: 2.1098344326019287, acc: 0.4005235731601715)
[2024-12-17 03:33:03,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:04,038][root][INFO] - Training Epoch: 1/2, step 223/7134 completed (loss: 2.097764253616333, acc: 0.41976892948150635)
[2024-12-17 03:33:04,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:04,475][root][INFO] - Training Epoch: 1/2, step 224/7134 completed (loss: 2.2424533367156982, acc: 0.37224385142326355)
[2024-12-17 03:33:04,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:04,960][root][INFO] - Training Epoch: 1/2, step 225/7134 completed (loss: 2.164173126220703, acc: 0.410783052444458)
[2024-12-17 03:33:05,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:05,449][root][INFO] - Training Epoch: 1/2, step 226/7134 completed (loss: 2.1815874576568604, acc: 0.40220049023628235)
[2024-12-17 03:33:05,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:05,908][root][INFO] - Training Epoch: 1/2, step 227/7134 completed (loss: 2.1523749828338623, acc: 0.4032258093357086)
[2024-12-17 03:33:06,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:06,373][root][INFO] - Training Epoch: 1/2, step 228/7134 completed (loss: 2.1353416442871094, acc: 0.4240231513977051)
[2024-12-17 03:33:06,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:06,859][root][INFO] - Training Epoch: 1/2, step 229/7134 completed (loss: 2.1716928482055664, acc: 0.4037974774837494)
[2024-12-17 03:33:07,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:07,362][root][INFO] - Training Epoch: 1/2, step 230/7134 completed (loss: 2.0896823406219482, acc: 0.40417689085006714)
[2024-12-17 03:33:07,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:07,787][root][INFO] - Training Epoch: 1/2, step 231/7134 completed (loss: 2.0970468521118164, acc: 0.40489640831947327)
[2024-12-17 03:33:07,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:08,227][root][INFO] - Training Epoch: 1/2, step 232/7134 completed (loss: 2.087284564971924, acc: 0.42009884119033813)
[2024-12-17 03:33:08,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:08,668][root][INFO] - Training Epoch: 1/2, step 233/7134 completed (loss: 2.162079334259033, acc: 0.40253564715385437)
[2024-12-17 03:33:08,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:09,119][root][INFO] - Training Epoch: 1/2, step 234/7134 completed (loss: 2.107565402984619, acc: 0.3868243098258972)
[2024-12-17 03:33:09,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:09,576][root][INFO] - Training Epoch: 1/2, step 235/7134 completed (loss: 2.1167967319488525, acc: 0.39743590354919434)
[2024-12-17 03:33:09,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:10,043][root][INFO] - Training Epoch: 1/2, step 236/7134 completed (loss: 2.138256788253784, acc: 0.3812499940395355)
[2024-12-17 03:33:10,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:10,473][root][INFO] - Training Epoch: 1/2, step 237/7134 completed (loss: 2.1244871616363525, acc: 0.4113263785839081)
[2024-12-17 03:33:10,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:10,899][root][INFO] - Training Epoch: 1/2, step 238/7134 completed (loss: 2.027339458465576, acc: 0.4458955228328705)
[2024-12-17 03:33:11,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:11,350][root][INFO] - Training Epoch: 1/2, step 239/7134 completed (loss: 2.1209917068481445, acc: 0.40336135029792786)
[2024-12-17 03:33:11,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:11,791][root][INFO] - Training Epoch: 1/2, step 240/7134 completed (loss: 2.1748008728027344, acc: 0.38771185278892517)
[2024-12-17 03:33:11,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:12,214][root][INFO] - Training Epoch: 1/2, step 241/7134 completed (loss: 2.070291042327881, acc: 0.43156200647354126)
[2024-12-17 03:33:12,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:12,637][root][INFO] - Training Epoch: 1/2, step 242/7134 completed (loss: 2.040611505508423, acc: 0.4142114520072937)
[2024-12-17 03:33:12,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:13,077][root][INFO] - Training Epoch: 1/2, step 243/7134 completed (loss: 2.158745765686035, acc: 0.40646257996559143)
[2024-12-17 03:33:13,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:13,514][root][INFO] - Training Epoch: 1/2, step 244/7134 completed (loss: 1.9954357147216797, acc: 0.4268476665019989)
[2024-12-17 03:33:13,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:13,957][root][INFO] - Training Epoch: 1/2, step 245/7134 completed (loss: 2.061634063720703, acc: 0.4133099913597107)
[2024-12-17 03:33:14,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:14,432][root][INFO] - Training Epoch: 1/2, step 246/7134 completed (loss: 2.041558027267456, acc: 0.4195583462715149)
[2024-12-17 03:33:14,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:14,859][root][INFO] - Training Epoch: 1/2, step 247/7134 completed (loss: 1.9857796430587769, acc: 0.44464609026908875)
[2024-12-17 03:33:15,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:15,314][root][INFO] - Training Epoch: 1/2, step 248/7134 completed (loss: 1.9622092247009277, acc: 0.4593023359775543)
[2024-12-17 03:33:15,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:15,715][root][INFO] - Training Epoch: 1/2, step 249/7134 completed (loss: 2.074599027633667, acc: 0.4584450423717499)
[2024-12-17 03:33:15,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:16,170][root][INFO] - Training Epoch: 1/2, step 250/7134 completed (loss: 2.1972711086273193, acc: 0.3971518874168396)
[2024-12-17 03:33:16,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:16,596][root][INFO] - Training Epoch: 1/2, step 251/7134 completed (loss: 2.0365138053894043, acc: 0.4512820541858673)
[2024-12-17 03:33:16,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:16,995][root][INFO] - Training Epoch: 1/2, step 252/7134 completed (loss: 2.132361650466919, acc: 0.4098360538482666)
[2024-12-17 03:33:17,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:17,449][root][INFO] - Training Epoch: 1/2, step 253/7134 completed (loss: 2.073352813720703, acc: 0.40285205841064453)
[2024-12-17 03:33:17,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:17,875][root][INFO] - Training Epoch: 1/2, step 254/7134 completed (loss: 2.0366506576538086, acc: 0.4375)
[2024-12-17 03:33:18,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:18,317][root][INFO] - Training Epoch: 1/2, step 255/7134 completed (loss: 1.987484097480774, acc: 0.4254385828971863)
[2024-12-17 03:33:18,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:18,700][root][INFO] - Training Epoch: 1/2, step 256/7134 completed (loss: 2.105984926223755, acc: 0.3860294222831726)
[2024-12-17 03:33:18,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:19,208][root][INFO] - Training Epoch: 1/2, step 257/7134 completed (loss: 2.0231432914733887, acc: 0.4049079716205597)
[2024-12-17 03:33:19,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:19,651][root][INFO] - Training Epoch: 1/2, step 258/7134 completed (loss: 2.082503318786621, acc: 0.4115702509880066)
[2024-12-17 03:33:19,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:20,106][root][INFO] - Training Epoch: 1/2, step 259/7134 completed (loss: 2.0163862705230713, acc: 0.43111830949783325)
[2024-12-17 03:33:20,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:20,560][root][INFO] - Training Epoch: 1/2, step 260/7134 completed (loss: 2.002399206161499, acc: 0.4348561763763428)
[2024-12-17 03:33:20,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:20,994][root][INFO] - Training Epoch: 1/2, step 261/7134 completed (loss: 1.9943876266479492, acc: 0.419222891330719)
[2024-12-17 03:33:21,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:21,418][root][INFO] - Training Epoch: 1/2, step 262/7134 completed (loss: 2.093223810195923, acc: 0.40765389800071716)
[2024-12-17 03:33:21,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:21,863][root][INFO] - Training Epoch: 1/2, step 263/7134 completed (loss: 2.0061254501342773, acc: 0.4367816150188446)
[2024-12-17 03:33:21,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:22,318][root][INFO] - Training Epoch: 1/2, step 264/7134 completed (loss: 2.028931140899658, acc: 0.4357476532459259)
[2024-12-17 03:33:22,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:22,770][root][INFO] - Training Epoch: 1/2, step 265/7134 completed (loss: 1.9823473691940308, acc: 0.44716495275497437)
[2024-12-17 03:33:22,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:23,222][root][INFO] - Training Epoch: 1/2, step 266/7134 completed (loss: 1.9899722337722778, acc: 0.427752286195755)
[2024-12-17 03:33:23,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:23,719][root][INFO] - Training Epoch: 1/2, step 267/7134 completed (loss: 2.030827283859253, acc: 0.4402298927307129)
[2024-12-17 03:33:23,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:24,217][root][INFO] - Training Epoch: 1/2, step 268/7134 completed (loss: 2.0140798091888428, acc: 0.4306095838546753)
[2024-12-17 03:33:24,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:24,727][root][INFO] - Training Epoch: 1/2, step 269/7134 completed (loss: 2.0472412109375, acc: 0.42420026659965515)
[2024-12-17 03:33:24,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:25,153][root][INFO] - Training Epoch: 1/2, step 270/7134 completed (loss: 1.9149452447891235, acc: 0.4552238881587982)
[2024-12-17 03:33:25,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:25,629][root][INFO] - Training Epoch: 1/2, step 271/7134 completed (loss: 1.9774699211120605, acc: 0.4287515878677368)
[2024-12-17 03:33:25,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:26,075][root][INFO] - Training Epoch: 1/2, step 272/7134 completed (loss: 2.057009220123291, acc: 0.4236641228199005)
[2024-12-17 03:33:26,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:26,541][root][INFO] - Training Epoch: 1/2, step 273/7134 completed (loss: 1.8721253871917725, acc: 0.46347305178642273)
[2024-12-17 03:33:26,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:27,001][root][INFO] - Training Epoch: 1/2, step 274/7134 completed (loss: 1.9996347427368164, acc: 0.4277854263782501)
[2024-12-17 03:33:27,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:27,503][root][INFO] - Training Epoch: 1/2, step 275/7134 completed (loss: 1.9218816757202148, acc: 0.47099769115448)
[2024-12-17 03:33:27,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:27,981][root][INFO] - Training Epoch: 1/2, step 276/7134 completed (loss: 1.960348129272461, acc: 0.42630937695503235)
[2024-12-17 03:33:28,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:28,452][root][INFO] - Training Epoch: 1/2, step 277/7134 completed (loss: 2.010934591293335, acc: 0.419562429189682)
[2024-12-17 03:33:28,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:28,886][root][INFO] - Training Epoch: 1/2, step 278/7134 completed (loss: 2.0320966243743896, acc: 0.4201788008213043)
[2024-12-17 03:33:29,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:29,344][root][INFO] - Training Epoch: 1/2, step 279/7134 completed (loss: 1.9700508117675781, acc: 0.4330708682537079)
[2024-12-17 03:33:29,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:29,798][root][INFO] - Training Epoch: 1/2, step 280/7134 completed (loss: 2.0417962074279785, acc: 0.41577062010765076)
[2024-12-17 03:33:29,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:30,219][root][INFO] - Training Epoch: 1/2, step 281/7134 completed (loss: 2.036353826522827, acc: 0.4180000126361847)
[2024-12-17 03:33:30,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:30,655][root][INFO] - Training Epoch: 1/2, step 282/7134 completed (loss: 2.087954521179199, acc: 0.40763360261917114)
[2024-12-17 03:33:30,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:31,088][root][INFO] - Training Epoch: 1/2, step 283/7134 completed (loss: 2.042118787765503, acc: 0.4074702858924866)
[2024-12-17 03:33:31,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:31,517][root][INFO] - Training Epoch: 1/2, step 284/7134 completed (loss: 2.0500950813293457, acc: 0.4127516746520996)
[2024-12-17 03:33:31,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:31,952][root][INFO] - Training Epoch: 1/2, step 285/7134 completed (loss: 2.0155396461486816, acc: 0.42328041791915894)
[2024-12-17 03:33:32,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:32,363][root][INFO] - Training Epoch: 1/2, step 286/7134 completed (loss: 2.0379602909088135, acc: 0.4318584203720093)
[2024-12-17 03:33:32,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:32,795][root][INFO] - Training Epoch: 1/2, step 287/7134 completed (loss: 2.0027365684509277, acc: 0.42696627974510193)
[2024-12-17 03:33:32,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:33,271][root][INFO] - Training Epoch: 1/2, step 288/7134 completed (loss: 2.031107187271118, acc: 0.4419889450073242)
[2024-12-17 03:33:33,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:33,764][root][INFO] - Training Epoch: 1/2, step 289/7134 completed (loss: 1.9961590766906738, acc: 0.43942132592201233)
[2024-12-17 03:33:33,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:34,188][root][INFO] - Training Epoch: 1/2, step 290/7134 completed (loss: 1.9857418537139893, acc: 0.4498480260372162)
[2024-12-17 03:33:34,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:34,673][root][INFO] - Training Epoch: 1/2, step 291/7134 completed (loss: 1.9529324769973755, acc: 0.4490131437778473)
[2024-12-17 03:33:34,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:35,120][root][INFO] - Training Epoch: 1/2, step 292/7134 completed (loss: 2.0880725383758545, acc: 0.401840478181839)
[2024-12-17 03:33:35,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:35,565][root][INFO] - Training Epoch: 1/2, step 293/7134 completed (loss: 1.9479225873947144, acc: 0.43775099515914917)
[2024-12-17 03:33:35,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:36,018][root][INFO] - Training Epoch: 1/2, step 294/7134 completed (loss: 1.949242353439331, acc: 0.4385964870452881)
[2024-12-17 03:33:36,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:36,537][root][INFO] - Training Epoch: 1/2, step 295/7134 completed (loss: 1.9932502508163452, acc: 0.44880545139312744)
[2024-12-17 03:33:36,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:37,002][root][INFO] - Training Epoch: 1/2, step 296/7134 completed (loss: 1.919011116027832, acc: 0.45891472697257996)
[2024-12-17 03:33:37,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:37,453][root][INFO] - Training Epoch: 1/2, step 297/7134 completed (loss: 2.01190185546875, acc: 0.4458259344100952)
[2024-12-17 03:33:37,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:37,917][root][INFO] - Training Epoch: 1/2, step 298/7134 completed (loss: 2.0434253215789795, acc: 0.41440001130104065)
[2024-12-17 03:33:38,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:38,364][root][INFO] - Training Epoch: 1/2, step 299/7134 completed (loss: 1.9983317852020264, acc: 0.410526305437088)
[2024-12-17 03:33:38,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:38,812][root][INFO] - Training Epoch: 1/2, step 300/7134 completed (loss: 1.7699551582336426, acc: 0.5)
[2024-12-17 03:33:38,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:39,301][root][INFO] - Training Epoch: 1/2, step 301/7134 completed (loss: 1.9071975946426392, acc: 0.45968881249427795)
[2024-12-17 03:33:39,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:39,708][root][INFO] - Training Epoch: 1/2, step 302/7134 completed (loss: 2.0314383506774902, acc: 0.4288499057292938)
[2024-12-17 03:33:39,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:40,100][root][INFO] - Training Epoch: 1/2, step 303/7134 completed (loss: 2.1313626766204834, acc: 0.3864077627658844)
[2024-12-17 03:33:40,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:40,552][root][INFO] - Training Epoch: 1/2, step 304/7134 completed (loss: 2.0326242446899414, acc: 0.42407408356666565)
[2024-12-17 03:33:40,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:40,980][root][INFO] - Training Epoch: 1/2, step 305/7134 completed (loss: 1.8855901956558228, acc: 0.44674086570739746)
[2024-12-17 03:33:41,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:41,409][root][INFO] - Training Epoch: 1/2, step 306/7134 completed (loss: 1.9385172128677368, acc: 0.4637681245803833)
[2024-12-17 03:33:41,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:41,899][root][INFO] - Training Epoch: 1/2, step 307/7134 completed (loss: 1.9244126081466675, acc: 0.4466192126274109)
[2024-12-17 03:33:42,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:42,321][root][INFO] - Training Epoch: 1/2, step 308/7134 completed (loss: 1.874829888343811, acc: 0.46875)
[2024-12-17 03:33:42,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:42,775][root][INFO] - Training Epoch: 1/2, step 309/7134 completed (loss: 1.9309180974960327, acc: 0.4482758641242981)
[2024-12-17 03:33:42,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:43,259][root][INFO] - Training Epoch: 1/2, step 310/7134 completed (loss: 1.830960988998413, acc: 0.48391813039779663)
[2024-12-17 03:33:43,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:43,677][root][INFO] - Training Epoch: 1/2, step 311/7134 completed (loss: 1.8535059690475464, acc: 0.460342139005661)
[2024-12-17 03:33:43,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:44,106][root][INFO] - Training Epoch: 1/2, step 312/7134 completed (loss: 1.8048434257507324, acc: 0.49740034341812134)
[2024-12-17 03:33:44,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:44,536][root][INFO] - Training Epoch: 1/2, step 313/7134 completed (loss: 1.836934208869934, acc: 0.46782609820365906)
[2024-12-17 03:33:44,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:44,974][root][INFO] - Training Epoch: 1/2, step 314/7134 completed (loss: 1.8319944143295288, acc: 0.4859375059604645)
[2024-12-17 03:33:45,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:45,425][root][INFO] - Training Epoch: 1/2, step 315/7134 completed (loss: 1.7410025596618652, acc: 0.49508196115493774)
[2024-12-17 03:33:45,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:45,827][root][INFO] - Training Epoch: 1/2, step 316/7134 completed (loss: 1.8618083000183105, acc: 0.4638989269733429)
[2024-12-17 03:33:46,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:46,323][root][INFO] - Training Epoch: 1/2, step 317/7134 completed (loss: 1.8358566761016846, acc: 0.4817320704460144)
[2024-12-17 03:33:46,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:46,827][root][INFO] - Training Epoch: 1/2, step 318/7134 completed (loss: 2.0507805347442627, acc: 0.41514042019844055)
[2024-12-17 03:33:46,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:47,243][root][INFO] - Training Epoch: 1/2, step 319/7134 completed (loss: 2.168672561645508, acc: 0.3913043439388275)
[2024-12-17 03:33:47,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:47,756][root][INFO] - Training Epoch: 1/2, step 320/7134 completed (loss: 1.9526621103286743, acc: 0.43081313371658325)
[2024-12-17 03:33:47,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:48,229][root][INFO] - Training Epoch: 1/2, step 321/7134 completed (loss: 2.097862958908081, acc: 0.4240102171897888)
[2024-12-17 03:33:48,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:48,714][root][INFO] - Training Epoch: 1/2, step 322/7134 completed (loss: 2.093538999557495, acc: 0.4189189076423645)
[2024-12-17 03:33:48,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:49,170][root][INFO] - Training Epoch: 1/2, step 323/7134 completed (loss: 2.123173713684082, acc: 0.40308088064193726)
[2024-12-17 03:33:49,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:49,635][root][INFO] - Training Epoch: 1/2, step 324/7134 completed (loss: 2.073457717895508, acc: 0.4372842311859131)
[2024-12-17 03:33:49,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:50,123][root][INFO] - Training Epoch: 1/2, step 325/7134 completed (loss: 2.0046215057373047, acc: 0.43059125542640686)
[2024-12-17 03:33:50,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:50,578][root][INFO] - Training Epoch: 1/2, step 326/7134 completed (loss: 1.9491674900054932, acc: 0.4591960906982422)
[2024-12-17 03:33:50,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:51,044][root][INFO] - Training Epoch: 1/2, step 327/7134 completed (loss: 1.9720491170883179, acc: 0.44144144654273987)
[2024-12-17 03:33:51,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:51,544][root][INFO] - Training Epoch: 1/2, step 328/7134 completed (loss: 1.982701301574707, acc: 0.4503703713417053)
[2024-12-17 03:33:51,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:52,017][root][INFO] - Training Epoch: 1/2, step 329/7134 completed (loss: 1.9173005819320679, acc: 0.4547591209411621)
[2024-12-17 03:33:52,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:52,511][root][INFO] - Training Epoch: 1/2, step 330/7134 completed (loss: 1.9579148292541504, acc: 0.46324270963668823)
[2024-12-17 03:33:52,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:52,991][root][INFO] - Training Epoch: 1/2, step 331/7134 completed (loss: 1.9557167291641235, acc: 0.45039910078048706)
[2024-12-17 03:33:53,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:53,457][root][INFO] - Training Epoch: 1/2, step 332/7134 completed (loss: 1.8715646266937256, acc: 0.4710743725299835)
[2024-12-17 03:33:53,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:53,941][root][INFO] - Training Epoch: 1/2, step 333/7134 completed (loss: 2.034553050994873, acc: 0.4270072877407074)
[2024-12-17 03:33:54,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:54,409][root][INFO] - Training Epoch: 1/2, step 334/7134 completed (loss: 1.970036268234253, acc: 0.41318124532699585)
[2024-12-17 03:33:54,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:54,858][root][INFO] - Training Epoch: 1/2, step 335/7134 completed (loss: 1.9307985305786133, acc: 0.44687044620513916)
[2024-12-17 03:33:54,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:55,313][root][INFO] - Training Epoch: 1/2, step 336/7134 completed (loss: 1.948582649230957, acc: 0.4491018056869507)
[2024-12-17 03:33:55,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:55,761][root][INFO] - Training Epoch: 1/2, step 337/7134 completed (loss: 2.004389524459839, acc: 0.4309816062450409)
[2024-12-17 03:33:55,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:56,205][root][INFO] - Training Epoch: 1/2, step 338/7134 completed (loss: 1.9399263858795166, acc: 0.4722921848297119)
[2024-12-17 03:33:56,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:56,651][root][INFO] - Training Epoch: 1/2, step 339/7134 completed (loss: 1.8944507837295532, acc: 0.4637500047683716)
[2024-12-17 03:33:56,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:57,085][root][INFO] - Training Epoch: 1/2, step 340/7134 completed (loss: 2.03486704826355, acc: 0.40458014607429504)
[2024-12-17 03:33:57,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:57,572][root][INFO] - Training Epoch: 1/2, step 341/7134 completed (loss: 1.8328193426132202, acc: 0.49432533979415894)
[2024-12-17 03:33:57,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:58,061][root][INFO] - Training Epoch: 1/2, step 342/7134 completed (loss: 1.9003406763076782, acc: 0.47575756907463074)
[2024-12-17 03:33:58,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:58,527][root][INFO] - Training Epoch: 1/2, step 343/7134 completed (loss: 2.1085281372070312, acc: 0.4291115403175354)
[2024-12-17 03:33:58,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:58,939][root][INFO] - Training Epoch: 1/2, step 344/7134 completed (loss: 1.966568112373352, acc: 0.45802921056747437)
[2024-12-17 03:33:59,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:59,333][root][INFO] - Training Epoch: 1/2, step 345/7134 completed (loss: 1.969478726387024, acc: 0.4464285671710968)
[2024-12-17 03:33:59,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:59,832][root][INFO] - Training Epoch: 1/2, step 346/7134 completed (loss: 1.8566356897354126, acc: 0.46104928851127625)
[2024-12-17 03:33:59,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:00,266][root][INFO] - Training Epoch: 1/2, step 347/7134 completed (loss: 1.9832301139831543, acc: 0.4417952299118042)
[2024-12-17 03:34:00,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:00,722][root][INFO] - Training Epoch: 1/2, step 348/7134 completed (loss: 1.8688852787017822, acc: 0.4789687991142273)
[2024-12-17 03:34:00,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:01,172][root][INFO] - Training Epoch: 1/2, step 349/7134 completed (loss: 1.9323160648345947, acc: 0.43892616033554077)
[2024-12-17 03:34:01,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:01,707][root][INFO] - Training Epoch: 1/2, step 350/7134 completed (loss: 1.9371474981307983, acc: 0.4560770094394684)
[2024-12-17 03:34:01,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:02,221][root][INFO] - Training Epoch: 1/2, step 351/7134 completed (loss: 1.9465168714523315, acc: 0.46310433745384216)
[2024-12-17 03:34:02,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:02,691][root][INFO] - Training Epoch: 1/2, step 352/7134 completed (loss: 1.839942216873169, acc: 0.47146740555763245)
[2024-12-17 03:34:02,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:03,181][root][INFO] - Training Epoch: 1/2, step 353/7134 completed (loss: 1.8087375164031982, acc: 0.4680851101875305)
[2024-12-17 03:34:03,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:03,636][root][INFO] - Training Epoch: 1/2, step 354/7134 completed (loss: 1.812729835510254, acc: 0.48195576667785645)
[2024-12-17 03:34:03,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:04,090][root][INFO] - Training Epoch: 1/2, step 355/7134 completed (loss: 1.9240816831588745, acc: 0.45949721336364746)
[2024-12-17 03:34:04,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:04,582][root][INFO] - Training Epoch: 1/2, step 356/7134 completed (loss: 1.8878250122070312, acc: 0.48148149251937866)
[2024-12-17 03:34:04,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:05,079][root][INFO] - Training Epoch: 1/2, step 357/7134 completed (loss: 1.8564866781234741, acc: 0.46055978536605835)
[2024-12-17 03:34:05,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:05,529][root][INFO] - Training Epoch: 1/2, step 358/7134 completed (loss: 1.8375416994094849, acc: 0.4829467833042145)
[2024-12-17 03:34:05,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:06,006][root][INFO] - Training Epoch: 1/2, step 359/7134 completed (loss: 1.9057703018188477, acc: 0.44999998807907104)
[2024-12-17 03:34:06,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:06,429][root][INFO] - Training Epoch: 1/2, step 360/7134 completed (loss: 1.809226393699646, acc: 0.4819277226924896)
[2024-12-17 03:34:06,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:06,914][root][INFO] - Training Epoch: 1/2, step 361/7134 completed (loss: 1.8724820613861084, acc: 0.47723934054374695)
[2024-12-17 03:34:07,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:07,391][root][INFO] - Training Epoch: 1/2, step 362/7134 completed (loss: 1.9030646085739136, acc: 0.46706587076187134)
[2024-12-17 03:34:07,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:07,856][root][INFO] - Training Epoch: 1/2, step 363/7134 completed (loss: 1.8742634057998657, acc: 0.4375)
[2024-12-17 03:34:07,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:08,282][root][INFO] - Training Epoch: 1/2, step 364/7134 completed (loss: 1.878843069076538, acc: 0.4532710313796997)
[2024-12-17 03:34:08,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:08,767][root][INFO] - Training Epoch: 1/2, step 365/7134 completed (loss: 1.8416367769241333, acc: 0.4807162582874298)
[2024-12-17 03:34:08,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:09,232][root][INFO] - Training Epoch: 1/2, step 366/7134 completed (loss: 1.878354787826538, acc: 0.4655172526836395)
[2024-12-17 03:34:09,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:09,712][root][INFO] - Training Epoch: 1/2, step 367/7134 completed (loss: 1.811333417892456, acc: 0.5012500286102295)
[2024-12-17 03:34:09,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:10,152][root][INFO] - Training Epoch: 1/2, step 368/7134 completed (loss: 1.769430160522461, acc: 0.48885586857795715)
[2024-12-17 03:34:10,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:10,569][root][INFO] - Training Epoch: 1/2, step 369/7134 completed (loss: 1.8588979244232178, acc: 0.4839203655719757)
[2024-12-17 03:34:10,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:11,043][root][INFO] - Training Epoch: 1/2, step 370/7134 completed (loss: 1.9274863004684448, acc: 0.44687044620513916)
[2024-12-17 03:34:11,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:11,500][root][INFO] - Training Epoch: 1/2, step 371/7134 completed (loss: 1.8078097105026245, acc: 0.4706766903400421)
[2024-12-17 03:34:11,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:11,940][root][INFO] - Training Epoch: 1/2, step 372/7134 completed (loss: 1.8512181043624878, acc: 0.47845467925071716)
[2024-12-17 03:34:12,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:12,411][root][INFO] - Training Epoch: 1/2, step 373/7134 completed (loss: 1.8322523832321167, acc: 0.4828101694583893)
[2024-12-17 03:34:12,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:12,869][root][INFO] - Training Epoch: 1/2, step 374/7134 completed (loss: 1.8051007986068726, acc: 0.47749197483062744)
[2024-12-17 03:34:12,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:13,359][root][INFO] - Training Epoch: 1/2, step 375/7134 completed (loss: 1.7953165769577026, acc: 0.47925034165382385)
[2024-12-17 03:34:13,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:13,824][root][INFO] - Training Epoch: 1/2, step 376/7134 completed (loss: 1.8734235763549805, acc: 0.46482759714126587)
[2024-12-17 03:34:13,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:14,328][root][INFO] - Training Epoch: 1/2, step 377/7134 completed (loss: 1.85332453250885, acc: 0.4828060567378998)
[2024-12-17 03:34:14,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:14,768][root][INFO] - Training Epoch: 1/2, step 378/7134 completed (loss: 1.8739619255065918, acc: 0.4550408720970154)
[2024-12-17 03:34:14,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:15,247][root][INFO] - Training Epoch: 1/2, step 379/7134 completed (loss: 1.8352142572402954, acc: 0.48241207003593445)
[2024-12-17 03:34:15,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:15,727][root][INFO] - Training Epoch: 1/2, step 380/7134 completed (loss: 1.9880033731460571, acc: 0.44152429699897766)
[2024-12-17 03:34:15,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:16,198][root][INFO] - Training Epoch: 1/2, step 381/7134 completed (loss: 1.8536049127578735, acc: 0.46124032139778137)
[2024-12-17 03:34:16,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:16,685][root][INFO] - Training Epoch: 1/2, step 382/7134 completed (loss: 1.8567752838134766, acc: 0.5032092332839966)
[2024-12-17 03:34:16,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:17,113][root][INFO] - Training Epoch: 1/2, step 383/7134 completed (loss: 1.7954905033111572, acc: 0.47258979082107544)
[2024-12-17 03:34:17,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:17,574][root][INFO] - Training Epoch: 1/2, step 384/7134 completed (loss: 1.7995566129684448, acc: 0.4926568865776062)
[2024-12-17 03:34:17,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:18,022][root][INFO] - Training Epoch: 1/2, step 385/7134 completed (loss: 1.7644362449645996, acc: 0.45996859669685364)
[2024-12-17 03:34:18,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:18,391][root][INFO] - Training Epoch: 1/2, step 386/7134 completed (loss: 1.6982520818710327, acc: 0.511247456073761)
[2024-12-17 03:34:18,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:18,876][root][INFO] - Training Epoch: 1/2, step 387/7134 completed (loss: 1.783252239227295, acc: 0.4737609326839447)
[2024-12-17 03:34:18,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:19,334][root][INFO] - Training Epoch: 1/2, step 388/7134 completed (loss: 1.7748135328292847, acc: 0.48943662643432617)
[2024-12-17 03:34:19,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:19,809][root][INFO] - Training Epoch: 1/2, step 389/7134 completed (loss: 1.7090264558792114, acc: 0.5151515007019043)
[2024-12-17 03:34:19,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:20,275][root][INFO] - Training Epoch: 1/2, step 390/7134 completed (loss: 1.7637383937835693, acc: 0.48220065236091614)
[2024-12-17 03:34:20,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:20,684][root][INFO] - Training Epoch: 1/2, step 391/7134 completed (loss: 1.7589335441589355, acc: 0.5)
[2024-12-17 03:34:20,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:21,156][root][INFO] - Training Epoch: 1/2, step 392/7134 completed (loss: 1.743455171585083, acc: 0.4977777898311615)
[2024-12-17 03:34:21,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:21,601][root][INFO] - Training Epoch: 1/2, step 393/7134 completed (loss: 1.866592288017273, acc: 0.4722222089767456)
[2024-12-17 03:34:21,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:22,071][root][INFO] - Training Epoch: 1/2, step 394/7134 completed (loss: 1.6837680339813232, acc: 0.5175096988677979)
[2024-12-17 03:34:22,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:22,510][root][INFO] - Training Epoch: 1/2, step 395/7134 completed (loss: 1.715108036994934, acc: 0.49519890546798706)
[2024-12-17 03:34:22,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:22,939][root][INFO] - Training Epoch: 1/2, step 396/7134 completed (loss: 1.7434391975402832, acc: 0.501075267791748)
[2024-12-17 03:34:23,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:23,433][root][INFO] - Training Epoch: 1/2, step 397/7134 completed (loss: 1.7632883787155151, acc: 0.5039682388305664)
[2024-12-17 03:34:23,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:23,882][root][INFO] - Training Epoch: 1/2, step 398/7134 completed (loss: 1.651222586631775, acc: 0.5347937941551208)
[2024-12-17 03:34:23,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:24,314][root][INFO] - Training Epoch: 1/2, step 399/7134 completed (loss: 1.6171640157699585, acc: 0.5641838312149048)
[2024-12-17 03:34:24,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:24,778][root][INFO] - Training Epoch: 1/2, step 400/7134 completed (loss: 2.1024746894836426, acc: 0.4119403064250946)
[2024-12-17 03:34:24,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:25,268][root][INFO] - Training Epoch: 1/2, step 401/7134 completed (loss: 1.8199902772903442, acc: 0.4840686321258545)
[2024-12-17 03:34:25,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:25,718][root][INFO] - Training Epoch: 1/2, step 402/7134 completed (loss: 1.8513213396072388, acc: 0.4752851724624634)
[2024-12-17 03:34:25,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:26,227][root][INFO] - Training Epoch: 1/2, step 403/7134 completed (loss: 1.81594979763031, acc: 0.5)
[2024-12-17 03:34:26,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:26,649][root][INFO] - Training Epoch: 1/2, step 404/7134 completed (loss: 1.8212404251098633, acc: 0.48461538553237915)
[2024-12-17 03:34:26,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:27,156][root][INFO] - Training Epoch: 1/2, step 405/7134 completed (loss: 1.9118688106536865, acc: 0.47663551568984985)
[2024-12-17 03:34:27,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:27,662][root][INFO] - Training Epoch: 1/2, step 406/7134 completed (loss: 1.7907123565673828, acc: 0.4978354871273041)
[2024-12-17 03:34:27,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:28,073][root][INFO] - Training Epoch: 1/2, step 407/7134 completed (loss: 1.8748832941055298, acc: 0.47288134694099426)
[2024-12-17 03:34:28,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:28,514][root][INFO] - Training Epoch: 1/2, step 408/7134 completed (loss: 1.839786171913147, acc: 0.49794238805770874)
[2024-12-17 03:34:28,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:28,972][root][INFO] - Training Epoch: 1/2, step 409/7134 completed (loss: 1.8020120859146118, acc: 0.49433961510658264)
[2024-12-17 03:34:29,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:29,485][root][INFO] - Training Epoch: 1/2, step 410/7134 completed (loss: 1.78438401222229, acc: 0.4881305694580078)
[2024-12-17 03:34:29,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:29,958][root][INFO] - Training Epoch: 1/2, step 411/7134 completed (loss: 1.884926199913025, acc: 0.4775604009628296)
[2024-12-17 03:34:30,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:30,435][root][INFO] - Training Epoch: 1/2, step 412/7134 completed (loss: 1.8473247289657593, acc: 0.45995423197746277)
[2024-12-17 03:34:30,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:30,860][root][INFO] - Training Epoch: 1/2, step 413/7134 completed (loss: 1.897777795791626, acc: 0.4819759726524353)
[2024-12-17 03:34:30,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:31,307][root][INFO] - Training Epoch: 1/2, step 414/7134 completed (loss: 1.8243827819824219, acc: 0.4658753573894501)
[2024-12-17 03:34:31,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:31,779][root][INFO] - Training Epoch: 1/2, step 415/7134 completed (loss: 1.7834258079528809, acc: 0.4756944477558136)
[2024-12-17 03:34:31,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:32,265][root][INFO] - Training Epoch: 1/2, step 416/7134 completed (loss: 1.73810613155365, acc: 0.4876033067703247)
[2024-12-17 03:34:32,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:32,742][root][INFO] - Training Epoch: 1/2, step 417/7134 completed (loss: 1.8629785776138306, acc: 0.48641303181648254)
[2024-12-17 03:34:32,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:33,235][root][INFO] - Training Epoch: 1/2, step 418/7134 completed (loss: 1.8086023330688477, acc: 0.48450058698654175)
[2024-12-17 03:34:33,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:33,700][root][INFO] - Training Epoch: 1/2, step 419/7134 completed (loss: 1.7279502153396606, acc: 0.5086848735809326)
[2024-12-17 03:34:33,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:34,160][root][INFO] - Training Epoch: 1/2, step 420/7134 completed (loss: 1.7893774509429932, acc: 0.48900169134140015)
[2024-12-17 03:34:34,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:34,652][root][INFO] - Training Epoch: 1/2, step 421/7134 completed (loss: 1.7615041732788086, acc: 0.506369411945343)
[2024-12-17 03:34:34,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:35,110][root][INFO] - Training Epoch: 1/2, step 422/7134 completed (loss: 1.580997109413147, acc: 0.533823549747467)
[2024-12-17 03:34:35,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:35,569][root][INFO] - Training Epoch: 1/2, step 423/7134 completed (loss: 1.6640249490737915, acc: 0.5257142782211304)
[2024-12-17 03:34:35,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:35,997][root][INFO] - Training Epoch: 1/2, step 424/7134 completed (loss: 1.662134051322937, acc: 0.517405092716217)
[2024-12-17 03:34:36,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:36,453][root][INFO] - Training Epoch: 1/2, step 425/7134 completed (loss: 1.552685260772705, acc: 0.5566860437393188)
[2024-12-17 03:34:36,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:36,881][root][INFO] - Training Epoch: 1/2, step 426/7134 completed (loss: 1.7130507230758667, acc: 0.5194985866546631)
[2024-12-17 03:34:36,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:37,296][root][INFO] - Training Epoch: 1/2, step 427/7134 completed (loss: 1.7966562509536743, acc: 0.4643399119377136)
[2024-12-17 03:34:37,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:37,757][root][INFO] - Training Epoch: 1/2, step 428/7134 completed (loss: 1.786805510520935, acc: 0.47439759969711304)
[2024-12-17 03:34:37,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:38,182][root][INFO] - Training Epoch: 1/2, step 429/7134 completed (loss: 1.7538573741912842, acc: 0.4960254430770874)
[2024-12-17 03:34:38,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:38,632][root][INFO] - Training Epoch: 1/2, step 430/7134 completed (loss: 1.792922019958496, acc: 0.5050215125083923)
[2024-12-17 03:34:38,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:39,066][root][INFO] - Training Epoch: 1/2, step 431/7134 completed (loss: 1.7381280660629272, acc: 0.5158501267433167)
[2024-12-17 03:34:39,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:39,531][root][INFO] - Training Epoch: 1/2, step 432/7134 completed (loss: 1.7886427640914917, acc: 0.4954296052455902)
[2024-12-17 03:34:39,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:40,031][root][INFO] - Training Epoch: 1/2, step 433/7134 completed (loss: 1.5700039863586426, acc: 0.5285326242446899)
[2024-12-17 03:34:40,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:40,488][root][INFO] - Training Epoch: 1/2, step 434/7134 completed (loss: 1.7433820962905884, acc: 0.47437775135040283)
[2024-12-17 03:34:40,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:40,938][root][INFO] - Training Epoch: 1/2, step 435/7134 completed (loss: 1.7734830379486084, acc: 0.479432612657547)
[2024-12-17 03:34:41,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:41,355][root][INFO] - Training Epoch: 1/2, step 436/7134 completed (loss: 1.655661702156067, acc: 0.5334645509719849)
[2024-12-17 03:34:41,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:41,765][root][INFO] - Training Epoch: 1/2, step 437/7134 completed (loss: 1.65622878074646, acc: 0.5053003430366516)
[2024-12-17 03:34:41,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:42,169][root][INFO] - Training Epoch: 1/2, step 438/7134 completed (loss: 1.6956833600997925, acc: 0.517307698726654)
[2024-12-17 03:34:42,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:42,687][root][INFO] - Training Epoch: 1/2, step 439/7134 completed (loss: 1.9508590698242188, acc: 0.45157068967819214)
[2024-12-17 03:34:42,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:43,173][root][INFO] - Training Epoch: 1/2, step 440/7134 completed (loss: 1.8932780027389526, acc: 0.46447139978408813)
[2024-12-17 03:34:43,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:43,650][root][INFO] - Training Epoch: 1/2, step 441/7134 completed (loss: 1.7844467163085938, acc: 0.4962518811225891)
[2024-12-17 03:34:43,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:44,105][root][INFO] - Training Epoch: 1/2, step 442/7134 completed (loss: 1.5802574157714844, acc: 0.5485074520111084)
[2024-12-17 03:34:44,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:44,555][root][INFO] - Training Epoch: 1/2, step 443/7134 completed (loss: 1.7982605695724487, acc: 0.47596898674964905)
[2024-12-17 03:34:44,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:44,979][root][INFO] - Training Epoch: 1/2, step 444/7134 completed (loss: 1.6974886655807495, acc: 0.5166666507720947)
[2024-12-17 03:34:45,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:45,411][root][INFO] - Training Epoch: 1/2, step 445/7134 completed (loss: 1.762723445892334, acc: 0.4854227304458618)
[2024-12-17 03:34:45,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:45,856][root][INFO] - Training Epoch: 1/2, step 446/7134 completed (loss: 1.7462974786758423, acc: 0.5)
[2024-12-17 03:34:45,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:46,305][root][INFO] - Training Epoch: 1/2, step 447/7134 completed (loss: 1.7792222499847412, acc: 0.49514561891555786)
[2024-12-17 03:34:46,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:46,783][root][INFO] - Training Epoch: 1/2, step 448/7134 completed (loss: 1.8270739316940308, acc: 0.49872124195098877)
[2024-12-17 03:34:46,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:47,252][root][INFO] - Training Epoch: 1/2, step 449/7134 completed (loss: 1.8341740369796753, acc: 0.4803664982318878)
[2024-12-17 03:34:47,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:47,731][root][INFO] - Training Epoch: 1/2, step 450/7134 completed (loss: 1.8831075429916382, acc: 0.46178343892097473)
[2024-12-17 03:34:47,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:48,204][root][INFO] - Training Epoch: 1/2, step 451/7134 completed (loss: 1.8267810344696045, acc: 0.47681331634521484)
[2024-12-17 03:34:48,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:48,674][root][INFO] - Training Epoch: 1/2, step 452/7134 completed (loss: 1.9168164730072021, acc: 0.4561643898487091)
[2024-12-17 03:34:48,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:49,088][root][INFO] - Training Epoch: 1/2, step 453/7134 completed (loss: 1.7842596769332886, acc: 0.4587155878543854)
[2024-12-17 03:34:49,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:49,561][root][INFO] - Training Epoch: 1/2, step 454/7134 completed (loss: 1.773241400718689, acc: 0.49085038900375366)
[2024-12-17 03:34:49,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:50,028][root][INFO] - Training Epoch: 1/2, step 455/7134 completed (loss: 1.8978008031845093, acc: 0.4627451002597809)
[2024-12-17 03:34:50,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:50,520][root][INFO] - Training Epoch: 1/2, step 456/7134 completed (loss: 1.8096429109573364, acc: 0.4617563784122467)
[2024-12-17 03:34:50,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:50,983][root][INFO] - Training Epoch: 1/2, step 457/7134 completed (loss: 1.8914610147476196, acc: 0.4463087320327759)
[2024-12-17 03:34:51,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:51,437][root][INFO] - Training Epoch: 1/2, step 458/7134 completed (loss: 1.9032186269760132, acc: 0.4512922465801239)
[2024-12-17 03:34:51,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:51,902][root][INFO] - Training Epoch: 1/2, step 459/7134 completed (loss: 1.9555624723434448, acc: 0.44296297430992126)
[2024-12-17 03:34:52,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:52,352][root][INFO] - Training Epoch: 1/2, step 460/7134 completed (loss: 1.774950623512268, acc: 0.4929133951663971)
[2024-12-17 03:34:52,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:52,831][root][INFO] - Training Epoch: 1/2, step 461/7134 completed (loss: 1.8893496990203857, acc: 0.4614305794239044)
[2024-12-17 03:34:52,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:53,354][root][INFO] - Training Epoch: 1/2, step 462/7134 completed (loss: 1.760504126548767, acc: 0.49182242155075073)
[2024-12-17 03:34:53,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:53,926][root][INFO] - Training Epoch: 1/2, step 463/7134 completed (loss: 1.8994308710098267, acc: 0.461731493473053)
[2024-12-17 03:34:54,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:54,417][root][INFO] - Training Epoch: 1/2, step 464/7134 completed (loss: 1.8459908962249756, acc: 0.4504249393939972)
[2024-12-17 03:34:54,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:54,877][root][INFO] - Training Epoch: 1/2, step 465/7134 completed (loss: 1.8262767791748047, acc: 0.48433420062065125)
[2024-12-17 03:34:55,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:55,361][root][INFO] - Training Epoch: 1/2, step 466/7134 completed (loss: 1.8260153532028198, acc: 0.4620334506034851)
[2024-12-17 03:34:55,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:55,847][root][INFO] - Training Epoch: 1/2, step 467/7134 completed (loss: 1.8941271305084229, acc: 0.45979616045951843)
[2024-12-17 03:34:56,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:56,295][root][INFO] - Training Epoch: 1/2, step 468/7134 completed (loss: 1.9237446784973145, acc: 0.4291609227657318)
[2024-12-17 03:34:56,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:56,741][root][INFO] - Training Epoch: 1/2, step 469/7134 completed (loss: 1.9325975179672241, acc: 0.42363113164901733)
[2024-12-17 03:34:56,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:57,173][root][INFO] - Training Epoch: 1/2, step 470/7134 completed (loss: 1.878387689590454, acc: 0.46666666865348816)
[2024-12-17 03:34:57,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:57,634][root][INFO] - Training Epoch: 1/2, step 471/7134 completed (loss: 1.820847749710083, acc: 0.45443788170814514)
[2024-12-17 03:34:57,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:58,144][root][INFO] - Training Epoch: 1/2, step 472/7134 completed (loss: 1.8572880029678345, acc: 0.47507330775260925)
[2024-12-17 03:34:58,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:58,604][root][INFO] - Training Epoch: 1/2, step 473/7134 completed (loss: 1.8164114952087402, acc: 0.4645061790943146)
[2024-12-17 03:34:58,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:59,064][root][INFO] - Training Epoch: 1/2, step 474/7134 completed (loss: 1.8959883451461792, acc: 0.4624505937099457)
[2024-12-17 03:34:59,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:59,537][root][INFO] - Training Epoch: 1/2, step 475/7134 completed (loss: 1.8473010063171387, acc: 0.4676470458507538)
[2024-12-17 03:34:59,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:00,002][root][INFO] - Training Epoch: 1/2, step 476/7134 completed (loss: 1.885333776473999, acc: 0.4584527313709259)
[2024-12-17 03:35:00,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:00,485][root][INFO] - Training Epoch: 1/2, step 477/7134 completed (loss: 1.8714333772659302, acc: 0.46454766392707825)
[2024-12-17 03:35:00,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:00,892][root][INFO] - Training Epoch: 1/2, step 478/7134 completed (loss: 1.8109644651412964, acc: 0.49894291162490845)
[2024-12-17 03:35:01,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:01,314][root][INFO] - Training Epoch: 1/2, step 479/7134 completed (loss: 1.839961290359497, acc: 0.4619799256324768)
[2024-12-17 03:35:01,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:01,742][root][INFO] - Training Epoch: 1/2, step 480/7134 completed (loss: 1.8678637742996216, acc: 0.4642335772514343)
[2024-12-17 03:35:01,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:02,203][root][INFO] - Training Epoch: 1/2, step 481/7134 completed (loss: 1.8199553489685059, acc: 0.5)
[2024-12-17 03:35:02,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:02,682][root][INFO] - Training Epoch: 1/2, step 482/7134 completed (loss: 1.7802680730819702, acc: 0.47285714745521545)
[2024-12-17 03:35:02,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:03,139][root][INFO] - Training Epoch: 1/2, step 483/7134 completed (loss: 1.8047196865081787, acc: 0.4754299819469452)
[2024-12-17 03:35:03,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:03,572][root][INFO] - Training Epoch: 1/2, step 484/7134 completed (loss: 1.9382288455963135, acc: 0.437165766954422)
[2024-12-17 03:35:03,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:03,997][root][INFO] - Training Epoch: 1/2, step 485/7134 completed (loss: 1.770708680152893, acc: 0.49621784687042236)
[2024-12-17 03:35:04,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:04,431][root][INFO] - Training Epoch: 1/2, step 486/7134 completed (loss: 1.9492648839950562, acc: 0.4243420958518982)
[2024-12-17 03:35:04,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:04,898][root][INFO] - Training Epoch: 1/2, step 487/7134 completed (loss: 1.875685691833496, acc: 0.45521292090415955)
[2024-12-17 03:35:04,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:05,303][root][INFO] - Training Epoch: 1/2, step 488/7134 completed (loss: 1.88261878490448, acc: 0.4637681245803833)
[2024-12-17 03:35:05,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:05,742][root][INFO] - Training Epoch: 1/2, step 489/7134 completed (loss: 1.8483086824417114, acc: 0.45378151535987854)
[2024-12-17 03:35:05,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:06,169][root][INFO] - Training Epoch: 1/2, step 490/7134 completed (loss: 1.7320024967193604, acc: 0.5224489569664001)
[2024-12-17 03:35:06,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:06,585][root][INFO] - Training Epoch: 1/2, step 491/7134 completed (loss: 1.8824363946914673, acc: 0.4753289520740509)
[2024-12-17 03:35:06,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:07,013][root][INFO] - Training Epoch: 1/2, step 492/7134 completed (loss: 1.716227650642395, acc: 0.49016642570495605)
[2024-12-17 03:35:07,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:07,526][root][INFO] - Training Epoch: 1/2, step 493/7134 completed (loss: 1.7814297676086426, acc: 0.48424068093299866)
[2024-12-17 03:35:07,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:08,031][root][INFO] - Training Epoch: 1/2, step 494/7134 completed (loss: 1.730141043663025, acc: 0.518750011920929)
[2024-12-17 03:35:08,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:08,520][root][INFO] - Training Epoch: 1/2, step 495/7134 completed (loss: 1.8809664249420166, acc: 0.4941176474094391)
[2024-12-17 03:35:08,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:08,941][root][INFO] - Training Epoch: 1/2, step 496/7134 completed (loss: 1.9254295825958252, acc: 0.4471544623374939)
[2024-12-17 03:35:09,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:09,386][root][INFO] - Training Epoch: 1/2, step 497/7134 completed (loss: 1.9053431749343872, acc: 0.45736435055732727)
[2024-12-17 03:35:09,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:09,828][root][INFO] - Training Epoch: 1/2, step 498/7134 completed (loss: 1.847438931465149, acc: 0.47756409645080566)
[2024-12-17 03:35:09,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:10,310][root][INFO] - Training Epoch: 1/2, step 499/7134 completed (loss: 1.8011255264282227, acc: 0.4895688593387604)
[2024-12-17 03:35:10,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:10,743][root][INFO] - Training Epoch: 1/2, step 500/7134 completed (loss: 1.7995001077651978, acc: 0.47866666316986084)
[2024-12-17 03:35:10,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:11,247][root][INFO] - Training Epoch: 1/2, step 501/7134 completed (loss: 1.8864774703979492, acc: 0.4570637047290802)
[2024-12-17 03:35:11,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:11,674][root][INFO] - Training Epoch: 1/2, step 502/7134 completed (loss: 1.714086890220642, acc: 0.49082568287849426)
[2024-12-17 03:35:11,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:12,078][root][INFO] - Training Epoch: 1/2, step 503/7134 completed (loss: 1.7937067747116089, acc: 0.48322147130966187)
[2024-12-17 03:35:12,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:12,527][root][INFO] - Training Epoch: 1/2, step 504/7134 completed (loss: 1.8108689785003662, acc: 0.46927374601364136)
[2024-12-17 03:35:12,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:12,945][root][INFO] - Training Epoch: 1/2, step 505/7134 completed (loss: 1.759132742881775, acc: 0.47905758023262024)
[2024-12-17 03:35:13,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:13,454][root][INFO] - Training Epoch: 1/2, step 506/7134 completed (loss: 1.7531570196151733, acc: 0.49751242995262146)
[2024-12-17 03:35:13,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:13,950][root][INFO] - Training Epoch: 1/2, step 507/7134 completed (loss: 1.7403932809829712, acc: 0.5013157725334167)
[2024-12-17 03:35:14,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:14,415][root][INFO] - Training Epoch: 1/2, step 508/7134 completed (loss: 1.7887201309204102, acc: 0.4846368730068207)
[2024-12-17 03:35:14,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:14,937][root][INFO] - Training Epoch: 1/2, step 509/7134 completed (loss: 1.8384534120559692, acc: 0.455950528383255)
[2024-12-17 03:35:15,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:15,371][root][INFO] - Training Epoch: 1/2, step 510/7134 completed (loss: 1.971280813217163, acc: 0.45322245359420776)
[2024-12-17 03:35:15,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:15,811][root][INFO] - Training Epoch: 1/2, step 511/7134 completed (loss: 1.8650577068328857, acc: 0.48655256628990173)
[2024-12-17 03:35:15,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:16,239][root][INFO] - Training Epoch: 1/2, step 512/7134 completed (loss: 1.922063946723938, acc: 0.46893787384033203)
[2024-12-17 03:35:16,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:16,674][root][INFO] - Training Epoch: 1/2, step 513/7134 completed (loss: 1.7885445356369019, acc: 0.49225473403930664)
[2024-12-17 03:35:16,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:17,069][root][INFO] - Training Epoch: 1/2, step 514/7134 completed (loss: 1.850048303604126, acc: 0.44723618030548096)
[2024-12-17 03:35:17,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:17,545][root][INFO] - Training Epoch: 1/2, step 515/7134 completed (loss: 1.7636529207229614, acc: 0.4936350882053375)
[2024-12-17 03:35:17,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:17,884][root][INFO] - Training Epoch: 1/2, step 516/7134 completed (loss: 1.6922715902328491, acc: 0.4942791759967804)
[2024-12-17 03:35:17,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:18,308][root][INFO] - Training Epoch: 1/2, step 517/7134 completed (loss: 1.8217108249664307, acc: 0.47132617235183716)
[2024-12-17 03:35:18,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:18,762][root][INFO] - Training Epoch: 1/2, step 518/7134 completed (loss: 1.758458137512207, acc: 0.5022488832473755)
[2024-12-17 03:35:18,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:19,204][root][INFO] - Training Epoch: 1/2, step 519/7134 completed (loss: 1.7732923030853271, acc: 0.49484536051750183)
[2024-12-17 03:35:19,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:19,629][root][INFO] - Training Epoch: 1/2, step 520/7134 completed (loss: 1.7897790670394897, acc: 0.4794303774833679)
[2024-12-17 03:35:19,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:20,067][root][INFO] - Training Epoch: 1/2, step 521/7134 completed (loss: 1.8130831718444824, acc: 0.4672897160053253)
[2024-12-17 03:35:20,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:20,528][root][INFO] - Training Epoch: 1/2, step 522/7134 completed (loss: 1.7338643074035645, acc: 0.5067024230957031)
[2024-12-17 03:35:20,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:20,988][root][INFO] - Training Epoch: 1/2, step 523/7134 completed (loss: 1.7522650957107544, acc: 0.5)
[2024-12-17 03:35:21,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:21,429][root][INFO] - Training Epoch: 1/2, step 524/7134 completed (loss: 1.7498126029968262, acc: 0.5147849321365356)
[2024-12-17 03:35:21,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:21,897][root][INFO] - Training Epoch: 1/2, step 525/7134 completed (loss: 1.773645043373108, acc: 0.5023183822631836)
[2024-12-17 03:35:22,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:22,361][root][INFO] - Training Epoch: 1/2, step 526/7134 completed (loss: 1.7936280965805054, acc: 0.4931506812572479)
[2024-12-17 03:35:22,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:22,781][root][INFO] - Training Epoch: 1/2, step 527/7134 completed (loss: 1.7503968477249146, acc: 0.4776119291782379)
[2024-12-17 03:35:22,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:23,237][root][INFO] - Training Epoch: 1/2, step 528/7134 completed (loss: 1.7236275672912598, acc: 0.4869215190410614)
[2024-12-17 03:35:23,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:23,734][root][INFO] - Training Epoch: 1/2, step 529/7134 completed (loss: 1.749807357788086, acc: 0.48571428656578064)
[2024-12-17 03:35:23,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:24,164][root][INFO] - Training Epoch: 1/2, step 530/7134 completed (loss: 1.678970217704773, acc: 0.5265865921974182)
[2024-12-17 03:35:24,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:24,562][root][INFO] - Training Epoch: 1/2, step 531/7134 completed (loss: 1.6619718074798584, acc: 0.5213675498962402)
[2024-12-17 03:35:24,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:24,982][root][INFO] - Training Epoch: 1/2, step 532/7134 completed (loss: 1.6711431741714478, acc: 0.5239084959030151)
[2024-12-17 03:35:25,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:25,448][root][INFO] - Training Epoch: 1/2, step 533/7134 completed (loss: 1.7696342468261719, acc: 0.5)
[2024-12-17 03:35:25,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:25,940][root][INFO] - Training Epoch: 1/2, step 534/7134 completed (loss: 1.6138335466384888, acc: 0.5068681240081787)
[2024-12-17 03:35:26,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:26,456][root][INFO] - Training Epoch: 1/2, step 535/7134 completed (loss: 1.7641915082931519, acc: 0.48330405354499817)
[2024-12-17 03:35:26,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:26,902][root][INFO] - Training Epoch: 1/2, step 536/7134 completed (loss: 1.760738492012024, acc: 0.47445255517959595)
[2024-12-17 03:35:26,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:27,315][root][INFO] - Training Epoch: 1/2, step 537/7134 completed (loss: 1.7983614206314087, acc: 0.48306334018707275)
[2024-12-17 03:35:27,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:27,759][root][INFO] - Training Epoch: 1/2, step 538/7134 completed (loss: 1.7762101888656616, acc: 0.5133531093597412)
[2024-12-17 03:35:27,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:28,206][root][INFO] - Training Epoch: 1/2, step 539/7134 completed (loss: 1.8905713558197021, acc: 0.45155709981918335)
[2024-12-17 03:35:28,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:28,613][root][INFO] - Training Epoch: 1/2, step 540/7134 completed (loss: 1.9169241189956665, acc: 0.45656564831733704)
[2024-12-17 03:35:28,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:29,083][root][INFO] - Training Epoch: 1/2, step 541/7134 completed (loss: 1.8894792795181274, acc: 0.4760638177394867)
[2024-12-17 03:35:29,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:29,459][root][INFO] - Training Epoch: 1/2, step 542/7134 completed (loss: 1.9822449684143066, acc: 0.4084506928920746)
[2024-12-17 03:35:29,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:29,900][root][INFO] - Training Epoch: 1/2, step 543/7134 completed (loss: 1.9886772632598877, acc: 0.43761301040649414)
[2024-12-17 03:35:29,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:30,345][root][INFO] - Training Epoch: 1/2, step 544/7134 completed (loss: 1.9133766889572144, acc: 0.45425868034362793)
[2024-12-17 03:35:30,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:30,828][root][INFO] - Training Epoch: 1/2, step 545/7134 completed (loss: 1.9061791896820068, acc: 0.4508856534957886)
[2024-12-17 03:35:30,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:31,259][root][INFO] - Training Epoch: 1/2, step 546/7134 completed (loss: 1.9792430400848389, acc: 0.4515366554260254)
[2024-12-17 03:35:31,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:31,719][root][INFO] - Training Epoch: 1/2, step 547/7134 completed (loss: 1.7988327741622925, acc: 0.4746008813381195)
[2024-12-17 03:35:31,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:32,163][root][INFO] - Training Epoch: 1/2, step 548/7134 completed (loss: 1.8002681732177734, acc: 0.48631030321121216)
[2024-12-17 03:35:32,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:32,599][root][INFO] - Training Epoch: 1/2, step 549/7134 completed (loss: 1.9062670469284058, acc: 0.45962733030319214)
[2024-12-17 03:35:32,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:33,029][root][INFO] - Training Epoch: 1/2, step 550/7134 completed (loss: 1.914466381072998, acc: 0.45563140511512756)
[2024-12-17 03:35:33,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:33,430][root][INFO] - Training Epoch: 1/2, step 551/7134 completed (loss: 1.897199034690857, acc: 0.46408841013908386)
[2024-12-17 03:35:33,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:33,847][root][INFO] - Training Epoch: 1/2, step 552/7134 completed (loss: 1.8220824003219604, acc: 0.5014244914054871)
[2024-12-17 03:35:33,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:34,246][root][INFO] - Training Epoch: 1/2, step 553/7134 completed (loss: 1.7956318855285645, acc: 0.484649121761322)
[2024-12-17 03:35:34,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:34,714][root][INFO] - Training Epoch: 1/2, step 554/7134 completed (loss: 1.805845022201538, acc: 0.47075605392456055)
[2024-12-17 03:35:34,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:35,148][root][INFO] - Training Epoch: 1/2, step 555/7134 completed (loss: 1.8576970100402832, acc: 0.45497629046440125)
[2024-12-17 03:35:35,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:35,585][root][INFO] - Training Epoch: 1/2, step 556/7134 completed (loss: 1.6768137216567993, acc: 0.5205091834068298)
[2024-12-17 03:35:35,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:36,008][root][INFO] - Training Epoch: 1/2, step 557/7134 completed (loss: 1.881595492362976, acc: 0.46700507402420044)
[2024-12-17 03:35:36,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:36,486][root][INFO] - Training Epoch: 1/2, step 558/7134 completed (loss: 1.7712218761444092, acc: 0.479432612657547)
[2024-12-17 03:35:36,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:36,929][root][INFO] - Training Epoch: 1/2, step 559/7134 completed (loss: 1.7921160459518433, acc: 0.48860397934913635)
[2024-12-17 03:35:37,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:37,347][root][INFO] - Training Epoch: 1/2, step 560/7134 completed (loss: 1.7291572093963623, acc: 0.463971883058548)
[2024-12-17 03:35:37,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:37,847][root][INFO] - Training Epoch: 1/2, step 561/7134 completed (loss: 1.7082959413528442, acc: 0.5031928420066833)
[2024-12-17 03:35:37,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:38,270][root][INFO] - Training Epoch: 1/2, step 562/7134 completed (loss: 1.7338536977767944, acc: 0.495364248752594)
[2024-12-17 03:35:38,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:38,675][root][INFO] - Training Epoch: 1/2, step 563/7134 completed (loss: 1.7630804777145386, acc: 0.4889240562915802)
[2024-12-17 03:35:38,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:39,164][root][INFO] - Training Epoch: 1/2, step 564/7134 completed (loss: 1.7270272970199585, acc: 0.505562424659729)
[2024-12-17 03:35:39,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:39,630][root][INFO] - Training Epoch: 1/2, step 565/7134 completed (loss: 1.7057806253433228, acc: 0.5041875839233398)
[2024-12-17 03:35:39,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:40,040][root][INFO] - Training Epoch: 1/2, step 566/7134 completed (loss: 1.9187743663787842, acc: 0.45939674973487854)
[2024-12-17 03:35:40,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:40,492][root][INFO] - Training Epoch: 1/2, step 567/7134 completed (loss: 1.954024314880371, acc: 0.43899017572402954)
[2024-12-17 03:35:40,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:40,924][root][INFO] - Training Epoch: 1/2, step 568/7134 completed (loss: 1.7948832511901855, acc: 0.48758170008659363)
[2024-12-17 03:35:41,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:41,367][root][INFO] - Training Epoch: 1/2, step 569/7134 completed (loss: 1.8153421878814697, acc: 0.4703703820705414)
[2024-12-17 03:35:41,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:41,855][root][INFO] - Training Epoch: 1/2, step 570/7134 completed (loss: 1.8161803483963013, acc: 0.48766157031059265)
[2024-12-17 03:35:41,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:42,313][root][INFO] - Training Epoch: 1/2, step 571/7134 completed (loss: 1.8943567276000977, acc: 0.44458436965942383)
[2024-12-17 03:35:42,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:42,757][root][INFO] - Training Epoch: 1/2, step 572/7134 completed (loss: 1.7667800188064575, acc: 0.4761904776096344)
[2024-12-17 03:35:42,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:43,212][root][INFO] - Training Epoch: 1/2, step 573/7134 completed (loss: 1.8625683784484863, acc: 0.47570332884788513)
[2024-12-17 03:35:43,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:43,633][root][INFO] - Training Epoch: 1/2, step 574/7134 completed (loss: 1.8481391668319702, acc: 0.4848484992980957)
[2024-12-17 03:35:43,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:44,162][root][INFO] - Training Epoch: 1/2, step 575/7134 completed (loss: 1.7877514362335205, acc: 0.4845758378505707)
[2024-12-17 03:35:44,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:44,605][root][INFO] - Training Epoch: 1/2, step 576/7134 completed (loss: 1.7220770120620728, acc: 0.49504950642585754)
[2024-12-17 03:35:44,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:45,055][root][INFO] - Training Epoch: 1/2, step 577/7134 completed (loss: 1.8094773292541504, acc: 0.47035571932792664)
[2024-12-17 03:35:45,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:45,552][root][INFO] - Training Epoch: 1/2, step 578/7134 completed (loss: 1.793032169342041, acc: 0.4988399147987366)
[2024-12-17 03:35:45,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:45,978][root][INFO] - Training Epoch: 1/2, step 579/7134 completed (loss: 1.883563756942749, acc: 0.47881901264190674)
[2024-12-17 03:35:46,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:46,435][root][INFO] - Training Epoch: 1/2, step 580/7134 completed (loss: 1.881130337715149, acc: 0.4512353837490082)
[2024-12-17 03:35:46,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:46,856][root][INFO] - Training Epoch: 1/2, step 581/7134 completed (loss: 1.7738940715789795, acc: 0.4867503345012665)
[2024-12-17 03:35:46,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:47,314][root][INFO] - Training Epoch: 1/2, step 582/7134 completed (loss: 1.8193044662475586, acc: 0.4766467213630676)
[2024-12-17 03:35:47,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:47,769][root][INFO] - Training Epoch: 1/2, step 583/7134 completed (loss: 1.8100080490112305, acc: 0.4935064911842346)
[2024-12-17 03:35:47,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:48,246][root][INFO] - Training Epoch: 1/2, step 584/7134 completed (loss: 1.754380464553833, acc: 0.49401915073394775)
[2024-12-17 03:35:48,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:48,685][root][INFO] - Training Epoch: 1/2, step 585/7134 completed (loss: 1.7673211097717285, acc: 0.49033817648887634)
[2024-12-17 03:35:48,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:49,106][root][INFO] - Training Epoch: 1/2, step 586/7134 completed (loss: 1.7120177745819092, acc: 0.5058670043945312)
[2024-12-17 03:35:49,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:49,605][root][INFO] - Training Epoch: 1/2, step 587/7134 completed (loss: 1.6658095121383667, acc: 0.5031766295433044)
[2024-12-17 03:35:49,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:50,081][root][INFO] - Training Epoch: 1/2, step 588/7134 completed (loss: 1.7791669368743896, acc: 0.4772370457649231)
[2024-12-17 03:35:50,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:50,522][root][INFO] - Training Epoch: 1/2, step 589/7134 completed (loss: 1.7819675207138062, acc: 0.46549192070961)
[2024-12-17 03:35:50,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:50,957][root][INFO] - Training Epoch: 1/2, step 590/7134 completed (loss: 1.6950336694717407, acc: 0.5082706809043884)
[2024-12-17 03:35:51,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:51,400][root][INFO] - Training Epoch: 1/2, step 591/7134 completed (loss: 1.733167052268982, acc: 0.49878934025764465)
[2024-12-17 03:35:51,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:51,829][root][INFO] - Training Epoch: 1/2, step 592/7134 completed (loss: 1.691368579864502, acc: 0.5164974331855774)
[2024-12-17 03:35:51,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:52,256][root][INFO] - Training Epoch: 1/2, step 593/7134 completed (loss: 1.6396093368530273, acc: 0.5262467265129089)
[2024-12-17 03:35:52,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:52,712][root][INFO] - Training Epoch: 1/2, step 594/7134 completed (loss: 1.7708847522735596, acc: 0.5044025182723999)
[2024-12-17 03:35:52,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:53,190][root][INFO] - Training Epoch: 1/2, step 595/7134 completed (loss: 1.6798009872436523, acc: 0.4841972291469574)
[2024-12-17 03:35:53,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:53,649][root][INFO] - Training Epoch: 1/2, step 596/7134 completed (loss: 1.7691540718078613, acc: 0.4884020686149597)
[2024-12-17 03:35:53,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:54,132][root][INFO] - Training Epoch: 1/2, step 597/7134 completed (loss: 1.7425884008407593, acc: 0.4624505937099457)
[2024-12-17 03:35:54,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:54,582][root][INFO] - Training Epoch: 1/2, step 598/7134 completed (loss: 1.7299110889434814, acc: 0.4884979724884033)
[2024-12-17 03:35:54,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:55,044][root][INFO] - Training Epoch: 1/2, step 599/7134 completed (loss: 1.6964170932769775, acc: 0.49624061584472656)
[2024-12-17 03:35:55,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:55,505][root][INFO] - Training Epoch: 1/2, step 600/7134 completed (loss: 1.7675963640213013, acc: 0.505415141582489)
[2024-12-17 03:35:55,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:56,028][root][INFO] - Training Epoch: 1/2, step 601/7134 completed (loss: 1.6892272233963013, acc: 0.5006915926933289)
[2024-12-17 03:35:56,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:56,478][root][INFO] - Training Epoch: 1/2, step 602/7134 completed (loss: 1.6463704109191895, acc: 0.5232018828392029)
[2024-12-17 03:35:56,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:56,927][root][INFO] - Training Epoch: 1/2, step 603/7134 completed (loss: 1.718889594078064, acc: 0.49614396691322327)
[2024-12-17 03:35:57,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:57,323][root][INFO] - Training Epoch: 1/2, step 604/7134 completed (loss: 1.7144148349761963, acc: 0.49487555027008057)
[2024-12-17 03:35:57,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:57,783][root][INFO] - Training Epoch: 1/2, step 605/7134 completed (loss: 1.664854884147644, acc: 0.5025906562805176)
[2024-12-17 03:35:57,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:58,232][root][INFO] - Training Epoch: 1/2, step 606/7134 completed (loss: 1.724755883216858, acc: 0.5191594362258911)
[2024-12-17 03:35:58,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:58,688][root][INFO] - Training Epoch: 1/2, step 607/7134 completed (loss: 1.6754456758499146, acc: 0.5060080289840698)
[2024-12-17 03:35:58,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:59,185][root][INFO] - Training Epoch: 1/2, step 608/7134 completed (loss: 1.643739104270935, acc: 0.5116580128669739)
[2024-12-17 03:35:59,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:59,678][root][INFO] - Training Epoch: 1/2, step 609/7134 completed (loss: 1.7879987955093384, acc: 0.5)
[2024-12-17 03:35:59,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:00,137][root][INFO] - Training Epoch: 1/2, step 610/7134 completed (loss: 1.6864981651306152, acc: 0.5044247508049011)
[2024-12-17 03:36:00,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:00,619][root][INFO] - Training Epoch: 1/2, step 611/7134 completed (loss: 1.6918920278549194, acc: 0.5158536434173584)
[2024-12-17 03:36:00,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:01,083][root][INFO] - Training Epoch: 1/2, step 612/7134 completed (loss: 1.693735122680664, acc: 0.5079155564308167)
[2024-12-17 03:36:01,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:01,564][root][INFO] - Training Epoch: 1/2, step 613/7134 completed (loss: 1.6348127126693726, acc: 0.5099648237228394)
[2024-12-17 03:36:01,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:02,016][root][INFO] - Training Epoch: 1/2, step 614/7134 completed (loss: 1.706690788269043, acc: 0.5084937810897827)
[2024-12-17 03:36:02,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:02,524][root][INFO] - Training Epoch: 1/2, step 615/7134 completed (loss: 1.6664009094238281, acc: 0.5104294419288635)
[2024-12-17 03:36:02,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:03,007][root][INFO] - Training Epoch: 1/2, step 616/7134 completed (loss: 1.6548465490341187, acc: 0.5056818127632141)
[2024-12-17 03:36:03,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:03,485][root][INFO] - Training Epoch: 1/2, step 617/7134 completed (loss: 1.5427037477493286, acc: 0.5387243628501892)
[2024-12-17 03:36:03,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:03,934][root][INFO] - Training Epoch: 1/2, step 618/7134 completed (loss: 1.5937199592590332, acc: 0.5374331474304199)
[2024-12-17 03:36:04,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:04,342][root][INFO] - Training Epoch: 1/2, step 619/7134 completed (loss: 1.6699827909469604, acc: 0.5060728788375854)
[2024-12-17 03:36:04,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:04,854][root][INFO] - Training Epoch: 1/2, step 620/7134 completed (loss: 1.6568821668624878, acc: 0.5238853693008423)
[2024-12-17 03:36:04,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:05,294][root][INFO] - Training Epoch: 1/2, step 621/7134 completed (loss: 1.854241967201233, acc: 0.46879756450653076)
[2024-12-17 03:36:05,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:05,727][root][INFO] - Training Epoch: 1/2, step 622/7134 completed (loss: 1.7488484382629395, acc: 0.47058823704719543)
[2024-12-17 03:36:05,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:06,153][root][INFO] - Training Epoch: 1/2, step 623/7134 completed (loss: 1.646834373474121, acc: 0.5408163070678711)
[2024-12-17 03:36:06,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:06,619][root][INFO] - Training Epoch: 1/2, step 624/7134 completed (loss: 1.6925030946731567, acc: 0.5229730010032654)
[2024-12-17 03:36:06,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:07,087][root][INFO] - Training Epoch: 1/2, step 625/7134 completed (loss: 1.6690598726272583, acc: 0.5105540752410889)
[2024-12-17 03:36:07,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:07,531][root][INFO] - Training Epoch: 1/2, step 626/7134 completed (loss: 1.8240782022476196, acc: 0.4879724979400635)
[2024-12-17 03:36:07,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:07,985][root][INFO] - Training Epoch: 1/2, step 627/7134 completed (loss: 1.7051235437393188, acc: 0.48672565817832947)
[2024-12-17 03:36:08,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:08,434][root][INFO] - Training Epoch: 1/2, step 628/7134 completed (loss: 1.7969962358474731, acc: 0.5062413215637207)
[2024-12-17 03:36:08,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:08,896][root][INFO] - Training Epoch: 1/2, step 629/7134 completed (loss: 1.7352501153945923, acc: 0.5135908722877502)
[2024-12-17 03:36:09,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:09,386][root][INFO] - Training Epoch: 1/2, step 630/7134 completed (loss: 1.7299586534500122, acc: 0.5181347131729126)
[2024-12-17 03:36:09,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:09,827][root][INFO] - Training Epoch: 1/2, step 631/7134 completed (loss: 1.6602643728256226, acc: 0.5315789580345154)
[2024-12-17 03:36:09,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:10,281][root][INFO] - Training Epoch: 1/2, step 632/7134 completed (loss: 1.8227256536483765, acc: 0.48381876945495605)
[2024-12-17 03:36:10,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:10,719][root][INFO] - Training Epoch: 1/2, step 633/7134 completed (loss: 1.7689566612243652, acc: 0.5123367309570312)
[2024-12-17 03:36:10,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:11,140][root][INFO] - Training Epoch: 1/2, step 634/7134 completed (loss: 1.7241039276123047, acc: 0.5047468543052673)
[2024-12-17 03:36:11,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:11,578][root][INFO] - Training Epoch: 1/2, step 635/7134 completed (loss: 1.7753872871398926, acc: 0.4824427366256714)
[2024-12-17 03:36:11,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:12,011][root][INFO] - Training Epoch: 1/2, step 636/7134 completed (loss: 1.7666852474212646, acc: 0.4868965446949005)
[2024-12-17 03:36:12,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:12,429][root][INFO] - Training Epoch: 1/2, step 637/7134 completed (loss: 1.685436487197876, acc: 0.5214152932167053)
[2024-12-17 03:36:12,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:12,851][root][INFO] - Training Epoch: 1/2, step 638/7134 completed (loss: 1.7405112981796265, acc: 0.4929797053337097)
[2024-12-17 03:36:12,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:13,266][root][INFO] - Training Epoch: 1/2, step 639/7134 completed (loss: 1.6235071420669556, acc: 0.54666668176651)
[2024-12-17 03:36:13,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:13,670][root][INFO] - Training Epoch: 1/2, step 640/7134 completed (loss: 1.6572948694229126, acc: 0.5060869455337524)
[2024-12-17 03:36:13,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:14,080][root][INFO] - Training Epoch: 1/2, step 641/7134 completed (loss: 1.6457380056381226, acc: 0.5040916800498962)
[2024-12-17 03:36:14,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:14,552][root][INFO] - Training Epoch: 1/2, step 642/7134 completed (loss: 1.5947359800338745, acc: 0.523809552192688)
[2024-12-17 03:36:14,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:14,986][root][INFO] - Training Epoch: 1/2, step 643/7134 completed (loss: 1.7516144514083862, acc: 0.48010268807411194)
[2024-12-17 03:36:15,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:15,431][root][INFO] - Training Epoch: 1/2, step 644/7134 completed (loss: 1.6601396799087524, acc: 0.5019304752349854)
[2024-12-17 03:36:15,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:15,891][root][INFO] - Training Epoch: 1/2, step 645/7134 completed (loss: 1.6266809701919556, acc: 0.5336700081825256)
[2024-12-17 03:36:16,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:16,324][root][INFO] - Training Epoch: 1/2, step 646/7134 completed (loss: 1.7017499208450317, acc: 0.5259938836097717)
[2024-12-17 03:36:16,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:16,780][root][INFO] - Training Epoch: 1/2, step 647/7134 completed (loss: 1.5704907178878784, acc: 0.5414551496505737)
[2024-12-17 03:36:16,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:17,245][root][INFO] - Training Epoch: 1/2, step 648/7134 completed (loss: 1.9130226373672485, acc: 0.4781849980354309)
[2024-12-17 03:36:17,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:17,723][root][INFO] - Training Epoch: 1/2, step 649/7134 completed (loss: 1.7524758577346802, acc: 0.514102578163147)
[2024-12-17 03:36:17,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:18,157][root][INFO] - Training Epoch: 1/2, step 650/7134 completed (loss: 1.750988483428955, acc: 0.4992150664329529)
[2024-12-17 03:36:18,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:18,588][root][INFO] - Training Epoch: 1/2, step 651/7134 completed (loss: 1.9141132831573486, acc: 0.4816513657569885)
[2024-12-17 03:36:18,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:19,023][root][INFO] - Training Epoch: 1/2, step 652/7134 completed (loss: 1.7196091413497925, acc: 0.48969072103500366)
[2024-12-17 03:36:19,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:19,450][root][INFO] - Training Epoch: 1/2, step 653/7134 completed (loss: 1.7264554500579834, acc: 0.4921985864639282)
[2024-12-17 03:36:19,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:19,879][root][INFO] - Training Epoch: 1/2, step 654/7134 completed (loss: 1.7008967399597168, acc: 0.511879026889801)
[2024-12-17 03:36:20,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:20,399][root][INFO] - Training Epoch: 1/2, step 655/7134 completed (loss: 1.735924482345581, acc: 0.5080645084381104)
[2024-12-17 03:36:20,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:20,846][root][INFO] - Training Epoch: 1/2, step 656/7134 completed (loss: 1.746522307395935, acc: 0.49340370297431946)
[2024-12-17 03:36:20,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:21,305][root][INFO] - Training Epoch: 1/2, step 657/7134 completed (loss: 1.6785120964050293, acc: 0.5280898809432983)
[2024-12-17 03:36:21,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:21,741][root][INFO] - Training Epoch: 1/2, step 658/7134 completed (loss: 1.5646235942840576, acc: 0.5467720627784729)
[2024-12-17 03:36:21,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:22,198][root][INFO] - Training Epoch: 1/2, step 659/7134 completed (loss: 1.6076066493988037, acc: 0.5293254852294922)
[2024-12-17 03:36:22,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:22,672][root][INFO] - Training Epoch: 1/2, step 660/7134 completed (loss: 1.800225853919983, acc: 0.48830410838127136)
[2024-12-17 03:36:22,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:23,164][root][INFO] - Training Epoch: 1/2, step 661/7134 completed (loss: 1.7225596904754639, acc: 0.4937238395214081)
[2024-12-17 03:36:23,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:23,672][root][INFO] - Training Epoch: 1/2, step 662/7134 completed (loss: 1.6745697259902954, acc: 0.5067024230957031)
[2024-12-17 03:36:23,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:24,195][root][INFO] - Training Epoch: 1/2, step 663/7134 completed (loss: 1.8185946941375732, acc: 0.4702581465244293)
[2024-12-17 03:36:24,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:24,665][root][INFO] - Training Epoch: 1/2, step 664/7134 completed (loss: 1.6810173988342285, acc: 0.5183333158493042)
[2024-12-17 03:36:24,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:25,108][root][INFO] - Training Epoch: 1/2, step 665/7134 completed (loss: 1.7338684797286987, acc: 0.5006729364395142)
[2024-12-17 03:36:25,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:25,609][root][INFO] - Training Epoch: 1/2, step 666/7134 completed (loss: 1.7376879453659058, acc: 0.4931318759918213)
[2024-12-17 03:36:25,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:26,110][root][INFO] - Training Epoch: 1/2, step 667/7134 completed (loss: 1.7129441499710083, acc: 0.5095729231834412)
[2024-12-17 03:36:26,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:26,566][root][INFO] - Training Epoch: 1/2, step 668/7134 completed (loss: 1.5978357791900635, acc: 0.517110288143158)
[2024-12-17 03:36:26,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:27,044][root][INFO] - Training Epoch: 1/2, step 669/7134 completed (loss: 1.6604365110397339, acc: 0.5279672741889954)
[2024-12-17 03:36:27,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:27,542][root][INFO] - Training Epoch: 1/2, step 670/7134 completed (loss: 1.7611918449401855, acc: 0.4887063801288605)
[2024-12-17 03:36:27,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:28,032][root][INFO] - Training Epoch: 1/2, step 671/7134 completed (loss: 1.7607516050338745, acc: 0.4866023659706116)
[2024-12-17 03:36:28,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:28,501][root][INFO] - Training Epoch: 1/2, step 672/7134 completed (loss: 1.6229068040847778, acc: 0.5201192498207092)
[2024-12-17 03:36:28,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:28,955][root][INFO] - Training Epoch: 1/2, step 673/7134 completed (loss: 1.6912678480148315, acc: 0.5)
[2024-12-17 03:36:29,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:29,407][root][INFO] - Training Epoch: 1/2, step 674/7134 completed (loss: 1.7018107175827026, acc: 0.49321267008781433)
[2024-12-17 03:36:29,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:29,878][root][INFO] - Training Epoch: 1/2, step 675/7134 completed (loss: 1.6107856035232544, acc: 0.5306388735771179)
[2024-12-17 03:36:29,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:30,336][root][INFO] - Training Epoch: 1/2, step 676/7134 completed (loss: 1.6317757368087769, acc: 0.5325443744659424)
[2024-12-17 03:36:30,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:30,811][root][INFO] - Training Epoch: 1/2, step 677/7134 completed (loss: 1.5033342838287354, acc: 0.5524044632911682)
[2024-12-17 03:36:30,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:31,272][root][INFO] - Training Epoch: 1/2, step 678/7134 completed (loss: 1.6667572259902954, acc: 0.5006729364395142)
[2024-12-17 03:36:31,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:31,682][root][INFO] - Training Epoch: 1/2, step 679/7134 completed (loss: 1.7222621440887451, acc: 0.5009451508522034)
[2024-12-17 03:36:31,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:32,143][root][INFO] - Training Epoch: 1/2, step 680/7134 completed (loss: 1.6216703653335571, acc: 0.5107816457748413)
[2024-12-17 03:36:32,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:32,696][root][INFO] - Training Epoch: 1/2, step 681/7134 completed (loss: 1.5938568115234375, acc: 0.5349693298339844)
[2024-12-17 03:36:32,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:33,160][root][INFO] - Training Epoch: 1/2, step 682/7134 completed (loss: 1.549122929573059, acc: 0.5417867302894592)
[2024-12-17 03:36:33,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:33,703][root][INFO] - Training Epoch: 1/2, step 683/7134 completed (loss: 1.6607054471969604, acc: 0.5034293532371521)
[2024-12-17 03:36:33,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:34,202][root][INFO] - Training Epoch: 1/2, step 684/7134 completed (loss: 1.6883008480072021, acc: 0.5318559408187866)
[2024-12-17 03:36:34,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:34,685][root][INFO] - Training Epoch: 1/2, step 685/7134 completed (loss: 1.7054393291473389, acc: 0.5199501514434814)
[2024-12-17 03:36:34,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:35,157][root][INFO] - Training Epoch: 1/2, step 686/7134 completed (loss: 1.5170307159423828, acc: 0.5429326295852661)
[2024-12-17 03:36:35,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:35,624][root][INFO] - Training Epoch: 1/2, step 687/7134 completed (loss: 1.7252832651138306, acc: 0.5009671449661255)
[2024-12-17 03:36:35,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:36,124][root][INFO] - Training Epoch: 1/2, step 688/7134 completed (loss: 1.5939489603042603, acc: 0.5369822382926941)
[2024-12-17 03:36:36,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:36,573][root][INFO] - Training Epoch: 1/2, step 689/7134 completed (loss: 1.6789244413375854, acc: 0.5264957547187805)
[2024-12-17 03:36:36,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:37,027][root][INFO] - Training Epoch: 1/2, step 690/7134 completed (loss: 1.7476890087127686, acc: 0.5103338360786438)
[2024-12-17 03:36:37,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:37,456][root][INFO] - Training Epoch: 1/2, step 691/7134 completed (loss: 1.7997031211853027, acc: 0.4885057508945465)
[2024-12-17 03:36:37,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:37,924][root][INFO] - Training Epoch: 1/2, step 692/7134 completed (loss: 1.7614083290100098, acc: 0.48399999737739563)
[2024-12-17 03:36:38,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:38,366][root][INFO] - Training Epoch: 1/2, step 693/7134 completed (loss: 1.7540249824523926, acc: 0.5040387511253357)
[2024-12-17 03:36:38,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:38,796][root][INFO] - Training Epoch: 1/2, step 694/7134 completed (loss: 1.7927671670913696, acc: 0.47007298469543457)
[2024-12-17 03:36:38,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:39,252][root][INFO] - Training Epoch: 1/2, step 695/7134 completed (loss: 1.8401931524276733, acc: 0.4733218550682068)
[2024-12-17 03:36:39,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:39,667][root][INFO] - Training Epoch: 1/2, step 696/7134 completed (loss: 1.8031916618347168, acc: 0.48381876945495605)
[2024-12-17 03:36:39,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:40,130][root][INFO] - Training Epoch: 1/2, step 697/7134 completed (loss: 1.6875160932540894, acc: 0.5012406706809998)
[2024-12-17 03:36:40,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:40,570][root][INFO] - Training Epoch: 1/2, step 698/7134 completed (loss: 1.7563252449035645, acc: 0.4967426657676697)
[2024-12-17 03:36:40,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:41,113][root][INFO] - Training Epoch: 1/2, step 699/7134 completed (loss: 1.7001169919967651, acc: 0.5124610662460327)
[2024-12-17 03:36:41,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:41,589][root][INFO] - Training Epoch: 1/2, step 700/7134 completed (loss: 1.8482977151870728, acc: 0.4552238881587982)
[2024-12-17 03:36:41,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:42,014][root][INFO] - Training Epoch: 1/2, step 701/7134 completed (loss: 1.7380025386810303, acc: 0.48758864402770996)
[2024-12-17 03:36:42,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:42,474][root][INFO] - Training Epoch: 1/2, step 702/7134 completed (loss: 1.7454743385314941, acc: 0.49837663769721985)
[2024-12-17 03:36:42,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:42,903][root][INFO] - Training Epoch: 1/2, step 703/7134 completed (loss: 1.7364294528961182, acc: 0.48788368701934814)
[2024-12-17 03:36:43,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:43,379][root][INFO] - Training Epoch: 1/2, step 704/7134 completed (loss: 1.7256819009780884, acc: 0.4954407215118408)
[2024-12-17 03:36:43,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:43,881][root][INFO] - Training Epoch: 1/2, step 705/7134 completed (loss: 1.7556710243225098, acc: 0.5039106011390686)
[2024-12-17 03:36:43,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:44,349][root][INFO] - Training Epoch: 1/2, step 706/7134 completed (loss: 1.596954107284546, acc: 0.5371991395950317)
[2024-12-17 03:36:44,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:44,794][root][INFO] - Training Epoch: 1/2, step 707/7134 completed (loss: 1.753593921661377, acc: 0.4808153510093689)
[2024-12-17 03:36:44,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:45,290][root][INFO] - Training Epoch: 1/2, step 708/7134 completed (loss: 1.6507344245910645, acc: 0.5117719769477844)
[2024-12-17 03:36:45,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:45,738][root][INFO] - Training Epoch: 1/2, step 709/7134 completed (loss: 1.6149120330810547, acc: 0.5393794775009155)
[2024-12-17 03:36:45,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:46,215][root][INFO] - Training Epoch: 1/2, step 710/7134 completed (loss: 1.599190592765808, acc: 0.5302663445472717)
[2024-12-17 03:36:46,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:46,649][root][INFO] - Training Epoch: 1/2, step 711/7134 completed (loss: 1.5651015043258667, acc: 0.5407319664955139)
[2024-12-17 03:36:46,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:47,105][root][INFO] - Training Epoch: 1/2, step 712/7134 completed (loss: 1.5387766361236572, acc: 0.5347985625267029)
[2024-12-17 03:36:47,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:47,586][root][INFO] - Training Epoch: 1/2, step 713/7134 completed (loss: 1.615977168083191, acc: 0.5098039507865906)
[2024-12-17 03:36:47,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:48,009][root][INFO] - Training Epoch: 1/2, step 714/7134 completed (loss: 1.6666404008865356, acc: 0.5144927501678467)
[2024-12-17 03:36:48,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:48,493][root][INFO] - Training Epoch: 1/2, step 715/7134 completed (loss: 1.586694598197937, acc: 0.5482954382896423)
[2024-12-17 03:36:48,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:48,947][root][INFO] - Training Epoch: 1/2, step 716/7134 completed (loss: 1.5731513500213623, acc: 0.5426621437072754)
[2024-12-17 03:36:49,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:49,386][root][INFO] - Training Epoch: 1/2, step 717/7134 completed (loss: 1.612675428390503, acc: 0.5284450054168701)
[2024-12-17 03:36:49,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:49,861][root][INFO] - Training Epoch: 1/2, step 718/7134 completed (loss: 1.573236107826233, acc: 0.5388470888137817)
[2024-12-17 03:36:49,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:50,292][root][INFO] - Training Epoch: 1/2, step 719/7134 completed (loss: 1.5176429748535156, acc: 0.5413793325424194)
[2024-12-17 03:36:50,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:50,757][root][INFO] - Training Epoch: 1/2, step 720/7134 completed (loss: 1.6326295137405396, acc: 0.5350877046585083)
[2024-12-17 03:36:50,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:51,226][root][INFO] - Training Epoch: 1/2, step 721/7134 completed (loss: 1.6096984148025513, acc: 0.5467349290847778)
[2024-12-17 03:36:51,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:51,737][root][INFO] - Training Epoch: 1/2, step 722/7134 completed (loss: 1.644751787185669, acc: 0.5192531943321228)
[2024-12-17 03:36:51,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:52,201][root][INFO] - Training Epoch: 1/2, step 723/7134 completed (loss: 1.6203340291976929, acc: 0.5302663445472717)
[2024-12-17 03:36:52,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:52,685][root][INFO] - Training Epoch: 1/2, step 724/7134 completed (loss: 1.6464622020721436, acc: 0.5336194634437561)
[2024-12-17 03:36:52,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:53,143][root][INFO] - Training Epoch: 1/2, step 725/7134 completed (loss: 1.4968816041946411, acc: 0.5658466219902039)
[2024-12-17 03:36:53,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:53,597][root][INFO] - Training Epoch: 1/2, step 726/7134 completed (loss: 1.4712316989898682, acc: 0.569037675857544)
[2024-12-17 03:36:53,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:54,035][root][INFO] - Training Epoch: 1/2, step 727/7134 completed (loss: 1.509369134902954, acc: 0.5584415793418884)
[2024-12-17 03:36:54,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:54,476][root][INFO] - Training Epoch: 1/2, step 728/7134 completed (loss: 1.5391120910644531, acc: 0.5454545617103577)
[2024-12-17 03:36:54,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:54,971][root][INFO] - Training Epoch: 1/2, step 729/7134 completed (loss: 1.5356080532073975, acc: 0.5674548149108887)
[2024-12-17 03:36:55,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:55,480][root][INFO] - Training Epoch: 1/2, step 730/7134 completed (loss: 1.4836204051971436, acc: 0.5564202070236206)
[2024-12-17 03:36:55,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:55,935][root][INFO] - Training Epoch: 1/2, step 731/7134 completed (loss: 1.3830602169036865, acc: 0.5893333554267883)
[2024-12-17 03:36:56,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:56,361][root][INFO] - Training Epoch: 1/2, step 732/7134 completed (loss: 1.862625002861023, acc: 0.4849056601524353)
[2024-12-17 03:36:56,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:56,773][root][INFO] - Training Epoch: 1/2, step 733/7134 completed (loss: 1.70037841796875, acc: 0.5133215188980103)
[2024-12-17 03:36:56,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:57,182][root][INFO] - Training Epoch: 1/2, step 734/7134 completed (loss: 1.5624483823776245, acc: 0.5299538969993591)
[2024-12-17 03:36:57,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:57,604][root][INFO] - Training Epoch: 1/2, step 735/7134 completed (loss: 1.62285578250885, acc: 0.5273311734199524)
[2024-12-17 03:36:57,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:58,018][root][INFO] - Training Epoch: 1/2, step 736/7134 completed (loss: 1.6611692905426025, acc: 0.5318681597709656)
[2024-12-17 03:36:58,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:58,445][root][INFO] - Training Epoch: 1/2, step 737/7134 completed (loss: 1.7175328731536865, acc: 0.5334685444831848)
[2024-12-17 03:36:58,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:58,857][root][INFO] - Training Epoch: 1/2, step 738/7134 completed (loss: 1.6673527956008911, acc: 0.5134615302085876)
[2024-12-17 03:36:58,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:59,282][root][INFO] - Training Epoch: 1/2, step 739/7134 completed (loss: 1.6530241966247559, acc: 0.526605486869812)
[2024-12-17 03:36:59,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:59,701][root][INFO] - Training Epoch: 1/2, step 740/7134 completed (loss: 1.4864126443862915, acc: 0.5825396776199341)
[2024-12-17 03:36:59,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:00,118][root][INFO] - Training Epoch: 1/2, step 741/7134 completed (loss: 1.6312453746795654, acc: 0.5315457582473755)
[2024-12-17 03:37:00,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:00,487][root][INFO] - Training Epoch: 1/2, step 742/7134 completed (loss: 1.5116857290267944, acc: 0.5744234919548035)
[2024-12-17 03:37:00,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:00,949][root][INFO] - Training Epoch: 1/2, step 743/7134 completed (loss: 1.4983714818954468, acc: 0.5647590160369873)
[2024-12-17 03:37:01,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:01,375][root][INFO] - Training Epoch: 1/2, step 744/7134 completed (loss: 1.5452830791473389, acc: 0.5436508059501648)
[2024-12-17 03:37:01,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:01,827][root][INFO] - Training Epoch: 1/2, step 745/7134 completed (loss: 1.5734134912490845, acc: 0.5664652585983276)
[2024-12-17 03:37:01,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:02,296][root][INFO] - Training Epoch: 1/2, step 746/7134 completed (loss: 1.637083888053894, acc: 0.5303776860237122)
[2024-12-17 03:37:02,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:02,696][root][INFO] - Training Epoch: 1/2, step 747/7134 completed (loss: 1.623047947883606, acc: 0.5332226157188416)
[2024-12-17 03:37:02,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:03,163][root][INFO] - Training Epoch: 1/2, step 748/7134 completed (loss: 1.688401460647583, acc: 0.5052631497383118)
[2024-12-17 03:37:03,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:03,598][root][INFO] - Training Epoch: 1/2, step 749/7134 completed (loss: 1.5548254251480103, acc: 0.5576369166374207)
[2024-12-17 03:37:03,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:04,085][root][INFO] - Training Epoch: 1/2, step 750/7134 completed (loss: 1.5639063119888306, acc: 0.5405405163764954)
[2024-12-17 03:37:04,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:04,546][root][INFO] - Training Epoch: 1/2, step 751/7134 completed (loss: 1.724151849746704, acc: 0.495741069316864)
[2024-12-17 03:37:04,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:04,933][root][INFO] - Training Epoch: 1/2, step 752/7134 completed (loss: 1.6902955770492554, acc: 0.522522509098053)
[2024-12-17 03:37:05,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:05,357][root][INFO] - Training Epoch: 1/2, step 753/7134 completed (loss: 1.7096878290176392, acc: 0.5304054021835327)
[2024-12-17 03:37:05,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:05,793][root][INFO] - Training Epoch: 1/2, step 754/7134 completed (loss: 1.4567357301712036, acc: 0.5987933874130249)
[2024-12-17 03:37:05,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:06,257][root][INFO] - Training Epoch: 1/2, step 755/7134 completed (loss: 1.4987540245056152, acc: 0.5792078971862793)
[2024-12-17 03:37:06,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:06,675][root][INFO] - Training Epoch: 1/2, step 756/7134 completed (loss: 1.5380327701568604, acc: 0.558878481388092)
[2024-12-17 03:37:06,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:07,097][root][INFO] - Training Epoch: 1/2, step 757/7134 completed (loss: 1.475494623184204, acc: 0.5727969408035278)
[2024-12-17 03:37:07,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:07,525][root][INFO] - Training Epoch: 1/2, step 758/7134 completed (loss: 1.4879957437515259, acc: 0.5524957180023193)
[2024-12-17 03:37:07,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:07,916][root][INFO] - Training Epoch: 1/2, step 759/7134 completed (loss: 1.5095597505569458, acc: 0.569767415523529)
[2024-12-17 03:37:08,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:08,343][root][INFO] - Training Epoch: 1/2, step 760/7134 completed (loss: 1.6455681324005127, acc: 0.5303292870521545)
[2024-12-17 03:37:08,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:08,760][root][INFO] - Training Epoch: 1/2, step 761/7134 completed (loss: 1.794498324394226, acc: 0.4804381728172302)
[2024-12-17 03:37:08,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:09,182][root][INFO] - Training Epoch: 1/2, step 762/7134 completed (loss: 1.903546929359436, acc: 0.46236559748649597)
[2024-12-17 03:37:09,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:09,610][root][INFO] - Training Epoch: 1/2, step 763/7134 completed (loss: 1.725175380706787, acc: 0.5065146684646606)
[2024-12-17 03:37:09,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:10,053][root][INFO] - Training Epoch: 1/2, step 764/7134 completed (loss: 1.575261116027832, acc: 0.5652797818183899)
[2024-12-17 03:37:10,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:10,561][root][INFO] - Training Epoch: 1/2, step 765/7134 completed (loss: 1.5248221158981323, acc: 0.5680819749832153)
[2024-12-17 03:37:10,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:11,010][root][INFO] - Training Epoch: 1/2, step 766/7134 completed (loss: 1.6127194166183472, acc: 0.5385756492614746)
[2024-12-17 03:37:11,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:11,464][root][INFO] - Training Epoch: 1/2, step 767/7134 completed (loss: 1.558241605758667, acc: 0.5300146341323853)
[2024-12-17 03:37:11,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:11,914][root][INFO] - Training Epoch: 1/2, step 768/7134 completed (loss: 1.668218970298767, acc: 0.5240793228149414)
[2024-12-17 03:37:12,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:12,355][root][INFO] - Training Epoch: 1/2, step 769/7134 completed (loss: 1.6061784029006958, acc: 0.5429799556732178)
[2024-12-17 03:37:12,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:12,766][root][INFO] - Training Epoch: 1/2, step 770/7134 completed (loss: 1.7224620580673218, acc: 0.5022971034049988)
[2024-12-17 03:37:12,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:13,188][root][INFO] - Training Epoch: 1/2, step 771/7134 completed (loss: 1.7568732500076294, acc: 0.48712870478630066)
[2024-12-17 03:37:13,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:13,605][root][INFO] - Training Epoch: 1/2, step 772/7134 completed (loss: 1.741215467453003, acc: 0.5226130485534668)
[2024-12-17 03:37:13,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:14,068][root][INFO] - Training Epoch: 1/2, step 773/7134 completed (loss: 1.5435889959335327, acc: 0.5424164533615112)
[2024-12-17 03:37:14,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:14,503][root][INFO] - Training Epoch: 1/2, step 774/7134 completed (loss: 1.6114976406097412, acc: 0.5448504686355591)
[2024-12-17 03:37:14,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:14,969][root][INFO] - Training Epoch: 1/2, step 775/7134 completed (loss: 1.5867717266082764, acc: 0.5486018657684326)
[2024-12-17 03:37:15,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:15,424][root][INFO] - Training Epoch: 1/2, step 776/7134 completed (loss: 1.4939889907836914, acc: 0.5636094808578491)
[2024-12-17 03:37:15,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:15,866][root][INFO] - Training Epoch: 1/2, step 777/7134 completed (loss: 1.5039968490600586, acc: 0.5650080442428589)
[2024-12-17 03:37:15,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:16,303][root][INFO] - Training Epoch: 1/2, step 778/7134 completed (loss: 1.594099998474121, acc: 0.5384615659713745)
[2024-12-17 03:37:16,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:16,729][root][INFO] - Training Epoch: 1/2, step 779/7134 completed (loss: 1.600903868675232, acc: 0.5430656671524048)
[2024-12-17 03:37:16,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:17,178][root][INFO] - Training Epoch: 1/2, step 780/7134 completed (loss: 1.751157283782959, acc: 0.4968314468860626)
[2024-12-17 03:37:17,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:17,661][root][INFO] - Training Epoch: 1/2, step 781/7134 completed (loss: 1.6044869422912598, acc: 0.5445665717124939)
[2024-12-17 03:37:17,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:18,062][root][INFO] - Training Epoch: 1/2, step 782/7134 completed (loss: 1.7072064876556396, acc: 0.5142405033111572)
[2024-12-17 03:37:18,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:18,536][root][INFO] - Training Epoch: 1/2, step 783/7134 completed (loss: 1.660639762878418, acc: 0.5159235596656799)
[2024-12-17 03:37:18,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:18,973][root][INFO] - Training Epoch: 1/2, step 784/7134 completed (loss: 1.5752818584442139, acc: 0.5517661571502686)
[2024-12-17 03:37:19,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:19,417][root][INFO] - Training Epoch: 1/2, step 785/7134 completed (loss: 1.7043696641921997, acc: 0.5066889524459839)
[2024-12-17 03:37:19,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:19,850][root][INFO] - Training Epoch: 1/2, step 786/7134 completed (loss: 1.5275592803955078, acc: 0.5204461216926575)
[2024-12-17 03:37:19,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:20,220][root][INFO] - Training Epoch: 1/2, step 787/7134 completed (loss: 1.533563494682312, acc: 0.5510948896408081)
[2024-12-17 03:37:20,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:20,685][root][INFO] - Training Epoch: 1/2, step 788/7134 completed (loss: 1.6141705513000488, acc: 0.5477239489555359)
[2024-12-17 03:37:20,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:21,115][root][INFO] - Training Epoch: 1/2, step 789/7134 completed (loss: 1.7005857229232788, acc: 0.49618321657180786)
[2024-12-17 03:37:21,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:21,552][root][INFO] - Training Epoch: 1/2, step 790/7134 completed (loss: 1.683035969734192, acc: 0.4911242723464966)
[2024-12-17 03:37:21,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:21,990][root][INFO] - Training Epoch: 1/2, step 791/7134 completed (loss: 1.4989242553710938, acc: 0.5375494360923767)
[2024-12-17 03:37:22,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:22,407][root][INFO] - Training Epoch: 1/2, step 792/7134 completed (loss: 1.6201295852661133, acc: 0.5502318143844604)
[2024-12-17 03:37:22,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:22,873][root][INFO] - Training Epoch: 1/2, step 793/7134 completed (loss: 1.5694314241409302, acc: 0.5414201021194458)
[2024-12-17 03:37:22,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:23,293][root][INFO] - Training Epoch: 1/2, step 794/7134 completed (loss: 1.5367431640625, acc: 0.5524475574493408)
[2024-12-17 03:37:23,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:23,713][root][INFO] - Training Epoch: 1/2, step 795/7134 completed (loss: 1.7091872692108154, acc: 0.5046728849411011)
[2024-12-17 03:37:23,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:24,176][root][INFO] - Training Epoch: 1/2, step 796/7134 completed (loss: 1.7270935773849487, acc: 0.5429292917251587)
[2024-12-17 03:37:24,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:24,587][root][INFO] - Training Epoch: 1/2, step 797/7134 completed (loss: 1.5643445253372192, acc: 0.5421686768531799)
[2024-12-17 03:37:24,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:24,989][root][INFO] - Training Epoch: 1/2, step 798/7134 completed (loss: 1.518399953842163, acc: 0.5582010746002197)
[2024-12-17 03:37:25,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:25,482][root][INFO] - Training Epoch: 1/2, step 799/7134 completed (loss: 1.5079885721206665, acc: 0.5591397881507874)
[2024-12-17 03:37:25,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:25,890][root][INFO] - Training Epoch: 1/2, step 800/7134 completed (loss: 1.6014984846115112, acc: 0.5623835921287537)
[2024-12-17 03:37:25,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:26,329][root][INFO] - Training Epoch: 1/2, step 801/7134 completed (loss: 1.708754301071167, acc: 0.4943999946117401)
[2024-12-17 03:37:26,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:26,761][root][INFO] - Training Epoch: 1/2, step 802/7134 completed (loss: 1.6917551755905151, acc: 0.5152978897094727)
[2024-12-17 03:37:26,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:27,155][root][INFO] - Training Epoch: 1/2, step 803/7134 completed (loss: 1.6330777406692505, acc: 0.5285714268684387)
[2024-12-17 03:37:27,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:27,600][root][INFO] - Training Epoch: 1/2, step 804/7134 completed (loss: 1.7601919174194336, acc: 0.4725050926208496)
[2024-12-17 03:37:27,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:28,020][root][INFO] - Training Epoch: 1/2, step 805/7134 completed (loss: 1.8469574451446533, acc: 0.4681648015975952)
[2024-12-17 03:37:28,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:28,492][root][INFO] - Training Epoch: 1/2, step 806/7134 completed (loss: 1.629828929901123, acc: 0.5125698447227478)
[2024-12-17 03:37:28,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:28,998][root][INFO] - Training Epoch: 1/2, step 807/7134 completed (loss: 1.6618056297302246, acc: 0.5340632796287537)
[2024-12-17 03:37:29,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:29,453][root][INFO] - Training Epoch: 1/2, step 808/7134 completed (loss: 1.6332224607467651, acc: 0.5293413400650024)
[2024-12-17 03:37:29,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:29,905][root][INFO] - Training Epoch: 1/2, step 809/7134 completed (loss: 1.640822172164917, acc: 0.5334323644638062)
[2024-12-17 03:37:30,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:30,334][root][INFO] - Training Epoch: 1/2, step 810/7134 completed (loss: 1.5550997257232666, acc: 0.5668016076087952)
[2024-12-17 03:37:30,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:30,751][root][INFO] - Training Epoch: 1/2, step 811/7134 completed (loss: 1.664451003074646, acc: 0.5395430326461792)
[2024-12-17 03:37:30,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:31,197][root][INFO] - Training Epoch: 1/2, step 812/7134 completed (loss: 1.6240589618682861, acc: 0.5245901346206665)
[2024-12-17 03:37:31,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:31,651][root][INFO] - Training Epoch: 1/2, step 813/7134 completed (loss: 1.6251693964004517, acc: 0.5326560139656067)
[2024-12-17 03:37:31,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:32,135][root][INFO] - Training Epoch: 1/2, step 814/7134 completed (loss: 1.6292979717254639, acc: 0.5354838967323303)
[2024-12-17 03:37:32,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:32,588][root][INFO] - Training Epoch: 1/2, step 815/7134 completed (loss: 1.5338575839996338, acc: 0.5533230304718018)
[2024-12-17 03:37:32,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:33,038][root][INFO] - Training Epoch: 1/2, step 816/7134 completed (loss: 1.6379588842391968, acc: 0.5169491767883301)
[2024-12-17 03:37:33,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:33,470][root][INFO] - Training Epoch: 1/2, step 817/7134 completed (loss: 1.6655268669128418, acc: 0.5191956162452698)
[2024-12-17 03:37:33,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:33,911][root][INFO] - Training Epoch: 1/2, step 818/7134 completed (loss: 1.734444260597229, acc: 0.4862543046474457)
[2024-12-17 03:37:34,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:34,320][root][INFO] - Training Epoch: 1/2, step 819/7134 completed (loss: 1.7198697328567505, acc: 0.5296000242233276)
[2024-12-17 03:37:34,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:34,820][root][INFO] - Training Epoch: 1/2, step 820/7134 completed (loss: 1.648808240890503, acc: 0.5301390886306763)
[2024-12-17 03:37:34,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:35,309][root][INFO] - Training Epoch: 1/2, step 821/7134 completed (loss: 1.6086430549621582, acc: 0.5455763936042786)
[2024-12-17 03:37:35,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:35,719][root][INFO] - Training Epoch: 1/2, step 822/7134 completed (loss: 1.5422509908676147, acc: 0.5463108420372009)
[2024-12-17 03:37:35,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:36,144][root][INFO] - Training Epoch: 1/2, step 823/7134 completed (loss: 1.6314256191253662, acc: 0.5347092151641846)
[2024-12-17 03:37:36,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:36,583][root][INFO] - Training Epoch: 1/2, step 824/7134 completed (loss: 1.831830620765686, acc: 0.4805653691291809)
[2024-12-17 03:37:36,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:37,083][root][INFO] - Training Epoch: 1/2, step 825/7134 completed (loss: 1.710339069366455, acc: 0.5230566263198853)
[2024-12-17 03:37:37,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:37,571][root][INFO] - Training Epoch: 1/2, step 826/7134 completed (loss: 1.60308837890625, acc: 0.5449591279029846)
[2024-12-17 03:37:37,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:38,008][root][INFO] - Training Epoch: 1/2, step 827/7134 completed (loss: 1.7164958715438843, acc: 0.5)
[2024-12-17 03:37:38,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:38,424][root][INFO] - Training Epoch: 1/2, step 828/7134 completed (loss: 1.736640214920044, acc: 0.5007776021957397)
[2024-12-17 03:37:38,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:38,853][root][INFO] - Training Epoch: 1/2, step 829/7134 completed (loss: 1.7825474739074707, acc: 0.48786407709121704)
[2024-12-17 03:37:38,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:39,319][root][INFO] - Training Epoch: 1/2, step 830/7134 completed (loss: 1.585868239402771, acc: 0.52491694688797)
[2024-12-17 03:37:39,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:39,768][root][INFO] - Training Epoch: 1/2, step 831/7134 completed (loss: 1.564420461654663, acc: 0.5452054738998413)
[2024-12-17 03:37:39,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:40,190][root][INFO] - Training Epoch: 1/2, step 832/7134 completed (loss: 1.7378206253051758, acc: 0.49829351902008057)
[2024-12-17 03:37:40,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:40,644][root][INFO] - Training Epoch: 1/2, step 833/7134 completed (loss: 1.6878911256790161, acc: 0.5070028305053711)
[2024-12-17 03:37:40,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:41,108][root][INFO] - Training Epoch: 1/2, step 834/7134 completed (loss: 1.6307440996170044, acc: 0.5272727012634277)
[2024-12-17 03:37:41,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:41,564][root][INFO] - Training Epoch: 1/2, step 835/7134 completed (loss: 1.6317603588104248, acc: 0.5314685106277466)
[2024-12-17 03:37:41,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:42,066][root][INFO] - Training Epoch: 1/2, step 836/7134 completed (loss: 1.5309852361679077, acc: 0.5556844472885132)
[2024-12-17 03:37:42,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:42,526][root][INFO] - Training Epoch: 1/2, step 837/7134 completed (loss: 1.565739631652832, acc: 0.5422343611717224)
[2024-12-17 03:37:42,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:42,962][root][INFO] - Training Epoch: 1/2, step 838/7134 completed (loss: 1.6806477308273315, acc: 0.5310015678405762)
[2024-12-17 03:37:43,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:43,417][root][INFO] - Training Epoch: 1/2, step 839/7134 completed (loss: 1.5643223524093628, acc: 0.559808611869812)
[2024-12-17 03:37:43,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:43,839][root][INFO] - Training Epoch: 1/2, step 840/7134 completed (loss: 1.5703188180923462, acc: 0.5285913348197937)
[2024-12-17 03:37:43,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:44,272][root][INFO] - Training Epoch: 1/2, step 841/7134 completed (loss: 1.7177926301956177, acc: 0.5117565989494324)
[2024-12-17 03:37:44,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:44,765][root][INFO] - Training Epoch: 1/2, step 842/7134 completed (loss: 1.5560890436172485, acc: 0.5579515099525452)
[2024-12-17 03:37:44,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:45,233][root][INFO] - Training Epoch: 1/2, step 843/7134 completed (loss: 1.5557445287704468, acc: 0.5354658961296082)
[2024-12-17 03:37:45,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:45,670][root][INFO] - Training Epoch: 1/2, step 844/7134 completed (loss: 1.6218913793563843, acc: 0.5276461243629456)
[2024-12-17 03:37:45,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:46,108][root][INFO] - Training Epoch: 1/2, step 845/7134 completed (loss: 1.6131079196929932, acc: 0.5415928959846497)
[2024-12-17 03:37:46,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:46,576][root][INFO] - Training Epoch: 1/2, step 846/7134 completed (loss: 1.5948028564453125, acc: 0.5459940433502197)
[2024-12-17 03:37:46,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:47,020][root][INFO] - Training Epoch: 1/2, step 847/7134 completed (loss: 1.744612216949463, acc: 0.5096030831336975)
[2024-12-17 03:37:47,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:47,454][root][INFO] - Training Epoch: 1/2, step 848/7134 completed (loss: 1.7418417930603027, acc: 0.505562424659729)
[2024-12-17 03:37:47,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:47,937][root][INFO] - Training Epoch: 1/2, step 849/7134 completed (loss: 1.6915892362594604, acc: 0.5151148438453674)
[2024-12-17 03:37:48,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:48,407][root][INFO] - Training Epoch: 1/2, step 850/7134 completed (loss: 1.5766509771347046, acc: 0.5570470094680786)
[2024-12-17 03:37:48,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:48,906][root][INFO] - Training Epoch: 1/2, step 851/7134 completed (loss: 1.568505048751831, acc: 0.5519053936004639)
[2024-12-17 03:37:49,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:49,365][root][INFO] - Training Epoch: 1/2, step 852/7134 completed (loss: 1.5365519523620605, acc: 0.5506715774536133)
[2024-12-17 03:37:49,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:49,840][root][INFO] - Training Epoch: 1/2, step 853/7134 completed (loss: 1.5445663928985596, acc: 0.5550661087036133)
[2024-12-17 03:37:49,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:50,275][root][INFO] - Training Epoch: 1/2, step 854/7134 completed (loss: 1.594071626663208, acc: 0.5199005007743835)
[2024-12-17 03:37:50,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:50,768][root][INFO] - Training Epoch: 1/2, step 855/7134 completed (loss: 1.528720498085022, acc: 0.5585480332374573)
[2024-12-17 03:37:50,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:51,226][root][INFO] - Training Epoch: 1/2, step 856/7134 completed (loss: 1.5274208784103394, acc: 0.5520581007003784)
[2024-12-17 03:37:51,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:51,659][root][INFO] - Training Epoch: 1/2, step 857/7134 completed (loss: 1.5676789283752441, acc: 0.553597629070282)
[2024-12-17 03:37:51,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:52,107][root][INFO] - Training Epoch: 1/2, step 858/7134 completed (loss: 1.6785935163497925, acc: 0.5124378204345703)
[2024-12-17 03:37:52,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:52,575][root][INFO] - Training Epoch: 1/2, step 859/7134 completed (loss: 1.899623155593872, acc: 0.4644549787044525)
[2024-12-17 03:37:52,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:53,029][root][INFO] - Training Epoch: 1/2, step 860/7134 completed (loss: 1.7164053916931152, acc: 0.499367892742157)
[2024-12-17 03:37:53,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:53,533][root][INFO] - Training Epoch: 1/2, step 861/7134 completed (loss: 1.6866748332977295, acc: 0.5222101807594299)
[2024-12-17 03:37:53,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:53,996][root][INFO] - Training Epoch: 1/2, step 862/7134 completed (loss: 1.78609299659729, acc: 0.5078219175338745)
[2024-12-17 03:37:54,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:54,463][root][INFO] - Training Epoch: 1/2, step 863/7134 completed (loss: 1.7115954160690308, acc: 0.5040745139122009)
[2024-12-17 03:37:54,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:54,925][root][INFO] - Training Epoch: 1/2, step 864/7134 completed (loss: 1.7059270143508911, acc: 0.5150442719459534)
[2024-12-17 03:37:55,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:55,399][root][INFO] - Training Epoch: 1/2, step 865/7134 completed (loss: 1.6917979717254639, acc: 0.5024330615997314)
[2024-12-17 03:37:55,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:55,886][root][INFO] - Training Epoch: 1/2, step 866/7134 completed (loss: 1.7749425172805786, acc: 0.4651851952075958)
[2024-12-17 03:37:56,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:56,395][root][INFO] - Training Epoch: 1/2, step 867/7134 completed (loss: 1.7676708698272705, acc: 0.47058823704719543)
[2024-12-17 03:37:56,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:56,872][root][INFO] - Training Epoch: 1/2, step 868/7134 completed (loss: 1.780482530593872, acc: 0.4803664982318878)
[2024-12-17 03:37:57,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:57,286][root][INFO] - Training Epoch: 1/2, step 869/7134 completed (loss: 1.7590608596801758, acc: 0.5191082954406738)
[2024-12-17 03:37:57,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:57,726][root][INFO] - Training Epoch: 1/2, step 870/7134 completed (loss: 1.5864025354385376, acc: 0.5471698045730591)
[2024-12-17 03:37:57,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:58,148][root][INFO] - Training Epoch: 1/2, step 871/7134 completed (loss: 1.7100294828414917, acc: 0.5016286373138428)
[2024-12-17 03:37:58,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:58,595][root][INFO] - Training Epoch: 1/2, step 872/7134 completed (loss: 1.5778106451034546, acc: 0.5416012406349182)
[2024-12-17 03:37:58,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:59,049][root][INFO] - Training Epoch: 1/2, step 873/7134 completed (loss: 1.5169237852096558, acc: 0.5591549277305603)
[2024-12-17 03:37:59,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:59,516][root][INFO] - Training Epoch: 1/2, step 874/7134 completed (loss: 1.6065696477890015, acc: 0.5254237055778503)
[2024-12-17 03:37:59,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:00,002][root][INFO] - Training Epoch: 1/2, step 875/7134 completed (loss: 1.5455973148345947, acc: 0.5256222486495972)
[2024-12-17 03:38:00,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:00,482][root][INFO] - Training Epoch: 1/2, step 876/7134 completed (loss: 1.4145698547363281, acc: 0.5818713307380676)
[2024-12-17 03:38:00,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:00,948][root][INFO] - Training Epoch: 1/2, step 877/7134 completed (loss: 1.5338274240493774, acc: 0.5576158761978149)
[2024-12-17 03:38:01,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:01,385][root][INFO] - Training Epoch: 1/2, step 878/7134 completed (loss: 1.6818642616271973, acc: 0.5079575777053833)
[2024-12-17 03:38:01,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:01,827][root][INFO] - Training Epoch: 1/2, step 879/7134 completed (loss: 1.5176215171813965, acc: 0.5371178984642029)
[2024-12-17 03:38:02,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:02,310][root][INFO] - Training Epoch: 1/2, step 880/7134 completed (loss: 1.5269153118133545, acc: 0.5545851588249207)
[2024-12-17 03:38:02,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:02,741][root][INFO] - Training Epoch: 1/2, step 881/7134 completed (loss: 1.6286609172821045, acc: 0.5370741486549377)
[2024-12-17 03:38:02,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:03,186][root][INFO] - Training Epoch: 1/2, step 882/7134 completed (loss: 1.5727089643478394, acc: 0.548561155796051)
[2024-12-17 03:38:03,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:03,636][root][INFO] - Training Epoch: 1/2, step 883/7134 completed (loss: 1.7751216888427734, acc: 0.4954128563404083)
[2024-12-17 03:38:03,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:04,079][root][INFO] - Training Epoch: 1/2, step 884/7134 completed (loss: 1.6517919301986694, acc: 0.525469183921814)
[2024-12-17 03:38:04,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:04,555][root][INFO] - Training Epoch: 1/2, step 885/7134 completed (loss: 1.6047362089157104, acc: 0.5365168452262878)
[2024-12-17 03:38:04,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:05,020][root][INFO] - Training Epoch: 1/2, step 886/7134 completed (loss: 1.67786705493927, acc: 0.5029239654541016)
[2024-12-17 03:38:05,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:05,449][root][INFO] - Training Epoch: 1/2, step 887/7134 completed (loss: 1.7100236415863037, acc: 0.5079646110534668)
[2024-12-17 03:38:05,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:05,898][root][INFO] - Training Epoch: 1/2, step 888/7134 completed (loss: 1.617197871208191, acc: 0.5326251983642578)
[2024-12-17 03:38:06,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:06,338][root][INFO] - Training Epoch: 1/2, step 889/7134 completed (loss: 1.6686279773712158, acc: 0.5)
[2024-12-17 03:38:06,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:06,764][root][INFO] - Training Epoch: 1/2, step 890/7134 completed (loss: 1.6774834394454956, acc: 0.5127334594726562)
[2024-12-17 03:38:06,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:07,227][root][INFO] - Training Epoch: 1/2, step 891/7134 completed (loss: 1.6244336366653442, acc: 0.5479832887649536)
[2024-12-17 03:38:07,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:07,707][root][INFO] - Training Epoch: 1/2, step 892/7134 completed (loss: 1.6456981897354126, acc: 0.5276162624359131)
[2024-12-17 03:38:07,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:08,142][root][INFO] - Training Epoch: 1/2, step 893/7134 completed (loss: 1.62413489818573, acc: 0.5433436632156372)
[2024-12-17 03:38:08,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:08,610][root][INFO] - Training Epoch: 1/2, step 894/7134 completed (loss: 1.5830037593841553, acc: 0.5321229100227356)
[2024-12-17 03:38:08,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:09,098][root][INFO] - Training Epoch: 1/2, step 895/7134 completed (loss: 1.509474515914917, acc: 0.5589743852615356)
[2024-12-17 03:38:09,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:09,507][root][INFO] - Training Epoch: 1/2, step 896/7134 completed (loss: 1.5803678035736084, acc: 0.550000011920929)
[2024-12-17 03:38:09,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:10,035][root][INFO] - Training Epoch: 1/2, step 897/7134 completed (loss: 1.6522796154022217, acc: 0.5264623761177063)
[2024-12-17 03:38:10,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:10,501][root][INFO] - Training Epoch: 1/2, step 898/7134 completed (loss: 1.6319589614868164, acc: 0.5118306279182434)
[2024-12-17 03:38:10,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:10,951][root][INFO] - Training Epoch: 1/2, step 899/7134 completed (loss: 1.6303333044052124, acc: 0.5261194109916687)
[2024-12-17 03:38:11,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:11,390][root][INFO] - Training Epoch: 1/2, step 900/7134 completed (loss: 1.6487994194030762, acc: 0.5077356100082397)
[2024-12-17 03:38:11,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:11,910][root][INFO] - Training Epoch: 1/2, step 901/7134 completed (loss: 1.643514633178711, acc: 0.515999972820282)
[2024-12-17 03:38:12,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:12,355][root][INFO] - Training Epoch: 1/2, step 902/7134 completed (loss: 1.5807993412017822, acc: 0.5724533796310425)
[2024-12-17 03:38:12,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:12,817][root][INFO] - Training Epoch: 1/2, step 903/7134 completed (loss: 1.5693848133087158, acc: 0.5323646068572998)
[2024-12-17 03:38:12,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:13,290][root][INFO] - Training Epoch: 1/2, step 904/7134 completed (loss: 1.5839300155639648, acc: 0.52734375)
[2024-12-17 03:38:13,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:13,752][root][INFO] - Training Epoch: 1/2, step 905/7134 completed (loss: 1.5076717138290405, acc: 0.5606468915939331)
[2024-12-17 03:38:13,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:14,204][root][INFO] - Training Epoch: 1/2, step 906/7134 completed (loss: 1.5829850435256958, acc: 0.5174262523651123)
[2024-12-17 03:38:14,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:14,670][root][INFO] - Training Epoch: 1/2, step 907/7134 completed (loss: 1.6415061950683594, acc: 0.5131579041481018)
[2024-12-17 03:38:14,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:15,113][root][INFO] - Training Epoch: 1/2, step 908/7134 completed (loss: 1.6346445083618164, acc: 0.5292587876319885)
[2024-12-17 03:38:15,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:15,545][root][INFO] - Training Epoch: 1/2, step 909/7134 completed (loss: 1.597883939743042, acc: 0.5285285115242004)
[2024-12-17 03:38:15,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:16,042][root][INFO] - Training Epoch: 1/2, step 910/7134 completed (loss: 1.713612675666809, acc: 0.499332457780838)
[2024-12-17 03:38:16,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:16,491][root][INFO] - Training Epoch: 1/2, step 911/7134 completed (loss: 1.6686588525772095, acc: 0.5076923370361328)
[2024-12-17 03:38:16,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:16,954][root][INFO] - Training Epoch: 1/2, step 912/7134 completed (loss: 1.6345367431640625, acc: 0.5283732414245605)
[2024-12-17 03:38:17,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:17,427][root][INFO] - Training Epoch: 1/2, step 913/7134 completed (loss: 1.643090009689331, acc: 0.5263819098472595)
[2024-12-17 03:38:17,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:17,878][root][INFO] - Training Epoch: 1/2, step 914/7134 completed (loss: 1.5814626216888428, acc: 0.5599489808082581)
[2024-12-17 03:38:18,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:18,324][root][INFO] - Training Epoch: 1/2, step 915/7134 completed (loss: 1.724039912223816, acc: 0.5339806079864502)
[2024-12-17 03:38:18,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:18,830][root][INFO] - Training Epoch: 1/2, step 916/7134 completed (loss: 1.6033328771591187, acc: 0.5375218391418457)
[2024-12-17 03:38:18,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:19,260][root][INFO] - Training Epoch: 1/2, step 917/7134 completed (loss: 1.6293295621871948, acc: 0.5263952016830444)
[2024-12-17 03:38:19,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:19,701][root][INFO] - Training Epoch: 1/2, step 918/7134 completed (loss: 1.52934730052948, acc: 0.5543644428253174)
[2024-12-17 03:38:19,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:20,108][root][INFO] - Training Epoch: 1/2, step 919/7134 completed (loss: 1.4836658239364624, acc: 0.5526695251464844)
[2024-12-17 03:38:20,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:20,561][root][INFO] - Training Epoch: 1/2, step 920/7134 completed (loss: 1.6430033445358276, acc: 0.5434173941612244)
[2024-12-17 03:38:20,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:21,017][root][INFO] - Training Epoch: 1/2, step 921/7134 completed (loss: 1.604697585105896, acc: 0.5257452726364136)
[2024-12-17 03:38:21,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:21,434][root][INFO] - Training Epoch: 1/2, step 922/7134 completed (loss: 1.60906183719635, acc: 0.5475409626960754)
[2024-12-17 03:38:21,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:21,900][root][INFO] - Training Epoch: 1/2, step 923/7134 completed (loss: 1.626541256904602, acc: 0.5304232835769653)
[2024-12-17 03:38:22,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:22,451][root][INFO] - Training Epoch: 1/2, step 924/7134 completed (loss: 1.5597074031829834, acc: 0.5640096664428711)
[2024-12-17 03:38:22,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:22,931][root][INFO] - Training Epoch: 1/2, step 925/7134 completed (loss: 1.5135177373886108, acc: 0.5829662084579468)
[2024-12-17 03:38:23,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:23,399][root][INFO] - Training Epoch: 1/2, step 926/7134 completed (loss: 1.59177827835083, acc: 0.5380774140357971)
[2024-12-17 03:38:23,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:23,859][root][INFO] - Training Epoch: 1/2, step 927/7134 completed (loss: 1.453519344329834, acc: 0.5816993713378906)
[2024-12-17 03:38:23,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:24,318][root][INFO] - Training Epoch: 1/2, step 928/7134 completed (loss: 1.530616044998169, acc: 0.5779092907905579)
[2024-12-17 03:38:24,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:24,761][root][INFO] - Training Epoch: 1/2, step 929/7134 completed (loss: 1.5646470785140991, acc: 0.5402843356132507)
[2024-12-17 03:38:24,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:25,171][root][INFO] - Training Epoch: 1/2, step 930/7134 completed (loss: 1.5788955688476562, acc: 0.5483871102333069)
[2024-12-17 03:38:25,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:25,645][root][INFO] - Training Epoch: 1/2, step 931/7134 completed (loss: 1.5861656665802002, acc: 0.5343915224075317)
[2024-12-17 03:38:25,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:26,116][root][INFO] - Training Epoch: 1/2, step 932/7134 completed (loss: 1.5369819402694702, acc: 0.5558739304542542)
[2024-12-17 03:38:26,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:26,542][root][INFO] - Training Epoch: 1/2, step 933/7134 completed (loss: 1.7092249393463135, acc: 0.5119886994361877)
[2024-12-17 03:38:26,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:27,002][root][INFO] - Training Epoch: 1/2, step 934/7134 completed (loss: 1.5453935861587524, acc: 0.5431936979293823)
[2024-12-17 03:38:27,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:27,442][root][INFO] - Training Epoch: 1/2, step 935/7134 completed (loss: 1.5843369960784912, acc: 0.544240415096283)
[2024-12-17 03:38:27,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:27,890][root][INFO] - Training Epoch: 1/2, step 936/7134 completed (loss: 1.568844199180603, acc: 0.5360281467437744)
[2024-12-17 03:38:28,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:28,339][root][INFO] - Training Epoch: 1/2, step 937/7134 completed (loss: 1.6058539152145386, acc: 0.5404929518699646)
[2024-12-17 03:38:28,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:28,805][root][INFO] - Training Epoch: 1/2, step 938/7134 completed (loss: 1.600476861000061, acc: 0.5444126129150391)
[2024-12-17 03:38:28,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:29,213][root][INFO] - Training Epoch: 1/2, step 939/7134 completed (loss: 1.694801926612854, acc: 0.5202492475509644)
[2024-12-17 03:38:29,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:29,677][root][INFO] - Training Epoch: 1/2, step 940/7134 completed (loss: 1.5834611654281616, acc: 0.5422031283378601)
[2024-12-17 03:38:29,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:30,146][root][INFO] - Training Epoch: 1/2, step 941/7134 completed (loss: 1.4290419816970825, acc: 0.5724138021469116)
[2024-12-17 03:38:30,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:30,581][root][INFO] - Training Epoch: 1/2, step 942/7134 completed (loss: 1.576327919960022, acc: 0.5384615659713745)
[2024-12-17 03:38:30,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:31,010][root][INFO] - Training Epoch: 1/2, step 943/7134 completed (loss: 1.515740156173706, acc: 0.5540334582328796)
[2024-12-17 03:38:31,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:31,444][root][INFO] - Training Epoch: 1/2, step 944/7134 completed (loss: 1.662251591682434, acc: 0.5112443566322327)
[2024-12-17 03:38:31,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:31,905][root][INFO] - Training Epoch: 1/2, step 945/7134 completed (loss: 1.6520615816116333, acc: 0.5174825191497803)
[2024-12-17 03:38:32,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:32,306][root][INFO] - Training Epoch: 1/2, step 946/7134 completed (loss: 1.5820870399475098, acc: 0.5289078950881958)
[2024-12-17 03:38:32,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:32,784][root][INFO] - Training Epoch: 1/2, step 947/7134 completed (loss: 1.525593638420105, acc: 0.5524957180023193)
[2024-12-17 03:38:32,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:33,278][root][INFO] - Training Epoch: 1/2, step 948/7134 completed (loss: 1.5470517873764038, acc: 0.5452016592025757)
[2024-12-17 03:38:33,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:33,854][root][INFO] - Training Epoch: 1/2, step 949/7134 completed (loss: 1.5120805501937866, acc: 0.5539972186088562)
[2024-12-17 03:38:34,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:34,334][root][INFO] - Training Epoch: 1/2, step 950/7134 completed (loss: 1.4318574666976929, acc: 0.5771604776382446)
[2024-12-17 03:38:34,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:34,778][root][INFO] - Training Epoch: 1/2, step 951/7134 completed (loss: 1.5341124534606934, acc: 0.5369718074798584)
[2024-12-17 03:38:34,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:35,252][root][INFO] - Training Epoch: 1/2, step 952/7134 completed (loss: 1.6366828680038452, acc: 0.5341098308563232)
[2024-12-17 03:38:35,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:35,727][root][INFO] - Training Epoch: 1/2, step 953/7134 completed (loss: 1.6768162250518799, acc: 0.5386503338813782)
[2024-12-17 03:38:35,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:36,183][root][INFO] - Training Epoch: 1/2, step 954/7134 completed (loss: 1.5442477464675903, acc: 0.5565345287322998)
[2024-12-17 03:38:36,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:36,656][root][INFO] - Training Epoch: 1/2, step 955/7134 completed (loss: 1.6456325054168701, acc: 0.5354752540588379)
[2024-12-17 03:38:36,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:37,105][root][INFO] - Training Epoch: 1/2, step 956/7134 completed (loss: 1.6238278150558472, acc: 0.5414634346961975)
[2024-12-17 03:38:37,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:37,560][root][INFO] - Training Epoch: 1/2, step 957/7134 completed (loss: 1.4916223287582397, acc: 0.5665528774261475)
[2024-12-17 03:38:37,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:37,981][root][INFO] - Training Epoch: 1/2, step 958/7134 completed (loss: 1.6318700313568115, acc: 0.5202205777168274)
[2024-12-17 03:38:38,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:38,414][root][INFO] - Training Epoch: 1/2, step 959/7134 completed (loss: 1.6838520765304565, acc: 0.5213903784751892)
[2024-12-17 03:38:38,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:38,845][root][INFO] - Training Epoch: 1/2, step 960/7134 completed (loss: 1.6977260112762451, acc: 0.517958402633667)
[2024-12-17 03:38:38,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:39,279][root][INFO] - Training Epoch: 1/2, step 961/7134 completed (loss: 1.631071925163269, acc: 0.5229110717773438)
[2024-12-17 03:38:39,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:39,729][root][INFO] - Training Epoch: 1/2, step 962/7134 completed (loss: 1.568742275238037, acc: 0.5324137806892395)
[2024-12-17 03:38:39,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:40,184][root][INFO] - Training Epoch: 1/2, step 963/7134 completed (loss: 1.6152064800262451, acc: 0.5396341681480408)
[2024-12-17 03:38:40,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:40,651][root][INFO] - Training Epoch: 1/2, step 964/7134 completed (loss: 1.6677652597427368, acc: 0.5142428874969482)
[2024-12-17 03:38:40,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:41,090][root][INFO] - Training Epoch: 1/2, step 965/7134 completed (loss: 1.6467775106430054, acc: 0.4992826282978058)
[2024-12-17 03:38:41,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:41,498][root][INFO] - Training Epoch: 1/2, step 966/7134 completed (loss: 1.5576671361923218, acc: 0.5442622900009155)
[2024-12-17 03:38:41,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:41,965][root][INFO] - Training Epoch: 1/2, step 967/7134 completed (loss: 1.603021502494812, acc: 0.5266029834747314)
[2024-12-17 03:38:42,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:42,436][root][INFO] - Training Epoch: 1/2, step 968/7134 completed (loss: 1.6264492273330688, acc: 0.5328031778335571)
[2024-12-17 03:38:42,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:42,872][root][INFO] - Training Epoch: 1/2, step 969/7134 completed (loss: 1.6642245054244995, acc: 0.49321267008781433)
[2024-12-17 03:38:43,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:43,333][root][INFO] - Training Epoch: 1/2, step 970/7134 completed (loss: 1.553572177886963, acc: 0.555343508720398)
[2024-12-17 03:38:43,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:43,789][root][INFO] - Training Epoch: 1/2, step 971/7134 completed (loss: 1.5999555587768555, acc: 0.5300613641738892)
[2024-12-17 03:38:43,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:44,259][root][INFO] - Training Epoch: 1/2, step 972/7134 completed (loss: 1.6866055727005005, acc: 0.49066001176834106)
[2024-12-17 03:38:44,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:44,709][root][INFO] - Training Epoch: 1/2, step 973/7134 completed (loss: 1.6827589273452759, acc: 0.5307692289352417)
[2024-12-17 03:38:44,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:45,185][root][INFO] - Training Epoch: 1/2, step 974/7134 completed (loss: 1.6445561647415161, acc: 0.5131129026412964)
[2024-12-17 03:38:45,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:45,625][root][INFO] - Training Epoch: 1/2, step 975/7134 completed (loss: 1.744120717048645, acc: 0.4844497740268707)
[2024-12-17 03:38:45,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:46,071][root][INFO] - Training Epoch: 1/2, step 976/7134 completed (loss: 1.5855647325515747, acc: 0.5218068361282349)
[2024-12-17 03:38:46,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:46,531][root][INFO] - Training Epoch: 1/2, step 977/7134 completed (loss: 1.6720616817474365, acc: 0.5194805264472961)
[2024-12-17 03:38:46,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:47,016][root][INFO] - Training Epoch: 1/2, step 978/7134 completed (loss: 1.5464872121810913, acc: 0.5246690511703491)
[2024-12-17 03:38:47,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:47,467][root][INFO] - Training Epoch: 1/2, step 979/7134 completed (loss: 1.5788029432296753, acc: 0.5320855379104614)
[2024-12-17 03:38:47,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:47,918][root][INFO] - Training Epoch: 1/2, step 980/7134 completed (loss: 1.628482460975647, acc: 0.518750011920929)
[2024-12-17 03:38:48,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:48,374][root][INFO] - Training Epoch: 1/2, step 981/7134 completed (loss: 1.7026928663253784, acc: 0.5032154321670532)
[2024-12-17 03:38:48,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:48,828][root][INFO] - Training Epoch: 1/2, step 982/7134 completed (loss: 1.5812472105026245, acc: 0.5280898809432983)
[2024-12-17 03:38:48,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:49,272][root][INFO] - Training Epoch: 1/2, step 983/7134 completed (loss: 1.5555291175842285, acc: 0.5325342416763306)
[2024-12-17 03:38:49,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:49,701][root][INFO] - Training Epoch: 1/2, step 984/7134 completed (loss: 1.4800916910171509, acc: 0.5827205777168274)
[2024-12-17 03:38:49,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:50,163][root][INFO] - Training Epoch: 1/2, step 985/7134 completed (loss: 1.4005215167999268, acc: 0.6007652878761292)
[2024-12-17 03:38:50,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:50,621][root][INFO] - Training Epoch: 1/2, step 986/7134 completed (loss: 1.57268488407135, acc: 0.5722379684448242)
[2024-12-17 03:38:50,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:51,082][root][INFO] - Training Epoch: 1/2, step 987/7134 completed (loss: 1.5319451093673706, acc: 0.5466237664222717)
[2024-12-17 03:38:51,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:51,513][root][INFO] - Training Epoch: 1/2, step 988/7134 completed (loss: 1.7150382995605469, acc: 0.5020804405212402)
[2024-12-17 03:38:51,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:51,954][root][INFO] - Training Epoch: 1/2, step 989/7134 completed (loss: 1.6723076105117798, acc: 0.5312934517860413)
[2024-12-17 03:38:52,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:52,395][root][INFO] - Training Epoch: 1/2, step 990/7134 completed (loss: 1.7266238927841187, acc: 0.49431100487709045)
[2024-12-17 03:38:52,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:52,832][root][INFO] - Training Epoch: 1/2, step 991/7134 completed (loss: 1.7850953340530396, acc: 0.471048504114151)
[2024-12-17 03:38:52,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:53,297][root][INFO] - Training Epoch: 1/2, step 992/7134 completed (loss: 1.7114589214324951, acc: 0.4973684251308441)
[2024-12-17 03:38:53,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:53,725][root][INFO] - Training Epoch: 1/2, step 993/7134 completed (loss: 1.7783023118972778, acc: 0.4680851101875305)
[2024-12-17 03:38:53,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:54,232][root][INFO] - Training Epoch: 1/2, step 994/7134 completed (loss: 1.6239975690841675, acc: 0.5304054021835327)
[2024-12-17 03:38:54,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:54,733][root][INFO] - Training Epoch: 1/2, step 995/7134 completed (loss: 1.6619654893875122, acc: 0.5262345671653748)
[2024-12-17 03:38:54,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:55,171][root][INFO] - Training Epoch: 1/2, step 996/7134 completed (loss: 1.7062937021255493, acc: 0.505586564540863)
[2024-12-17 03:38:55,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:55,617][root][INFO] - Training Epoch: 1/2, step 997/7134 completed (loss: 1.6541402339935303, acc: 0.5315186381340027)
[2024-12-17 03:38:55,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:56,050][root][INFO] - Training Epoch: 1/2, step 998/7134 completed (loss: 1.6661754846572876, acc: 0.5056338310241699)
[2024-12-17 03:38:56,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:56,464][root][INFO] - Training Epoch: 1/2, step 999/7134 completed (loss: 1.6700598001480103, acc: 0.519713282585144)
[2024-12-17 03:38:56,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:56,884][root][INFO] - Training Epoch: 1/2, step 1000/7134 completed (loss: 1.6128168106079102, acc: 0.5188356041908264)
[2024-12-17 03:38:57,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:57,322][root][INFO] - Training Epoch: 1/2, step 1001/7134 completed (loss: 1.6211013793945312, acc: 0.5171717405319214)
[2024-12-17 03:38:57,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:57,770][root][INFO] - Training Epoch: 1/2, step 1002/7134 completed (loss: 1.5525999069213867, acc: 0.5534949898719788)
[2024-12-17 03:38:57,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:58,215][root][INFO] - Training Epoch: 1/2, step 1003/7134 completed (loss: 1.5837441682815552, acc: 0.5616641640663147)
[2024-12-17 03:38:58,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:58,634][root][INFO] - Training Epoch: 1/2, step 1004/7134 completed (loss: 1.6923108100891113, acc: 0.49896907806396484)
[2024-12-17 03:38:58,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:59,079][root][INFO] - Training Epoch: 1/2, step 1005/7134 completed (loss: 1.5748387575149536, acc: 0.5231788158416748)
[2024-12-17 03:38:59,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:59,514][root][INFO] - Training Epoch: 1/2, step 1006/7134 completed (loss: 1.6513627767562866, acc: 0.5264623761177063)
[2024-12-17 03:38:59,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:38:59,958][root][INFO] - Training Epoch: 1/2, step 1007/7134 completed (loss: 1.629083275794983, acc: 0.5180533528327942)
[2024-12-17 03:39:00,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:00,399][root][INFO] - Training Epoch: 1/2, step 1008/7134 completed (loss: 1.598573923110962, acc: 0.5234042406082153)
[2024-12-17 03:39:00,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:00,826][root][INFO] - Training Epoch: 1/2, step 1009/7134 completed (loss: 1.4740232229232788, acc: 0.5595026612281799)
[2024-12-17 03:39:00,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:01,238][root][INFO] - Training Epoch: 1/2, step 1010/7134 completed (loss: 1.6696110963821411, acc: 0.5)
[2024-12-17 03:39:01,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:01,674][root][INFO] - Training Epoch: 1/2, step 1011/7134 completed (loss: 1.5108273029327393, acc: 0.5615491271018982)
[2024-12-17 03:39:01,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:02,104][root][INFO] - Training Epoch: 1/2, step 1012/7134 completed (loss: 1.634144902229309, acc: 0.5311614871025085)
[2024-12-17 03:39:02,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:02,540][root][INFO] - Training Epoch: 1/2, step 1013/7134 completed (loss: 1.5968213081359863, acc: 0.5257879495620728)
[2024-12-17 03:39:02,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:02,964][root][INFO] - Training Epoch: 1/2, step 1014/7134 completed (loss: 1.6093453168869019, acc: 0.5336617231369019)
[2024-12-17 03:39:03,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:03,388][root][INFO] - Training Epoch: 1/2, step 1015/7134 completed (loss: 1.5706135034561157, acc: 0.5451807379722595)
[2024-12-17 03:39:03,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:03,846][root][INFO] - Training Epoch: 1/2, step 1016/7134 completed (loss: 1.5728596448898315, acc: 0.5468451380729675)
[2024-12-17 03:39:03,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:04,313][root][INFO] - Training Epoch: 1/2, step 1017/7134 completed (loss: 1.6176748275756836, acc: 0.5395973324775696)
[2024-12-17 03:39:04,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:04,747][root][INFO] - Training Epoch: 1/2, step 1018/7134 completed (loss: 1.6401251554489136, acc: 0.5373352766036987)
[2024-12-17 03:39:04,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:05,169][root][INFO] - Training Epoch: 1/2, step 1019/7134 completed (loss: 1.6873172521591187, acc: 0.49839743971824646)
[2024-12-17 03:39:05,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:05,603][root][INFO] - Training Epoch: 1/2, step 1020/7134 completed (loss: 1.5810195207595825, acc: 0.5373134613037109)
[2024-12-17 03:39:05,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:06,052][root][INFO] - Training Epoch: 1/2, step 1021/7134 completed (loss: 1.5492353439331055, acc: 0.5350318551063538)
[2024-12-17 03:39:06,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:06,503][root][INFO] - Training Epoch: 1/2, step 1022/7134 completed (loss: 1.4965441226959229, acc: 0.5454545617103577)
[2024-12-17 03:39:06,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:06,949][root][INFO] - Training Epoch: 1/2, step 1023/7134 completed (loss: 1.5769329071044922, acc: 0.5276705026626587)
[2024-12-17 03:39:07,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:07,419][root][INFO] - Training Epoch: 1/2, step 1024/7134 completed (loss: 1.4839128255844116, acc: 0.5601436495780945)
[2024-12-17 03:39:07,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:07,838][root][INFO] - Training Epoch: 1/2, step 1025/7134 completed (loss: 1.4772100448608398, acc: 0.5658363103866577)
[2024-12-17 03:39:07,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:08,270][root][INFO] - Training Epoch: 1/2, step 1026/7134 completed (loss: 1.5096081495285034, acc: 0.557894766330719)
[2024-12-17 03:39:08,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:08,689][root][INFO] - Training Epoch: 1/2, step 1027/7134 completed (loss: 1.4925785064697266, acc: 0.5561569929122925)
[2024-12-17 03:39:08,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:09,141][root][INFO] - Training Epoch: 1/2, step 1028/7134 completed (loss: 1.5816142559051514, acc: 0.5261584520339966)
[2024-12-17 03:39:09,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:09,601][root][INFO] - Training Epoch: 1/2, step 1029/7134 completed (loss: 1.6066309213638306, acc: 0.5319464802742004)
[2024-12-17 03:39:09,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:10,033][root][INFO] - Training Epoch: 1/2, step 1030/7134 completed (loss: 1.5369765758514404, acc: 0.5592991709709167)
[2024-12-17 03:39:10,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:10,485][root][INFO] - Training Epoch: 1/2, step 1031/7134 completed (loss: 1.6808013916015625, acc: 0.5152438879013062)
[2024-12-17 03:39:10,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:10,946][root][INFO] - Training Epoch: 1/2, step 1032/7134 completed (loss: 1.5681074857711792, acc: 0.5472350120544434)
[2024-12-17 03:39:11,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:11,412][root][INFO] - Training Epoch: 1/2, step 1033/7134 completed (loss: 1.6506941318511963, acc: 0.5265423059463501)
[2024-12-17 03:39:11,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:11,867][root][INFO] - Training Epoch: 1/2, step 1034/7134 completed (loss: 1.6336456537246704, acc: 0.541329026222229)
[2024-12-17 03:39:12,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:12,281][root][INFO] - Training Epoch: 1/2, step 1035/7134 completed (loss: 1.7399344444274902, acc: 0.4771929681301117)
[2024-12-17 03:39:12,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:12,686][root][INFO] - Training Epoch: 1/2, step 1036/7134 completed (loss: 1.8180149793624878, acc: 0.4555555582046509)
[2024-12-17 03:39:12,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:13,172][root][INFO] - Training Epoch: 1/2, step 1037/7134 completed (loss: 1.6164087057113647, acc: 0.5440475940704346)
[2024-12-17 03:39:13,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:13,631][root][INFO] - Training Epoch: 1/2, step 1038/7134 completed (loss: 1.680968165397644, acc: 0.5016778707504272)
[2024-12-17 03:39:13,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:14,084][root][INFO] - Training Epoch: 1/2, step 1039/7134 completed (loss: 1.650862693786621, acc: 0.5175983309745789)
[2024-12-17 03:39:14,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:14,544][root][INFO] - Training Epoch: 1/2, step 1040/7134 completed (loss: 1.6246689558029175, acc: 0.5308219194412231)
[2024-12-17 03:39:14,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:14,988][root][INFO] - Training Epoch: 1/2, step 1041/7134 completed (loss: 1.549769639968872, acc: 0.5623052716255188)
[2024-12-17 03:39:15,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:15,497][root][INFO] - Training Epoch: 1/2, step 1042/7134 completed (loss: 1.6004843711853027, acc: 0.5448718070983887)
[2024-12-17 03:39:15,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:15,975][root][INFO] - Training Epoch: 1/2, step 1043/7134 completed (loss: 1.5765920877456665, acc: 0.5342960357666016)
[2024-12-17 03:39:16,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:16,451][root][INFO] - Training Epoch: 1/2, step 1044/7134 completed (loss: 1.5322729349136353, acc: 0.5547945499420166)
[2024-12-17 03:39:16,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:16,892][root][INFO] - Training Epoch: 1/2, step 1045/7134 completed (loss: 1.9534766674041748, acc: 0.4491114616394043)
[2024-12-17 03:39:16,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:17,309][root][INFO] - Training Epoch: 1/2, step 1046/7134 completed (loss: 1.7118470668792725, acc: 0.4942084848880768)
[2024-12-17 03:39:17,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:17,763][root][INFO] - Training Epoch: 1/2, step 1047/7134 completed (loss: 1.7342780828475952, acc: 0.5288888812065125)
[2024-12-17 03:39:17,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:18,313][root][INFO] - Training Epoch: 1/2, step 1048/7134 completed (loss: 1.5523452758789062, acc: 0.5395894646644592)
[2024-12-17 03:39:18,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:18,741][root][INFO] - Training Epoch: 1/2, step 1049/7134 completed (loss: 1.6173186302185059, acc: 0.5270863771438599)
[2024-12-17 03:39:18,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:19,184][root][INFO] - Training Epoch: 1/2, step 1050/7134 completed (loss: 1.5552690029144287, acc: 0.5491803288459778)
[2024-12-17 03:39:19,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:19,643][root][INFO] - Training Epoch: 1/2, step 1051/7134 completed (loss: 1.5882481336593628, acc: 0.534246563911438)
[2024-12-17 03:39:19,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:20,077][root][INFO] - Training Epoch: 1/2, step 1052/7134 completed (loss: 1.652089238166809, acc: 0.5298869013786316)
[2024-12-17 03:39:20,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:20,496][root][INFO] - Training Epoch: 1/2, step 1053/7134 completed (loss: 1.5531421899795532, acc: 0.5605633854866028)
[2024-12-17 03:39:20,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:20,934][root][INFO] - Training Epoch: 1/2, step 1054/7134 completed (loss: 1.560484766960144, acc: 0.5496688485145569)
[2024-12-17 03:39:21,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:21,367][root][INFO] - Training Epoch: 1/2, step 1055/7134 completed (loss: 1.6370368003845215, acc: 0.5099778175354004)
[2024-12-17 03:39:21,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:21,835][root][INFO] - Training Epoch: 1/2, step 1056/7134 completed (loss: 1.6444975137710571, acc: 0.5343383550643921)
[2024-12-17 03:39:21,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:22,271][root][INFO] - Training Epoch: 1/2, step 1057/7134 completed (loss: 1.5736563205718994, acc: 0.5361271500587463)
[2024-12-17 03:39:22,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:22,730][root][INFO] - Training Epoch: 1/2, step 1058/7134 completed (loss: 1.5901708602905273, acc: 0.5362318754196167)
[2024-12-17 03:39:22,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:23,223][root][INFO] - Training Epoch: 1/2, step 1059/7134 completed (loss: 1.540662169456482, acc: 0.5445161461830139)
[2024-12-17 03:39:23,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:23,674][root][INFO] - Training Epoch: 1/2, step 1060/7134 completed (loss: 1.5542279481887817, acc: 0.5441640615463257)
[2024-12-17 03:39:23,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:24,218][root][INFO] - Training Epoch: 1/2, step 1061/7134 completed (loss: 1.4867244958877563, acc: 0.5566860437393188)
[2024-12-17 03:39:24,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:24,715][root][INFO] - Training Epoch: 1/2, step 1062/7134 completed (loss: 1.589058756828308, acc: 0.5288135409355164)
[2024-12-17 03:39:24,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:25,189][root][INFO] - Training Epoch: 1/2, step 1063/7134 completed (loss: 1.5711592435836792, acc: 0.5332252979278564)
[2024-12-17 03:39:25,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:25,660][root][INFO] - Training Epoch: 1/2, step 1064/7134 completed (loss: 1.5539859533309937, acc: 0.5493826866149902)
[2024-12-17 03:39:25,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:26,106][root][INFO] - Training Epoch: 1/2, step 1065/7134 completed (loss: 1.555060625076294, acc: 0.5406504273414612)
[2024-12-17 03:39:26,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:26,553][root][INFO] - Training Epoch: 1/2, step 1066/7134 completed (loss: 1.7021074295043945, acc: 0.5167785286903381)
[2024-12-17 03:39:26,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:26,977][root][INFO] - Training Epoch: 1/2, step 1067/7134 completed (loss: 1.6277062892913818, acc: 0.5423728823661804)
[2024-12-17 03:39:27,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:27,394][root][INFO] - Training Epoch: 1/2, step 1068/7134 completed (loss: 1.6214221715927124, acc: 0.5121951103210449)
[2024-12-17 03:39:27,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:27,820][root][INFO] - Training Epoch: 1/2, step 1069/7134 completed (loss: 1.6927388906478882, acc: 0.5041736364364624)
[2024-12-17 03:39:27,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:28,223][root][INFO] - Training Epoch: 1/2, step 1070/7134 completed (loss: 1.485115885734558, acc: 0.5747126340866089)
[2024-12-17 03:39:28,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:28,725][root][INFO] - Training Epoch: 1/2, step 1071/7134 completed (loss: 1.409833550453186, acc: 0.5876840949058533)
[2024-12-17 03:39:28,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:29,174][root][INFO] - Training Epoch: 1/2, step 1072/7134 completed (loss: 1.3863427639007568, acc: 0.5791610479354858)
[2024-12-17 03:39:29,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:29,618][root][INFO] - Training Epoch: 1/2, step 1073/7134 completed (loss: 1.4108725786209106, acc: 0.5835734605789185)
[2024-12-17 03:39:29,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:30,058][root][INFO] - Training Epoch: 1/2, step 1074/7134 completed (loss: 1.5335595607757568, acc: 0.5302245020866394)
[2024-12-17 03:39:30,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:30,503][root][INFO] - Training Epoch: 1/2, step 1075/7134 completed (loss: 1.5988385677337646, acc: 0.5340699553489685)
[2024-12-17 03:39:30,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:30,950][root][INFO] - Training Epoch: 1/2, step 1076/7134 completed (loss: 1.6140918731689453, acc: 0.541223406791687)
[2024-12-17 03:39:31,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:31,361][root][INFO] - Training Epoch: 1/2, step 1077/7134 completed (loss: 1.6593140363693237, acc: 0.5135135054588318)
[2024-12-17 03:39:31,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:31,813][root][INFO] - Training Epoch: 1/2, step 1078/7134 completed (loss: 1.6486552953720093, acc: 0.5169628262519836)
[2024-12-17 03:39:31,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:32,269][root][INFO] - Training Epoch: 1/2, step 1079/7134 completed (loss: 1.5749900341033936, acc: 0.5455594062805176)
[2024-12-17 03:39:32,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:32,697][root][INFO] - Training Epoch: 1/2, step 1080/7134 completed (loss: 1.6866257190704346, acc: 0.5357142686843872)
[2024-12-17 03:39:32,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:33,138][root][INFO] - Training Epoch: 1/2, step 1081/7134 completed (loss: 1.5204437971115112, acc: 0.5441794991493225)
[2024-12-17 03:39:33,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:33,684][root][INFO] - Training Epoch: 1/2, step 1082/7134 completed (loss: 1.4343419075012207, acc: 0.5652620792388916)
[2024-12-17 03:39:33,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:34,151][root][INFO] - Training Epoch: 1/2, step 1083/7134 completed (loss: 1.4551682472229004, acc: 0.5468926429748535)
[2024-12-17 03:39:34,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:34,623][root][INFO] - Training Epoch: 1/2, step 1084/7134 completed (loss: 1.3952891826629639, acc: 0.5811648368835449)
[2024-12-17 03:39:34,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:35,081][root][INFO] - Training Epoch: 1/2, step 1085/7134 completed (loss: 1.5291461944580078, acc: 0.5542168617248535)
[2024-12-17 03:39:35,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:35,514][root][INFO] - Training Epoch: 1/2, step 1086/7134 completed (loss: 1.7363693714141846, acc: 0.49716445803642273)
[2024-12-17 03:39:35,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:35,988][root][INFO] - Training Epoch: 1/2, step 1087/7134 completed (loss: 1.5688260793685913, acc: 0.5524390339851379)
[2024-12-17 03:39:36,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:36,433][root][INFO] - Training Epoch: 1/2, step 1088/7134 completed (loss: 1.479535460472107, acc: 0.5544692873954773)
[2024-12-17 03:39:36,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:36,866][root][INFO] - Training Epoch: 1/2, step 1089/7134 completed (loss: 1.5813063383102417, acc: 0.5424739122390747)
[2024-12-17 03:39:36,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:37,362][root][INFO] - Training Epoch: 1/2, step 1090/7134 completed (loss: 1.424926996231079, acc: 0.5819032788276672)
[2024-12-17 03:39:37,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:37,783][root][INFO] - Training Epoch: 1/2, step 1091/7134 completed (loss: 1.4406254291534424, acc: 0.5936073064804077)
[2024-12-17 03:39:37,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:38,235][root][INFO] - Training Epoch: 1/2, step 1092/7134 completed (loss: 1.3426002264022827, acc: 0.6069363951683044)
[2024-12-17 03:39:38,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:38,665][root][INFO] - Training Epoch: 1/2, step 1093/7134 completed (loss: 1.448534607887268, acc: 0.5987460613250732)
[2024-12-17 03:39:38,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:39,098][root][INFO] - Training Epoch: 1/2, step 1094/7134 completed (loss: 1.6043660640716553, acc: 0.5446096658706665)
[2024-12-17 03:39:39,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:39,620][root][INFO] - Training Epoch: 1/2, step 1095/7134 completed (loss: 1.5731737613677979, acc: 0.5615103244781494)
[2024-12-17 03:39:39,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:40,092][root][INFO] - Training Epoch: 1/2, step 1096/7134 completed (loss: 1.6085401773452759, acc: 0.5354430675506592)
[2024-12-17 03:39:40,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:40,542][root][INFO] - Training Epoch: 1/2, step 1097/7134 completed (loss: 1.6936548948287964, acc: 0.516853928565979)
[2024-12-17 03:39:40,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:40,982][root][INFO] - Training Epoch: 1/2, step 1098/7134 completed (loss: 1.4834442138671875, acc: 0.5562422871589661)
[2024-12-17 03:39:41,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:41,446][root][INFO] - Training Epoch: 1/2, step 1099/7134 completed (loss: 1.5343503952026367, acc: 0.5525640845298767)
[2024-12-17 03:39:41,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:41,949][root][INFO] - Training Epoch: 1/2, step 1100/7134 completed (loss: 1.5674006938934326, acc: 0.5461956262588501)
[2024-12-17 03:39:42,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:42,420][root][INFO] - Training Epoch: 1/2, step 1101/7134 completed (loss: 1.4989773035049438, acc: 0.5415584444999695)
[2024-12-17 03:39:42,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:42,850][root][INFO] - Training Epoch: 1/2, step 1102/7134 completed (loss: 1.552761197090149, acc: 0.5401174426078796)
[2024-12-17 03:39:42,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:43,324][root][INFO] - Training Epoch: 1/2, step 1103/7134 completed (loss: 1.6635560989379883, acc: 0.5120000243186951)
[2024-12-17 03:39:43,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:43,771][root][INFO] - Training Epoch: 1/2, step 1104/7134 completed (loss: 1.5594353675842285, acc: 0.5504322648048401)
[2024-12-17 03:39:43,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:44,214][root][INFO] - Training Epoch: 1/2, step 1105/7134 completed (loss: 1.6951930522918701, acc: 0.5)
[2024-12-17 03:39:44,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:44,725][root][INFO] - Training Epoch: 1/2, step 1106/7134 completed (loss: 1.6569172143936157, acc: 0.502754807472229)
[2024-12-17 03:39:44,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:45,214][root][INFO] - Training Epoch: 1/2, step 1107/7134 completed (loss: 1.5455608367919922, acc: 0.5404455065727234)
[2024-12-17 03:39:45,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:45,664][root][INFO] - Training Epoch: 1/2, step 1108/7134 completed (loss: 1.5423555374145508, acc: 0.5579897165298462)
[2024-12-17 03:39:45,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:46,175][root][INFO] - Training Epoch: 1/2, step 1109/7134 completed (loss: 1.702202320098877, acc: 0.48603352904319763)
[2024-12-17 03:39:46,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:46,628][root][INFO] - Training Epoch: 1/2, step 1110/7134 completed (loss: 1.6450008153915405, acc: 0.5229358077049255)
[2024-12-17 03:39:46,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:47,077][root][INFO] - Training Epoch: 1/2, step 1111/7134 completed (loss: 1.5411674976348877, acc: 0.5359116196632385)
[2024-12-17 03:39:47,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:47,504][root][INFO] - Training Epoch: 1/2, step 1112/7134 completed (loss: 1.5865628719329834, acc: 0.5397058725357056)
[2024-12-17 03:39:47,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:47,939][root][INFO] - Training Epoch: 1/2, step 1113/7134 completed (loss: 1.5064409971237183, acc: 0.5366795659065247)
[2024-12-17 03:39:48,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:48,411][root][INFO] - Training Epoch: 1/2, step 1114/7134 completed (loss: 1.6676090955734253, acc: 0.5006075501441956)
[2024-12-17 03:39:48,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:48,877][root][INFO] - Training Epoch: 1/2, step 1115/7134 completed (loss: 1.6082706451416016, acc: 0.5172955989837646)
[2024-12-17 03:39:49,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:49,303][root][INFO] - Training Epoch: 1/2, step 1116/7134 completed (loss: 1.5394062995910645, acc: 0.5634328126907349)
[2024-12-17 03:39:49,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:49,730][root][INFO] - Training Epoch: 1/2, step 1117/7134 completed (loss: 1.4898326396942139, acc: 0.550613522529602)
[2024-12-17 03:39:49,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:50,194][root][INFO] - Training Epoch: 1/2, step 1118/7134 completed (loss: 1.6594318151474, acc: 0.5224137902259827)
[2024-12-17 03:39:50,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:50,649][root][INFO] - Training Epoch: 1/2, step 1119/7134 completed (loss: 1.503161072731018, acc: 0.5608214735984802)
[2024-12-17 03:39:50,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:51,082][root][INFO] - Training Epoch: 1/2, step 1120/7134 completed (loss: 1.5306153297424316, acc: 0.5566037893295288)
[2024-12-17 03:39:51,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:51,511][root][INFO] - Training Epoch: 1/2, step 1121/7134 completed (loss: 1.4400525093078613, acc: 0.5568685531616211)
[2024-12-17 03:39:51,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:51,904][root][INFO] - Training Epoch: 1/2, step 1122/7134 completed (loss: 1.4917106628417969, acc: 0.5611650347709656)
[2024-12-17 03:39:52,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:52,325][root][INFO] - Training Epoch: 1/2, step 1123/7134 completed (loss: 1.5331270694732666, acc: 0.5521669387817383)
[2024-12-17 03:39:52,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:52,765][root][INFO] - Training Epoch: 1/2, step 1124/7134 completed (loss: 1.5878725051879883, acc: 0.5557275414466858)
[2024-12-17 03:39:52,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:53,207][root][INFO] - Training Epoch: 1/2, step 1125/7134 completed (loss: 1.4499975442886353, acc: 0.5737482905387878)
[2024-12-17 03:39:53,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:53,642][root][INFO] - Training Epoch: 1/2, step 1126/7134 completed (loss: 1.4594917297363281, acc: 0.5552486181259155)
[2024-12-17 03:39:53,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:54,070][root][INFO] - Training Epoch: 1/2, step 1127/7134 completed (loss: 1.437816858291626, acc: 0.5759999752044678)
[2024-12-17 03:39:54,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:54,490][root][INFO] - Training Epoch: 1/2, step 1128/7134 completed (loss: 1.5926804542541504, acc: 0.5451388955116272)
[2024-12-17 03:39:54,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:54,883][root][INFO] - Training Epoch: 1/2, step 1129/7134 completed (loss: 1.6614327430725098, acc: 0.5201793909072876)
[2024-12-17 03:39:54,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:55,329][root][INFO] - Training Epoch: 1/2, step 1130/7134 completed (loss: 1.5112358331680298, acc: 0.5444265007972717)
[2024-12-17 03:39:55,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:55,807][root][INFO] - Training Epoch: 1/2, step 1131/7134 completed (loss: 1.4924757480621338, acc: 0.5896226167678833)
[2024-12-17 03:39:55,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:56,228][root][INFO] - Training Epoch: 1/2, step 1132/7134 completed (loss: 1.5859698057174683, acc: 0.560490071773529)
[2024-12-17 03:39:56,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:56,706][root][INFO] - Training Epoch: 1/2, step 1133/7134 completed (loss: 1.5681281089782715, acc: 0.5435092449188232)
[2024-12-17 03:39:56,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:57,148][root][INFO] - Training Epoch: 1/2, step 1134/7134 completed (loss: 1.5202580690383911, acc: 0.5461346507072449)
[2024-12-17 03:39:57,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:57,579][root][INFO] - Training Epoch: 1/2, step 1135/7134 completed (loss: 1.5808868408203125, acc: 0.5519999861717224)
[2024-12-17 03:39:57,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:58,035][root][INFO] - Training Epoch: 1/2, step 1136/7134 completed (loss: 1.639613389968872, acc: 0.5265306234359741)
[2024-12-17 03:39:58,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:58,404][root][INFO] - Training Epoch: 1/2, step 1137/7134 completed (loss: 1.5149940252304077, acc: 0.5772727131843567)
[2024-12-17 03:39:58,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:58,875][root][INFO] - Training Epoch: 1/2, step 1138/7134 completed (loss: 1.5423405170440674, acc: 0.5655737519264221)
[2024-12-17 03:39:58,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:59,304][root][INFO] - Training Epoch: 1/2, step 1139/7134 completed (loss: 1.6423699855804443, acc: 0.5244519114494324)
[2024-12-17 03:39:59,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:39:59,787][root][INFO] - Training Epoch: 1/2, step 1140/7134 completed (loss: 1.5118809938430786, acc: 0.5563910007476807)
[2024-12-17 03:39:59,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:00,213][root][INFO] - Training Epoch: 1/2, step 1141/7134 completed (loss: 1.5004571676254272, acc: 0.5714285969734192)
[2024-12-17 03:40:00,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:00,664][root][INFO] - Training Epoch: 1/2, step 1142/7134 completed (loss: 1.4276875257492065, acc: 0.5729166865348816)
[2024-12-17 03:40:00,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:01,116][root][INFO] - Training Epoch: 1/2, step 1143/7134 completed (loss: 1.5906060934066772, acc: 0.5507649779319763)
[2024-12-17 03:40:01,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:01,565][root][INFO] - Training Epoch: 1/2, step 1144/7134 completed (loss: 1.527529001235962, acc: 0.5712500214576721)
[2024-12-17 03:40:01,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:02,017][root][INFO] - Training Epoch: 1/2, step 1145/7134 completed (loss: 1.4673775434494019, acc: 0.5863309502601624)
[2024-12-17 03:40:02,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:02,433][root][INFO] - Training Epoch: 1/2, step 1146/7134 completed (loss: 1.4700278043746948, acc: 0.5724637508392334)
[2024-12-17 03:40:02,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:02,858][root][INFO] - Training Epoch: 1/2, step 1147/7134 completed (loss: 1.5071114301681519, acc: 0.5698254108428955)
[2024-12-17 03:40:02,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:03,292][root][INFO] - Training Epoch: 1/2, step 1148/7134 completed (loss: 1.5080585479736328, acc: 0.5546075105667114)
[2024-12-17 03:40:03,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:03,711][root][INFO] - Training Epoch: 1/2, step 1149/7134 completed (loss: 1.6581870317459106, acc: 0.5076923370361328)
[2024-12-17 03:40:03,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:04,166][root][INFO] - Training Epoch: 1/2, step 1150/7134 completed (loss: 1.5090949535369873, acc: 0.5503876209259033)
[2024-12-17 03:40:04,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:04,621][root][INFO] - Training Epoch: 1/2, step 1151/7134 completed (loss: 1.626544713973999, acc: 0.5273833870887756)
[2024-12-17 03:40:04,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:05,057][root][INFO] - Training Epoch: 1/2, step 1152/7134 completed (loss: 1.42339289188385, acc: 0.5692307949066162)
[2024-12-17 03:40:05,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:05,509][root][INFO] - Training Epoch: 1/2, step 1153/7134 completed (loss: 1.428397297859192, acc: 0.5749318599700928)
[2024-12-17 03:40:05,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:05,968][root][INFO] - Training Epoch: 1/2, step 1154/7134 completed (loss: 1.4067997932434082, acc: 0.5911504626274109)
[2024-12-17 03:40:06,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:06,428][root][INFO] - Training Epoch: 1/2, step 1155/7134 completed (loss: 1.6094741821289062, acc: 0.5504385828971863)
[2024-12-17 03:40:06,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:06,909][root][INFO] - Training Epoch: 1/2, step 1156/7134 completed (loss: 1.4407188892364502, acc: 0.5898617506027222)
[2024-12-17 03:40:07,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:07,364][root][INFO] - Training Epoch: 1/2, step 1157/7134 completed (loss: 1.516845464706421, acc: 0.5500848889350891)
[2024-12-17 03:40:07,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:07,797][root][INFO] - Training Epoch: 1/2, step 1158/7134 completed (loss: 1.4618604183197021, acc: 0.5838264226913452)
[2024-12-17 03:40:07,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:08,247][root][INFO] - Training Epoch: 1/2, step 1159/7134 completed (loss: 1.5986733436584473, acc: 0.5347517728805542)
[2024-12-17 03:40:08,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:08,741][root][INFO] - Training Epoch: 1/2, step 1160/7134 completed (loss: 1.407762050628662, acc: 0.6086309552192688)
[2024-12-17 03:40:08,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:09,181][root][INFO] - Training Epoch: 1/2, step 1161/7134 completed (loss: 1.400735855102539, acc: 0.6084828972816467)
[2024-12-17 03:40:09,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:09,612][root][INFO] - Training Epoch: 1/2, step 1162/7134 completed (loss: 1.5885229110717773, acc: 0.542148768901825)
[2024-12-17 03:40:09,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:10,034][root][INFO] - Training Epoch: 1/2, step 1163/7134 completed (loss: 1.5713090896606445, acc: 0.5273037552833557)
[2024-12-17 03:40:10,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:10,521][root][INFO] - Training Epoch: 1/2, step 1164/7134 completed (loss: 1.6375300884246826, acc: 0.5340750813484192)
[2024-12-17 03:40:10,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:10,995][root][INFO] - Training Epoch: 1/2, step 1165/7134 completed (loss: 1.5205800533294678, acc: 0.5522388219833374)
[2024-12-17 03:40:11,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:11,432][root][INFO] - Training Epoch: 1/2, step 1166/7134 completed (loss: 1.5272873640060425, acc: 0.5390946269035339)
[2024-12-17 03:40:11,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:11,860][root][INFO] - Training Epoch: 1/2, step 1167/7134 completed (loss: 1.5642790794372559, acc: 0.5363457798957825)
[2024-12-17 03:40:12,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:12,379][root][INFO] - Training Epoch: 1/2, step 1168/7134 completed (loss: 1.392577052116394, acc: 0.5815789699554443)
[2024-12-17 03:40:12,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:12,816][root][INFO] - Training Epoch: 1/2, step 1169/7134 completed (loss: 1.5045098066329956, acc: 0.5675675868988037)
[2024-12-17 03:40:12,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:13,268][root][INFO] - Training Epoch: 1/2, step 1170/7134 completed (loss: 1.6016939878463745, acc: 0.5393258333206177)
[2024-12-17 03:40:13,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:13,713][root][INFO] - Training Epoch: 1/2, step 1171/7134 completed (loss: 1.6099847555160522, acc: 0.542570948600769)
[2024-12-17 03:40:13,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:14,153][root][INFO] - Training Epoch: 1/2, step 1172/7134 completed (loss: 1.5632121562957764, acc: 0.5446293354034424)
[2024-12-17 03:40:14,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:14,582][root][INFO] - Training Epoch: 1/2, step 1173/7134 completed (loss: 1.425655484199524, acc: 0.5637680888175964)
[2024-12-17 03:40:14,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:15,041][root][INFO] - Training Epoch: 1/2, step 1174/7134 completed (loss: 1.3997187614440918, acc: 0.5960960984230042)
[2024-12-17 03:40:15,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:15,537][root][INFO] - Training Epoch: 1/2, step 1175/7134 completed (loss: 1.527350664138794, acc: 0.5565217137336731)
[2024-12-17 03:40:15,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:15,963][root][INFO] - Training Epoch: 1/2, step 1176/7134 completed (loss: 1.4828269481658936, acc: 0.573630154132843)
[2024-12-17 03:40:16,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:16,391][root][INFO] - Training Epoch: 1/2, step 1177/7134 completed (loss: 1.4849753379821777, acc: 0.5568627715110779)
[2024-12-17 03:40:16,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:16,835][root][INFO] - Training Epoch: 1/2, step 1178/7134 completed (loss: 1.4975976943969727, acc: 0.5467289686203003)
[2024-12-17 03:40:16,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:17,276][root][INFO] - Training Epoch: 1/2, step 1179/7134 completed (loss: 1.5316838026046753, acc: 0.5296367406845093)
[2024-12-17 03:40:17,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:17,766][root][INFO] - Training Epoch: 1/2, step 1180/7134 completed (loss: 1.4217777252197266, acc: 0.5638686418533325)
[2024-12-17 03:40:17,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:18,207][root][INFO] - Training Epoch: 1/2, step 1181/7134 completed (loss: 1.498401165008545, acc: 0.564028799533844)
[2024-12-17 03:40:18,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:18,632][root][INFO] - Training Epoch: 1/2, step 1182/7134 completed (loss: 1.4684743881225586, acc: 0.5760684013366699)
[2024-12-17 03:40:18,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:19,091][root][INFO] - Training Epoch: 1/2, step 1183/7134 completed (loss: 1.5833836793899536, acc: 0.5565345287322998)
[2024-12-17 03:40:19,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:19,536][root][INFO] - Training Epoch: 1/2, step 1184/7134 completed (loss: 1.4769395589828491, acc: 0.5608011484146118)
[2024-12-17 03:40:19,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:20,008][root][INFO] - Training Epoch: 1/2, step 1185/7134 completed (loss: 1.528625249862671, acc: 0.548872172832489)
[2024-12-17 03:40:20,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:20,442][root][INFO] - Training Epoch: 1/2, step 1186/7134 completed (loss: 1.4685131311416626, acc: 0.575875461101532)
[2024-12-17 03:40:20,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:20,925][root][INFO] - Training Epoch: 1/2, step 1187/7134 completed (loss: 1.4337663650512695, acc: 0.5858725905418396)
[2024-12-17 03:40:21,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:21,372][root][INFO] - Training Epoch: 1/2, step 1188/7134 completed (loss: 1.2941882610321045, acc: 0.6187335252761841)
[2024-12-17 03:40:21,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:21,818][root][INFO] - Training Epoch: 1/2, step 1189/7134 completed (loss: 1.350020170211792, acc: 0.6069363951683044)
[2024-12-17 03:40:21,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:22,264][root][INFO] - Training Epoch: 1/2, step 1190/7134 completed (loss: 1.6511420011520386, acc: 0.5216284990310669)
[2024-12-17 03:40:22,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:22,701][root][INFO] - Training Epoch: 1/2, step 1191/7134 completed (loss: 1.63420832157135, acc: 0.5199409127235413)
[2024-12-17 03:40:22,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:23,155][root][INFO] - Training Epoch: 1/2, step 1192/7134 completed (loss: 1.4383738040924072, acc: 0.5648754835128784)
[2024-12-17 03:40:23,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:23,598][root][INFO] - Training Epoch: 1/2, step 1193/7134 completed (loss: 1.503876805305481, acc: 0.5518341064453125)
[2024-12-17 03:40:23,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:24,025][root][INFO] - Training Epoch: 1/2, step 1194/7134 completed (loss: 1.438561201095581, acc: 0.5645604133605957)
[2024-12-17 03:40:24,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:24,460][root][INFO] - Training Epoch: 1/2, step 1195/7134 completed (loss: 1.5141583681106567, acc: 0.5800653696060181)
[2024-12-17 03:40:24,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:24,916][root][INFO] - Training Epoch: 1/2, step 1196/7134 completed (loss: 1.5287072658538818, acc: 0.55409836769104)
[2024-12-17 03:40:25,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:25,330][root][INFO] - Training Epoch: 1/2, step 1197/7134 completed (loss: 1.4986371994018555, acc: 0.5674486756324768)
[2024-12-17 03:40:25,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:25,761][root][INFO] - Training Epoch: 1/2, step 1198/7134 completed (loss: 1.4741733074188232, acc: 0.564028799533844)
[2024-12-17 03:40:25,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:26,280][root][INFO] - Training Epoch: 1/2, step 1199/7134 completed (loss: 1.5050225257873535, acc: 0.5596465468406677)
[2024-12-17 03:40:26,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:26,747][root][INFO] - Training Epoch: 1/2, step 1200/7134 completed (loss: 1.505695104598999, acc: 0.558521568775177)
[2024-12-17 03:40:26,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:27,218][root][INFO] - Training Epoch: 1/2, step 1201/7134 completed (loss: 1.556909441947937, acc: 0.5346097350120544)
[2024-12-17 03:40:27,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:27,695][root][INFO] - Training Epoch: 1/2, step 1202/7134 completed (loss: 1.6587369441986084, acc: 0.5047106146812439)
[2024-12-17 03:40:27,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:28,158][root][INFO] - Training Epoch: 1/2, step 1203/7134 completed (loss: 1.610803484916687, acc: 0.5204855799674988)
[2024-12-17 03:40:28,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:28,581][root][INFO] - Training Epoch: 1/2, step 1204/7134 completed (loss: 1.705277919769287, acc: 0.5298507213592529)
[2024-12-17 03:40:28,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:29,027][root][INFO] - Training Epoch: 1/2, step 1205/7134 completed (loss: 1.7551921606063843, acc: 0.4985915422439575)
[2024-12-17 03:40:29,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:29,480][root][INFO] - Training Epoch: 1/2, step 1206/7134 completed (loss: 1.604886531829834, acc: 0.5322580933570862)
[2024-12-17 03:40:29,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:29,959][root][INFO] - Training Epoch: 1/2, step 1207/7134 completed (loss: 1.7179609537124634, acc: 0.5075376629829407)
[2024-12-17 03:40:30,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:30,385][root][INFO] - Training Epoch: 1/2, step 1208/7134 completed (loss: 1.7580338716506958, acc: 0.48507463932037354)
[2024-12-17 03:40:30,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:30,819][root][INFO] - Training Epoch: 1/2, step 1209/7134 completed (loss: 1.7611503601074219, acc: 0.4972577691078186)
[2024-12-17 03:40:30,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:31,257][root][INFO] - Training Epoch: 1/2, step 1210/7134 completed (loss: 1.7908806800842285, acc: 0.49920254945755005)
[2024-12-17 03:40:31,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:31,703][root][INFO] - Training Epoch: 1/2, step 1211/7134 completed (loss: 1.8736337423324585, acc: 0.47398844361305237)
[2024-12-17 03:40:31,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:32,130][root][INFO] - Training Epoch: 1/2, step 1212/7134 completed (loss: 1.739788293838501, acc: 0.4984756112098694)
[2024-12-17 03:40:32,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:32,592][root][INFO] - Training Epoch: 1/2, step 1213/7134 completed (loss: 1.5339159965515137, acc: 0.5530410408973694)
[2024-12-17 03:40:32,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:33,033][root][INFO] - Training Epoch: 1/2, step 1214/7134 completed (loss: 1.6547590494155884, acc: 0.5138461589813232)
[2024-12-17 03:40:33,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:33,481][root][INFO] - Training Epoch: 1/2, step 1215/7134 completed (loss: 1.6971386671066284, acc: 0.5117241144180298)
[2024-12-17 03:40:33,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:33,929][root][INFO] - Training Epoch: 1/2, step 1216/7134 completed (loss: 1.664740800857544, acc: 0.4948905110359192)
[2024-12-17 03:40:34,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:34,404][root][INFO] - Training Epoch: 1/2, step 1217/7134 completed (loss: 1.6961328983306885, acc: 0.5081169009208679)
[2024-12-17 03:40:34,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:34,876][root][INFO] - Training Epoch: 1/2, step 1218/7134 completed (loss: 1.6072735786437988, acc: 0.5552238821983337)
[2024-12-17 03:40:35,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:35,359][root][INFO] - Training Epoch: 1/2, step 1219/7134 completed (loss: 1.6794451475143433, acc: 0.5219683647155762)
[2024-12-17 03:40:35,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:35,835][root][INFO] - Training Epoch: 1/2, step 1220/7134 completed (loss: 1.6144007444381714, acc: 0.5520304441452026)
[2024-12-17 03:40:35,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:36,352][root][INFO] - Training Epoch: 1/2, step 1221/7134 completed (loss: 1.548230528831482, acc: 0.5745614171028137)
[2024-12-17 03:40:36,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:36,809][root][INFO] - Training Epoch: 1/2, step 1222/7134 completed (loss: 1.5480821132659912, acc: 0.5494636297225952)
[2024-12-17 03:40:36,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:37,261][root][INFO] - Training Epoch: 1/2, step 1223/7134 completed (loss: 1.649023413658142, acc: 0.5363511443138123)
[2024-12-17 03:40:37,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:37,727][root][INFO] - Training Epoch: 1/2, step 1224/7134 completed (loss: 1.5107232332229614, acc: 0.5518763661384583)
[2024-12-17 03:40:37,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:38,198][root][INFO] - Training Epoch: 1/2, step 1225/7134 completed (loss: 1.5201449394226074, acc: 0.5686719417572021)
[2024-12-17 03:40:38,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:38,647][root][INFO] - Training Epoch: 1/2, step 1226/7134 completed (loss: 1.5550588369369507, acc: 0.5533199310302734)
[2024-12-17 03:40:38,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:39,091][root][INFO] - Training Epoch: 1/2, step 1227/7134 completed (loss: 1.5556782484054565, acc: 0.5603216886520386)
[2024-12-17 03:40:39,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:39,531][root][INFO] - Training Epoch: 1/2, step 1228/7134 completed (loss: 1.5906556844711304, acc: 0.5550786852836609)
[2024-12-17 03:40:39,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:39,987][root][INFO] - Training Epoch: 1/2, step 1229/7134 completed (loss: 1.509738802909851, acc: 0.5630252361297607)
[2024-12-17 03:40:40,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:40,467][root][INFO] - Training Epoch: 1/2, step 1230/7134 completed (loss: 1.5696722269058228, acc: 0.5423728823661804)
[2024-12-17 03:40:40,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:41,008][root][INFO] - Training Epoch: 1/2, step 1231/7134 completed (loss: 1.4970608949661255, acc: 0.5791106224060059)
[2024-12-17 03:40:41,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:41,509][root][INFO] - Training Epoch: 1/2, step 1232/7134 completed (loss: 1.4113352298736572, acc: 0.5995740294456482)
[2024-12-17 03:40:41,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:41,992][root][INFO] - Training Epoch: 1/2, step 1233/7134 completed (loss: 1.5324381589889526, acc: 0.5815029144287109)
[2024-12-17 03:40:42,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:42,495][root][INFO] - Training Epoch: 1/2, step 1234/7134 completed (loss: 1.5069936513900757, acc: 0.5714285969734192)
[2024-12-17 03:40:42,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:42,968][root][INFO] - Training Epoch: 1/2, step 1235/7134 completed (loss: 1.4550937414169312, acc: 0.5947242379188538)
[2024-12-17 03:40:43,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:43,428][root][INFO] - Training Epoch: 1/2, step 1236/7134 completed (loss: 1.502781867980957, acc: 0.5856515169143677)
[2024-12-17 03:40:43,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:43,884][root][INFO] - Training Epoch: 1/2, step 1237/7134 completed (loss: 1.5394566059112549, acc: 0.5341615080833435)
[2024-12-17 03:40:44,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:44,340][root][INFO] - Training Epoch: 1/2, step 1238/7134 completed (loss: 1.4265801906585693, acc: 0.5953420400619507)
[2024-12-17 03:40:44,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:44,834][root][INFO] - Training Epoch: 1/2, step 1239/7134 completed (loss: 1.5905835628509521, acc: 0.5422031283378601)
[2024-12-17 03:40:44,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:45,303][root][INFO] - Training Epoch: 1/2, step 1240/7134 completed (loss: 1.5146576166152954, acc: 0.5727513432502747)
[2024-12-17 03:40:45,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:45,719][root][INFO] - Training Epoch: 1/2, step 1241/7134 completed (loss: 1.511612057685852, acc: 0.5502008199691772)
[2024-12-17 03:40:45,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:46,197][root][INFO] - Training Epoch: 1/2, step 1242/7134 completed (loss: 1.4029717445373535, acc: 0.5853365659713745)
[2024-12-17 03:40:46,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:46,686][root][INFO] - Training Epoch: 1/2, step 1243/7134 completed (loss: 1.3900028467178345, acc: 0.6087865829467773)
[2024-12-17 03:40:46,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:47,144][root][INFO] - Training Epoch: 1/2, step 1244/7134 completed (loss: 1.5091238021850586, acc: 0.5761589407920837)
[2024-12-17 03:40:47,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:47,628][root][INFO] - Training Epoch: 1/2, step 1245/7134 completed (loss: 1.4271489381790161, acc: 0.5982367992401123)
[2024-12-17 03:40:47,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:48,052][root][INFO] - Training Epoch: 1/2, step 1246/7134 completed (loss: 1.5253033638000488, acc: 0.562259316444397)
[2024-12-17 03:40:48,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:48,522][root][INFO] - Training Epoch: 1/2, step 1247/7134 completed (loss: 1.364489197731018, acc: 0.6150506734848022)
[2024-12-17 03:40:48,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:48,952][root][INFO] - Training Epoch: 1/2, step 1248/7134 completed (loss: 1.6110790967941284, acc: 0.5537757277488708)
[2024-12-17 03:40:49,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:49,422][root][INFO] - Training Epoch: 1/2, step 1249/7134 completed (loss: 1.5212340354919434, acc: 0.5338078141212463)
[2024-12-17 03:40:49,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:49,878][root][INFO] - Training Epoch: 1/2, step 1250/7134 completed (loss: 1.4297065734863281, acc: 0.5722379684448242)
[2024-12-17 03:40:50,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:50,338][root][INFO] - Training Epoch: 1/2, step 1251/7134 completed (loss: 1.6222259998321533, acc: 0.547325074672699)
[2024-12-17 03:40:50,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:50,791][root][INFO] - Training Epoch: 1/2, step 1252/7134 completed (loss: 1.543652892112732, acc: 0.5447530746459961)
[2024-12-17 03:40:50,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:51,237][root][INFO] - Training Epoch: 1/2, step 1253/7134 completed (loss: 1.552610158920288, acc: 0.5656370520591736)
[2024-12-17 03:40:51,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:51,675][root][INFO] - Training Epoch: 1/2, step 1254/7134 completed (loss: 1.645385980606079, acc: 0.5318182110786438)
[2024-12-17 03:40:51,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:52,106][root][INFO] - Training Epoch: 1/2, step 1255/7134 completed (loss: 1.5499192476272583, acc: 0.5626822113990784)
[2024-12-17 03:40:52,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:52,515][root][INFO] - Training Epoch: 1/2, step 1256/7134 completed (loss: 1.5212736129760742, acc: 0.5787781476974487)
[2024-12-17 03:40:52,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:52,966][root][INFO] - Training Epoch: 1/2, step 1257/7134 completed (loss: 1.5291343927383423, acc: 0.5605815649032593)
[2024-12-17 03:40:53,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:53,400][root][INFO] - Training Epoch: 1/2, step 1258/7134 completed (loss: 1.615902066230774, acc: 0.5417276620864868)
[2024-12-17 03:40:53,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:53,845][root][INFO] - Training Epoch: 1/2, step 1259/7134 completed (loss: 1.503252387046814, acc: 0.557939887046814)
[2024-12-17 03:40:53,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:54,287][root][INFO] - Training Epoch: 1/2, step 1260/7134 completed (loss: 1.4748071432113647, acc: 0.5621387362480164)
[2024-12-17 03:40:54,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:54,803][root][INFO] - Training Epoch: 1/2, step 1261/7134 completed (loss: 1.5240594148635864, acc: 0.5474777221679688)
[2024-12-17 03:40:54,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:55,241][root][INFO] - Training Epoch: 1/2, step 1262/7134 completed (loss: 1.5494518280029297, acc: 0.5329670310020447)
[2024-12-17 03:40:55,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:55,662][root][INFO] - Training Epoch: 1/2, step 1263/7134 completed (loss: 1.4566103219985962, acc: 0.5514285564422607)
[2024-12-17 03:40:55,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:56,117][root][INFO] - Training Epoch: 1/2, step 1264/7134 completed (loss: 1.4382990598678589, acc: 0.585669755935669)
[2024-12-17 03:40:56,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:56,595][root][INFO] - Training Epoch: 1/2, step 1265/7134 completed (loss: 1.4536867141723633, acc: 0.5989974737167358)
[2024-12-17 03:40:56,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:57,038][root][INFO] - Training Epoch: 1/2, step 1266/7134 completed (loss: 1.3320485353469849, acc: 0.6041308045387268)
[2024-12-17 03:40:57,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:57,461][root][INFO] - Training Epoch: 1/2, step 1267/7134 completed (loss: 1.4208484888076782, acc: 0.5668965578079224)
[2024-12-17 03:40:57,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:57,912][root][INFO] - Training Epoch: 1/2, step 1268/7134 completed (loss: 1.538312554359436, acc: 0.5672082901000977)
[2024-12-17 03:40:58,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:58,373][root][INFO] - Training Epoch: 1/2, step 1269/7134 completed (loss: 1.5277177095413208, acc: 0.5620689392089844)
[2024-12-17 03:40:58,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:58,804][root][INFO] - Training Epoch: 1/2, step 1270/7134 completed (loss: 1.438222050666809, acc: 0.5704323649406433)
[2024-12-17 03:40:58,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:59,224][root][INFO] - Training Epoch: 1/2, step 1271/7134 completed (loss: 1.4659018516540527, acc: 0.5722222328186035)
[2024-12-17 03:40:59,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:40:59,735][root][INFO] - Training Epoch: 1/2, step 1272/7134 completed (loss: 1.3312222957611084, acc: 0.616908848285675)
[2024-12-17 03:40:59,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:00,163][root][INFO] - Training Epoch: 1/2, step 1273/7134 completed (loss: 1.4185675382614136, acc: 0.5838709473609924)
[2024-12-17 03:41:00,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:00,612][root][INFO] - Training Epoch: 1/2, step 1274/7134 completed (loss: 1.3564884662628174, acc: 0.5979729890823364)
[2024-12-17 03:41:00,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:01,038][root][INFO] - Training Epoch: 1/2, step 1275/7134 completed (loss: 1.43373703956604, acc: 0.5816876292228699)
[2024-12-17 03:41:01,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:01,454][root][INFO] - Training Epoch: 1/2, step 1276/7134 completed (loss: 1.333953619003296, acc: 0.6129032373428345)
[2024-12-17 03:41:01,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:01,879][root][INFO] - Training Epoch: 1/2, step 1277/7134 completed (loss: 1.4051648378372192, acc: 0.5864297151565552)
[2024-12-17 03:41:02,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:02,356][root][INFO] - Training Epoch: 1/2, step 1278/7134 completed (loss: 1.6588510274887085, acc: 0.5272161960601807)
[2024-12-17 03:41:02,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:02,815][root][INFO] - Training Epoch: 1/2, step 1279/7134 completed (loss: 1.5541621446609497, acc: 0.5248138904571533)
[2024-12-17 03:41:02,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:03,236][root][INFO] - Training Epoch: 1/2, step 1280/7134 completed (loss: 1.6340335607528687, acc: 0.5308803915977478)
[2024-12-17 03:41:03,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:03,655][root][INFO] - Training Epoch: 1/2, step 1281/7134 completed (loss: 1.673255443572998, acc: 0.5318416357040405)
[2024-12-17 03:41:03,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:04,108][root][INFO] - Training Epoch: 1/2, step 1282/7134 completed (loss: 1.6901168823242188, acc: 0.5213903784751892)
[2024-12-17 03:41:04,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:04,572][root][INFO] - Training Epoch: 1/2, step 1283/7134 completed (loss: 1.5751460790634155, acc: 0.533450722694397)
[2024-12-17 03:41:04,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:05,014][root][INFO] - Training Epoch: 1/2, step 1284/7134 completed (loss: 1.6019278764724731, acc: 0.5354223251342773)
[2024-12-17 03:41:05,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:05,450][root][INFO] - Training Epoch: 1/2, step 1285/7134 completed (loss: 1.5521976947784424, acc: 0.5569985508918762)
[2024-12-17 03:41:05,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:05,927][root][INFO] - Training Epoch: 1/2, step 1286/7134 completed (loss: 1.5107603073120117, acc: 0.5507868528366089)
[2024-12-17 03:41:06,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:06,356][root][INFO] - Training Epoch: 1/2, step 1287/7134 completed (loss: 1.5775853395462036, acc: 0.5598006844520569)
[2024-12-17 03:41:06,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:06,791][root][INFO] - Training Epoch: 1/2, step 1288/7134 completed (loss: 1.5347071886062622, acc: 0.5418781638145447)
[2024-12-17 03:41:06,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:07,209][root][INFO] - Training Epoch: 1/2, step 1289/7134 completed (loss: 1.6603310108184814, acc: 0.5209380388259888)
[2024-12-17 03:41:07,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:07,655][root][INFO] - Training Epoch: 1/2, step 1290/7134 completed (loss: 1.4674310684204102, acc: 0.5929577350616455)
[2024-12-17 03:41:07,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:08,143][root][INFO] - Training Epoch: 1/2, step 1291/7134 completed (loss: 1.5471950769424438, acc: 0.5509065389633179)
[2024-12-17 03:41:08,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:08,587][root][INFO] - Training Epoch: 1/2, step 1292/7134 completed (loss: 1.6531741619110107, acc: 0.5116882920265198)
[2024-12-17 03:41:08,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:09,046][root][INFO] - Training Epoch: 1/2, step 1293/7134 completed (loss: 1.5331127643585205, acc: 0.5669382810592651)
[2024-12-17 03:41:09,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:09,510][root][INFO] - Training Epoch: 1/2, step 1294/7134 completed (loss: 1.5724354982376099, acc: 0.5253576040267944)
[2024-12-17 03:41:09,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:09,971][root][INFO] - Training Epoch: 1/2, step 1295/7134 completed (loss: 1.5451624393463135, acc: 0.5195246338844299)
[2024-12-17 03:41:10,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:10,403][root][INFO] - Training Epoch: 1/2, step 1296/7134 completed (loss: 1.5043522119522095, acc: 0.5486725568771362)
[2024-12-17 03:41:10,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:10,861][root][INFO] - Training Epoch: 1/2, step 1297/7134 completed (loss: 1.5896477699279785, acc: 0.5717255473136902)
[2024-12-17 03:41:10,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:11,294][root][INFO] - Training Epoch: 1/2, step 1298/7134 completed (loss: 1.5542882680892944, acc: 0.528777003288269)
[2024-12-17 03:41:11,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:11,722][root][INFO] - Training Epoch: 1/2, step 1299/7134 completed (loss: 1.6374300718307495, acc: 0.5130208134651184)
[2024-12-17 03:41:11,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:12,233][root][INFO] - Training Epoch: 1/2, step 1300/7134 completed (loss: 1.5714424848556519, acc: 0.5529841780662537)
[2024-12-17 03:41:12,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:12,657][root][INFO] - Training Epoch: 1/2, step 1301/7134 completed (loss: 1.4179829359054565, acc: 0.5979228615760803)
[2024-12-17 03:41:12,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:13,115][root][INFO] - Training Epoch: 1/2, step 1302/7134 completed (loss: 1.4391839504241943, acc: 0.5870535969734192)
[2024-12-17 03:41:13,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:13,581][root][INFO] - Training Epoch: 1/2, step 1303/7134 completed (loss: 1.4130630493164062, acc: 0.59375)
[2024-12-17 03:41:13,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:14,012][root][INFO] - Training Epoch: 1/2, step 1304/7134 completed (loss: 1.5061657428741455, acc: 0.5691699385643005)
[2024-12-17 03:41:14,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:14,477][root][INFO] - Training Epoch: 1/2, step 1305/7134 completed (loss: 1.6168746948242188, acc: 0.5126903653144836)
[2024-12-17 03:41:14,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:14,989][root][INFO] - Training Epoch: 1/2, step 1306/7134 completed (loss: 1.5072569847106934, acc: 0.5857359766960144)
[2024-12-17 03:41:15,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:15,405][root][INFO] - Training Epoch: 1/2, step 1307/7134 completed (loss: 1.5864231586456299, acc: 0.548183262348175)
[2024-12-17 03:41:15,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:15,849][root][INFO] - Training Epoch: 1/2, step 1308/7134 completed (loss: 1.5259723663330078, acc: 0.553383469581604)
[2024-12-17 03:41:15,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:16,320][root][INFO] - Training Epoch: 1/2, step 1309/7134 completed (loss: 1.5741831064224243, acc: 0.5430622100830078)
[2024-12-17 03:41:16,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:16,795][root][INFO] - Training Epoch: 1/2, step 1310/7134 completed (loss: 1.6860443353652954, acc: 0.4911564588546753)
[2024-12-17 03:41:16,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:17,240][root][INFO] - Training Epoch: 1/2, step 1311/7134 completed (loss: 1.5110740661621094, acc: 0.5361990928649902)
[2024-12-17 03:41:17,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:17,706][root][INFO] - Training Epoch: 1/2, step 1312/7134 completed (loss: 1.5683780908584595, acc: 0.5592991709709167)
[2024-12-17 03:41:17,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:18,165][root][INFO] - Training Epoch: 1/2, step 1313/7134 completed (loss: 1.5404245853424072, acc: 0.5538243651390076)
[2024-12-17 03:41:18,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:18,589][root][INFO] - Training Epoch: 1/2, step 1314/7134 completed (loss: 1.5483036041259766, acc: 0.5421052575111389)
[2024-12-17 03:41:18,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:19,020][root][INFO] - Training Epoch: 1/2, step 1315/7134 completed (loss: 1.6375033855438232, acc: 0.5360000133514404)
[2024-12-17 03:41:19,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:19,468][root][INFO] - Training Epoch: 1/2, step 1316/7134 completed (loss: 1.4715781211853027, acc: 0.5838041305541992)
[2024-12-17 03:41:19,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:19,868][root][INFO] - Training Epoch: 1/2, step 1317/7134 completed (loss: 1.6318789720535278, acc: 0.5406504273414612)
[2024-12-17 03:41:19,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:20,353][root][INFO] - Training Epoch: 1/2, step 1318/7134 completed (loss: 1.546488881111145, acc: 0.5585830807685852)
[2024-12-17 03:41:20,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:20,786][root][INFO] - Training Epoch: 1/2, step 1319/7134 completed (loss: 1.5620197057724, acc: 0.5606407523155212)
[2024-12-17 03:41:20,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:21,225][root][INFO] - Training Epoch: 1/2, step 1320/7134 completed (loss: 1.5655690431594849, acc: 0.5521172881126404)
[2024-12-17 03:41:21,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:21,882][root][INFO] - Training Epoch: 1/2, step 1321/7134 completed (loss: 1.5426018238067627, acc: 0.563725471496582)
[2024-12-17 03:41:21,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:22,326][root][INFO] - Training Epoch: 1/2, step 1322/7134 completed (loss: 1.6415233612060547, acc: 0.5499181747436523)
[2024-12-17 03:41:22,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:22,788][root][INFO] - Training Epoch: 1/2, step 1323/7134 completed (loss: 1.5142287015914917, acc: 0.5535714030265808)
[2024-12-17 03:41:22,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:23,257][root][INFO] - Training Epoch: 1/2, step 1324/7134 completed (loss: 1.4604551792144775, acc: 0.5888158082962036)
[2024-12-17 03:41:23,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:23,683][root][INFO] - Training Epoch: 1/2, step 1325/7134 completed (loss: 1.655460238456726, acc: 0.5147392153739929)
[2024-12-17 03:41:23,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:24,151][root][INFO] - Training Epoch: 1/2, step 1326/7134 completed (loss: 1.4995815753936768, acc: 0.5499451160430908)
[2024-12-17 03:41:24,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:24,627][root][INFO] - Training Epoch: 1/2, step 1327/7134 completed (loss: 1.5506882667541504, acc: 0.5547226667404175)
[2024-12-17 03:41:24,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:25,085][root][INFO] - Training Epoch: 1/2, step 1328/7134 completed (loss: 1.5472346544265747, acc: 0.5488371849060059)
[2024-12-17 03:41:25,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:25,535][root][INFO] - Training Epoch: 1/2, step 1329/7134 completed (loss: 1.682305932044983, acc: 0.530386745929718)
[2024-12-17 03:41:25,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:25,923][root][INFO] - Training Epoch: 1/2, step 1330/7134 completed (loss: 1.4604969024658203, acc: 0.5711835622787476)
[2024-12-17 03:41:26,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:26,389][root][INFO] - Training Epoch: 1/2, step 1331/7134 completed (loss: 1.4788942337036133, acc: 0.5814332365989685)
[2024-12-17 03:41:26,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:26,768][root][INFO] - Training Epoch: 1/2, step 1332/7134 completed (loss: 1.4508939981460571, acc: 0.5917030572891235)
[2024-12-17 03:41:26,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:27,236][root][INFO] - Training Epoch: 1/2, step 1333/7134 completed (loss: 1.506008505821228, acc: 0.5595238208770752)
[2024-12-17 03:41:27,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:27,696][root][INFO] - Training Epoch: 1/2, step 1334/7134 completed (loss: 1.5400865077972412, acc: 0.5714285969734192)
[2024-12-17 03:41:27,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:28,109][root][INFO] - Training Epoch: 1/2, step 1335/7134 completed (loss: 1.510046124458313, acc: 0.5459387302398682)
[2024-12-17 03:41:28,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:28,554][root][INFO] - Training Epoch: 1/2, step 1336/7134 completed (loss: 1.463334083557129, acc: 0.565629243850708)
[2024-12-17 03:41:28,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:29,070][root][INFO] - Training Epoch: 1/2, step 1337/7134 completed (loss: 1.5343513488769531, acc: 0.546012282371521)
[2024-12-17 03:41:29,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:29,519][root][INFO] - Training Epoch: 1/2, step 1338/7134 completed (loss: 1.6004722118377686, acc: 0.5582329034805298)
[2024-12-17 03:41:29,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:29,973][root][INFO] - Training Epoch: 1/2, step 1339/7134 completed (loss: 1.6579033136367798, acc: 0.5280898809432983)
[2024-12-17 03:41:30,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:30,404][root][INFO] - Training Epoch: 1/2, step 1340/7134 completed (loss: 1.6447583436965942, acc: 0.5394933223724365)
[2024-12-17 03:41:30,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:30,822][root][INFO] - Training Epoch: 1/2, step 1341/7134 completed (loss: 1.4310507774353027, acc: 0.5564971566200256)
[2024-12-17 03:41:30,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:31,295][root][INFO] - Training Epoch: 1/2, step 1342/7134 completed (loss: 1.4055436849594116, acc: 0.5990338325500488)
[2024-12-17 03:41:31,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:31,763][root][INFO] - Training Epoch: 1/2, step 1343/7134 completed (loss: 1.734907627105713, acc: 0.5044722557067871)
[2024-12-17 03:41:31,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:32,178][root][INFO] - Training Epoch: 1/2, step 1344/7134 completed (loss: 1.5336265563964844, acc: 0.5271493196487427)
[2024-12-17 03:41:32,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:32,608][root][INFO] - Training Epoch: 1/2, step 1345/7134 completed (loss: 1.5732675790786743, acc: 0.5596817135810852)
[2024-12-17 03:41:32,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:33,120][root][INFO] - Training Epoch: 1/2, step 1346/7134 completed (loss: 1.5987216234207153, acc: 0.5260347127914429)
[2024-12-17 03:41:33,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:33,558][root][INFO] - Training Epoch: 1/2, step 1347/7134 completed (loss: 1.6857435703277588, acc: 0.4912891983985901)
[2024-12-17 03:41:33,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:34,026][root][INFO] - Training Epoch: 1/2, step 1348/7134 completed (loss: 1.544076681137085, acc: 0.547837495803833)
[2024-12-17 03:41:34,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:34,466][root][INFO] - Training Epoch: 1/2, step 1349/7134 completed (loss: 1.4615718126296997, acc: 0.5777778029441833)
[2024-12-17 03:41:34,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:34,890][root][INFO] - Training Epoch: 1/2, step 1350/7134 completed (loss: 1.4778547286987305, acc: 0.5615050792694092)
[2024-12-17 03:41:35,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:35,309][root][INFO] - Training Epoch: 1/2, step 1351/7134 completed (loss: 1.4401658773422241, acc: 0.5933202505111694)
[2024-12-17 03:41:35,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:35,744][root][INFO] - Training Epoch: 1/2, step 1352/7134 completed (loss: 1.4612113237380981, acc: 0.5535714030265808)
[2024-12-17 03:41:35,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:36,211][root][INFO] - Training Epoch: 1/2, step 1353/7134 completed (loss: 1.4136745929718018, acc: 0.5555555820465088)
[2024-12-17 03:41:36,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:36,658][root][INFO] - Training Epoch: 1/2, step 1354/7134 completed (loss: 1.4415254592895508, acc: 0.601296603679657)
[2024-12-17 03:41:36,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:37,094][root][INFO] - Training Epoch: 1/2, step 1355/7134 completed (loss: 1.4084892272949219, acc: 0.5747663378715515)
[2024-12-17 03:41:37,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:37,552][root][INFO] - Training Epoch: 1/2, step 1356/7134 completed (loss: 1.3880375623703003, acc: 0.5842105150222778)
[2024-12-17 03:41:37,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:38,004][root][INFO] - Training Epoch: 1/2, step 1357/7134 completed (loss: 1.4703549146652222, acc: 0.5472887754440308)
[2024-12-17 03:41:38,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:38,497][root][INFO] - Training Epoch: 1/2, step 1358/7134 completed (loss: 1.38313889503479, acc: 0.5727272629737854)
[2024-12-17 03:41:38,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:38,925][root][INFO] - Training Epoch: 1/2, step 1359/7134 completed (loss: 1.299275279045105, acc: 0.5951417088508606)
[2024-12-17 03:41:39,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:39,356][root][INFO] - Training Epoch: 1/2, step 1360/7134 completed (loss: 1.4416468143463135, acc: 0.5591397881507874)
[2024-12-17 03:41:39,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:39,843][root][INFO] - Training Epoch: 1/2, step 1361/7134 completed (loss: 1.3650175333023071, acc: 0.5970802903175354)
[2024-12-17 03:41:39,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:40,277][root][INFO] - Training Epoch: 1/2, step 1362/7134 completed (loss: 1.4003466367721558, acc: 0.5915300250053406)
[2024-12-17 03:41:40,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:40,782][root][INFO] - Training Epoch: 1/2, step 1363/7134 completed (loss: 1.4622724056243896, acc: 0.5817694664001465)
[2024-12-17 03:41:40,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:41,234][root][INFO] - Training Epoch: 1/2, step 1364/7134 completed (loss: 1.3854962587356567, acc: 0.5685714483261108)
[2024-12-17 03:41:41,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:41,667][root][INFO] - Training Epoch: 1/2, step 1365/7134 completed (loss: 1.2667827606201172, acc: 0.6300366520881653)
[2024-12-17 03:41:41,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:42,137][root][INFO] - Training Epoch: 1/2, step 1366/7134 completed (loss: 1.3777108192443848, acc: 0.5928571224212646)
[2024-12-17 03:41:42,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:42,560][root][INFO] - Training Epoch: 1/2, step 1367/7134 completed (loss: 1.374112606048584, acc: 0.5827586054801941)
[2024-12-17 03:41:42,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:43,027][root][INFO] - Training Epoch: 1/2, step 1368/7134 completed (loss: 1.4882954359054565, acc: 0.5731707215309143)
[2024-12-17 03:41:43,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:43,452][root][INFO] - Training Epoch: 1/2, step 1369/7134 completed (loss: 1.4768409729003906, acc: 0.5656742453575134)
[2024-12-17 03:41:43,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:43,892][root][INFO] - Training Epoch: 1/2, step 1370/7134 completed (loss: 1.4649379253387451, acc: 0.5739570260047913)
[2024-12-17 03:41:43,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:44,343][root][INFO] - Training Epoch: 1/2, step 1371/7134 completed (loss: 1.4405356645584106, acc: 0.5720524191856384)
[2024-12-17 03:41:44,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:44,771][root][INFO] - Training Epoch: 1/2, step 1372/7134 completed (loss: 1.6456385850906372, acc: 0.5393258333206177)
[2024-12-17 03:41:44,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:45,227][root][INFO] - Training Epoch: 1/2, step 1373/7134 completed (loss: 1.5083098411560059, acc: 0.5649606585502625)
[2024-12-17 03:41:45,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:45,681][root][INFO] - Training Epoch: 1/2, step 1374/7134 completed (loss: 1.6453865766525269, acc: 0.5504950284957886)
[2024-12-17 03:41:45,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:46,100][root][INFO] - Training Epoch: 1/2, step 1375/7134 completed (loss: 1.3752022981643677, acc: 0.588942289352417)
[2024-12-17 03:41:46,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:46,533][root][INFO] - Training Epoch: 1/2, step 1376/7134 completed (loss: 1.6744906902313232, acc: 0.5281836986541748)
[2024-12-17 03:41:46,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:46,973][root][INFO] - Training Epoch: 1/2, step 1377/7134 completed (loss: 1.6581791639328003, acc: 0.5317646861076355)
[2024-12-17 03:41:47,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:47,379][root][INFO] - Training Epoch: 1/2, step 1378/7134 completed (loss: 1.67661714553833, acc: 0.5204678177833557)
[2024-12-17 03:41:47,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:47,817][root][INFO] - Training Epoch: 1/2, step 1379/7134 completed (loss: 1.616346001625061, acc: 0.5419355034828186)
[2024-12-17 03:41:47,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:48,288][root][INFO] - Training Epoch: 1/2, step 1380/7134 completed (loss: 1.673242449760437, acc: 0.5158878564834595)
[2024-12-17 03:41:48,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:48,751][root][INFO] - Training Epoch: 1/2, step 1381/7134 completed (loss: 1.4603878259658813, acc: 0.5704809427261353)
[2024-12-17 03:41:48,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:49,170][root][INFO] - Training Epoch: 1/2, step 1382/7134 completed (loss: 1.5800881385803223, acc: 0.5444444417953491)
[2024-12-17 03:41:49,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:49,613][root][INFO] - Training Epoch: 1/2, step 1383/7134 completed (loss: 1.614490270614624, acc: 0.5215146541595459)
[2024-12-17 03:41:49,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:50,050][root][INFO] - Training Epoch: 1/2, step 1384/7134 completed (loss: 1.682588815689087, acc: 0.5274542570114136)
[2024-12-17 03:41:50,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:50,476][root][INFO] - Training Epoch: 1/2, step 1385/7134 completed (loss: 1.6473767757415771, acc: 0.5229358077049255)
[2024-12-17 03:41:50,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:50,913][root][INFO] - Training Epoch: 1/2, step 1386/7134 completed (loss: 1.4437226057052612, acc: 0.5884955525398254)
[2024-12-17 03:41:51,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:51,342][root][INFO] - Training Epoch: 1/2, step 1387/7134 completed (loss: 1.5111620426177979, acc: 0.5558739304542542)
[2024-12-17 03:41:51,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:51,753][root][INFO] - Training Epoch: 1/2, step 1388/7134 completed (loss: 1.5236636400222778, acc: 0.5604770183563232)
[2024-12-17 03:41:51,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:52,188][root][INFO] - Training Epoch: 1/2, step 1389/7134 completed (loss: 1.5982590913772583, acc: 0.5445705056190491)
[2024-12-17 03:41:52,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:52,630][root][INFO] - Training Epoch: 1/2, step 1390/7134 completed (loss: 1.513267159461975, acc: 0.5522620677947998)
[2024-12-17 03:41:52,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:53,070][root][INFO] - Training Epoch: 1/2, step 1391/7134 completed (loss: 1.612104892730713, acc: 0.5342706441879272)
[2024-12-17 03:41:53,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:53,497][root][INFO] - Training Epoch: 1/2, step 1392/7134 completed (loss: 1.6052931547164917, acc: 0.5346021056175232)
[2024-12-17 03:41:53,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:53,908][root][INFO] - Training Epoch: 1/2, step 1393/7134 completed (loss: 1.4842164516448975, acc: 0.5898617506027222)
[2024-12-17 03:41:54,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:54,342][root][INFO] - Training Epoch: 1/2, step 1394/7134 completed (loss: 1.5308586359024048, acc: 0.579365074634552)
[2024-12-17 03:41:54,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:54,760][root][INFO] - Training Epoch: 1/2, step 1395/7134 completed (loss: 1.5719718933105469, acc: 0.5483234524726868)
[2024-12-17 03:41:54,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:55,170][root][INFO] - Training Epoch: 1/2, step 1396/7134 completed (loss: 1.370168924331665, acc: 0.6097972989082336)
[2024-12-17 03:41:55,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:55,592][root][INFO] - Training Epoch: 1/2, step 1397/7134 completed (loss: 1.5114870071411133, acc: 0.5733557939529419)
[2024-12-17 03:41:55,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:56,000][root][INFO] - Training Epoch: 1/2, step 1398/7134 completed (loss: 1.4483674764633179, acc: 0.5821501016616821)
[2024-12-17 03:41:56,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:56,438][root][INFO] - Training Epoch: 1/2, step 1399/7134 completed (loss: 1.6251599788665771, acc: 0.5199275612831116)
[2024-12-17 03:41:56,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:56,880][root][INFO] - Training Epoch: 1/2, step 1400/7134 completed (loss: 1.6309291124343872, acc: 0.5392670035362244)
[2024-12-17 03:41:57,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:57,325][root][INFO] - Training Epoch: 1/2, step 1401/7134 completed (loss: 1.5615304708480835, acc: 0.5337726473808289)
[2024-12-17 03:41:57,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:57,731][root][INFO] - Training Epoch: 1/2, step 1402/7134 completed (loss: 1.4582759141921997, acc: 0.5699481964111328)
[2024-12-17 03:41:57,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:58,176][root][INFO] - Training Epoch: 1/2, step 1403/7134 completed (loss: 1.446586012840271, acc: 0.5555555820465088)
[2024-12-17 03:41:58,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:58,642][root][INFO] - Training Epoch: 1/2, step 1404/7134 completed (loss: 1.5177136659622192, acc: 0.5623342394828796)
[2024-12-17 03:41:58,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:59,122][root][INFO] - Training Epoch: 1/2, step 1405/7134 completed (loss: 1.5049657821655273, acc: 0.5484330654144287)
[2024-12-17 03:41:59,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:41:59,600][root][INFO] - Training Epoch: 1/2, step 1406/7134 completed (loss: 1.5070265531539917, acc: 0.5646551847457886)
[2024-12-17 03:41:59,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:00,031][root][INFO] - Training Epoch: 1/2, step 1407/7134 completed (loss: 1.3656128644943237, acc: 0.5958278775215149)
[2024-12-17 03:42:00,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:00,467][root][INFO] - Training Epoch: 1/2, step 1408/7134 completed (loss: 1.385120153427124, acc: 0.5977563858032227)
[2024-12-17 03:42:00,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:00,903][root][INFO] - Training Epoch: 1/2, step 1409/7134 completed (loss: 1.3821769952774048, acc: 0.6050670742988586)
[2024-12-17 03:42:01,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:01,360][root][INFO] - Training Epoch: 1/2, step 1410/7134 completed (loss: 1.439353585243225, acc: 0.5729166865348816)
[2024-12-17 03:42:01,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:01,807][root][INFO] - Training Epoch: 1/2, step 1411/7134 completed (loss: 1.4052244424819946, acc: 0.5744680762290955)
[2024-12-17 03:42:01,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:02,327][root][INFO] - Training Epoch: 1/2, step 1412/7134 completed (loss: 1.3900396823883057, acc: 0.599762499332428)
[2024-12-17 03:42:02,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:02,782][root][INFO] - Training Epoch: 1/2, step 1413/7134 completed (loss: 1.427011489868164, acc: 0.5928057432174683)
[2024-12-17 03:42:02,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:03,215][root][INFO] - Training Epoch: 1/2, step 1414/7134 completed (loss: 1.4090492725372314, acc: 0.6074766516685486)
[2024-12-17 03:42:03,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:03,667][root][INFO] - Training Epoch: 1/2, step 1415/7134 completed (loss: 1.3651857376098633, acc: 0.6241722106933594)
[2024-12-17 03:42:03,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:04,140][root][INFO] - Training Epoch: 1/2, step 1416/7134 completed (loss: 1.4070813655853271, acc: 0.5898876190185547)
[2024-12-17 03:42:04,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:04,570][root][INFO] - Training Epoch: 1/2, step 1417/7134 completed (loss: 1.3638150691986084, acc: 0.6105442047119141)
[2024-12-17 03:42:04,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:04,983][root][INFO] - Training Epoch: 1/2, step 1418/7134 completed (loss: 1.445959210395813, acc: 0.6068702340126038)
[2024-12-17 03:42:05,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:05,456][root][INFO] - Training Epoch: 1/2, step 1419/7134 completed (loss: 1.4371869564056396, acc: 0.5681511759757996)
[2024-12-17 03:42:05,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:05,892][root][INFO] - Training Epoch: 1/2, step 1420/7134 completed (loss: 1.4164873361587524, acc: 0.5835579633712769)
[2024-12-17 03:42:05,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:06,327][root][INFO] - Training Epoch: 1/2, step 1421/7134 completed (loss: 1.3792259693145752, acc: 0.5945512652397156)
[2024-12-17 03:42:06,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:06,796][root][INFO] - Training Epoch: 1/2, step 1422/7134 completed (loss: 1.4678033590316772, acc: 0.5698005557060242)
[2024-12-17 03:42:06,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:07,270][root][INFO] - Training Epoch: 1/2, step 1423/7134 completed (loss: 1.6880415678024292, acc: 0.5367347002029419)
[2024-12-17 03:42:07,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:07,706][root][INFO] - Training Epoch: 1/2, step 1424/7134 completed (loss: 1.5861562490463257, acc: 0.5551331043243408)
[2024-12-17 03:42:07,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:08,147][root][INFO] - Training Epoch: 1/2, step 1425/7134 completed (loss: 1.7064467668533325, acc: 0.497764527797699)
[2024-12-17 03:42:08,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:08,661][root][INFO] - Training Epoch: 1/2, step 1426/7134 completed (loss: 1.4972364902496338, acc: 0.5732647776603699)
[2024-12-17 03:42:08,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:09,134][root][INFO] - Training Epoch: 1/2, step 1427/7134 completed (loss: 1.6574475765228271, acc: 0.5300127863883972)
[2024-12-17 03:42:09,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:09,578][root][INFO] - Training Epoch: 1/2, step 1428/7134 completed (loss: 2.1360716819763184, acc: 0.42296072840690613)
[2024-12-17 03:42:09,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:10,026][root][INFO] - Training Epoch: 1/2, step 1429/7134 completed (loss: 1.4683836698532104, acc: 0.5738045573234558)
[2024-12-17 03:42:10,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:10,515][root][INFO] - Training Epoch: 1/2, step 1430/7134 completed (loss: 1.5218645334243774, acc: 0.5682656764984131)
[2024-12-17 03:42:10,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:10,976][root][INFO] - Training Epoch: 1/2, step 1431/7134 completed (loss: 1.5835423469543457, acc: 0.5468114018440247)
[2024-12-17 03:42:11,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:11,431][root][INFO] - Training Epoch: 1/2, step 1432/7134 completed (loss: 1.4427767992019653, acc: 0.5842986106872559)
[2024-12-17 03:42:11,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:11,895][root][INFO] - Training Epoch: 1/2, step 1433/7134 completed (loss: 1.5014591217041016, acc: 0.5484293103218079)
[2024-12-17 03:42:12,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:12,336][root][INFO] - Training Epoch: 1/2, step 1434/7134 completed (loss: 1.5134388208389282, acc: 0.5515394806861877)
[2024-12-17 03:42:12,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:12,807][root][INFO] - Training Epoch: 1/2, step 1435/7134 completed (loss: 1.6348744630813599, acc: 0.5425220131874084)
[2024-12-17 03:42:12,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:13,261][root][INFO] - Training Epoch: 1/2, step 1436/7134 completed (loss: 1.5206091403961182, acc: 0.539340078830719)
[2024-12-17 03:42:13,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:13,688][root][INFO] - Training Epoch: 1/2, step 1437/7134 completed (loss: 1.4560730457305908, acc: 0.5654596090316772)
[2024-12-17 03:42:13,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:14,158][root][INFO] - Training Epoch: 1/2, step 1438/7134 completed (loss: 1.5636260509490967, acc: 0.5474452376365662)
[2024-12-17 03:42:14,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:14,626][root][INFO] - Training Epoch: 1/2, step 1439/7134 completed (loss: 1.4264622926712036, acc: 0.5899814367294312)
[2024-12-17 03:42:14,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:15,076][root][INFO] - Training Epoch: 1/2, step 1440/7134 completed (loss: 1.5659294128417969, acc: 0.5559380650520325)
[2024-12-17 03:42:15,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:15,531][root][INFO] - Training Epoch: 1/2, step 1441/7134 completed (loss: 1.5223684310913086, acc: 0.5615835785865784)
[2024-12-17 03:42:15,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:15,935][root][INFO] - Training Epoch: 1/2, step 1442/7134 completed (loss: 1.4468947649002075, acc: 0.5669856667518616)
[2024-12-17 03:42:16,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:16,376][root][INFO] - Training Epoch: 1/2, step 1443/7134 completed (loss: 1.4314147233963013, acc: 0.5606327056884766)
[2024-12-17 03:42:16,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:16,824][root][INFO] - Training Epoch: 1/2, step 1444/7134 completed (loss: 1.5480934381484985, acc: 0.5466926097869873)
[2024-12-17 03:42:16,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:17,279][root][INFO] - Training Epoch: 1/2, step 1445/7134 completed (loss: 1.3954600095748901, acc: 0.5873544216156006)
[2024-12-17 03:42:17,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:17,706][root][INFO] - Training Epoch: 1/2, step 1446/7134 completed (loss: 1.509401798248291, acc: 0.5490753650665283)
[2024-12-17 03:42:17,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:18,145][root][INFO] - Training Epoch: 1/2, step 1447/7134 completed (loss: 1.4330981969833374, acc: 0.5858156085014343)
[2024-12-17 03:42:18,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:18,539][root][INFO] - Training Epoch: 1/2, step 1448/7134 completed (loss: 1.8566336631774902, acc: 0.4555084705352783)
[2024-12-17 03:42:18,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:18,989][root][INFO] - Training Epoch: 1/2, step 1449/7134 completed (loss: 1.7265770435333252, acc: 0.5084269642829895)
[2024-12-17 03:42:19,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:19,415][root][INFO] - Training Epoch: 1/2, step 1450/7134 completed (loss: 1.4641432762145996, acc: 0.5573294758796692)
[2024-12-17 03:42:19,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:19,847][root][INFO] - Training Epoch: 1/2, step 1451/7134 completed (loss: 1.4250495433807373, acc: 0.5959004163742065)
[2024-12-17 03:42:20,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:20,293][root][INFO] - Training Epoch: 1/2, step 1452/7134 completed (loss: 1.4836030006408691, acc: 0.578125)
[2024-12-17 03:42:20,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:20,729][root][INFO] - Training Epoch: 1/2, step 1453/7134 completed (loss: 1.4587624073028564, acc: 0.5752773284912109)
[2024-12-17 03:42:20,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:21,202][root][INFO] - Training Epoch: 1/2, step 1454/7134 completed (loss: 1.5669479370117188, acc: 0.5275908708572388)
[2024-12-17 03:42:21,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:21,653][root][INFO] - Training Epoch: 1/2, step 1455/7134 completed (loss: 1.5192806720733643, acc: 0.5376147031784058)
[2024-12-17 03:42:21,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:22,098][root][INFO] - Training Epoch: 1/2, step 1456/7134 completed (loss: 1.3741792440414429, acc: 0.5786026120185852)
[2024-12-17 03:42:22,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:22,519][root][INFO] - Training Epoch: 1/2, step 1457/7134 completed (loss: 1.5426114797592163, acc: 0.5906976461410522)
[2024-12-17 03:42:22,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:22,955][root][INFO] - Training Epoch: 1/2, step 1458/7134 completed (loss: 1.4724477529525757, acc: 0.5802651047706604)
[2024-12-17 03:42:23,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:23,403][root][INFO] - Training Epoch: 1/2, step 1459/7134 completed (loss: 1.6000072956085205, acc: 0.5293073058128357)
[2024-12-17 03:42:23,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:23,850][root][INFO] - Training Epoch: 1/2, step 1460/7134 completed (loss: 1.6008694171905518, acc: 0.5513157844543457)
[2024-12-17 03:42:23,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:24,270][root][INFO] - Training Epoch: 1/2, step 1461/7134 completed (loss: 1.5837256908416748, acc: 0.519936203956604)
[2024-12-17 03:42:24,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:24,712][root][INFO] - Training Epoch: 1/2, step 1462/7134 completed (loss: 1.6411999464035034, acc: 0.5099206566810608)
[2024-12-17 03:42:24,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:25,148][root][INFO] - Training Epoch: 1/2, step 1463/7134 completed (loss: 1.5331628322601318, acc: 0.5355648398399353)
[2024-12-17 03:42:25,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:25,630][root][INFO] - Training Epoch: 1/2, step 1464/7134 completed (loss: 1.623002529144287, acc: 0.5270270109176636)
[2024-12-17 03:42:25,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:26,097][root][INFO] - Training Epoch: 1/2, step 1465/7134 completed (loss: 1.5196301937103271, acc: 0.5297805666923523)
[2024-12-17 03:42:26,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:26,555][root][INFO] - Training Epoch: 1/2, step 1466/7134 completed (loss: 1.4740655422210693, acc: 0.5736544132232666)
[2024-12-17 03:42:26,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:27,004][root][INFO] - Training Epoch: 1/2, step 1467/7134 completed (loss: 1.4669049978256226, acc: 0.5403458476066589)
[2024-12-17 03:42:27,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:27,458][root][INFO] - Training Epoch: 1/2, step 1468/7134 completed (loss: 1.4481096267700195, acc: 0.5627477169036865)
[2024-12-17 03:42:27,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:27,899][root][INFO] - Training Epoch: 1/2, step 1469/7134 completed (loss: 1.4024533033370972, acc: 0.5746971964836121)
[2024-12-17 03:42:28,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:28,335][root][INFO] - Training Epoch: 1/2, step 1470/7134 completed (loss: 1.5248112678527832, acc: 0.5708092451095581)
[2024-12-17 03:42:28,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:28,778][root][INFO] - Training Epoch: 1/2, step 1471/7134 completed (loss: 1.4813281297683716, acc: 0.5825932621955872)
[2024-12-17 03:42:28,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:29,240][root][INFO] - Training Epoch: 1/2, step 1472/7134 completed (loss: 1.4459707736968994, acc: 0.6000000238418579)
[2024-12-17 03:42:29,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:29,704][root][INFO] - Training Epoch: 1/2, step 1473/7134 completed (loss: 1.4146372079849243, acc: 0.5905044674873352)
[2024-12-17 03:42:29,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:30,136][root][INFO] - Training Epoch: 1/2, step 1474/7134 completed (loss: 1.503731369972229, acc: 0.5721476674079895)
[2024-12-17 03:42:30,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:30,592][root][INFO] - Training Epoch: 1/2, step 1475/7134 completed (loss: 1.3973355293273926, acc: 0.6042216420173645)
[2024-12-17 03:42:30,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:31,040][root][INFO] - Training Epoch: 1/2, step 1476/7134 completed (loss: 1.5315895080566406, acc: 0.5341615080833435)
[2024-12-17 03:42:31,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:31,489][root][INFO] - Training Epoch: 1/2, step 1477/7134 completed (loss: 1.4591346979141235, acc: 0.5619546175003052)
[2024-12-17 03:42:31,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:31,932][root][INFO] - Training Epoch: 1/2, step 1478/7134 completed (loss: 1.2986465692520142, acc: 0.6204379796981812)
[2024-12-17 03:42:32,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:32,378][root][INFO] - Training Epoch: 1/2, step 1479/7134 completed (loss: 1.4683183431625366, acc: 0.5775862336158752)
[2024-12-17 03:42:32,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:32,834][root][INFO] - Training Epoch: 1/2, step 1480/7134 completed (loss: 1.4358971118927002, acc: 0.5636363625526428)
[2024-12-17 03:42:32,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:33,302][root][INFO] - Training Epoch: 1/2, step 1481/7134 completed (loss: 1.2953975200653076, acc: 0.6223683953285217)
[2024-12-17 03:42:33,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:33,760][root][INFO] - Training Epoch: 1/2, step 1482/7134 completed (loss: 1.5112217664718628, acc: 0.5610795617103577)
[2024-12-17 03:42:33,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:34,195][root][INFO] - Training Epoch: 1/2, step 1483/7134 completed (loss: 1.3983469009399414, acc: 0.5924170613288879)
[2024-12-17 03:42:34,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:34,649][root][INFO] - Training Epoch: 1/2, step 1484/7134 completed (loss: 1.491287350654602, acc: 0.5520231127738953)
[2024-12-17 03:42:34,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:35,104][root][INFO] - Training Epoch: 1/2, step 1485/7134 completed (loss: 1.5094600915908813, acc: 0.5587863326072693)
[2024-12-17 03:42:35,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:35,561][root][INFO] - Training Epoch: 1/2, step 1486/7134 completed (loss: 1.4439325332641602, acc: 0.5981055498123169)
[2024-12-17 03:42:35,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:36,013][root][INFO] - Training Epoch: 1/2, step 1487/7134 completed (loss: 1.4504345655441284, acc: 0.5673202872276306)
[2024-12-17 03:42:36,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:36,501][root][INFO] - Training Epoch: 1/2, step 1488/7134 completed (loss: 1.4354199171066284, acc: 0.5572192668914795)
[2024-12-17 03:42:36,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:36,975][root][INFO] - Training Epoch: 1/2, step 1489/7134 completed (loss: 1.5047017335891724, acc: 0.5549065470695496)
[2024-12-17 03:42:37,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:37,474][root][INFO] - Training Epoch: 1/2, step 1490/7134 completed (loss: 1.507109522819519, acc: 0.5597883462905884)
[2024-12-17 03:42:37,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:37,929][root][INFO] - Training Epoch: 1/2, step 1491/7134 completed (loss: 1.466813564300537, acc: 0.5597701072692871)
[2024-12-17 03:42:38,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:38,399][root][INFO] - Training Epoch: 1/2, step 1492/7134 completed (loss: 1.5198400020599365, acc: 0.5696055889129639)
[2024-12-17 03:42:38,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:38,884][root][INFO] - Training Epoch: 1/2, step 1493/7134 completed (loss: 1.4595530033111572, acc: 0.5725806355476379)
[2024-12-17 03:42:39,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:39,361][root][INFO] - Training Epoch: 1/2, step 1494/7134 completed (loss: 1.5068151950836182, acc: 0.5620437860488892)
[2024-12-17 03:42:39,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:39,819][root][INFO] - Training Epoch: 1/2, step 1495/7134 completed (loss: 1.5208241939544678, acc: 0.5485029816627502)
[2024-12-17 03:42:39,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:40,278][root][INFO] - Training Epoch: 1/2, step 1496/7134 completed (loss: 1.4126137495040894, acc: 0.5797720551490784)
[2024-12-17 03:42:40,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:40,763][root][INFO] - Training Epoch: 1/2, step 1497/7134 completed (loss: 1.437375545501709, acc: 0.5746606588363647)
[2024-12-17 03:42:40,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:41,181][root][INFO] - Training Epoch: 1/2, step 1498/7134 completed (loss: 1.4934325218200684, acc: 0.5612648129463196)
[2024-12-17 03:42:41,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:41,663][root][INFO] - Training Epoch: 1/2, step 1499/7134 completed (loss: 1.4047185182571411, acc: 0.5860023498535156)
[2024-12-17 03:42:41,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:42,080][root][INFO] - Training Epoch: 1/2, step 1500/7134 completed (loss: 1.4322588443756104, acc: 0.5844370722770691)
[2024-12-17 03:42:42,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:42,544][root][INFO] - Training Epoch: 1/2, step 1501/7134 completed (loss: 1.5474351644515991, acc: 0.5103244781494141)
[2024-12-17 03:42:42,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:43,010][root][INFO] - Training Epoch: 1/2, step 1502/7134 completed (loss: 1.5667299032211304, acc: 0.5445321202278137)
[2024-12-17 03:42:43,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:43,446][root][INFO] - Training Epoch: 1/2, step 1503/7134 completed (loss: 1.711150050163269, acc: 0.49147728085517883)
[2024-12-17 03:42:43,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:43,871][root][INFO] - Training Epoch: 1/2, step 1504/7134 completed (loss: 1.5165988206863403, acc: 0.545911967754364)
[2024-12-17 03:42:43,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:44,303][root][INFO] - Training Epoch: 1/2, step 1505/7134 completed (loss: 1.5684443712234497, acc: 0.5358255505561829)
[2024-12-17 03:42:44,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:44,758][root][INFO] - Training Epoch: 1/2, step 1506/7134 completed (loss: 1.646970272064209, acc: 0.5151975750923157)
[2024-12-17 03:42:44,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:45,218][root][INFO] - Training Epoch: 1/2, step 1507/7134 completed (loss: 1.5651544332504272, acc: 0.551047146320343)
[2024-12-17 03:42:45,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:45,715][root][INFO] - Training Epoch: 1/2, step 1508/7134 completed (loss: 1.3868318796157837, acc: 0.5743982791900635)
[2024-12-17 03:42:45,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:46,166][root][INFO] - Training Epoch: 1/2, step 1509/7134 completed (loss: 1.4947400093078613, acc: 0.5658263564109802)
[2024-12-17 03:42:46,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:46,635][root][INFO] - Training Epoch: 1/2, step 1510/7134 completed (loss: 1.6080918312072754, acc: 0.5600000023841858)
[2024-12-17 03:42:46,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:47,080][root][INFO] - Training Epoch: 1/2, step 1511/7134 completed (loss: 1.5438202619552612, acc: 0.5588652491569519)
[2024-12-17 03:42:47,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:47,531][root][INFO] - Training Epoch: 1/2, step 1512/7134 completed (loss: 1.4332869052886963, acc: 0.5920852422714233)
[2024-12-17 03:42:47,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:47,973][root][INFO] - Training Epoch: 1/2, step 1513/7134 completed (loss: 1.4751728773117065, acc: 0.5568783283233643)
[2024-12-17 03:42:48,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:48,446][root][INFO] - Training Epoch: 1/2, step 1514/7134 completed (loss: 1.437187910079956, acc: 0.5863354206085205)
[2024-12-17 03:42:48,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:48,912][root][INFO] - Training Epoch: 1/2, step 1515/7134 completed (loss: 1.6228313446044922, acc: 0.5)
[2024-12-17 03:42:49,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:49,315][root][INFO] - Training Epoch: 1/2, step 1516/7134 completed (loss: 1.4856998920440674, acc: 0.5783475637435913)
[2024-12-17 03:42:49,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:49,702][root][INFO] - Training Epoch: 1/2, step 1517/7134 completed (loss: 1.6046983003616333, acc: 0.5273109078407288)
[2024-12-17 03:42:49,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:50,067][root][INFO] - Training Epoch: 1/2, step 1518/7134 completed (loss: 1.5431885719299316, acc: 0.5542168617248535)
[2024-12-17 03:42:50,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:50,528][root][INFO] - Training Epoch: 1/2, step 1519/7134 completed (loss: 1.5176690816879272, acc: 0.5368663668632507)
[2024-12-17 03:42:50,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:51,010][root][INFO] - Training Epoch: 1/2, step 1520/7134 completed (loss: 1.535598635673523, acc: 0.5600624084472656)
[2024-12-17 03:42:51,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:51,534][root][INFO] - Training Epoch: 1/2, step 1521/7134 completed (loss: 1.788106918334961, acc: 0.5102421045303345)
[2024-12-17 03:42:51,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:51,961][root][INFO] - Training Epoch: 1/2, step 1522/7134 completed (loss: 1.8120841979980469, acc: 0.4951830506324768)
[2024-12-17 03:42:52,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:52,388][root][INFO] - Training Epoch: 1/2, step 1523/7134 completed (loss: 1.912697434425354, acc: 0.46326836943626404)
[2024-12-17 03:42:52,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:52,820][root][INFO] - Training Epoch: 1/2, step 1524/7134 completed (loss: 1.5735753774642944, acc: 0.5302013158798218)
[2024-12-17 03:42:52,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:53,276][root][INFO] - Training Epoch: 1/2, step 1525/7134 completed (loss: 1.5412766933441162, acc: 0.5497737526893616)
[2024-12-17 03:42:53,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:53,784][root][INFO] - Training Epoch: 1/2, step 1526/7134 completed (loss: 1.8242785930633545, acc: 0.48040637373924255)
[2024-12-17 03:42:53,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:54,310][root][INFO] - Training Epoch: 1/2, step 1527/7134 completed (loss: 1.6789015531539917, acc: 0.5091819763183594)
[2024-12-17 03:42:54,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:54,813][root][INFO] - Training Epoch: 1/2, step 1528/7134 completed (loss: 1.595856785774231, acc: 0.5410627722740173)
[2024-12-17 03:42:54,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:55,285][root][INFO] - Training Epoch: 1/2, step 1529/7134 completed (loss: 1.5486847162246704, acc: 0.5374554395675659)
[2024-12-17 03:42:55,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:55,726][root][INFO] - Training Epoch: 1/2, step 1530/7134 completed (loss: 1.6497522592544556, acc: 0.5315487384796143)
[2024-12-17 03:42:55,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:56,155][root][INFO] - Training Epoch: 1/2, step 1531/7134 completed (loss: 1.9434961080551147, acc: 0.45390069484710693)
[2024-12-17 03:42:56,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:56,698][root][INFO] - Training Epoch: 1/2, step 1532/7134 completed (loss: 1.4855855703353882, acc: 0.5780346989631653)
[2024-12-17 03:42:56,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:57,151][root][INFO] - Training Epoch: 1/2, step 1533/7134 completed (loss: 1.6207424402236938, acc: 0.5034578442573547)
[2024-12-17 03:42:57,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:57,635][root][INFO] - Training Epoch: 1/2, step 1534/7134 completed (loss: 1.5009539127349854, acc: 0.5567867159843445)
[2024-12-17 03:42:57,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:58,204][root][INFO] - Training Epoch: 1/2, step 1535/7134 completed (loss: 1.4396435022354126, acc: 0.5868263244628906)
[2024-12-17 03:42:58,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:58,682][root][INFO] - Training Epoch: 1/2, step 1536/7134 completed (loss: 1.464206576347351, acc: 0.5840708017349243)
[2024-12-17 03:42:58,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:59,164][root][INFO] - Training Epoch: 1/2, step 1537/7134 completed (loss: 1.547641634941101, acc: 0.5392670035362244)
[2024-12-17 03:42:59,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:42:59,605][root][INFO] - Training Epoch: 1/2, step 1538/7134 completed (loss: 1.4728912115097046, acc: 0.5595390796661377)
[2024-12-17 03:42:59,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:00,089][root][INFO] - Training Epoch: 1/2, step 1539/7134 completed (loss: 1.5027709007263184, acc: 0.5494071245193481)
[2024-12-17 03:43:00,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:00,548][root][INFO] - Training Epoch: 1/2, step 1540/7134 completed (loss: 1.5092689990997314, acc: 0.554959774017334)
[2024-12-17 03:43:00,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:00,998][root][INFO] - Training Epoch: 1/2, step 1541/7134 completed (loss: 1.6809477806091309, acc: 0.5081760883331299)
[2024-12-17 03:43:01,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:01,482][root][INFO] - Training Epoch: 1/2, step 1542/7134 completed (loss: 1.5191373825073242, acc: 0.5431267023086548)
[2024-12-17 03:43:01,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:01,970][root][INFO] - Training Epoch: 1/2, step 1543/7134 completed (loss: 1.626819372177124, acc: 0.5234972834587097)
[2024-12-17 03:43:02,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:02,450][root][INFO] - Training Epoch: 1/2, step 1544/7134 completed (loss: 1.565670371055603, acc: 0.5364077687263489)
[2024-12-17 03:43:02,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:02,890][root][INFO] - Training Epoch: 1/2, step 1545/7134 completed (loss: 1.6867601871490479, acc: 0.5193687081336975)
[2024-12-17 03:43:03,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:03,381][root][INFO] - Training Epoch: 1/2, step 1546/7134 completed (loss: 1.633316159248352, acc: 0.5245441794395447)
[2024-12-17 03:43:03,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:03,880][root][INFO] - Training Epoch: 1/2, step 1547/7134 completed (loss: 1.6464753150939941, acc: 0.5104477405548096)
[2024-12-17 03:43:04,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:04,376][root][INFO] - Training Epoch: 1/2, step 1548/7134 completed (loss: 1.555080533027649, acc: 0.5494880676269531)
[2024-12-17 03:43:04,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:04,864][root][INFO] - Training Epoch: 1/2, step 1549/7134 completed (loss: 1.447084903717041, acc: 0.5891472697257996)
[2024-12-17 03:43:05,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:05,334][root][INFO] - Training Epoch: 1/2, step 1550/7134 completed (loss: 1.4095345735549927, acc: 0.572877049446106)
[2024-12-17 03:43:05,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:05,777][root][INFO] - Training Epoch: 1/2, step 1551/7134 completed (loss: 1.4403057098388672, acc: 0.5714285969734192)
[2024-12-17 03:43:05,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:06,254][root][INFO] - Training Epoch: 1/2, step 1552/7134 completed (loss: 1.4753801822662354, acc: 0.5743534564971924)
[2024-12-17 03:43:06,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:06,706][root][INFO] - Training Epoch: 1/2, step 1553/7134 completed (loss: 1.480316162109375, acc: 0.577373206615448)
[2024-12-17 03:43:06,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:07,194][root][INFO] - Training Epoch: 1/2, step 1554/7134 completed (loss: 1.462364673614502, acc: 0.5749717950820923)
[2024-12-17 03:43:07,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:07,650][root][INFO] - Training Epoch: 1/2, step 1555/7134 completed (loss: 1.4282422065734863, acc: 0.5554311275482178)
[2024-12-17 03:43:07,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:08,127][root][INFO] - Training Epoch: 1/2, step 1556/7134 completed (loss: 1.4095964431762695, acc: 0.598119854927063)
[2024-12-17 03:43:08,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:08,602][root][INFO] - Training Epoch: 1/2, step 1557/7134 completed (loss: 1.381761074066162, acc: 0.5894854664802551)
[2024-12-17 03:43:08,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:09,062][root][INFO] - Training Epoch: 1/2, step 1558/7134 completed (loss: 1.5117164850234985, acc: 0.5541490912437439)
[2024-12-17 03:43:09,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:09,510][root][INFO] - Training Epoch: 1/2, step 1559/7134 completed (loss: 1.5368797779083252, acc: 0.5435073375701904)
[2024-12-17 03:43:09,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:09,977][root][INFO] - Training Epoch: 1/2, step 1560/7134 completed (loss: 1.4345413446426392, acc: 0.5603557825088501)
[2024-12-17 03:43:10,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:10,440][root][INFO] - Training Epoch: 1/2, step 1561/7134 completed (loss: 1.6078664064407349, acc: 0.5254604816436768)
[2024-12-17 03:43:10,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:10,926][root][INFO] - Training Epoch: 1/2, step 1562/7134 completed (loss: 1.5069109201431274, acc: 0.5355522036552429)
[2024-12-17 03:43:11,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:11,391][root][INFO] - Training Epoch: 1/2, step 1563/7134 completed (loss: 1.5686231851577759, acc: 0.5360000133514404)
[2024-12-17 03:43:11,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:11,854][root][INFO] - Training Epoch: 1/2, step 1564/7134 completed (loss: 1.7012284994125366, acc: 0.5061880946159363)
[2024-12-17 03:43:11,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:12,268][root][INFO] - Training Epoch: 1/2, step 1565/7134 completed (loss: 1.5914016962051392, acc: 0.5210084319114685)
[2024-12-17 03:43:12,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:12,705][root][INFO] - Training Epoch: 1/2, step 1566/7134 completed (loss: 1.4510432481765747, acc: 0.5677154660224915)
[2024-12-17 03:43:12,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:13,205][root][INFO] - Training Epoch: 1/2, step 1567/7134 completed (loss: 1.5243526697158813, acc: 0.5586034655570984)
[2024-12-17 03:43:13,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:13,683][root][INFO] - Training Epoch: 1/2, step 1568/7134 completed (loss: 1.5550020933151245, acc: 0.5467455387115479)
[2024-12-17 03:43:13,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:14,140][root][INFO] - Training Epoch: 1/2, step 1569/7134 completed (loss: 1.5561937093734741, acc: 0.5380116701126099)
[2024-12-17 03:43:14,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:14,618][root][INFO] - Training Epoch: 1/2, step 1570/7134 completed (loss: 1.5258674621582031, acc: 0.5402425527572632)
[2024-12-17 03:43:14,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:15,051][root][INFO] - Training Epoch: 1/2, step 1571/7134 completed (loss: 1.4704058170318604, acc: 0.5575326085090637)
[2024-12-17 03:43:15,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:15,548][root][INFO] - Training Epoch: 1/2, step 1572/7134 completed (loss: 1.4992039203643799, acc: 0.5712603330612183)
[2024-12-17 03:43:15,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:15,969][root][INFO] - Training Epoch: 1/2, step 1573/7134 completed (loss: 1.3782224655151367, acc: 0.5878084301948547)
[2024-12-17 03:43:16,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:16,442][root][INFO] - Training Epoch: 1/2, step 1574/7134 completed (loss: 1.5731910467147827, acc: 0.5525164008140564)
[2024-12-17 03:43:16,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:16,896][root][INFO] - Training Epoch: 1/2, step 1575/7134 completed (loss: 1.4867618083953857, acc: 0.5798225998878479)
[2024-12-17 03:43:17,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:17,357][root][INFO] - Training Epoch: 1/2, step 1576/7134 completed (loss: 1.3412772417068481, acc: 0.6191588640213013)
[2024-12-17 03:43:17,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:17,853][root][INFO] - Training Epoch: 1/2, step 1577/7134 completed (loss: 1.3726792335510254, acc: 0.5995288491249084)
[2024-12-17 03:43:17,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:18,306][root][INFO] - Training Epoch: 1/2, step 1578/7134 completed (loss: 1.5474556684494019, acc: 0.5453315377235413)
[2024-12-17 03:43:18,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:18,785][root][INFO] - Training Epoch: 1/2, step 1579/7134 completed (loss: 1.5795516967773438, acc: 0.5426267385482788)
[2024-12-17 03:43:18,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:19,261][root][INFO] - Training Epoch: 1/2, step 1580/7134 completed (loss: 1.6788623332977295, acc: 0.5110132098197937)
[2024-12-17 03:43:19,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:19,676][root][INFO] - Training Epoch: 1/2, step 1581/7134 completed (loss: 1.675881266593933, acc: 0.5061728358268738)
[2024-12-17 03:43:19,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:20,138][root][INFO] - Training Epoch: 1/2, step 1582/7134 completed (loss: 1.637863278388977, acc: 0.5289514660835266)
[2024-12-17 03:43:20,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:20,580][root][INFO] - Training Epoch: 1/2, step 1583/7134 completed (loss: 1.573482632637024, acc: 0.5544412732124329)
[2024-12-17 03:43:20,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:21,074][root][INFO] - Training Epoch: 1/2, step 1584/7134 completed (loss: 1.5465160608291626, acc: 0.5674518346786499)
[2024-12-17 03:43:21,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:21,516][root][INFO] - Training Epoch: 1/2, step 1585/7134 completed (loss: 1.4400590658187866, acc: 0.5889281630516052)
[2024-12-17 03:43:21,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:22,033][root][INFO] - Training Epoch: 1/2, step 1586/7134 completed (loss: 1.5324457883834839, acc: 0.5522565245628357)
[2024-12-17 03:43:22,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:22,485][root][INFO] - Training Epoch: 1/2, step 1587/7134 completed (loss: 1.444288730621338, acc: 0.5792778730392456)
[2024-12-17 03:43:22,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:22,941][root][INFO] - Training Epoch: 1/2, step 1588/7134 completed (loss: 1.3848456144332886, acc: 0.59121173620224)
[2024-12-17 03:43:23,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:23,386][root][INFO] - Training Epoch: 1/2, step 1589/7134 completed (loss: 1.4336562156677246, acc: 0.5881612300872803)
[2024-12-17 03:43:23,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:23,801][root][INFO] - Training Epoch: 1/2, step 1590/7134 completed (loss: 1.4598692655563354, acc: 0.5679758191108704)
[2024-12-17 03:43:23,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:24,234][root][INFO] - Training Epoch: 1/2, step 1591/7134 completed (loss: 1.3968768119812012, acc: 0.5989847779273987)
[2024-12-17 03:43:24,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:24,702][root][INFO] - Training Epoch: 1/2, step 1592/7134 completed (loss: 1.4881036281585693, acc: 0.5592011213302612)
[2024-12-17 03:43:24,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:25,197][root][INFO] - Training Epoch: 1/2, step 1593/7134 completed (loss: 1.4047719240188599, acc: 0.588505744934082)
[2024-12-17 03:43:25,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:25,634][root][INFO] - Training Epoch: 1/2, step 1594/7134 completed (loss: 1.4828535318374634, acc: 0.5669421553611755)
[2024-12-17 03:43:25,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:26,070][root][INFO] - Training Epoch: 1/2, step 1595/7134 completed (loss: 1.3314954042434692, acc: 0.6200717091560364)
[2024-12-17 03:43:26,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:26,499][root][INFO] - Training Epoch: 1/2, step 1596/7134 completed (loss: 1.345231056213379, acc: 0.6157480478286743)
[2024-12-17 03:43:26,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:26,926][root][INFO] - Training Epoch: 1/2, step 1597/7134 completed (loss: 1.412095546722412, acc: 0.5802292227745056)
[2024-12-17 03:43:27,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:27,328][root][INFO] - Training Epoch: 1/2, step 1598/7134 completed (loss: 1.5586272478103638, acc: 0.56886225938797)
[2024-12-17 03:43:27,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:27,757][root][INFO] - Training Epoch: 1/2, step 1599/7134 completed (loss: 1.5873476266860962, acc: 0.5619834661483765)
[2024-12-17 03:43:27,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:28,210][root][INFO] - Training Epoch: 1/2, step 1600/7134 completed (loss: 1.3603601455688477, acc: 0.6108545064926147)
[2024-12-17 03:43:28,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:28,643][root][INFO] - Training Epoch: 1/2, step 1601/7134 completed (loss: 1.4114806652069092, acc: 0.5832186937332153)
[2024-12-17 03:43:28,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:29,111][root][INFO] - Training Epoch: 1/2, step 1602/7134 completed (loss: 1.4291431903839111, acc: 0.5791855454444885)
[2024-12-17 03:43:29,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:29,530][root][INFO] - Training Epoch: 1/2, step 1603/7134 completed (loss: 1.3629138469696045, acc: 0.6086956262588501)
[2024-12-17 03:43:29,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:29,987][root][INFO] - Training Epoch: 1/2, step 1604/7134 completed (loss: 1.2604433298110962, acc: 0.6419098377227783)
[2024-12-17 03:43:30,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:30,437][root][INFO] - Training Epoch: 1/2, step 1605/7134 completed (loss: 1.418286919593811, acc: 0.5801825523376465)
[2024-12-17 03:43:30,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:30,905][root][INFO] - Training Epoch: 1/2, step 1606/7134 completed (loss: 1.2876062393188477, acc: 0.621745765209198)
[2024-12-17 03:43:31,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:31,311][root][INFO] - Training Epoch: 1/2, step 1607/7134 completed (loss: 1.179123878479004, acc: 0.6415478587150574)
[2024-12-17 03:43:31,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:31,742][root][INFO] - Training Epoch: 1/2, step 1608/7134 completed (loss: 1.3121392726898193, acc: 0.6115241646766663)
[2024-12-17 03:43:31,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:32,196][root][INFO] - Training Epoch: 1/2, step 1609/7134 completed (loss: 1.3250232934951782, acc: 0.6199377179145813)
[2024-12-17 03:43:32,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:32,629][root][INFO] - Training Epoch: 1/2, step 1610/7134 completed (loss: 1.2741577625274658, acc: 0.6193656325340271)
[2024-12-17 03:43:32,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:33,064][root][INFO] - Training Epoch: 1/2, step 1611/7134 completed (loss: 1.389735460281372, acc: 0.5965608358383179)
[2024-12-17 03:43:33,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:33,495][root][INFO] - Training Epoch: 1/2, step 1612/7134 completed (loss: 1.3792346715927124, acc: 0.6017811894416809)
[2024-12-17 03:43:33,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:33,931][root][INFO] - Training Epoch: 1/2, step 1613/7134 completed (loss: 1.366428256034851, acc: 0.5968379378318787)
[2024-12-17 03:43:34,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:34,373][root][INFO] - Training Epoch: 1/2, step 1614/7134 completed (loss: 1.4030203819274902, acc: 0.5806028842926025)
[2024-12-17 03:43:34,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:34,857][root][INFO] - Training Epoch: 1/2, step 1615/7134 completed (loss: 1.3599729537963867, acc: 0.5798657536506653)
[2024-12-17 03:43:34,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:35,298][root][INFO] - Training Epoch: 1/2, step 1616/7134 completed (loss: 1.396004557609558, acc: 0.5786435604095459)
[2024-12-17 03:43:35,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:35,732][root][INFO] - Training Epoch: 1/2, step 1617/7134 completed (loss: 1.3041023015975952, acc: 0.6037441492080688)
[2024-12-17 03:43:35,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:36,170][root][INFO] - Training Epoch: 1/2, step 1618/7134 completed (loss: 1.6232008934020996, acc: 0.5403508543968201)
[2024-12-17 03:43:36,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:36,618][root][INFO] - Training Epoch: 1/2, step 1619/7134 completed (loss: 1.591240406036377, acc: 0.5381471514701843)
[2024-12-17 03:43:36,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:37,108][root][INFO] - Training Epoch: 1/2, step 1620/7134 completed (loss: 1.6043603420257568, acc: 0.5521936416625977)
[2024-12-17 03:43:37,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:37,562][root][INFO] - Training Epoch: 1/2, step 1621/7134 completed (loss: 1.674446702003479, acc: 0.5202702879905701)
[2024-12-17 03:43:37,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:37,998][root][INFO] - Training Epoch: 1/2, step 1622/7134 completed (loss: 1.6170597076416016, acc: 0.5194985866546631)
[2024-12-17 03:43:38,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:38,456][root][INFO] - Training Epoch: 1/2, step 1623/7134 completed (loss: 1.6056052446365356, acc: 0.5266854166984558)
[2024-12-17 03:43:38,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:38,904][root][INFO] - Training Epoch: 1/2, step 1624/7134 completed (loss: 1.5632990598678589, acc: 0.5462555289268494)
[2024-12-17 03:43:38,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:39,340][root][INFO] - Training Epoch: 1/2, step 1625/7134 completed (loss: 1.4698376655578613, acc: 0.5683760643005371)
[2024-12-17 03:43:39,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:39,782][root][INFO] - Training Epoch: 1/2, step 1626/7134 completed (loss: 1.6945210695266724, acc: 0.49074074625968933)
[2024-12-17 03:43:39,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:40,192][root][INFO] - Training Epoch: 1/2, step 1627/7134 completed (loss: 1.6363497972488403, acc: 0.5383211970329285)
[2024-12-17 03:43:40,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:40,624][root][INFO] - Training Epoch: 1/2, step 1628/7134 completed (loss: 1.4530003070831299, acc: 0.5758017301559448)
[2024-12-17 03:43:40,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:41,031][root][INFO] - Training Epoch: 1/2, step 1629/7134 completed (loss: 1.6171954870224, acc: 0.5327273011207581)
[2024-12-17 03:43:41,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:41,449][root][INFO] - Training Epoch: 1/2, step 1630/7134 completed (loss: 1.605635643005371, acc: 0.5362963080406189)
[2024-12-17 03:43:41,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:41,875][root][INFO] - Training Epoch: 1/2, step 1631/7134 completed (loss: 1.5725847482681274, acc: 0.5482314825057983)
[2024-12-17 03:43:41,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:42,288][root][INFO] - Training Epoch: 1/2, step 1632/7134 completed (loss: 1.515093445777893, acc: 0.5323383212089539)
[2024-12-17 03:43:42,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:42,716][root][INFO] - Training Epoch: 1/2, step 1633/7134 completed (loss: 1.5661348104476929, acc: 0.5557299852371216)
[2024-12-17 03:43:42,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:43,143][root][INFO] - Training Epoch: 1/2, step 1634/7134 completed (loss: 1.6099458932876587, acc: 0.5421133041381836)
[2024-12-17 03:43:43,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:43,563][root][INFO] - Training Epoch: 1/2, step 1635/7134 completed (loss: 1.473152995109558, acc: 0.57230144739151)
[2024-12-17 03:43:43,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:43,991][root][INFO] - Training Epoch: 1/2, step 1636/7134 completed (loss: 1.5420475006103516, acc: 0.5733333230018616)
[2024-12-17 03:43:44,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:44,429][root][INFO] - Training Epoch: 1/2, step 1637/7134 completed (loss: 1.482621192932129, acc: 0.549435019493103)
[2024-12-17 03:43:44,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:44,865][root][INFO] - Training Epoch: 1/2, step 1638/7134 completed (loss: 1.6458672285079956, acc: 0.5534804463386536)
[2024-12-17 03:43:44,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:45,312][root][INFO] - Training Epoch: 1/2, step 1639/7134 completed (loss: 1.6673630475997925, acc: 0.5155096054077148)
[2024-12-17 03:43:45,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:45,767][root][INFO] - Training Epoch: 1/2, step 1640/7134 completed (loss: 1.5420953035354614, acc: 0.5350610017776489)
[2024-12-17 03:43:45,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:46,204][root][INFO] - Training Epoch: 1/2, step 1641/7134 completed (loss: 1.4799935817718506, acc: 0.568965494632721)
[2024-12-17 03:43:46,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:46,657][root][INFO] - Training Epoch: 1/2, step 1642/7134 completed (loss: 1.4875967502593994, acc: 0.5684210658073425)
[2024-12-17 03:43:46,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:47,069][root][INFO] - Training Epoch: 1/2, step 1643/7134 completed (loss: 1.6809360980987549, acc: 0.5129982829093933)
[2024-12-17 03:43:47,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:47,519][root][INFO] - Training Epoch: 1/2, step 1644/7134 completed (loss: 1.421665906906128, acc: 0.5632333755493164)
[2024-12-17 03:43:47,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:47,953][root][INFO] - Training Epoch: 1/2, step 1645/7134 completed (loss: 1.4332219362258911, acc: 0.5732758641242981)
[2024-12-17 03:43:48,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:48,430][root][INFO] - Training Epoch: 1/2, step 1646/7134 completed (loss: 1.5678237676620483, acc: 0.5543131232261658)
[2024-12-17 03:43:48,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:48,882][root][INFO] - Training Epoch: 1/2, step 1647/7134 completed (loss: 1.6412416696548462, acc: 0.5263158082962036)
[2024-12-17 03:43:49,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:49,353][root][INFO] - Training Epoch: 1/2, step 1648/7134 completed (loss: 1.708076000213623, acc: 0.5159574747085571)
[2024-12-17 03:43:49,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:49,811][root][INFO] - Training Epoch: 1/2, step 1649/7134 completed (loss: 1.5795725584030151, acc: 0.538290798664093)
[2024-12-17 03:43:49,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:50,275][root][INFO] - Training Epoch: 1/2, step 1650/7134 completed (loss: 1.6664422750473022, acc: 0.5257731676101685)
[2024-12-17 03:43:50,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:50,751][root][INFO] - Training Epoch: 1/2, step 1651/7134 completed (loss: 1.5808002948760986, acc: 0.5387167930603027)
[2024-12-17 03:43:50,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:51,259][root][INFO] - Training Epoch: 1/2, step 1652/7134 completed (loss: 1.591556191444397, acc: 0.5485278367996216)
[2024-12-17 03:43:51,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:51,725][root][INFO] - Training Epoch: 1/2, step 1653/7134 completed (loss: 1.5032165050506592, acc: 0.5579078197479248)
[2024-12-17 03:43:51,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:52,226][root][INFO] - Training Epoch: 1/2, step 1654/7134 completed (loss: 1.5715218782424927, acc: 0.5606523752212524)
[2024-12-17 03:43:52,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:52,704][root][INFO] - Training Epoch: 1/2, step 1655/7134 completed (loss: 1.5395619869232178, acc: 0.5613383054733276)
[2024-12-17 03:43:52,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:53,159][root][INFO] - Training Epoch: 1/2, step 1656/7134 completed (loss: 1.5795320272445679, acc: 0.5518018007278442)
[2024-12-17 03:43:53,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:53,655][root][INFO] - Training Epoch: 1/2, step 1657/7134 completed (loss: 1.4701212644577026, acc: 0.567123293876648)
[2024-12-17 03:43:53,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:54,131][root][INFO] - Training Epoch: 1/2, step 1658/7134 completed (loss: 1.4481643438339233, acc: 0.5602040886878967)
[2024-12-17 03:43:54,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:54,600][root][INFO] - Training Epoch: 1/2, step 1659/7134 completed (loss: 1.506561040878296, acc: 0.5677725076675415)
[2024-12-17 03:43:54,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:55,096][root][INFO] - Training Epoch: 1/2, step 1660/7134 completed (loss: 1.3938572406768799, acc: 0.5966183543205261)
[2024-12-17 03:43:55,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:55,580][root][INFO] - Training Epoch: 1/2, step 1661/7134 completed (loss: 1.5494716167449951, acc: 0.5634573101997375)
[2024-12-17 03:43:55,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:56,058][root][INFO] - Training Epoch: 1/2, step 1662/7134 completed (loss: 1.4236572980880737, acc: 0.5811240673065186)
[2024-12-17 03:43:56,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:56,543][root][INFO] - Training Epoch: 1/2, step 1663/7134 completed (loss: 1.4308398962020874, acc: 0.5765672922134399)
[2024-12-17 03:43:56,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:56,985][root][INFO] - Training Epoch: 1/2, step 1664/7134 completed (loss: 1.5805282592773438, acc: 0.5578069090843201)
[2024-12-17 03:43:57,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:57,443][root][INFO] - Training Epoch: 1/2, step 1665/7134 completed (loss: 1.4702110290527344, acc: 0.5942445993423462)
[2024-12-17 03:43:57,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:57,980][root][INFO] - Training Epoch: 1/2, step 1666/7134 completed (loss: 1.3811031579971313, acc: 0.5868263244628906)
[2024-12-17 03:43:58,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:58,504][root][INFO] - Training Epoch: 1/2, step 1667/7134 completed (loss: 1.3557392358779907, acc: 0.5973871946334839)
[2024-12-17 03:43:58,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:58,981][root][INFO] - Training Epoch: 1/2, step 1668/7134 completed (loss: 1.3997262716293335, acc: 0.5808823704719543)
[2024-12-17 03:43:59,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:43:59,510][root][INFO] - Training Epoch: 1/2, step 1669/7134 completed (loss: 1.4084296226501465, acc: 0.6016949415206909)
[2024-12-17 03:43:59,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:00,027][root][INFO] - Training Epoch: 1/2, step 1670/7134 completed (loss: 1.353434443473816, acc: 0.6116412281990051)
[2024-12-17 03:44:00,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:00,509][root][INFO] - Training Epoch: 1/2, step 1671/7134 completed (loss: 1.4027554988861084, acc: 0.5794504284858704)
[2024-12-17 03:44:00,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:00,959][root][INFO] - Training Epoch: 1/2, step 1672/7134 completed (loss: 1.5130013227462769, acc: 0.5644090175628662)
[2024-12-17 03:44:01,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:01,421][root][INFO] - Training Epoch: 1/2, step 1673/7134 completed (loss: 1.5139081478118896, acc: 0.5631720423698425)
[2024-12-17 03:44:01,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:01,874][root][INFO] - Training Epoch: 1/2, step 1674/7134 completed (loss: 1.6190035343170166, acc: 0.5600558519363403)
[2024-12-17 03:44:01,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:02,334][root][INFO] - Training Epoch: 1/2, step 1675/7134 completed (loss: 1.499680995941162, acc: 0.563265323638916)
[2024-12-17 03:44:02,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:02,809][root][INFO] - Training Epoch: 1/2, step 1676/7134 completed (loss: 1.589778184890747, acc: 0.5455800890922546)
[2024-12-17 03:44:02,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:03,234][root][INFO] - Training Epoch: 1/2, step 1677/7134 completed (loss: 1.5255409479141235, acc: 0.5761047601699829)
[2024-12-17 03:44:03,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:03,689][root][INFO] - Training Epoch: 1/2, step 1678/7134 completed (loss: 1.4829413890838623, acc: 0.5739725828170776)
[2024-12-17 03:44:03,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:04,110][root][INFO] - Training Epoch: 1/2, step 1679/7134 completed (loss: 1.514837384223938, acc: 0.5710102319717407)
[2024-12-17 03:44:04,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:04,583][root][INFO] - Training Epoch: 1/2, step 1680/7134 completed (loss: 1.5110399723052979, acc: 0.5764074921607971)
[2024-12-17 03:44:04,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:05,003][root][INFO] - Training Epoch: 1/2, step 1681/7134 completed (loss: 1.4699641466140747, acc: 0.5681818127632141)
[2024-12-17 03:44:05,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:05,448][root][INFO] - Training Epoch: 1/2, step 1682/7134 completed (loss: 1.4083501100540161, acc: 0.590778112411499)
[2024-12-17 03:44:05,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:05,888][root][INFO] - Training Epoch: 1/2, step 1683/7134 completed (loss: 1.5065432786941528, acc: 0.5679611563682556)
[2024-12-17 03:44:05,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:06,319][root][INFO] - Training Epoch: 1/2, step 1684/7134 completed (loss: 1.5828279256820679, acc: 0.5616438388824463)
[2024-12-17 03:44:06,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:06,756][root][INFO] - Training Epoch: 1/2, step 1685/7134 completed (loss: 1.4993467330932617, acc: 0.5730180740356445)
[2024-12-17 03:44:06,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:07,167][root][INFO] - Training Epoch: 1/2, step 1686/7134 completed (loss: 1.5312092304229736, acc: 0.5439189076423645)
[2024-12-17 03:44:07,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:07,634][root][INFO] - Training Epoch: 1/2, step 1687/7134 completed (loss: 1.4698272943496704, acc: 0.5874524712562561)
[2024-12-17 03:44:07,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:08,042][root][INFO] - Training Epoch: 1/2, step 1688/7134 completed (loss: 1.6484854221343994, acc: 0.5208655595779419)
[2024-12-17 03:44:08,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:08,473][root][INFO] - Training Epoch: 1/2, step 1689/7134 completed (loss: 1.5053998231887817, acc: 0.5743145942687988)
[2024-12-17 03:44:08,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:08,876][root][INFO] - Training Epoch: 1/2, step 1690/7134 completed (loss: 1.5235273838043213, acc: 0.5508130192756653)
[2024-12-17 03:44:08,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:09,282][root][INFO] - Training Epoch: 1/2, step 1691/7134 completed (loss: 1.6419432163238525, acc: 0.4834437072277069)
[2024-12-17 03:44:09,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:09,694][root][INFO] - Training Epoch: 1/2, step 1692/7134 completed (loss: 1.5371026992797852, acc: 0.558178722858429)
[2024-12-17 03:44:09,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:10,123][root][INFO] - Training Epoch: 1/2, step 1693/7134 completed (loss: 1.423266887664795, acc: 0.591317355632782)
[2024-12-17 03:44:10,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:10,552][root][INFO] - Training Epoch: 1/2, step 1694/7134 completed (loss: 1.4039900302886963, acc: 0.5868544578552246)
[2024-12-17 03:44:10,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:10,987][root][INFO] - Training Epoch: 1/2, step 1695/7134 completed (loss: 1.3339287042617798, acc: 0.6018018126487732)
[2024-12-17 03:44:11,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:11,444][root][INFO] - Training Epoch: 1/2, step 1696/7134 completed (loss: 1.5116894245147705, acc: 0.5644891262054443)
[2024-12-17 03:44:11,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:11,862][root][INFO] - Training Epoch: 1/2, step 1697/7134 completed (loss: 1.4415042400360107, acc: 0.5790297389030457)
[2024-12-17 03:44:11,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:12,293][root][INFO] - Training Epoch: 1/2, step 1698/7134 completed (loss: 1.3481587171554565, acc: 0.5862069129943848)
[2024-12-17 03:44:12,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:12,739][root][INFO] - Training Epoch: 1/2, step 1699/7134 completed (loss: 1.3934524059295654, acc: 0.5882353186607361)
[2024-12-17 03:44:12,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:13,202][root][INFO] - Training Epoch: 1/2, step 1700/7134 completed (loss: 1.5692815780639648, acc: 0.5277280807495117)
[2024-12-17 03:44:13,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:13,626][root][INFO] - Training Epoch: 1/2, step 1701/7134 completed (loss: 1.4333066940307617, acc: 0.58553546667099)
[2024-12-17 03:44:13,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:14,063][root][INFO] - Training Epoch: 1/2, step 1702/7134 completed (loss: 1.448534369468689, acc: 0.5602484345436096)
[2024-12-17 03:44:14,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:14,502][root][INFO] - Training Epoch: 1/2, step 1703/7134 completed (loss: 1.3796006441116333, acc: 0.5925414562225342)
[2024-12-17 03:44:14,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:14,949][root][INFO] - Training Epoch: 1/2, step 1704/7134 completed (loss: 1.5665483474731445, acc: 0.53125)
[2024-12-17 03:44:15,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:15,409][root][INFO] - Training Epoch: 1/2, step 1705/7134 completed (loss: 1.6314994096755981, acc: 0.5325443744659424)
[2024-12-17 03:44:15,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:15,722][root][INFO] - Training Epoch: 1/2, step 1706/7134 completed (loss: 1.5224367380142212, acc: 0.5568181872367859)
[2024-12-17 03:44:15,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:16,141][root][INFO] - Training Epoch: 1/2, step 1707/7134 completed (loss: 1.3938887119293213, acc: 0.5856236815452576)
[2024-12-17 03:44:16,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:16,576][root][INFO] - Training Epoch: 1/2, step 1708/7134 completed (loss: 1.414964199066162, acc: 0.577235758304596)
[2024-12-17 03:44:16,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:17,036][root][INFO] - Training Epoch: 1/2, step 1709/7134 completed (loss: 1.5970239639282227, acc: 0.5431034564971924)
[2024-12-17 03:44:17,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:17,535][root][INFO] - Training Epoch: 1/2, step 1710/7134 completed (loss: 1.4575793743133545, acc: 0.545976996421814)
[2024-12-17 03:44:17,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:17,946][root][INFO] - Training Epoch: 1/2, step 1711/7134 completed (loss: 1.4326574802398682, acc: 0.5820379853248596)
[2024-12-17 03:44:18,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:18,372][root][INFO] - Training Epoch: 1/2, step 1712/7134 completed (loss: 1.3557109832763672, acc: 0.6070175170898438)
[2024-12-17 03:44:18,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:18,818][root][INFO] - Training Epoch: 1/2, step 1713/7134 completed (loss: 1.5038893222808838, acc: 0.5608782172203064)
[2024-12-17 03:44:18,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:19,268][root][INFO] - Training Epoch: 1/2, step 1714/7134 completed (loss: 1.4715057611465454, acc: 0.5674341917037964)
[2024-12-17 03:44:19,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:19,708][root][INFO] - Training Epoch: 1/2, step 1715/7134 completed (loss: 1.3396402597427368, acc: 0.610547661781311)
[2024-12-17 03:44:19,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:20,110][root][INFO] - Training Epoch: 1/2, step 1716/7134 completed (loss: 1.4857532978057861, acc: 0.5550000071525574)
[2024-12-17 03:44:20,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:20,537][root][INFO] - Training Epoch: 1/2, step 1717/7134 completed (loss: 1.5069760084152222, acc: 0.548638105392456)
[2024-12-17 03:44:20,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:21,031][root][INFO] - Training Epoch: 1/2, step 1718/7134 completed (loss: 1.420686960220337, acc: 0.570155918598175)
[2024-12-17 03:44:21,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:21,478][root][INFO] - Training Epoch: 1/2, step 1719/7134 completed (loss: 1.393120527267456, acc: 0.5931506752967834)
[2024-12-17 03:44:21,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:21,856][root][INFO] - Training Epoch: 1/2, step 1720/7134 completed (loss: 1.5447771549224854, acc: 0.5383023023605347)
[2024-12-17 03:44:21,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:22,233][root][INFO] - Training Epoch: 1/2, step 1721/7134 completed (loss: 1.3682596683502197, acc: 0.5851601958274841)
[2024-12-17 03:44:22,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:22,628][root][INFO] - Training Epoch: 1/2, step 1722/7134 completed (loss: 1.4492912292480469, acc: 0.5684210658073425)
[2024-12-17 03:44:22,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:23,040][root][INFO] - Training Epoch: 1/2, step 1723/7134 completed (loss: 1.5071340799331665, acc: 0.564828634262085)
[2024-12-17 03:44:23,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:23,465][root][INFO] - Training Epoch: 1/2, step 1724/7134 completed (loss: 1.3443498611450195, acc: 0.6043956279754639)
[2024-12-17 03:44:23,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:23,814][root][INFO] - Training Epoch: 1/2, step 1725/7134 completed (loss: 1.35756254196167, acc: 0.5916398763656616)
[2024-12-17 03:44:23,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:24,205][root][INFO] - Training Epoch: 1/2, step 1726/7134 completed (loss: 1.301792025566101, acc: 0.6031390428543091)
[2024-12-17 03:44:24,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:24,630][root][INFO] - Training Epoch: 1/2, step 1727/7134 completed (loss: 1.3599600791931152, acc: 0.6277372241020203)
[2024-12-17 03:44:24,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:25,068][root][INFO] - Training Epoch: 1/2, step 1728/7134 completed (loss: 1.3771326541900635, acc: 0.5943708419799805)
[2024-12-17 03:44:25,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:25,463][root][INFO] - Training Epoch: 1/2, step 1729/7134 completed (loss: 1.4814690351486206, acc: 0.5967413187026978)
[2024-12-17 03:44:25,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:25,913][root][INFO] - Training Epoch: 1/2, step 1730/7134 completed (loss: 1.3716832399368286, acc: 0.599571704864502)
[2024-12-17 03:44:26,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:26,317][root][INFO] - Training Epoch: 1/2, step 1731/7134 completed (loss: 1.4147030115127563, acc: 0.6011560559272766)
[2024-12-17 03:44:26,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:26,737][root][INFO] - Training Epoch: 1/2, step 1732/7134 completed (loss: 1.3941068649291992, acc: 0.5852156281471252)
[2024-12-17 03:44:26,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:27,126][root][INFO] - Training Epoch: 1/2, step 1733/7134 completed (loss: 1.4573519229888916, acc: 0.588477373123169)
[2024-12-17 03:44:27,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:27,637][root][INFO] - Training Epoch: 1/2, step 1734/7134 completed (loss: 1.424877405166626, acc: 0.5872235894203186)
[2024-12-17 03:44:27,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:28,080][root][INFO] - Training Epoch: 1/2, step 1735/7134 completed (loss: 1.4758073091506958, acc: 0.5652173757553101)
[2024-12-17 03:44:28,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:28,543][root][INFO] - Training Epoch: 1/2, step 1736/7134 completed (loss: 1.4685819149017334, acc: 0.5660606026649475)
[2024-12-17 03:44:28,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:29,013][root][INFO] - Training Epoch: 1/2, step 1737/7134 completed (loss: 1.4334471225738525, acc: 0.5828651785850525)
[2024-12-17 03:44:29,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:29,491][root][INFO] - Training Epoch: 1/2, step 1738/7134 completed (loss: 1.4222062826156616, acc: 0.5729795098304749)
[2024-12-17 03:44:29,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:29,947][root][INFO] - Training Epoch: 1/2, step 1739/7134 completed (loss: 1.5001709461212158, acc: 0.552395224571228)
[2024-12-17 03:44:30,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:30,402][root][INFO] - Training Epoch: 1/2, step 1740/7134 completed (loss: 1.4837313890457153, acc: 0.5526315569877625)
[2024-12-17 03:44:30,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:30,905][root][INFO] - Training Epoch: 1/2, step 1741/7134 completed (loss: 1.3707499504089355, acc: 0.5820105671882629)
[2024-12-17 03:44:31,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:31,340][root][INFO] - Training Epoch: 1/2, step 1742/7134 completed (loss: 1.4602688550949097, acc: 0.5744680762290955)
[2024-12-17 03:44:31,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:31,851][root][INFO] - Training Epoch: 1/2, step 1743/7134 completed (loss: 1.4351285696029663, acc: 0.5714285969734192)
[2024-12-17 03:44:31,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:32,294][root][INFO] - Training Epoch: 1/2, step 1744/7134 completed (loss: 1.4456150531768799, acc: 0.5651465654373169)
[2024-12-17 03:44:32,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:32,755][root][INFO] - Training Epoch: 1/2, step 1745/7134 completed (loss: 1.468762993812561, acc: 0.5701754093170166)
[2024-12-17 03:44:32,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:33,226][root][INFO] - Training Epoch: 1/2, step 1746/7134 completed (loss: 1.4395248889923096, acc: 0.5625)
[2024-12-17 03:44:33,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:33,696][root][INFO] - Training Epoch: 1/2, step 1747/7134 completed (loss: 1.4661316871643066, acc: 0.5669587254524231)
[2024-12-17 03:44:33,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:34,178][root][INFO] - Training Epoch: 1/2, step 1748/7134 completed (loss: 1.4912041425704956, acc: 0.5732010006904602)
[2024-12-17 03:44:34,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:34,678][root][INFO] - Training Epoch: 1/2, step 1749/7134 completed (loss: 1.3108798265457153, acc: 0.6174801588058472)
[2024-12-17 03:44:34,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:35,184][root][INFO] - Training Epoch: 1/2, step 1750/7134 completed (loss: 1.4010729789733887, acc: 0.5947242379188538)
[2024-12-17 03:44:35,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:35,654][root][INFO] - Training Epoch: 1/2, step 1751/7134 completed (loss: 1.448072910308838, acc: 0.581818163394928)
[2024-12-17 03:44:35,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:36,119][root][INFO] - Training Epoch: 1/2, step 1752/7134 completed (loss: 1.4956504106521606, acc: 0.5554123520851135)
[2024-12-17 03:44:36,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:36,567][root][INFO] - Training Epoch: 1/2, step 1753/7134 completed (loss: 1.3876267671585083, acc: 0.5942782759666443)
[2024-12-17 03:44:36,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:37,012][root][INFO] - Training Epoch: 1/2, step 1754/7134 completed (loss: 1.4087975025177002, acc: 0.5806916356086731)
[2024-12-17 03:44:37,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:37,468][root][INFO] - Training Epoch: 1/2, step 1755/7134 completed (loss: 1.3411434888839722, acc: 0.6124338507652283)
[2024-12-17 03:44:37,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:37,918][root][INFO] - Training Epoch: 1/2, step 1756/7134 completed (loss: 1.4234743118286133, acc: 0.5812743902206421)
[2024-12-17 03:44:38,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:38,344][root][INFO] - Training Epoch: 1/2, step 1757/7134 completed (loss: 1.2644697427749634, acc: 0.6256239414215088)
[2024-12-17 03:44:38,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:38,828][root][INFO] - Training Epoch: 1/2, step 1758/7134 completed (loss: 1.2540972232818604, acc: 0.6212121248245239)
[2024-12-17 03:44:38,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:39,269][root][INFO] - Training Epoch: 1/2, step 1759/7134 completed (loss: 1.3068476915359497, acc: 0.6216968297958374)
[2024-12-17 03:44:39,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:39,716][root][INFO] - Training Epoch: 1/2, step 1760/7134 completed (loss: 1.2837305068969727, acc: 0.6235294342041016)
[2024-12-17 03:44:39,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:40,124][root][INFO] - Training Epoch: 1/2, step 1761/7134 completed (loss: 1.3315365314483643, acc: 0.5951704382896423)
[2024-12-17 03:44:40,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:40,552][root][INFO] - Training Epoch: 1/2, step 1762/7134 completed (loss: 1.5367754697799683, acc: 0.5649484395980835)
[2024-12-17 03:44:40,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:40,982][root][INFO] - Training Epoch: 1/2, step 1763/7134 completed (loss: 1.6107616424560547, acc: 0.5480769276618958)
[2024-12-17 03:44:41,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:41,402][root][INFO] - Training Epoch: 1/2, step 1764/7134 completed (loss: 1.6597236394882202, acc: 0.5315985083580017)
[2024-12-17 03:44:41,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:41,846][root][INFO] - Training Epoch: 1/2, step 1765/7134 completed (loss: 1.5395278930664062, acc: 0.5509259104728699)
[2024-12-17 03:44:41,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:42,261][root][INFO] - Training Epoch: 1/2, step 1766/7134 completed (loss: 1.4966267347335815, acc: 0.5469208359718323)
[2024-12-17 03:44:42,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:42,702][root][INFO] - Training Epoch: 1/2, step 1767/7134 completed (loss: 1.5903435945510864, acc: 0.5502121448516846)
[2024-12-17 03:44:42,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:43,126][root][INFO] - Training Epoch: 1/2, step 1768/7134 completed (loss: 1.4602636098861694, acc: 0.5799614787101746)
[2024-12-17 03:44:43,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:43,593][root][INFO] - Training Epoch: 1/2, step 1769/7134 completed (loss: 1.4893922805786133, acc: 0.5661764740943909)
[2024-12-17 03:44:43,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:44,015][root][INFO] - Training Epoch: 1/2, step 1770/7134 completed (loss: 1.507105827331543, acc: 0.5720788836479187)
[2024-12-17 03:44:44,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:44,451][root][INFO] - Training Epoch: 1/2, step 1771/7134 completed (loss: 1.4407082796096802, acc: 0.5684357285499573)
[2024-12-17 03:44:44,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:44,879][root][INFO] - Training Epoch: 1/2, step 1772/7134 completed (loss: 1.5521507263183594, acc: 0.5443885922431946)
[2024-12-17 03:44:45,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:45,323][root][INFO] - Training Epoch: 1/2, step 1773/7134 completed (loss: 1.442240834236145, acc: 0.5930232405662537)
[2024-12-17 03:44:45,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:45,791][root][INFO] - Training Epoch: 1/2, step 1774/7134 completed (loss: 1.4528416395187378, acc: 0.5963455438613892)
[2024-12-17 03:44:45,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:46,186][root][INFO] - Training Epoch: 1/2, step 1775/7134 completed (loss: 1.3629803657531738, acc: 0.5859375)
[2024-12-17 03:44:46,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:46,624][root][INFO] - Training Epoch: 1/2, step 1776/7134 completed (loss: 1.420445203781128, acc: 0.597305417060852)
[2024-12-17 03:44:46,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:47,037][root][INFO] - Training Epoch: 1/2, step 1777/7134 completed (loss: 1.3768072128295898, acc: 0.5961538553237915)
[2024-12-17 03:44:47,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:47,493][root][INFO] - Training Epoch: 1/2, step 1778/7134 completed (loss: 1.4899719953536987, acc: 0.5917159914970398)
[2024-12-17 03:44:47,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:47,909][root][INFO] - Training Epoch: 1/2, step 1779/7134 completed (loss: 1.3465077877044678, acc: 0.5878787636756897)
[2024-12-17 03:44:48,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:48,401][root][INFO] - Training Epoch: 1/2, step 1780/7134 completed (loss: 1.3883296251296997, acc: 0.591230571269989)
[2024-12-17 03:44:48,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:48,828][root][INFO] - Training Epoch: 1/2, step 1781/7134 completed (loss: 1.4206229448318481, acc: 0.5847328305244446)
[2024-12-17 03:44:48,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:49,264][root][INFO] - Training Epoch: 1/2, step 1782/7134 completed (loss: 1.3981106281280518, acc: 0.5753424763679504)
[2024-12-17 03:44:50,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:50,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:51,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:51,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:51,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:52,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:52,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:53,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:53,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:53,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:54,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:54,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:55,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:55,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:55,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:56,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:56,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:57,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:57,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:57,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:58,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:58,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:59,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:59,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:44:59,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:00,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:00,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:00,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:01,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:01,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:02,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:02,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:02,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:03,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:03,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:04,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:04,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:04,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:05,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:05,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:05,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:06,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:06,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:07,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:07,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:08,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:08,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:08,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:09,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:09,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:09,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:10,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:10,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:11,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:11,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:11,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:12,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:12,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:12,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:12,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:13,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:13,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:14,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:14,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:14,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:15,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:15,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:16,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:16,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:16,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:17,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:17,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:18,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:18,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:18,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:19,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:19,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:19,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:20,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:20,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:20,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:21,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:21,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:21,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:22,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:22,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:23,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:23,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:24,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:24,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:25,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:25,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:25,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:26,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:26,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:26,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:27,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:27,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:28,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:28,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:28,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:29,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:29,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:29,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:30,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:30,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:31,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:31,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:31,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:32,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:32,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:32,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:33,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:33,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:34,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:34,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:34,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:35,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:35,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:36,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:36,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:36,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:37,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:37,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:38,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:38,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:39,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:39,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:39,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:40,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:40,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:41,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:41,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:41,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:42,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:42,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:43,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:43,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:43,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:44,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:44,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:44,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:45,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:45,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:46,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:46,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:47,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:47,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:47,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:48,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:48,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:48,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:49,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:49,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:49,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:50,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:50,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:51,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:51,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:51,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:52,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:52,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:52,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:53,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:53,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:54,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:54,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:54,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:55,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:55,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:56,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:56,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:56,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:57,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:57,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:58,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:58,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:58,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:59,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:45:59,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:00,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:00,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:00,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:01,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:01,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:02,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:02,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:03,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:03,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:04,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:04,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:04,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:05,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:05,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:05,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:06,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:06,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:07,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:07,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:07,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:08,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:08,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:08,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:09,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:09,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:09,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:10,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:10,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:11,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:11,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:11,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:12,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:12,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:13,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:13,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:13,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:14,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:14,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:14,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:15,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:15,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:15,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:16,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:16,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:16,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:17,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:17,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:17,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:18,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:18,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:19,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:19,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:20,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:20,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:20,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:21,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:21,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:21,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:22,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:22,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:23,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:23,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:23,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:24,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:24,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:24,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:25,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:26,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:26,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:26,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:27,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:27,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:28,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:28,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:29,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:29,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:29,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:30,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:30,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:31,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:31,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:31,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:32,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:32,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:32,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:33,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:33,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:33,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:34,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:34,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:35,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:35,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:36,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:36,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:36,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:37,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:37,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:38,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:38,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:38,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:39,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:39,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:40,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:40,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:40,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:41,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:41,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:42,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:42,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:42,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:43,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:43,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:44,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:44,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:45,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:45,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:45,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:46,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:46,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:47,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:47,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:47,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:48,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:48,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:48,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:49,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:49,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:49,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:50,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:50,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:50,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:51,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:51,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:51,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:52,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:52,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:52,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:53,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:53,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:54,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:54,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:54,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:55,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:55,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:55,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:56,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:56,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:57,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:57,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:58,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:58,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:58,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:59,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:59,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:46:59,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:00,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:00,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:01,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:01,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:01,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:02,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:02,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:03,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:03,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:03,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:04,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:04,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:05,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:05,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:06,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:06,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:07,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:07,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:07,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:08,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:08,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:09,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:09,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:09,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:10,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:10,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:11,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:11,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:12,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:13,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:13,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:13,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:14,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:14,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:15,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:15,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:15,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:16,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:16,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:16,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:17,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:17,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:17,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:18,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:18,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:19,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:19,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:20,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:20,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:20,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:21,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:21,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:21,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:22,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:22,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:22,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:23,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:23,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:24,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:24,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:24,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:25,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:25,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:26,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:26,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:26,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:27,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:27,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:27,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:28,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:28,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:28,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:29,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:29,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:30,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:30,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:30,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:31,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:31,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:32,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:32,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:32,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:33,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:33,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:33,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:34,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:34,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:35,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:35,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:36,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:36,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:36,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:37,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:37,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:37,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:38,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:38,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:39,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:39,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:39,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:40,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:40,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:41,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:41,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:41,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:42,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:42,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:43,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:43,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:44,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:44,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:44,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:45,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:45,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:45,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:46,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:46,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:46,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:47,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:47,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:48,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:48,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:48,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:49,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:49,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:49,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:50,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:50,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:50,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:51,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:51,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:51,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:52,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:52,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:53,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:53,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:53,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:54,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:54,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:54,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:55,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:55,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:56,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:56,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:56,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:57,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:57,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:58,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:58,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:58,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:59,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:47:59,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:00,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:00,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:01,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:01,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:01,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:02,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:02,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:02,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:03,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:03,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:04,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:04,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:04,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:05,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:05,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:06,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:06,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:07,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:07,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:07,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:08,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:08,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:09,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:09,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:09,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:10,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:10,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:10,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:11,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:11,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:11,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:12,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:12,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:12,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:13,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:13,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:14,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:14,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:14,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:15,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:15,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:15,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:16,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:16,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:17,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:17,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:17,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:18,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:18,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:19,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:19,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:19,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:20,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:20,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:20,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:21,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:21,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:22,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:22,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:22,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:23,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:23,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:24,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:24,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:24,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:25,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:25,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:26,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:26,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:26,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:27,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:27,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:27,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:28,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:28,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:28,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:29,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:29,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:30,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:30,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:30,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:31,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:31,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:32,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:32,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:32,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:33,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:33,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:34,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:34,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:35,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:35,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:35,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:36,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:36,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:37,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:37,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:38,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:38,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:38,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:39,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:39,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:39,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:40,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:40,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:40,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:41,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:41,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:41,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:42,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:42,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:43,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:43,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:43,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:44,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:44,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:44,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:45,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:45,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:46,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:46,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:46,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:47,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:47,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:48,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:48,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:48,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:49,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:49,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:50,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:50,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:50,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:51,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:51,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:51,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:52,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:52,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:53,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:53,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:54,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:55,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:55,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:55,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:56,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:56,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:57,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:57,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:58,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:58,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:59,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:48:59,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:00,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:00,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:00,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:01,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:01,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:01,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:02,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:02,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:03,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:03,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:03,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:04,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:04,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:05,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:05,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:05,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:06,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:06,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:06,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:07,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:07,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:07,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:08,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:08,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:09,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:09,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:09,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:10,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:10,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:11,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:11,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:11,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:12,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:12,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:12,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:13,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:13,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:14,429][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(4.7051, device='cuda:0') eval_epoch_loss=tensor(1.5486, device='cuda:0') eval_epoch_acc=tensor(0.5554, device='cuda:0')
[2024-12-17 03:49:14,431][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-17 03:49:14,431][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 03:49:14,712][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_1_step_1783_loss_1.5486396551132202/model.pt
[2024-12-17 03:49:14,716][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-12-17 03:49:14,717][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 1.5486396551132202
[2024-12-17 03:49:14,717][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.5554115772247314
[2024-12-17 03:49:14,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:15,210][root][INFO] - Training Epoch: 1/2, step 1783/7134 completed (loss: 1.4289714097976685, acc: 0.5797297358512878)
[2024-12-17 03:49:15,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:15,648][root][INFO] - Training Epoch: 1/2, step 1784/7134 completed (loss: 1.3142263889312744, acc: 0.607038140296936)
[2024-12-17 03:49:15,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:16,097][root][INFO] - Training Epoch: 1/2, step 1785/7134 completed (loss: 1.5607740879058838, acc: 0.5557084083557129)
[2024-12-17 03:49:16,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:16,506][root][INFO] - Training Epoch: 1/2, step 1786/7134 completed (loss: 1.4824904203414917, acc: 0.5912636518478394)
[2024-12-17 03:49:16,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:16,929][root][INFO] - Training Epoch: 1/2, step 1787/7134 completed (loss: 1.4800183773040771, acc: 0.5696428418159485)
[2024-12-17 03:49:17,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:17,329][root][INFO] - Training Epoch: 1/2, step 1788/7134 completed (loss: 1.5154533386230469, acc: 0.5613747835159302)
[2024-12-17 03:49:17,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:17,751][root][INFO] - Training Epoch: 1/2, step 1789/7134 completed (loss: 1.4628009796142578, acc: 0.5514593124389648)
[2024-12-17 03:49:17,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:18,204][root][INFO] - Training Epoch: 1/2, step 1790/7134 completed (loss: 1.5000340938568115, acc: 0.5845410823822021)
[2024-12-17 03:49:18,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:18,609][root][INFO] - Training Epoch: 1/2, step 1791/7134 completed (loss: 1.6784954071044922, acc: 0.5306704640388489)
[2024-12-17 03:49:18,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:19,063][root][INFO] - Training Epoch: 1/2, step 1792/7134 completed (loss: 1.4796462059020996, acc: 0.577235758304596)
[2024-12-17 03:49:19,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:19,507][root][INFO] - Training Epoch: 1/2, step 1793/7134 completed (loss: 1.5011600255966187, acc: 0.5756756663322449)
[2024-12-17 03:49:19,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:19,961][root][INFO] - Training Epoch: 1/2, step 1794/7134 completed (loss: 1.5601047277450562, acc: 0.5393081903457642)
[2024-12-17 03:49:20,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:20,384][root][INFO] - Training Epoch: 1/2, step 1795/7134 completed (loss: 1.5774507522583008, acc: 0.5585106611251831)
[2024-12-17 03:49:20,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:20,804][root][INFO] - Training Epoch: 1/2, step 1796/7134 completed (loss: 1.592875361442566, acc: 0.5282131433486938)
[2024-12-17 03:49:20,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:21,225][root][INFO] - Training Epoch: 1/2, step 1797/7134 completed (loss: 1.5643397569656372, acc: 0.5364145636558533)
[2024-12-17 03:49:21,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:21,677][root][INFO] - Training Epoch: 1/2, step 1798/7134 completed (loss: 1.5998560190200806, acc: 0.5598455667495728)
[2024-12-17 03:49:21,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:22,122][root][INFO] - Training Epoch: 1/2, step 1799/7134 completed (loss: 1.498213529586792, acc: 0.55402010679245)
[2024-12-17 03:49:22,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:22,573][root][INFO] - Training Epoch: 1/2, step 1800/7134 completed (loss: 1.4893561601638794, acc: 0.572429895401001)
[2024-12-17 03:49:22,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:23,016][root][INFO] - Training Epoch: 1/2, step 1801/7134 completed (loss: 1.4288409948349, acc: 0.6016949415206909)
[2024-12-17 03:49:23,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:23,455][root][INFO] - Training Epoch: 1/2, step 1802/7134 completed (loss: 1.4846553802490234, acc: 0.5744680762290955)
[2024-12-17 03:49:23,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:23,873][root][INFO] - Training Epoch: 1/2, step 1803/7134 completed (loss: 1.485459566116333, acc: 0.5516178607940674)
[2024-12-17 03:49:23,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:24,299][root][INFO] - Training Epoch: 1/2, step 1804/7134 completed (loss: 1.4305460453033447, acc: 0.5565110445022583)
[2024-12-17 03:49:24,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:24,756][root][INFO] - Training Epoch: 1/2, step 1805/7134 completed (loss: 1.4632964134216309, acc: 0.5584415793418884)
[2024-12-17 03:49:24,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:25,195][root][INFO] - Training Epoch: 1/2, step 1806/7134 completed (loss: 1.4410595893859863, acc: 0.5776315927505493)
[2024-12-17 03:49:25,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:25,615][root][INFO] - Training Epoch: 1/2, step 1807/7134 completed (loss: 1.5800427198410034, acc: 0.5374823212623596)
[2024-12-17 03:49:25,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:26,039][root][INFO] - Training Epoch: 1/2, step 1808/7134 completed (loss: 1.4864639043807983, acc: 0.5721716284751892)
[2024-12-17 03:49:26,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:26,489][root][INFO] - Training Epoch: 1/2, step 1809/7134 completed (loss: 1.4727400541305542, acc: 0.5635135173797607)
[2024-12-17 03:49:26,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:26,952][root][INFO] - Training Epoch: 1/2, step 1810/7134 completed (loss: 1.4722689390182495, acc: 0.5889175534248352)
[2024-12-17 03:49:27,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:27,380][root][INFO] - Training Epoch: 1/2, step 1811/7134 completed (loss: 1.5297220945358276, acc: 0.5440977215766907)
[2024-12-17 03:49:27,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:27,816][root][INFO] - Training Epoch: 1/2, step 1812/7134 completed (loss: 1.4096161127090454, acc: 0.5803571343421936)
[2024-12-17 03:49:27,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:28,272][root][INFO] - Training Epoch: 1/2, step 1813/7134 completed (loss: 1.4477194547653198, acc: 0.5640718340873718)
[2024-12-17 03:49:28,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:28,741][root][INFO] - Training Epoch: 1/2, step 1814/7134 completed (loss: 1.476309061050415, acc: 0.5641025900840759)
[2024-12-17 03:49:28,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:29,177][root][INFO] - Training Epoch: 1/2, step 1815/7134 completed (loss: 1.5249742269515991, acc: 0.5632184147834778)
[2024-12-17 03:49:29,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:29,609][root][INFO] - Training Epoch: 1/2, step 1816/7134 completed (loss: 1.6209723949432373, acc: 0.5414710640907288)
[2024-12-17 03:49:29,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:30,075][root][INFO] - Training Epoch: 1/2, step 1817/7134 completed (loss: 1.4725526571273804, acc: 0.5751789808273315)
[2024-12-17 03:49:30,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:30,529][root][INFO] - Training Epoch: 1/2, step 1818/7134 completed (loss: 1.456102967262268, acc: 0.5675340890884399)
[2024-12-17 03:49:30,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:30,984][root][INFO] - Training Epoch: 1/2, step 1819/7134 completed (loss: 1.3272560834884644, acc: 0.6296758055686951)
[2024-12-17 03:49:31,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:31,501][root][INFO] - Training Epoch: 1/2, step 1820/7134 completed (loss: 1.4339425563812256, acc: 0.5895196795463562)
[2024-12-17 03:49:31,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:31,943][root][INFO] - Training Epoch: 1/2, step 1821/7134 completed (loss: 1.3468602895736694, acc: 0.5984682440757751)
[2024-12-17 03:49:32,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:32,358][root][INFO] - Training Epoch: 1/2, step 1822/7134 completed (loss: 1.4284602403640747, acc: 0.5760233998298645)
[2024-12-17 03:49:32,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:32,790][root][INFO] - Training Epoch: 1/2, step 1823/7134 completed (loss: 1.4803357124328613, acc: 0.5552523732185364)
[2024-12-17 03:49:32,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:33,228][root][INFO] - Training Epoch: 1/2, step 1824/7134 completed (loss: 1.3600436449050903, acc: 0.6056860089302063)
[2024-12-17 03:49:33,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:33,678][root][INFO] - Training Epoch: 1/2, step 1825/7134 completed (loss: 1.354474425315857, acc: 0.6076233386993408)
[2024-12-17 03:49:33,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:34,123][root][INFO] - Training Epoch: 1/2, step 1826/7134 completed (loss: 1.338283658027649, acc: 0.5975773930549622)
[2024-12-17 03:49:34,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:34,575][root][INFO] - Training Epoch: 1/2, step 1827/7134 completed (loss: 1.2950583696365356, acc: 0.6119073629379272)
[2024-12-17 03:49:34,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:35,025][root][INFO] - Training Epoch: 1/2, step 1828/7134 completed (loss: 1.350209355354309, acc: 0.599742591381073)
[2024-12-17 03:49:35,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:35,481][root][INFO] - Training Epoch: 1/2, step 1829/7134 completed (loss: 1.3585176467895508, acc: 0.5788819789886475)
[2024-12-17 03:49:35,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:35,937][root][INFO] - Training Epoch: 1/2, step 1830/7134 completed (loss: 1.4478785991668701, acc: 0.5629540085792542)
[2024-12-17 03:49:36,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:36,347][root][INFO] - Training Epoch: 1/2, step 1831/7134 completed (loss: 1.569385290145874, acc: 0.5390625)
[2024-12-17 03:49:36,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:36,756][root][INFO] - Training Epoch: 1/2, step 1832/7134 completed (loss: 1.5590192079544067, acc: 0.5512367486953735)
[2024-12-17 03:49:36,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:37,200][root][INFO] - Training Epoch: 1/2, step 1833/7134 completed (loss: 1.5084606409072876, acc: 0.5708245038986206)
[2024-12-17 03:49:37,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:37,656][root][INFO] - Training Epoch: 1/2, step 1834/7134 completed (loss: 1.4802558422088623, acc: 0.580281674861908)
[2024-12-17 03:49:37,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:38,082][root][INFO] - Training Epoch: 1/2, step 1835/7134 completed (loss: 1.5646812915802002, acc: 0.5537790656089783)
[2024-12-17 03:49:38,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:38,522][root][INFO] - Training Epoch: 1/2, step 1836/7134 completed (loss: 1.4984828233718872, acc: 0.5460993051528931)
[2024-12-17 03:49:38,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:38,966][root][INFO] - Training Epoch: 1/2, step 1837/7134 completed (loss: 1.4570767879486084, acc: 0.5823096036911011)
[2024-12-17 03:49:39,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:39,337][root][INFO] - Training Epoch: 1/2, step 1838/7134 completed (loss: 1.5459845066070557, acc: 0.5734694004058838)
[2024-12-17 03:49:39,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:39,795][root][INFO] - Training Epoch: 1/2, step 1839/7134 completed (loss: 1.5990855693817139, acc: 0.5233160853385925)
[2024-12-17 03:49:39,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:40,248][root][INFO] - Training Epoch: 1/2, step 1840/7134 completed (loss: 1.5965369939804077, acc: 0.5202231407165527)
[2024-12-17 03:49:40,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:40,664][root][INFO] - Training Epoch: 1/2, step 1841/7134 completed (loss: 1.5224041938781738, acc: 0.5744680762290955)
[2024-12-17 03:49:40,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:41,112][root][INFO] - Training Epoch: 1/2, step 1842/7134 completed (loss: 1.462867259979248, acc: 0.5782312750816345)
[2024-12-17 03:49:41,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:41,531][root][INFO] - Training Epoch: 1/2, step 1843/7134 completed (loss: 1.4071056842803955, acc: 0.5975000262260437)
[2024-12-17 03:49:41,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:41,978][root][INFO] - Training Epoch: 1/2, step 1844/7134 completed (loss: 1.371124029159546, acc: 0.6097561120986938)
[2024-12-17 03:49:42,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:42,462][root][INFO] - Training Epoch: 1/2, step 1845/7134 completed (loss: 1.411487102508545, acc: 0.5887265205383301)
[2024-12-17 03:49:42,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:42,889][root][INFO] - Training Epoch: 1/2, step 1846/7134 completed (loss: 1.396796464920044, acc: 0.6239316463470459)
[2024-12-17 03:49:42,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:43,345][root][INFO] - Training Epoch: 1/2, step 1847/7134 completed (loss: 1.6160215139389038, acc: 0.523809552192688)
[2024-12-17 03:49:43,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:43,796][root][INFO] - Training Epoch: 1/2, step 1848/7134 completed (loss: 1.4897499084472656, acc: 0.5677965879440308)
[2024-12-17 03:49:43,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:44,231][root][INFO] - Training Epoch: 1/2, step 1849/7134 completed (loss: 1.5022791624069214, acc: 0.5676625370979309)
[2024-12-17 03:49:44,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:44,683][root][INFO] - Training Epoch: 1/2, step 1850/7134 completed (loss: 1.5141834020614624, acc: 0.57334965467453)
[2024-12-17 03:49:44,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:45,127][root][INFO] - Training Epoch: 1/2, step 1851/7134 completed (loss: 1.5374845266342163, acc: 0.5677655935287476)
[2024-12-17 03:49:45,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:45,552][root][INFO] - Training Epoch: 1/2, step 1852/7134 completed (loss: 1.5970885753631592, acc: 0.5512422323226929)
[2024-12-17 03:49:45,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:46,003][root][INFO] - Training Epoch: 1/2, step 1853/7134 completed (loss: 1.620847225189209, acc: 0.529904305934906)
[2024-12-17 03:49:46,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:46,444][root][INFO] - Training Epoch: 1/2, step 1854/7134 completed (loss: 1.6431562900543213, acc: 0.5291320085525513)
[2024-12-17 03:49:46,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:46,886][root][INFO] - Training Epoch: 1/2, step 1855/7134 completed (loss: 1.5955721139907837, acc: 0.5306358337402344)
[2024-12-17 03:49:47,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:47,303][root][INFO] - Training Epoch: 1/2, step 1856/7134 completed (loss: 1.3886313438415527, acc: 0.5842558145523071)
[2024-12-17 03:49:47,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:47,825][root][INFO] - Training Epoch: 1/2, step 1857/7134 completed (loss: 1.5320098400115967, acc: 0.552955687046051)
[2024-12-17 03:49:47,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:48,276][root][INFO] - Training Epoch: 1/2, step 1858/7134 completed (loss: 1.4866914749145508, acc: 0.5657894611358643)
[2024-12-17 03:49:48,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:48,746][root][INFO] - Training Epoch: 1/2, step 1859/7134 completed (loss: 1.475365161895752, acc: 0.5574516654014587)
[2024-12-17 03:49:48,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:49,192][root][INFO] - Training Epoch: 1/2, step 1860/7134 completed (loss: 1.4699618816375732, acc: 0.5632911324501038)
[2024-12-17 03:49:49,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:49,627][root][INFO] - Training Epoch: 1/2, step 1861/7134 completed (loss: 1.4256328344345093, acc: 0.5891472697257996)
[2024-12-17 03:49:49,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:50,063][root][INFO] - Training Epoch: 1/2, step 1862/7134 completed (loss: 1.4369337558746338, acc: 0.6051560640335083)
[2024-12-17 03:49:50,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:50,501][root][INFO] - Training Epoch: 1/2, step 1863/7134 completed (loss: 1.4030990600585938, acc: 0.5899280309677124)
[2024-12-17 03:49:50,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:50,923][root][INFO] - Training Epoch: 1/2, step 1864/7134 completed (loss: 1.5557130575180054, acc: 0.5605441927909851)
[2024-12-17 03:49:51,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:51,330][root][INFO] - Training Epoch: 1/2, step 1865/7134 completed (loss: 1.5227137804031372, acc: 0.576988160610199)
[2024-12-17 03:49:51,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:51,757][root][INFO] - Training Epoch: 1/2, step 1866/7134 completed (loss: 1.3831087350845337, acc: 0.5924369692802429)
[2024-12-17 03:49:51,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:52,225][root][INFO] - Training Epoch: 1/2, step 1867/7134 completed (loss: 1.3762543201446533, acc: 0.5901639461517334)
[2024-12-17 03:49:52,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:52,706][root][INFO] - Training Epoch: 1/2, step 1868/7134 completed (loss: 1.6023614406585693, acc: 0.5346534848213196)
[2024-12-17 03:49:52,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:53,144][root][INFO] - Training Epoch: 1/2, step 1869/7134 completed (loss: 1.430649757385254, acc: 0.6068515777587891)
[2024-12-17 03:49:53,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:53,577][root][INFO] - Training Epoch: 1/2, step 1870/7134 completed (loss: 1.3475645780563354, acc: 0.609375)
[2024-12-17 03:49:53,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:54,026][root][INFO] - Training Epoch: 1/2, step 1871/7134 completed (loss: 1.3675378561019897, acc: 0.5823817253112793)
[2024-12-17 03:49:54,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:54,441][root][INFO] - Training Epoch: 1/2, step 1872/7134 completed (loss: 1.9480371475219727, acc: 0.45856353640556335)
[2024-12-17 03:49:54,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:54,881][root][INFO] - Training Epoch: 1/2, step 1873/7134 completed (loss: 1.5634410381317139, acc: 0.5724465847015381)
[2024-12-17 03:49:55,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:55,341][root][INFO] - Training Epoch: 1/2, step 1874/7134 completed (loss: 1.4637080430984497, acc: 0.5701179504394531)
[2024-12-17 03:49:55,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:55,759][root][INFO] - Training Epoch: 1/2, step 1875/7134 completed (loss: 1.2724902629852295, acc: 0.6179039478302002)
[2024-12-17 03:49:55,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:56,177][root][INFO] - Training Epoch: 1/2, step 1876/7134 completed (loss: 1.5734684467315674, acc: 0.5449914932250977)
[2024-12-17 03:49:56,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:56,616][root][INFO] - Training Epoch: 1/2, step 1877/7134 completed (loss: 1.3053842782974243, acc: 0.6083123683929443)
[2024-12-17 03:49:56,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:57,048][root][INFO] - Training Epoch: 1/2, step 1878/7134 completed (loss: 1.382371187210083, acc: 0.6117103099822998)
[2024-12-17 03:49:57,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:57,490][root][INFO] - Training Epoch: 1/2, step 1879/7134 completed (loss: 1.5394631624221802, acc: 0.559543251991272)
[2024-12-17 03:49:57,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:57,912][root][INFO] - Training Epoch: 1/2, step 1880/7134 completed (loss: 1.5204778909683228, acc: 0.5412474870681763)
[2024-12-17 03:49:58,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:58,336][root][INFO] - Training Epoch: 1/2, step 1881/7134 completed (loss: 1.5359705686569214, acc: 0.5669934749603271)
[2024-12-17 03:49:58,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:58,693][root][INFO] - Training Epoch: 1/2, step 1882/7134 completed (loss: 1.5713224411010742, acc: 0.5517241358757019)
[2024-12-17 03:49:58,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:59,113][root][INFO] - Training Epoch: 1/2, step 1883/7134 completed (loss: 1.6030267477035522, acc: 0.5177165269851685)
[2024-12-17 03:49:59,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:59,518][root][INFO] - Training Epoch: 1/2, step 1884/7134 completed (loss: 1.5603301525115967, acc: 0.548183262348175)
[2024-12-17 03:49:59,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:49:59,921][root][INFO] - Training Epoch: 1/2, step 1885/7134 completed (loss: 1.5569111108779907, acc: 0.5666041374206543)
[2024-12-17 03:50:00,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:00,338][root][INFO] - Training Epoch: 1/2, step 1886/7134 completed (loss: 1.5250905752182007, acc: 0.555323600769043)
[2024-12-17 03:50:00,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:00,741][root][INFO] - Training Epoch: 1/2, step 1887/7134 completed (loss: 1.538801670074463, acc: 0.5616698265075684)
[2024-12-17 03:50:00,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:01,193][root][INFO] - Training Epoch: 1/2, step 1888/7134 completed (loss: 1.4395041465759277, acc: 0.6084452867507935)
[2024-12-17 03:50:01,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:01,639][root][INFO] - Training Epoch: 1/2, step 1889/7134 completed (loss: 1.437691569328308, acc: 0.5722543597221375)
[2024-12-17 03:50:01,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:02,073][root][INFO] - Training Epoch: 1/2, step 1890/7134 completed (loss: 1.523603916168213, acc: 0.574303388595581)
[2024-12-17 03:50:02,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:02,504][root][INFO] - Training Epoch: 1/2, step 1891/7134 completed (loss: 1.560249924659729, acc: 0.5665584206581116)
[2024-12-17 03:50:02,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:02,926][root][INFO] - Training Epoch: 1/2, step 1892/7134 completed (loss: 1.4507032632827759, acc: 0.557959794998169)
[2024-12-17 03:50:03,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:03,341][root][INFO] - Training Epoch: 1/2, step 1893/7134 completed (loss: 1.426505446434021, acc: 0.5834633111953735)
[2024-12-17 03:50:03,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:03,787][root][INFO] - Training Epoch: 1/2, step 1894/7134 completed (loss: 1.4902268648147583, acc: 0.5364583134651184)
[2024-12-17 03:50:03,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:04,191][root][INFO] - Training Epoch: 1/2, step 1895/7134 completed (loss: 1.7878293991088867, acc: 0.5032680034637451)
[2024-12-17 03:50:04,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:04,611][root][INFO] - Training Epoch: 1/2, step 1896/7134 completed (loss: 1.5774908065795898, acc: 0.5717647075653076)
[2024-12-17 03:50:04,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:05,048][root][INFO] - Training Epoch: 1/2, step 1897/7134 completed (loss: 1.3978333473205566, acc: 0.5962963104248047)
[2024-12-17 03:50:05,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:05,459][root][INFO] - Training Epoch: 1/2, step 1898/7134 completed (loss: 1.4341057538986206, acc: 0.5970149040222168)
[2024-12-17 03:50:05,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:05,847][root][INFO] - Training Epoch: 1/2, step 1899/7134 completed (loss: 1.5089952945709229, acc: 0.573236882686615)
[2024-12-17 03:50:05,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:06,284][root][INFO] - Training Epoch: 1/2, step 1900/7134 completed (loss: 1.4236315488815308, acc: 0.5744336843490601)
[2024-12-17 03:50:06,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:06,709][root][INFO] - Training Epoch: 1/2, step 1901/7134 completed (loss: 1.4169665575027466, acc: 0.5850091576576233)
[2024-12-17 03:50:06,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:07,112][root][INFO] - Training Epoch: 1/2, step 1902/7134 completed (loss: 1.446882963180542, acc: 0.5834797620773315)
[2024-12-17 03:50:07,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:07,533][root][INFO] - Training Epoch: 1/2, step 1903/7134 completed (loss: 1.4386839866638184, acc: 0.5763888955116272)
[2024-12-17 03:50:07,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:07,923][root][INFO] - Training Epoch: 1/2, step 1904/7134 completed (loss: 1.359883427619934, acc: 0.5995762944221497)
[2024-12-17 03:50:08,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:08,309][root][INFO] - Training Epoch: 1/2, step 1905/7134 completed (loss: 1.3966164588928223, acc: 0.6053169965744019)
[2024-12-17 03:50:08,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:08,718][root][INFO] - Training Epoch: 1/2, step 1906/7134 completed (loss: 1.325453519821167, acc: 0.6179337501525879)
[2024-12-17 03:50:08,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:09,113][root][INFO] - Training Epoch: 1/2, step 1907/7134 completed (loss: 1.4524974822998047, acc: 0.5680672526359558)
[2024-12-17 03:50:09,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:09,553][root][INFO] - Training Epoch: 1/2, step 1908/7134 completed (loss: 1.436079502105713, acc: 0.5853920578956604)
[2024-12-17 03:50:09,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:09,968][root][INFO] - Training Epoch: 1/2, step 1909/7134 completed (loss: 1.5218514204025269, acc: 0.5430463552474976)
[2024-12-17 03:50:10,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:10,419][root][INFO] - Training Epoch: 1/2, step 1910/7134 completed (loss: 1.4740947484970093, acc: 0.547149121761322)
[2024-12-17 03:50:10,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:10,869][root][INFO] - Training Epoch: 1/2, step 1911/7134 completed (loss: 1.476272463798523, acc: 0.5740291476249695)
[2024-12-17 03:50:10,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:11,313][root][INFO] - Training Epoch: 1/2, step 1912/7134 completed (loss: 1.3991453647613525, acc: 0.5832223892211914)
[2024-12-17 03:50:11,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:11,744][root][INFO] - Training Epoch: 1/2, step 1913/7134 completed (loss: 1.4188345670700073, acc: 0.573283851146698)
[2024-12-17 03:50:11,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:12,186][root][INFO] - Training Epoch: 1/2, step 1914/7134 completed (loss: 1.5418665409088135, acc: 0.5615696907043457)
[2024-12-17 03:50:12,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:12,611][root][INFO] - Training Epoch: 1/2, step 1915/7134 completed (loss: 1.3352911472320557, acc: 0.6019575595855713)
[2024-12-17 03:50:12,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:13,043][root][INFO] - Training Epoch: 1/2, step 1916/7134 completed (loss: 1.5197043418884277, acc: 0.5444579720497131)
[2024-12-17 03:50:13,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:13,477][root][INFO] - Training Epoch: 1/2, step 1917/7134 completed (loss: 1.3905633687973022, acc: 0.5742297172546387)
[2024-12-17 03:50:13,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:13,881][root][INFO] - Training Epoch: 1/2, step 1918/7134 completed (loss: 1.4172500371932983, acc: 0.592476487159729)
[2024-12-17 03:50:14,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:14,369][root][INFO] - Training Epoch: 1/2, step 1919/7134 completed (loss: 1.4144186973571777, acc: 0.5738880634307861)
[2024-12-17 03:50:14,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:14,839][root][INFO] - Training Epoch: 1/2, step 1920/7134 completed (loss: 1.4665915966033936, acc: 0.5586419701576233)
[2024-12-17 03:50:14,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:15,257][root][INFO] - Training Epoch: 1/2, step 1921/7134 completed (loss: 1.4944895505905151, acc: 0.5581717491149902)
[2024-12-17 03:50:15,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:15,727][root][INFO] - Training Epoch: 1/2, step 1922/7134 completed (loss: 1.4298391342163086, acc: 0.583499014377594)
[2024-12-17 03:50:15,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:16,162][root][INFO] - Training Epoch: 1/2, step 1923/7134 completed (loss: 1.3561592102050781, acc: 0.5963149070739746)
[2024-12-17 03:50:16,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:16,601][root][INFO] - Training Epoch: 1/2, step 1924/7134 completed (loss: 1.4182298183441162, acc: 0.6051502227783203)
[2024-12-17 03:50:16,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:17,064][root][INFO] - Training Epoch: 1/2, step 1925/7134 completed (loss: 1.3434888124465942, acc: 0.6000000238418579)
[2024-12-17 03:50:17,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:17,546][root][INFO] - Training Epoch: 1/2, step 1926/7134 completed (loss: 1.335637092590332, acc: 0.6128702759742737)
[2024-12-17 03:50:17,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:18,010][root][INFO] - Training Epoch: 1/2, step 1927/7134 completed (loss: 1.3998970985412598, acc: 0.5834254026412964)
[2024-12-17 03:50:18,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:18,472][root][INFO] - Training Epoch: 1/2, step 1928/7134 completed (loss: 1.4427410364151, acc: 0.5820668935775757)
[2024-12-17 03:50:18,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:18,915][root][INFO] - Training Epoch: 1/2, step 1929/7134 completed (loss: 1.5614770650863647, acc: 0.5437853336334229)
[2024-12-17 03:50:19,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:19,357][root][INFO] - Training Epoch: 1/2, step 1930/7134 completed (loss: 1.7007508277893066, acc: 0.5209974050521851)
[2024-12-17 03:50:19,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:19,818][root][INFO] - Training Epoch: 1/2, step 1931/7134 completed (loss: 1.6322983503341675, acc: 0.5372945666313171)
[2024-12-17 03:50:19,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:20,232][root][INFO] - Training Epoch: 1/2, step 1932/7134 completed (loss: 1.6131160259246826, acc: 0.5432835817337036)
[2024-12-17 03:50:20,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:20,678][root][INFO] - Training Epoch: 1/2, step 1933/7134 completed (loss: 1.6902493238449097, acc: 0.5336134433746338)
[2024-12-17 03:50:20,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:21,094][root][INFO] - Training Epoch: 1/2, step 1934/7134 completed (loss: 1.5084325075149536, acc: 0.5593220591545105)
[2024-12-17 03:50:21,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:21,547][root][INFO] - Training Epoch: 1/2, step 1935/7134 completed (loss: 1.456918478012085, acc: 0.5633187890052795)
[2024-12-17 03:50:21,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:21,998][root][INFO] - Training Epoch: 1/2, step 1936/7134 completed (loss: 1.4255015850067139, acc: 0.5845181941986084)
[2024-12-17 03:50:22,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:22,400][root][INFO] - Training Epoch: 1/2, step 1937/7134 completed (loss: 1.6036535501480103, acc: 0.5746753215789795)
[2024-12-17 03:50:22,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:22,827][root][INFO] - Training Epoch: 1/2, step 1938/7134 completed (loss: 1.5917153358459473, acc: 0.5413105487823486)
[2024-12-17 03:50:22,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:23,257][root][INFO] - Training Epoch: 1/2, step 1939/7134 completed (loss: 1.5481711626052856, acc: 0.5762711763381958)
[2024-12-17 03:50:23,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:23,697][root][INFO] - Training Epoch: 1/2, step 1940/7134 completed (loss: 1.5524183511734009, acc: 0.5496598482131958)
[2024-12-17 03:50:23,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:24,166][root][INFO] - Training Epoch: 1/2, step 1941/7134 completed (loss: 1.4421426057815552, acc: 0.5842245817184448)
[2024-12-17 03:50:24,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:24,603][root][INFO] - Training Epoch: 1/2, step 1942/7134 completed (loss: 1.3574297428131104, acc: 0.6056910753250122)
[2024-12-17 03:50:24,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:25,073][root][INFO] - Training Epoch: 1/2, step 1943/7134 completed (loss: 1.55485200881958, acc: 0.54756098985672)
[2024-12-17 03:50:25,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:25,518][root][INFO] - Training Epoch: 1/2, step 1944/7134 completed (loss: 1.4998400211334229, acc: 0.5648994445800781)
[2024-12-17 03:50:25,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:25,959][root][INFO] - Training Epoch: 1/2, step 1945/7134 completed (loss: 1.5029407739639282, acc: 0.5807086825370789)
[2024-12-17 03:50:26,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:26,400][root][INFO] - Training Epoch: 1/2, step 1946/7134 completed (loss: 1.4006834030151367, acc: 0.5806451439857483)
[2024-12-17 03:50:26,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:26,836][root][INFO] - Training Epoch: 1/2, step 1947/7134 completed (loss: 1.4508756399154663, acc: 0.5618420839309692)
[2024-12-17 03:50:26,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:27,266][root][INFO] - Training Epoch: 1/2, step 1948/7134 completed (loss: 1.5063518285751343, acc: 0.5730550289154053)
[2024-12-17 03:50:27,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:27,660][root][INFO] - Training Epoch: 1/2, step 1949/7134 completed (loss: 1.5296740531921387, acc: 0.5418060421943665)
[2024-12-17 03:50:27,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:28,107][root][INFO] - Training Epoch: 1/2, step 1950/7134 completed (loss: 1.4728751182556152, acc: 0.5802919864654541)
[2024-12-17 03:50:28,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:28,583][root][INFO] - Training Epoch: 1/2, step 1951/7134 completed (loss: 1.389434576034546, acc: 0.5836120247840881)
[2024-12-17 03:50:28,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:28,996][root][INFO] - Training Epoch: 1/2, step 1952/7134 completed (loss: 1.377580165863037, acc: 0.5890182852745056)
[2024-12-17 03:50:29,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:29,416][root][INFO] - Training Epoch: 1/2, step 1953/7134 completed (loss: 1.4029645919799805, acc: 0.5789473652839661)
[2024-12-17 03:50:29,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:29,797][root][INFO] - Training Epoch: 1/2, step 1954/7134 completed (loss: 1.4625099897384644, acc: 0.5780487656593323)
[2024-12-17 03:50:29,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:30,227][root][INFO] - Training Epoch: 1/2, step 1955/7134 completed (loss: 1.3848176002502441, acc: 0.5940245985984802)
[2024-12-17 03:50:30,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:30,568][root][INFO] - Training Epoch: 1/2, step 1956/7134 completed (loss: 1.4182273149490356, acc: 0.5645161271095276)
[2024-12-17 03:50:30,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:30,976][root][INFO] - Training Epoch: 1/2, step 1957/7134 completed (loss: 1.5331147909164429, acc: 0.5388888716697693)
[2024-12-17 03:50:31,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:31,325][root][INFO] - Training Epoch: 1/2, step 1958/7134 completed (loss: 1.4271730184555054, acc: 0.5558739304542542)
[2024-12-17 03:50:31,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:31,758][root][INFO] - Training Epoch: 1/2, step 1959/7134 completed (loss: 1.3732160329818726, acc: 0.5778251886367798)
[2024-12-17 03:50:31,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:32,181][root][INFO] - Training Epoch: 1/2, step 1960/7134 completed (loss: 1.4861234426498413, acc: 0.5770676732063293)
[2024-12-17 03:50:32,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:32,582][root][INFO] - Training Epoch: 1/2, step 1961/7134 completed (loss: 1.426180362701416, acc: 0.6020066738128662)
[2024-12-17 03:50:32,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:33,002][root][INFO] - Training Epoch: 1/2, step 1962/7134 completed (loss: 1.3583686351776123, acc: 0.5726256966590881)
[2024-12-17 03:50:33,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:33,410][root][INFO] - Training Epoch: 1/2, step 1963/7134 completed (loss: 1.5068013668060303, acc: 0.5544041395187378)
[2024-12-17 03:50:33,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:33,841][root][INFO] - Training Epoch: 1/2, step 1964/7134 completed (loss: 1.5317168235778809, acc: 0.5641025900840759)
[2024-12-17 03:50:33,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:34,271][root][INFO] - Training Epoch: 1/2, step 1965/7134 completed (loss: 1.491808533668518, acc: 0.5704323649406433)
[2024-12-17 03:50:34,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:34,690][root][INFO] - Training Epoch: 1/2, step 1966/7134 completed (loss: 1.638079047203064, acc: 0.5183486342430115)
[2024-12-17 03:50:34,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:35,140][root][INFO] - Training Epoch: 1/2, step 1967/7134 completed (loss: 1.4444726705551147, acc: 0.5745223164558411)
[2024-12-17 03:50:35,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:35,590][root][INFO] - Training Epoch: 1/2, step 1968/7134 completed (loss: 1.4313466548919678, acc: 0.5740740895271301)
[2024-12-17 03:50:35,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:36,004][root][INFO] - Training Epoch: 1/2, step 1969/7134 completed (loss: 1.4300923347473145, acc: 0.581333339214325)
[2024-12-17 03:50:36,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:36,439][root][INFO] - Training Epoch: 1/2, step 1970/7134 completed (loss: 1.4413251876831055, acc: 0.5828220844268799)
[2024-12-17 03:50:36,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:36,850][root][INFO] - Training Epoch: 1/2, step 1971/7134 completed (loss: 1.4295607805252075, acc: 0.5822281241416931)
[2024-12-17 03:50:37,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:37,253][root][INFO] - Training Epoch: 1/2, step 1972/7134 completed (loss: 1.5894992351531982, acc: 0.525798499584198)
[2024-12-17 03:50:37,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:37,674][root][INFO] - Training Epoch: 1/2, step 1973/7134 completed (loss: 1.59658682346344, acc: 0.5447618961334229)
[2024-12-17 03:50:37,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:38,122][root][INFO] - Training Epoch: 1/2, step 1974/7134 completed (loss: 1.425135612487793, acc: 0.5690954923629761)
[2024-12-17 03:50:38,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:38,536][root][INFO] - Training Epoch: 1/2, step 1975/7134 completed (loss: 1.4754736423492432, acc: 0.5757575631141663)
[2024-12-17 03:50:38,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:38,998][root][INFO] - Training Epoch: 1/2, step 1976/7134 completed (loss: 1.4750289916992188, acc: 0.5628539323806763)
[2024-12-17 03:50:39,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:39,439][root][INFO] - Training Epoch: 1/2, step 1977/7134 completed (loss: 1.5019315481185913, acc: 0.5579710006713867)
[2024-12-17 03:50:39,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:39,868][root][INFO] - Training Epoch: 1/2, step 1978/7134 completed (loss: 1.3958849906921387, acc: 0.5919463038444519)
[2024-12-17 03:50:40,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:40,321][root][INFO] - Training Epoch: 1/2, step 1979/7134 completed (loss: 1.4436508417129517, acc: 0.5729166865348816)
[2024-12-17 03:50:40,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:40,773][root][INFO] - Training Epoch: 1/2, step 1980/7134 completed (loss: 1.4824161529541016, acc: 0.5762711763381958)
[2024-12-17 03:50:40,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:41,216][root][INFO] - Training Epoch: 1/2, step 1981/7134 completed (loss: 1.378282070159912, acc: 0.5846154093742371)
[2024-12-17 03:50:41,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:41,628][root][INFO] - Training Epoch: 1/2, step 1982/7134 completed (loss: 1.4007055759429932, acc: 0.5637065768241882)
[2024-12-17 03:50:41,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:42,053][root][INFO] - Training Epoch: 1/2, step 1983/7134 completed (loss: 1.3245362043380737, acc: 0.6119592785835266)
[2024-12-17 03:50:42,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:42,465][root][INFO] - Training Epoch: 1/2, step 1984/7134 completed (loss: 1.364715337753296, acc: 0.5814266204833984)
[2024-12-17 03:50:42,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:42,895][root][INFO] - Training Epoch: 1/2, step 1985/7134 completed (loss: 1.4051976203918457, acc: 0.5905292630195618)
[2024-12-17 03:50:43,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:43,341][root][INFO] - Training Epoch: 1/2, step 1986/7134 completed (loss: 1.3393174409866333, acc: 0.6138995885848999)
[2024-12-17 03:50:43,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:43,790][root][INFO] - Training Epoch: 1/2, step 1987/7134 completed (loss: 1.4369699954986572, acc: 0.5920680165290833)
[2024-12-17 03:50:43,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:44,225][root][INFO] - Training Epoch: 1/2, step 1988/7134 completed (loss: 1.4857642650604248, acc: 0.5863052606582642)
[2024-12-17 03:50:44,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:44,626][root][INFO] - Training Epoch: 1/2, step 1989/7134 completed (loss: 1.3854124546051025, acc: 0.6267942786216736)
[2024-12-17 03:50:44,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:45,076][root][INFO] - Training Epoch: 1/2, step 1990/7134 completed (loss: 1.3092072010040283, acc: 0.6116504669189453)
[2024-12-17 03:50:45,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:45,515][root][INFO] - Training Epoch: 1/2, step 1991/7134 completed (loss: 1.4183636903762817, acc: 0.5614618062973022)
[2024-12-17 03:50:45,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:45,932][root][INFO] - Training Epoch: 1/2, step 1992/7134 completed (loss: 1.6892582178115845, acc: 0.5410852432250977)
[2024-12-17 03:50:46,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:46,350][root][INFO] - Training Epoch: 1/2, step 1993/7134 completed (loss: 1.559313178062439, acc: 0.557117760181427)
[2024-12-17 03:50:46,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:46,778][root][INFO] - Training Epoch: 1/2, step 1994/7134 completed (loss: 1.3555666208267212, acc: 0.5896551609039307)
[2024-12-17 03:50:46,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:47,218][root][INFO] - Training Epoch: 1/2, step 1995/7134 completed (loss: 1.418172836303711, acc: 0.5873261094093323)
[2024-12-17 03:50:47,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:47,637][root][INFO] - Training Epoch: 1/2, step 1996/7134 completed (loss: 1.5092244148254395, acc: 0.5619834661483765)
[2024-12-17 03:50:47,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:48,062][root][INFO] - Training Epoch: 1/2, step 1997/7134 completed (loss: 1.3873637914657593, acc: 0.5866084694862366)
[2024-12-17 03:50:48,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:48,473][root][INFO] - Training Epoch: 1/2, step 1998/7134 completed (loss: 1.3816953897476196, acc: 0.5886970162391663)
[2024-12-17 03:50:48,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:48,899][root][INFO] - Training Epoch: 1/2, step 1999/7134 completed (loss: 1.4892891645431519, acc: 0.5517826676368713)
[2024-12-17 03:50:49,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:49,314][root][INFO] - Training Epoch: 1/2, step 2000/7134 completed (loss: 1.4235283136367798, acc: 0.5694006085395813)
[2024-12-17 03:50:49,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:49,708][root][INFO] - Training Epoch: 1/2, step 2001/7134 completed (loss: 1.455910086631775, acc: 0.5833333134651184)
[2024-12-17 03:50:49,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:50,173][root][INFO] - Training Epoch: 1/2, step 2002/7134 completed (loss: 1.5470869541168213, acc: 0.5460869669914246)
[2024-12-17 03:50:50,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:50,552][root][INFO] - Training Epoch: 1/2, step 2003/7134 completed (loss: 1.5090159177780151, acc: 0.5729166865348816)
[2024-12-17 03:50:50,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:50,919][root][INFO] - Training Epoch: 1/2, step 2004/7134 completed (loss: 1.6657004356384277, acc: 0.5485231876373291)
[2024-12-17 03:50:51,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:51,367][root][INFO] - Training Epoch: 1/2, step 2005/7134 completed (loss: 1.5272504091262817, acc: 0.5726027488708496)
[2024-12-17 03:50:51,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:51,788][root][INFO] - Training Epoch: 1/2, step 2006/7134 completed (loss: 1.423790454864502, acc: 0.5994236469268799)
[2024-12-17 03:50:51,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:52,213][root][INFO] - Training Epoch: 1/2, step 2007/7134 completed (loss: 1.4930981397628784, acc: 0.5742971897125244)
[2024-12-17 03:50:52,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:52,607][root][INFO] - Training Epoch: 1/2, step 2008/7134 completed (loss: 1.5345556735992432, acc: 0.5480427145957947)
[2024-12-17 03:50:52,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:53,016][root][INFO] - Training Epoch: 1/2, step 2009/7134 completed (loss: 1.364540934562683, acc: 0.6173285245895386)
[2024-12-17 03:50:53,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:53,418][root][INFO] - Training Epoch: 1/2, step 2010/7134 completed (loss: 1.410620927810669, acc: 0.578044593334198)
[2024-12-17 03:50:53,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:53,846][root][INFO] - Training Epoch: 1/2, step 2011/7134 completed (loss: 1.472275733947754, acc: 0.5655577182769775)
[2024-12-17 03:50:53,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:54,248][root][INFO] - Training Epoch: 1/2, step 2012/7134 completed (loss: 1.4811533689498901, acc: 0.5644820332527161)
[2024-12-17 03:50:54,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:54,676][root][INFO] - Training Epoch: 1/2, step 2013/7134 completed (loss: 1.5104596614837646, acc: 0.5540000200271606)
[2024-12-17 03:50:54,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:55,103][root][INFO] - Training Epoch: 1/2, step 2014/7134 completed (loss: 1.4040251970291138, acc: 0.5889763832092285)
[2024-12-17 03:50:55,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:55,526][root][INFO] - Training Epoch: 1/2, step 2015/7134 completed (loss: 1.4617592096328735, acc: 0.5756579041481018)
[2024-12-17 03:50:55,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:55,962][root][INFO] - Training Epoch: 1/2, step 2016/7134 completed (loss: 1.5978740453720093, acc: 0.5430769324302673)
[2024-12-17 03:50:56,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:56,406][root][INFO] - Training Epoch: 1/2, step 2017/7134 completed (loss: 1.5450624227523804, acc: 0.5621621608734131)
[2024-12-17 03:50:56,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:56,835][root][INFO] - Training Epoch: 1/2, step 2018/7134 completed (loss: 1.4443774223327637, acc: 0.5679486989974976)
[2024-12-17 03:50:56,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:57,311][root][INFO] - Training Epoch: 1/2, step 2019/7134 completed (loss: 1.4386658668518066, acc: 0.569655179977417)
[2024-12-17 03:50:57,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:57,738][root][INFO] - Training Epoch: 1/2, step 2020/7134 completed (loss: 1.4195523262023926, acc: 0.5837563276290894)
[2024-12-17 03:50:57,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:58,176][root][INFO] - Training Epoch: 1/2, step 2021/7134 completed (loss: 1.5239710807800293, acc: 0.5623376369476318)
[2024-12-17 03:50:58,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:58,587][root][INFO] - Training Epoch: 1/2, step 2022/7134 completed (loss: 1.4483022689819336, acc: 0.5753899216651917)
[2024-12-17 03:50:58,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:59,011][root][INFO] - Training Epoch: 1/2, step 2023/7134 completed (loss: 1.4933592081069946, acc: 0.5489051342010498)
[2024-12-17 03:50:59,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:59,448][root][INFO] - Training Epoch: 1/2, step 2024/7134 completed (loss: 1.52518630027771, acc: 0.5555555820465088)
[2024-12-17 03:50:59,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:50:59,881][root][INFO] - Training Epoch: 1/2, step 2025/7134 completed (loss: 1.4574207067489624, acc: 0.5853333473205566)
[2024-12-17 03:50:59,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:00,296][root][INFO] - Training Epoch: 1/2, step 2026/7134 completed (loss: 1.5527658462524414, acc: 0.5451807379722595)
[2024-12-17 03:51:00,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:00,711][root][INFO] - Training Epoch: 1/2, step 2027/7134 completed (loss: 1.4854605197906494, acc: 0.5448504686355591)
[2024-12-17 03:51:00,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:01,132][root][INFO] - Training Epoch: 1/2, step 2028/7134 completed (loss: 1.4370198249816895, acc: 0.5774853825569153)
[2024-12-17 03:51:01,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:01,548][root][INFO] - Training Epoch: 1/2, step 2029/7134 completed (loss: 1.4826549291610718, acc: 0.5653409361839294)
[2024-12-17 03:51:01,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:01,958][root][INFO] - Training Epoch: 1/2, step 2030/7134 completed (loss: 1.4268059730529785, acc: 0.5567484498023987)
[2024-12-17 03:51:02,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:02,404][root][INFO] - Training Epoch: 1/2, step 2031/7134 completed (loss: 1.3866578340530396, acc: 0.5987730026245117)
[2024-12-17 03:51:02,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:02,822][root][INFO] - Training Epoch: 1/2, step 2032/7134 completed (loss: 1.4956450462341309, acc: 0.5645161271095276)
[2024-12-17 03:51:02,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:03,270][root][INFO] - Training Epoch: 1/2, step 2033/7134 completed (loss: 1.4219549894332886, acc: 0.5694682598114014)
[2024-12-17 03:51:03,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:03,673][root][INFO] - Training Epoch: 1/2, step 2034/7134 completed (loss: 1.3592839241027832, acc: 0.6003062725067139)
[2024-12-17 03:51:03,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:04,118][root][INFO] - Training Epoch: 1/2, step 2035/7134 completed (loss: 1.4033071994781494, acc: 0.5965130925178528)
[2024-12-17 03:51:04,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:04,507][root][INFO] - Training Epoch: 1/2, step 2036/7134 completed (loss: 1.4174973964691162, acc: 0.6020761132240295)
[2024-12-17 03:51:04,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:04,946][root][INFO] - Training Epoch: 1/2, step 2037/7134 completed (loss: 1.431756854057312, acc: 0.5919881463050842)
[2024-12-17 03:51:05,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:05,395][root][INFO] - Training Epoch: 1/2, step 2038/7134 completed (loss: 1.3770191669464111, acc: 0.5910165309906006)
[2024-12-17 03:51:05,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:05,814][root][INFO] - Training Epoch: 1/2, step 2039/7134 completed (loss: 1.3733546733856201, acc: 0.5891891717910767)
[2024-12-17 03:51:05,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:06,178][root][INFO] - Training Epoch: 1/2, step 2040/7134 completed (loss: 1.3228641748428345, acc: 0.6275720000267029)
[2024-12-17 03:51:06,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:06,628][root][INFO] - Training Epoch: 1/2, step 2041/7134 completed (loss: 1.3236639499664307, acc: 0.6181318759918213)
[2024-12-17 03:51:06,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:07,035][root][INFO] - Training Epoch: 1/2, step 2042/7134 completed (loss: 1.4567946195602417, acc: 0.5685483813285828)
[2024-12-17 03:51:07,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:07,446][root][INFO] - Training Epoch: 1/2, step 2043/7134 completed (loss: 1.3356473445892334, acc: 0.596875011920929)
[2024-12-17 03:51:07,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:07,877][root][INFO] - Training Epoch: 1/2, step 2044/7134 completed (loss: 1.4208924770355225, acc: 0.584973156452179)
[2024-12-17 03:51:07,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:08,272][root][INFO] - Training Epoch: 1/2, step 2045/7134 completed (loss: 1.4963339567184448, acc: 0.5660036206245422)
[2024-12-17 03:51:08,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:08,628][root][INFO] - Training Epoch: 1/2, step 2046/7134 completed (loss: 1.5430902242660522, acc: 0.5691056847572327)
[2024-12-17 03:51:08,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:09,045][root][INFO] - Training Epoch: 1/2, step 2047/7134 completed (loss: 1.5722204446792603, acc: 0.542570948600769)
[2024-12-17 03:51:09,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:09,463][root][INFO] - Training Epoch: 1/2, step 2048/7134 completed (loss: 1.69292414188385, acc: 0.5396113395690918)
[2024-12-17 03:51:09,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:09,867][root][INFO] - Training Epoch: 1/2, step 2049/7134 completed (loss: 1.5360488891601562, acc: 0.592941164970398)
[2024-12-17 03:51:09,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:10,252][root][INFO] - Training Epoch: 1/2, step 2050/7134 completed (loss: 1.4983667135238647, acc: 0.5470085740089417)
[2024-12-17 03:51:10,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:10,652][root][INFO] - Training Epoch: 1/2, step 2051/7134 completed (loss: 1.488611102104187, acc: 0.568359375)
[2024-12-17 03:51:10,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:11,063][root][INFO] - Training Epoch: 1/2, step 2052/7134 completed (loss: 1.6094088554382324, acc: 0.5443686246871948)
[2024-12-17 03:51:11,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:11,490][root][INFO] - Training Epoch: 1/2, step 2053/7134 completed (loss: 1.6629455089569092, acc: 0.5239999890327454)
[2024-12-17 03:51:11,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:11,919][root][INFO] - Training Epoch: 1/2, step 2054/7134 completed (loss: 1.6336724758148193, acc: 0.5270700454711914)
[2024-12-17 03:51:12,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:12,350][root][INFO] - Training Epoch: 1/2, step 2055/7134 completed (loss: 1.7228046655654907, acc: 0.5086613893508911)
[2024-12-17 03:51:12,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:12,829][root][INFO] - Training Epoch: 1/2, step 2056/7134 completed (loss: 1.6965993642807007, acc: 0.5045395493507385)
[2024-12-17 03:51:12,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:13,260][root][INFO] - Training Epoch: 1/2, step 2057/7134 completed (loss: 1.6497960090637207, acc: 0.5291723012924194)
[2024-12-17 03:51:13,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:13,703][root][INFO] - Training Epoch: 1/2, step 2058/7134 completed (loss: 1.680348515510559, acc: 0.5078909397125244)
[2024-12-17 03:51:13,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:14,129][root][INFO] - Training Epoch: 1/2, step 2059/7134 completed (loss: 1.8241499662399292, acc: 0.4714038074016571)
[2024-12-17 03:51:14,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:14,557][root][INFO] - Training Epoch: 1/2, step 2060/7134 completed (loss: 1.6236422061920166, acc: 0.5207439064979553)
[2024-12-17 03:51:14,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:14,997][root][INFO] - Training Epoch: 1/2, step 2061/7134 completed (loss: 1.5636019706726074, acc: 0.5481586456298828)
[2024-12-17 03:51:15,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:15,408][root][INFO] - Training Epoch: 1/2, step 2062/7134 completed (loss: 1.6953043937683105, acc: 0.5388994216918945)
[2024-12-17 03:51:15,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:15,800][root][INFO] - Training Epoch: 1/2, step 2063/7134 completed (loss: 1.5148288011550903, acc: 0.5746268630027771)
[2024-12-17 03:51:15,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:16,248][root][INFO] - Training Epoch: 1/2, step 2064/7134 completed (loss: 1.324830174446106, acc: 0.6343749761581421)
[2024-12-17 03:51:16,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:16,647][root][INFO] - Training Epoch: 1/2, step 2065/7134 completed (loss: 1.4926576614379883, acc: 0.5511810779571533)
[2024-12-17 03:51:16,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:17,012][root][INFO] - Training Epoch: 1/2, step 2066/7134 completed (loss: 1.4611501693725586, acc: 0.5511022210121155)
[2024-12-17 03:51:17,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:17,421][root][INFO] - Training Epoch: 1/2, step 2067/7134 completed (loss: 1.4585440158843994, acc: 0.5616698265075684)
[2024-12-17 03:51:17,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:17,825][root][INFO] - Training Epoch: 1/2, step 2068/7134 completed (loss: 1.4428387880325317, acc: 0.5620608925819397)
[2024-12-17 03:51:17,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:18,282][root][INFO] - Training Epoch: 1/2, step 2069/7134 completed (loss: 1.4272246360778809, acc: 0.5969230532646179)
[2024-12-17 03:51:18,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:18,682][root][INFO] - Training Epoch: 1/2, step 2070/7134 completed (loss: 1.4762369394302368, acc: 0.5703421831130981)
[2024-12-17 03:51:18,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:19,098][root][INFO] - Training Epoch: 1/2, step 2071/7134 completed (loss: 1.3757692575454712, acc: 0.5854800939559937)
[2024-12-17 03:51:19,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:19,515][root][INFO] - Training Epoch: 1/2, step 2072/7134 completed (loss: 1.4312161207199097, acc: 0.5767326951026917)
[2024-12-17 03:51:19,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:19,901][root][INFO] - Training Epoch: 1/2, step 2073/7134 completed (loss: 1.4976242780685425, acc: 0.5538461804389954)
[2024-12-17 03:51:19,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:20,354][root][INFO] - Training Epoch: 1/2, step 2074/7134 completed (loss: 1.4113433361053467, acc: 0.5727699398994446)
[2024-12-17 03:51:20,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:20,765][root][INFO] - Training Epoch: 1/2, step 2075/7134 completed (loss: 1.5235211849212646, acc: 0.552587628364563)
[2024-12-17 03:51:20,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:21,204][root][INFO] - Training Epoch: 1/2, step 2076/7134 completed (loss: 1.3928149938583374, acc: 0.5723077058792114)
[2024-12-17 03:51:21,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:21,638][root][INFO] - Training Epoch: 1/2, step 2077/7134 completed (loss: 1.384785532951355, acc: 0.5763612389564514)
[2024-12-17 03:51:21,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:22,087][root][INFO] - Training Epoch: 1/2, step 2078/7134 completed (loss: 1.4371596574783325, acc: 0.580232560634613)
[2024-12-17 03:51:22,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:22,524][root][INFO] - Training Epoch: 1/2, step 2079/7134 completed (loss: 1.393747329711914, acc: 0.5753968358039856)
[2024-12-17 03:51:22,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:22,944][root][INFO] - Training Epoch: 1/2, step 2080/7134 completed (loss: 1.4584757089614868, acc: 0.5897058844566345)
[2024-12-17 03:51:23,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:23,376][root][INFO] - Training Epoch: 1/2, step 2081/7134 completed (loss: 1.403572678565979, acc: 0.5849056839942932)
[2024-12-17 03:51:23,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:23,831][root][INFO] - Training Epoch: 1/2, step 2082/7134 completed (loss: 1.3918426036834717, acc: 0.5849056839942932)
[2024-12-17 03:51:23,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:24,213][root][INFO] - Training Epoch: 1/2, step 2083/7134 completed (loss: 1.3908178806304932, acc: 0.5981481671333313)
[2024-12-17 03:51:24,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:24,621][root][INFO] - Training Epoch: 1/2, step 2084/7134 completed (loss: 1.3746848106384277, acc: 0.6055900454521179)
[2024-12-17 03:51:24,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:25,026][root][INFO] - Training Epoch: 1/2, step 2085/7134 completed (loss: 1.3812967538833618, acc: 0.6007393598556519)
[2024-12-17 03:51:25,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:25,424][root][INFO] - Training Epoch: 1/2, step 2086/7134 completed (loss: 1.437699317932129, acc: 0.6004565954208374)
[2024-12-17 03:51:25,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:25,868][root][INFO] - Training Epoch: 1/2, step 2087/7134 completed (loss: 1.4537495374679565, acc: 0.5590327382087708)
[2024-12-17 03:51:25,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:26,301][root][INFO] - Training Epoch: 1/2, step 2088/7134 completed (loss: 1.4105688333511353, acc: 0.5850144028663635)
[2024-12-17 03:51:26,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:26,734][root][INFO] - Training Epoch: 1/2, step 2089/7134 completed (loss: 1.5092488527297974, acc: 0.5757097601890564)
[2024-12-17 03:51:26,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:27,138][root][INFO] - Training Epoch: 1/2, step 2090/7134 completed (loss: 1.3780666589736938, acc: 0.5860979557037354)
[2024-12-17 03:51:27,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:27,572][root][INFO] - Training Epoch: 1/2, step 2091/7134 completed (loss: 1.3144965171813965, acc: 0.6064189076423645)
[2024-12-17 03:51:27,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:28,027][root][INFO] - Training Epoch: 1/2, step 2092/7134 completed (loss: 1.246004343032837, acc: 0.6435331106185913)
[2024-12-17 03:51:28,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:28,510][root][INFO] - Training Epoch: 1/2, step 2093/7134 completed (loss: 1.3482122421264648, acc: 0.611940324306488)
[2024-12-17 03:51:28,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:28,899][root][INFO] - Training Epoch: 1/2, step 2094/7134 completed (loss: 1.536587119102478, acc: 0.545638918876648)
[2024-12-17 03:51:29,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:29,361][root][INFO] - Training Epoch: 1/2, step 2095/7134 completed (loss: 1.4467432498931885, acc: 0.583113431930542)
[2024-12-17 03:51:29,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:29,766][root][INFO] - Training Epoch: 1/2, step 2096/7134 completed (loss: 1.4127116203308105, acc: 0.5896551609039307)
[2024-12-17 03:51:29,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:30,186][root][INFO] - Training Epoch: 1/2, step 2097/7134 completed (loss: 1.4890953302383423, acc: 0.5511921644210815)
[2024-12-17 03:51:30,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:30,606][root][INFO] - Training Epoch: 1/2, step 2098/7134 completed (loss: 1.2560023069381714, acc: 0.6125401854515076)
[2024-12-17 03:51:30,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:31,009][root][INFO] - Training Epoch: 1/2, step 2099/7134 completed (loss: 1.460273265838623, acc: 0.5761467814445496)
[2024-12-17 03:51:31,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:31,449][root][INFO] - Training Epoch: 1/2, step 2100/7134 completed (loss: 1.39016592502594, acc: 0.5949535369873047)
[2024-12-17 03:51:31,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:31,878][root][INFO] - Training Epoch: 1/2, step 2101/7134 completed (loss: 1.5720182657241821, acc: 0.5302267074584961)
[2024-12-17 03:51:32,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:32,315][root][INFO] - Training Epoch: 1/2, step 2102/7134 completed (loss: 1.4793930053710938, acc: 0.5586734414100647)
[2024-12-17 03:51:32,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:32,742][root][INFO] - Training Epoch: 1/2, step 2103/7134 completed (loss: 1.4999347925186157, acc: 0.5628834366798401)
[2024-12-17 03:51:32,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:33,199][root][INFO] - Training Epoch: 1/2, step 2104/7134 completed (loss: 1.4112149477005005, acc: 0.5876288414001465)
[2024-12-17 03:51:33,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:33,617][root][INFO] - Training Epoch: 1/2, step 2105/7134 completed (loss: 1.4469664096832275, acc: 0.5649452209472656)
[2024-12-17 03:51:33,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:34,029][root][INFO] - Training Epoch: 1/2, step 2106/7134 completed (loss: 1.4235340356826782, acc: 0.5804597735404968)
[2024-12-17 03:51:34,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:34,484][root][INFO] - Training Epoch: 1/2, step 2107/7134 completed (loss: 1.4631232023239136, acc: 0.5668016076087952)
[2024-12-17 03:51:34,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:34,928][root][INFO] - Training Epoch: 1/2, step 2108/7134 completed (loss: 1.4113414287567139, acc: 0.5964125394821167)
[2024-12-17 03:51:35,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:35,336][root][INFO] - Training Epoch: 1/2, step 2109/7134 completed (loss: 1.5709831714630127, acc: 0.5573192238807678)
[2024-12-17 03:51:35,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:35,799][root][INFO] - Training Epoch: 1/2, step 2110/7134 completed (loss: 1.586776852607727, acc: 0.5406976938247681)
[2024-12-17 03:51:35,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:36,217][root][INFO] - Training Epoch: 1/2, step 2111/7134 completed (loss: 1.5496069192886353, acc: 0.5473411083221436)
[2024-12-17 03:51:36,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:36,610][root][INFO] - Training Epoch: 1/2, step 2112/7134 completed (loss: 1.4563065767288208, acc: 0.5923566818237305)
[2024-12-17 03:51:36,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:37,022][root][INFO] - Training Epoch: 1/2, step 2113/7134 completed (loss: 1.4479519128799438, acc: 0.5961251854896545)
[2024-12-17 03:51:37,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:37,441][root][INFO] - Training Epoch: 1/2, step 2114/7134 completed (loss: 1.536569595336914, acc: 0.5503268241882324)
[2024-12-17 03:51:37,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:37,884][root][INFO] - Training Epoch: 1/2, step 2115/7134 completed (loss: 1.4950900077819824, acc: 0.5657071471214294)
[2024-12-17 03:51:37,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:38,298][root][INFO] - Training Epoch: 1/2, step 2116/7134 completed (loss: 1.514244556427002, acc: 0.5628834366798401)
[2024-12-17 03:51:38,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:38,726][root][INFO] - Training Epoch: 1/2, step 2117/7134 completed (loss: 1.5098398923873901, acc: 0.5485074520111084)
[2024-12-17 03:51:38,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:39,141][root][INFO] - Training Epoch: 1/2, step 2118/7134 completed (loss: 1.4301897287368774, acc: 0.6030013561248779)
[2024-12-17 03:51:39,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:39,554][root][INFO] - Training Epoch: 1/2, step 2119/7134 completed (loss: 1.4812129735946655, acc: 0.5603674650192261)
[2024-12-17 03:51:39,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:39,978][root][INFO] - Training Epoch: 1/2, step 2120/7134 completed (loss: 1.473737359046936, acc: 0.5707762837409973)
[2024-12-17 03:51:40,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:40,387][root][INFO] - Training Epoch: 1/2, step 2121/7134 completed (loss: 1.4467512369155884, acc: 0.5873016119003296)
[2024-12-17 03:51:40,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:40,825][root][INFO] - Training Epoch: 1/2, step 2122/7134 completed (loss: 1.4245699644088745, acc: 0.5833333134651184)
[2024-12-17 03:51:40,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:41,253][root][INFO] - Training Epoch: 1/2, step 2123/7134 completed (loss: 1.4439481496810913, acc: 0.5864779949188232)
[2024-12-17 03:51:41,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:41,673][root][INFO] - Training Epoch: 1/2, step 2124/7134 completed (loss: 1.4189363718032837, acc: 0.573208749294281)
[2024-12-17 03:51:41,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:42,102][root][INFO] - Training Epoch: 1/2, step 2125/7134 completed (loss: 1.4164669513702393, acc: 0.5848484635353088)
[2024-12-17 03:51:42,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:42,543][root][INFO] - Training Epoch: 1/2, step 2126/7134 completed (loss: 1.5417594909667969, acc: 0.5747899413108826)
[2024-12-17 03:51:42,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:42,961][root][INFO] - Training Epoch: 1/2, step 2127/7134 completed (loss: 1.523058295249939, acc: 0.5516223907470703)
[2024-12-17 03:51:43,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:43,408][root][INFO] - Training Epoch: 1/2, step 2128/7134 completed (loss: 1.5143194198608398, acc: 0.569553792476654)
[2024-12-17 03:51:43,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:43,842][root][INFO] - Training Epoch: 1/2, step 2129/7134 completed (loss: 1.4855549335479736, acc: 0.5610859990119934)
[2024-12-17 03:51:43,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:44,278][root][INFO] - Training Epoch: 1/2, step 2130/7134 completed (loss: 1.4824974536895752, acc: 0.5544554591178894)
[2024-12-17 03:51:44,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:44,728][root][INFO] - Training Epoch: 1/2, step 2131/7134 completed (loss: 1.4396196603775024, acc: 0.5789473652839661)
[2024-12-17 03:51:44,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:45,153][root][INFO] - Training Epoch: 1/2, step 2132/7134 completed (loss: 1.3616924285888672, acc: 0.6051213145256042)
[2024-12-17 03:51:45,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:45,575][root][INFO] - Training Epoch: 1/2, step 2133/7134 completed (loss: 1.4747365713119507, acc: 0.5852047801017761)
[2024-12-17 03:51:45,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:46,006][root][INFO] - Training Epoch: 1/2, step 2134/7134 completed (loss: 1.3984776735305786, acc: 0.586345374584198)
[2024-12-17 03:51:46,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:46,423][root][INFO] - Training Epoch: 1/2, step 2135/7134 completed (loss: 1.4463273286819458, acc: 0.5662650465965271)
[2024-12-17 03:51:46,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:46,852][root][INFO] - Training Epoch: 1/2, step 2136/7134 completed (loss: 1.4661380052566528, acc: 0.5727636814117432)
[2024-12-17 03:51:46,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:47,299][root][INFO] - Training Epoch: 1/2, step 2137/7134 completed (loss: 1.5213592052459717, acc: 0.5561290383338928)
[2024-12-17 03:51:47,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:47,760][root][INFO] - Training Epoch: 1/2, step 2138/7134 completed (loss: 1.3531047105789185, acc: 0.5853658318519592)
[2024-12-17 03:51:47,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:48,204][root][INFO] - Training Epoch: 1/2, step 2139/7134 completed (loss: 1.3393433094024658, acc: 0.6116504669189453)
[2024-12-17 03:51:48,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:48,684][root][INFO] - Training Epoch: 1/2, step 2140/7134 completed (loss: 1.372067928314209, acc: 0.6129476428031921)
[2024-12-17 03:51:48,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:49,077][root][INFO] - Training Epoch: 1/2, step 2141/7134 completed (loss: 1.6937395334243774, acc: 0.47660818696022034)
[2024-12-17 03:51:49,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:49,530][root][INFO] - Training Epoch: 1/2, step 2142/7134 completed (loss: 1.5932844877243042, acc: 0.5396600365638733)
[2024-12-17 03:51:49,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:49,969][root][INFO] - Training Epoch: 1/2, step 2143/7134 completed (loss: 1.538682222366333, acc: 0.5526315569877625)
[2024-12-17 03:51:50,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:50,434][root][INFO] - Training Epoch: 1/2, step 2144/7134 completed (loss: 1.434213638305664, acc: 0.5790172815322876)
[2024-12-17 03:51:50,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:50,886][root][INFO] - Training Epoch: 1/2, step 2145/7134 completed (loss: 1.5517981052398682, acc: 0.552217423915863)
[2024-12-17 03:51:51,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:51,309][root][INFO] - Training Epoch: 1/2, step 2146/7134 completed (loss: 1.4059416055679321, acc: 0.5757042169570923)
[2024-12-17 03:51:51,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:51,782][root][INFO] - Training Epoch: 1/2, step 2147/7134 completed (loss: 1.4436111450195312, acc: 0.5735660791397095)
[2024-12-17 03:51:51,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:52,221][root][INFO] - Training Epoch: 1/2, step 2148/7134 completed (loss: 1.3848158121109009, acc: 0.5895196795463562)
[2024-12-17 03:51:52,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:52,657][root][INFO] - Training Epoch: 1/2, step 2149/7134 completed (loss: 1.391300916671753, acc: 0.6056337952613831)
[2024-12-17 03:51:52,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:53,088][root][INFO] - Training Epoch: 1/2, step 2150/7134 completed (loss: 1.377512812614441, acc: 0.5866666436195374)
[2024-12-17 03:51:53,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:53,507][root][INFO] - Training Epoch: 1/2, step 2151/7134 completed (loss: 1.4242409467697144, acc: 0.5899999737739563)
[2024-12-17 03:51:53,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:53,935][root][INFO] - Training Epoch: 1/2, step 2152/7134 completed (loss: 1.6125963926315308, acc: 0.5422794222831726)
[2024-12-17 03:51:54,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:54,558][root][INFO] - Training Epoch: 1/2, step 2153/7134 completed (loss: 1.4255863428115845, acc: 0.5760266184806824)
[2024-12-17 03:51:54,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:55,050][root][INFO] - Training Epoch: 1/2, step 2154/7134 completed (loss: 1.4796764850616455, acc: 0.5600505471229553)
[2024-12-17 03:51:55,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:55,468][root][INFO] - Training Epoch: 1/2, step 2155/7134 completed (loss: 1.3969401121139526, acc: 0.5851648449897766)
[2024-12-17 03:51:55,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:55,903][root][INFO] - Training Epoch: 1/2, step 2156/7134 completed (loss: 1.4783053398132324, acc: 0.578125)
[2024-12-17 03:51:56,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:56,365][root][INFO] - Training Epoch: 1/2, step 2157/7134 completed (loss: 1.4583714008331299, acc: 0.5653631091117859)
[2024-12-17 03:51:56,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:56,832][root][INFO] - Training Epoch: 1/2, step 2158/7134 completed (loss: 1.4903769493103027, acc: 0.5612244606018066)
[2024-12-17 03:51:56,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:57,287][root][INFO] - Training Epoch: 1/2, step 2159/7134 completed (loss: 1.354993462562561, acc: 0.5772669315338135)
[2024-12-17 03:51:57,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:57,746][root][INFO] - Training Epoch: 1/2, step 2160/7134 completed (loss: 1.3697537183761597, acc: 0.5887207984924316)
[2024-12-17 03:51:57,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:58,228][root][INFO] - Training Epoch: 1/2, step 2161/7134 completed (loss: 1.4779893159866333, acc: 0.577464759349823)
[2024-12-17 03:51:58,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:58,665][root][INFO] - Training Epoch: 1/2, step 2162/7134 completed (loss: 1.4313435554504395, acc: 0.5779122710227966)
[2024-12-17 03:51:58,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:59,125][root][INFO] - Training Epoch: 1/2, step 2163/7134 completed (loss: 1.3153681755065918, acc: 0.5921260118484497)
[2024-12-17 03:51:59,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:51:59,565][root][INFO] - Training Epoch: 1/2, step 2164/7134 completed (loss: 1.4116960763931274, acc: 0.5763293504714966)
[2024-12-17 03:51:59,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:00,025][root][INFO] - Training Epoch: 1/2, step 2165/7134 completed (loss: 1.3929184675216675, acc: 0.5939741730690002)
[2024-12-17 03:52:00,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:00,458][root][INFO] - Training Epoch: 1/2, step 2166/7134 completed (loss: 1.3235775232315063, acc: 0.60546875)
[2024-12-17 03:52:00,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:00,926][root][INFO] - Training Epoch: 1/2, step 2167/7134 completed (loss: 1.3239216804504395, acc: 0.6057906746864319)
[2024-12-17 03:52:01,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:01,356][root][INFO] - Training Epoch: 1/2, step 2168/7134 completed (loss: 1.3434439897537231, acc: 0.5857142806053162)
[2024-12-17 03:52:01,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:01,814][root][INFO] - Training Epoch: 1/2, step 2169/7134 completed (loss: 1.3119308948516846, acc: 0.6102088093757629)
[2024-12-17 03:52:01,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:02,259][root][INFO] - Training Epoch: 1/2, step 2170/7134 completed (loss: 1.4038347005844116, acc: 0.5720524191856384)
[2024-12-17 03:52:02,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:02,737][root][INFO] - Training Epoch: 1/2, step 2171/7134 completed (loss: 1.3700062036514282, acc: 0.6160815358161926)
[2024-12-17 03:52:02,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:03,202][root][INFO] - Training Epoch: 1/2, step 2172/7134 completed (loss: 1.3875129222869873, acc: 0.5929751992225647)
[2024-12-17 03:52:03,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:03,649][root][INFO] - Training Epoch: 1/2, step 2173/7134 completed (loss: 1.4258872270584106, acc: 0.5951661467552185)
[2024-12-17 03:52:03,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:04,096][root][INFO] - Training Epoch: 1/2, step 2174/7134 completed (loss: 1.3468408584594727, acc: 0.609929084777832)
[2024-12-17 03:52:04,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:04,528][root][INFO] - Training Epoch: 1/2, step 2175/7134 completed (loss: 1.2924209833145142, acc: 0.6246537566184998)
[2024-12-17 03:52:04,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:05,010][root][INFO] - Training Epoch: 1/2, step 2176/7134 completed (loss: 1.3416136503219604, acc: 0.6125592589378357)
[2024-12-17 03:52:05,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:05,466][root][INFO] - Training Epoch: 1/2, step 2177/7134 completed (loss: 1.3160231113433838, acc: 0.6064935326576233)
[2024-12-17 03:52:05,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:05,900][root][INFO] - Training Epoch: 1/2, step 2178/7134 completed (loss: 1.2653634548187256, acc: 0.6302428245544434)
[2024-12-17 03:52:05,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:06,345][root][INFO] - Training Epoch: 1/2, step 2179/7134 completed (loss: 1.284830093383789, acc: 0.6341772079467773)
[2024-12-17 03:52:06,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:06,801][root][INFO] - Training Epoch: 1/2, step 2180/7134 completed (loss: 1.3599779605865479, acc: 0.5957446694374084)
[2024-12-17 03:52:06,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:07,282][root][INFO] - Training Epoch: 1/2, step 2181/7134 completed (loss: 1.3915462493896484, acc: 0.6065808534622192)
[2024-12-17 03:52:07,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:07,721][root][INFO] - Training Epoch: 1/2, step 2182/7134 completed (loss: 1.4621117115020752, acc: 0.5824682712554932)
[2024-12-17 03:52:07,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:08,239][root][INFO] - Training Epoch: 1/2, step 2183/7134 completed (loss: 1.2717326879501343, acc: 0.6216530799865723)
[2024-12-17 03:52:08,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:08,695][root][INFO] - Training Epoch: 1/2, step 2184/7134 completed (loss: 1.4555108547210693, acc: 0.5782747864723206)
[2024-12-17 03:52:08,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:09,148][root][INFO] - Training Epoch: 1/2, step 2185/7134 completed (loss: 1.4779051542282104, acc: 0.5481586456298828)
[2024-12-17 03:52:09,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:09,606][root][INFO] - Training Epoch: 1/2, step 2186/7134 completed (loss: 1.4262622594833374, acc: 0.591572105884552)
[2024-12-17 03:52:09,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:10,034][root][INFO] - Training Epoch: 1/2, step 2187/7134 completed (loss: 1.5244767665863037, acc: 0.5856000185012817)
[2024-12-17 03:52:10,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:10,526][root][INFO] - Training Epoch: 1/2, step 2188/7134 completed (loss: 1.3423776626586914, acc: 0.604651153087616)
[2024-12-17 03:52:10,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:10,937][root][INFO] - Training Epoch: 1/2, step 2189/7134 completed (loss: 1.5443302392959595, acc: 0.5535168051719666)
[2024-12-17 03:52:11,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:11,386][root][INFO] - Training Epoch: 1/2, step 2190/7134 completed (loss: 1.4249799251556396, acc: 0.6134564876556396)
[2024-12-17 03:52:11,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:11,779][root][INFO] - Training Epoch: 1/2, step 2191/7134 completed (loss: 1.464165210723877, acc: 0.5636856555938721)
[2024-12-17 03:52:11,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:12,191][root][INFO] - Training Epoch: 1/2, step 2192/7134 completed (loss: 1.4067957401275635, acc: 0.5875706076622009)
[2024-12-17 03:52:12,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:12,656][root][INFO] - Training Epoch: 1/2, step 2193/7134 completed (loss: 1.4132847785949707, acc: 0.583776593208313)
[2024-12-17 03:52:12,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:13,073][root][INFO] - Training Epoch: 1/2, step 2194/7134 completed (loss: 1.5039209127426147, acc: 0.552763819694519)
[2024-12-17 03:52:13,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:13,499][root][INFO] - Training Epoch: 1/2, step 2195/7134 completed (loss: 1.4003595113754272, acc: 0.5871999859809875)
[2024-12-17 03:52:13,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:13,940][root][INFO] - Training Epoch: 1/2, step 2196/7134 completed (loss: 1.3151553869247437, acc: 0.5997409224510193)
[2024-12-17 03:52:14,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:14,339][root][INFO] - Training Epoch: 1/2, step 2197/7134 completed (loss: 1.3921922445297241, acc: 0.5719490051269531)
[2024-12-17 03:52:14,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:14,765][root][INFO] - Training Epoch: 1/2, step 2198/7134 completed (loss: 1.313004970550537, acc: 0.6003016829490662)
[2024-12-17 03:52:14,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:15,198][root][INFO] - Training Epoch: 1/2, step 2199/7134 completed (loss: 1.2783392667770386, acc: 0.6253776550292969)
[2024-12-17 03:52:15,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:15,636][root][INFO] - Training Epoch: 1/2, step 2200/7134 completed (loss: 1.2805023193359375, acc: 0.5858951210975647)
[2024-12-17 03:52:15,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:16,064][root][INFO] - Training Epoch: 1/2, step 2201/7134 completed (loss: 1.2102415561676025, acc: 0.6303030252456665)
[2024-12-17 03:52:16,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:16,491][root][INFO] - Training Epoch: 1/2, step 2202/7134 completed (loss: 1.3262726068496704, acc: 0.6043405532836914)
[2024-12-17 03:52:16,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:16,941][root][INFO] - Training Epoch: 1/2, step 2203/7134 completed (loss: 1.3264118432998657, acc: 0.6054794788360596)
[2024-12-17 03:52:17,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:17,367][root][INFO] - Training Epoch: 1/2, step 2204/7134 completed (loss: 1.2935199737548828, acc: 0.6169590353965759)
[2024-12-17 03:52:17,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:17,796][root][INFO] - Training Epoch: 1/2, step 2205/7134 completed (loss: 1.3087743520736694, acc: 0.582456111907959)
[2024-12-17 03:52:17,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:18,202][root][INFO] - Training Epoch: 1/2, step 2206/7134 completed (loss: 1.3488035202026367, acc: 0.6045694351196289)
[2024-12-17 03:52:18,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:18,619][root][INFO] - Training Epoch: 1/2, step 2207/7134 completed (loss: 1.2565860748291016, acc: 0.6122778654098511)
[2024-12-17 03:52:18,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:19,070][root][INFO] - Training Epoch: 1/2, step 2208/7134 completed (loss: 1.326155185699463, acc: 0.6181818246841431)
[2024-12-17 03:52:19,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:19,503][root][INFO] - Training Epoch: 1/2, step 2209/7134 completed (loss: 1.3206183910369873, acc: 0.6138613820075989)
[2024-12-17 03:52:19,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:19,921][root][INFO] - Training Epoch: 1/2, step 2210/7134 completed (loss: 1.4235388040542603, acc: 0.5857359766960144)
[2024-12-17 03:52:20,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:20,350][root][INFO] - Training Epoch: 1/2, step 2211/7134 completed (loss: 1.3666497468948364, acc: 0.5886426568031311)
[2024-12-17 03:52:20,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:20,778][root][INFO] - Training Epoch: 1/2, step 2212/7134 completed (loss: 1.360433578491211, acc: 0.5930555462837219)
[2024-12-17 03:52:20,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:21,197][root][INFO] - Training Epoch: 1/2, step 2213/7134 completed (loss: 1.390029788017273, acc: 0.5918079018592834)
[2024-12-17 03:52:21,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:21,613][root][INFO] - Training Epoch: 1/2, step 2214/7134 completed (loss: 1.3415240049362183, acc: 0.5880597233772278)
[2024-12-17 03:52:21,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:22,051][root][INFO] - Training Epoch: 1/2, step 2215/7134 completed (loss: 1.31000816822052, acc: 0.6137640476226807)
[2024-12-17 03:52:22,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:22,472][root][INFO] - Training Epoch: 1/2, step 2216/7134 completed (loss: 1.2985618114471436, acc: 0.6234980225563049)
[2024-12-17 03:52:22,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:22,915][root][INFO] - Training Epoch: 1/2, step 2217/7134 completed (loss: 1.1844377517700195, acc: 0.6488169431686401)
[2024-12-17 03:52:23,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:23,320][root][INFO] - Training Epoch: 1/2, step 2218/7134 completed (loss: 1.3943802118301392, acc: 0.5804597735404968)
[2024-12-17 03:52:23,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:23,732][root][INFO] - Training Epoch: 1/2, step 2219/7134 completed (loss: 1.2914787530899048, acc: 0.6336939930915833)
[2024-12-17 03:52:23,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:24,140][root][INFO] - Training Epoch: 1/2, step 2220/7134 completed (loss: 1.3358311653137207, acc: 0.6006289124488831)
[2024-12-17 03:52:24,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:24,610][root][INFO] - Training Epoch: 1/2, step 2221/7134 completed (loss: 1.2504215240478516, acc: 0.6207792162895203)
[2024-12-17 03:52:24,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:25,025][root][INFO] - Training Epoch: 1/2, step 2222/7134 completed (loss: 1.3678295612335205, acc: 0.6040462255477905)
[2024-12-17 03:52:25,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:25,442][root][INFO] - Training Epoch: 1/2, step 2223/7134 completed (loss: 1.265303611755371, acc: 0.6122733354568481)
[2024-12-17 03:52:25,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:25,874][root][INFO] - Training Epoch: 1/2, step 2224/7134 completed (loss: 1.2787292003631592, acc: 0.5939643383026123)
[2024-12-17 03:52:25,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:26,297][root][INFO] - Training Epoch: 1/2, step 2225/7134 completed (loss: 1.390421986579895, acc: 0.6078147888183594)
[2024-12-17 03:52:26,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:26,732][root][INFO] - Training Epoch: 1/2, step 2226/7134 completed (loss: 1.3078058958053589, acc: 0.6133942008018494)
[2024-12-17 03:52:26,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:27,152][root][INFO] - Training Epoch: 1/2, step 2227/7134 completed (loss: 1.2915211915969849, acc: 0.6090775728225708)
[2024-12-17 03:52:27,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:27,542][root][INFO] - Training Epoch: 1/2, step 2228/7134 completed (loss: 1.2547098398208618, acc: 0.6357723474502563)
[2024-12-17 03:52:27,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:27,953][root][INFO] - Training Epoch: 1/2, step 2229/7134 completed (loss: 1.4006646871566772, acc: 0.5960000157356262)
[2024-12-17 03:52:28,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:28,363][root][INFO] - Training Epoch: 1/2, step 2230/7134 completed (loss: 1.2349447011947632, acc: 0.6245954632759094)
[2024-12-17 03:52:28,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:28,764][root][INFO] - Training Epoch: 1/2, step 2231/7134 completed (loss: 1.5739572048187256, acc: 0.541832685470581)
[2024-12-17 03:52:28,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:29,190][root][INFO] - Training Epoch: 1/2, step 2232/7134 completed (loss: 1.3141899108886719, acc: 0.6109625697135925)
[2024-12-17 03:52:29,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:29,614][root][INFO] - Training Epoch: 1/2, step 2233/7134 completed (loss: 1.4701688289642334, acc: 0.566145122051239)
[2024-12-17 03:52:29,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:30,073][root][INFO] - Training Epoch: 1/2, step 2234/7134 completed (loss: 1.3098373413085938, acc: 0.6120218634605408)
[2024-12-17 03:52:30,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:30,494][root][INFO] - Training Epoch: 1/2, step 2235/7134 completed (loss: 1.492712378501892, acc: 0.5485893487930298)
[2024-12-17 03:52:30,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:30,895][root][INFO] - Training Epoch: 1/2, step 2236/7134 completed (loss: 1.3763878345489502, acc: 0.6026986241340637)
[2024-12-17 03:52:31,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:31,327][root][INFO] - Training Epoch: 1/2, step 2237/7134 completed (loss: 1.3375447988510132, acc: 0.608203649520874)
[2024-12-17 03:52:31,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:31,785][root][INFO] - Training Epoch: 1/2, step 2238/7134 completed (loss: 1.4199120998382568, acc: 0.5976845026016235)
[2024-12-17 03:52:31,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:32,232][root][INFO] - Training Epoch: 1/2, step 2239/7134 completed (loss: 1.5964710712432861, acc: 0.5402597188949585)
[2024-12-17 03:52:32,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:32,681][root][INFO] - Training Epoch: 1/2, step 2240/7134 completed (loss: 1.5728346109390259, acc: 0.5415584444999695)
[2024-12-17 03:52:32,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:33,106][root][INFO] - Training Epoch: 1/2, step 2241/7134 completed (loss: 1.4098666906356812, acc: 0.5957446694374084)
[2024-12-17 03:52:33,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:33,548][root][INFO] - Training Epoch: 1/2, step 2242/7134 completed (loss: 1.5440410375595093, acc: 0.5581947565078735)
[2024-12-17 03:52:33,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:34,027][root][INFO] - Training Epoch: 1/2, step 2243/7134 completed (loss: 1.6070834398269653, acc: 0.5328244566917419)
[2024-12-17 03:52:34,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:34,487][root][INFO] - Training Epoch: 1/2, step 2244/7134 completed (loss: 1.67946195602417, acc: 0.5377358198165894)
[2024-12-17 03:52:34,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:34,901][root][INFO] - Training Epoch: 1/2, step 2245/7134 completed (loss: 1.5053439140319824, acc: 0.5517799258232117)
[2024-12-17 03:52:35,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:35,348][root][INFO] - Training Epoch: 1/2, step 2246/7134 completed (loss: 1.6821726560592651, acc: 0.5310810804367065)
[2024-12-17 03:52:35,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:35,784][root][INFO] - Training Epoch: 1/2, step 2247/7134 completed (loss: 1.757157564163208, acc: 0.4655172526836395)
[2024-12-17 03:52:35,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:36,239][root][INFO] - Training Epoch: 1/2, step 2248/7134 completed (loss: 1.5801658630371094, acc: 0.5062240958213806)
[2024-12-17 03:52:36,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:36,682][root][INFO] - Training Epoch: 1/2, step 2249/7134 completed (loss: 1.5239752531051636, acc: 0.5530726313591003)
[2024-12-17 03:52:36,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:37,128][root][INFO] - Training Epoch: 1/2, step 2250/7134 completed (loss: 1.5842102766036987, acc: 0.5628342032432556)
[2024-12-17 03:52:37,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:37,516][root][INFO] - Training Epoch: 1/2, step 2251/7134 completed (loss: 1.4876561164855957, acc: 0.5714285969734192)
[2024-12-17 03:52:37,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:37,938][root][INFO] - Training Epoch: 1/2, step 2252/7134 completed (loss: 1.4945931434631348, acc: 0.5672268867492676)
[2024-12-17 03:52:38,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:38,357][root][INFO] - Training Epoch: 1/2, step 2253/7134 completed (loss: 1.4858028888702393, acc: 0.5418060421943665)
[2024-12-17 03:52:38,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:38,751][root][INFO] - Training Epoch: 1/2, step 2254/7134 completed (loss: 1.613213300704956, acc: 0.5358565449714661)
[2024-12-17 03:52:38,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:39,179][root][INFO] - Training Epoch: 1/2, step 2255/7134 completed (loss: 1.372038722038269, acc: 0.5963581204414368)
[2024-12-17 03:52:39,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:39,560][root][INFO] - Training Epoch: 1/2, step 2256/7134 completed (loss: 1.6166374683380127, acc: 0.528761088848114)
[2024-12-17 03:52:39,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:39,997][root][INFO] - Training Epoch: 1/2, step 2257/7134 completed (loss: 1.4051295518875122, acc: 0.5891238451004028)
[2024-12-17 03:52:40,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:40,406][root][INFO] - Training Epoch: 1/2, step 2258/7134 completed (loss: 1.4344494342803955, acc: 0.5711538195610046)
[2024-12-17 03:52:40,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:40,807][root][INFO] - Training Epoch: 1/2, step 2259/7134 completed (loss: 1.457366704940796, acc: 0.5666666626930237)
[2024-12-17 03:52:40,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:41,217][root][INFO] - Training Epoch: 1/2, step 2260/7134 completed (loss: 1.5821385383605957, acc: 0.5469697117805481)
[2024-12-17 03:52:41,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:41,612][root][INFO] - Training Epoch: 1/2, step 2261/7134 completed (loss: 1.4540642499923706, acc: 0.5729926824569702)
[2024-12-17 03:52:41,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:42,014][root][INFO] - Training Epoch: 1/2, step 2262/7134 completed (loss: 1.4266035556793213, acc: 0.589318573474884)
[2024-12-17 03:52:42,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:42,434][root][INFO] - Training Epoch: 1/2, step 2263/7134 completed (loss: 1.4509133100509644, acc: 0.5891891717910767)
[2024-12-17 03:52:42,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:42,853][root][INFO] - Training Epoch: 1/2, step 2264/7134 completed (loss: 1.5275566577911377, acc: 0.5625879168510437)
[2024-12-17 03:52:42,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:43,291][root][INFO] - Training Epoch: 1/2, step 2265/7134 completed (loss: 1.5704145431518555, acc: 0.524055004119873)
[2024-12-17 03:52:43,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:43,727][root][INFO] - Training Epoch: 1/2, step 2266/7134 completed (loss: 1.4258317947387695, acc: 0.5817694664001465)
[2024-12-17 03:52:43,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:44,135][root][INFO] - Training Epoch: 1/2, step 2267/7134 completed (loss: 1.4440181255340576, acc: 0.5987654328346252)
[2024-12-17 03:52:44,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:44,588][root][INFO] - Training Epoch: 1/2, step 2268/7134 completed (loss: 1.471388578414917, acc: 0.5638450384140015)
[2024-12-17 03:52:44,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:45,037][root][INFO] - Training Epoch: 1/2, step 2269/7134 completed (loss: 1.4075510501861572, acc: 0.5874213576316833)
[2024-12-17 03:52:45,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:45,470][root][INFO] - Training Epoch: 1/2, step 2270/7134 completed (loss: 1.5171438455581665, acc: 0.5638474225997925)
[2024-12-17 03:52:45,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:45,937][root][INFO] - Training Epoch: 1/2, step 2271/7134 completed (loss: 1.563713550567627, acc: 0.5397008061408997)
[2024-12-17 03:52:46,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:46,420][root][INFO] - Training Epoch: 1/2, step 2272/7134 completed (loss: 1.5599819421768188, acc: 0.5427873134613037)
[2024-12-17 03:52:46,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:46,870][root][INFO] - Training Epoch: 1/2, step 2273/7134 completed (loss: 1.4346976280212402, acc: 0.5796407461166382)
[2024-12-17 03:52:46,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:47,327][root][INFO] - Training Epoch: 1/2, step 2274/7134 completed (loss: 1.5756478309631348, acc: 0.5528662204742432)
[2024-12-17 03:52:47,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:47,778][root][INFO] - Training Epoch: 1/2, step 2275/7134 completed (loss: 1.4769536256790161, acc: 0.565727710723877)
[2024-12-17 03:52:47,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:48,256][root][INFO] - Training Epoch: 1/2, step 2276/7134 completed (loss: 1.4777657985687256, acc: 0.571090042591095)
[2024-12-17 03:52:48,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:48,719][root][INFO] - Training Epoch: 1/2, step 2277/7134 completed (loss: 1.4525647163391113, acc: 0.568129301071167)
[2024-12-17 03:52:48,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:49,158][root][INFO] - Training Epoch: 1/2, step 2278/7134 completed (loss: 1.592312216758728, acc: 0.5543131232261658)
[2024-12-17 03:52:49,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:49,603][root][INFO] - Training Epoch: 1/2, step 2279/7134 completed (loss: 1.4353481531143188, acc: 0.5785123705863953)
[2024-12-17 03:52:49,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:50,064][root][INFO] - Training Epoch: 1/2, step 2280/7134 completed (loss: 1.5089926719665527, acc: 0.5560802817344666)
[2024-12-17 03:52:50,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:50,495][root][INFO] - Training Epoch: 1/2, step 2281/7134 completed (loss: 1.4702192544937134, acc: 0.5733333230018616)
[2024-12-17 03:52:50,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:50,943][root][INFO] - Training Epoch: 1/2, step 2282/7134 completed (loss: 1.4392168521881104, acc: 0.572311520576477)
[2024-12-17 03:52:51,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:51,386][root][INFO] - Training Epoch: 1/2, step 2283/7134 completed (loss: 1.486136794090271, acc: 0.5696821808815002)
[2024-12-17 03:52:51,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:51,834][root][INFO] - Training Epoch: 1/2, step 2284/7134 completed (loss: 1.4385570287704468, acc: 0.5775480270385742)
[2024-12-17 03:52:51,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:52,308][root][INFO] - Training Epoch: 1/2, step 2285/7134 completed (loss: 1.4463602304458618, acc: 0.5752508640289307)
[2024-12-17 03:52:52,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:52,751][root][INFO] - Training Epoch: 1/2, step 2286/7134 completed (loss: 1.496826171875, acc: 0.5434500575065613)
[2024-12-17 03:52:52,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:53,220][root][INFO] - Training Epoch: 1/2, step 2287/7134 completed (loss: 1.3727543354034424, acc: 0.5764074921607971)
[2024-12-17 03:52:53,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:53,678][root][INFO] - Training Epoch: 1/2, step 2288/7134 completed (loss: 1.397914171218872, acc: 0.5783274173736572)
[2024-12-17 03:52:53,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:54,105][root][INFO] - Training Epoch: 1/2, step 2289/7134 completed (loss: 1.4026769399642944, acc: 0.5789473652839661)
[2024-12-17 03:52:54,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:54,535][root][INFO] - Training Epoch: 1/2, step 2290/7134 completed (loss: 1.4968137741088867, acc: 0.5668789744377136)
[2024-12-17 03:52:54,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:54,981][root][INFO] - Training Epoch: 1/2, step 2291/7134 completed (loss: 1.4486583471298218, acc: 0.5748987793922424)
[2024-12-17 03:52:55,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:55,414][root][INFO] - Training Epoch: 1/2, step 2292/7134 completed (loss: 1.5413049459457397, acc: 0.5496774315834045)
[2024-12-17 03:52:55,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:55,881][root][INFO] - Training Epoch: 1/2, step 2293/7134 completed (loss: 1.3909255266189575, acc: 0.602449893951416)
[2024-12-17 03:52:55,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:56,320][root][INFO] - Training Epoch: 1/2, step 2294/7134 completed (loss: 1.5017033815383911, acc: 0.5568053722381592)
[2024-12-17 03:52:56,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:56,827][root][INFO] - Training Epoch: 1/2, step 2295/7134 completed (loss: 1.6018074750900269, acc: 0.5498575568199158)
[2024-12-17 03:52:56,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:57,296][root][INFO] - Training Epoch: 1/2, step 2296/7134 completed (loss: 1.3828905820846558, acc: 0.5968084931373596)
[2024-12-17 03:52:57,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:57,785][root][INFO] - Training Epoch: 1/2, step 2297/7134 completed (loss: 1.4272267818450928, acc: 0.602642297744751)
[2024-12-17 03:52:57,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:58,231][root][INFO] - Training Epoch: 1/2, step 2298/7134 completed (loss: 1.4347038269042969, acc: 0.569926381111145)
[2024-12-17 03:52:58,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:58,730][root][INFO] - Training Epoch: 1/2, step 2299/7134 completed (loss: 1.498184323310852, acc: 0.5540387034416199)
[2024-12-17 03:52:58,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:59,202][root][INFO] - Training Epoch: 1/2, step 2300/7134 completed (loss: 1.430202603340149, acc: 0.5749717950820923)
[2024-12-17 03:52:59,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:52:59,674][root][INFO] - Training Epoch: 1/2, step 2301/7134 completed (loss: 1.5266499519348145, acc: 0.5774834156036377)
[2024-12-17 03:52:59,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:00,134][root][INFO] - Training Epoch: 1/2, step 2302/7134 completed (loss: 1.5027493238449097, acc: 0.5674019455909729)
[2024-12-17 03:53:00,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:00,566][root][INFO] - Training Epoch: 1/2, step 2303/7134 completed (loss: 1.4468532800674438, acc: 0.6002277731895447)
[2024-12-17 03:53:00,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:01,031][root][INFO] - Training Epoch: 1/2, step 2304/7134 completed (loss: 1.4278734922409058, acc: 0.5899280309677124)
[2024-12-17 03:53:01,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:01,502][root][INFO] - Training Epoch: 1/2, step 2305/7134 completed (loss: 1.4983208179473877, acc: 0.5740149021148682)
[2024-12-17 03:53:01,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:01,955][root][INFO] - Training Epoch: 1/2, step 2306/7134 completed (loss: 1.409003734588623, acc: 0.601995587348938)
[2024-12-17 03:53:02,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:02,421][root][INFO] - Training Epoch: 1/2, step 2307/7134 completed (loss: 1.4356274604797363, acc: 0.5878099203109741)
[2024-12-17 03:53:02,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:02,889][root][INFO] - Training Epoch: 1/2, step 2308/7134 completed (loss: 1.4439369440078735, acc: 0.5791624188423157)
[2024-12-17 03:53:03,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:03,333][root][INFO] - Training Epoch: 1/2, step 2309/7134 completed (loss: 1.2934871912002563, acc: 0.623501181602478)
[2024-12-17 03:53:03,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:03,775][root][INFO] - Training Epoch: 1/2, step 2310/7134 completed (loss: 1.3597707748413086, acc: 0.592090368270874)
[2024-12-17 03:53:03,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:04,220][root][INFO] - Training Epoch: 1/2, step 2311/7134 completed (loss: 1.2957260608673096, acc: 0.6066513657569885)
[2024-12-17 03:53:04,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:04,687][root][INFO] - Training Epoch: 1/2, step 2312/7134 completed (loss: 1.3931158781051636, acc: 0.5885528922080994)
[2024-12-17 03:53:04,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:05,146][root][INFO] - Training Epoch: 1/2, step 2313/7134 completed (loss: 1.4221570491790771, acc: 0.5993150472640991)
[2024-12-17 03:53:05,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:05,618][root][INFO] - Training Epoch: 1/2, step 2314/7134 completed (loss: 1.2967214584350586, acc: 0.6326304078102112)
[2024-12-17 03:53:05,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:06,105][root][INFO] - Training Epoch: 1/2, step 2315/7134 completed (loss: 1.3767796754837036, acc: 0.5964705944061279)
[2024-12-17 03:53:06,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:06,556][root][INFO] - Training Epoch: 1/2, step 2316/7134 completed (loss: 1.323153018951416, acc: 0.6121979355812073)
[2024-12-17 03:53:06,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:07,062][root][INFO] - Training Epoch: 1/2, step 2317/7134 completed (loss: 1.3252135515213013, acc: 0.6253968477249146)
[2024-12-17 03:53:07,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:07,542][root][INFO] - Training Epoch: 1/2, step 2318/7134 completed (loss: 1.2474241256713867, acc: 0.6359832882881165)
[2024-12-17 03:53:07,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:08,001][root][INFO] - Training Epoch: 1/2, step 2319/7134 completed (loss: 1.2416212558746338, acc: 0.6433260440826416)
[2024-12-17 03:53:08,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:08,463][root][INFO] - Training Epoch: 1/2, step 2320/7134 completed (loss: 1.2633918523788452, acc: 0.6147727370262146)
[2024-12-17 03:53:08,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:08,887][root][INFO] - Training Epoch: 1/2, step 2321/7134 completed (loss: 1.3912508487701416, acc: 0.5902777910232544)
[2024-12-17 03:53:08,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:09,320][root][INFO] - Training Epoch: 1/2, step 2322/7134 completed (loss: 1.402997374534607, acc: 0.5703703761100769)
[2024-12-17 03:53:09,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:09,752][root][INFO] - Training Epoch: 1/2, step 2323/7134 completed (loss: 1.5860987901687622, acc: 0.5362775921821594)
[2024-12-17 03:53:09,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:10,225][root][INFO] - Training Epoch: 1/2, step 2324/7134 completed (loss: 1.4579318761825562, acc: 0.5840455889701843)
[2024-12-17 03:53:10,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:10,658][root][INFO] - Training Epoch: 1/2, step 2325/7134 completed (loss: 1.5069431066513062, acc: 0.5538461804389954)
[2024-12-17 03:53:10,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:11,066][root][INFO] - Training Epoch: 1/2, step 2326/7134 completed (loss: 1.3705388307571411, acc: 0.59375)
[2024-12-17 03:53:11,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:11,463][root][INFO] - Training Epoch: 1/2, step 2327/7134 completed (loss: 1.4027036428451538, acc: 0.5688524842262268)
[2024-12-17 03:53:11,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:11,882][root][INFO] - Training Epoch: 1/2, step 2328/7134 completed (loss: 1.422168493270874, acc: 0.6003584265708923)
[2024-12-17 03:53:11,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:12,295][root][INFO] - Training Epoch: 1/2, step 2329/7134 completed (loss: 1.4245002269744873, acc: 0.5860465168952942)
[2024-12-17 03:53:12,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:12,694][root][INFO] - Training Epoch: 1/2, step 2330/7134 completed (loss: 1.4237971305847168, acc: 0.5847328305244446)
[2024-12-17 03:53:12,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:13,120][root][INFO] - Training Epoch: 1/2, step 2331/7134 completed (loss: 1.399255394935608, acc: 0.5720859169960022)
[2024-12-17 03:53:13,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:13,551][root][INFO] - Training Epoch: 1/2, step 2332/7134 completed (loss: 1.3823559284210205, acc: 0.5958395004272461)
[2024-12-17 03:53:13,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:13,983][root][INFO] - Training Epoch: 1/2, step 2333/7134 completed (loss: 1.3695051670074463, acc: 0.5997023582458496)
[2024-12-17 03:53:14,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:14,404][root][INFO] - Training Epoch: 1/2, step 2334/7134 completed (loss: 1.3493733406066895, acc: 0.6014925241470337)
[2024-12-17 03:53:14,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:14,848][root][INFO] - Training Epoch: 1/2, step 2335/7134 completed (loss: 1.3966721296310425, acc: 0.5951613187789917)
[2024-12-17 03:53:14,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:15,261][root][INFO] - Training Epoch: 1/2, step 2336/7134 completed (loss: 1.3534834384918213, acc: 0.6089644432067871)
[2024-12-17 03:53:15,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:15,692][root][INFO] - Training Epoch: 1/2, step 2337/7134 completed (loss: 1.4259183406829834, acc: 0.5815485715866089)
[2024-12-17 03:53:15,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:16,112][root][INFO] - Training Epoch: 1/2, step 2338/7134 completed (loss: 1.355141282081604, acc: 0.5950540900230408)
[2024-12-17 03:53:16,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:16,541][root][INFO] - Training Epoch: 1/2, step 2339/7134 completed (loss: 1.4300581216812134, acc: 0.5807504057884216)
[2024-12-17 03:53:16,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:16,968][root][INFO] - Training Epoch: 1/2, step 2340/7134 completed (loss: 1.3828321695327759, acc: 0.5942685008049011)
[2024-12-17 03:53:17,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:17,387][root][INFO] - Training Epoch: 1/2, step 2341/7134 completed (loss: 1.4480352401733398, acc: 0.5827067494392395)
[2024-12-17 03:53:17,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:17,802][root][INFO] - Training Epoch: 1/2, step 2342/7134 completed (loss: 1.4132258892059326, acc: 0.5819793343544006)
[2024-12-17 03:53:17,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:18,231][root][INFO] - Training Epoch: 1/2, step 2343/7134 completed (loss: 1.4689762592315674, acc: 0.5680000185966492)
[2024-12-17 03:53:18,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:18,689][root][INFO] - Training Epoch: 1/2, step 2344/7134 completed (loss: 1.5047751665115356, acc: 0.5633803009986877)
[2024-12-17 03:53:18,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:19,114][root][INFO] - Training Epoch: 1/2, step 2345/7134 completed (loss: 1.469323992729187, acc: 0.5860139727592468)
[2024-12-17 03:53:19,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:19,562][root][INFO] - Training Epoch: 1/2, step 2346/7134 completed (loss: 1.3803426027297974, acc: 0.6048158407211304)
[2024-12-17 03:53:19,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:19,982][root][INFO] - Training Epoch: 1/2, step 2347/7134 completed (loss: 1.3913453817367554, acc: 0.5723684430122375)
[2024-12-17 03:53:20,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:20,424][root][INFO] - Training Epoch: 1/2, step 2348/7134 completed (loss: 1.62267005443573, acc: 0.5220680832862854)
[2024-12-17 03:53:20,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:20,846][root][INFO] - Training Epoch: 1/2, step 2349/7134 completed (loss: 1.5894029140472412, acc: 0.5236111283302307)
[2024-12-17 03:53:20,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:21,315][root][INFO] - Training Epoch: 1/2, step 2350/7134 completed (loss: 1.6618226766586304, acc: 0.5)
[2024-12-17 03:53:21,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:21,758][root][INFO] - Training Epoch: 1/2, step 2351/7134 completed (loss: 1.506308674812317, acc: 0.5601093173027039)
[2024-12-17 03:53:21,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:22,165][root][INFO] - Training Epoch: 1/2, step 2352/7134 completed (loss: 1.6278878450393677, acc: 0.5144230723381042)
[2024-12-17 03:53:22,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:22,614][root][INFO] - Training Epoch: 1/2, step 2353/7134 completed (loss: 1.5324121713638306, acc: 0.5276595950126648)
[2024-12-17 03:53:22,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:23,043][root][INFO] - Training Epoch: 1/2, step 2354/7134 completed (loss: 1.4667831659317017, acc: 0.5797468423843384)
[2024-12-17 03:53:23,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:23,478][root][INFO] - Training Epoch: 1/2, step 2355/7134 completed (loss: 1.5561293363571167, acc: 0.5469135642051697)
[2024-12-17 03:53:23,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:23,885][root][INFO] - Training Epoch: 1/2, step 2356/7134 completed (loss: 1.5945402383804321, acc: 0.5318021178245544)
[2024-12-17 03:53:23,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:24,287][root][INFO] - Training Epoch: 1/2, step 2357/7134 completed (loss: 1.6737475395202637, acc: 0.5158730149269104)
[2024-12-17 03:53:24,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:24,739][root][INFO] - Training Epoch: 1/2, step 2358/7134 completed (loss: 1.5228228569030762, acc: 0.5602409839630127)
[2024-12-17 03:53:24,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:25,173][root][INFO] - Training Epoch: 1/2, step 2359/7134 completed (loss: 1.4804151058197021, acc: 0.5785609483718872)
[2024-12-17 03:53:25,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:25,651][root][INFO] - Training Epoch: 1/2, step 2360/7134 completed (loss: 1.4373594522476196, acc: 0.5812591314315796)
[2024-12-17 03:53:25,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:26,092][root][INFO] - Training Epoch: 1/2, step 2361/7134 completed (loss: 1.4303843975067139, acc: 0.5769230723381042)
[2024-12-17 03:53:26,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:26,466][root][INFO] - Training Epoch: 1/2, step 2362/7134 completed (loss: 1.3729832172393799, acc: 0.605381190776825)
[2024-12-17 03:53:26,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:26,949][root][INFO] - Training Epoch: 1/2, step 2363/7134 completed (loss: 1.4303587675094604, acc: 0.5816918015480042)
[2024-12-17 03:53:27,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:27,370][root][INFO] - Training Epoch: 1/2, step 2364/7134 completed (loss: 1.3546677827835083, acc: 0.6012176275253296)
[2024-12-17 03:53:27,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:27,784][root][INFO] - Training Epoch: 1/2, step 2365/7134 completed (loss: 1.3662790060043335, acc: 0.5950413346290588)
[2024-12-17 03:53:27,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:28,221][root][INFO] - Training Epoch: 1/2, step 2366/7134 completed (loss: 1.334197998046875, acc: 0.59375)
[2024-12-17 03:53:28,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:28,680][root][INFO] - Training Epoch: 1/2, step 2367/7134 completed (loss: 1.3854143619537354, acc: 0.5854271650314331)
[2024-12-17 03:53:28,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:29,132][root][INFO] - Training Epoch: 1/2, step 2368/7134 completed (loss: 1.380384087562561, acc: 0.5939394235610962)
[2024-12-17 03:53:29,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:29,600][root][INFO] - Training Epoch: 1/2, step 2369/7134 completed (loss: 1.4082058668136597, acc: 0.5788235068321228)
[2024-12-17 03:53:29,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:29,977][root][INFO] - Training Epoch: 1/2, step 2370/7134 completed (loss: 1.2840263843536377, acc: 0.5987654328346252)
[2024-12-17 03:53:30,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:30,430][root][INFO] - Training Epoch: 1/2, step 2371/7134 completed (loss: 1.447047233581543, acc: 0.579250693321228)
[2024-12-17 03:53:30,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:30,874][root][INFO] - Training Epoch: 1/2, step 2372/7134 completed (loss: 1.2749850749969482, acc: 0.6190476417541504)
[2024-12-17 03:53:30,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:31,301][root][INFO] - Training Epoch: 1/2, step 2373/7134 completed (loss: 1.3523368835449219, acc: 0.5980148911476135)
[2024-12-17 03:53:31,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:31,729][root][INFO] - Training Epoch: 1/2, step 2374/7134 completed (loss: 1.4108772277832031, acc: 0.5983935594558716)
[2024-12-17 03:53:31,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:32,182][root][INFO] - Training Epoch: 1/2, step 2375/7134 completed (loss: 1.4084672927856445, acc: 0.5787878632545471)
[2024-12-17 03:53:32,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:32,605][root][INFO] - Training Epoch: 1/2, step 2376/7134 completed (loss: 1.5451929569244385, acc: 0.5536627173423767)
[2024-12-17 03:53:32,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:33,050][root][INFO] - Training Epoch: 1/2, step 2377/7134 completed (loss: 1.531291127204895, acc: 0.5555555820465088)
[2024-12-17 03:53:33,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:33,484][root][INFO] - Training Epoch: 1/2, step 2378/7134 completed (loss: 1.489641547203064, acc: 0.5434272289276123)
[2024-12-17 03:53:33,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:33,930][root][INFO] - Training Epoch: 1/2, step 2379/7134 completed (loss: 1.550262212753296, acc: 0.5572413802146912)
[2024-12-17 03:53:34,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:34,370][root][INFO] - Training Epoch: 1/2, step 2380/7134 completed (loss: 1.5783658027648926, acc: 0.5308343172073364)
[2024-12-17 03:53:34,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:34,753][root][INFO] - Training Epoch: 1/2, step 2381/7134 completed (loss: 1.7610398530960083, acc: 0.5126903653144836)
[2024-12-17 03:53:34,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:35,199][root][INFO] - Training Epoch: 1/2, step 2382/7134 completed (loss: 1.4590122699737549, acc: 0.5642201900482178)
[2024-12-17 03:53:35,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:35,608][root][INFO] - Training Epoch: 1/2, step 2383/7134 completed (loss: 1.552536964416504, acc: 0.5444947481155396)
[2024-12-17 03:53:35,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:36,037][root][INFO] - Training Epoch: 1/2, step 2384/7134 completed (loss: 1.582969069480896, acc: 0.529411792755127)
[2024-12-17 03:53:36,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:36,497][root][INFO] - Training Epoch: 1/2, step 2385/7134 completed (loss: 1.5055224895477295, acc: 0.560773491859436)
[2024-12-17 03:53:36,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:36,917][root][INFO] - Training Epoch: 1/2, step 2386/7134 completed (loss: 1.583950161933899, acc: 0.551047146320343)
[2024-12-17 03:53:37,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:37,384][root][INFO] - Training Epoch: 1/2, step 2387/7134 completed (loss: 1.4591244459152222, acc: 0.5522041916847229)
[2024-12-17 03:53:37,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:37,824][root][INFO] - Training Epoch: 1/2, step 2388/7134 completed (loss: 1.5588635206222534, acc: 0.5566149950027466)
[2024-12-17 03:53:37,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:38,319][root][INFO] - Training Epoch: 1/2, step 2389/7134 completed (loss: 1.4740667343139648, acc: 0.5545350313186646)
[2024-12-17 03:53:38,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:38,761][root][INFO] - Training Epoch: 1/2, step 2390/7134 completed (loss: 1.5444214344024658, acc: 0.5471923351287842)
[2024-12-17 03:53:38,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:39,186][root][INFO] - Training Epoch: 1/2, step 2391/7134 completed (loss: 1.5206525325775146, acc: 0.5438373684883118)
[2024-12-17 03:53:39,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:39,619][root][INFO] - Training Epoch: 1/2, step 2392/7134 completed (loss: 1.4544363021850586, acc: 0.5740988254547119)
[2024-12-17 03:53:39,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:40,049][root][INFO] - Training Epoch: 1/2, step 2393/7134 completed (loss: 1.482315182685852, acc: 0.5629053115844727)
[2024-12-17 03:53:40,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:40,502][root][INFO] - Training Epoch: 1/2, step 2394/7134 completed (loss: 1.532236933708191, acc: 0.539393961429596)
[2024-12-17 03:53:40,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:40,923][root][INFO] - Training Epoch: 1/2, step 2395/7134 completed (loss: 1.6171891689300537, acc: 0.5407165884971619)
[2024-12-17 03:53:41,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:41,389][root][INFO] - Training Epoch: 1/2, step 2396/7134 completed (loss: 1.5971133708953857, acc: 0.5509641766548157)
[2024-12-17 03:53:41,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:41,776][root][INFO] - Training Epoch: 1/2, step 2397/7134 completed (loss: 1.6423553228378296, acc: 0.5196506381034851)
[2024-12-17 03:53:41,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:42,205][root][INFO] - Training Epoch: 1/2, step 2398/7134 completed (loss: 1.4442707300186157, acc: 0.5722146034240723)
[2024-12-17 03:53:42,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:42,634][root][INFO] - Training Epoch: 1/2, step 2399/7134 completed (loss: 1.552625060081482, acc: 0.5207439064979553)
[2024-12-17 03:53:42,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:43,089][root][INFO] - Training Epoch: 1/2, step 2400/7134 completed (loss: 1.5042670965194702, acc: 0.5600000023841858)
[2024-12-17 03:53:43,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:43,503][root][INFO] - Training Epoch: 1/2, step 2401/7134 completed (loss: 1.600365400314331, acc: 0.550632894039154)
[2024-12-17 03:53:43,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:43,938][root][INFO] - Training Epoch: 1/2, step 2402/7134 completed (loss: 1.531702995300293, acc: 0.5471447706222534)
[2024-12-17 03:53:44,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:44,367][root][INFO] - Training Epoch: 1/2, step 2403/7134 completed (loss: 1.5014625787734985, acc: 0.5432624220848083)
[2024-12-17 03:53:44,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:44,800][root][INFO] - Training Epoch: 1/2, step 2404/7134 completed (loss: 1.3403717279434204, acc: 0.6215847134590149)
[2024-12-17 03:53:44,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:45,257][root][INFO] - Training Epoch: 1/2, step 2405/7134 completed (loss: 1.4694013595581055, acc: 0.5568562150001526)
[2024-12-17 03:53:45,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:45,683][root][INFO] - Training Epoch: 1/2, step 2406/7134 completed (loss: 1.386379361152649, acc: 0.5797872543334961)
[2024-12-17 03:53:45,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:46,123][root][INFO] - Training Epoch: 1/2, step 2407/7134 completed (loss: 1.4032373428344727, acc: 0.5987842082977295)
[2024-12-17 03:53:46,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:46,560][root][INFO] - Training Epoch: 1/2, step 2408/7134 completed (loss: 1.3422572612762451, acc: 0.6131578683853149)
[2024-12-17 03:53:46,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:46,989][root][INFO] - Training Epoch: 1/2, step 2409/7134 completed (loss: 1.416148066520691, acc: 0.5983606576919556)
[2024-12-17 03:53:47,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:47,404][root][INFO] - Training Epoch: 1/2, step 2410/7134 completed (loss: 1.443907380104065, acc: 0.5738880634307861)
[2024-12-17 03:53:47,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:47,837][root][INFO] - Training Epoch: 1/2, step 2411/7134 completed (loss: 1.4159340858459473, acc: 0.6015523672103882)
[2024-12-17 03:53:47,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:48,255][root][INFO] - Training Epoch: 1/2, step 2412/7134 completed (loss: 1.3667423725128174, acc: 0.6038461327552795)
[2024-12-17 03:53:48,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:48,693][root][INFO] - Training Epoch: 1/2, step 2413/7134 completed (loss: 1.3287343978881836, acc: 0.6264294981956482)
[2024-12-17 03:53:48,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:49,152][root][INFO] - Training Epoch: 1/2, step 2414/7134 completed (loss: 1.3678675889968872, acc: 0.5982587337493896)
[2024-12-17 03:53:49,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:49,617][root][INFO] - Training Epoch: 1/2, step 2415/7134 completed (loss: 1.4216837882995605, acc: 0.5843621492385864)
[2024-12-17 03:53:49,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:50,090][root][INFO] - Training Epoch: 1/2, step 2416/7134 completed (loss: 1.3997858762741089, acc: 0.5933610200881958)
[2024-12-17 03:53:50,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:50,565][root][INFO] - Training Epoch: 1/2, step 2417/7134 completed (loss: 1.354640007019043, acc: 0.6064659953117371)
[2024-12-17 03:53:50,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:50,982][root][INFO] - Training Epoch: 1/2, step 2418/7134 completed (loss: 1.387944221496582, acc: 0.604781985282898)
[2024-12-17 03:53:51,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:51,421][root][INFO] - Training Epoch: 1/2, step 2419/7134 completed (loss: 1.4257835149765015, acc: 0.5736767053604126)
[2024-12-17 03:53:51,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:51,853][root][INFO] - Training Epoch: 1/2, step 2420/7134 completed (loss: 1.3752996921539307, acc: 0.618573784828186)
[2024-12-17 03:53:51,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:52,300][root][INFO] - Training Epoch: 1/2, step 2421/7134 completed (loss: 1.3563674688339233, acc: 0.603233814239502)
[2024-12-17 03:53:52,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:52,790][root][INFO] - Training Epoch: 1/2, step 2422/7134 completed (loss: 1.2667896747589111, acc: 0.6028369069099426)
[2024-12-17 03:53:52,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:53,218][root][INFO] - Training Epoch: 1/2, step 2423/7134 completed (loss: 1.282639980316162, acc: 0.6290097832679749)
[2024-12-17 03:53:53,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:53,649][root][INFO] - Training Epoch: 1/2, step 2424/7134 completed (loss: 1.3635255098342896, acc: 0.6137640476226807)
[2024-12-17 03:53:53,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:54,075][root][INFO] - Training Epoch: 1/2, step 2425/7134 completed (loss: 1.387159824371338, acc: 0.6039999723434448)
[2024-12-17 03:53:54,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:54,542][root][INFO] - Training Epoch: 1/2, step 2426/7134 completed (loss: 1.2762436866760254, acc: 0.6052318811416626)
[2024-12-17 03:53:54,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:55,002][root][INFO] - Training Epoch: 1/2, step 2427/7134 completed (loss: 1.2569526433944702, acc: 0.6125289797782898)
[2024-12-17 03:53:55,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:55,455][root][INFO] - Training Epoch: 1/2, step 2428/7134 completed (loss: 1.2820895910263062, acc: 0.6165605187416077)
[2024-12-17 03:53:55,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:55,891][root][INFO] - Training Epoch: 1/2, step 2429/7134 completed (loss: 1.444850206375122, acc: 0.5996884703636169)
[2024-12-17 03:53:56,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:56,300][root][INFO] - Training Epoch: 1/2, step 2430/7134 completed (loss: 1.2740933895111084, acc: 0.625931441783905)
[2024-12-17 03:53:56,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:56,748][root][INFO] - Training Epoch: 1/2, step 2431/7134 completed (loss: 1.2617464065551758, acc: 0.633431077003479)
[2024-12-17 03:53:56,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:57,204][root][INFO] - Training Epoch: 1/2, step 2432/7134 completed (loss: 1.4852991104125977, acc: 0.5840407609939575)
[2024-12-17 03:53:57,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:57,653][root][INFO] - Training Epoch: 1/2, step 2433/7134 completed (loss: 1.3663808107376099, acc: 0.5909090638160706)
[2024-12-17 03:53:57,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:58,066][root][INFO] - Training Epoch: 1/2, step 2434/7134 completed (loss: 1.4867863655090332, acc: 0.5822981595993042)
[2024-12-17 03:53:58,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:58,525][root][INFO] - Training Epoch: 1/2, step 2435/7134 completed (loss: 1.492094874382019, acc: 0.5876153111457825)
[2024-12-17 03:53:58,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:58,975][root][INFO] - Training Epoch: 1/2, step 2436/7134 completed (loss: 1.384796142578125, acc: 0.610011637210846)
[2024-12-17 03:53:59,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:59,395][root][INFO] - Training Epoch: 1/2, step 2437/7134 completed (loss: 1.4271503686904907, acc: 0.6033182740211487)
[2024-12-17 03:53:59,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:53:59,867][root][INFO] - Training Epoch: 1/2, step 2438/7134 completed (loss: 1.3339576721191406, acc: 0.6136363744735718)
[2024-12-17 03:53:59,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:00,329][root][INFO] - Training Epoch: 1/2, step 2439/7134 completed (loss: 1.3292890787124634, acc: 0.6038751602172852)
[2024-12-17 03:54:00,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:00,753][root][INFO] - Training Epoch: 1/2, step 2440/7134 completed (loss: 1.4180527925491333, acc: 0.5762332081794739)
[2024-12-17 03:54:00,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:01,183][root][INFO] - Training Epoch: 1/2, step 2441/7134 completed (loss: 1.4662353992462158, acc: 0.5681381821632385)
[2024-12-17 03:54:01,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:01,622][root][INFO] - Training Epoch: 1/2, step 2442/7134 completed (loss: 1.4890196323394775, acc: 0.5860139727592468)
[2024-12-17 03:54:01,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:02,077][root][INFO] - Training Epoch: 1/2, step 2443/7134 completed (loss: 1.4852337837219238, acc: 0.5549374222755432)
[2024-12-17 03:54:02,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:02,497][root][INFO] - Training Epoch: 1/2, step 2444/7134 completed (loss: 1.4404544830322266, acc: 0.6003788113594055)
[2024-12-17 03:54:02,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:02,947][root][INFO] - Training Epoch: 1/2, step 2445/7134 completed (loss: 1.3315200805664062, acc: 0.6129441857337952)
[2024-12-17 03:54:03,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:03,417][root][INFO] - Training Epoch: 1/2, step 2446/7134 completed (loss: 1.5070157051086426, acc: 0.5569444298744202)
[2024-12-17 03:54:03,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:03,889][root][INFO] - Training Epoch: 1/2, step 2447/7134 completed (loss: 1.4067697525024414, acc: 0.5660377144813538)
[2024-12-17 03:54:04,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:04,318][root][INFO] - Training Epoch: 1/2, step 2448/7134 completed (loss: 1.2751305103302002, acc: 0.6270053386688232)
[2024-12-17 03:54:04,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:04,726][root][INFO] - Training Epoch: 1/2, step 2449/7134 completed (loss: 1.3198895454406738, acc: 0.6246684193611145)
[2024-12-17 03:54:04,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:05,151][root][INFO] - Training Epoch: 1/2, step 2450/7134 completed (loss: 1.4065741300582886, acc: 0.579415500164032)
[2024-12-17 03:54:05,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:05,579][root][INFO] - Training Epoch: 1/2, step 2451/7134 completed (loss: 1.4830366373062134, acc: 0.559235692024231)
[2024-12-17 03:54:05,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:06,026][root][INFO] - Training Epoch: 1/2, step 2452/7134 completed (loss: 1.4419221878051758, acc: 0.5942782759666443)
[2024-12-17 03:54:06,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:06,486][root][INFO] - Training Epoch: 1/2, step 2453/7134 completed (loss: 1.545353889465332, acc: 0.5561290383338928)
[2024-12-17 03:54:06,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:06,921][root][INFO] - Training Epoch: 1/2, step 2454/7134 completed (loss: 1.4485725164413452, acc: 0.5802675485610962)
[2024-12-17 03:54:07,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:07,384][root][INFO] - Training Epoch: 1/2, step 2455/7134 completed (loss: 1.4065828323364258, acc: 0.600566565990448)
[2024-12-17 03:54:07,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:07,822][root][INFO] - Training Epoch: 1/2, step 2456/7134 completed (loss: 1.5436519384384155, acc: 0.5408560037612915)
[2024-12-17 03:54:07,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:08,307][root][INFO] - Training Epoch: 1/2, step 2457/7134 completed (loss: 1.6414449214935303, acc: 0.5108153223991394)
[2024-12-17 03:54:08,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:08,779][root][INFO] - Training Epoch: 1/2, step 2458/7134 completed (loss: 1.5369600057601929, acc: 0.5644654035568237)
[2024-12-17 03:54:08,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:09,239][root][INFO] - Training Epoch: 1/2, step 2459/7134 completed (loss: 1.4035589694976807, acc: 0.584319531917572)
[2024-12-17 03:54:09,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:09,679][root][INFO] - Training Epoch: 1/2, step 2460/7134 completed (loss: 1.3949499130249023, acc: 0.5864453911781311)
[2024-12-17 03:54:09,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:10,120][root][INFO] - Training Epoch: 1/2, step 2461/7134 completed (loss: 1.4615031480789185, acc: 0.5724637508392334)
[2024-12-17 03:54:10,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:10,538][root][INFO] - Training Epoch: 1/2, step 2462/7134 completed (loss: 1.4367581605911255, acc: 0.5862069129943848)
[2024-12-17 03:54:10,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:10,984][root][INFO] - Training Epoch: 1/2, step 2463/7134 completed (loss: 1.3492885828018188, acc: 0.5960665941238403)
[2024-12-17 03:54:11,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:11,390][root][INFO] - Training Epoch: 1/2, step 2464/7134 completed (loss: 1.4887199401855469, acc: 0.5599250793457031)
[2024-12-17 03:54:11,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:11,820][root][INFO] - Training Epoch: 1/2, step 2465/7134 completed (loss: 1.363435983657837, acc: 0.5894039869308472)
[2024-12-17 03:54:11,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:12,264][root][INFO] - Training Epoch: 1/2, step 2466/7134 completed (loss: 1.4293326139450073, acc: 0.5774834156036377)
[2024-12-17 03:54:12,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:12,692][root][INFO] - Training Epoch: 1/2, step 2467/7134 completed (loss: 1.3938798904418945, acc: 0.5951156616210938)
[2024-12-17 03:54:12,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:13,137][root][INFO] - Training Epoch: 1/2, step 2468/7134 completed (loss: 1.3731189966201782, acc: 0.5916084051132202)
[2024-12-17 03:54:13,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:13,580][root][INFO] - Training Epoch: 1/2, step 2469/7134 completed (loss: 1.3414443731307983, acc: 0.5948158502578735)
[2024-12-17 03:54:13,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:14,005][root][INFO] - Training Epoch: 1/2, step 2470/7134 completed (loss: 1.3685410022735596, acc: 0.6077440977096558)
[2024-12-17 03:54:14,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:14,422][root][INFO] - Training Epoch: 1/2, step 2471/7134 completed (loss: 1.3506770133972168, acc: 0.6020066738128662)
[2024-12-17 03:54:14,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:14,836][root][INFO] - Training Epoch: 1/2, step 2472/7134 completed (loss: 1.3241641521453857, acc: 0.6045454740524292)
[2024-12-17 03:54:14,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:15,276][root][INFO] - Training Epoch: 1/2, step 2473/7134 completed (loss: 1.3386855125427246, acc: 0.6127049326896667)
[2024-12-17 03:54:15,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:15,714][root][INFO] - Training Epoch: 1/2, step 2474/7134 completed (loss: 1.4100406169891357, acc: 0.5859155058860779)
[2024-12-17 03:54:15,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:16,143][root][INFO] - Training Epoch: 1/2, step 2475/7134 completed (loss: 1.3271692991256714, acc: 0.6277872920036316)
[2024-12-17 03:54:16,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:16,565][root][INFO] - Training Epoch: 1/2, step 2476/7134 completed (loss: 1.436287760734558, acc: 0.5919219851493835)
[2024-12-17 03:54:16,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:16,973][root][INFO] - Training Epoch: 1/2, step 2477/7134 completed (loss: 1.288877248764038, acc: 0.6187845468521118)
[2024-12-17 03:54:17,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:17,392][root][INFO] - Training Epoch: 1/2, step 2478/7134 completed (loss: 1.2987384796142578, acc: 0.6137071847915649)
[2024-12-17 03:54:17,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:17,801][root][INFO] - Training Epoch: 1/2, step 2479/7134 completed (loss: 1.3908542394638062, acc: 0.5993640422821045)
[2024-12-17 03:54:17,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:18,216][root][INFO] - Training Epoch: 1/2, step 2480/7134 completed (loss: 1.2243154048919678, acc: 0.6288889050483704)
[2024-12-17 03:54:18,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:18,619][root][INFO] - Training Epoch: 1/2, step 2481/7134 completed (loss: 1.3089176416397095, acc: 0.6144278645515442)
[2024-12-17 03:54:18,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:19,049][root][INFO] - Training Epoch: 1/2, step 2482/7134 completed (loss: 1.4540303945541382, acc: 0.5810593962669373)
[2024-12-17 03:54:19,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:19,487][root][INFO] - Training Epoch: 1/2, step 2483/7134 completed (loss: 1.2818108797073364, acc: 0.6310679316520691)
[2024-12-17 03:54:19,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:19,927][root][INFO] - Training Epoch: 1/2, step 2484/7134 completed (loss: 1.269451379776001, acc: 0.6291666626930237)
[2024-12-17 03:54:20,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:20,348][root][INFO] - Training Epoch: 1/2, step 2485/7134 completed (loss: 1.2768690586090088, acc: 0.617460310459137)
[2024-12-17 03:54:20,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:20,773][root][INFO] - Training Epoch: 1/2, step 2486/7134 completed (loss: 1.216416597366333, acc: 0.6336206793785095)
[2024-12-17 03:54:20,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:21,199][root][INFO] - Training Epoch: 1/2, step 2487/7134 completed (loss: 1.361702799797058, acc: 0.6015747785568237)
[2024-12-17 03:54:21,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:21,620][root][INFO] - Training Epoch: 1/2, step 2488/7134 completed (loss: 1.435134768486023, acc: 0.5676795840263367)
[2024-12-17 03:54:21,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:22,033][root][INFO] - Training Epoch: 1/2, step 2489/7134 completed (loss: 1.3190404176712036, acc: 0.621169924736023)
[2024-12-17 03:54:22,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:22,460][root][INFO] - Training Epoch: 1/2, step 2490/7134 completed (loss: 1.3926118612289429, acc: 0.609129786491394)
[2024-12-17 03:54:22,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:22,872][root][INFO] - Training Epoch: 1/2, step 2491/7134 completed (loss: 1.3513553142547607, acc: 0.60317462682724)
[2024-12-17 03:54:23,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:23,306][root][INFO] - Training Epoch: 1/2, step 2492/7134 completed (loss: 1.288454294204712, acc: 0.6203473806381226)
[2024-12-17 03:54:23,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:23,753][root][INFO] - Training Epoch: 1/2, step 2493/7134 completed (loss: 1.2881972789764404, acc: 0.6302816867828369)
[2024-12-17 03:54:23,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:24,212][root][INFO] - Training Epoch: 1/2, step 2494/7134 completed (loss: 1.3115358352661133, acc: 0.5994993448257446)
[2024-12-17 03:54:24,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:24,639][root][INFO] - Training Epoch: 1/2, step 2495/7134 completed (loss: 1.3770955801010132, acc: 0.5943012237548828)
[2024-12-17 03:54:24,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:25,093][root][INFO] - Training Epoch: 1/2, step 2496/7134 completed (loss: 1.319442868232727, acc: 0.6123595237731934)
[2024-12-17 03:54:25,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:25,538][root][INFO] - Training Epoch: 1/2, step 2497/7134 completed (loss: 1.3129479885101318, acc: 0.6009732484817505)
[2024-12-17 03:54:25,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:25,989][root][INFO] - Training Epoch: 1/2, step 2498/7134 completed (loss: 1.2757694721221924, acc: 0.5995449423789978)
[2024-12-17 03:54:26,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:26,440][root][INFO] - Training Epoch: 1/2, step 2499/7134 completed (loss: 1.2939040660858154, acc: 0.6074879169464111)
[2024-12-17 03:54:26,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:26,902][root][INFO] - Training Epoch: 1/2, step 2500/7134 completed (loss: 1.2460378408432007, acc: 0.6319176554679871)
[2024-12-17 03:54:27,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:27,343][root][INFO] - Training Epoch: 1/2, step 2501/7134 completed (loss: 1.2872600555419922, acc: 0.6292906403541565)
[2024-12-17 03:54:27,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:27,793][root][INFO] - Training Epoch: 1/2, step 2502/7134 completed (loss: 1.2000958919525146, acc: 0.666077733039856)
[2024-12-17 03:54:27,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:28,197][root][INFO] - Training Epoch: 1/2, step 2503/7134 completed (loss: 1.2599308490753174, acc: 0.6282051205635071)
[2024-12-17 03:54:28,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:28,641][root][INFO] - Training Epoch: 1/2, step 2504/7134 completed (loss: 1.3484448194503784, acc: 0.5933333039283752)
[2024-12-17 03:54:28,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:29,113][root][INFO] - Training Epoch: 1/2, step 2505/7134 completed (loss: 1.2469581365585327, acc: 0.6370875835418701)
[2024-12-17 03:54:29,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:29,587][root][INFO] - Training Epoch: 1/2, step 2506/7134 completed (loss: 1.2435942888259888, acc: 0.6330128312110901)
[2024-12-17 03:54:29,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:30,036][root][INFO] - Training Epoch: 1/2, step 2507/7134 completed (loss: 1.2595446109771729, acc: 0.635307788848877)
[2024-12-17 03:54:30,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:30,499][root][INFO] - Training Epoch: 1/2, step 2508/7134 completed (loss: 1.2557026147842407, acc: 0.6221198439598083)
[2024-12-17 03:54:30,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:30,925][root][INFO] - Training Epoch: 1/2, step 2509/7134 completed (loss: 1.1704435348510742, acc: 0.6487147808074951)
[2024-12-17 03:54:31,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:31,362][root][INFO] - Training Epoch: 1/2, step 2510/7134 completed (loss: 1.1454839706420898, acc: 0.6433990597724915)
[2024-12-17 03:54:31,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:31,803][root][INFO] - Training Epoch: 1/2, step 2511/7134 completed (loss: 1.2436270713806152, acc: 0.6334080696105957)
[2024-12-17 03:54:31,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:32,225][root][INFO] - Training Epoch: 1/2, step 2512/7134 completed (loss: 1.3438516855239868, acc: 0.5951417088508606)
[2024-12-17 03:54:32,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:32,687][root][INFO] - Training Epoch: 1/2, step 2513/7134 completed (loss: 1.1954474449157715, acc: 0.6315165758132935)
[2024-12-17 03:54:32,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:33,141][root][INFO] - Training Epoch: 1/2, step 2514/7134 completed (loss: 1.1312673091888428, acc: 0.6697782874107361)
[2024-12-17 03:54:33,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:33,587][root][INFO] - Training Epoch: 1/2, step 2515/7134 completed (loss: 1.1316637992858887, acc: 0.6801040172576904)
[2024-12-17 03:54:33,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:34,073][root][INFO] - Training Epoch: 1/2, step 2516/7134 completed (loss: 1.1086225509643555, acc: 0.6522727012634277)
[2024-12-17 03:54:34,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:34,533][root][INFO] - Training Epoch: 1/2, step 2517/7134 completed (loss: 1.230093240737915, acc: 0.6475315690040588)
[2024-12-17 03:54:34,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:34,952][root][INFO] - Training Epoch: 1/2, step 2518/7134 completed (loss: 1.2930514812469482, acc: 0.6123033165931702)
[2024-12-17 03:54:35,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:35,394][root][INFO] - Training Epoch: 1/2, step 2519/7134 completed (loss: 1.2835631370544434, acc: 0.6141079068183899)
[2024-12-17 03:54:35,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:35,834][root][INFO] - Training Epoch: 1/2, step 2520/7134 completed (loss: 1.3613500595092773, acc: 0.5982906222343445)
[2024-12-17 03:54:35,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:36,296][root][INFO] - Training Epoch: 1/2, step 2521/7134 completed (loss: 1.377202033996582, acc: 0.5984556078910828)
[2024-12-17 03:54:36,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:36,719][root][INFO] - Training Epoch: 1/2, step 2522/7134 completed (loss: 1.3051953315734863, acc: 0.6189111471176147)
[2024-12-17 03:54:36,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:37,142][root][INFO] - Training Epoch: 1/2, step 2523/7134 completed (loss: 1.3256765604019165, acc: 0.6073298454284668)
[2024-12-17 03:54:37,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:37,563][root][INFO] - Training Epoch: 1/2, step 2524/7134 completed (loss: 1.363468885421753, acc: 0.6063535809516907)
[2024-12-17 03:54:37,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:38,005][root][INFO] - Training Epoch: 1/2, step 2525/7134 completed (loss: 1.4778212308883667, acc: 0.5659432411193848)
[2024-12-17 03:54:38,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:38,369][root][INFO] - Training Epoch: 1/2, step 2526/7134 completed (loss: 1.3111963272094727, acc: 0.6117647290229797)
[2024-12-17 03:54:38,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:38,807][root][INFO] - Training Epoch: 1/2, step 2527/7134 completed (loss: 1.3202881813049316, acc: 0.5963414907455444)
[2024-12-17 03:54:38,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:39,229][root][INFO] - Training Epoch: 1/2, step 2528/7134 completed (loss: 1.3274037837982178, acc: 0.604651153087616)
[2024-12-17 03:54:39,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:39,717][root][INFO] - Training Epoch: 1/2, step 2529/7134 completed (loss: 1.2840709686279297, acc: 0.6117021441459656)
[2024-12-17 03:54:39,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:40,179][root][INFO] - Training Epoch: 1/2, step 2530/7134 completed (loss: 1.2778996229171753, acc: 0.6116883158683777)
[2024-12-17 03:54:40,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:40,596][root][INFO] - Training Epoch: 1/2, step 2531/7134 completed (loss: 1.2711858749389648, acc: 0.6118784546852112)
[2024-12-17 03:54:40,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:41,033][root][INFO] - Training Epoch: 1/2, step 2532/7134 completed (loss: 1.291075348854065, acc: 0.6055470108985901)
[2024-12-17 03:54:41,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:41,460][root][INFO] - Training Epoch: 1/2, step 2533/7134 completed (loss: 1.2664837837219238, acc: 0.6440422534942627)
[2024-12-17 03:54:41,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:41,886][root][INFO] - Training Epoch: 1/2, step 2534/7134 completed (loss: 1.304558277130127, acc: 0.6254777312278748)
[2024-12-17 03:54:41,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:42,306][root][INFO] - Training Epoch: 1/2, step 2535/7134 completed (loss: 1.2926369905471802, acc: 0.6069363951683044)
[2024-12-17 03:54:42,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:42,763][root][INFO] - Training Epoch: 1/2, step 2536/7134 completed (loss: 1.445587396621704, acc: 0.5904058814048767)
[2024-12-17 03:54:42,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:43,169][root][INFO] - Training Epoch: 1/2, step 2537/7134 completed (loss: 1.4379962682724, acc: 0.5963302850723267)
[2024-12-17 03:54:43,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:43,594][root][INFO] - Training Epoch: 1/2, step 2538/7134 completed (loss: 1.5024476051330566, acc: 0.5694050788879395)
[2024-12-17 03:54:43,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:44,005][root][INFO] - Training Epoch: 1/2, step 2539/7134 completed (loss: 1.552451491355896, acc: 0.5732142925262451)
[2024-12-17 03:54:44,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:44,435][root][INFO] - Training Epoch: 1/2, step 2540/7134 completed (loss: 1.3660261631011963, acc: 0.608562707901001)
[2024-12-17 03:54:44,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:44,859][root][INFO] - Training Epoch: 1/2, step 2541/7134 completed (loss: 1.3783358335494995, acc: 0.5894039869308472)
[2024-12-17 03:54:44,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:45,276][root][INFO] - Training Epoch: 1/2, step 2542/7134 completed (loss: 1.3854539394378662, acc: 0.5991124510765076)
[2024-12-17 03:54:45,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:45,731][root][INFO] - Training Epoch: 1/2, step 2543/7134 completed (loss: 1.4114651679992676, acc: 0.5915300250053406)
[2024-12-17 03:54:45,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:46,178][root][INFO] - Training Epoch: 1/2, step 2544/7134 completed (loss: 1.2976878881454468, acc: 0.5979381203651428)
[2024-12-17 03:54:46,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:46,613][root][INFO] - Training Epoch: 1/2, step 2545/7134 completed (loss: 1.2836552858352661, acc: 0.6230366230010986)
[2024-12-17 03:54:46,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:47,132][root][INFO] - Training Epoch: 1/2, step 2546/7134 completed (loss: 1.413708209991455, acc: 0.5858343243598938)
[2024-12-17 03:54:47,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:47,560][root][INFO] - Training Epoch: 1/2, step 2547/7134 completed (loss: 1.3145561218261719, acc: 0.6119162440299988)
[2024-12-17 03:54:47,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:47,985][root][INFO] - Training Epoch: 1/2, step 2548/7134 completed (loss: 1.2570958137512207, acc: 0.6102362275123596)
[2024-12-17 03:54:48,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:48,409][root][INFO] - Training Epoch: 1/2, step 2549/7134 completed (loss: 1.391271948814392, acc: 0.5635359287261963)
[2024-12-17 03:54:48,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:48,820][root][INFO] - Training Epoch: 1/2, step 2550/7134 completed (loss: 1.1706616878509521, acc: 0.6427406072616577)
[2024-12-17 03:54:48,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:49,238][root][INFO] - Training Epoch: 1/2, step 2551/7134 completed (loss: 1.3425780534744263, acc: 0.6089109182357788)
[2024-12-17 03:54:49,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:49,627][root][INFO] - Training Epoch: 1/2, step 2552/7134 completed (loss: 1.3344838619232178, acc: 0.5899053812026978)
[2024-12-17 03:54:49,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:50,021][root][INFO] - Training Epoch: 1/2, step 2553/7134 completed (loss: 1.3398103713989258, acc: 0.5800604224205017)
[2024-12-17 03:54:50,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:50,455][root][INFO] - Training Epoch: 1/2, step 2554/7134 completed (loss: 1.251008152961731, acc: 0.6365159153938293)
[2024-12-17 03:54:50,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:50,849][root][INFO] - Training Epoch: 1/2, step 2555/7134 completed (loss: 1.3284555673599243, acc: 0.60537189245224)
[2024-12-17 03:54:50,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:51,260][root][INFO] - Training Epoch: 1/2, step 2556/7134 completed (loss: 1.200188398361206, acc: 0.6477987170219421)
[2024-12-17 03:54:51,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:51,713][root][INFO] - Training Epoch: 1/2, step 2557/7134 completed (loss: 1.2742693424224854, acc: 0.6327868700027466)
[2024-12-17 03:54:51,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:52,117][root][INFO] - Training Epoch: 1/2, step 2558/7134 completed (loss: 1.282829999923706, acc: 0.6148867607116699)
[2024-12-17 03:54:52,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:52,543][root][INFO] - Training Epoch: 1/2, step 2559/7134 completed (loss: 1.2658358812332153, acc: 0.6319350600242615)
[2024-12-17 03:54:52,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:52,996][root][INFO] - Training Epoch: 1/2, step 2560/7134 completed (loss: 1.2919172048568726, acc: 0.5853658318519592)
[2024-12-17 03:54:53,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:53,415][root][INFO] - Training Epoch: 1/2, step 2561/7134 completed (loss: 1.329001545906067, acc: 0.6034858226776123)
[2024-12-17 03:54:53,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:53,822][root][INFO] - Training Epoch: 1/2, step 2562/7134 completed (loss: 1.2430384159088135, acc: 0.6256410479545593)
[2024-12-17 03:54:53,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:54,259][root][INFO] - Training Epoch: 1/2, step 2563/7134 completed (loss: 1.4000917673110962, acc: 0.5850439667701721)
[2024-12-17 03:54:54,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:54,706][root][INFO] - Training Epoch: 1/2, step 2564/7134 completed (loss: 1.3049476146697998, acc: 0.5989933013916016)
[2024-12-17 03:54:54,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:55,121][root][INFO] - Training Epoch: 1/2, step 2565/7134 completed (loss: 1.2301430702209473, acc: 0.616314172744751)
[2024-12-17 03:54:55,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:55,571][root][INFO] - Training Epoch: 1/2, step 2566/7134 completed (loss: 1.1967731714248657, acc: 0.6544944047927856)
[2024-12-17 03:54:55,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:55,931][root][INFO] - Training Epoch: 1/2, step 2567/7134 completed (loss: 1.2467964887619019, acc: 0.6490299701690674)
[2024-12-17 03:54:56,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:56,374][root][INFO] - Training Epoch: 1/2, step 2568/7134 completed (loss: 1.277430534362793, acc: 0.6141618490219116)
[2024-12-17 03:54:56,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:56,811][root][INFO] - Training Epoch: 1/2, step 2569/7134 completed (loss: 1.2985256910324097, acc: 0.5978915691375732)
[2024-12-17 03:54:56,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:57,238][root][INFO] - Training Epoch: 1/2, step 2570/7134 completed (loss: 1.2228777408599854, acc: 0.622188925743103)
[2024-12-17 03:54:57,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:57,641][root][INFO] - Training Epoch: 1/2, step 2571/7134 completed (loss: 1.202134370803833, acc: 0.6432337164878845)
[2024-12-17 03:54:57,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:58,075][root][INFO] - Training Epoch: 1/2, step 2572/7134 completed (loss: 1.1953067779541016, acc: 0.64826500415802)
[2024-12-17 03:54:58,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:58,498][root][INFO] - Training Epoch: 1/2, step 2573/7134 completed (loss: 1.221518874168396, acc: 0.6213114857673645)
[2024-12-17 03:54:58,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:58,891][root][INFO] - Training Epoch: 1/2, step 2574/7134 completed (loss: 1.3023284673690796, acc: 0.6069868803024292)
[2024-12-17 03:54:59,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:59,305][root][INFO] - Training Epoch: 1/2, step 2575/7134 completed (loss: 1.1798369884490967, acc: 0.6579925417900085)
[2024-12-17 03:54:59,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:54:59,728][root][INFO] - Training Epoch: 1/2, step 2576/7134 completed (loss: 1.1602874994277954, acc: 0.6499999761581421)
[2024-12-17 03:54:59,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:00,164][root][INFO] - Training Epoch: 1/2, step 2577/7134 completed (loss: 1.261311650276184, acc: 0.6256410479545593)
[2024-12-17 03:55:00,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:00,594][root][INFO] - Training Epoch: 1/2, step 2578/7134 completed (loss: 1.46210515499115, acc: 0.5758039951324463)
[2024-12-17 03:55:00,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:01,015][root][INFO] - Training Epoch: 1/2, step 2579/7134 completed (loss: 1.5585438013076782, acc: 0.5395569801330566)
[2024-12-17 03:55:01,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:01,464][root][INFO] - Training Epoch: 1/2, step 2580/7134 completed (loss: 1.531551718711853, acc: 0.5757180452346802)
[2024-12-17 03:55:01,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:01,913][root][INFO] - Training Epoch: 1/2, step 2581/7134 completed (loss: 1.5560754537582397, acc: 0.5518169403076172)
[2024-12-17 03:55:02,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:02,354][root][INFO] - Training Epoch: 1/2, step 2582/7134 completed (loss: 1.683768391609192, acc: 0.5067750811576843)
[2024-12-17 03:55:02,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:02,771][root][INFO] - Training Epoch: 1/2, step 2583/7134 completed (loss: 1.6443358659744263, acc: 0.5277382731437683)
[2024-12-17 03:55:02,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:03,169][root][INFO] - Training Epoch: 1/2, step 2584/7134 completed (loss: 1.661461353302002, acc: 0.5095986127853394)
[2024-12-17 03:55:03,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:03,633][root][INFO] - Training Epoch: 1/2, step 2585/7134 completed (loss: 1.4396384954452515, acc: 0.5669064521789551)
[2024-12-17 03:55:03,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:04,085][root][INFO] - Training Epoch: 1/2, step 2586/7134 completed (loss: 1.4986528158187866, acc: 0.5704225301742554)
[2024-12-17 03:55:04,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:04,531][root][INFO] - Training Epoch: 1/2, step 2587/7134 completed (loss: 1.3589627742767334, acc: 0.6007370948791504)
[2024-12-17 03:55:04,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:04,977][root][INFO] - Training Epoch: 1/2, step 2588/7134 completed (loss: 1.2953342199325562, acc: 0.6248294711112976)
[2024-12-17 03:55:05,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:05,398][root][INFO] - Training Epoch: 1/2, step 2589/7134 completed (loss: 1.4314662218093872, acc: 0.5724381804466248)
[2024-12-17 03:55:05,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:05,816][root][INFO] - Training Epoch: 1/2, step 2590/7134 completed (loss: 1.4844452142715454, acc: 0.5571895241737366)
[2024-12-17 03:55:05,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:06,251][root][INFO] - Training Epoch: 1/2, step 2591/7134 completed (loss: 1.5057858228683472, acc: 0.5780051350593567)
[2024-12-17 03:55:06,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:06,700][root][INFO] - Training Epoch: 1/2, step 2592/7134 completed (loss: 1.3857649564743042, acc: 0.6027060151100159)
[2024-12-17 03:55:06,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:07,147][root][INFO] - Training Epoch: 1/2, step 2593/7134 completed (loss: 1.3221492767333984, acc: 0.6191099286079407)
[2024-12-17 03:55:07,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:07,569][root][INFO] - Training Epoch: 1/2, step 2594/7134 completed (loss: 1.363964557647705, acc: 0.6039755344390869)
[2024-12-17 03:55:07,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:08,011][root][INFO] - Training Epoch: 1/2, step 2595/7134 completed (loss: 1.3677805662155151, acc: 0.5913978219032288)
[2024-12-17 03:55:08,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:08,481][root][INFO] - Training Epoch: 1/2, step 2596/7134 completed (loss: 1.3754148483276367, acc: 0.5952380895614624)
[2024-12-17 03:55:08,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:08,930][root][INFO] - Training Epoch: 1/2, step 2597/7134 completed (loss: 1.409194827079773, acc: 0.6094594597816467)
[2024-12-17 03:55:09,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:09,355][root][INFO] - Training Epoch: 1/2, step 2598/7134 completed (loss: 1.4085326194763184, acc: 0.62848299741745)
[2024-12-17 03:55:09,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:09,765][root][INFO] - Training Epoch: 1/2, step 2599/7134 completed (loss: 1.2440459728240967, acc: 0.6240105628967285)
[2024-12-17 03:55:09,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:10,231][root][INFO] - Training Epoch: 1/2, step 2600/7134 completed (loss: 1.2501616477966309, acc: 0.6389244794845581)
[2024-12-17 03:55:10,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:10,681][root][INFO] - Training Epoch: 1/2, step 2601/7134 completed (loss: 1.291563868522644, acc: 0.6292287111282349)
[2024-12-17 03:55:10,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:11,122][root][INFO] - Training Epoch: 1/2, step 2602/7134 completed (loss: 1.3785256147384644, acc: 0.6101694703102112)
[2024-12-17 03:55:11,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:11,580][root][INFO] - Training Epoch: 1/2, step 2603/7134 completed (loss: 1.357669711112976, acc: 0.6155038475990295)
[2024-12-17 03:55:11,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:12,058][root][INFO] - Training Epoch: 1/2, step 2604/7134 completed (loss: 1.4272178411483765, acc: 0.5734649300575256)
[2024-12-17 03:55:12,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:12,508][root][INFO] - Training Epoch: 1/2, step 2605/7134 completed (loss: 1.5035244226455688, acc: 0.5667870044708252)
[2024-12-17 03:55:12,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:12,963][root][INFO] - Training Epoch: 1/2, step 2606/7134 completed (loss: 1.5202748775482178, acc: 0.5467625856399536)
[2024-12-17 03:55:13,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:13,402][root][INFO] - Training Epoch: 1/2, step 2607/7134 completed (loss: 1.355812430381775, acc: 0.6035293936729431)
[2024-12-17 03:55:13,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:13,838][root][INFO] - Training Epoch: 1/2, step 2608/7134 completed (loss: 1.4964150190353394, acc: 0.5797280669212341)
[2024-12-17 03:55:13,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:14,272][root][INFO] - Training Epoch: 1/2, step 2609/7134 completed (loss: 1.654985785484314, acc: 0.5208913683891296)
[2024-12-17 03:55:14,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:14,632][root][INFO] - Training Epoch: 1/2, step 2610/7134 completed (loss: 1.5173991918563843, acc: 0.5587786436080933)
[2024-12-17 03:55:14,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:15,103][root][INFO] - Training Epoch: 1/2, step 2611/7134 completed (loss: 1.4433428049087524, acc: 0.6016073226928711)
[2024-12-17 03:55:15,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:15,576][root][INFO] - Training Epoch: 1/2, step 2612/7134 completed (loss: 1.5891413688659668, acc: 0.5421412587165833)
[2024-12-17 03:55:15,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:16,057][root][INFO] - Training Epoch: 1/2, step 2613/7134 completed (loss: 1.4608750343322754, acc: 0.5734177231788635)
[2024-12-17 03:55:16,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:16,515][root][INFO] - Training Epoch: 1/2, step 2614/7134 completed (loss: 1.5364830493927002, acc: 0.572892963886261)
[2024-12-17 03:55:16,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:16,959][root][INFO] - Training Epoch: 1/2, step 2615/7134 completed (loss: 1.5010018348693848, acc: 0.5642673373222351)
[2024-12-17 03:55:17,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:17,397][root][INFO] - Training Epoch: 1/2, step 2616/7134 completed (loss: 1.4254217147827148, acc: 0.5781893134117126)
[2024-12-17 03:55:17,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:17,856][root][INFO] - Training Epoch: 1/2, step 2617/7134 completed (loss: 1.5290868282318115, acc: 0.5533063411712646)
[2024-12-17 03:55:18,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:18,297][root][INFO] - Training Epoch: 1/2, step 2618/7134 completed (loss: 1.4840848445892334, acc: 0.5749486684799194)
[2024-12-17 03:55:18,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:18,738][root][INFO] - Training Epoch: 1/2, step 2619/7134 completed (loss: 1.4602570533752441, acc: 0.5654362440109253)
[2024-12-17 03:55:18,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:19,182][root][INFO] - Training Epoch: 1/2, step 2620/7134 completed (loss: 1.4262961149215698, acc: 0.5935564041137695)
[2024-12-17 03:55:19,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:19,630][root][INFO] - Training Epoch: 1/2, step 2621/7134 completed (loss: 1.5639220476150513, acc: 0.5402843356132507)
[2024-12-17 03:55:19,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:20,087][root][INFO] - Training Epoch: 1/2, step 2622/7134 completed (loss: 1.60927414894104, acc: 0.5073649883270264)
[2024-12-17 03:55:20,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:20,552][root][INFO] - Training Epoch: 1/2, step 2623/7134 completed (loss: 1.5286859273910522, acc: 0.5735632181167603)
[2024-12-17 03:55:20,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:21,022][root][INFO] - Training Epoch: 1/2, step 2624/7134 completed (loss: 1.519783616065979, acc: 0.5691788792610168)
[2024-12-17 03:55:21,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:21,464][root][INFO] - Training Epoch: 1/2, step 2625/7134 completed (loss: 1.4399755001068115, acc: 0.574999988079071)
[2024-12-17 03:55:21,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:21,925][root][INFO] - Training Epoch: 1/2, step 2626/7134 completed (loss: 1.4555144309997559, acc: 0.5643564462661743)
[2024-12-17 03:55:22,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:22,379][root][INFO] - Training Epoch: 1/2, step 2627/7134 completed (loss: 1.4598808288574219, acc: 0.5723951458930969)
[2024-12-17 03:55:22,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:22,806][root][INFO] - Training Epoch: 1/2, step 2628/7134 completed (loss: 1.37871515750885, acc: 0.5972222089767456)
[2024-12-17 03:55:22,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:23,347][root][INFO] - Training Epoch: 1/2, step 2629/7134 completed (loss: 1.2984533309936523, acc: 0.6219974756240845)
[2024-12-17 03:55:23,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:23,759][root][INFO] - Training Epoch: 1/2, step 2630/7134 completed (loss: 1.3590470552444458, acc: 0.6038338541984558)
[2024-12-17 03:55:23,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:24,204][root][INFO] - Training Epoch: 1/2, step 2631/7134 completed (loss: 1.4746218919754028, acc: 0.5801169872283936)
[2024-12-17 03:55:24,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:24,651][root][INFO] - Training Epoch: 1/2, step 2632/7134 completed (loss: 1.3241945505142212, acc: 0.6149312257766724)
[2024-12-17 03:55:24,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:25,095][root][INFO] - Training Epoch: 1/2, step 2633/7134 completed (loss: 1.3824986219406128, acc: 0.5835694074630737)
[2024-12-17 03:55:25,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:25,524][root][INFO] - Training Epoch: 1/2, step 2634/7134 completed (loss: 1.463191032409668, acc: 0.5772113800048828)
[2024-12-17 03:55:25,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:25,985][root][INFO] - Training Epoch: 1/2, step 2635/7134 completed (loss: 1.4859590530395508, acc: 0.5569444298744202)
[2024-12-17 03:55:26,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:26,431][root][INFO] - Training Epoch: 1/2, step 2636/7134 completed (loss: 1.4998657703399658, acc: 0.5604552030563354)
[2024-12-17 03:55:26,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:26,852][root][INFO] - Training Epoch: 1/2, step 2637/7134 completed (loss: 1.4399099349975586, acc: 0.5840407609939575)
[2024-12-17 03:55:26,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:27,301][root][INFO] - Training Epoch: 1/2, step 2638/7134 completed (loss: 1.4896633625030518, acc: 0.571056067943573)
[2024-12-17 03:55:27,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:27,711][root][INFO] - Training Epoch: 1/2, step 2639/7134 completed (loss: 1.4586390256881714, acc: 0.5809128880500793)
[2024-12-17 03:55:27,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:28,155][root][INFO] - Training Epoch: 1/2, step 2640/7134 completed (loss: 1.310422658920288, acc: 0.6117353439331055)
[2024-12-17 03:55:28,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:28,590][root][INFO] - Training Epoch: 1/2, step 2641/7134 completed (loss: 1.33360755443573, acc: 0.6244477033615112)
[2024-12-17 03:55:28,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:28,986][root][INFO] - Training Epoch: 1/2, step 2642/7134 completed (loss: 1.4741320610046387, acc: 0.5551601648330688)
[2024-12-17 03:55:29,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:29,417][root][INFO] - Training Epoch: 1/2, step 2643/7134 completed (loss: 1.402779459953308, acc: 0.5980066657066345)
[2024-12-17 03:55:29,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:29,908][root][INFO] - Training Epoch: 1/2, step 2644/7134 completed (loss: 1.3396319150924683, acc: 0.5958737730979919)
[2024-12-17 03:55:30,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:30,323][root][INFO] - Training Epoch: 1/2, step 2645/7134 completed (loss: 1.4203094244003296, acc: 0.5743440389633179)
[2024-12-17 03:55:30,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:30,727][root][INFO] - Training Epoch: 1/2, step 2646/7134 completed (loss: 1.3929320573806763, acc: 0.5923566818237305)
[2024-12-17 03:55:30,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:31,182][root][INFO] - Training Epoch: 1/2, step 2647/7134 completed (loss: 1.3435015678405762, acc: 0.6228868365287781)
[2024-12-17 03:55:31,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:31,624][root][INFO] - Training Epoch: 1/2, step 2648/7134 completed (loss: 1.3319028615951538, acc: 0.6232258081436157)
[2024-12-17 03:55:31,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:32,069][root][INFO] - Training Epoch: 1/2, step 2649/7134 completed (loss: 1.6567105054855347, acc: 0.5305514335632324)
[2024-12-17 03:55:32,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:32,475][root][INFO] - Training Epoch: 1/2, step 2650/7134 completed (loss: 1.4716874361038208, acc: 0.5718607902526855)
[2024-12-17 03:55:32,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:32,916][root][INFO] - Training Epoch: 1/2, step 2651/7134 completed (loss: 1.2927145957946777, acc: 0.6162097454071045)
[2024-12-17 03:55:33,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:33,338][root][INFO] - Training Epoch: 1/2, step 2652/7134 completed (loss: 1.3130908012390137, acc: 0.6166456341743469)
[2024-12-17 03:55:33,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:33,733][root][INFO] - Training Epoch: 1/2, step 2653/7134 completed (loss: 1.3589993715286255, acc: 0.6085526347160339)
[2024-12-17 03:55:33,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:34,156][root][INFO] - Training Epoch: 1/2, step 2654/7134 completed (loss: 1.3369686603546143, acc: 0.6081967353820801)
[2024-12-17 03:55:34,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:34,564][root][INFO] - Training Epoch: 1/2, step 2655/7134 completed (loss: 1.237918734550476, acc: 0.6278365850448608)
[2024-12-17 03:55:34,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:34,988][root][INFO] - Training Epoch: 1/2, step 2656/7134 completed (loss: 1.2371848821640015, acc: 0.6411682963371277)
[2024-12-17 03:55:35,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:35,407][root][INFO] - Training Epoch: 1/2, step 2657/7134 completed (loss: 1.3180454969406128, acc: 0.6306451559066772)
[2024-12-17 03:55:35,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:35,836][root][INFO] - Training Epoch: 1/2, step 2658/7134 completed (loss: 1.3389185667037964, acc: 0.6088117361068726)
[2024-12-17 03:55:35,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:36,242][root][INFO] - Training Epoch: 1/2, step 2659/7134 completed (loss: 1.2477641105651855, acc: 0.6302682161331177)
[2024-12-17 03:55:36,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:36,641][root][INFO] - Training Epoch: 1/2, step 2660/7134 completed (loss: 1.2927931547164917, acc: 0.6169354915618896)
[2024-12-17 03:55:36,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:37,075][root][INFO] - Training Epoch: 1/2, step 2661/7134 completed (loss: 1.1704543828964233, acc: 0.6647966504096985)
[2024-12-17 03:55:37,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:37,522][root][INFO] - Training Epoch: 1/2, step 2662/7134 completed (loss: 1.1646956205368042, acc: 0.6642958521842957)
[2024-12-17 03:55:37,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:37,985][root][INFO] - Training Epoch: 1/2, step 2663/7134 completed (loss: 1.0555996894836426, acc: 0.6783625483512878)
[2024-12-17 03:55:38,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:38,424][root][INFO] - Training Epoch: 1/2, step 2664/7134 completed (loss: 1.1904152631759644, acc: 0.6348387002944946)
[2024-12-17 03:55:38,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:38,849][root][INFO] - Training Epoch: 1/2, step 2665/7134 completed (loss: 1.0609468221664429, acc: 0.6940104365348816)
[2024-12-17 03:55:38,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:39,318][root][INFO] - Training Epoch: 1/2, step 2666/7134 completed (loss: 0.942396342754364, acc: 0.7209302186965942)
[2024-12-17 03:55:39,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:39,736][root][INFO] - Training Epoch: 1/2, step 2667/7134 completed (loss: 0.8354096412658691, acc: 0.743626058101654)
[2024-12-17 03:55:39,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:40,162][root][INFO] - Training Epoch: 1/2, step 2668/7134 completed (loss: 0.8765161633491516, acc: 0.7456258535385132)
[2024-12-17 03:55:40,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:40,627][root][INFO] - Training Epoch: 1/2, step 2669/7134 completed (loss: 0.8399338722229004, acc: 0.7364786863327026)
[2024-12-17 03:55:40,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:41,065][root][INFO] - Training Epoch: 1/2, step 2670/7134 completed (loss: 0.8323128819465637, acc: 0.7431192398071289)
[2024-12-17 03:55:41,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:41,498][root][INFO] - Training Epoch: 1/2, step 2671/7134 completed (loss: 0.8306962847709656, acc: 0.7580214142799377)
[2024-12-17 03:55:41,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:41,945][root][INFO] - Training Epoch: 1/2, step 2672/7134 completed (loss: 0.7062748670578003, acc: 0.7871720194816589)
[2024-12-17 03:55:42,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:42,402][root][INFO] - Training Epoch: 1/2, step 2673/7134 completed (loss: 0.7171099185943604, acc: 0.7714646458625793)
[2024-12-17 03:55:42,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:42,817][root][INFO] - Training Epoch: 1/2, step 2674/7134 completed (loss: 0.7011483907699585, acc: 0.7838214635848999)
[2024-12-17 03:55:42,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:43,277][root][INFO] - Training Epoch: 1/2, step 2675/7134 completed (loss: 0.5538004040718079, acc: 0.8369863033294678)
[2024-12-17 03:55:43,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:43,734][root][INFO] - Training Epoch: 1/2, step 2676/7134 completed (loss: 0.6215131878852844, acc: 0.8246753215789795)
[2024-12-17 03:55:43,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:44,181][root][INFO] - Training Epoch: 1/2, step 2677/7134 completed (loss: 0.47106480598449707, acc: 0.8705357313156128)
[2024-12-17 03:55:44,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:44,639][root][INFO] - Training Epoch: 1/2, step 2678/7134 completed (loss: 0.4482719302177429, acc: 0.8522427678108215)
[2024-12-17 03:55:44,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:45,104][root][INFO] - Training Epoch: 1/2, step 2679/7134 completed (loss: 0.472495436668396, acc: 0.8585858345031738)
[2024-12-17 03:55:45,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:45,547][root][INFO] - Training Epoch: 1/2, step 2680/7134 completed (loss: 0.4362431764602661, acc: 0.879161536693573)
[2024-12-17 03:55:45,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:45,972][root][INFO] - Training Epoch: 1/2, step 2681/7134 completed (loss: 0.31187769770622253, acc: 0.9044005870819092)
[2024-12-17 03:55:46,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:46,391][root][INFO] - Training Epoch: 1/2, step 2682/7134 completed (loss: 0.3157370686531067, acc: 0.8947368264198303)
[2024-12-17 03:55:46,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:46,793][root][INFO] - Training Epoch: 1/2, step 2683/7134 completed (loss: 0.3919253945350647, acc: 0.8801214098930359)
[2024-12-17 03:55:46,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:47,225][root][INFO] - Training Epoch: 1/2, step 2684/7134 completed (loss: 0.4933333992958069, acc: 0.8781362175941467)
[2024-12-17 03:55:47,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:47,686][root][INFO] - Training Epoch: 1/2, step 2685/7134 completed (loss: 0.36597323417663574, acc: 0.8894668221473694)
[2024-12-17 03:55:47,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:48,158][root][INFO] - Training Epoch: 1/2, step 2686/7134 completed (loss: 0.5611147880554199, acc: 0.8391203880310059)
[2024-12-17 03:55:48,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:48,587][root][INFO] - Training Epoch: 1/2, step 2687/7134 completed (loss: 0.6085164546966553, acc: 0.8233215808868408)
[2024-12-17 03:55:48,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:49,025][root][INFO] - Training Epoch: 1/2, step 2688/7134 completed (loss: 0.6245009899139404, acc: 0.8128930926322937)
[2024-12-17 03:55:49,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:49,429][root][INFO] - Training Epoch: 1/2, step 2689/7134 completed (loss: 0.48654264211654663, acc: 0.8571428656578064)
[2024-12-17 03:55:49,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:49,907][root][INFO] - Training Epoch: 1/2, step 2690/7134 completed (loss: 0.7193533182144165, acc: 0.8160741925239563)
[2024-12-17 03:55:50,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:50,325][root][INFO] - Training Epoch: 1/2, step 2691/7134 completed (loss: 0.5713899731636047, acc: 0.837890625)
[2024-12-17 03:55:50,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:50,763][root][INFO] - Training Epoch: 1/2, step 2692/7134 completed (loss: 0.5171856880187988, acc: 0.8528863787651062)
[2024-12-17 03:55:50,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:51,127][root][INFO] - Training Epoch: 1/2, step 2693/7134 completed (loss: 0.5384482145309448, acc: 0.8480769395828247)
[2024-12-17 03:55:51,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:51,545][root][INFO] - Training Epoch: 1/2, step 2694/7134 completed (loss: 0.5290722846984863, acc: 0.854411780834198)
[2024-12-17 03:55:51,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:52,016][root][INFO] - Training Epoch: 1/2, step 2695/7134 completed (loss: 0.46014338731765747, acc: 0.8643215894699097)
[2024-12-17 03:55:52,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:52,471][root][INFO] - Training Epoch: 1/2, step 2696/7134 completed (loss: 0.44584739208221436, acc: 0.8600953817367554)
[2024-12-17 03:55:52,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:52,882][root][INFO] - Training Epoch: 1/2, step 2697/7134 completed (loss: 0.5322539806365967, acc: 0.8428351283073425)
[2024-12-17 03:55:52,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:53,324][root][INFO] - Training Epoch: 1/2, step 2698/7134 completed (loss: 0.4918343722820282, acc: 0.8393162488937378)
[2024-12-17 03:55:53,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:53,779][root][INFO] - Training Epoch: 1/2, step 2699/7134 completed (loss: 0.4472372829914093, acc: 0.871964693069458)
[2024-12-17 03:55:53,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:54,175][root][INFO] - Training Epoch: 1/2, step 2700/7134 completed (loss: 0.49537181854248047, acc: 0.8664688467979431)
[2024-12-17 03:55:54,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:54,628][root][INFO] - Training Epoch: 1/2, step 2701/7134 completed (loss: 0.4178692102432251, acc: 0.8672268986701965)
[2024-12-17 03:55:54,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:55,037][root][INFO] - Training Epoch: 1/2, step 2702/7134 completed (loss: 0.47483348846435547, acc: 0.8697916865348816)
[2024-12-17 03:55:55,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:55,442][root][INFO] - Training Epoch: 1/2, step 2703/7134 completed (loss: 0.36841243505477905, acc: 0.9076433181762695)
[2024-12-17 03:55:55,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:55,898][root][INFO] - Training Epoch: 1/2, step 2704/7134 completed (loss: 0.3623960018157959, acc: 0.8867924809455872)
[2024-12-17 03:55:56,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:56,339][root][INFO] - Training Epoch: 1/2, step 2705/7134 completed (loss: 0.3976343870162964, acc: 0.8842592835426331)
[2024-12-17 03:55:56,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:56,801][root][INFO] - Training Epoch: 1/2, step 2706/7134 completed (loss: 0.3160909414291382, acc: 0.8882438540458679)
[2024-12-17 03:55:56,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:57,262][root][INFO] - Training Epoch: 1/2, step 2707/7134 completed (loss: 0.3704347610473633, acc: 0.9051724076271057)
[2024-12-17 03:55:57,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:57,733][root][INFO] - Training Epoch: 1/2, step 2708/7134 completed (loss: 0.4079800546169281, acc: 0.8821879625320435)
[2024-12-17 03:55:57,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:58,202][root][INFO] - Training Epoch: 1/2, step 2709/7134 completed (loss: 0.2789580225944519, acc: 0.9188311696052551)
[2024-12-17 03:55:58,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:58,637][root][INFO] - Training Epoch: 1/2, step 2710/7134 completed (loss: 0.2879791557788849, acc: 0.9230769276618958)
[2024-12-17 03:55:58,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:59,056][root][INFO] - Training Epoch: 1/2, step 2711/7134 completed (loss: 0.3361937403678894, acc: 0.9033018946647644)
[2024-12-17 03:55:59,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:59,512][root][INFO] - Training Epoch: 1/2, step 2712/7134 completed (loss: 0.41252654790878296, acc: 0.8772321343421936)
[2024-12-17 03:55:59,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:55:59,976][root][INFO] - Training Epoch: 1/2, step 2713/7134 completed (loss: 0.30999425053596497, acc: 0.9136490225791931)
[2024-12-17 03:56:00,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:00,433][root][INFO] - Training Epoch: 1/2, step 2714/7134 completed (loss: 0.23783424496650696, acc: 0.9367720484733582)
[2024-12-17 03:56:00,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:00,870][root][INFO] - Training Epoch: 1/2, step 2715/7134 completed (loss: 0.2543768882751465, acc: 0.927819550037384)
[2024-12-17 03:56:00,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:01,306][root][INFO] - Training Epoch: 1/2, step 2716/7134 completed (loss: 0.27505138516426086, acc: 0.9134993553161621)
[2024-12-17 03:56:01,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:01,732][root][INFO] - Training Epoch: 1/2, step 2717/7134 completed (loss: 0.43612048029899597, acc: 0.8788501024246216)
[2024-12-17 03:56:01,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:02,172][root][INFO] - Training Epoch: 1/2, step 2718/7134 completed (loss: 0.5269059538841248, acc: 0.8591549396514893)
[2024-12-17 03:56:02,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:02,617][root][INFO] - Training Epoch: 1/2, step 2719/7134 completed (loss: 0.41555124521255493, acc: 0.8967850804328918)
[2024-12-17 03:56:02,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:03,059][root][INFO] - Training Epoch: 1/2, step 2720/7134 completed (loss: 0.3074256479740143, acc: 0.8943217396736145)
[2024-12-17 03:56:03,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:03,456][root][INFO] - Training Epoch: 1/2, step 2721/7134 completed (loss: 0.22686567902565002, acc: 0.9304347634315491)
[2024-12-17 03:56:03,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:03,829][root][INFO] - Training Epoch: 1/2, step 2722/7134 completed (loss: 0.39628493785858154, acc: 0.9021739363670349)
[2024-12-17 03:56:03,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:04,267][root][INFO] - Training Epoch: 1/2, step 2723/7134 completed (loss: 0.4143369793891907, acc: 0.892988920211792)
[2024-12-17 03:56:04,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:04,712][root][INFO] - Training Epoch: 1/2, step 2724/7134 completed (loss: 0.3677924871444702, acc: 0.8967193365097046)
[2024-12-17 03:56:04,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:05,161][root][INFO] - Training Epoch: 1/2, step 2725/7134 completed (loss: 0.2746635675430298, acc: 0.9195402264595032)
[2024-12-17 03:56:05,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:05,582][root][INFO] - Training Epoch: 1/2, step 2726/7134 completed (loss: 0.30659228563308716, acc: 0.9188191890716553)
[2024-12-17 03:56:05,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:06,055][root][INFO] - Training Epoch: 1/2, step 2727/7134 completed (loss: 0.32544612884521484, acc: 0.9074074029922485)
[2024-12-17 03:56:06,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:06,467][root][INFO] - Training Epoch: 1/2, step 2728/7134 completed (loss: 0.5579202175140381, acc: 0.85550457239151)
[2024-12-17 03:56:06,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:06,915][root][INFO] - Training Epoch: 1/2, step 2729/7134 completed (loss: 0.5284504890441895, acc: 0.8519163727760315)
[2024-12-17 03:56:07,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:07,331][root][INFO] - Training Epoch: 1/2, step 2730/7134 completed (loss: 0.34760984778404236, acc: 0.9041666388511658)
[2024-12-17 03:56:07,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:07,720][root][INFO] - Training Epoch: 1/2, step 2731/7134 completed (loss: 0.39213043451309204, acc: 0.8929440379142761)
[2024-12-17 03:56:07,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:08,166][root][INFO] - Training Epoch: 1/2, step 2732/7134 completed (loss: 0.3614971339702606, acc: 0.8946700692176819)
[2024-12-17 03:56:08,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:08,601][root][INFO] - Training Epoch: 1/2, step 2733/7134 completed (loss: 0.3216911256313324, acc: 0.9077340364456177)
[2024-12-17 03:56:08,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:08,995][root][INFO] - Training Epoch: 1/2, step 2734/7134 completed (loss: 0.2883921265602112, acc: 0.9295774698257446)
[2024-12-17 03:56:09,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:09,485][root][INFO] - Training Epoch: 1/2, step 2735/7134 completed (loss: 0.25791916251182556, acc: 0.9214091897010803)
[2024-12-17 03:56:09,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:09,868][root][INFO] - Training Epoch: 1/2, step 2736/7134 completed (loss: 0.3586159348487854, acc: 0.9011194109916687)
[2024-12-17 03:56:09,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:10,276][root][INFO] - Training Epoch: 1/2, step 2737/7134 completed (loss: 0.2705574631690979, acc: 0.9224422574043274)
[2024-12-17 03:56:10,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:10,683][root][INFO] - Training Epoch: 1/2, step 2738/7134 completed (loss: 0.2953680753707886, acc: 0.9171428680419922)
[2024-12-17 03:56:10,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:11,119][root][INFO] - Training Epoch: 1/2, step 2739/7134 completed (loss: 0.31776517629623413, acc: 0.8963636159896851)
[2024-12-17 03:56:11,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:11,537][root][INFO] - Training Epoch: 1/2, step 2740/7134 completed (loss: 0.2611924409866333, acc: 0.9230769276618958)
[2024-12-17 03:56:11,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:11,938][root][INFO] - Training Epoch: 1/2, step 2741/7134 completed (loss: 0.3491435945034027, acc: 0.9112149477005005)
[2024-12-17 03:56:12,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:12,382][root][INFO] - Training Epoch: 1/2, step 2742/7134 completed (loss: 0.33790963888168335, acc: 0.9083333611488342)
[2024-12-17 03:56:12,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:12,785][root][INFO] - Training Epoch: 1/2, step 2743/7134 completed (loss: 0.18220578134059906, acc: 0.942105233669281)
[2024-12-17 03:56:12,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:13,151][root][INFO] - Training Epoch: 1/2, step 2744/7134 completed (loss: 0.23758719861507416, acc: 0.938697338104248)
[2024-12-17 03:56:13,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:13,568][root][INFO] - Training Epoch: 1/2, step 2745/7134 completed (loss: 0.3988763988018036, acc: 0.888501763343811)
[2024-12-17 03:56:13,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:13,977][root][INFO] - Training Epoch: 1/2, step 2746/7134 completed (loss: 0.2627452313899994, acc: 0.9262820482254028)
[2024-12-17 03:56:14,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:14,369][root][INFO] - Training Epoch: 1/2, step 2747/7134 completed (loss: 0.26841333508491516, acc: 0.9262899160385132)
[2024-12-17 03:56:14,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:14,704][root][INFO] - Training Epoch: 1/2, step 2748/7134 completed (loss: 0.11437711119651794, acc: 0.9713375568389893)
[2024-12-17 03:56:14,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:15,074][root][INFO] - Training Epoch: 1/2, step 2749/7134 completed (loss: 0.15547356009483337, acc: 0.9644808769226074)
[2024-12-17 03:56:15,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:15,477][root][INFO] - Training Epoch: 1/2, step 2750/7134 completed (loss: 0.2005375474691391, acc: 0.9413533806800842)
[2024-12-17 03:56:15,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:15,869][root][INFO] - Training Epoch: 1/2, step 2751/7134 completed (loss: 0.20428171753883362, acc: 0.9316455721855164)
[2024-12-17 03:56:15,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:16,275][root][INFO] - Training Epoch: 1/2, step 2752/7134 completed (loss: 0.23929980397224426, acc: 0.9315589070320129)
[2024-12-17 03:56:16,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:16,710][root][INFO] - Training Epoch: 1/2, step 2753/7134 completed (loss: 0.31291431188583374, acc: 0.9248120188713074)
[2024-12-17 03:56:16,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:17,163][root][INFO] - Training Epoch: 1/2, step 2754/7134 completed (loss: 0.3008061647415161, acc: 0.9269776940345764)
[2024-12-17 03:56:17,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:17,572][root][INFO] - Training Epoch: 1/2, step 2755/7134 completed (loss: 0.12418798357248306, acc: 0.9651162624359131)
[2024-12-17 03:56:17,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:18,004][root][INFO] - Training Epoch: 1/2, step 2756/7134 completed (loss: 0.2651119828224182, acc: 0.9295238256454468)
[2024-12-17 03:56:18,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:18,382][root][INFO] - Training Epoch: 1/2, step 2757/7134 completed (loss: 0.2508237957954407, acc: 0.9426229596138)
[2024-12-17 03:56:18,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:18,817][root][INFO] - Training Epoch: 1/2, step 2758/7134 completed (loss: 0.21298834681510925, acc: 0.9429223537445068)
[2024-12-17 03:56:18,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:19,226][root][INFO] - Training Epoch: 1/2, step 2759/7134 completed (loss: 0.26212942600250244, acc: 0.9230769276618958)
[2024-12-17 03:56:19,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:19,593][root][INFO] - Training Epoch: 1/2, step 2760/7134 completed (loss: 0.2534164488315582, acc: 0.9238095283508301)
[2024-12-17 03:56:19,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:20,007][root][INFO] - Training Epoch: 1/2, step 2761/7134 completed (loss: 0.24469153583049774, acc: 0.9431818127632141)
[2024-12-17 03:56:20,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:20,484][root][INFO] - Training Epoch: 1/2, step 2762/7134 completed (loss: 0.24894367158412933, acc: 0.9286535978317261)
[2024-12-17 03:56:20,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:20,920][root][INFO] - Training Epoch: 1/2, step 2763/7134 completed (loss: 0.20135188102722168, acc: 0.9484924674034119)
[2024-12-17 03:56:21,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:21,387][root][INFO] - Training Epoch: 1/2, step 2764/7134 completed (loss: 0.2609102427959442, acc: 0.9249011874198914)
[2024-12-17 03:56:21,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:21,826][root][INFO] - Training Epoch: 1/2, step 2765/7134 completed (loss: 0.2473374903202057, acc: 0.9353448152542114)
[2024-12-17 03:56:21,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:22,287][root][INFO] - Training Epoch: 1/2, step 2766/7134 completed (loss: 0.20858803391456604, acc: 0.9386106729507446)
[2024-12-17 03:56:22,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:22,733][root][INFO] - Training Epoch: 1/2, step 2767/7134 completed (loss: 0.339857280254364, acc: 0.9074074029922485)
[2024-12-17 03:56:22,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:23,176][root][INFO] - Training Epoch: 1/2, step 2768/7134 completed (loss: 0.2440274953842163, acc: 0.9264497756958008)
[2024-12-17 03:56:23,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:23,623][root][INFO] - Training Epoch: 1/2, step 2769/7134 completed (loss: 0.25088074803352356, acc: 0.9256756901741028)
[2024-12-17 03:56:23,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:24,080][root][INFO] - Training Epoch: 1/2, step 2770/7134 completed (loss: 0.2445656806230545, acc: 0.9346314072608948)
[2024-12-17 03:56:24,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:24,595][root][INFO] - Training Epoch: 1/2, step 2771/7134 completed (loss: 0.2471984326839447, acc: 0.9281886219978333)
[2024-12-17 03:56:24,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:25,072][root][INFO] - Training Epoch: 1/2, step 2772/7134 completed (loss: 0.20731161534786224, acc: 0.9451901316642761)
[2024-12-17 03:56:25,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:25,538][root][INFO] - Training Epoch: 1/2, step 2773/7134 completed (loss: 0.23162178695201874, acc: 0.9394285678863525)
[2024-12-17 03:56:25,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:25,995][root][INFO] - Training Epoch: 1/2, step 2774/7134 completed (loss: 0.2331157624721527, acc: 0.9353070259094238)
[2024-12-17 03:56:26,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:26,434][root][INFO] - Training Epoch: 1/2, step 2775/7134 completed (loss: 0.17789973318576813, acc: 0.9521472454071045)
[2024-12-17 03:56:26,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:26,921][root][INFO] - Training Epoch: 1/2, step 2776/7134 completed (loss: 0.17899154126644135, acc: 0.9447852969169617)
[2024-12-17 03:56:27,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:27,361][root][INFO] - Training Epoch: 1/2, step 2777/7134 completed (loss: 0.1808428168296814, acc: 0.9426829218864441)
[2024-12-17 03:56:27,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:27,822][root][INFO] - Training Epoch: 1/2, step 2778/7134 completed (loss: 0.1598481982946396, acc: 0.9582850337028503)
[2024-12-17 03:56:27,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:28,290][root][INFO] - Training Epoch: 1/2, step 2779/7134 completed (loss: 0.22830064594745636, acc: 0.9356539845466614)
[2024-12-17 03:56:28,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:28,753][root][INFO] - Training Epoch: 1/2, step 2780/7134 completed (loss: 0.19798757135868073, acc: 0.9324894547462463)
[2024-12-17 03:56:28,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:29,220][root][INFO] - Training Epoch: 1/2, step 2781/7134 completed (loss: 0.1807263046503067, acc: 0.9520725607872009)
[2024-12-17 03:56:29,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:29,678][root][INFO] - Training Epoch: 1/2, step 2782/7134 completed (loss: 0.16555123031139374, acc: 0.950630247592926)
[2024-12-17 03:56:29,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:30,113][root][INFO] - Training Epoch: 1/2, step 2783/7134 completed (loss: 0.14620380103588104, acc: 0.9564564824104309)
[2024-12-17 03:56:30,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:30,576][root][INFO] - Training Epoch: 1/2, step 2784/7134 completed (loss: 0.13841159641742706, acc: 0.9558359384536743)
[2024-12-17 03:56:30,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:31,046][root][INFO] - Training Epoch: 1/2, step 2785/7134 completed (loss: 0.1393262892961502, acc: 0.9596070051193237)
[2024-12-17 03:56:31,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:31,508][root][INFO] - Training Epoch: 1/2, step 2786/7134 completed (loss: 0.1737688034772873, acc: 0.9501557350158691)
[2024-12-17 03:56:31,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:31,984][root][INFO] - Training Epoch: 1/2, step 2787/7134 completed (loss: 0.17155298590660095, acc: 0.9495351910591125)
[2024-12-17 03:56:32,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:32,440][root][INFO] - Training Epoch: 1/2, step 2788/7134 completed (loss: 0.17043760418891907, acc: 0.9476439952850342)
[2024-12-17 03:56:32,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:32,817][root][INFO] - Training Epoch: 1/2, step 2789/7134 completed (loss: 0.45145514607429504, acc: 0.8616714477539062)
[2024-12-17 03:56:32,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:33,206][root][INFO] - Training Epoch: 1/2, step 2790/7134 completed (loss: 0.3677932918071747, acc: 0.9072847962379456)
[2024-12-17 03:56:33,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:33,655][root][INFO] - Training Epoch: 1/2, step 2791/7134 completed (loss: 0.1918979287147522, acc: 0.9431988000869751)
[2024-12-17 03:56:33,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:34,115][root][INFO] - Training Epoch: 1/2, step 2792/7134 completed (loss: 0.13630814850330353, acc: 0.9592549204826355)
[2024-12-17 03:56:34,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:34,566][root][INFO] - Training Epoch: 1/2, step 2793/7134 completed (loss: 0.16713076829910278, acc: 0.9487179517745972)
[2024-12-17 03:56:34,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:34,942][root][INFO] - Training Epoch: 1/2, step 2794/7134 completed (loss: 0.35148581862449646, acc: 0.885993480682373)
[2024-12-17 03:56:35,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:35,372][root][INFO] - Training Epoch: 1/2, step 2795/7134 completed (loss: 0.36620083451271057, acc: 0.8932714462280273)
[2024-12-17 03:56:35,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:35,785][root][INFO] - Training Epoch: 1/2, step 2796/7134 completed (loss: 0.45807433128356934, acc: 0.8732718825340271)
[2024-12-17 03:56:35,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:36,205][root][INFO] - Training Epoch: 1/2, step 2797/7134 completed (loss: 0.2817328870296478, acc: 0.9240506291389465)
[2024-12-17 03:56:36,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:36,629][root][INFO] - Training Epoch: 1/2, step 2798/7134 completed (loss: 0.40793880820274353, acc: 0.8655462265014648)
[2024-12-17 03:56:36,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:37,066][root][INFO] - Training Epoch: 1/2, step 2799/7134 completed (loss: 0.37787967920303345, acc: 0.8984237909317017)
[2024-12-17 03:56:37,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:37,436][root][INFO] - Training Epoch: 1/2, step 2800/7134 completed (loss: 0.3912113606929779, acc: 0.9015817046165466)
[2024-12-17 03:56:37,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:37,896][root][INFO] - Training Epoch: 1/2, step 2801/7134 completed (loss: 0.26928576827049255, acc: 0.9181585907936096)
[2024-12-17 03:56:38,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:38,356][root][INFO] - Training Epoch: 1/2, step 2802/7134 completed (loss: 0.2490290254354477, acc: 0.9275904893875122)
[2024-12-17 03:56:38,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:38,794][root][INFO] - Training Epoch: 1/2, step 2803/7134 completed (loss: 0.17220211029052734, acc: 0.9504950642585754)
[2024-12-17 03:56:38,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:39,269][root][INFO] - Training Epoch: 1/2, step 2804/7134 completed (loss: 0.20805954933166504, acc: 0.9368811845779419)
[2024-12-17 03:56:39,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:39,699][root][INFO] - Training Epoch: 1/2, step 2805/7134 completed (loss: 0.15253639221191406, acc: 0.9631093740463257)
[2024-12-17 03:56:39,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:40,124][root][INFO] - Training Epoch: 1/2, step 2806/7134 completed (loss: 0.2445063591003418, acc: 0.9393442869186401)
[2024-12-17 03:56:40,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:40,548][root][INFO] - Training Epoch: 1/2, step 2807/7134 completed (loss: 0.33813267946243286, acc: 0.9064449071884155)
[2024-12-17 03:56:40,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:40,996][root][INFO] - Training Epoch: 1/2, step 2808/7134 completed (loss: 0.19577457010746002, acc: 0.9417142868041992)
[2024-12-17 03:56:41,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:41,421][root][INFO] - Training Epoch: 1/2, step 2809/7134 completed (loss: 0.21850591897964478, acc: 0.9376114010810852)
[2024-12-17 03:56:41,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:41,915][root][INFO] - Training Epoch: 1/2, step 2810/7134 completed (loss: 0.15295881032943726, acc: 0.9524940848350525)
[2024-12-17 03:56:42,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:42,401][root][INFO] - Training Epoch: 1/2, step 2811/7134 completed (loss: 0.1611282378435135, acc: 0.9439140558242798)
[2024-12-17 03:56:42,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:42,872][root][INFO] - Training Epoch: 1/2, step 2812/7134 completed (loss: 0.17825676500797272, acc: 0.9475308656692505)
[2024-12-17 03:56:42,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:43,337][root][INFO] - Training Epoch: 1/2, step 2813/7134 completed (loss: 0.10860717296600342, acc: 0.9685138463973999)
[2024-12-17 03:56:43,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:43,752][root][INFO] - Training Epoch: 1/2, step 2814/7134 completed (loss: 0.13288705050945282, acc: 0.9662337899208069)
[2024-12-17 03:56:43,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:44,210][root][INFO] - Training Epoch: 1/2, step 2815/7134 completed (loss: 0.16123901307582855, acc: 0.9584816098213196)
[2024-12-17 03:56:44,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:44,691][root][INFO] - Training Epoch: 1/2, step 2816/7134 completed (loss: 0.17066563665866852, acc: 0.9525691866874695)
[2024-12-17 03:56:44,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:45,182][root][INFO] - Training Epoch: 1/2, step 2817/7134 completed (loss: 0.18054375052452087, acc: 0.955974817276001)
[2024-12-17 03:56:45,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:45,638][root][INFO] - Training Epoch: 1/2, step 2818/7134 completed (loss: 0.13362351059913635, acc: 0.9627193212509155)
[2024-12-17 03:56:45,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:46,108][root][INFO] - Training Epoch: 1/2, step 2819/7134 completed (loss: 0.12943488359451294, acc: 0.9709208607673645)
[2024-12-17 03:56:46,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:46,535][root][INFO] - Training Epoch: 1/2, step 2820/7134 completed (loss: 0.25807985663414, acc: 0.9410898089408875)
[2024-12-17 03:56:46,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:46,977][root][INFO] - Training Epoch: 1/2, step 2821/7134 completed (loss: 0.23970118165016174, acc: 0.9330943822860718)
[2024-12-17 03:56:47,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:47,453][root][INFO] - Training Epoch: 1/2, step 2822/7134 completed (loss: 0.2973422706127167, acc: 0.9317319989204407)
[2024-12-17 03:56:47,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:47,989][root][INFO] - Training Epoch: 1/2, step 2823/7134 completed (loss: 0.30758124589920044, acc: 0.9191489219665527)
[2024-12-17 03:56:48,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:48,416][root][INFO] - Training Epoch: 1/2, step 2824/7134 completed (loss: 0.36192381381988525, acc: 0.8944805264472961)
[2024-12-17 03:56:48,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:48,850][root][INFO] - Training Epoch: 1/2, step 2825/7134 completed (loss: 0.23589591681957245, acc: 0.9369127750396729)
[2024-12-17 03:56:48,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:49,288][root][INFO] - Training Epoch: 1/2, step 2826/7134 completed (loss: 0.27037662267684937, acc: 0.9352409839630127)
[2024-12-17 03:56:49,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:49,733][root][INFO] - Training Epoch: 1/2, step 2827/7134 completed (loss: 0.294082373380661, acc: 0.9182630777359009)
[2024-12-17 03:56:49,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:50,182][root][INFO] - Training Epoch: 1/2, step 2828/7134 completed (loss: 0.286162793636322, acc: 0.9279999732971191)
[2024-12-17 03:56:50,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:50,627][root][INFO] - Training Epoch: 1/2, step 2829/7134 completed (loss: 0.2573450207710266, acc: 0.9236016273498535)
[2024-12-17 03:56:50,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:51,070][root][INFO] - Training Epoch: 1/2, step 2830/7134 completed (loss: 0.1512881964445114, acc: 0.9562841653823853)
[2024-12-17 03:56:51,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:51,494][root][INFO] - Training Epoch: 1/2, step 2831/7134 completed (loss: 0.18883690237998962, acc: 0.9447077512741089)
[2024-12-17 03:56:51,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:51,923][root][INFO] - Training Epoch: 1/2, step 2832/7134 completed (loss: 0.195429265499115, acc: 0.9574176073074341)
[2024-12-17 03:56:52,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:52,382][root][INFO] - Training Epoch: 1/2, step 2833/7134 completed (loss: 0.15882161259651184, acc: 0.9567251205444336)
[2024-12-17 03:56:52,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:52,832][root][INFO] - Training Epoch: 1/2, step 2834/7134 completed (loss: 0.20561601221561432, acc: 0.9403553009033203)
[2024-12-17 03:56:52,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:53,273][root][INFO] - Training Epoch: 1/2, step 2835/7134 completed (loss: 0.23785053193569183, acc: 0.9402261972427368)
[2024-12-17 03:56:53,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:53,675][root][INFO] - Training Epoch: 1/2, step 2836/7134 completed (loss: 0.23121856153011322, acc: 0.9407582879066467)
[2024-12-17 03:56:53,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:54,120][root][INFO] - Training Epoch: 1/2, step 2837/7134 completed (loss: 0.21490369737148285, acc: 0.9310810565948486)
[2024-12-17 03:56:54,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:54,598][root][INFO] - Training Epoch: 1/2, step 2838/7134 completed (loss: 0.22647960484027863, acc: 0.930962324142456)
[2024-12-17 03:56:54,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:55,029][root][INFO] - Training Epoch: 1/2, step 2839/7134 completed (loss: 0.16261789202690125, acc: 0.9559939503669739)
[2024-12-17 03:56:55,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:55,500][root][INFO] - Training Epoch: 1/2, step 2840/7134 completed (loss: 0.09243036061525345, acc: 0.9723756909370422)
[2024-12-17 03:56:55,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:55,936][root][INFO] - Training Epoch: 1/2, step 2841/7134 completed (loss: 0.25867027044296265, acc: 0.921658992767334)
[2024-12-17 03:56:56,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:56,399][root][INFO] - Training Epoch: 1/2, step 2842/7134 completed (loss: 0.20210504531860352, acc: 0.9428571462631226)
[2024-12-17 03:56:56,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:56,813][root][INFO] - Training Epoch: 1/2, step 2843/7134 completed (loss: 0.14951281249523163, acc: 0.9529411792755127)
[2024-12-17 03:56:56,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:57,264][root][INFO] - Training Epoch: 1/2, step 2844/7134 completed (loss: 0.29894304275512695, acc: 0.9261285662651062)
[2024-12-17 03:56:57,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:57,676][root][INFO] - Training Epoch: 1/2, step 2845/7134 completed (loss: 0.14340472221374512, acc: 0.9653379321098328)
[2024-12-17 03:56:57,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:58,096][root][INFO] - Training Epoch: 1/2, step 2846/7134 completed (loss: 0.2171347290277481, acc: 0.9439868330955505)
[2024-12-17 03:56:58,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:58,551][root][INFO] - Training Epoch: 1/2, step 2847/7134 completed (loss: 0.24581627547740936, acc: 0.9222874045372009)
[2024-12-17 03:56:58,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:58,945][root][INFO] - Training Epoch: 1/2, step 2848/7134 completed (loss: 0.20062632858753204, acc: 0.9370629191398621)
[2024-12-17 03:56:59,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:59,387][root][INFO] - Training Epoch: 1/2, step 2849/7134 completed (loss: 0.14883819222450256, acc: 0.9612724781036377)
[2024-12-17 03:56:59,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:56:59,802][root][INFO] - Training Epoch: 1/2, step 2850/7134 completed (loss: 0.11401844769716263, acc: 0.9591397643089294)
[2024-12-17 03:56:59,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:00,227][root][INFO] - Training Epoch: 1/2, step 2851/7134 completed (loss: 0.1599203646183014, acc: 0.9760589599609375)
[2024-12-17 03:57:00,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:00,640][root][INFO] - Training Epoch: 1/2, step 2852/7134 completed (loss: 0.09892357140779495, acc: 0.974155068397522)
[2024-12-17 03:57:00,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:01,024][root][INFO] - Training Epoch: 1/2, step 2853/7134 completed (loss: 0.11226897686719894, acc: 0.9670050740242004)
[2024-12-17 03:57:01,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:01,458][root][INFO] - Training Epoch: 1/2, step 2854/7134 completed (loss: 0.12011934071779251, acc: 0.9658246636390686)
[2024-12-17 03:57:01,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:01,861][root][INFO] - Training Epoch: 1/2, step 2855/7134 completed (loss: 0.09278961271047592, acc: 0.9806138873100281)
[2024-12-17 03:57:02,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:02,327][root][INFO] - Training Epoch: 1/2, step 2856/7134 completed (loss: 0.09056674689054489, acc: 0.9746121168136597)
[2024-12-17 03:57:02,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:02,780][root][INFO] - Training Epoch: 1/2, step 2857/7134 completed (loss: 0.12212169170379639, acc: 0.9725433588027954)
[2024-12-17 03:57:02,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:03,184][root][INFO] - Training Epoch: 1/2, step 2858/7134 completed (loss: 0.0752769410610199, acc: 0.9779179692268372)
[2024-12-17 03:57:03,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:03,610][root][INFO] - Training Epoch: 1/2, step 2859/7134 completed (loss: 0.17830854654312134, acc: 0.956764280796051)
[2024-12-17 03:57:03,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:04,017][root][INFO] - Training Epoch: 1/2, step 2860/7134 completed (loss: 0.12567901611328125, acc: 0.957798182964325)
[2024-12-17 03:57:04,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:04,429][root][INFO] - Training Epoch: 1/2, step 2861/7134 completed (loss: 0.10174015909433365, acc: 0.9716024398803711)
[2024-12-17 03:57:04,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:04,829][root][INFO] - Training Epoch: 1/2, step 2862/7134 completed (loss: 0.08374898880720139, acc: 0.9691252112388611)
[2024-12-17 03:57:04,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:05,276][root][INFO] - Training Epoch: 1/2, step 2863/7134 completed (loss: 0.07088302075862885, acc: 0.9757961630821228)
[2024-12-17 03:57:05,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:05,626][root][INFO] - Training Epoch: 1/2, step 2864/7134 completed (loss: 0.09591879695653915, acc: 0.9766233563423157)
[2024-12-17 03:57:05,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:06,053][root][INFO] - Training Epoch: 1/2, step 2865/7134 completed (loss: 0.08996579051017761, acc: 0.969565212726593)
[2024-12-17 03:57:06,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:06,480][root][INFO] - Training Epoch: 1/2, step 2866/7134 completed (loss: 0.14324355125427246, acc: 0.9641255736351013)
[2024-12-17 03:57:06,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:06,913][root][INFO] - Training Epoch: 1/2, step 2867/7134 completed (loss: 0.11358175426721573, acc: 0.9693251252174377)
[2024-12-17 03:57:07,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:07,329][root][INFO] - Training Epoch: 1/2, step 2868/7134 completed (loss: 0.18245570361614227, acc: 0.949438214302063)
[2024-12-17 03:57:07,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:07,742][root][INFO] - Training Epoch: 1/2, step 2869/7134 completed (loss: 0.10139858722686768, acc: 0.9721815586090088)
[2024-12-17 03:57:07,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:08,166][root][INFO] - Training Epoch: 1/2, step 2870/7134 completed (loss: 0.15615685284137726, acc: 0.947589099407196)
[2024-12-17 03:57:08,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:08,600][root][INFO] - Training Epoch: 1/2, step 2871/7134 completed (loss: 0.13122916221618652, acc: 0.9672386646270752)
[2024-12-17 03:57:08,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:09,025][root][INFO] - Training Epoch: 1/2, step 2872/7134 completed (loss: 0.080237977206707, acc: 0.97265625)
[2024-12-17 03:57:09,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:09,449][root][INFO] - Training Epoch: 1/2, step 2873/7134 completed (loss: 0.09411945939064026, acc: 0.9781022071838379)
[2024-12-17 03:57:09,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:09,876][root][INFO] - Training Epoch: 1/2, step 2874/7134 completed (loss: 0.09507381170988083, acc: 0.975039005279541)
[2024-12-17 03:57:10,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:10,332][root][INFO] - Training Epoch: 1/2, step 2875/7134 completed (loss: 0.09426838904619217, acc: 0.9758179187774658)
[2024-12-17 03:57:10,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:10,732][root][INFO] - Training Epoch: 1/2, step 2876/7134 completed (loss: 0.16332559287548065, acc: 0.9562212228775024)
[2024-12-17 03:57:10,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:11,162][root][INFO] - Training Epoch: 1/2, step 2877/7134 completed (loss: 0.11849275976419449, acc: 0.9650654792785645)
[2024-12-17 03:57:11,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:11,556][root][INFO] - Training Epoch: 1/2, step 2878/7134 completed (loss: 0.08481209725141525, acc: 0.9788135886192322)
[2024-12-17 03:57:11,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:11,970][root][INFO] - Training Epoch: 1/2, step 2879/7134 completed (loss: 0.06037962809205055, acc: 0.9843260049819946)
[2024-12-17 03:57:12,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:12,409][root][INFO] - Training Epoch: 1/2, step 2880/7134 completed (loss: 0.0917200893163681, acc: 0.96875)
[2024-12-17 03:57:12,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:12,810][root][INFO] - Training Epoch: 1/2, step 2881/7134 completed (loss: 0.09584106504917145, acc: 0.971377432346344)
[2024-12-17 03:57:12,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:13,247][root][INFO] - Training Epoch: 1/2, step 2882/7134 completed (loss: 0.144968643784523, acc: 0.956843376159668)
[2024-12-17 03:57:13,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:13,665][root][INFO] - Training Epoch: 1/2, step 2883/7134 completed (loss: 0.12475679069757462, acc: 0.9695767164230347)
[2024-12-17 03:57:13,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:14,066][root][INFO] - Training Epoch: 1/2, step 2884/7134 completed (loss: 0.19952641427516937, acc: 0.953242838382721)
[2024-12-17 03:57:14,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:14,464][root][INFO] - Training Epoch: 1/2, step 2885/7134 completed (loss: 0.1713988482952118, acc: 0.9484066963195801)
[2024-12-17 03:57:14,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:14,858][root][INFO] - Training Epoch: 1/2, step 2886/7134 completed (loss: 0.18983449041843414, acc: 0.9522387981414795)
[2024-12-17 03:57:15,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:15,325][root][INFO] - Training Epoch: 1/2, step 2887/7134 completed (loss: 0.17894364893436432, acc: 0.944378674030304)
[2024-12-17 03:57:15,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:15,775][root][INFO] - Training Epoch: 1/2, step 2888/7134 completed (loss: 0.17701077461242676, acc: 0.9583911299705505)
[2024-12-17 03:57:15,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:16,203][root][INFO] - Training Epoch: 1/2, step 2889/7134 completed (loss: 0.1366722136735916, acc: 0.9653739333152771)
[2024-12-17 03:57:16,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:16,649][root][INFO] - Training Epoch: 1/2, step 2890/7134 completed (loss: 0.13915835320949554, acc: 0.9627164006233215)
[2024-12-17 03:57:16,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:17,087][root][INFO] - Training Epoch: 1/2, step 2891/7134 completed (loss: 0.18016192317008972, acc: 0.9430769085884094)
[2024-12-17 03:57:17,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:17,528][root][INFO] - Training Epoch: 1/2, step 2892/7134 completed (loss: 0.22005866467952728, acc: 0.9471032619476318)
[2024-12-17 03:57:17,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:17,968][root][INFO] - Training Epoch: 1/2, step 2893/7134 completed (loss: 0.2233748584985733, acc: 0.941992461681366)
[2024-12-17 03:57:18,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:18,384][root][INFO] - Training Epoch: 1/2, step 2894/7134 completed (loss: 0.10632842779159546, acc: 0.9680672287940979)
[2024-12-17 03:57:18,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:18,763][root][INFO] - Training Epoch: 1/2, step 2895/7134 completed (loss: 0.13611574470996857, acc: 0.9527410268783569)
[2024-12-17 03:57:18,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:19,200][root][INFO] - Training Epoch: 1/2, step 2896/7134 completed (loss: 0.11677439510822296, acc: 0.9618320465087891)
[2024-12-17 03:57:19,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:19,595][root][INFO] - Training Epoch: 1/2, step 2897/7134 completed (loss: 0.20727895200252533, acc: 0.9449378252029419)
[2024-12-17 03:57:19,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:20,032][root][INFO] - Training Epoch: 1/2, step 2898/7134 completed (loss: 0.1348399966955185, acc: 0.9686274528503418)
[2024-12-17 03:57:20,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:20,463][root][INFO] - Training Epoch: 1/2, step 2899/7134 completed (loss: 0.19405631721019745, acc: 0.9505813717842102)
[2024-12-17 03:57:20,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:20,905][root][INFO] - Training Epoch: 1/2, step 2900/7134 completed (loss: 0.13180743157863617, acc: 0.9592592716217041)
[2024-12-17 03:57:21,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:21,346][root][INFO] - Training Epoch: 1/2, step 2901/7134 completed (loss: 0.15168796479701996, acc: 0.9649681448936462)
[2024-12-17 03:57:21,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:21,762][root][INFO] - Training Epoch: 1/2, step 2902/7134 completed (loss: 0.13644276559352875, acc: 0.9586465954780579)
[2024-12-17 03:57:21,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:22,198][root][INFO] - Training Epoch: 1/2, step 2903/7134 completed (loss: 0.155259370803833, acc: 0.9622132182121277)
[2024-12-17 03:57:22,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:22,647][root][INFO] - Training Epoch: 1/2, step 2904/7134 completed (loss: 0.09568746387958527, acc: 0.9687890410423279)
[2024-12-17 03:57:22,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:23,099][root][INFO] - Training Epoch: 1/2, step 2905/7134 completed (loss: 0.12901905179023743, acc: 0.9649562239646912)
[2024-12-17 03:57:23,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:23,547][root][INFO] - Training Epoch: 1/2, step 2906/7134 completed (loss: 0.06995563954114914, acc: 0.9724550843238831)
[2024-12-17 03:57:23,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:23,969][root][INFO] - Training Epoch: 1/2, step 2907/7134 completed (loss: 0.14245013892650604, acc: 0.9623149633407593)
[2024-12-17 03:57:24,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:24,413][root][INFO] - Training Epoch: 1/2, step 2908/7134 completed (loss: 0.10551159828901291, acc: 0.9728330969810486)
[2024-12-17 03:57:24,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:24,862][root][INFO] - Training Epoch: 1/2, step 2909/7134 completed (loss: 0.11023831367492676, acc: 0.9652278423309326)
[2024-12-17 03:57:25,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:25,334][root][INFO] - Training Epoch: 1/2, step 2910/7134 completed (loss: 0.18824832141399384, acc: 0.9496787786483765)
[2024-12-17 03:57:25,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:25,801][root][INFO] - Training Epoch: 1/2, step 2911/7134 completed (loss: 0.11832217127084732, acc: 0.9610738158226013)
[2024-12-17 03:57:25,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:26,277][root][INFO] - Training Epoch: 1/2, step 2912/7134 completed (loss: 0.12406415492296219, acc: 0.9613792896270752)
[2024-12-17 03:57:26,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:26,736][root][INFO] - Training Epoch: 1/2, step 2913/7134 completed (loss: 0.12951870262622833, acc: 0.9558404684066772)
[2024-12-17 03:57:26,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:27,202][root][INFO] - Training Epoch: 1/2, step 2914/7134 completed (loss: 0.11043243855237961, acc: 0.9722557067871094)
[2024-12-17 03:57:27,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:27,628][root][INFO] - Training Epoch: 1/2, step 2915/7134 completed (loss: 0.20017294585704803, acc: 0.9510086178779602)
[2024-12-17 03:57:27,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:28,036][root][INFO] - Training Epoch: 1/2, step 2916/7134 completed (loss: 0.16515691578388214, acc: 0.9553264379501343)
[2024-12-17 03:57:28,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:28,470][root][INFO] - Training Epoch: 1/2, step 2917/7134 completed (loss: 0.13888107240200043, acc: 0.9597989916801453)
[2024-12-17 03:57:28,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:28,911][root][INFO] - Training Epoch: 1/2, step 2918/7134 completed (loss: 0.09477008879184723, acc: 0.9696969985961914)
[2024-12-17 03:57:29,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:29,358][root][INFO] - Training Epoch: 1/2, step 2919/7134 completed (loss: 0.15887857973575592, acc: 0.9541715383529663)
[2024-12-17 03:57:29,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:29,839][root][INFO] - Training Epoch: 1/2, step 2920/7134 completed (loss: 0.153096005320549, acc: 0.9576159119606018)
[2024-12-17 03:57:29,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:30,273][root][INFO] - Training Epoch: 1/2, step 2921/7134 completed (loss: 0.08618225157260895, acc: 0.9755747318267822)
[2024-12-17 03:57:30,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:30,684][root][INFO] - Training Epoch: 1/2, step 2922/7134 completed (loss: 0.14924219250679016, acc: 0.9597989916801453)
[2024-12-17 03:57:30,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:31,123][root][INFO] - Training Epoch: 1/2, step 2923/7134 completed (loss: 0.23149380087852478, acc: 0.9431643486022949)
[2024-12-17 03:57:31,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:31,540][root][INFO] - Training Epoch: 1/2, step 2924/7134 completed (loss: 0.12188160419464111, acc: 0.9716981053352356)
[2024-12-17 03:57:31,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:32,026][root][INFO] - Training Epoch: 1/2, step 2925/7134 completed (loss: 0.16961482167243958, acc: 0.9606879353523254)
[2024-12-17 03:57:32,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:32,502][root][INFO] - Training Epoch: 1/2, step 2926/7134 completed (loss: 0.23181666433811188, acc: 0.948317289352417)
[2024-12-17 03:57:32,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:32,969][root][INFO] - Training Epoch: 1/2, step 2927/7134 completed (loss: 0.10634047538042068, acc: 0.9673518538475037)
[2024-12-17 03:57:33,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:33,407][root][INFO] - Training Epoch: 1/2, step 2928/7134 completed (loss: 0.1161668598651886, acc: 0.9695122241973877)
[2024-12-17 03:57:33,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:33,903][root][INFO] - Training Epoch: 1/2, step 2929/7134 completed (loss: 0.089217409491539, acc: 0.9751958250999451)
[2024-12-17 03:57:34,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:34,356][root][INFO] - Training Epoch: 1/2, step 2930/7134 completed (loss: 0.07868673652410507, acc: 0.9823788404464722)
[2024-12-17 03:57:34,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:34,767][root][INFO] - Training Epoch: 1/2, step 2931/7134 completed (loss: 0.17761287093162537, acc: 0.9536621570587158)
[2024-12-17 03:57:34,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:35,191][root][INFO] - Training Epoch: 1/2, step 2932/7134 completed (loss: 0.09873051941394806, acc: 0.9745075106620789)
[2024-12-17 03:57:35,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:35,638][root][INFO] - Training Epoch: 1/2, step 2933/7134 completed (loss: 0.14290717244148254, acc: 0.9466089606285095)
[2024-12-17 03:57:35,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:36,101][root][INFO] - Training Epoch: 1/2, step 2934/7134 completed (loss: 0.075269915163517, acc: 0.9774330258369446)
[2024-12-17 03:57:36,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:36,570][root][INFO] - Training Epoch: 1/2, step 2935/7134 completed (loss: 0.11294504255056381, acc: 0.9614537358283997)
[2024-12-17 03:57:36,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:37,042][root][INFO] - Training Epoch: 1/2, step 2936/7134 completed (loss: 0.1114463284611702, acc: 0.9704985022544861)
[2024-12-17 03:57:37,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:37,467][root][INFO] - Training Epoch: 1/2, step 2937/7134 completed (loss: 0.13472549617290497, acc: 0.9655666947364807)
[2024-12-17 03:57:37,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:37,917][root][INFO] - Training Epoch: 1/2, step 2938/7134 completed (loss: 0.09599178284406662, acc: 0.9743016958236694)
[2024-12-17 03:57:38,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:38,299][root][INFO] - Training Epoch: 1/2, step 2939/7134 completed (loss: 0.08836117386817932, acc: 0.9791666865348816)
[2024-12-17 03:57:38,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:38,719][root][INFO] - Training Epoch: 1/2, step 2940/7134 completed (loss: 0.13649867475032806, acc: 0.9616963267326355)
[2024-12-17 03:57:38,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:39,114][root][INFO] - Training Epoch: 1/2, step 2941/7134 completed (loss: 0.12418278306722641, acc: 0.9753265380859375)
[2024-12-17 03:57:39,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:39,505][root][INFO] - Training Epoch: 1/2, step 2942/7134 completed (loss: 0.12112493813037872, acc: 0.9717682003974915)
[2024-12-17 03:57:39,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:39,963][root][INFO] - Training Epoch: 1/2, step 2943/7134 completed (loss: 0.07770653069019318, acc: 0.979763925075531)
[2024-12-17 03:57:40,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:40,380][root][INFO] - Training Epoch: 1/2, step 2944/7134 completed (loss: 0.09919624775648117, acc: 0.9735682606697083)
[2024-12-17 03:57:40,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:40,806][root][INFO] - Training Epoch: 1/2, step 2945/7134 completed (loss: 0.08433809131383896, acc: 0.9720062017440796)
[2024-12-17 03:57:40,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:41,191][root][INFO] - Training Epoch: 1/2, step 2946/7134 completed (loss: 0.08634471148252487, acc: 0.9767441749572754)
[2024-12-17 03:57:41,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:41,641][root][INFO] - Training Epoch: 1/2, step 2947/7134 completed (loss: 0.13640083372592926, acc: 0.9654088020324707)
[2024-12-17 03:57:41,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:42,052][root][INFO] - Training Epoch: 1/2, step 2948/7134 completed (loss: 0.12510529160499573, acc: 0.9703459739685059)
[2024-12-17 03:57:42,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:42,448][root][INFO] - Training Epoch: 1/2, step 2949/7134 completed (loss: 0.07001324743032455, acc: 0.9801223278045654)
[2024-12-17 03:57:42,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:42,859][root][INFO] - Training Epoch: 1/2, step 2950/7134 completed (loss: 0.06714744120836258, acc: 0.9806896448135376)
[2024-12-17 03:57:42,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:43,272][root][INFO] - Training Epoch: 1/2, step 2951/7134 completed (loss: 0.043700896203517914, acc: 0.9927536249160767)
[2024-12-17 03:57:43,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:43,699][root][INFO] - Training Epoch: 1/2, step 2952/7134 completed (loss: 0.053303949534893036, acc: 0.9866468906402588)
[2024-12-17 03:57:43,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:44,104][root][INFO] - Training Epoch: 1/2, step 2953/7134 completed (loss: 0.09144553542137146, acc: 0.9695945978164673)
[2024-12-17 03:57:44,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:44,543][root][INFO] - Training Epoch: 1/2, step 2954/7134 completed (loss: 0.07735911011695862, acc: 0.9781209826469421)
[2024-12-17 03:57:44,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:44,933][root][INFO] - Training Epoch: 1/2, step 2955/7134 completed (loss: 0.1016211211681366, acc: 0.9673295617103577)
[2024-12-17 03:57:45,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:45,363][root][INFO] - Training Epoch: 1/2, step 2956/7134 completed (loss: 0.09200035035610199, acc: 0.9765739440917969)
[2024-12-17 03:57:45,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:45,792][root][INFO] - Training Epoch: 1/2, step 2957/7134 completed (loss: 0.06496702134609222, acc: 0.9839572310447693)
[2024-12-17 03:57:45,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:46,213][root][INFO] - Training Epoch: 1/2, step 2958/7134 completed (loss: 0.08591059595346451, acc: 0.9777777791023254)
[2024-12-17 03:57:46,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:46,656][root][INFO] - Training Epoch: 1/2, step 2959/7134 completed (loss: 0.07984139025211334, acc: 0.9766082167625427)
[2024-12-17 03:57:46,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:47,091][root][INFO] - Training Epoch: 1/2, step 2960/7134 completed (loss: 0.08406323194503784, acc: 0.9765840172767639)
[2024-12-17 03:57:47,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:47,540][root][INFO] - Training Epoch: 1/2, step 2961/7134 completed (loss: 0.08686285465955734, acc: 0.9741496443748474)
[2024-12-17 03:57:47,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:47,953][root][INFO] - Training Epoch: 1/2, step 2962/7134 completed (loss: 0.07271237671375275, acc: 0.9780077338218689)
[2024-12-17 03:57:48,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:48,402][root][INFO] - Training Epoch: 1/2, step 2963/7134 completed (loss: 0.11736937612295151, acc: 0.9738219976425171)
[2024-12-17 03:57:48,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:48,835][root][INFO] - Training Epoch: 1/2, step 2964/7134 completed (loss: 0.061848584562540054, acc: 0.985358715057373)
[2024-12-17 03:57:48,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:49,263][root][INFO] - Training Epoch: 1/2, step 2965/7134 completed (loss: 0.1868494153022766, acc: 0.9537313580513)
[2024-12-17 03:57:49,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:49,709][root][INFO] - Training Epoch: 1/2, step 2966/7134 completed (loss: 0.044049981981515884, acc: 0.9893389940261841)
[2024-12-17 03:57:49,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:50,140][root][INFO] - Training Epoch: 1/2, step 2967/7134 completed (loss: 0.0881602093577385, acc: 0.9804469347000122)
[2024-12-17 03:57:50,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:50,598][root][INFO] - Training Epoch: 1/2, step 2968/7134 completed (loss: 0.20445261895656586, acc: 0.9533762335777283)
[2024-12-17 03:57:50,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:51,006][root][INFO] - Training Epoch: 1/2, step 2969/7134 completed (loss: 0.3775191307067871, acc: 0.9097633361816406)
[2024-12-17 03:57:51,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:51,423][root][INFO] - Training Epoch: 1/2, step 2970/7134 completed (loss: 0.418136328458786, acc: 0.915032684803009)
[2024-12-17 03:57:51,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:51,857][root][INFO] - Training Epoch: 1/2, step 2971/7134 completed (loss: 0.12889845669269562, acc: 0.96714848279953)
[2024-12-17 03:57:51,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:52,283][root][INFO] - Training Epoch: 1/2, step 2972/7134 completed (loss: 0.11309370398521423, acc: 0.9762611389160156)
[2024-12-17 03:57:52,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:52,720][root][INFO] - Training Epoch: 1/2, step 2973/7134 completed (loss: 0.17216336727142334, acc: 0.9556962251663208)
[2024-12-17 03:57:52,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:53,160][root][INFO] - Training Epoch: 1/2, step 2974/7134 completed (loss: 0.13819889724254608, acc: 0.9623864889144897)
[2024-12-17 03:57:53,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:53,596][root][INFO] - Training Epoch: 1/2, step 2975/7134 completed (loss: 0.1397242695093155, acc: 0.9558011293411255)
[2024-12-17 03:57:53,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:54,064][root][INFO] - Training Epoch: 1/2, step 2976/7134 completed (loss: 0.11789148300886154, acc: 0.9723404049873352)
[2024-12-17 03:57:54,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:54,491][root][INFO] - Training Epoch: 1/2, step 2977/7134 completed (loss: 0.1231190487742424, acc: 0.97398841381073)
[2024-12-17 03:57:54,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:54,922][root][INFO] - Training Epoch: 1/2, step 2978/7134 completed (loss: 0.10888611525297165, acc: 0.9702127575874329)
[2024-12-17 03:57:55,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:55,322][root][INFO] - Training Epoch: 1/2, step 2979/7134 completed (loss: 0.07388205826282501, acc: 0.9828660488128662)
[2024-12-17 03:57:55,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:55,764][root][INFO] - Training Epoch: 1/2, step 2980/7134 completed (loss: 0.11101767420768738, acc: 0.9732484221458435)
[2024-12-17 03:57:55,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:56,211][root][INFO] - Training Epoch: 1/2, step 2981/7134 completed (loss: 0.1230584904551506, acc: 0.974219799041748)
[2024-12-17 03:57:56,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:56,636][root][INFO] - Training Epoch: 1/2, step 2982/7134 completed (loss: 0.11228432506322861, acc: 0.9685863852500916)
[2024-12-17 03:57:56,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:57,066][root][INFO] - Training Epoch: 1/2, step 2983/7134 completed (loss: 0.14954261481761932, acc: 0.9589946866035461)
[2024-12-17 03:57:57,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:57,531][root][INFO] - Training Epoch: 1/2, step 2984/7134 completed (loss: 0.08604121208190918, acc: 0.9761006236076355)
[2024-12-17 03:57:57,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:57,980][root][INFO] - Training Epoch: 1/2, step 2985/7134 completed (loss: 0.1093560978770256, acc: 0.9713945388793945)
[2024-12-17 03:57:58,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:58,442][root][INFO] - Training Epoch: 1/2, step 2986/7134 completed (loss: 0.09159418940544128, acc: 0.9763593673706055)
[2024-12-17 03:57:58,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:58,874][root][INFO] - Training Epoch: 1/2, step 2987/7134 completed (loss: 0.09237648546695709, acc: 0.971731424331665)
[2024-12-17 03:57:58,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:59,310][root][INFO] - Training Epoch: 1/2, step 2988/7134 completed (loss: 0.09378252178430557, acc: 0.9732360243797302)
[2024-12-17 03:57:59,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:57:59,751][root][INFO] - Training Epoch: 1/2, step 2989/7134 completed (loss: 0.12261408567428589, acc: 0.9699346423149109)
[2024-12-17 03:57:59,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:00,158][root][INFO] - Training Epoch: 1/2, step 2990/7134 completed (loss: 0.22405503690242767, acc: 0.9458041787147522)
[2024-12-17 03:58:00,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:00,581][root][INFO] - Training Epoch: 1/2, step 2991/7134 completed (loss: 0.3233632445335388, acc: 0.9209431409835815)
[2024-12-17 03:58:00,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:00,992][root][INFO] - Training Epoch: 1/2, step 2992/7134 completed (loss: 0.13815829157829285, acc: 0.9622926115989685)
[2024-12-17 03:58:01,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:01,448][root][INFO] - Training Epoch: 1/2, step 2993/7134 completed (loss: 0.10790283232927322, acc: 0.9694376587867737)
[2024-12-17 03:58:01,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:01,874][root][INFO] - Training Epoch: 1/2, step 2994/7134 completed (loss: 0.10343887656927109, acc: 0.9730215668678284)
[2024-12-17 03:58:02,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:02,355][root][INFO] - Training Epoch: 1/2, step 2995/7134 completed (loss: 0.08040684461593628, acc: 0.9785310626029968)
[2024-12-17 03:58:02,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:02,789][root][INFO] - Training Epoch: 1/2, step 2996/7134 completed (loss: 0.13046997785568237, acc: 0.9695906639099121)
[2024-12-17 03:58:02,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:03,253][root][INFO] - Training Epoch: 1/2, step 2997/7134 completed (loss: 0.07067044824361801, acc: 0.9802494645118713)
[2024-12-17 03:58:03,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:03,679][root][INFO] - Training Epoch: 1/2, step 2998/7134 completed (loss: 0.10642292350530624, acc: 0.9696969985961914)
[2024-12-17 03:58:03,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:04,160][root][INFO] - Training Epoch: 1/2, step 2999/7134 completed (loss: 0.10642901808023453, acc: 0.9753979444503784)
[2024-12-17 03:58:04,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:04,628][root][INFO] - Training Epoch: 1/2, step 3000/7134 completed (loss: 0.09600270539522171, acc: 0.9710921049118042)
[2024-12-17 03:58:04,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:05,088][root][INFO] - Training Epoch: 1/2, step 3001/7134 completed (loss: 0.13465434312820435, acc: 0.9656398296356201)
[2024-12-17 03:58:05,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:05,533][root][INFO] - Training Epoch: 1/2, step 3002/7134 completed (loss: 0.11412831395864487, acc: 0.9682539701461792)
[2024-12-17 03:58:05,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:06,000][root][INFO] - Training Epoch: 1/2, step 3003/7134 completed (loss: 0.08617349714040756, acc: 0.9756380319595337)
[2024-12-17 03:58:06,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:06,449][root][INFO] - Training Epoch: 1/2, step 3004/7134 completed (loss: 0.0727233737707138, acc: 0.9754189848899841)
[2024-12-17 03:58:06,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:06,914][root][INFO] - Training Epoch: 1/2, step 3005/7134 completed (loss: 0.06181060150265694, acc: 0.9828962087631226)
[2024-12-17 03:58:07,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:07,380][root][INFO] - Training Epoch: 1/2, step 3006/7134 completed (loss: 0.07200247049331665, acc: 0.9821200370788574)
[2024-12-17 03:58:07,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:07,858][root][INFO] - Training Epoch: 1/2, step 3007/7134 completed (loss: 0.12653300166130066, acc: 0.9695550203323364)
[2024-12-17 03:58:07,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:08,278][root][INFO] - Training Epoch: 1/2, step 3008/7134 completed (loss: 0.16802144050598145, acc: 0.9594405889511108)
[2024-12-17 03:58:08,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:08,680][root][INFO] - Training Epoch: 1/2, step 3009/7134 completed (loss: 0.17390897870063782, acc: 0.949367105960846)
[2024-12-17 03:58:08,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:09,132][root][INFO] - Training Epoch: 1/2, step 3010/7134 completed (loss: 0.10671698302030563, acc: 0.9635359048843384)
[2024-12-17 03:58:09,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:09,571][root][INFO] - Training Epoch: 1/2, step 3011/7134 completed (loss: 0.1928812861442566, acc: 0.952924370765686)
[2024-12-17 03:58:09,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:10,003][root][INFO] - Training Epoch: 1/2, step 3012/7134 completed (loss: 0.1581232249736786, acc: 0.9603803753852844)
[2024-12-17 03:58:10,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:10,467][root][INFO] - Training Epoch: 1/2, step 3013/7134 completed (loss: 0.07910223305225372, acc: 0.9781106114387512)
[2024-12-17 03:58:10,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:10,914][root][INFO] - Training Epoch: 1/2, step 3014/7134 completed (loss: 0.11564451456069946, acc: 0.9648300409317017)
[2024-12-17 03:58:11,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:11,323][root][INFO] - Training Epoch: 1/2, step 3015/7134 completed (loss: 0.10063054412603378, acc: 0.9779614210128784)
[2024-12-17 03:58:11,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:11,773][root][INFO] - Training Epoch: 1/2, step 3016/7134 completed (loss: 0.08940690755844116, acc: 0.9774965047836304)
[2024-12-17 03:58:11,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:12,207][root][INFO] - Training Epoch: 1/2, step 3017/7134 completed (loss: 0.18376664817333221, acc: 0.9372881650924683)
[2024-12-17 03:58:12,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:12,616][root][INFO] - Training Epoch: 1/2, step 3018/7134 completed (loss: 0.10546217858791351, acc: 0.9735537171363831)
[2024-12-17 03:58:12,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:13,045][root][INFO] - Training Epoch: 1/2, step 3019/7134 completed (loss: 0.08289504051208496, acc: 0.9771241545677185)
[2024-12-17 03:58:13,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:13,460][root][INFO] - Training Epoch: 1/2, step 3020/7134 completed (loss: 0.1470683366060257, acc: 0.9750445485115051)
[2024-12-17 03:58:13,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:13,861][root][INFO] - Training Epoch: 1/2, step 3021/7134 completed (loss: 0.07362793385982513, acc: 0.9854545593261719)
[2024-12-17 03:58:13,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:14,289][root][INFO] - Training Epoch: 1/2, step 3022/7134 completed (loss: 0.10896024107933044, acc: 0.9742765426635742)
[2024-12-17 03:58:14,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:14,657][root][INFO] - Training Epoch: 1/2, step 3023/7134 completed (loss: 0.14326822757720947, acc: 0.9701789021492004)
[2024-12-17 03:58:14,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:15,094][root][INFO] - Training Epoch: 1/2, step 3024/7134 completed (loss: 0.08296652138233185, acc: 0.967432975769043)
[2024-12-17 03:58:15,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:15,540][root][INFO] - Training Epoch: 1/2, step 3025/7134 completed (loss: 0.11535344272851944, acc: 0.9689655303955078)
[2024-12-17 03:58:15,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:15,952][root][INFO] - Training Epoch: 1/2, step 3026/7134 completed (loss: 0.10639143735170364, acc: 0.9676840305328369)
[2024-12-17 03:58:16,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:16,362][root][INFO] - Training Epoch: 1/2, step 3027/7134 completed (loss: 0.12016287446022034, acc: 0.9757575988769531)
[2024-12-17 03:58:16,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:16,814][root][INFO] - Training Epoch: 1/2, step 3028/7134 completed (loss: 0.08070117235183716, acc: 0.9727891087532043)
[2024-12-17 03:58:16,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:17,219][root][INFO] - Training Epoch: 1/2, step 3029/7134 completed (loss: 0.09465457499027252, acc: 0.973724901676178)
[2024-12-17 03:58:17,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:17,674][root][INFO] - Training Epoch: 1/2, step 3030/7134 completed (loss: 0.11380171775817871, acc: 0.970992386341095)
[2024-12-17 03:58:17,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:18,069][root][INFO] - Training Epoch: 1/2, step 3031/7134 completed (loss: 0.08436757326126099, acc: 0.9703390002250671)
[2024-12-17 03:58:18,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:18,532][root][INFO] - Training Epoch: 1/2, step 3032/7134 completed (loss: 0.1012091413140297, acc: 0.9782214164733887)
[2024-12-17 03:58:18,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:18,934][root][INFO] - Training Epoch: 1/2, step 3033/7134 completed (loss: 0.07538634538650513, acc: 0.9753086566925049)
[2024-12-17 03:58:19,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:19,344][root][INFO] - Training Epoch: 1/2, step 3034/7134 completed (loss: 0.10223842412233353, acc: 0.9765957593917847)
[2024-12-17 03:58:19,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:19,741][root][INFO] - Training Epoch: 1/2, step 3035/7134 completed (loss: 0.07537007331848145, acc: 0.9763779640197754)
[2024-12-17 03:58:19,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:20,169][root][INFO] - Training Epoch: 1/2, step 3036/7134 completed (loss: 0.1531655490398407, acc: 0.9615384340286255)
[2024-12-17 03:58:20,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:20,623][root][INFO] - Training Epoch: 1/2, step 3037/7134 completed (loss: 0.14579248428344727, acc: 0.9583975076675415)
[2024-12-17 03:58:20,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:21,046][root][INFO] - Training Epoch: 1/2, step 3038/7134 completed (loss: 0.05662114545702934, acc: 0.9878261089324951)
[2024-12-17 03:58:21,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:21,463][root][INFO] - Training Epoch: 1/2, step 3039/7134 completed (loss: 0.08240928500890732, acc: 0.9785605072975159)
[2024-12-17 03:58:21,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:21,864][root][INFO] - Training Epoch: 1/2, step 3040/7134 completed (loss: 0.11891322582960129, acc: 0.9647495150566101)
[2024-12-17 03:58:22,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:22,301][root][INFO] - Training Epoch: 1/2, step 3041/7134 completed (loss: 0.13771650195121765, acc: 0.9665071964263916)
[2024-12-17 03:58:22,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:22,727][root][INFO] - Training Epoch: 1/2, step 3042/7134 completed (loss: 0.08348961174488068, acc: 0.9763663411140442)
[2024-12-17 03:58:22,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:23,137][root][INFO] - Training Epoch: 1/2, step 3043/7134 completed (loss: 0.09570226818323135, acc: 0.9752851724624634)
[2024-12-17 03:58:23,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:23,523][root][INFO] - Training Epoch: 1/2, step 3044/7134 completed (loss: 0.05889880657196045, acc: 0.9861830472946167)
[2024-12-17 03:58:23,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:23,932][root][INFO] - Training Epoch: 1/2, step 3045/7134 completed (loss: 0.05197330564260483, acc: 0.9864406585693359)
[2024-12-17 03:58:24,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:24,385][root][INFO] - Training Epoch: 1/2, step 3046/7134 completed (loss: 0.10254509747028351, acc: 0.9713114500045776)
[2024-12-17 03:58:24,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:24,822][root][INFO] - Training Epoch: 1/2, step 3047/7134 completed (loss: 0.043152134865522385, acc: 0.9886792302131653)
[2024-12-17 03:58:24,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:25,316][root][INFO] - Training Epoch: 1/2, step 3048/7134 completed (loss: 0.05974331125617027, acc: 0.984886646270752)
[2024-12-17 03:58:25,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:25,735][root][INFO] - Training Epoch: 1/2, step 3049/7134 completed (loss: 0.07758785039186478, acc: 0.9767441749572754)
[2024-12-17 03:58:25,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:26,184][root][INFO] - Training Epoch: 1/2, step 3050/7134 completed (loss: 0.07829279452562332, acc: 0.9798099994659424)
[2024-12-17 03:58:26,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:26,601][root][INFO] - Training Epoch: 1/2, step 3051/7134 completed (loss: 0.13823555409908295, acc: 0.9624060392379761)
[2024-12-17 03:58:26,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:27,036][root][INFO] - Training Epoch: 1/2, step 3052/7134 completed (loss: 0.08556820452213287, acc: 0.9716494679450989)
[2024-12-17 03:58:27,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:27,480][root][INFO] - Training Epoch: 1/2, step 3053/7134 completed (loss: 0.08444977551698685, acc: 0.977053165435791)
[2024-12-17 03:58:27,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:27,906][root][INFO] - Training Epoch: 1/2, step 3054/7134 completed (loss: 0.12081929296255112, acc: 0.9766233563423157)
[2024-12-17 03:58:28,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:28,328][root][INFO] - Training Epoch: 1/2, step 3055/7134 completed (loss: 0.09808754920959473, acc: 0.9743589758872986)
[2024-12-17 03:58:28,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:28,779][root][INFO] - Training Epoch: 1/2, step 3056/7134 completed (loss: 0.08080105483531952, acc: 0.9768637418746948)
[2024-12-17 03:58:28,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:29,246][root][INFO] - Training Epoch: 1/2, step 3057/7134 completed (loss: 0.05839630216360092, acc: 0.9805825352668762)
[2024-12-17 03:58:29,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:29,694][root][INFO] - Training Epoch: 1/2, step 3058/7134 completed (loss: 0.14927445352077484, acc: 0.9572538733482361)
[2024-12-17 03:58:29,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:30,128][root][INFO] - Training Epoch: 1/2, step 3059/7134 completed (loss: 0.06555420160293579, acc: 0.9794520735740662)
[2024-12-17 03:58:30,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:30,579][root][INFO] - Training Epoch: 1/2, step 3060/7134 completed (loss: 0.07989513128995895, acc: 0.9773269891738892)
[2024-12-17 03:58:30,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:31,027][root][INFO] - Training Epoch: 1/2, step 3061/7134 completed (loss: 0.0524858720600605, acc: 0.9863636493682861)
[2024-12-17 03:58:31,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:31,480][root][INFO] - Training Epoch: 1/2, step 3062/7134 completed (loss: 0.05381527170538902, acc: 0.9892183542251587)
[2024-12-17 03:58:31,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:31,913][root][INFO] - Training Epoch: 1/2, step 3063/7134 completed (loss: 0.08187482506036758, acc: 0.9756097793579102)
[2024-12-17 03:58:32,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:32,336][root][INFO] - Training Epoch: 1/2, step 3064/7134 completed (loss: 0.06427907198667526, acc: 0.9845070242881775)
[2024-12-17 03:58:32,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:32,778][root][INFO] - Training Epoch: 1/2, step 3065/7134 completed (loss: 0.06474006175994873, acc: 0.9865591526031494)
[2024-12-17 03:58:32,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:33,207][root][INFO] - Training Epoch: 1/2, step 3066/7134 completed (loss: 0.06728393584489822, acc: 0.9806451797485352)
[2024-12-17 03:58:33,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:33,614][root][INFO] - Training Epoch: 1/2, step 3067/7134 completed (loss: 0.08170288056135178, acc: 0.9800000190734863)
[2024-12-17 03:58:33,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:34,072][root][INFO] - Training Epoch: 1/2, step 3068/7134 completed (loss: 0.08758580684661865, acc: 0.9797022938728333)
[2024-12-17 03:58:34,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:34,521][root][INFO] - Training Epoch: 1/2, step 3069/7134 completed (loss: 0.05858130753040314, acc: 0.981566846370697)
[2024-12-17 03:58:34,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:34,996][root][INFO] - Training Epoch: 1/2, step 3070/7134 completed (loss: 0.05117977410554886, acc: 0.9830328822135925)
[2024-12-17 03:58:35,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:35,450][root][INFO] - Training Epoch: 1/2, step 3071/7134 completed (loss: 0.06919068098068237, acc: 0.9806950092315674)
[2024-12-17 03:58:35,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:35,905][root][INFO] - Training Epoch: 1/2, step 3072/7134 completed (loss: 0.07408484071493149, acc: 0.9766627550125122)
[2024-12-17 03:58:36,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:36,340][root][INFO] - Training Epoch: 1/2, step 3073/7134 completed (loss: 0.060065239667892456, acc: 0.9847328066825867)
[2024-12-17 03:58:36,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:36,754][root][INFO] - Training Epoch: 1/2, step 3074/7134 completed (loss: 0.06689418107271194, acc: 0.981697142124176)
[2024-12-17 03:58:36,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:37,190][root][INFO] - Training Epoch: 1/2, step 3075/7134 completed (loss: 0.06037374213337898, acc: 0.9833333492279053)
[2024-12-17 03:58:37,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:37,640][root][INFO] - Training Epoch: 1/2, step 3076/7134 completed (loss: 0.10327354073524475, acc: 0.9722530245780945)
[2024-12-17 03:58:37,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:38,123][root][INFO] - Training Epoch: 1/2, step 3077/7134 completed (loss: 0.16839680075645447, acc: 0.9595628380775452)
[2024-12-17 03:58:38,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:38,574][root][INFO] - Training Epoch: 1/2, step 3078/7134 completed (loss: 0.12455160170793533, acc: 0.9683060050010681)
[2024-12-17 03:58:38,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:39,025][root][INFO] - Training Epoch: 1/2, step 3079/7134 completed (loss: 0.07560806721448898, acc: 0.9753086566925049)
[2024-12-17 03:58:39,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:39,484][root][INFO] - Training Epoch: 1/2, step 3080/7134 completed (loss: 0.13561590015888214, acc: 0.9585605263710022)
[2024-12-17 03:58:39,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:39,878][root][INFO] - Training Epoch: 1/2, step 3081/7134 completed (loss: 0.06374906003475189, acc: 0.982758641242981)
[2024-12-17 03:58:40,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:40,330][root][INFO] - Training Epoch: 1/2, step 3082/7134 completed (loss: 0.15241636335849762, acc: 0.9554753303527832)
[2024-12-17 03:58:40,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:40,777][root][INFO] - Training Epoch: 1/2, step 3083/7134 completed (loss: 0.12433736026287079, acc: 0.967277467250824)
[2024-12-17 03:58:40,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:41,221][root][INFO] - Training Epoch: 1/2, step 3084/7134 completed (loss: 0.11718209832906723, acc: 0.9714285731315613)
[2024-12-17 03:58:41,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:41,695][root][INFO] - Training Epoch: 1/2, step 3085/7134 completed (loss: 0.15673379600048065, acc: 0.9605839252471924)
[2024-12-17 03:58:41,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:42,172][root][INFO] - Training Epoch: 1/2, step 3086/7134 completed (loss: 0.1282847374677658, acc: 0.9719416499137878)
[2024-12-17 03:58:42,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:42,624][root][INFO] - Training Epoch: 1/2, step 3087/7134 completed (loss: 0.13479946553707123, acc: 0.9641320109367371)
[2024-12-17 03:58:42,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:43,101][root][INFO] - Training Epoch: 1/2, step 3088/7134 completed (loss: 0.09845112264156342, acc: 0.9706876873970032)
[2024-12-17 03:58:43,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:43,581][root][INFO] - Training Epoch: 1/2, step 3089/7134 completed (loss: 0.09106682240962982, acc: 0.9719525575637817)
[2024-12-17 03:58:43,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:44,043][root][INFO] - Training Epoch: 1/2, step 3090/7134 completed (loss: 0.17318330705165863, acc: 0.9510869383811951)
[2024-12-17 03:58:44,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:44,514][root][INFO] - Training Epoch: 1/2, step 3091/7134 completed (loss: 0.12843428552150726, acc: 0.9642857313156128)
[2024-12-17 03:58:44,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:44,936][root][INFO] - Training Epoch: 1/2, step 3092/7134 completed (loss: 0.14597874879837036, acc: 0.9648798704147339)
[2024-12-17 03:58:45,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:45,383][root][INFO] - Training Epoch: 1/2, step 3093/7134 completed (loss: 0.13810577988624573, acc: 0.9646798968315125)
[2024-12-17 03:58:45,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:45,854][root][INFO] - Training Epoch: 1/2, step 3094/7134 completed (loss: 0.0798957571387291, acc: 0.9700272679328918)
[2024-12-17 03:58:45,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:46,282][root][INFO] - Training Epoch: 1/2, step 3095/7134 completed (loss: 0.11182571202516556, acc: 0.9666666388511658)
[2024-12-17 03:58:46,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:46,733][root][INFO] - Training Epoch: 1/2, step 3096/7134 completed (loss: 0.15761259198188782, acc: 0.9589216709136963)
[2024-12-17 03:58:46,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:47,192][root][INFO] - Training Epoch: 1/2, step 3097/7134 completed (loss: 0.1412280946969986, acc: 0.9515669345855713)
[2024-12-17 03:58:47,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:47,634][root][INFO] - Training Epoch: 1/2, step 3098/7134 completed (loss: 0.10219734907150269, acc: 0.9701257944107056)
[2024-12-17 03:58:47,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:48,052][root][INFO] - Training Epoch: 1/2, step 3099/7134 completed (loss: 0.09747675806283951, acc: 0.9708265662193298)
[2024-12-17 03:58:48,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:48,533][root][INFO] - Training Epoch: 1/2, step 3100/7134 completed (loss: 0.08097784966230392, acc: 0.9797872304916382)
[2024-12-17 03:58:48,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:48,982][root][INFO] - Training Epoch: 1/2, step 3101/7134 completed (loss: 0.10044894367456436, acc: 0.9732360243797302)
[2024-12-17 03:58:49,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:49,449][root][INFO] - Training Epoch: 1/2, step 3102/7134 completed (loss: 0.09121665358543396, acc: 0.9792592525482178)
[2024-12-17 03:58:49,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:49,918][root][INFO] - Training Epoch: 1/2, step 3103/7134 completed (loss: 0.1338232457637787, acc: 0.96592116355896)
[2024-12-17 03:58:50,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:50,310][root][INFO] - Training Epoch: 1/2, step 3104/7134 completed (loss: 0.07234319299459457, acc: 0.9751908183097839)
[2024-12-17 03:58:50,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:50,744][root][INFO] - Training Epoch: 1/2, step 3105/7134 completed (loss: 0.1215207427740097, acc: 0.9648351669311523)
[2024-12-17 03:58:50,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:51,185][root][INFO] - Training Epoch: 1/2, step 3106/7134 completed (loss: 0.08902046084403992, acc: 0.9732441306114197)
[2024-12-17 03:58:51,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:51,605][root][INFO] - Training Epoch: 1/2, step 3107/7134 completed (loss: 0.07170958071947098, acc: 0.9843137264251709)
[2024-12-17 03:58:51,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:52,050][root][INFO] - Training Epoch: 1/2, step 3108/7134 completed (loss: 0.09861923009157181, acc: 0.9800000190734863)
[2024-12-17 03:58:52,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:52,468][root][INFO] - Training Epoch: 1/2, step 3109/7134 completed (loss: 0.10874184966087341, acc: 0.9741697311401367)
[2024-12-17 03:58:52,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:52,899][root][INFO] - Training Epoch: 1/2, step 3110/7134 completed (loss: 0.10988778620958328, acc: 0.9658536314964294)
[2024-12-17 03:58:53,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:53,316][root][INFO] - Training Epoch: 1/2, step 3111/7134 completed (loss: 0.1577634960412979, acc: 0.9570446610450745)
[2024-12-17 03:58:53,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:53,715][root][INFO] - Training Epoch: 1/2, step 3112/7134 completed (loss: 0.12549525499343872, acc: 0.9719298481941223)
[2024-12-17 03:58:53,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:54,195][root][INFO] - Training Epoch: 1/2, step 3113/7134 completed (loss: 0.07012316584587097, acc: 0.9817415475845337)
[2024-12-17 03:58:54,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:54,628][root][INFO] - Training Epoch: 1/2, step 3114/7134 completed (loss: 0.13236457109451294, acc: 0.9620689749717712)
[2024-12-17 03:58:54,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:55,037][root][INFO] - Training Epoch: 1/2, step 3115/7134 completed (loss: 0.08362353593111038, acc: 0.9783950448036194)
[2024-12-17 03:58:55,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:55,491][root][INFO] - Training Epoch: 1/2, step 3116/7134 completed (loss: 0.0812501534819603, acc: 0.9769230484962463)
[2024-12-17 03:58:55,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:55,932][root][INFO] - Training Epoch: 1/2, step 3117/7134 completed (loss: 0.1883542835712433, acc: 0.960597813129425)
[2024-12-17 03:58:56,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:56,359][root][INFO] - Training Epoch: 1/2, step 3118/7134 completed (loss: 0.10201098769903183, acc: 0.9723320007324219)
[2024-12-17 03:58:56,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:56,796][root][INFO] - Training Epoch: 1/2, step 3119/7134 completed (loss: 0.09312571585178375, acc: 0.9727626442909241)
[2024-12-17 03:58:56,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:57,215][root][INFO] - Training Epoch: 1/2, step 3120/7134 completed (loss: 0.07761314511299133, acc: 0.9844852089881897)
[2024-12-17 03:58:57,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:57,636][root][INFO] - Training Epoch: 1/2, step 3121/7134 completed (loss: 0.09246677160263062, acc: 0.9768637418746948)
[2024-12-17 03:58:57,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:58,088][root][INFO] - Training Epoch: 1/2, step 3122/7134 completed (loss: 0.08121555298566818, acc: 0.9767441749572754)
[2024-12-17 03:58:58,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:58,534][root][INFO] - Training Epoch: 1/2, step 3123/7134 completed (loss: 0.12303446978330612, acc: 0.9689054489135742)
[2024-12-17 03:58:58,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:58,963][root][INFO] - Training Epoch: 1/2, step 3124/7134 completed (loss: 0.10271018743515015, acc: 0.9777227640151978)
[2024-12-17 03:58:59,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:59,405][root][INFO] - Training Epoch: 1/2, step 3125/7134 completed (loss: 0.05582970008254051, acc: 0.9863842725753784)
[2024-12-17 03:58:59,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:58:59,898][root][INFO] - Training Epoch: 1/2, step 3126/7134 completed (loss: 0.11794110387563705, acc: 0.9707750678062439)
[2024-12-17 03:59:00,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:00,345][root][INFO] - Training Epoch: 1/2, step 3127/7134 completed (loss: 0.0733199492096901, acc: 0.9767441749572754)
[2024-12-17 03:59:00,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:00,774][root][INFO] - Training Epoch: 1/2, step 3128/7134 completed (loss: 0.05724000185728073, acc: 0.9870967864990234)
[2024-12-17 03:59:00,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:01,233][root][INFO] - Training Epoch: 1/2, step 3129/7134 completed (loss: 0.08192078024148941, acc: 0.9765142202377319)
[2024-12-17 03:59:01,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:01,701][root][INFO] - Training Epoch: 1/2, step 3130/7134 completed (loss: 0.08062645047903061, acc: 0.9759174585342407)
[2024-12-17 03:59:01,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:02,126][root][INFO] - Training Epoch: 1/2, step 3131/7134 completed (loss: 0.12887971103191376, acc: 0.9652174115180969)
[2024-12-17 03:59:02,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:02,491][root][INFO] - Training Epoch: 1/2, step 3132/7134 completed (loss: 0.08369505405426025, acc: 0.9739696383476257)
[2024-12-17 03:59:02,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:03,005][root][INFO] - Training Epoch: 1/2, step 3133/7134 completed (loss: 0.1633024364709854, acc: 0.9629120826721191)
[2024-12-17 03:59:03,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:03,450][root][INFO] - Training Epoch: 1/2, step 3134/7134 completed (loss: 0.06418795138597488, acc: 0.9835164546966553)
[2024-12-17 03:59:03,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:03,848][root][INFO] - Training Epoch: 1/2, step 3135/7134 completed (loss: 0.1095796599984169, acc: 0.9699769020080566)
[2024-12-17 03:59:03,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:04,282][root][INFO] - Training Epoch: 1/2, step 3136/7134 completed (loss: 0.08229722827672958, acc: 0.9739130139350891)
[2024-12-17 03:59:04,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:04,701][root][INFO] - Training Epoch: 1/2, step 3137/7134 completed (loss: 0.18771588802337646, acc: 0.9464285969734192)
[2024-12-17 03:59:04,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:05,103][root][INFO] - Training Epoch: 1/2, step 3138/7134 completed (loss: 0.15165646374225616, acc: 0.979411780834198)
[2024-12-17 03:59:05,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:05,520][root][INFO] - Training Epoch: 1/2, step 3139/7134 completed (loss: 0.23086798191070557, acc: 0.942060112953186)
[2024-12-17 03:59:05,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:05,925][root][INFO] - Training Epoch: 1/2, step 3140/7134 completed (loss: 0.17074424028396606, acc: 0.9533073902130127)
[2024-12-17 03:59:06,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:06,343][root][INFO] - Training Epoch: 1/2, step 3141/7134 completed (loss: 0.13017232716083527, acc: 0.9737762212753296)
[2024-12-17 03:59:06,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:06,773][root][INFO] - Training Epoch: 1/2, step 3142/7134 completed (loss: 0.0851324200630188, acc: 0.974588930606842)
[2024-12-17 03:59:06,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:07,188][root][INFO] - Training Epoch: 1/2, step 3143/7134 completed (loss: 0.10580337792634964, acc: 0.9694533944129944)
[2024-12-17 03:59:07,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:07,608][root][INFO] - Training Epoch: 1/2, step 3144/7134 completed (loss: 0.07152435928583145, acc: 0.9795597195625305)
[2024-12-17 03:59:07,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:08,020][root][INFO] - Training Epoch: 1/2, step 3145/7134 completed (loss: 0.1299460083246231, acc: 0.9628008604049683)
[2024-12-17 03:59:08,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:08,447][root][INFO] - Training Epoch: 1/2, step 3146/7134 completed (loss: 0.1284639835357666, acc: 0.9713541865348816)
[2024-12-17 03:59:08,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:08,867][root][INFO] - Training Epoch: 1/2, step 3147/7134 completed (loss: 0.10122362524271011, acc: 0.9759229421615601)
[2024-12-17 03:59:09,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:09,322][root][INFO] - Training Epoch: 1/2, step 3148/7134 completed (loss: 0.12130726873874664, acc: 0.9655612111091614)
[2024-12-17 03:59:09,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:09,746][root][INFO] - Training Epoch: 1/2, step 3149/7134 completed (loss: 0.053585298359394073, acc: 0.980966329574585)
[2024-12-17 03:59:09,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:10,167][root][INFO] - Training Epoch: 1/2, step 3150/7134 completed (loss: 0.27508729696273804, acc: 0.9349112510681152)
[2024-12-17 03:59:10,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:10,563][root][INFO] - Training Epoch: 1/2, step 3151/7134 completed (loss: 0.2385779172182083, acc: 0.9482758641242981)
[2024-12-17 03:59:10,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:10,966][root][INFO] - Training Epoch: 1/2, step 3152/7134 completed (loss: 0.1372303068637848, acc: 0.9621211886405945)
[2024-12-17 03:59:11,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:11,388][root][INFO] - Training Epoch: 1/2, step 3153/7134 completed (loss: 0.11120747774839401, acc: 0.9736841917037964)
[2024-12-17 03:59:11,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:11,805][root][INFO] - Training Epoch: 1/2, step 3154/7134 completed (loss: 0.1019541546702385, acc: 0.9751332402229309)
[2024-12-17 03:59:11,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:12,222][root][INFO] - Training Epoch: 1/2, step 3155/7134 completed (loss: 0.23228469491004944, acc: 0.9492900371551514)
[2024-12-17 03:59:12,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:12,665][root][INFO] - Training Epoch: 1/2, step 3156/7134 completed (loss: 0.1785525381565094, acc: 0.9569093585014343)
[2024-12-17 03:59:12,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:13,064][root][INFO] - Training Epoch: 1/2, step 3157/7134 completed (loss: 0.06892039626836777, acc: 0.9827957153320312)
[2024-12-17 03:59:13,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:13,460][root][INFO] - Training Epoch: 1/2, step 3158/7134 completed (loss: 0.08671335130929947, acc: 0.9738562107086182)
[2024-12-17 03:59:13,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:13,874][root][INFO] - Training Epoch: 1/2, step 3159/7134 completed (loss: 0.11306063085794449, acc: 0.968137264251709)
[2024-12-17 03:59:13,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:14,306][root][INFO] - Training Epoch: 1/2, step 3160/7134 completed (loss: 0.07080753147602081, acc: 0.9751037359237671)
[2024-12-17 03:59:14,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:14,754][root][INFO] - Training Epoch: 1/2, step 3161/7134 completed (loss: 0.08878642320632935, acc: 0.9831932783126831)
[2024-12-17 03:59:14,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:15,173][root][INFO] - Training Epoch: 1/2, step 3162/7134 completed (loss: 0.05727870389819145, acc: 0.9868804812431335)
[2024-12-17 03:59:15,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:15,577][root][INFO] - Training Epoch: 1/2, step 3163/7134 completed (loss: 0.11806786060333252, acc: 0.9766277074813843)
[2024-12-17 03:59:15,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:16,010][root][INFO] - Training Epoch: 1/2, step 3164/7134 completed (loss: 0.13513238728046417, acc: 0.9648241400718689)
[2024-12-17 03:59:16,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:16,421][root][INFO] - Training Epoch: 1/2, step 3165/7134 completed (loss: 0.06534359604120255, acc: 0.9883138537406921)
[2024-12-17 03:59:16,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:16,874][root][INFO] - Training Epoch: 1/2, step 3166/7134 completed (loss: 0.14204740524291992, acc: 0.965413510799408)
[2024-12-17 03:59:17,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:17,321][root][INFO] - Training Epoch: 1/2, step 3167/7134 completed (loss: 0.188205748796463, acc: 0.9515625238418579)
[2024-12-17 03:59:17,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:17,767][root][INFO] - Training Epoch: 1/2, step 3168/7134 completed (loss: 0.16853205859661102, acc: 0.9557926654815674)
[2024-12-17 03:59:17,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:18,208][root][INFO] - Training Epoch: 1/2, step 3169/7134 completed (loss: 0.126728817820549, acc: 0.9713114500045776)
[2024-12-17 03:59:18,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:18,630][root][INFO] - Training Epoch: 1/2, step 3170/7134 completed (loss: 0.0830804854631424, acc: 0.9818181991577148)
[2024-12-17 03:59:18,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:19,055][root][INFO] - Training Epoch: 1/2, step 3171/7134 completed (loss: 0.1181238442659378, acc: 0.9724770784378052)
[2024-12-17 03:59:19,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:19,457][root][INFO] - Training Epoch: 1/2, step 3172/7134 completed (loss: 0.06635213643312454, acc: 0.984674334526062)
[2024-12-17 03:59:19,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:19,851][root][INFO] - Training Epoch: 1/2, step 3173/7134 completed (loss: 0.11480880528688431, acc: 0.9719387888908386)
[2024-12-17 03:59:19,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:20,284][root][INFO] - Training Epoch: 1/2, step 3174/7134 completed (loss: 0.12543804943561554, acc: 0.965976357460022)
[2024-12-17 03:59:20,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:20,706][root][INFO] - Training Epoch: 1/2, step 3175/7134 completed (loss: 0.09331121295690536, acc: 0.9774647951126099)
[2024-12-17 03:59:20,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:21,126][root][INFO] - Training Epoch: 1/2, step 3176/7134 completed (loss: 0.1304319053888321, acc: 0.9669172763824463)
[2024-12-17 03:59:21,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:21,519][root][INFO] - Training Epoch: 1/2, step 3177/7134 completed (loss: 0.13416466116905212, acc: 0.9635416865348816)
[2024-12-17 03:59:21,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:21,937][root][INFO] - Training Epoch: 1/2, step 3178/7134 completed (loss: 0.06693767011165619, acc: 0.9852216839790344)
[2024-12-17 03:59:22,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:22,377][root][INFO] - Training Epoch: 1/2, step 3179/7134 completed (loss: 0.1296238750219345, acc: 0.9734659790992737)
[2024-12-17 03:59:22,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:22,811][root][INFO] - Training Epoch: 1/2, step 3180/7134 completed (loss: 0.08253561705350876, acc: 0.9785714149475098)
[2024-12-17 03:59:22,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:23,230][root][INFO] - Training Epoch: 1/2, step 3181/7134 completed (loss: 0.14225231111049652, acc: 0.9719188809394836)
[2024-12-17 03:59:23,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:23,664][root][INFO] - Training Epoch: 1/2, step 3182/7134 completed (loss: 0.08053115010261536, acc: 0.9880775213241577)
[2024-12-17 03:59:23,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:24,055][root][INFO] - Training Epoch: 1/2, step 3183/7134 completed (loss: 0.11380831152200699, acc: 0.9644669890403748)
[2024-12-17 03:59:24,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:24,474][root][INFO] - Training Epoch: 1/2, step 3184/7134 completed (loss: 0.08359737694263458, acc: 0.9821428656578064)
[2024-12-17 03:59:24,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:24,902][root][INFO] - Training Epoch: 1/2, step 3185/7134 completed (loss: 0.030461875721812248, acc: 0.995726466178894)
[2024-12-17 03:59:25,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:25,322][root][INFO] - Training Epoch: 1/2, step 3186/7134 completed (loss: 0.06681373715400696, acc: 0.9866666793823242)
[2024-12-17 03:59:25,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:25,706][root][INFO] - Training Epoch: 1/2, step 3187/7134 completed (loss: 0.07745445519685745, acc: 0.982594907283783)
[2024-12-17 03:59:25,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:26,130][root][INFO] - Training Epoch: 1/2, step 3188/7134 completed (loss: 0.06275639683008194, acc: 0.9793014526367188)
[2024-12-17 03:59:26,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:26,549][root][INFO] - Training Epoch: 1/2, step 3189/7134 completed (loss: 0.1068030446767807, acc: 0.9782923460006714)
[2024-12-17 03:59:26,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:26,991][root][INFO] - Training Epoch: 1/2, step 3190/7134 completed (loss: 0.09659752994775772, acc: 0.9772151708602905)
[2024-12-17 03:59:27,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:27,382][root][INFO] - Training Epoch: 1/2, step 3191/7134 completed (loss: 0.07256530970335007, acc: 0.9885714054107666)
[2024-12-17 03:59:27,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:27,788][root][INFO] - Training Epoch: 1/2, step 3192/7134 completed (loss: 0.07302393764257431, acc: 0.9848771095275879)
[2024-12-17 03:59:27,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:28,200][root][INFO] - Training Epoch: 1/2, step 3193/7134 completed (loss: 0.11824391037225723, acc: 0.9692533016204834)
[2024-12-17 03:59:28,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:28,597][root][INFO] - Training Epoch: 1/2, step 3194/7134 completed (loss: 0.1099773496389389, acc: 0.9738562107086182)
[2024-12-17 03:59:28,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:29,007][root][INFO] - Training Epoch: 1/2, step 3195/7134 completed (loss: 0.11125584691762924, acc: 0.9674099683761597)
[2024-12-17 03:59:29,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:29,423][root][INFO] - Training Epoch: 1/2, step 3196/7134 completed (loss: 0.06687819957733154, acc: 0.9831775426864624)
[2024-12-17 03:59:29,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:29,832][root][INFO] - Training Epoch: 1/2, step 3197/7134 completed (loss: 0.09409564733505249, acc: 0.9788732528686523)
[2024-12-17 03:59:29,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:30,270][root][INFO] - Training Epoch: 1/2, step 3198/7134 completed (loss: 0.1043965145945549, acc: 0.9712556600570679)
[2024-12-17 03:59:30,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:30,685][root][INFO] - Training Epoch: 1/2, step 3199/7134 completed (loss: 0.08574878424406052, acc: 0.9809104204177856)
[2024-12-17 03:59:30,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:31,134][root][INFO] - Training Epoch: 1/2, step 3200/7134 completed (loss: 0.08161300420761108, acc: 0.9753954410552979)
[2024-12-17 03:59:31,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:31,584][root][INFO] - Training Epoch: 1/2, step 3201/7134 completed (loss: 0.19438084959983826, acc: 0.9544468522071838)
[2024-12-17 03:59:31,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:32,007][root][INFO] - Training Epoch: 1/2, step 3202/7134 completed (loss: 0.07303541898727417, acc: 0.9834024906158447)
[2024-12-17 03:59:32,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:32,411][root][INFO] - Training Epoch: 1/2, step 3203/7134 completed (loss: 0.09901367127895355, acc: 0.971563994884491)
[2024-12-17 03:59:32,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:32,797][root][INFO] - Training Epoch: 1/2, step 3204/7134 completed (loss: 0.1608632355928421, acc: 0.9567669034004211)
[2024-12-17 03:59:32,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:33,198][root][INFO] - Training Epoch: 1/2, step 3205/7134 completed (loss: 0.05894191190600395, acc: 0.9805653691291809)
[2024-12-17 03:59:33,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:33,655][root][INFO] - Training Epoch: 1/2, step 3206/7134 completed (loss: 0.07109072804450989, acc: 0.9811866879463196)
[2024-12-17 03:59:33,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:34,076][root][INFO] - Training Epoch: 1/2, step 3207/7134 completed (loss: 0.10132481157779694, acc: 0.9770290851593018)
[2024-12-17 03:59:34,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:34,523][root][INFO] - Training Epoch: 1/2, step 3208/7134 completed (loss: 0.12770795822143555, acc: 0.9689542651176453)
[2024-12-17 03:59:34,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:34,928][root][INFO] - Training Epoch: 1/2, step 3209/7134 completed (loss: 0.07874402403831482, acc: 0.980654776096344)
[2024-12-17 03:59:35,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:35,351][root][INFO] - Training Epoch: 1/2, step 3210/7134 completed (loss: 0.038451652973890305, acc: 0.9924699068069458)
[2024-12-17 03:59:35,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:35,744][root][INFO] - Training Epoch: 1/2, step 3211/7134 completed (loss: 0.06098446995019913, acc: 0.9896050095558167)
[2024-12-17 03:59:35,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:36,164][root][INFO] - Training Epoch: 1/2, step 3212/7134 completed (loss: 0.038454826921224594, acc: 0.9930070042610168)
[2024-12-17 03:59:36,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:36,582][root][INFO] - Training Epoch: 1/2, step 3213/7134 completed (loss: 0.060509007424116135, acc: 0.9856528043746948)
[2024-12-17 03:59:36,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:37,029][root][INFO] - Training Epoch: 1/2, step 3214/7134 completed (loss: 0.06952055543661118, acc: 0.9839357137680054)
[2024-12-17 03:59:37,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:37,465][root][INFO] - Training Epoch: 1/2, step 3215/7134 completed (loss: 0.0742972269654274, acc: 0.9859943985939026)
[2024-12-17 03:59:37,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:37,901][root][INFO] - Training Epoch: 1/2, step 3216/7134 completed (loss: 0.03850990906357765, acc: 0.9899713397026062)
[2024-12-17 03:59:38,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:38,354][root][INFO] - Training Epoch: 1/2, step 3217/7134 completed (loss: 0.05996169522404671, acc: 0.9845161437988281)
[2024-12-17 03:59:38,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:38,753][root][INFO] - Training Epoch: 1/2, step 3218/7134 completed (loss: 0.0998353585600853, acc: 0.9718309640884399)
[2024-12-17 03:59:38,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:39,176][root][INFO] - Training Epoch: 1/2, step 3219/7134 completed (loss: 0.10505145788192749, acc: 0.9734120965003967)
[2024-12-17 03:59:39,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:39,607][root][INFO] - Training Epoch: 1/2, step 3220/7134 completed (loss: 0.08540883660316467, acc: 0.9746328592300415)
[2024-12-17 03:59:39,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:40,045][root][INFO] - Training Epoch: 1/2, step 3221/7134 completed (loss: 0.0890762209892273, acc: 0.9739726185798645)
[2024-12-17 03:59:40,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:40,461][root][INFO] - Training Epoch: 1/2, step 3222/7134 completed (loss: 0.12594088912010193, acc: 0.9712139964103699)
[2024-12-17 03:59:40,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:40,888][root][INFO] - Training Epoch: 1/2, step 3223/7134 completed (loss: 0.11496096104383469, acc: 0.9746031761169434)
[2024-12-17 03:59:40,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:41,343][root][INFO] - Training Epoch: 1/2, step 3224/7134 completed (loss: 0.12612317502498627, acc: 0.969609260559082)
[2024-12-17 03:59:41,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:41,789][root][INFO] - Training Epoch: 1/2, step 3225/7134 completed (loss: 0.10777832567691803, acc: 0.9721871018409729)
[2024-12-17 03:59:41,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:42,187][root][INFO] - Training Epoch: 1/2, step 3226/7134 completed (loss: 0.14057713747024536, acc: 0.9640933275222778)
[2024-12-17 03:59:42,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:42,667][root][INFO] - Training Epoch: 1/2, step 3227/7134 completed (loss: 0.15236791968345642, acc: 0.9560439586639404)
[2024-12-17 03:59:42,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:43,118][root][INFO] - Training Epoch: 1/2, step 3228/7134 completed (loss: 0.08602064102888107, acc: 0.9789750576019287)
[2024-12-17 03:59:43,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:43,567][root][INFO] - Training Epoch: 1/2, step 3229/7134 completed (loss: 0.09280708432197571, acc: 0.9742962121963501)
[2024-12-17 03:59:43,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:43,980][root][INFO] - Training Epoch: 1/2, step 3230/7134 completed (loss: 0.139157235622406, acc: 0.9644970297813416)
[2024-12-17 03:59:44,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:44,388][root][INFO] - Training Epoch: 1/2, step 3231/7134 completed (loss: 0.15413647890090942, acc: 0.9650455713272095)
[2024-12-17 03:59:44,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:44,862][root][INFO] - Training Epoch: 1/2, step 3232/7134 completed (loss: 0.08962608873844147, acc: 0.9741863012313843)
[2024-12-17 03:59:45,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:45,279][root][INFO] - Training Epoch: 1/2, step 3233/7134 completed (loss: 0.12090715020895004, acc: 0.9802761077880859)
[2024-12-17 03:59:45,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:45,689][root][INFO] - Training Epoch: 1/2, step 3234/7134 completed (loss: 0.09447547048330307, acc: 0.9826224446296692)
[2024-12-17 03:59:45,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:46,107][root][INFO] - Training Epoch: 1/2, step 3235/7134 completed (loss: 0.07481477409601212, acc: 0.977142870426178)
[2024-12-17 03:59:46,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:46,497][root][INFO] - Training Epoch: 1/2, step 3236/7134 completed (loss: 0.15991108119487762, acc: 0.9587628841400146)
[2024-12-17 03:59:46,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:46,925][root][INFO] - Training Epoch: 1/2, step 3237/7134 completed (loss: 0.0778607428073883, acc: 0.9838969111442566)
[2024-12-17 03:59:47,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:47,353][root][INFO] - Training Epoch: 1/2, step 3238/7134 completed (loss: 0.13788510859012604, acc: 0.9616564512252808)
[2024-12-17 03:59:47,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:47,770][root][INFO] - Training Epoch: 1/2, step 3239/7134 completed (loss: 0.07000590115785599, acc: 0.9842271208763123)
[2024-12-17 03:59:47,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:48,207][root][INFO] - Training Epoch: 1/2, step 3240/7134 completed (loss: 0.06609708070755005, acc: 0.9835575222969055)
[2024-12-17 03:59:48,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:48,645][root][INFO] - Training Epoch: 1/2, step 3241/7134 completed (loss: 0.05306381359696388, acc: 0.9866468906402588)
[2024-12-17 03:59:48,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:49,070][root][INFO] - Training Epoch: 1/2, step 3242/7134 completed (loss: 0.06991167366504669, acc: 0.9852941036224365)
[2024-12-17 03:59:49,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:49,508][root][INFO] - Training Epoch: 1/2, step 3243/7134 completed (loss: 0.06003892794251442, acc: 0.9809264540672302)
[2024-12-17 03:59:49,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:49,919][root][INFO] - Training Epoch: 1/2, step 3244/7134 completed (loss: 0.05365587770938873, acc: 0.9870874881744385)
[2024-12-17 03:59:50,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:50,366][root][INFO] - Training Epoch: 1/2, step 3245/7134 completed (loss: 0.08060488849878311, acc: 0.9819587469100952)
[2024-12-17 03:59:50,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:50,809][root][INFO] - Training Epoch: 1/2, step 3246/7134 completed (loss: 0.11615433543920517, acc: 0.9615384340286255)
[2024-12-17 03:59:50,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:51,241][root][INFO] - Training Epoch: 1/2, step 3247/7134 completed (loss: 0.07539954036474228, acc: 0.9805510640144348)
[2024-12-17 03:59:51,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:51,656][root][INFO] - Training Epoch: 1/2, step 3248/7134 completed (loss: 0.046516451984643936, acc: 0.9901477694511414)
[2024-12-17 03:59:51,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:52,077][root][INFO] - Training Epoch: 1/2, step 3249/7134 completed (loss: 0.06807485222816467, acc: 0.9875173568725586)
[2024-12-17 03:59:52,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:52,495][root][INFO] - Training Epoch: 1/2, step 3250/7134 completed (loss: 0.07112552225589752, acc: 0.9812949895858765)
[2024-12-17 03:59:52,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:52,910][root][INFO] - Training Epoch: 1/2, step 3251/7134 completed (loss: 0.037023961544036865, acc: 0.9914407730102539)
[2024-12-17 03:59:53,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:53,339][root][INFO] - Training Epoch: 1/2, step 3252/7134 completed (loss: 0.03755733370780945, acc: 0.9929078221321106)
[2024-12-17 03:59:53,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:53,767][root][INFO] - Training Epoch: 1/2, step 3253/7134 completed (loss: 0.03826534003019333, acc: 0.9903692007064819)
[2024-12-17 03:59:53,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:54,206][root][INFO] - Training Epoch: 1/2, step 3254/7134 completed (loss: 0.05371333658695221, acc: 0.979763925075531)
[2024-12-17 03:59:54,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:54,619][root][INFO] - Training Epoch: 1/2, step 3255/7134 completed (loss: 0.034543849527835846, acc: 0.9880159497261047)
[2024-12-17 03:59:54,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:55,034][root][INFO] - Training Epoch: 1/2, step 3256/7134 completed (loss: 0.043514229357242584, acc: 0.9851852059364319)
[2024-12-17 03:59:55,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:55,451][root][INFO] - Training Epoch: 1/2, step 3257/7134 completed (loss: 0.04779569059610367, acc: 0.9875173568725586)
[2024-12-17 03:59:55,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:55,884][root][INFO] - Training Epoch: 1/2, step 3258/7134 completed (loss: 0.08044740557670593, acc: 0.9730769395828247)
[2024-12-17 03:59:56,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:56,308][root][INFO] - Training Epoch: 1/2, step 3259/7134 completed (loss: 0.06017598509788513, acc: 0.9823529124259949)
[2024-12-17 03:59:56,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:56,731][root][INFO] - Training Epoch: 1/2, step 3260/7134 completed (loss: 0.12025178968906403, acc: 0.9703264236450195)
[2024-12-17 03:59:56,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:57,151][root][INFO] - Training Epoch: 1/2, step 3261/7134 completed (loss: 0.12415361404418945, acc: 0.9697986841201782)
[2024-12-17 03:59:57,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:57,593][root][INFO] - Training Epoch: 1/2, step 3262/7134 completed (loss: 0.050774261355400085, acc: 0.9840810298919678)
[2024-12-17 03:59:57,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:58,013][root][INFO] - Training Epoch: 1/2, step 3263/7134 completed (loss: 0.10395421832799911, acc: 0.9765051603317261)
[2024-12-17 03:59:58,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:58,418][root][INFO] - Training Epoch: 1/2, step 3264/7134 completed (loss: 0.050461821258068085, acc: 0.987500011920929)
[2024-12-17 03:59:58,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:58,855][root][INFO] - Training Epoch: 1/2, step 3265/7134 completed (loss: 0.13248108327388763, acc: 0.9686609506607056)
[2024-12-17 03:59:58,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:59,287][root][INFO] - Training Epoch: 1/2, step 3266/7134 completed (loss: 0.061770543456077576, acc: 0.9834834933280945)
[2024-12-17 03:59:59,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:59:59,724][root][INFO] - Training Epoch: 1/2, step 3267/7134 completed (loss: 0.11932122707366943, acc: 0.9684813618659973)
[2024-12-17 03:59:59,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:00,118][root][INFO] - Training Epoch: 1/2, step 3268/7134 completed (loss: 0.08764791488647461, acc: 0.9799692034721375)
[2024-12-17 04:00:00,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:00,559][root][INFO] - Training Epoch: 1/2, step 3269/7134 completed (loss: 0.09126565605401993, acc: 0.9797979593276978)
[2024-12-17 04:00:00,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:01,004][root][INFO] - Training Epoch: 1/2, step 3270/7134 completed (loss: 0.05089731141924858, acc: 0.9868420958518982)
[2024-12-17 04:00:01,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:01,436][root][INFO] - Training Epoch: 1/2, step 3271/7134 completed (loss: 0.031165655702352524, acc: 0.9899665713310242)
[2024-12-17 04:00:01,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:01,872][root][INFO] - Training Epoch: 1/2, step 3272/7134 completed (loss: 0.05284309759736061, acc: 0.9923664331436157)
[2024-12-17 04:00:01,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:02,323][root][INFO] - Training Epoch: 1/2, step 3273/7134 completed (loss: 0.05903495475649834, acc: 0.9821200370788574)
[2024-12-17 04:00:02,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:02,772][root][INFO] - Training Epoch: 1/2, step 3274/7134 completed (loss: 0.07189953327178955, acc: 0.9867841601371765)
[2024-12-17 04:00:02,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:03,199][root][INFO] - Training Epoch: 1/2, step 3275/7134 completed (loss: 0.20598602294921875, acc: 0.9473684430122375)
[2024-12-17 04:00:03,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:03,619][root][INFO] - Training Epoch: 1/2, step 3276/7134 completed (loss: 0.13907665014266968, acc: 0.9600551128387451)
[2024-12-17 04:00:03,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:04,042][root][INFO] - Training Epoch: 1/2, step 3277/7134 completed (loss: 0.1065177246928215, acc: 0.9725610017776489)
[2024-12-17 04:00:04,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:04,433][root][INFO] - Training Epoch: 1/2, step 3278/7134 completed (loss: 0.09091857075691223, acc: 0.9789674878120422)
[2024-12-17 04:00:04,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:04,875][root][INFO] - Training Epoch: 1/2, step 3279/7134 completed (loss: 0.10677481442689896, acc: 0.9627329111099243)
[2024-12-17 04:00:05,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:05,274][root][INFO] - Training Epoch: 1/2, step 3280/7134 completed (loss: 0.2375793308019638, acc: 0.9481327533721924)
[2024-12-17 04:00:05,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:05,705][root][INFO] - Training Epoch: 1/2, step 3281/7134 completed (loss: 0.094340980052948, acc: 0.9710144996643066)
[2024-12-17 04:00:05,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:06,123][root][INFO] - Training Epoch: 1/2, step 3282/7134 completed (loss: 0.07027827948331833, acc: 0.9810126423835754)
[2024-12-17 04:00:06,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:06,569][root][INFO] - Training Epoch: 1/2, step 3283/7134 completed (loss: 0.09901820868253708, acc: 0.9752577543258667)
[2024-12-17 04:00:06,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:06,992][root][INFO] - Training Epoch: 1/2, step 3284/7134 completed (loss: 0.12933173775672913, acc: 0.9619482755661011)
[2024-12-17 04:00:07,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:07,398][root][INFO] - Training Epoch: 1/2, step 3285/7134 completed (loss: 0.07559683918952942, acc: 0.9798761606216431)
[2024-12-17 04:00:07,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:07,812][root][INFO] - Training Epoch: 1/2, step 3286/7134 completed (loss: 0.08460400253534317, acc: 0.9804511070251465)
[2024-12-17 04:00:07,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:08,217][root][INFO] - Training Epoch: 1/2, step 3287/7134 completed (loss: 0.15500424802303314, acc: 0.9605262875556946)
[2024-12-17 04:00:08,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:08,654][root][INFO] - Training Epoch: 1/2, step 3288/7134 completed (loss: 0.08632081747055054, acc: 0.976047933101654)
[2024-12-17 04:00:08,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:09,028][root][INFO] - Training Epoch: 1/2, step 3289/7134 completed (loss: 0.1558893769979477, acc: 0.9649122953414917)
[2024-12-17 04:00:09,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:09,428][root][INFO] - Training Epoch: 1/2, step 3290/7134 completed (loss: 0.15267087519168854, acc: 0.9652777910232544)
[2024-12-17 04:00:09,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:09,835][root][INFO] - Training Epoch: 1/2, step 3291/7134 completed (loss: 0.12495925277471542, acc: 0.9621380567550659)
[2024-12-17 04:00:09,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:10,249][root][INFO] - Training Epoch: 1/2, step 3292/7134 completed (loss: 0.09301735460758209, acc: 0.9753086566925049)
[2024-12-17 04:00:10,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:10,700][root][INFO] - Training Epoch: 1/2, step 3293/7134 completed (loss: 0.06918171793222427, acc: 0.9778761267662048)
[2024-12-17 04:00:10,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:11,116][root][INFO] - Training Epoch: 1/2, step 3294/7134 completed (loss: 0.11914379149675369, acc: 0.9663093686103821)
[2024-12-17 04:00:11,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:11,521][root][INFO] - Training Epoch: 1/2, step 3295/7134 completed (loss: 0.04428519308567047, acc: 0.9931740760803223)
[2024-12-17 04:00:11,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:11,938][root][INFO] - Training Epoch: 1/2, step 3296/7134 completed (loss: 0.0960078090429306, acc: 0.97074955701828)
[2024-12-17 04:00:12,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:12,343][root][INFO] - Training Epoch: 1/2, step 3297/7134 completed (loss: 0.1153227686882019, acc: 0.9671361446380615)
[2024-12-17 04:00:12,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:12,775][root][INFO] - Training Epoch: 1/2, step 3298/7134 completed (loss: 0.14981186389923096, acc: 0.9648562073707581)
[2024-12-17 04:00:12,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:13,194][root][INFO] - Training Epoch: 1/2, step 3299/7134 completed (loss: 0.0762229636311531, acc: 0.9731543660163879)
[2024-12-17 04:00:13,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:13,619][root][INFO] - Training Epoch: 1/2, step 3300/7134 completed (loss: 0.1602035015821457, acc: 0.9572192430496216)
[2024-12-17 04:00:13,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:14,011][root][INFO] - Training Epoch: 1/2, step 3301/7134 completed (loss: 0.13515473902225494, acc: 0.9730290174484253)
[2024-12-17 04:00:14,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:14,410][root][INFO] - Training Epoch: 1/2, step 3302/7134 completed (loss: 0.10355427861213684, acc: 0.9663299918174744)
[2024-12-17 04:00:14,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:14,804][root][INFO] - Training Epoch: 1/2, step 3303/7134 completed (loss: 0.11146648228168488, acc: 0.9779735803604126)
[2024-12-17 04:00:14,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:15,248][root][INFO] - Training Epoch: 1/2, step 3304/7134 completed (loss: 0.0618911013007164, acc: 0.9856801629066467)
[2024-12-17 04:00:15,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:15,683][root][INFO] - Training Epoch: 1/2, step 3305/7134 completed (loss: 0.09849622845649719, acc: 0.9758672714233398)
[2024-12-17 04:00:15,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:16,158][root][INFO] - Training Epoch: 1/2, step 3306/7134 completed (loss: 0.09502244740724564, acc: 0.9753566980361938)
[2024-12-17 04:00:16,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:16,585][root][INFO] - Training Epoch: 1/2, step 3307/7134 completed (loss: 0.1104145497083664, acc: 0.9763113260269165)
[2024-12-17 04:00:16,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:17,005][root][INFO] - Training Epoch: 1/2, step 3308/7134 completed (loss: 0.0730365514755249, acc: 0.9768785834312439)
[2024-12-17 04:00:17,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:17,411][root][INFO] - Training Epoch: 1/2, step 3309/7134 completed (loss: 0.1405692845582962, acc: 0.9646017551422119)
[2024-12-17 04:00:17,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:17,864][root][INFO] - Training Epoch: 1/2, step 3310/7134 completed (loss: 0.0783480778336525, acc: 0.9722814559936523)
[2024-12-17 04:00:17,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:18,221][root][INFO] - Training Epoch: 1/2, step 3311/7134 completed (loss: 0.0858004167675972, acc: 0.9741935729980469)
[2024-12-17 04:00:18,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:18,637][root][INFO] - Training Epoch: 1/2, step 3312/7134 completed (loss: 0.10078651458024979, acc: 0.9763636589050293)
[2024-12-17 04:00:18,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:19,063][root][INFO] - Training Epoch: 1/2, step 3313/7134 completed (loss: 0.07344768196344376, acc: 0.9832935333251953)
[2024-12-17 04:00:19,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:19,472][root][INFO] - Training Epoch: 1/2, step 3314/7134 completed (loss: 0.09981350600719452, acc: 0.9655796885490417)
[2024-12-17 04:00:19,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:19,918][root][INFO] - Training Epoch: 1/2, step 3315/7134 completed (loss: 0.14722071588039398, acc: 0.9592944383621216)
[2024-12-17 04:00:20,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:20,366][root][INFO] - Training Epoch: 1/2, step 3316/7134 completed (loss: 0.06521061807870865, acc: 0.9848739504814148)
[2024-12-17 04:00:20,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:20,811][root][INFO] - Training Epoch: 1/2, step 3317/7134 completed (loss: 0.16511297225952148, acc: 0.9557692408561707)
[2024-12-17 04:00:20,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:21,168][root][INFO] - Training Epoch: 1/2, step 3318/7134 completed (loss: 0.11402494460344315, acc: 0.9638988971710205)
[2024-12-17 04:00:21,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:21,621][root][INFO] - Training Epoch: 1/2, step 3319/7134 completed (loss: 0.09726040065288544, acc: 0.975570023059845)
[2024-12-17 04:00:21,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:22,067][root][INFO] - Training Epoch: 1/2, step 3320/7134 completed (loss: 0.1422177106142044, acc: 0.9568063020706177)
[2024-12-17 04:00:22,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:22,481][root][INFO] - Training Epoch: 1/2, step 3321/7134 completed (loss: 0.19546999037265778, acc: 0.957798182964325)
[2024-12-17 04:00:22,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:22,939][root][INFO] - Training Epoch: 1/2, step 3322/7134 completed (loss: 0.07948479801416397, acc: 0.9804804921150208)
[2024-12-17 04:00:23,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:23,379][root][INFO] - Training Epoch: 1/2, step 3323/7134 completed (loss: 0.09064537286758423, acc: 0.9668965339660645)
[2024-12-17 04:00:23,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:23,848][root][INFO] - Training Epoch: 1/2, step 3324/7134 completed (loss: 0.13083915412425995, acc: 0.9634864330291748)
[2024-12-17 04:00:23,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:24,295][root][INFO] - Training Epoch: 1/2, step 3325/7134 completed (loss: 0.08637528121471405, acc: 0.9811828136444092)
[2024-12-17 04:00:24,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:24,740][root][INFO] - Training Epoch: 1/2, step 3326/7134 completed (loss: 0.11979427933692932, acc: 0.9716535210609436)
[2024-12-17 04:00:24,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:25,161][root][INFO] - Training Epoch: 1/2, step 3327/7134 completed (loss: 0.10740439593791962, acc: 0.97428959608078)
[2024-12-17 04:00:25,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:25,630][root][INFO] - Training Epoch: 1/2, step 3328/7134 completed (loss: 0.0699908435344696, acc: 0.9862155318260193)
[2024-12-17 04:00:25,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:26,065][root][INFO] - Training Epoch: 1/2, step 3329/7134 completed (loss: 0.05964399874210358, acc: 0.9841656684875488)
[2024-12-17 04:00:26,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:26,519][root][INFO] - Training Epoch: 1/2, step 3330/7134 completed (loss: 0.11921391636133194, acc: 0.9746543765068054)
[2024-12-17 04:00:26,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:26,933][root][INFO] - Training Epoch: 1/2, step 3331/7134 completed (loss: 0.21826575696468353, acc: 0.9505813717842102)
[2024-12-17 04:00:27,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:27,371][root][INFO] - Training Epoch: 1/2, step 3332/7134 completed (loss: 0.14977657794952393, acc: 0.9498270153999329)
[2024-12-17 04:00:27,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:27,760][root][INFO] - Training Epoch: 1/2, step 3333/7134 completed (loss: 0.12001791596412659, acc: 0.9672130942344666)
[2024-12-17 04:00:27,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:28,177][root][INFO] - Training Epoch: 1/2, step 3334/7134 completed (loss: 0.13997100293636322, acc: 0.9554054141044617)
[2024-12-17 04:00:28,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:28,600][root][INFO] - Training Epoch: 1/2, step 3335/7134 completed (loss: 0.06918881088495255, acc: 0.982594907283783)
[2024-12-17 04:00:28,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:29,014][root][INFO] - Training Epoch: 1/2, step 3336/7134 completed (loss: 0.05336368829011917, acc: 0.9854227304458618)
[2024-12-17 04:00:29,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:29,430][root][INFO] - Training Epoch: 1/2, step 3337/7134 completed (loss: 0.05184090510010719, acc: 0.9822485446929932)
[2024-12-17 04:00:29,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:29,869][root][INFO] - Training Epoch: 1/2, step 3338/7134 completed (loss: 0.04611436277627945, acc: 0.9888198971748352)
[2024-12-17 04:00:29,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:30,321][root][INFO] - Training Epoch: 1/2, step 3339/7134 completed (loss: 0.09456605464220047, acc: 0.9713603854179382)
[2024-12-17 04:00:30,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:30,739][root][INFO] - Training Epoch: 1/2, step 3340/7134 completed (loss: 0.1549115926027298, acc: 0.9607843160629272)
[2024-12-17 04:00:30,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:31,177][root][INFO] - Training Epoch: 1/2, step 3341/7134 completed (loss: 0.12149187177419662, acc: 0.9748148322105408)
[2024-12-17 04:00:31,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:31,603][root][INFO] - Training Epoch: 1/2, step 3342/7134 completed (loss: 0.09599306434392929, acc: 0.9763513803482056)
[2024-12-17 04:00:31,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:32,064][root][INFO] - Training Epoch: 1/2, step 3343/7134 completed (loss: 0.08072417974472046, acc: 0.975806474685669)
[2024-12-17 04:00:32,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:32,485][root][INFO] - Training Epoch: 1/2, step 3344/7134 completed (loss: 0.08207082003355026, acc: 0.9742709994316101)
[2024-12-17 04:00:32,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:32,932][root][INFO] - Training Epoch: 1/2, step 3345/7134 completed (loss: 0.08704743534326553, acc: 0.9821717739105225)
[2024-12-17 04:00:33,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:33,356][root][INFO] - Training Epoch: 1/2, step 3346/7134 completed (loss: 0.04638342186808586, acc: 0.9853801131248474)
[2024-12-17 04:00:33,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:33,786][root][INFO] - Training Epoch: 1/2, step 3347/7134 completed (loss: 0.12467128038406372, acc: 0.965798020362854)
[2024-12-17 04:00:33,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:34,194][root][INFO] - Training Epoch: 1/2, step 3348/7134 completed (loss: 0.0940505862236023, acc: 0.9748148322105408)
[2024-12-17 04:00:34,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:34,571][root][INFO] - Training Epoch: 1/2, step 3349/7134 completed (loss: 0.07999017834663391, acc: 0.9753086566925049)
[2024-12-17 04:00:34,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:34,985][root][INFO] - Training Epoch: 1/2, step 3350/7134 completed (loss: 0.06220614165067673, acc: 0.9878048896789551)
[2024-12-17 04:00:35,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:35,383][root][INFO] - Training Epoch: 1/2, step 3351/7134 completed (loss: 0.17098286747932434, acc: 0.970822274684906)
[2024-12-17 04:00:35,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:35,785][root][INFO] - Training Epoch: 1/2, step 3352/7134 completed (loss: 0.05108245834708214, acc: 0.9895651936531067)
[2024-12-17 04:00:35,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:36,203][root][INFO] - Training Epoch: 1/2, step 3353/7134 completed (loss: 0.07251805812120438, acc: 0.9802761077880859)
[2024-12-17 04:00:36,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:36,616][root][INFO] - Training Epoch: 1/2, step 3354/7134 completed (loss: 0.05571271479129791, acc: 0.9906976819038391)
[2024-12-17 04:00:36,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:37,033][root][INFO] - Training Epoch: 1/2, step 3355/7134 completed (loss: 0.04839196801185608, acc: 0.9887164831161499)
[2024-12-17 04:00:37,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:37,445][root][INFO] - Training Epoch: 1/2, step 3356/7134 completed (loss: 0.03438275679945946, acc: 0.9878472089767456)
[2024-12-17 04:00:37,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:37,875][root][INFO] - Training Epoch: 1/2, step 3357/7134 completed (loss: 0.06740403175354004, acc: 0.9855700135231018)
[2024-12-17 04:00:37,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:38,271][root][INFO] - Training Epoch: 1/2, step 3358/7134 completed (loss: 0.13568483293056488, acc: 0.9515570998191833)
[2024-12-17 04:00:38,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:38,669][root][INFO] - Training Epoch: 1/2, step 3359/7134 completed (loss: 0.06826800853013992, acc: 0.9822006225585938)
[2024-12-17 04:00:38,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:39,069][root][INFO] - Training Epoch: 1/2, step 3360/7134 completed (loss: 0.12140814960002899, acc: 0.9742489457130432)
[2024-12-17 04:00:39,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:39,469][root][INFO] - Training Epoch: 1/2, step 3361/7134 completed (loss: 0.1313798576593399, acc: 0.9709172248840332)
[2024-12-17 04:00:39,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:39,868][root][INFO] - Training Epoch: 1/2, step 3362/7134 completed (loss: 0.0778789296746254, acc: 0.9818593859672546)
[2024-12-17 04:00:39,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:40,225][root][INFO] - Training Epoch: 1/2, step 3363/7134 completed (loss: 0.04256269335746765, acc: 0.98591548204422)
[2024-12-17 04:00:40,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:40,660][root][INFO] - Training Epoch: 1/2, step 3364/7134 completed (loss: 0.14350873231887817, acc: 0.9646697640419006)
[2024-12-17 04:00:40,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:41,068][root][INFO] - Training Epoch: 1/2, step 3365/7134 completed (loss: 0.1310928612947464, acc: 0.9710843563079834)
[2024-12-17 04:00:41,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:41,477][root][INFO] - Training Epoch: 1/2, step 3366/7134 completed (loss: 0.07483447343111038, acc: 0.9798206090927124)
[2024-12-17 04:00:41,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:41,882][root][INFO] - Training Epoch: 1/2, step 3367/7134 completed (loss: 0.07424892485141754, acc: 0.9779614210128784)
[2024-12-17 04:00:41,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:42,303][root][INFO] - Training Epoch: 1/2, step 3368/7134 completed (loss: 0.11701855808496475, acc: 0.9672386646270752)
[2024-12-17 04:00:42,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:42,750][root][INFO] - Training Epoch: 1/2, step 3369/7134 completed (loss: 0.11964476108551025, acc: 0.9741007089614868)
[2024-12-17 04:00:42,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:43,165][root][INFO] - Training Epoch: 1/2, step 3370/7134 completed (loss: 0.09638119488954544, acc: 0.9742489457130432)
[2024-12-17 04:00:43,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:43,586][root][INFO] - Training Epoch: 1/2, step 3371/7134 completed (loss: 0.1153285875916481, acc: 0.9621710777282715)
[2024-12-17 04:00:43,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:44,024][root][INFO] - Training Epoch: 1/2, step 3372/7134 completed (loss: 0.08922813087701797, acc: 0.9717868566513062)
[2024-12-17 04:00:44,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:44,430][root][INFO] - Training Epoch: 1/2, step 3373/7134 completed (loss: 0.0782015323638916, acc: 0.9783950448036194)
[2024-12-17 04:00:44,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:44,881][root][INFO] - Training Epoch: 1/2, step 3374/7134 completed (loss: 0.0956641137599945, acc: 0.9777158498764038)
[2024-12-17 04:00:44,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:45,326][root][INFO] - Training Epoch: 1/2, step 3375/7134 completed (loss: 0.07172080129384995, acc: 0.986975371837616)
[2024-12-17 04:00:45,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:45,765][root][INFO] - Training Epoch: 1/2, step 3376/7134 completed (loss: 0.043978579342365265, acc: 0.992337167263031)
[2024-12-17 04:00:45,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:46,233][root][INFO] - Training Epoch: 1/2, step 3377/7134 completed (loss: 0.04779486358165741, acc: 0.9856972694396973)
[2024-12-17 04:00:46,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:46,664][root][INFO] - Training Epoch: 1/2, step 3378/7134 completed (loss: 0.0617346465587616, acc: 0.9817708134651184)
[2024-12-17 04:00:46,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:47,071][root][INFO] - Training Epoch: 1/2, step 3379/7134 completed (loss: 0.07945947349071503, acc: 0.9729323387145996)
[2024-12-17 04:00:47,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:47,486][root][INFO] - Training Epoch: 1/2, step 3380/7134 completed (loss: 0.08571477234363556, acc: 0.9769230484962463)
[2024-12-17 04:00:47,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:47,930][root][INFO] - Training Epoch: 1/2, step 3381/7134 completed (loss: 0.1004631444811821, acc: 0.9715762138366699)
[2024-12-17 04:00:48,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:48,343][root][INFO] - Training Epoch: 1/2, step 3382/7134 completed (loss: 0.06361240148544312, acc: 0.9861591458320618)
[2024-12-17 04:00:48,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:48,785][root][INFO] - Training Epoch: 1/2, step 3383/7134 completed (loss: 0.083652563393116, acc: 0.9799138903617859)
[2024-12-17 04:00:48,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:49,176][root][INFO] - Training Epoch: 1/2, step 3384/7134 completed (loss: 0.09865380823612213, acc: 0.9694189429283142)
[2024-12-17 04:00:49,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:49,589][root][INFO] - Training Epoch: 1/2, step 3385/7134 completed (loss: 0.08352974057197571, acc: 0.971222996711731)
[2024-12-17 04:00:49,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:50,017][root][INFO] - Training Epoch: 1/2, step 3386/7134 completed (loss: 0.06141837313771248, acc: 0.9802259802818298)
[2024-12-17 04:00:50,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:50,442][root][INFO] - Training Epoch: 1/2, step 3387/7134 completed (loss: 0.09841182827949524, acc: 0.9741496443748474)
[2024-12-17 04:00:50,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:50,863][root][INFO] - Training Epoch: 1/2, step 3388/7134 completed (loss: 0.08786844462156296, acc: 0.9692586064338684)
[2024-12-17 04:00:50,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:51,282][root][INFO] - Training Epoch: 1/2, step 3389/7134 completed (loss: 0.06914804875850677, acc: 0.9868247509002686)
[2024-12-17 04:00:51,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:51,709][root][INFO] - Training Epoch: 1/2, step 3390/7134 completed (loss: 0.06487930566072464, acc: 0.9766839146614075)
[2024-12-17 04:00:51,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:52,105][root][INFO] - Training Epoch: 1/2, step 3391/7134 completed (loss: 0.03656012564897537, acc: 0.9903846383094788)
[2024-12-17 04:00:52,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:52,499][root][INFO] - Training Epoch: 1/2, step 3392/7134 completed (loss: 0.04492121934890747, acc: 0.9842767119407654)
[2024-12-17 04:00:52,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:52,901][root][INFO] - Training Epoch: 1/2, step 3393/7134 completed (loss: 0.059417229145765305, acc: 0.979938268661499)
[2024-12-17 04:00:53,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:53,323][root][INFO] - Training Epoch: 1/2, step 3394/7134 completed (loss: 0.06079072132706642, acc: 0.9857594966888428)
[2024-12-17 04:00:53,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:53,716][root][INFO] - Training Epoch: 1/2, step 3395/7134 completed (loss: 0.15136279165744781, acc: 0.9610389471054077)
[2024-12-17 04:00:53,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:54,161][root][INFO] - Training Epoch: 1/2, step 3396/7134 completed (loss: 0.053285542875528336, acc: 0.9892215728759766)
[2024-12-17 04:00:54,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:54,609][root][INFO] - Training Epoch: 1/2, step 3397/7134 completed (loss: 0.08234614133834839, acc: 0.9828850626945496)
[2024-12-17 04:00:54,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:55,031][root][INFO] - Training Epoch: 1/2, step 3398/7134 completed (loss: 0.0825612023472786, acc: 0.9784946441650391)
[2024-12-17 04:00:55,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:55,438][root][INFO] - Training Epoch: 1/2, step 3399/7134 completed (loss: 0.1919267773628235, acc: 0.9577205777168274)
[2024-12-17 04:00:55,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:55,856][root][INFO] - Training Epoch: 1/2, step 3400/7134 completed (loss: 0.17729759216308594, acc: 0.9574036598205566)
[2024-12-17 04:00:55,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:56,272][root][INFO] - Training Epoch: 1/2, step 3401/7134 completed (loss: 0.15846504271030426, acc: 0.9597902297973633)
[2024-12-17 04:00:56,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:56,766][root][INFO] - Training Epoch: 1/2, step 3402/7134 completed (loss: 0.13747389614582062, acc: 0.9657443761825562)
[2024-12-17 04:00:56,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:57,254][root][INFO] - Training Epoch: 1/2, step 3403/7134 completed (loss: 0.1546187549829483, acc: 0.9583333134651184)
[2024-12-17 04:00:57,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:57,672][root][INFO] - Training Epoch: 1/2, step 3404/7134 completed (loss: 0.056775711476802826, acc: 0.988041877746582)
[2024-12-17 04:00:57,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:58,103][root][INFO] - Training Epoch: 1/2, step 3405/7134 completed (loss: 0.1337590366601944, acc: 0.971222996711731)
[2024-12-17 04:00:58,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:58,539][root][INFO] - Training Epoch: 1/2, step 3406/7134 completed (loss: 0.08874301612377167, acc: 0.9768041372299194)
[2024-12-17 04:00:58,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:58,923][root][INFO] - Training Epoch: 1/2, step 3407/7134 completed (loss: 0.07073431462049484, acc: 0.9843993782997131)
[2024-12-17 04:00:59,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:59,319][root][INFO] - Training Epoch: 1/2, step 3408/7134 completed (loss: 0.08590016514062881, acc: 0.9723502397537231)
[2024-12-17 04:00:59,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:00:59,766][root][INFO] - Training Epoch: 1/2, step 3409/7134 completed (loss: 0.10081711411476135, acc: 0.9729363918304443)
[2024-12-17 04:00:59,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:00,181][root][INFO] - Training Epoch: 1/2, step 3410/7134 completed (loss: 0.09452566504478455, acc: 0.9765840172767639)
[2024-12-17 04:01:00,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:00,624][root][INFO] - Training Epoch: 1/2, step 3411/7134 completed (loss: 0.09471789747476578, acc: 0.9793014526367188)
[2024-12-17 04:01:00,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:01,020][root][INFO] - Training Epoch: 1/2, step 3412/7134 completed (loss: 0.12550649046897888, acc: 0.9584121108055115)
[2024-12-17 04:01:01,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:01,448][root][INFO] - Training Epoch: 1/2, step 3413/7134 completed (loss: 0.09073493629693985, acc: 0.9679999947547913)
[2024-12-17 04:01:01,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:01,858][root][INFO] - Training Epoch: 1/2, step 3414/7134 completed (loss: 0.090571328997612, acc: 0.9816360473632812)
[2024-12-17 04:01:01,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:02,297][root][INFO] - Training Epoch: 1/2, step 3415/7134 completed (loss: 0.0847783014178276, acc: 0.9807692170143127)
[2024-12-17 04:01:02,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:02,752][root][INFO] - Training Epoch: 1/2, step 3416/7134 completed (loss: 0.09664398431777954, acc: 0.9771908521652222)
[2024-12-17 04:01:02,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:03,186][root][INFO] - Training Epoch: 1/2, step 3417/7134 completed (loss: 0.07364145666360855, acc: 0.9797570705413818)
[2024-12-17 04:01:03,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:03,623][root][INFO] - Training Epoch: 1/2, step 3418/7134 completed (loss: 0.04132775962352753, acc: 0.9955817461013794)
[2024-12-17 04:01:03,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:04,023][root][INFO] - Training Epoch: 1/2, step 3419/7134 completed (loss: 0.025135105475783348, acc: 0.9927954077720642)
[2024-12-17 04:01:04,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:04,439][root][INFO] - Training Epoch: 1/2, step 3420/7134 completed (loss: 0.0364176444709301, acc: 0.9936808943748474)
[2024-12-17 04:01:04,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:04,861][root][INFO] - Training Epoch: 1/2, step 3421/7134 completed (loss: 0.04088475927710533, acc: 0.9953343868255615)
[2024-12-17 04:01:04,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:05,246][root][INFO] - Training Epoch: 1/2, step 3422/7134 completed (loss: 0.020345238968729973, acc: 0.9982486963272095)
[2024-12-17 04:01:05,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:05,673][root][INFO] - Training Epoch: 1/2, step 3423/7134 completed (loss: 0.027413876727223396, acc: 0.9939393997192383)
[2024-12-17 04:01:05,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:06,084][root][INFO] - Training Epoch: 1/2, step 3424/7134 completed (loss: 0.0884489044547081, acc: 0.974397599697113)
[2024-12-17 04:01:06,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:06,504][root][INFO] - Training Epoch: 1/2, step 3425/7134 completed (loss: 0.08873683214187622, acc: 0.9820512533187866)
[2024-12-17 04:01:06,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:06,940][root][INFO] - Training Epoch: 1/2, step 3426/7134 completed (loss: 0.06686180084943771, acc: 0.9848275780677795)
[2024-12-17 04:01:07,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:07,364][root][INFO] - Training Epoch: 1/2, step 3427/7134 completed (loss: 0.0639747902750969, acc: 0.9921011328697205)
[2024-12-17 04:01:07,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:07,800][root][INFO] - Training Epoch: 1/2, step 3428/7134 completed (loss: 0.03773505240678787, acc: 0.9928366541862488)
[2024-12-17 04:01:07,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:08,245][root][INFO] - Training Epoch: 1/2, step 3429/7134 completed (loss: 0.07935740798711777, acc: 0.9822006225585938)
[2024-12-17 04:01:08,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:08,661][root][INFO] - Training Epoch: 1/2, step 3430/7134 completed (loss: 0.12303375452756882, acc: 0.9837925434112549)
[2024-12-17 04:01:08,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:09,103][root][INFO] - Training Epoch: 1/2, step 3431/7134 completed (loss: 0.0846116915345192, acc: 0.9830220937728882)
[2024-12-17 04:01:09,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:09,550][root][INFO] - Training Epoch: 1/2, step 3432/7134 completed (loss: 0.05841928347945213, acc: 0.9862825870513916)
[2024-12-17 04:01:09,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:10,001][root][INFO] - Training Epoch: 1/2, step 3433/7134 completed (loss: 0.09452104568481445, acc: 0.9787581562995911)
[2024-12-17 04:01:10,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:10,413][root][INFO] - Training Epoch: 1/2, step 3434/7134 completed (loss: 0.06748318672180176, acc: 0.9809221029281616)
[2024-12-17 04:01:10,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:10,830][root][INFO] - Training Epoch: 1/2, step 3435/7134 completed (loss: 0.07794195413589478, acc: 0.9742765426635742)
[2024-12-17 04:01:10,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:11,258][root][INFO] - Training Epoch: 1/2, step 3436/7134 completed (loss: 0.07374949753284454, acc: 0.9707317352294922)
[2024-12-17 04:01:11,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:11,641][root][INFO] - Training Epoch: 1/2, step 3437/7134 completed (loss: 0.05209469795227051, acc: 0.986328125)
[2024-12-17 04:01:11,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:12,055][root][INFO] - Training Epoch: 1/2, step 3438/7134 completed (loss: 0.07309145480394363, acc: 0.9777777791023254)
[2024-12-17 04:01:12,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:12,436][root][INFO] - Training Epoch: 1/2, step 3439/7134 completed (loss: 0.08575713634490967, acc: 0.9746835231781006)
[2024-12-17 04:01:12,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:12,845][root][INFO] - Training Epoch: 1/2, step 3440/7134 completed (loss: 0.18359500169754028, acc: 0.9465020298957825)
[2024-12-17 04:01:12,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:13,259][root][INFO] - Training Epoch: 1/2, step 3441/7134 completed (loss: 0.0856163501739502, acc: 0.9826589822769165)
[2024-12-17 04:01:13,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:13,678][root][INFO] - Training Epoch: 1/2, step 3442/7134 completed (loss: 0.048746295273303986, acc: 0.9817517995834351)
[2024-12-17 04:01:13,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:14,079][root][INFO] - Training Epoch: 1/2, step 3443/7134 completed (loss: 0.11553114652633667, acc: 0.9775280952453613)
[2024-12-17 04:01:14,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:14,488][root][INFO] - Training Epoch: 1/2, step 3444/7134 completed (loss: 0.09304027259349823, acc: 0.9794303774833679)
[2024-12-17 04:01:14,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:14,857][root][INFO] - Training Epoch: 1/2, step 3445/7134 completed (loss: 0.20329220592975616, acc: 0.9569892287254333)
[2024-12-17 04:01:14,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:15,295][root][INFO] - Training Epoch: 1/2, step 3446/7134 completed (loss: 0.14532539248466492, acc: 0.9615384340286255)
[2024-12-17 04:01:15,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:15,725][root][INFO] - Training Epoch: 1/2, step 3447/7134 completed (loss: 0.12463341653347015, acc: 0.9592834115028381)
[2024-12-17 04:01:15,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:16,152][root][INFO] - Training Epoch: 1/2, step 3448/7134 completed (loss: 0.0804552286863327, acc: 0.9804804921150208)
[2024-12-17 04:01:16,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:16,562][root][INFO] - Training Epoch: 1/2, step 3449/7134 completed (loss: 0.1214418113231659, acc: 0.9744898080825806)
[2024-12-17 04:01:16,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:16,981][root][INFO] - Training Epoch: 1/2, step 3450/7134 completed (loss: 0.10547568649053574, acc: 0.9721518754959106)
[2024-12-17 04:01:17,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:17,393][root][INFO] - Training Epoch: 1/2, step 3451/7134 completed (loss: 0.08724339306354523, acc: 0.9734982252120972)
[2024-12-17 04:01:17,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:17,808][root][INFO] - Training Epoch: 1/2, step 3452/7134 completed (loss: 0.10279233753681183, acc: 0.9761388301849365)
[2024-12-17 04:01:17,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:18,210][root][INFO] - Training Epoch: 1/2, step 3453/7134 completed (loss: 0.08216015249490738, acc: 0.9813242554664612)
[2024-12-17 04:01:18,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:18,653][root][INFO] - Training Epoch: 1/2, step 3454/7134 completed (loss: 0.08046547323465347, acc: 0.9774330258369446)
[2024-12-17 04:01:18,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:19,099][root][INFO] - Training Epoch: 1/2, step 3455/7134 completed (loss: 0.046712979674339294, acc: 0.9869565367698669)
[2024-12-17 04:01:19,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:19,543][root][INFO] - Training Epoch: 1/2, step 3456/7134 completed (loss: 0.06599072366952896, acc: 0.9847058653831482)
[2024-12-17 04:01:19,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:19,979][root][INFO] - Training Epoch: 1/2, step 3457/7134 completed (loss: 0.04935876652598381, acc: 0.988135576248169)
[2024-12-17 04:01:20,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:20,424][root][INFO] - Training Epoch: 1/2, step 3458/7134 completed (loss: 0.10260467976331711, acc: 0.9783491492271423)
[2024-12-17 04:01:20,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:20,831][root][INFO] - Training Epoch: 1/2, step 3459/7134 completed (loss: 0.07620785385370255, acc: 0.9802131056785583)
[2024-12-17 04:01:20,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:21,183][root][INFO] - Training Epoch: 1/2, step 3460/7134 completed (loss: 0.25999391078948975, acc: 0.9487179517745972)
[2024-12-17 04:01:21,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:21,563][root][INFO] - Training Epoch: 1/2, step 3461/7134 completed (loss: 0.28528013825416565, acc: 0.931034505367279)
[2024-12-17 04:01:21,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:21,964][root][INFO] - Training Epoch: 1/2, step 3462/7134 completed (loss: 0.17594176530838013, acc: 0.9591836929321289)
[2024-12-17 04:01:22,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:22,414][root][INFO] - Training Epoch: 1/2, step 3463/7134 completed (loss: 0.05972979962825775, acc: 0.9819004535675049)
[2024-12-17 04:01:22,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:22,854][root][INFO] - Training Epoch: 1/2, step 3464/7134 completed (loss: 0.10221204906702042, acc: 0.97050940990448)
[2024-12-17 04:01:22,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:23,245][root][INFO] - Training Epoch: 1/2, step 3465/7134 completed (loss: 0.09218987077474594, acc: 0.9837067127227783)
[2024-12-17 04:01:23,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:23,654][root][INFO] - Training Epoch: 1/2, step 3466/7134 completed (loss: 0.052257996052503586, acc: 0.9889065027236938)
[2024-12-17 04:01:23,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:24,066][root][INFO] - Training Epoch: 1/2, step 3467/7134 completed (loss: 0.09604319930076599, acc: 0.9766454100608826)
[2024-12-17 04:01:24,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:24,490][root][INFO] - Training Epoch: 1/2, step 3468/7134 completed (loss: 0.020136550068855286, acc: 0.9971056580543518)
[2024-12-17 04:01:24,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:24,908][root][INFO] - Training Epoch: 1/2, step 3469/7134 completed (loss: 0.06605871021747589, acc: 0.9830188751220703)
[2024-12-17 04:01:25,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:25,309][root][INFO] - Training Epoch: 1/2, step 3470/7134 completed (loss: 0.06319122761487961, acc: 0.9861751198768616)
[2024-12-17 04:01:25,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:25,715][root][INFO] - Training Epoch: 1/2, step 3471/7134 completed (loss: 0.09639684110879898, acc: 0.980663001537323)
[2024-12-17 04:01:25,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:26,150][root][INFO] - Training Epoch: 1/2, step 3472/7134 completed (loss: 0.05594519153237343, acc: 0.9821162223815918)
[2024-12-17 04:01:26,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:26,629][root][INFO] - Training Epoch: 1/2, step 3473/7134 completed (loss: 0.06491750478744507, acc: 0.9834437370300293)
[2024-12-17 04:01:26,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:27,032][root][INFO] - Training Epoch: 1/2, step 3474/7134 completed (loss: 0.07437115907669067, acc: 0.9840989112854004)
[2024-12-17 04:01:27,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:27,450][root][INFO] - Training Epoch: 1/2, step 3475/7134 completed (loss: 0.053474925458431244, acc: 0.9875665903091431)
[2024-12-17 04:01:27,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:27,868][root][INFO] - Training Epoch: 1/2, step 3476/7134 completed (loss: 0.10838232189416885, acc: 0.9760273694992065)
[2024-12-17 04:01:28,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:28,289][root][INFO] - Training Epoch: 1/2, step 3477/7134 completed (loss: 0.06795258074998856, acc: 0.9851973652839661)
[2024-12-17 04:01:28,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:28,703][root][INFO] - Training Epoch: 1/2, step 3478/7134 completed (loss: 0.043591540306806564, acc: 0.992514967918396)
[2024-12-17 04:01:28,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:29,112][root][INFO] - Training Epoch: 1/2, step 3479/7134 completed (loss: 0.040127113461494446, acc: 0.9878970980644226)
[2024-12-17 04:01:29,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:29,553][root][INFO] - Training Epoch: 1/2, step 3480/7134 completed (loss: 0.09097505360841751, acc: 0.9768392443656921)
[2024-12-17 04:01:29,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:29,965][root][INFO] - Training Epoch: 1/2, step 3481/7134 completed (loss: 0.03474586084485054, acc: 0.9946808218955994)
[2024-12-17 04:01:30,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:30,382][root][INFO] - Training Epoch: 1/2, step 3482/7134 completed (loss: 0.04069671034812927, acc: 0.9838129281997681)
[2024-12-17 04:01:30,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:30,816][root][INFO] - Training Epoch: 1/2, step 3483/7134 completed (loss: 0.025922736153006554, acc: 0.9892141819000244)
[2024-12-17 04:01:30,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:31,238][root][INFO] - Training Epoch: 1/2, step 3484/7134 completed (loss: 0.038432780653238297, acc: 0.9882006049156189)
[2024-12-17 04:01:31,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:31,646][root][INFO] - Training Epoch: 1/2, step 3485/7134 completed (loss: 0.042257197201251984, acc: 0.9870129823684692)
[2024-12-17 04:01:31,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:32,090][root][INFO] - Training Epoch: 1/2, step 3486/7134 completed (loss: 0.06010514497756958, acc: 0.980215847492218)
[2024-12-17 04:01:32,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:32,514][root][INFO] - Training Epoch: 1/2, step 3487/7134 completed (loss: 0.08169838041067123, acc: 0.9793814420700073)
[2024-12-17 04:01:32,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:32,939][root][INFO] - Training Epoch: 1/2, step 3488/7134 completed (loss: 0.050648801028728485, acc: 0.9901315569877625)
[2024-12-17 04:01:33,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:33,335][root][INFO] - Training Epoch: 1/2, step 3489/7134 completed (loss: 0.11920227855443954, acc: 0.9723756909370422)
[2024-12-17 04:01:33,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:33,782][root][INFO] - Training Epoch: 1/2, step 3490/7134 completed (loss: 0.08633451908826828, acc: 0.9822747707366943)
[2024-12-17 04:01:33,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:34,206][root][INFO] - Training Epoch: 1/2, step 3491/7134 completed (loss: 0.07861907035112381, acc: 0.980141818523407)
[2024-12-17 04:01:34,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:34,573][root][INFO] - Training Epoch: 1/2, step 3492/7134 completed (loss: 0.06356348842382431, acc: 0.987679660320282)
[2024-12-17 04:01:34,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:35,000][root][INFO] - Training Epoch: 1/2, step 3493/7134 completed (loss: 0.041919395327568054, acc: 0.9887955188751221)
[2024-12-17 04:01:35,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:35,395][root][INFO] - Training Epoch: 1/2, step 3494/7134 completed (loss: 0.05681079998612404, acc: 0.9879310131072998)
[2024-12-17 04:01:35,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:35,794][root][INFO] - Training Epoch: 1/2, step 3495/7134 completed (loss: 0.058342497795820236, acc: 0.9832134246826172)
[2024-12-17 04:01:35,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:36,179][root][INFO] - Training Epoch: 1/2, step 3496/7134 completed (loss: 0.06789770722389221, acc: 0.9684684872627258)
[2024-12-17 04:01:36,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:36,579][root][INFO] - Training Epoch: 1/2, step 3497/7134 completed (loss: 0.06646431982517242, acc: 0.9762611389160156)
[2024-12-17 04:01:36,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:36,997][root][INFO] - Training Epoch: 1/2, step 3498/7134 completed (loss: 0.0868534967303276, acc: 0.9710366129875183)
[2024-12-17 04:01:37,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:37,404][root][INFO] - Training Epoch: 1/2, step 3499/7134 completed (loss: 0.05223681405186653, acc: 0.990275502204895)
[2024-12-17 04:01:37,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:37,818][root][INFO] - Training Epoch: 1/2, step 3500/7134 completed (loss: 0.11420673877000809, acc: 0.9662261605262756)
[2024-12-17 04:01:37,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:38,234][root][INFO] - Training Epoch: 1/2, step 3501/7134 completed (loss: 0.1317165493965149, acc: 0.9657947421073914)
[2024-12-17 04:01:38,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:38,682][root][INFO] - Training Epoch: 1/2, step 3502/7134 completed (loss: 0.14634272456169128, acc: 0.9649122953414917)
[2024-12-17 04:01:38,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:39,101][root][INFO] - Training Epoch: 1/2, step 3503/7134 completed (loss: 0.12187430262565613, acc: 0.9688041806221008)
[2024-12-17 04:01:39,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:39,512][root][INFO] - Training Epoch: 1/2, step 3504/7134 completed (loss: 0.05331839248538017, acc: 0.9894419312477112)
[2024-12-17 04:01:39,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:39,932][root][INFO] - Training Epoch: 1/2, step 3505/7134 completed (loss: 0.05918195843696594, acc: 0.980322003364563)
[2024-12-17 04:01:40,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:40,332][root][INFO] - Training Epoch: 1/2, step 3506/7134 completed (loss: 0.0774005874991417, acc: 0.9810963869094849)
[2024-12-17 04:01:40,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:40,760][root][INFO] - Training Epoch: 1/2, step 3507/7134 completed (loss: 0.03040064498782158, acc: 0.9900662302970886)
[2024-12-17 04:01:40,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:41,186][root][INFO] - Training Epoch: 1/2, step 3508/7134 completed (loss: 0.06482252478599548, acc: 0.9853801131248474)
[2024-12-17 04:01:41,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:41,635][root][INFO] - Training Epoch: 1/2, step 3509/7134 completed (loss: 0.06729226559400558, acc: 0.9779005646705627)
[2024-12-17 04:01:41,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:42,056][root][INFO] - Training Epoch: 1/2, step 3510/7134 completed (loss: 0.07350751757621765, acc: 0.9828473329544067)
[2024-12-17 04:01:42,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:42,492][root][INFO] - Training Epoch: 1/2, step 3511/7134 completed (loss: 0.035272058099508286, acc: 0.9927927851676941)
[2024-12-17 04:01:42,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:42,929][root][INFO] - Training Epoch: 1/2, step 3512/7134 completed (loss: 0.07269900292158127, acc: 0.9841521382331848)
[2024-12-17 04:01:43,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:43,347][root][INFO] - Training Epoch: 1/2, step 3513/7134 completed (loss: 0.07498971372842789, acc: 0.9787610769271851)
[2024-12-17 04:01:43,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:43,794][root][INFO] - Training Epoch: 1/2, step 3514/7134 completed (loss: 0.06668338924646378, acc: 0.985023021697998)
[2024-12-17 04:01:43,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:44,211][root][INFO] - Training Epoch: 1/2, step 3515/7134 completed (loss: 0.04018719494342804, acc: 0.9916201233863831)
[2024-12-17 04:01:44,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:44,681][root][INFO] - Training Epoch: 1/2, step 3516/7134 completed (loss: 0.034694112837314606, acc: 0.9924160242080688)
[2024-12-17 04:01:44,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:45,133][root][INFO] - Training Epoch: 1/2, step 3517/7134 completed (loss: 0.0278629083186388, acc: 0.9928486347198486)
[2024-12-17 04:01:45,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:45,587][root][INFO] - Training Epoch: 1/2, step 3518/7134 completed (loss: 0.06535135954618454, acc: 0.9778188467025757)
[2024-12-17 04:01:45,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:46,040][root][INFO] - Training Epoch: 1/2, step 3519/7134 completed (loss: 0.053078871220350266, acc: 0.9865168333053589)
[2024-12-17 04:01:46,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:46,493][root][INFO] - Training Epoch: 1/2, step 3520/7134 completed (loss: 0.11587738990783691, acc: 0.9729411602020264)
[2024-12-17 04:01:46,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:46,941][root][INFO] - Training Epoch: 1/2, step 3521/7134 completed (loss: 0.03127918392419815, acc: 0.9928876161575317)
[2024-12-17 04:01:47,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:47,339][root][INFO] - Training Epoch: 1/2, step 3522/7134 completed (loss: 0.05664313584566116, acc: 0.9839572310447693)
[2024-12-17 04:01:47,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:47,780][root][INFO] - Training Epoch: 1/2, step 3523/7134 completed (loss: 0.01883983053267002, acc: 0.9953774809837341)
[2024-12-17 04:01:47,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:48,220][root][INFO] - Training Epoch: 1/2, step 3524/7134 completed (loss: 0.06816229969263077, acc: 0.9791666865348816)
[2024-12-17 04:01:48,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:48,667][root][INFO] - Training Epoch: 1/2, step 3525/7134 completed (loss: 0.05418079346418381, acc: 0.9818781018257141)
[2024-12-17 04:01:48,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:49,111][root][INFO] - Training Epoch: 1/2, step 3526/7134 completed (loss: 0.08461176604032516, acc: 0.9784537553787231)
[2024-12-17 04:01:49,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:49,570][root][INFO] - Training Epoch: 1/2, step 3527/7134 completed (loss: 0.07627198845148087, acc: 0.9795134663581848)
[2024-12-17 04:01:49,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:50,025][root][INFO] - Training Epoch: 1/2, step 3528/7134 completed (loss: 0.029975632205605507, acc: 0.9953863620758057)
[2024-12-17 04:01:50,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:50,456][root][INFO] - Training Epoch: 1/2, step 3529/7134 completed (loss: 0.06565725803375244, acc: 0.981176495552063)
[2024-12-17 04:01:50,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:50,927][root][INFO] - Training Epoch: 1/2, step 3530/7134 completed (loss: 0.05904184654355049, acc: 0.9850917458534241)
[2024-12-17 04:01:51,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:51,373][root][INFO] - Training Epoch: 1/2, step 3531/7134 completed (loss: 0.052027713507413864, acc: 0.9864457845687866)
[2024-12-17 04:01:51,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:51,816][root][INFO] - Training Epoch: 1/2, step 3532/7134 completed (loss: 0.042872872203588486, acc: 0.9865319728851318)
[2024-12-17 04:01:51,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:52,257][root][INFO] - Training Epoch: 1/2, step 3533/7134 completed (loss: 0.04713624715805054, acc: 0.9860302805900574)
[2024-12-17 04:01:52,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:52,694][root][INFO] - Training Epoch: 1/2, step 3534/7134 completed (loss: 0.07414431124925613, acc: 0.9805285334587097)
[2024-12-17 04:01:52,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:53,122][root][INFO] - Training Epoch: 1/2, step 3535/7134 completed (loss: 0.07165084779262543, acc: 0.9800307154655457)
[2024-12-17 04:01:53,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:53,550][root][INFO] - Training Epoch: 1/2, step 3536/7134 completed (loss: 0.07787349820137024, acc: 0.9795082211494446)
[2024-12-17 04:01:53,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:53,947][root][INFO] - Training Epoch: 1/2, step 3537/7134 completed (loss: 0.07409238815307617, acc: 0.9848993420600891)
[2024-12-17 04:01:54,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:54,341][root][INFO] - Training Epoch: 1/2, step 3538/7134 completed (loss: 0.06368561089038849, acc: 0.9885931611061096)
[2024-12-17 04:01:54,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:54,696][root][INFO] - Training Epoch: 1/2, step 3539/7134 completed (loss: 0.05502292513847351, acc: 0.987864077091217)
[2024-12-17 04:01:54,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:55,090][root][INFO] - Training Epoch: 1/2, step 3540/7134 completed (loss: 0.08850537240505219, acc: 0.9711684584617615)
[2024-12-17 04:01:55,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:55,511][root][INFO] - Training Epoch: 1/2, step 3541/7134 completed (loss: 0.08925653249025345, acc: 0.9750367403030396)
[2024-12-17 04:01:55,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:55,929][root][INFO] - Training Epoch: 1/2, step 3542/7134 completed (loss: 0.051938604563474655, acc: 0.9846153855323792)
[2024-12-17 04:01:56,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:56,338][root][INFO] - Training Epoch: 1/2, step 3543/7134 completed (loss: 0.09899381548166275, acc: 0.9700704216957092)
[2024-12-17 04:01:56,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:56,786][root][INFO] - Training Epoch: 1/2, step 3544/7134 completed (loss: 0.1117444559931755, acc: 0.9676923155784607)
[2024-12-17 04:01:56,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:57,233][root][INFO] - Training Epoch: 1/2, step 3545/7134 completed (loss: 0.051798440515995026, acc: 0.9860248565673828)
[2024-12-17 04:01:57,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:57,654][root][INFO] - Training Epoch: 1/2, step 3546/7134 completed (loss: 0.05664175748825073, acc: 0.9801980257034302)
[2024-12-17 04:01:57,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:58,101][root][INFO] - Training Epoch: 1/2, step 3547/7134 completed (loss: 0.08993258327245712, acc: 0.9762237668037415)
[2024-12-17 04:01:58,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:58,523][root][INFO] - Training Epoch: 1/2, step 3548/7134 completed (loss: 0.06780394911766052, acc: 0.980088472366333)
[2024-12-17 04:01:58,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:58,952][root][INFO] - Training Epoch: 1/2, step 3549/7134 completed (loss: 0.10638292133808136, acc: 0.9664903283119202)
[2024-12-17 04:01:59,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:59,354][root][INFO] - Training Epoch: 1/2, step 3550/7134 completed (loss: 0.07452644407749176, acc: 0.9737303256988525)
[2024-12-17 04:01:59,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:01:59,766][root][INFO] - Training Epoch: 1/2, step 3551/7134 completed (loss: 0.06250174343585968, acc: 0.9814814925193787)
[2024-12-17 04:01:59,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:00,206][root][INFO] - Training Epoch: 1/2, step 3552/7134 completed (loss: 0.1586565524339676, acc: 0.9588015079498291)
[2024-12-17 04:02:00,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:00,614][root][INFO] - Training Epoch: 1/2, step 3553/7134 completed (loss: 0.10231718420982361, acc: 0.9786184430122375)
[2024-12-17 04:02:00,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:01,033][root][INFO] - Training Epoch: 1/2, step 3554/7134 completed (loss: 0.07356225699186325, acc: 0.9789156913757324)
[2024-12-17 04:02:01,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:01,427][root][INFO] - Training Epoch: 1/2, step 3555/7134 completed (loss: 0.08275917172431946, acc: 0.9733123779296875)
[2024-12-17 04:02:01,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:01,834][root][INFO] - Training Epoch: 1/2, step 3556/7134 completed (loss: 0.11324062198400497, acc: 0.973128616809845)
[2024-12-17 04:02:01,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:02,285][root][INFO] - Training Epoch: 1/2, step 3557/7134 completed (loss: 0.05981278419494629, acc: 0.9854809641838074)
[2024-12-17 04:02:02,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:02,700][root][INFO] - Training Epoch: 1/2, step 3558/7134 completed (loss: 0.09715836495161057, acc: 0.969072163105011)
[2024-12-17 04:02:02,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:03,121][root][INFO] - Training Epoch: 1/2, step 3559/7134 completed (loss: 0.05758298188447952, acc: 0.9825581312179565)
[2024-12-17 04:02:03,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:03,548][root][INFO] - Training Epoch: 1/2, step 3560/7134 completed (loss: 0.05687609687447548, acc: 0.982191801071167)
[2024-12-17 04:02:03,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:03,975][root][INFO] - Training Epoch: 1/2, step 3561/7134 completed (loss: 0.060800760984420776, acc: 0.9789915680885315)
[2024-12-17 04:02:04,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:04,374][root][INFO] - Training Epoch: 1/2, step 3562/7134 completed (loss: 0.08071425557136536, acc: 0.9714285731315613)
[2024-12-17 04:02:04,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:04,796][root][INFO] - Training Epoch: 1/2, step 3563/7134 completed (loss: 0.0870477482676506, acc: 0.9777424335479736)
[2024-12-17 04:02:04,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:05,222][root][INFO] - Training Epoch: 1/2, step 3564/7134 completed (loss: 0.13760071992874146, acc: 0.9661654233932495)
[2024-12-17 04:02:05,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:05,633][root][INFO] - Training Epoch: 1/2, step 3565/7134 completed (loss: 0.1361648440361023, acc: 0.9624060392379761)
[2024-12-17 04:02:06,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:06,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:07,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:07,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:07,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:08,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:08,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:08,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:09,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:09,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:09,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:10,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:10,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:11,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:11,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:11,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:12,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:12,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:12,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:13,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:13,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:13,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:14,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:14,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:15,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:15,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:15,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:15,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:16,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:16,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:17,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:17,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:18,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:18,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:18,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:19,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:19,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:19,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:20,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:20,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:20,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:21,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:21,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:21,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:22,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:22,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:23,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:23,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:23,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:24,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:24,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:25,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:25,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:25,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:26,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:26,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:26,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:27,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:27,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:27,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:28,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:28,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:29,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:29,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:29,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:29,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:30,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:30,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:30,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:31,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:31,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:31,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:32,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:32,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:33,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:33,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:33,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:34,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:34,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:34,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:35,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:35,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:35,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:36,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:36,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:37,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:37,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:37,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:38,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:38,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:39,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:39,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:39,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:40,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:40,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:40,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:40,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:41,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:41,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:41,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:42,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:42,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:43,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:43,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:43,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:44,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:44,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:44,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:45,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:45,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:46,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:46,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:46,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:47,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:47,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:47,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:48,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:48,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:48,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:49,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:49,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:50,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:50,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:50,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:51,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:51,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:52,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:52,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:52,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:53,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:53,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:53,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:54,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:54,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:55,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:55,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:55,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:56,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:56,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:56,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:57,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:57,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:57,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:58,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:58,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:59,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:59,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:59,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:02:59,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:00,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:00,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:01,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:01,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:01,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:02,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:02,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:02,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:03,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:03,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:03,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:04,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:04,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:04,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:05,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:05,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:06,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:06,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:06,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:07,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:07,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:08,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:08,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:08,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:09,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:09,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:10,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:10,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:10,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:11,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:11,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:11,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:12,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:12,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:12,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:13,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:13,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:13,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:14,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:14,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:14,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:15,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:15,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:16,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:16,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:16,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:17,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:17,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:17,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:18,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:18,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:18,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:19,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:19,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:20,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:20,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:20,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:21,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:21,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:21,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:22,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:22,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:23,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:23,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:23,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:24,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:24,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:24,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:24,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:25,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:25,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:25,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:26,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:26,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:27,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:27,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:27,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:28,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:28,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:28,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:29,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:29,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:29,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:30,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:30,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:30,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:31,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:31,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:31,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:32,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:32,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:32,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:33,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:33,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:33,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:34,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:34,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:35,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:35,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:36,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:36,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:36,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:37,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:37,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:37,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:38,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:38,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:38,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:39,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:39,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:40,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:40,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:41,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:41,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:41,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:42,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:42,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:43,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:43,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:43,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:44,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:44,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:44,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:45,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:45,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:46,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:46,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:46,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:47,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:47,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:48,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:48,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:48,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:49,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:49,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:50,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:50,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:50,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:51,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:51,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:52,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:52,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:53,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:53,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:53,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:54,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:54,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:55,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:55,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:55,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:56,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:56,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:57,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:57,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:57,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:58,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:58,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:58,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:59,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:59,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:03:59,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:00,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:00,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:00,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:01,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:01,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:02,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:02,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:02,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:03,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:03,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:04,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:04,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:04,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:05,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:05,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:06,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:06,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:06,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:07,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:07,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:08,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:08,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:09,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:09,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:09,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:10,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:10,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:10,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:11,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:11,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:11,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:12,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:12,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:13,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:13,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:14,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:14,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:15,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:15,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:15,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:16,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:16,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:16,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:17,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:17,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:17,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:18,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:18,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:18,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:19,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:19,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:20,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:20,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:21,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:21,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:22,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:22,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:23,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:23,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:23,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:24,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:24,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:24,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:25,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:25,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:25,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:25,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:26,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:26,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:26,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:27,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:27,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:27,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:28,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:28,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:28,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:29,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:29,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:29,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:29,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:30,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:30,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:30,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:31,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:31,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:31,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:32,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:32,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:32,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:33,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:33,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:34,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:34,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:34,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:35,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:35,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:35,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:36,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:36,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:36,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:37,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:37,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:37,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:38,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:38,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:38,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:39,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:39,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:39,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:40,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:40,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:40,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:41,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:41,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:41,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:42,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:42,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:42,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:43,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:43,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:43,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:44,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:44,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:45,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:45,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:45,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:46,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:46,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:46,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:47,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:47,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:47,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:48,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:48,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:49,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:49,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:49,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:50,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:50,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:51,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:51,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:51,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:51,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:52,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:52,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:52,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:53,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:53,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:54,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:54,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:55,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:55,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:55,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:56,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:56,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:56,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:57,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:57,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:57,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:58,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:58,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:59,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:59,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:04:59,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:00,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:00,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:00,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:01,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:01,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:01,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:02,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:02,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:03,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:03,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:03,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:04,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:04,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:04,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:05,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:05,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:06,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:06,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:06,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:07,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:07,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:07,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:08,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:08,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:09,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:09,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:09,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:10,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:10,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:11,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:11,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:11,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:12,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:12,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:13,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:13,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:13,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:14,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:14,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:15,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:15,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:15,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:16,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:16,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:17,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:17,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:17,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:18,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:18,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:18,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:19,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:19,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:19,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:20,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:20,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:20,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:21,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:21,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:21,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:22,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:22,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:23,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:23,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:23,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:24,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:24,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:24,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:25,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:25,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:26,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:26,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:26,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:27,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:27,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:27,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:28,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:28,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:29,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:29,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:29,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:30,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:30,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:31,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:31,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:31,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:32,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:32,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:32,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:33,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:33,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:34,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:34,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:34,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:35,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:35,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:35,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:36,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:36,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:36,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:37,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:37,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:38,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:38,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:38,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:39,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:39,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:40,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:40,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:41,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:41,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:41,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:42,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:42,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:43,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:43,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:43,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:44,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:44,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:45,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:45,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:45,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:45,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:46,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:46,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:47,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:47,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:47,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:48,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:48,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:48,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:49,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:49,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:49,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:50,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:50,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:51,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:51,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:52,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:52,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:52,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:53,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:53,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:53,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:54,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:54,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:54,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:55,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:55,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:56,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:56,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:56,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:57,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:58,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:58,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:59,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:05:59,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:00,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:00,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:00,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:01,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:01,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:02,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:02,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:03,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:03,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:03,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:04,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:04,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:05,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:05,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:05,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:06,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:06,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:07,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:07,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:07,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:08,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:08,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:08,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:09,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:09,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:10,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:10,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:10,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:11,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:11,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:11,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:12,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:12,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:12,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:13,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:13,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:13,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:13,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:14,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:14,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:15,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:15,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:15,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:16,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:16,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:17,707][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.1045, device='cuda:0') eval_epoch_loss=tensor(0.0994, device='cuda:0') eval_epoch_acc=tensor(0.9732, device='cuda:0')
[2024-12-17 04:06:17,709][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-17 04:06:17,709][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 04:06:18,033][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_1_step_3566_loss_0.099400095641613/model.pt
[2024-12-17 04:06:18,045][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-12-17 04:06:18,047][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 0.099400095641613
[2024-12-17 04:06:18,048][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.9732137322425842
[2024-12-17 04:06:18,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:18,517][root][INFO] - Training Epoch: 1/2, step 3566/7134 completed (loss: 0.07892610132694244, acc: 0.980079710483551)
[2024-12-17 04:06:18,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:18,928][root][INFO] - Training Epoch: 1/2, step 3567/7134 completed (loss: 0.154804065823555, acc: 0.9689521193504333)
[2024-12-17 04:06:19,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:19,345][root][INFO] - Training Epoch: 1/2, step 3568/7134 completed (loss: 0.13456247746944427, acc: 0.9656301140785217)
[2024-12-17 04:06:19,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:19,732][root][INFO] - Training Epoch: 1/2, step 3569/7134 completed (loss: 0.08907964080572128, acc: 0.9731183052062988)
[2024-12-17 04:06:19,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:20,159][root][INFO] - Training Epoch: 1/2, step 3570/7134 completed (loss: 0.10211549699306488, acc: 0.9702479243278503)
[2024-12-17 04:06:20,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:20,573][root][INFO] - Training Epoch: 1/2, step 3571/7134 completed (loss: 0.12175191193819046, acc: 0.9734748005867004)
[2024-12-17 04:06:20,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:21,046][root][INFO] - Training Epoch: 1/2, step 3572/7134 completed (loss: 0.05797532573342323, acc: 0.9881423115730286)
[2024-12-17 04:06:21,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:21,494][root][INFO] - Training Epoch: 1/2, step 3573/7134 completed (loss: 0.10081012547016144, acc: 0.9733333587646484)
[2024-12-17 04:06:21,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:21,894][root][INFO] - Training Epoch: 1/2, step 3574/7134 completed (loss: 0.1426888257265091, acc: 0.9655172228813171)
[2024-12-17 04:06:22,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:22,309][root][INFO] - Training Epoch: 1/2, step 3575/7134 completed (loss: 0.17393533885478973, acc: 0.9571183323860168)
[2024-12-17 04:06:22,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:22,737][root][INFO] - Training Epoch: 1/2, step 3576/7134 completed (loss: 0.1483588069677353, acc: 0.9613259434700012)
[2024-12-17 04:06:22,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:23,229][root][INFO] - Training Epoch: 1/2, step 3577/7134 completed (loss: 0.1195591613650322, acc: 0.9696586728096008)
[2024-12-17 04:06:23,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:23,665][root][INFO] - Training Epoch: 1/2, step 3578/7134 completed (loss: 0.07746753841638565, acc: 0.983988344669342)
[2024-12-17 04:06:23,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:24,088][root][INFO] - Training Epoch: 1/2, step 3579/7134 completed (loss: 0.07531537115573883, acc: 0.984000027179718)
[2024-12-17 04:06:24,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:24,538][root][INFO] - Training Epoch: 1/2, step 3580/7134 completed (loss: 0.147192120552063, acc: 0.9559054970741272)
[2024-12-17 04:06:24,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:24,966][root][INFO] - Training Epoch: 1/2, step 3581/7134 completed (loss: 0.10827630758285522, acc: 0.9661266803741455)
[2024-12-17 04:06:25,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:25,374][root][INFO] - Training Epoch: 1/2, step 3582/7134 completed (loss: 0.10119185596704483, acc: 0.971563994884491)
[2024-12-17 04:06:25,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:25,811][root][INFO] - Training Epoch: 1/2, step 3583/7134 completed (loss: 0.1268669068813324, acc: 0.9635258316993713)
[2024-12-17 04:06:25,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:26,194][root][INFO] - Training Epoch: 1/2, step 3584/7134 completed (loss: 0.11041326075792313, acc: 0.9788359999656677)
[2024-12-17 04:06:26,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:26,618][root][INFO] - Training Epoch: 1/2, step 3585/7134 completed (loss: 0.15050286054611206, acc: 0.9635416865348816)
[2024-12-17 04:06:26,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:27,029][root][INFO] - Training Epoch: 1/2, step 3586/7134 completed (loss: 0.11274829506874084, acc: 0.9775280952453613)
[2024-12-17 04:06:27,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:27,439][root][INFO] - Training Epoch: 1/2, step 3587/7134 completed (loss: 0.07542354613542557, acc: 0.9813874959945679)
[2024-12-17 04:06:27,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:27,889][root][INFO] - Training Epoch: 1/2, step 3588/7134 completed (loss: 0.1502615064382553, acc: 0.9689348936080933)
[2024-12-17 04:06:27,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:28,324][root][INFO] - Training Epoch: 1/2, step 3589/7134 completed (loss: 0.11206880211830139, acc: 0.97579425573349)
[2024-12-17 04:06:28,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:28,784][root][INFO] - Training Epoch: 1/2, step 3590/7134 completed (loss: 0.0662052184343338, acc: 0.9747191071510315)
[2024-12-17 04:06:28,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:29,174][root][INFO] - Training Epoch: 1/2, step 3591/7134 completed (loss: 0.07352490723133087, acc: 0.9759759902954102)
[2024-12-17 04:06:29,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:29,588][root][INFO] - Training Epoch: 1/2, step 3592/7134 completed (loss: 0.05247613042593002, acc: 0.9834710955619812)
[2024-12-17 04:06:29,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:30,023][root][INFO] - Training Epoch: 1/2, step 3593/7134 completed (loss: 0.10609911382198334, acc: 0.9684763550758362)
[2024-12-17 04:06:30,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:30,436][root][INFO] - Training Epoch: 1/2, step 3594/7134 completed (loss: 0.05413356423377991, acc: 0.9837662577629089)
[2024-12-17 04:06:30,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:30,868][root][INFO] - Training Epoch: 1/2, step 3595/7134 completed (loss: 0.07258496433496475, acc: 0.9754977226257324)
[2024-12-17 04:06:30,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:31,291][root][INFO] - Training Epoch: 1/2, step 3596/7134 completed (loss: 0.08019186556339264, acc: 0.9766162037849426)
[2024-12-17 04:06:31,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:31,743][root][INFO] - Training Epoch: 1/2, step 3597/7134 completed (loss: 0.06937529146671295, acc: 0.9827337861061096)
[2024-12-17 04:06:31,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:32,227][root][INFO] - Training Epoch: 1/2, step 3598/7134 completed (loss: 0.09348839521408081, acc: 0.9748283624649048)
[2024-12-17 04:06:32,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:32,690][root][INFO] - Training Epoch: 1/2, step 3599/7134 completed (loss: 0.09152450412511826, acc: 0.9798234701156616)
[2024-12-17 04:06:32,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:33,162][root][INFO] - Training Epoch: 1/2, step 3600/7134 completed (loss: 0.0768015906214714, acc: 0.9764309525489807)
[2024-12-17 04:06:33,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:33,616][root][INFO] - Training Epoch: 1/2, step 3601/7134 completed (loss: 0.19900338351726532, acc: 0.9586206674575806)
[2024-12-17 04:06:33,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:34,070][root][INFO] - Training Epoch: 1/2, step 3602/7134 completed (loss: 0.1574050784111023, acc: 0.9579929709434509)
[2024-12-17 04:06:34,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:34,479][root][INFO] - Training Epoch: 1/2, step 3603/7134 completed (loss: 0.08155904710292816, acc: 0.973437488079071)
[2024-12-17 04:06:34,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:34,912][root][INFO] - Training Epoch: 1/2, step 3604/7134 completed (loss: 0.09273567795753479, acc: 0.9737336039543152)
[2024-12-17 04:06:35,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:35,374][root][INFO] - Training Epoch: 1/2, step 3605/7134 completed (loss: 0.08829399198293686, acc: 0.97826087474823)
[2024-12-17 04:06:35,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:35,825][root][INFO] - Training Epoch: 1/2, step 3606/7134 completed (loss: 0.12534694373607635, acc: 0.9698046445846558)
[2024-12-17 04:06:35,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:36,275][root][INFO] - Training Epoch: 1/2, step 3607/7134 completed (loss: 0.0879259780049324, acc: 0.9731543660163879)
[2024-12-17 04:06:36,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:36,734][root][INFO] - Training Epoch: 1/2, step 3608/7134 completed (loss: 0.12678846716880798, acc: 0.971238911151886)
[2024-12-17 04:06:36,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:37,197][root][INFO] - Training Epoch: 1/2, step 3609/7134 completed (loss: 0.08529731631278992, acc: 0.9809644818305969)
[2024-12-17 04:06:37,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:37,644][root][INFO] - Training Epoch: 1/2, step 3610/7134 completed (loss: 0.16838312149047852, acc: 0.9493506550788879)
[2024-12-17 04:06:37,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:38,085][root][INFO] - Training Epoch: 1/2, step 3611/7134 completed (loss: 0.11054851859807968, acc: 0.9677419066429138)
[2024-12-17 04:06:38,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:38,554][root][INFO] - Training Epoch: 1/2, step 3612/7134 completed (loss: 0.1565307080745697, acc: 0.9595435857772827)
[2024-12-17 04:06:38,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:39,016][root][INFO] - Training Epoch: 1/2, step 3613/7134 completed (loss: 0.11465279012918472, acc: 0.9656488299369812)
[2024-12-17 04:06:39,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:39,435][root][INFO] - Training Epoch: 1/2, step 3614/7134 completed (loss: 0.10175051540136337, acc: 0.9705488681793213)
[2024-12-17 04:06:39,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:39,871][root][INFO] - Training Epoch: 1/2, step 3615/7134 completed (loss: 0.06566481292247772, acc: 0.9831804037094116)
[2024-12-17 04:06:39,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:40,306][root][INFO] - Training Epoch: 1/2, step 3616/7134 completed (loss: 0.09810535609722137, acc: 0.9686028361320496)
[2024-12-17 04:06:40,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:40,769][root][INFO] - Training Epoch: 1/2, step 3617/7134 completed (loss: 0.08970154076814651, acc: 0.9777227640151978)
[2024-12-17 04:06:40,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:41,175][root][INFO] - Training Epoch: 1/2, step 3618/7134 completed (loss: 0.16982680559158325, acc: 0.9575163125991821)
[2024-12-17 04:06:41,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:41,623][root][INFO] - Training Epoch: 1/2, step 3619/7134 completed (loss: 0.1566748470067978, acc: 0.9607142806053162)
[2024-12-17 04:06:41,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:42,089][root][INFO] - Training Epoch: 1/2, step 3620/7134 completed (loss: 0.10226428508758545, acc: 0.9718706011772156)
[2024-12-17 04:06:42,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:42,501][root][INFO] - Training Epoch: 1/2, step 3621/7134 completed (loss: 0.06629886478185654, acc: 0.9778085947036743)
[2024-12-17 04:06:42,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:42,951][root][INFO] - Training Epoch: 1/2, step 3622/7134 completed (loss: 0.09554282575845718, acc: 0.9759759902954102)
[2024-12-17 04:06:43,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:43,308][root][INFO] - Training Epoch: 1/2, step 3623/7134 completed (loss: 0.056519217789173126, acc: 0.9925650358200073)
[2024-12-17 04:06:43,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:43,730][root][INFO] - Training Epoch: 1/2, step 3624/7134 completed (loss: 0.08550821989774704, acc: 0.9783333539962769)
[2024-12-17 04:06:43,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:44,146][root][INFO] - Training Epoch: 1/2, step 3625/7134 completed (loss: 0.08724961429834366, acc: 0.9738430380821228)
[2024-12-17 04:06:44,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:44,589][root][INFO] - Training Epoch: 1/2, step 3626/7134 completed (loss: 0.2759074568748474, acc: 0.9333333373069763)
[2024-12-17 04:06:44,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:45,008][root][INFO] - Training Epoch: 1/2, step 3627/7134 completed (loss: 0.12155167013406754, acc: 0.9763593673706055)
[2024-12-17 04:06:45,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:45,419][root][INFO] - Training Epoch: 1/2, step 3628/7134 completed (loss: 0.2124129682779312, acc: 0.9488636255264282)
[2024-12-17 04:06:45,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:45,804][root][INFO] - Training Epoch: 1/2, step 3629/7134 completed (loss: 0.2002936452627182, acc: 0.9491869807243347)
[2024-12-17 04:06:45,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:46,189][root][INFO] - Training Epoch: 1/2, step 3630/7134 completed (loss: 0.17146167159080505, acc: 0.961240291595459)
[2024-12-17 04:06:46,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:46,622][root][INFO] - Training Epoch: 1/2, step 3631/7134 completed (loss: 0.16755877435207367, acc: 0.9524590373039246)
[2024-12-17 04:06:46,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:47,054][root][INFO] - Training Epoch: 1/2, step 3632/7134 completed (loss: 0.1344776600599289, acc: 0.9597585797309875)
[2024-12-17 04:06:47,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:47,460][root][INFO] - Training Epoch: 1/2, step 3633/7134 completed (loss: 0.14358268678188324, acc: 0.9626972675323486)
[2024-12-17 04:06:47,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:47,858][root][INFO] - Training Epoch: 1/2, step 3634/7134 completed (loss: 0.14773112535476685, acc: 0.9716598987579346)
[2024-12-17 04:06:47,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:48,273][root][INFO] - Training Epoch: 1/2, step 3635/7134 completed (loss: 0.09936101734638214, acc: 0.9695340394973755)
[2024-12-17 04:06:48,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:48,678][root][INFO] - Training Epoch: 1/2, step 3636/7134 completed (loss: 0.057398270815610886, acc: 0.9862204790115356)
[2024-12-17 04:06:48,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:49,094][root][INFO] - Training Epoch: 1/2, step 3637/7134 completed (loss: 0.07326842844486237, acc: 0.9879275560379028)
[2024-12-17 04:06:49,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:49,483][root][INFO] - Training Epoch: 1/2, step 3638/7134 completed (loss: 0.08346734195947647, acc: 0.9788235425949097)
[2024-12-17 04:06:49,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:49,894][root][INFO] - Training Epoch: 1/2, step 3639/7134 completed (loss: 0.055842600762844086, acc: 0.9842342138290405)
[2024-12-17 04:06:49,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:50,320][root][INFO] - Training Epoch: 1/2, step 3640/7134 completed (loss: 0.0961376279592514, acc: 0.9732824563980103)
[2024-12-17 04:06:50,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:50,687][root][INFO] - Training Epoch: 1/2, step 3641/7134 completed (loss: 0.07469432801008224, acc: 0.9824903011322021)
[2024-12-17 04:06:50,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:51,105][root][INFO] - Training Epoch: 1/2, step 3642/7134 completed (loss: 0.05195758491754532, acc: 0.9814528822898865)
[2024-12-17 04:06:51,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:51,512][root][INFO] - Training Epoch: 1/2, step 3643/7134 completed (loss: 0.0796888917684555, acc: 0.9793814420700073)
[2024-12-17 04:06:51,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:51,920][root][INFO] - Training Epoch: 1/2, step 3644/7134 completed (loss: 0.0808798223733902, acc: 0.9821138381958008)
[2024-12-17 04:06:52,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:52,339][root][INFO] - Training Epoch: 1/2, step 3645/7134 completed (loss: 0.10647563636302948, acc: 0.9788732528686523)
[2024-12-17 04:06:52,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:52,734][root][INFO] - Training Epoch: 1/2, step 3646/7134 completed (loss: 0.1321672946214676, acc: 0.9635416865348816)
[2024-12-17 04:06:52,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:53,127][root][INFO] - Training Epoch: 1/2, step 3647/7134 completed (loss: 0.02946830913424492, acc: 0.9922480583190918)
[2024-12-17 04:06:53,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:53,578][root][INFO] - Training Epoch: 1/2, step 3648/7134 completed (loss: 0.14441680908203125, acc: 0.9629629850387573)
[2024-12-17 04:06:53,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:54,009][root][INFO] - Training Epoch: 1/2, step 3649/7134 completed (loss: 0.16200749576091766, acc: 0.9565826058387756)
[2024-12-17 04:06:54,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:54,453][root][INFO] - Training Epoch: 1/2, step 3650/7134 completed (loss: 0.12474159896373749, acc: 0.9594771265983582)
[2024-12-17 04:06:54,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:54,898][root][INFO] - Training Epoch: 1/2, step 3651/7134 completed (loss: 0.0902392640709877, acc: 0.974530816078186)
[2024-12-17 04:06:54,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:55,311][root][INFO] - Training Epoch: 1/2, step 3652/7134 completed (loss: 0.12226426601409912, acc: 0.965309202671051)
[2024-12-17 04:06:55,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:55,732][root][INFO] - Training Epoch: 1/2, step 3653/7134 completed (loss: 0.13938818871974945, acc: 0.9668174982070923)
[2024-12-17 04:06:55,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:56,158][root][INFO] - Training Epoch: 1/2, step 3654/7134 completed (loss: 0.05574662983417511, acc: 0.9861830472946167)
[2024-12-17 04:06:56,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:56,587][root][INFO] - Training Epoch: 1/2, step 3655/7134 completed (loss: 0.08952268958091736, acc: 0.9793956279754639)
[2024-12-17 04:06:56,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:56,951][root][INFO] - Training Epoch: 1/2, step 3656/7134 completed (loss: 0.1287653148174286, acc: 0.9672726988792419)
[2024-12-17 04:06:57,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:57,367][root][INFO] - Training Epoch: 1/2, step 3657/7134 completed (loss: 0.036294497549533844, acc: 0.9855769276618958)
[2024-12-17 04:06:57,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:57,787][root][INFO] - Training Epoch: 1/2, step 3658/7134 completed (loss: 0.06160394474864006, acc: 0.985981285572052)
[2024-12-17 04:06:57,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:58,203][root][INFO] - Training Epoch: 1/2, step 3659/7134 completed (loss: 0.08264689147472382, acc: 0.9760836958885193)
[2024-12-17 04:06:58,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:58,578][root][INFO] - Training Epoch: 1/2, step 3660/7134 completed (loss: 0.09426984935998917, acc: 0.9704918265342712)
[2024-12-17 04:06:58,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:58,977][root][INFO] - Training Epoch: 1/2, step 3661/7134 completed (loss: 0.07859160751104355, acc: 0.9785714149475098)
[2024-12-17 04:06:59,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:59,425][root][INFO] - Training Epoch: 1/2, step 3662/7134 completed (loss: 0.12081179022789001, acc: 0.9695122241973877)
[2024-12-17 04:06:59,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:06:59,835][root][INFO] - Training Epoch: 1/2, step 3663/7134 completed (loss: 0.08440853655338287, acc: 0.9725274443626404)
[2024-12-17 04:06:59,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:00,265][root][INFO] - Training Epoch: 1/2, step 3664/7134 completed (loss: 0.08872587978839874, acc: 0.9817629456520081)
[2024-12-17 04:07:00,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:00,681][root][INFO] - Training Epoch: 1/2, step 3665/7134 completed (loss: 0.06066451221704483, acc: 0.9819375872612)
[2024-12-17 04:07:00,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:01,085][root][INFO] - Training Epoch: 1/2, step 3666/7134 completed (loss: 0.09387990832328796, acc: 0.9726277589797974)
[2024-12-17 04:07:01,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:01,467][root][INFO] - Training Epoch: 1/2, step 3667/7134 completed (loss: 0.2451278567314148, acc: 0.9430524110794067)
[2024-12-17 04:07:01,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:01,866][root][INFO] - Training Epoch: 1/2, step 3668/7134 completed (loss: 0.06860223412513733, acc: 0.9895287752151489)
[2024-12-17 04:07:01,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:02,277][root][INFO] - Training Epoch: 1/2, step 3669/7134 completed (loss: 0.03710270673036575, acc: 0.9905481934547424)
[2024-12-17 04:07:02,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:02,694][root][INFO] - Training Epoch: 1/2, step 3670/7134 completed (loss: 0.04484608396887779, acc: 0.9876373410224915)
[2024-12-17 04:07:02,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:03,085][root][INFO] - Training Epoch: 1/2, step 3671/7134 completed (loss: 0.06882798671722412, acc: 0.9855491518974304)
[2024-12-17 04:07:03,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:03,535][root][INFO] - Training Epoch: 1/2, step 3672/7134 completed (loss: 0.05062674358487129, acc: 0.9848484992980957)
[2024-12-17 04:07:03,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:03,936][root][INFO] - Training Epoch: 1/2, step 3673/7134 completed (loss: 0.09647931903600693, acc: 0.974916398525238)
[2024-12-17 04:07:04,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:04,359][root][INFO] - Training Epoch: 1/2, step 3674/7134 completed (loss: 0.04701300337910652, acc: 0.9905511736869812)
[2024-12-17 04:07:04,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:04,790][root][INFO] - Training Epoch: 1/2, step 3675/7134 completed (loss: 0.04201294854283333, acc: 0.9872449040412903)
[2024-12-17 04:07:04,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:05,216][root][INFO] - Training Epoch: 1/2, step 3676/7134 completed (loss: 0.05202107131481171, acc: 0.9810495376586914)
[2024-12-17 04:07:05,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:05,657][root][INFO] - Training Epoch: 1/2, step 3677/7134 completed (loss: 0.06827720999717712, acc: 0.9794520735740662)
[2024-12-17 04:07:05,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:06,084][root][INFO] - Training Epoch: 1/2, step 3678/7134 completed (loss: 0.07974662631750107, acc: 0.9784075617790222)
[2024-12-17 04:07:06,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:06,537][root][INFO] - Training Epoch: 1/2, step 3679/7134 completed (loss: 0.05524685978889465, acc: 0.9818181991577148)
[2024-12-17 04:07:06,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:06,975][root][INFO] - Training Epoch: 1/2, step 3680/7134 completed (loss: 0.08040331304073334, acc: 0.9772727489471436)
[2024-12-17 04:07:07,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:07,382][root][INFO] - Training Epoch: 1/2, step 3681/7134 completed (loss: 0.056694887578487396, acc: 0.9846368432044983)
[2024-12-17 04:07:07,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:07,804][root][INFO] - Training Epoch: 1/2, step 3682/7134 completed (loss: 0.03903599828481674, acc: 0.9894598126411438)
[2024-12-17 04:07:07,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:08,251][root][INFO] - Training Epoch: 1/2, step 3683/7134 completed (loss: 0.048362500965595245, acc: 0.9905511736869812)
[2024-12-17 04:07:08,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:08,655][root][INFO] - Training Epoch: 1/2, step 3684/7134 completed (loss: 0.0656093880534172, acc: 0.9797979593276978)
[2024-12-17 04:07:08,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:09,049][root][INFO] - Training Epoch: 1/2, step 3685/7134 completed (loss: 0.058869216591119766, acc: 0.9865125417709351)
[2024-12-17 04:07:09,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:09,456][root][INFO] - Training Epoch: 1/2, step 3686/7134 completed (loss: 0.06381353735923767, acc: 0.9850075244903564)
[2024-12-17 04:07:09,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:09,869][root][INFO] - Training Epoch: 1/2, step 3687/7134 completed (loss: 0.05254112929105759, acc: 0.9846153855323792)
[2024-12-17 04:07:09,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:10,271][root][INFO] - Training Epoch: 1/2, step 3688/7134 completed (loss: 0.03097398392856121, acc: 0.9898580312728882)
[2024-12-17 04:07:10,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:10,686][root][INFO] - Training Epoch: 1/2, step 3689/7134 completed (loss: 0.05653301626443863, acc: 0.983660101890564)
[2024-12-17 04:07:10,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:11,137][root][INFO] - Training Epoch: 1/2, step 3690/7134 completed (loss: 0.050039634108543396, acc: 0.9856938719749451)
[2024-12-17 04:07:11,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:11,534][root][INFO] - Training Epoch: 1/2, step 3691/7134 completed (loss: 0.07279249280691147, acc: 0.977667510509491)
[2024-12-17 04:07:11,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:11,954][root][INFO] - Training Epoch: 1/2, step 3692/7134 completed (loss: 0.09512019902467728, acc: 0.9771689772605896)
[2024-12-17 04:07:12,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:12,374][root][INFO] - Training Epoch: 1/2, step 3693/7134 completed (loss: 0.0760180652141571, acc: 0.9731861352920532)
[2024-12-17 04:07:12,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:12,803][root][INFO] - Training Epoch: 1/2, step 3694/7134 completed (loss: 0.0509016215801239, acc: 0.9871976971626282)
[2024-12-17 04:07:12,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:13,235][root][INFO] - Training Epoch: 1/2, step 3695/7134 completed (loss: 0.046977002173662186, acc: 0.9844192862510681)
[2024-12-17 04:07:13,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:13,685][root][INFO] - Training Epoch: 1/2, step 3696/7134 completed (loss: 0.05421784520149231, acc: 0.9832904934883118)
[2024-12-17 04:07:13,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:14,092][root][INFO] - Training Epoch: 1/2, step 3697/7134 completed (loss: 0.04170868918299675, acc: 0.9854227304458618)
[2024-12-17 04:07:14,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:14,513][root][INFO] - Training Epoch: 1/2, step 3698/7134 completed (loss: 0.06436202675104141, acc: 0.9823434948921204)
[2024-12-17 04:07:14,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:14,915][root][INFO] - Training Epoch: 1/2, step 3699/7134 completed (loss: 0.017253180965781212, acc: 0.9949324131011963)
[2024-12-17 04:07:15,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:15,344][root][INFO] - Training Epoch: 1/2, step 3700/7134 completed (loss: 0.04410234093666077, acc: 0.9897959232330322)
[2024-12-17 04:07:15,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:15,789][root][INFO] - Training Epoch: 1/2, step 3701/7134 completed (loss: 0.056550025939941406, acc: 0.9867549538612366)
[2024-12-17 04:07:15,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:16,196][root][INFO] - Training Epoch: 1/2, step 3702/7134 completed (loss: 0.07772783190011978, acc: 0.9793388247489929)
[2024-12-17 04:07:16,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:16,640][root][INFO] - Training Epoch: 1/2, step 3703/7134 completed (loss: 0.05015384778380394, acc: 0.9897828698158264)
[2024-12-17 04:07:16,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:17,043][root][INFO] - Training Epoch: 1/2, step 3704/7134 completed (loss: 0.02839444950222969, acc: 0.9895397424697876)
[2024-12-17 04:07:17,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:17,460][root][INFO] - Training Epoch: 1/2, step 3705/7134 completed (loss: 0.07979085296392441, acc: 0.9745222926139832)
[2024-12-17 04:07:17,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:17,872][root][INFO] - Training Epoch: 1/2, step 3706/7134 completed (loss: 0.15852239727973938, acc: 0.9643296599388123)
[2024-12-17 04:07:17,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:18,299][root][INFO] - Training Epoch: 1/2, step 3707/7134 completed (loss: 0.06311040371656418, acc: 0.9845722317695618)
[2024-12-17 04:07:18,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:18,748][root][INFO] - Training Epoch: 1/2, step 3708/7134 completed (loss: 0.10241803526878357, acc: 0.9726190567016602)
[2024-12-17 04:07:18,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:19,225][root][INFO] - Training Epoch: 1/2, step 3709/7134 completed (loss: 0.05667201057076454, acc: 0.9858012199401855)
[2024-12-17 04:07:19,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:19,699][root][INFO] - Training Epoch: 1/2, step 3710/7134 completed (loss: 0.08149818331003189, acc: 0.9764344096183777)
[2024-12-17 04:07:19,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:20,134][root][INFO] - Training Epoch: 1/2, step 3711/7134 completed (loss: 0.08490858972072601, acc: 0.9677419066429138)
[2024-12-17 04:07:20,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:20,596][root][INFO] - Training Epoch: 1/2, step 3712/7134 completed (loss: 0.07697857916355133, acc: 0.9844683408737183)
[2024-12-17 04:07:20,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:21,028][root][INFO] - Training Epoch: 1/2, step 3713/7134 completed (loss: 0.07936155796051025, acc: 0.9786535501480103)
[2024-12-17 04:07:21,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:21,460][root][INFO] - Training Epoch: 1/2, step 3714/7134 completed (loss: 0.06114300712943077, acc: 0.9845303893089294)
[2024-12-17 04:07:21,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:21,905][root][INFO] - Training Epoch: 1/2, step 3715/7134 completed (loss: 0.0706879049539566, acc: 0.9818621277809143)
[2024-12-17 04:07:22,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:22,386][root][INFO] - Training Epoch: 1/2, step 3716/7134 completed (loss: 0.1049463078379631, acc: 0.9753391146659851)
[2024-12-17 04:07:22,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:22,832][root][INFO] - Training Epoch: 1/2, step 3717/7134 completed (loss: 0.07965566217899323, acc: 0.9781420826911926)
[2024-12-17 04:07:22,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:23,298][root][INFO] - Training Epoch: 1/2, step 3718/7134 completed (loss: 0.09187749773263931, acc: 0.974208652973175)
[2024-12-17 04:07:23,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:23,747][root][INFO] - Training Epoch: 1/2, step 3719/7134 completed (loss: 0.0828419178724289, acc: 0.979411780834198)
[2024-12-17 04:07:23,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:24,168][root][INFO] - Training Epoch: 1/2, step 3720/7134 completed (loss: 0.045125048607587814, acc: 0.9912023544311523)
[2024-12-17 04:07:24,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:24,637][root][INFO] - Training Epoch: 1/2, step 3721/7134 completed (loss: 0.06964198499917984, acc: 0.9800266027450562)
[2024-12-17 04:07:24,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:25,080][root][INFO] - Training Epoch: 1/2, step 3722/7134 completed (loss: 0.049613215029239655, acc: 0.9876847267150879)
[2024-12-17 04:07:25,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:25,509][root][INFO] - Training Epoch: 1/2, step 3723/7134 completed (loss: 0.07758134603500366, acc: 0.9798561334609985)
[2024-12-17 04:07:25,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:25,949][root][INFO] - Training Epoch: 1/2, step 3724/7134 completed (loss: 0.06734728068113327, acc: 0.9813218116760254)
[2024-12-17 04:07:26,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:26,398][root][INFO] - Training Epoch: 1/2, step 3725/7134 completed (loss: 0.1574917435646057, acc: 0.9646017551422119)
[2024-12-17 04:07:26,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:26,872][root][INFO] - Training Epoch: 1/2, step 3726/7134 completed (loss: 0.05804568529129028, acc: 0.9808714389801025)
[2024-12-17 04:07:26,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:27,306][root][INFO] - Training Epoch: 1/2, step 3727/7134 completed (loss: 0.046969156712293625, acc: 0.9906542301177979)
[2024-12-17 04:07:27,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:27,760][root][INFO] - Training Epoch: 1/2, step 3728/7134 completed (loss: 0.027964651584625244, acc: 0.9921082258224487)
[2024-12-17 04:07:27,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:28,207][root][INFO] - Training Epoch: 1/2, step 3729/7134 completed (loss: 0.08351940661668777, acc: 0.9761363863945007)
[2024-12-17 04:07:28,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:28,649][root][INFO] - Training Epoch: 1/2, step 3730/7134 completed (loss: 0.0250258706510067, acc: 0.9945725798606873)
[2024-12-17 04:07:28,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:29,095][root][INFO] - Training Epoch: 1/2, step 3731/7134 completed (loss: 0.05632069706916809, acc: 0.9813200235366821)
[2024-12-17 04:07:29,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:29,540][root][INFO] - Training Epoch: 1/2, step 3732/7134 completed (loss: 0.03707796707749367, acc: 0.9909194111824036)
[2024-12-17 04:07:29,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:29,980][root][INFO] - Training Epoch: 1/2, step 3733/7134 completed (loss: 0.06687150150537491, acc: 0.9817671775817871)
[2024-12-17 04:07:30,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:30,385][root][INFO] - Training Epoch: 1/2, step 3734/7134 completed (loss: 0.11485839635133743, acc: 0.9595469236373901)
[2024-12-17 04:07:30,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:30,826][root][INFO] - Training Epoch: 1/2, step 3735/7134 completed (loss: 0.0890161320567131, acc: 0.9759036302566528)
[2024-12-17 04:07:30,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:31,279][root][INFO] - Training Epoch: 1/2, step 3736/7134 completed (loss: 0.176582470536232, acc: 0.9547826051712036)
[2024-12-17 04:07:31,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:31,706][root][INFO] - Training Epoch: 1/2, step 3737/7134 completed (loss: 0.10353433340787888, acc: 0.9728506803512573)
[2024-12-17 04:07:31,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:32,128][root][INFO] - Training Epoch: 1/2, step 3738/7134 completed (loss: 0.06829909235239029, acc: 0.9818481802940369)
[2024-12-17 04:07:32,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:32,516][root][INFO] - Training Epoch: 1/2, step 3739/7134 completed (loss: 0.20682336390018463, acc: 0.9550561904907227)
[2024-12-17 04:07:32,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:32,935][root][INFO] - Training Epoch: 1/2, step 3740/7134 completed (loss: 0.09463077038526535, acc: 0.9707792401313782)
[2024-12-17 04:07:33,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:33,358][root][INFO] - Training Epoch: 1/2, step 3741/7134 completed (loss: 0.10421797633171082, acc: 0.9786019921302795)
[2024-12-17 04:07:33,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:33,753][root][INFO] - Training Epoch: 1/2, step 3742/7134 completed (loss: 0.07837411761283875, acc: 0.9794871807098389)
[2024-12-17 04:07:33,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:34,182][root][INFO] - Training Epoch: 1/2, step 3743/7134 completed (loss: 0.11452898383140564, acc: 0.974926233291626)
[2024-12-17 04:07:34,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:34,622][root][INFO] - Training Epoch: 1/2, step 3744/7134 completed (loss: 0.12445612251758575, acc: 0.9683794379234314)
[2024-12-17 04:07:34,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:35,045][root][INFO] - Training Epoch: 1/2, step 3745/7134 completed (loss: 0.1492793709039688, acc: 0.9605568647384644)
[2024-12-17 04:07:35,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:35,488][root][INFO] - Training Epoch: 1/2, step 3746/7134 completed (loss: 0.13750407099723816, acc: 0.9646596908569336)
[2024-12-17 04:07:35,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:35,954][root][INFO] - Training Epoch: 1/2, step 3747/7134 completed (loss: 0.11107628047466278, acc: 0.967930018901825)
[2024-12-17 04:07:36,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:36,316][root][INFO] - Training Epoch: 1/2, step 3748/7134 completed (loss: 0.10131987184286118, acc: 0.9823943376541138)
[2024-12-17 04:07:36,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:36,725][root][INFO] - Training Epoch: 1/2, step 3749/7134 completed (loss: 0.1265551894903183, acc: 0.9700149893760681)
[2024-12-17 04:07:36,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:37,155][root][INFO] - Training Epoch: 1/2, step 3750/7134 completed (loss: 0.07165388762950897, acc: 0.9790794849395752)
[2024-12-17 04:07:37,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:37,595][root][INFO] - Training Epoch: 1/2, step 3751/7134 completed (loss: 0.09405341744422913, acc: 0.9715505242347717)
[2024-12-17 04:07:37,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:38,020][root][INFO] - Training Epoch: 1/2, step 3752/7134 completed (loss: 0.08385276049375534, acc: 0.9791044592857361)
[2024-12-17 04:07:38,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:38,447][root][INFO] - Training Epoch: 1/2, step 3753/7134 completed (loss: 0.10994629561901093, acc: 0.9701046347618103)
[2024-12-17 04:07:38,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:38,861][root][INFO] - Training Epoch: 1/2, step 3754/7134 completed (loss: 0.06345435231924057, acc: 0.9802731275558472)
[2024-12-17 04:07:38,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:39,279][root][INFO] - Training Epoch: 1/2, step 3755/7134 completed (loss: 0.0636582225561142, acc: 0.9777365326881409)
[2024-12-17 04:07:39,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:39,697][root][INFO] - Training Epoch: 1/2, step 3756/7134 completed (loss: 0.09950244426727295, acc: 0.9764543175697327)
[2024-12-17 04:07:39,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:40,130][root][INFO] - Training Epoch: 1/2, step 3757/7134 completed (loss: 0.12066582590341568, acc: 0.9655172228813171)
[2024-12-17 04:07:40,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:40,541][root][INFO] - Training Epoch: 1/2, step 3758/7134 completed (loss: 0.07111989706754684, acc: 0.9855855703353882)
[2024-12-17 04:07:40,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:40,957][root][INFO] - Training Epoch: 1/2, step 3759/7134 completed (loss: 0.14360055327415466, acc: 0.9645270109176636)
[2024-12-17 04:07:41,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:41,416][root][INFO] - Training Epoch: 1/2, step 3760/7134 completed (loss: 0.10272671282291412, acc: 0.9802259802818298)
[2024-12-17 04:07:41,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:41,845][root][INFO] - Training Epoch: 1/2, step 3761/7134 completed (loss: 0.058106906712055206, acc: 0.9876352548599243)
[2024-12-17 04:07:41,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:42,287][root][INFO] - Training Epoch: 1/2, step 3762/7134 completed (loss: 0.06015181168913841, acc: 0.9834938049316406)
[2024-12-17 04:07:42,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:42,707][root][INFO] - Training Epoch: 1/2, step 3763/7134 completed (loss: 0.05817463994026184, acc: 0.9814814925193787)
[2024-12-17 04:07:42,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:43,133][root][INFO] - Training Epoch: 1/2, step 3764/7134 completed (loss: 0.08947643637657166, acc: 0.9822161197662354)
[2024-12-17 04:07:43,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:43,632][root][INFO] - Training Epoch: 1/2, step 3765/7134 completed (loss: 0.06325308233499527, acc: 0.9807923436164856)
[2024-12-17 04:07:43,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:44,042][root][INFO] - Training Epoch: 1/2, step 3766/7134 completed (loss: 0.10620133578777313, acc: 0.9757834672927856)
[2024-12-17 04:07:44,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:44,495][root][INFO] - Training Epoch: 1/2, step 3767/7134 completed (loss: 0.05136742815375328, acc: 0.9837905168533325)
[2024-12-17 04:07:44,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:44,911][root][INFO] - Training Epoch: 1/2, step 3768/7134 completed (loss: 0.07183197140693665, acc: 0.9771783947944641)
[2024-12-17 04:07:45,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:45,363][root][INFO] - Training Epoch: 1/2, step 3769/7134 completed (loss: 0.0482989139854908, acc: 0.983627200126648)
[2024-12-17 04:07:45,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:45,802][root][INFO] - Training Epoch: 1/2, step 3770/7134 completed (loss: 0.06258262693881989, acc: 0.9816384315490723)
[2024-12-17 04:07:45,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:46,250][root][INFO] - Training Epoch: 1/2, step 3771/7134 completed (loss: 0.04893755912780762, acc: 0.9870129823684692)
[2024-12-17 04:07:46,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:46,685][root][INFO] - Training Epoch: 1/2, step 3772/7134 completed (loss: 0.10196983069181442, acc: 0.9701046347618103)
[2024-12-17 04:07:46,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:47,136][root][INFO] - Training Epoch: 1/2, step 3773/7134 completed (loss: 0.07183931022882462, acc: 0.9787946343421936)
[2024-12-17 04:07:47,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:47,585][root][INFO] - Training Epoch: 1/2, step 3774/7134 completed (loss: 0.08791554719209671, acc: 0.9756380319595337)
[2024-12-17 04:07:47,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:48,017][root][INFO] - Training Epoch: 1/2, step 3775/7134 completed (loss: 0.04350851848721504, acc: 0.9885386824607849)
[2024-12-17 04:07:48,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:48,475][root][INFO] - Training Epoch: 1/2, step 3776/7134 completed (loss: 0.10261242091655731, acc: 0.9748148322105408)
[2024-12-17 04:07:48,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:48,947][root][INFO] - Training Epoch: 1/2, step 3777/7134 completed (loss: 0.051454320549964905, acc: 0.9887217879295349)
[2024-12-17 04:07:49,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:49,369][root][INFO] - Training Epoch: 1/2, step 3778/7134 completed (loss: 0.10816004872322083, acc: 0.9815078377723694)
[2024-12-17 04:07:49,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:49,778][root][INFO] - Training Epoch: 1/2, step 3779/7134 completed (loss: 0.05972429737448692, acc: 0.9829059839248657)
[2024-12-17 04:07:49,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:50,199][root][INFO] - Training Epoch: 1/2, step 3780/7134 completed (loss: 0.059185754507780075, acc: 0.9812679886817932)
[2024-12-17 04:07:50,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:50,622][root][INFO] - Training Epoch: 1/2, step 3781/7134 completed (loss: 0.08952249586582184, acc: 0.9780521392822266)
[2024-12-17 04:07:50,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:51,040][root][INFO] - Training Epoch: 1/2, step 3782/7134 completed (loss: 0.0811464861035347, acc: 0.9715099930763245)
[2024-12-17 04:07:51,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:51,470][root][INFO] - Training Epoch: 1/2, step 3783/7134 completed (loss: 0.08442988991737366, acc: 0.9741935729980469)
[2024-12-17 04:07:51,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:51,880][root][INFO] - Training Epoch: 1/2, step 3784/7134 completed (loss: 0.09056077897548676, acc: 0.9783616662025452)
[2024-12-17 04:07:51,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:52,303][root][INFO] - Training Epoch: 1/2, step 3785/7134 completed (loss: 0.03302857652306557, acc: 0.9890795350074768)
[2024-12-17 04:07:52,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:52,729][root][INFO] - Training Epoch: 1/2, step 3786/7134 completed (loss: 0.07468177378177643, acc: 0.9780077338218689)
[2024-12-17 04:07:52,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:53,135][root][INFO] - Training Epoch: 1/2, step 3787/7134 completed (loss: 0.06920430064201355, acc: 0.980861246585846)
[2024-12-17 04:07:53,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:53,591][root][INFO] - Training Epoch: 1/2, step 3788/7134 completed (loss: 0.06594143807888031, acc: 0.9811066389083862)
[2024-12-17 04:07:53,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:54,036][root][INFO] - Training Epoch: 1/2, step 3789/7134 completed (loss: 0.09519782662391663, acc: 0.9732770919799805)
[2024-12-17 04:07:54,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:54,478][root][INFO] - Training Epoch: 1/2, step 3790/7134 completed (loss: 0.1273171603679657, acc: 0.9657794833183289)
[2024-12-17 04:07:54,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:54,884][root][INFO] - Training Epoch: 1/2, step 3791/7134 completed (loss: 0.07066383957862854, acc: 0.9845161437988281)
[2024-12-17 04:07:54,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:55,292][root][INFO] - Training Epoch: 1/2, step 3792/7134 completed (loss: 0.06299679726362228, acc: 0.9753694534301758)
[2024-12-17 04:07:55,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:55,717][root][INFO] - Training Epoch: 1/2, step 3793/7134 completed (loss: 0.07137507200241089, acc: 0.9824324250221252)
[2024-12-17 04:07:55,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:56,142][root][INFO] - Training Epoch: 1/2, step 3794/7134 completed (loss: 0.08190922439098358, acc: 0.9831387996673584)
[2024-12-17 04:07:56,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:56,591][root][INFO] - Training Epoch: 1/2, step 3795/7134 completed (loss: 0.07226976752281189, acc: 0.9759036302566528)
[2024-12-17 04:07:56,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:57,024][root][INFO] - Training Epoch: 1/2, step 3796/7134 completed (loss: 0.07404493540525436, acc: 0.9748743772506714)
[2024-12-17 04:07:57,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:57,434][root][INFO] - Training Epoch: 1/2, step 3797/7134 completed (loss: 0.036761388182640076, acc: 0.9882659912109375)
[2024-12-17 04:07:57,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:57,845][root][INFO] - Training Epoch: 1/2, step 3798/7134 completed (loss: 0.08782407641410828, acc: 0.9755747318267822)
[2024-12-17 04:07:57,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:58,264][root][INFO] - Training Epoch: 1/2, step 3799/7134 completed (loss: 0.08392979949712753, acc: 0.9755469560623169)
[2024-12-17 04:07:58,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:58,679][root][INFO] - Training Epoch: 1/2, step 3800/7134 completed (loss: 0.0901455283164978, acc: 0.9694189429283142)
[2024-12-17 04:07:58,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:59,123][root][INFO] - Training Epoch: 1/2, step 3801/7134 completed (loss: 0.05288390815258026, acc: 0.9827160239219666)
[2024-12-17 04:07:59,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:59,562][root][INFO] - Training Epoch: 1/2, step 3802/7134 completed (loss: 0.06670601665973663, acc: 0.9810874462127686)
[2024-12-17 04:07:59,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:07:59,974][root][INFO] - Training Epoch: 1/2, step 3803/7134 completed (loss: 0.09405884146690369, acc: 0.976190447807312)
[2024-12-17 04:08:00,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:00,420][root][INFO] - Training Epoch: 1/2, step 3804/7134 completed (loss: 0.05813443660736084, acc: 0.9782270789146423)
[2024-12-17 04:08:00,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:00,871][root][INFO] - Training Epoch: 1/2, step 3805/7134 completed (loss: 0.05136580765247345, acc: 0.985602080821991)
[2024-12-17 04:08:01,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:01,280][root][INFO] - Training Epoch: 1/2, step 3806/7134 completed (loss: 0.07262591272592545, acc: 0.9802761077880859)
[2024-12-17 04:08:01,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:01,705][root][INFO] - Training Epoch: 1/2, step 3807/7134 completed (loss: 0.03267861530184746, acc: 0.9897660613059998)
[2024-12-17 04:08:01,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:02,155][root][INFO] - Training Epoch: 1/2, step 3808/7134 completed (loss: 0.0592605285346508, acc: 0.9835442900657654)
[2024-12-17 04:08:02,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:02,597][root][INFO] - Training Epoch: 1/2, step 3809/7134 completed (loss: 0.08760468661785126, acc: 0.9720812439918518)
[2024-12-17 04:08:02,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:03,007][root][INFO] - Training Epoch: 1/2, step 3810/7134 completed (loss: 0.06909070909023285, acc: 0.980654776096344)
[2024-12-17 04:08:03,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:03,438][root][INFO] - Training Epoch: 1/2, step 3811/7134 completed (loss: 0.07473671436309814, acc: 0.9848275780677795)
[2024-12-17 04:08:03,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:03,890][root][INFO] - Training Epoch: 1/2, step 3812/7134 completed (loss: 0.08600898832082748, acc: 0.9759863018989563)
[2024-12-17 04:08:04,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:04,344][root][INFO] - Training Epoch: 1/2, step 3813/7134 completed (loss: 0.09238377213478088, acc: 0.9775725603103638)
[2024-12-17 04:08:04,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:04,782][root][INFO] - Training Epoch: 1/2, step 3814/7134 completed (loss: 0.043380334973335266, acc: 0.9839141964912415)
[2024-12-17 04:08:04,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:05,188][root][INFO] - Training Epoch: 1/2, step 3815/7134 completed (loss: 0.05066375061869621, acc: 0.9881481528282166)
[2024-12-17 04:08:05,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:05,648][root][INFO] - Training Epoch: 1/2, step 3816/7134 completed (loss: 0.054290998727083206, acc: 0.9810725450515747)
[2024-12-17 04:08:05,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:06,092][root][INFO] - Training Epoch: 1/2, step 3817/7134 completed (loss: 0.09030374884605408, acc: 0.9784172773361206)
[2024-12-17 04:08:06,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:06,499][root][INFO] - Training Epoch: 1/2, step 3818/7134 completed (loss: 0.11217765510082245, acc: 0.9777777791023254)
[2024-12-17 04:08:06,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:06,896][root][INFO] - Training Epoch: 1/2, step 3819/7134 completed (loss: 0.13407081365585327, acc: 0.9638554453849792)
[2024-12-17 04:08:07,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:07,318][root][INFO] - Training Epoch: 1/2, step 3820/7134 completed (loss: 0.10862388461828232, acc: 0.95961993932724)
[2024-12-17 04:08:07,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:07,715][root][INFO] - Training Epoch: 1/2, step 3821/7134 completed (loss: 0.08581564575433731, acc: 0.9746192693710327)
[2024-12-17 04:08:07,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:08,112][root][INFO] - Training Epoch: 1/2, step 3822/7134 completed (loss: 0.07004352658987045, acc: 0.9783890247344971)
[2024-12-17 04:08:08,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:08,539][root][INFO] - Training Epoch: 1/2, step 3823/7134 completed (loss: 0.05352826043963432, acc: 0.9806362390518188)
[2024-12-17 04:08:08,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:08,934][root][INFO] - Training Epoch: 1/2, step 3824/7134 completed (loss: 0.11133290827274323, acc: 0.9713321924209595)
[2024-12-17 04:08:09,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:09,349][root][INFO] - Training Epoch: 1/2, step 3825/7134 completed (loss: 0.06586933135986328, acc: 0.9800398945808411)
[2024-12-17 04:08:09,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:09,781][root][INFO] - Training Epoch: 1/2, step 3826/7134 completed (loss: 0.07784979045391083, acc: 0.9779411554336548)
[2024-12-17 04:08:09,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:10,217][root][INFO] - Training Epoch: 1/2, step 3827/7134 completed (loss: 0.0569102019071579, acc: 0.9859943985939026)
[2024-12-17 04:08:10,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:10,595][root][INFO] - Training Epoch: 1/2, step 3828/7134 completed (loss: 0.07602040469646454, acc: 0.9761273264884949)
[2024-12-17 04:08:10,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:11,047][root][INFO] - Training Epoch: 1/2, step 3829/7134 completed (loss: 0.06267552822828293, acc: 0.9834087491035461)
[2024-12-17 04:08:11,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:11,467][root][INFO] - Training Epoch: 1/2, step 3830/7134 completed (loss: 0.09577091783285141, acc: 0.9765493869781494)
[2024-12-17 04:08:11,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:11,900][root][INFO] - Training Epoch: 1/2, step 3831/7134 completed (loss: 0.06828955560922623, acc: 0.9804804921150208)
[2024-12-17 04:08:12,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:12,302][root][INFO] - Training Epoch: 1/2, step 3832/7134 completed (loss: 0.05783712863922119, acc: 0.9862475395202637)
[2024-12-17 04:08:12,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:12,738][root][INFO] - Training Epoch: 1/2, step 3833/7134 completed (loss: 0.023548495024442673, acc: 0.9925742745399475)
[2024-12-17 04:08:12,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:13,152][root][INFO] - Training Epoch: 1/2, step 3834/7134 completed (loss: 0.02471688762307167, acc: 0.9909090995788574)
[2024-12-17 04:08:13,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:13,559][root][INFO] - Training Epoch: 1/2, step 3835/7134 completed (loss: 0.021964099258184433, acc: 0.9951456189155579)
[2024-12-17 04:08:13,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:13,903][root][INFO] - Training Epoch: 1/2, step 3836/7134 completed (loss: 0.10079275816679001, acc: 0.9768115878105164)
[2024-12-17 04:08:13,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:14,318][root][INFO] - Training Epoch: 1/2, step 3837/7134 completed (loss: 0.04392408952116966, acc: 0.9928160905838013)
[2024-12-17 04:08:14,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:14,750][root][INFO] - Training Epoch: 1/2, step 3838/7134 completed (loss: 0.03855063021183014, acc: 0.9867197871208191)
[2024-12-17 04:08:14,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:15,236][root][INFO] - Training Epoch: 1/2, step 3839/7134 completed (loss: 0.04012380912899971, acc: 0.988950252532959)
[2024-12-17 04:08:15,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:15,660][root][INFO] - Training Epoch: 1/2, step 3840/7134 completed (loss: 0.045703157782554626, acc: 0.9866130948066711)
[2024-12-17 04:08:15,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:16,119][root][INFO] - Training Epoch: 1/2, step 3841/7134 completed (loss: 0.08767160773277283, acc: 0.9789122939109802)
[2024-12-17 04:08:16,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:16,472][root][INFO] - Training Epoch: 1/2, step 3842/7134 completed (loss: 0.026719901710748672, acc: 0.9926470518112183)
[2024-12-17 04:08:16,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:16,958][root][INFO] - Training Epoch: 1/2, step 3843/7134 completed (loss: 0.054432980716228485, acc: 0.985401451587677)
[2024-12-17 04:08:17,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:17,400][root][INFO] - Training Epoch: 1/2, step 3844/7134 completed (loss: 0.05293211340904236, acc: 0.987293541431427)
[2024-12-17 04:08:17,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:17,803][root][INFO] - Training Epoch: 1/2, step 3845/7134 completed (loss: 0.08522212505340576, acc: 0.9713804721832275)
[2024-12-17 04:08:17,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:18,252][root][INFO] - Training Epoch: 1/2, step 3846/7134 completed (loss: 0.027041791006922722, acc: 0.9932088255882263)
[2024-12-17 04:08:18,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:18,700][root][INFO] - Training Epoch: 1/2, step 3847/7134 completed (loss: 0.03307829424738884, acc: 0.9919999837875366)
[2024-12-17 04:08:18,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:19,162][root][INFO] - Training Epoch: 1/2, step 3848/7134 completed (loss: 0.037580620497465134, acc: 0.991094172000885)
[2024-12-17 04:08:19,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:19,565][root][INFO] - Training Epoch: 1/2, step 3849/7134 completed (loss: 0.1076081320643425, acc: 0.9714794754981995)
[2024-12-17 04:08:19,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:19,990][root][INFO] - Training Epoch: 1/2, step 3850/7134 completed (loss: 0.11830691993236542, acc: 0.9731051325798035)
[2024-12-17 04:08:20,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:20,445][root][INFO] - Training Epoch: 1/2, step 3851/7134 completed (loss: 0.07548240572214127, acc: 0.9818689227104187)
[2024-12-17 04:08:20,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:20,853][root][INFO] - Training Epoch: 1/2, step 3852/7134 completed (loss: 0.06847675889730453, acc: 0.9839228391647339)
[2024-12-17 04:08:20,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:21,278][root][INFO] - Training Epoch: 1/2, step 3853/7134 completed (loss: 0.09908820688724518, acc: 0.9732770919799805)
[2024-12-17 04:08:21,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:21,699][root][INFO] - Training Epoch: 1/2, step 3854/7134 completed (loss: 0.05239946022629738, acc: 0.9845505356788635)
[2024-12-17 04:08:21,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:22,141][root][INFO] - Training Epoch: 1/2, step 3855/7134 completed (loss: 0.07716629654169083, acc: 0.9788029789924622)
[2024-12-17 04:08:22,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:22,556][root][INFO] - Training Epoch: 1/2, step 3856/7134 completed (loss: 0.10926264524459839, acc: 0.9776847958564758)
[2024-12-17 04:08:22,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:22,952][root][INFO] - Training Epoch: 1/2, step 3857/7134 completed (loss: 0.06891508400440216, acc: 0.9758842587471008)
[2024-12-17 04:08:23,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:23,385][root][INFO] - Training Epoch: 1/2, step 3858/7134 completed (loss: 0.08866478502750397, acc: 0.9730878472328186)
[2024-12-17 04:08:23,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:23,819][root][INFO] - Training Epoch: 1/2, step 3859/7134 completed (loss: 0.08254749327898026, acc: 0.9796437621116638)
[2024-12-17 04:08:23,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:24,320][root][INFO] - Training Epoch: 1/2, step 3860/7134 completed (loss: 0.057163920253515244, acc: 0.9832402467727661)
[2024-12-17 04:08:24,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:24,760][root][INFO] - Training Epoch: 1/2, step 3861/7134 completed (loss: 0.09431405365467072, acc: 0.9714285731315613)
[2024-12-17 04:08:24,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:25,174][root][INFO] - Training Epoch: 1/2, step 3862/7134 completed (loss: 0.09771400690078735, acc: 0.9737274050712585)
[2024-12-17 04:08:25,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:25,652][root][INFO] - Training Epoch: 1/2, step 3863/7134 completed (loss: 0.06277518719434738, acc: 0.9814814925193787)
[2024-12-17 04:08:25,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:26,102][root][INFO] - Training Epoch: 1/2, step 3864/7134 completed (loss: 0.07391876727342606, acc: 0.9817232489585876)
[2024-12-17 04:08:26,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:26,546][root][INFO] - Training Epoch: 1/2, step 3865/7134 completed (loss: 0.07000894099473953, acc: 0.9840637445449829)
[2024-12-17 04:08:26,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:26,965][root][INFO] - Training Epoch: 1/2, step 3866/7134 completed (loss: 0.10226798057556152, acc: 0.9731379747390747)
[2024-12-17 04:08:27,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:27,414][root][INFO] - Training Epoch: 1/2, step 3867/7134 completed (loss: 0.07302253693342209, acc: 0.9772727489471436)
[2024-12-17 04:08:27,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:27,857][root][INFO] - Training Epoch: 1/2, step 3868/7134 completed (loss: 0.07139679789543152, acc: 0.9847715497016907)
[2024-12-17 04:08:27,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:28,277][root][INFO] - Training Epoch: 1/2, step 3869/7134 completed (loss: 0.06711944192647934, acc: 0.9848713874816895)
[2024-12-17 04:08:28,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:28,693][root][INFO] - Training Epoch: 1/2, step 3870/7134 completed (loss: 0.08064475655555725, acc: 0.9819444417953491)
[2024-12-17 04:08:28,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:29,112][root][INFO] - Training Epoch: 1/2, step 3871/7134 completed (loss: 0.0782412514090538, acc: 0.9800498485565186)
[2024-12-17 04:08:29,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:29,576][root][INFO] - Training Epoch: 1/2, step 3872/7134 completed (loss: 0.10040079802274704, acc: 0.9689507484436035)
[2024-12-17 04:08:29,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:30,014][root][INFO] - Training Epoch: 1/2, step 3873/7134 completed (loss: 0.06642572581768036, acc: 0.9833759665489197)
[2024-12-17 04:08:30,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:30,447][root][INFO] - Training Epoch: 1/2, step 3874/7134 completed (loss: 0.08581871539354324, acc: 0.9806362390518188)
[2024-12-17 04:08:30,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:30,901][root][INFO] - Training Epoch: 1/2, step 3875/7134 completed (loss: 0.10453752428293228, acc: 0.9694148898124695)
[2024-12-17 04:08:31,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:31,314][root][INFO] - Training Epoch: 1/2, step 3876/7134 completed (loss: 0.07436194270849228, acc: 0.9793621301651001)
[2024-12-17 04:08:31,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:31,745][root][INFO] - Training Epoch: 1/2, step 3877/7134 completed (loss: 0.09143125265836716, acc: 0.9791122674942017)
[2024-12-17 04:08:31,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:32,169][root][INFO] - Training Epoch: 1/2, step 3878/7134 completed (loss: 0.1081089898943901, acc: 0.973045825958252)
[2024-12-17 04:08:32,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:32,613][root][INFO] - Training Epoch: 1/2, step 3879/7134 completed (loss: 0.04302743077278137, acc: 0.9815157055854797)
[2024-12-17 04:08:32,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:33,078][root][INFO] - Training Epoch: 1/2, step 3880/7134 completed (loss: 0.12131284177303314, acc: 0.9676945805549622)
[2024-12-17 04:08:33,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:33,497][root][INFO] - Training Epoch: 1/2, step 3881/7134 completed (loss: 0.12777788937091827, acc: 0.9639999866485596)
[2024-12-17 04:08:33,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:33,921][root][INFO] - Training Epoch: 1/2, step 3882/7134 completed (loss: 0.12456155568361282, acc: 0.9750000238418579)
[2024-12-17 04:08:34,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:34,353][root][INFO] - Training Epoch: 1/2, step 3883/7134 completed (loss: 0.04921150952577591, acc: 0.977622389793396)
[2024-12-17 04:08:34,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:34,773][root][INFO] - Training Epoch: 1/2, step 3884/7134 completed (loss: 0.05360232666134834, acc: 0.9823129177093506)
[2024-12-17 04:08:34,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:35,212][root][INFO] - Training Epoch: 1/2, step 3885/7134 completed (loss: 0.05407271161675453, acc: 0.9895561337471008)
[2024-12-17 04:08:35,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:35,659][root][INFO] - Training Epoch: 1/2, step 3886/7134 completed (loss: 0.05760757625102997, acc: 0.979468584060669)
[2024-12-17 04:08:35,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:36,076][root][INFO] - Training Epoch: 1/2, step 3887/7134 completed (loss: 0.05448295176029205, acc: 0.9834087491035461)
[2024-12-17 04:08:36,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:36,509][root][INFO] - Training Epoch: 1/2, step 3888/7134 completed (loss: 0.07500437647104263, acc: 0.981249988079071)
[2024-12-17 04:08:36,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:36,974][root][INFO] - Training Epoch: 1/2, step 3889/7134 completed (loss: 0.0488230437040329, acc: 0.9910600185394287)
[2024-12-17 04:08:37,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:37,429][root][INFO] - Training Epoch: 1/2, step 3890/7134 completed (loss: 0.04370861127972603, acc: 0.9915764331817627)
[2024-12-17 04:08:37,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:37,890][root][INFO] - Training Epoch: 1/2, step 3891/7134 completed (loss: 0.05394185334444046, acc: 0.9803921580314636)
[2024-12-17 04:08:38,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:38,330][root][INFO] - Training Epoch: 1/2, step 3892/7134 completed (loss: 0.04645031690597534, acc: 0.9846153855323792)
[2024-12-17 04:08:38,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:38,772][root][INFO] - Training Epoch: 1/2, step 3893/7134 completed (loss: 0.10682326555252075, acc: 0.9729381203651428)
[2024-12-17 04:08:38,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:39,169][root][INFO] - Training Epoch: 1/2, step 3894/7134 completed (loss: 0.05598156526684761, acc: 0.9845505356788635)
[2024-12-17 04:08:39,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:39,609][root][INFO] - Training Epoch: 1/2, step 3895/7134 completed (loss: 0.060300592333078384, acc: 0.9819355010986328)
[2024-12-17 04:08:39,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:40,071][root][INFO] - Training Epoch: 1/2, step 3896/7134 completed (loss: 0.04023978114128113, acc: 0.9898419976234436)
[2024-12-17 04:08:40,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:40,526][root][INFO] - Training Epoch: 1/2, step 3897/7134 completed (loss: 0.0858614444732666, acc: 0.9760563373565674)
[2024-12-17 04:08:40,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:40,963][root][INFO] - Training Epoch: 1/2, step 3898/7134 completed (loss: 0.06456457078456879, acc: 0.9821882843971252)
[2024-12-17 04:08:41,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:41,410][root][INFO] - Training Epoch: 1/2, step 3899/7134 completed (loss: 0.05261499062180519, acc: 0.9883570671081543)
[2024-12-17 04:08:41,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:41,877][root][INFO] - Training Epoch: 1/2, step 3900/7134 completed (loss: 0.06364760547876358, acc: 0.9826187491416931)
[2024-12-17 04:08:41,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:42,295][root][INFO] - Training Epoch: 1/2, step 3901/7134 completed (loss: 0.11641571670770645, acc: 0.9703503847122192)
[2024-12-17 04:08:42,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:42,730][root][INFO] - Training Epoch: 1/2, step 3902/7134 completed (loss: 0.15080465376377106, acc: 0.9576159119606018)
[2024-12-17 04:08:42,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:43,192][root][INFO] - Training Epoch: 1/2, step 3903/7134 completed (loss: 0.1452176868915558, acc: 0.9638069868087769)
[2024-12-17 04:08:43,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:43,629][root][INFO] - Training Epoch: 1/2, step 3904/7134 completed (loss: 0.10189781337976456, acc: 0.9741247892379761)
[2024-12-17 04:08:43,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:44,077][root][INFO] - Training Epoch: 1/2, step 3905/7134 completed (loss: 0.09187348932027817, acc: 0.9802538752555847)
[2024-12-17 04:08:44,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:44,525][root][INFO] - Training Epoch: 1/2, step 3906/7134 completed (loss: 0.08752131462097168, acc: 0.9727011322975159)
[2024-12-17 04:08:44,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:44,936][root][INFO] - Training Epoch: 1/2, step 3907/7134 completed (loss: 0.05836431309580803, acc: 0.9845758080482483)
[2024-12-17 04:08:45,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:45,377][root][INFO] - Training Epoch: 1/2, step 3908/7134 completed (loss: 0.09398617595434189, acc: 0.9770290851593018)
[2024-12-17 04:08:45,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:45,793][root][INFO] - Training Epoch: 1/2, step 3909/7134 completed (loss: 0.05955604463815689, acc: 0.9789983630180359)
[2024-12-17 04:08:45,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:46,224][root][INFO] - Training Epoch: 1/2, step 3910/7134 completed (loss: 0.07939771562814713, acc: 0.9819193482398987)
[2024-12-17 04:08:46,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:46,662][root][INFO] - Training Epoch: 1/2, step 3911/7134 completed (loss: 0.05435628071427345, acc: 0.983818769454956)
[2024-12-17 04:08:46,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:47,110][root][INFO] - Training Epoch: 1/2, step 3912/7134 completed (loss: 0.033305756747722626, acc: 0.9866071343421936)
[2024-12-17 04:08:47,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:47,541][root][INFO] - Training Epoch: 1/2, step 3913/7134 completed (loss: 0.07111234217882156, acc: 0.9846153855323792)
[2024-12-17 04:08:47,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:47,964][root][INFO] - Training Epoch: 1/2, step 3914/7134 completed (loss: 0.056012120097875595, acc: 0.9865319728851318)
[2024-12-17 04:08:48,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:48,411][root][INFO] - Training Epoch: 1/2, step 3915/7134 completed (loss: 0.05347909778356552, acc: 0.9858956336975098)
[2024-12-17 04:08:48,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:48,849][root][INFO] - Training Epoch: 1/2, step 3916/7134 completed (loss: 0.06118796765804291, acc: 0.9821656346321106)
[2024-12-17 04:08:48,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:49,300][root][INFO] - Training Epoch: 1/2, step 3917/7134 completed (loss: 0.04422670602798462, acc: 0.9867629408836365)
[2024-12-17 04:08:49,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:49,730][root][INFO] - Training Epoch: 1/2, step 3918/7134 completed (loss: 0.08925361186265945, acc: 0.97265625)
[2024-12-17 04:08:49,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:50,167][root][INFO] - Training Epoch: 1/2, step 3919/7134 completed (loss: 0.14781774580478668, acc: 0.9560260772705078)
[2024-12-17 04:08:50,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:50,620][root][INFO] - Training Epoch: 1/2, step 3920/7134 completed (loss: 0.10306219011545181, acc: 0.9719626307487488)
[2024-12-17 04:08:50,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:51,047][root][INFO] - Training Epoch: 1/2, step 3921/7134 completed (loss: 0.09472761303186417, acc: 0.9679999947547913)
[2024-12-17 04:08:51,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:51,473][root][INFO] - Training Epoch: 1/2, step 3922/7134 completed (loss: 0.17775069177150726, acc: 0.9580712914466858)
[2024-12-17 04:08:51,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:51,879][root][INFO] - Training Epoch: 1/2, step 3923/7134 completed (loss: 0.13473863899707794, acc: 0.9623287916183472)
[2024-12-17 04:08:52,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:52,336][root][INFO] - Training Epoch: 1/2, step 3924/7134 completed (loss: 0.12348821014165878, acc: 0.9640804529190063)
[2024-12-17 04:08:52,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:52,775][root][INFO] - Training Epoch: 1/2, step 3925/7134 completed (loss: 0.11470456421375275, acc: 0.9721815586090088)
[2024-12-17 04:08:52,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:53,203][root][INFO] - Training Epoch: 1/2, step 3926/7134 completed (loss: 0.08903594315052032, acc: 0.9697842001914978)
[2024-12-17 04:08:53,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:53,638][root][INFO] - Training Epoch: 1/2, step 3927/7134 completed (loss: 0.08077482134103775, acc: 0.9793672561645508)
[2024-12-17 04:08:53,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:54,068][root][INFO] - Training Epoch: 1/2, step 3928/7134 completed (loss: 0.09937340021133423, acc: 0.9712643623352051)
[2024-12-17 04:08:54,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:54,488][root][INFO] - Training Epoch: 1/2, step 3929/7134 completed (loss: 0.05365926772356033, acc: 0.9841017723083496)
[2024-12-17 04:08:54,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:54,916][root][INFO] - Training Epoch: 1/2, step 3930/7134 completed (loss: 0.09952188283205032, acc: 0.9684873819351196)
[2024-12-17 04:08:55,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:55,326][root][INFO] - Training Epoch: 1/2, step 3931/7134 completed (loss: 0.07048167288303375, acc: 0.9820627570152283)
[2024-12-17 04:08:55,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:55,752][root][INFO] - Training Epoch: 1/2, step 3932/7134 completed (loss: 0.06386690586805344, acc: 0.9841897487640381)
[2024-12-17 04:08:55,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:56,133][root][INFO] - Training Epoch: 1/2, step 3933/7134 completed (loss: 0.044385991990566254, acc: 0.9901315569877625)
[2024-12-17 04:08:56,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:56,544][root][INFO] - Training Epoch: 1/2, step 3934/7134 completed (loss: 0.06610216200351715, acc: 0.9812646508216858)
[2024-12-17 04:08:56,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:56,988][root][INFO] - Training Epoch: 1/2, step 3935/7134 completed (loss: 0.025596678256988525, acc: 0.9929328560829163)
[2024-12-17 04:08:57,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:57,401][root][INFO] - Training Epoch: 1/2, step 3936/7134 completed (loss: 0.07774016261100769, acc: 0.9867924451828003)
[2024-12-17 04:08:57,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:57,822][root][INFO] - Training Epoch: 1/2, step 3937/7134 completed (loss: 0.09505482763051987, acc: 0.981632649898529)
[2024-12-17 04:08:57,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:58,232][root][INFO] - Training Epoch: 1/2, step 3938/7134 completed (loss: 0.06121109426021576, acc: 0.9909502267837524)
[2024-12-17 04:08:58,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:58,645][root][INFO] - Training Epoch: 1/2, step 3939/7134 completed (loss: 0.1310516595840454, acc: 0.9661590456962585)
[2024-12-17 04:08:58,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:59,087][root][INFO] - Training Epoch: 1/2, step 3940/7134 completed (loss: 0.09460987150669098, acc: 0.979899525642395)
[2024-12-17 04:08:59,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:59,438][root][INFO] - Training Epoch: 1/2, step 3941/7134 completed (loss: 0.058181390166282654, acc: 0.9847561120986938)
[2024-12-17 04:08:59,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:08:59,868][root][INFO] - Training Epoch: 1/2, step 3942/7134 completed (loss: 0.054652005434036255, acc: 0.9815573692321777)
[2024-12-17 04:08:59,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:00,217][root][INFO] - Training Epoch: 1/2, step 3943/7134 completed (loss: 0.08112727105617523, acc: 0.9729729890823364)
[2024-12-17 04:09:00,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:00,644][root][INFO] - Training Epoch: 1/2, step 3944/7134 completed (loss: 0.06561382859945297, acc: 0.9797047972679138)
[2024-12-17 04:09:00,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:01,053][root][INFO] - Training Epoch: 1/2, step 3945/7134 completed (loss: 0.06428345292806625, acc: 0.9832317233085632)
[2024-12-17 04:09:01,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:01,426][root][INFO] - Training Epoch: 1/2, step 3946/7134 completed (loss: 0.06181200593709946, acc: 0.9853861927986145)
[2024-12-17 04:09:01,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:01,868][root][INFO] - Training Epoch: 1/2, step 3947/7134 completed (loss: 0.06860537081956863, acc: 0.9870466589927673)
[2024-12-17 04:09:01,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:02,258][root][INFO] - Training Epoch: 1/2, step 3948/7134 completed (loss: 0.06000840663909912, acc: 0.9849246144294739)
[2024-12-17 04:09:02,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:02,661][root][INFO] - Training Epoch: 1/2, step 3949/7134 completed (loss: 0.05614647641777992, acc: 0.9813432693481445)
[2024-12-17 04:09:02,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:03,062][root][INFO] - Training Epoch: 1/2, step 3950/7134 completed (loss: 0.0722498670220375, acc: 0.9821428656578064)
[2024-12-17 04:09:03,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:03,439][root][INFO] - Training Epoch: 1/2, step 3951/7134 completed (loss: 0.08482158929109573, acc: 0.9799498915672302)
[2024-12-17 04:09:03,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:03,848][root][INFO] - Training Epoch: 1/2, step 3952/7134 completed (loss: 0.04304512217640877, acc: 0.9897435903549194)
[2024-12-17 04:09:03,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:04,266][root][INFO] - Training Epoch: 1/2, step 3953/7134 completed (loss: 0.08104880899190903, acc: 0.9886147975921631)
[2024-12-17 04:09:04,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:04,650][root][INFO] - Training Epoch: 1/2, step 3954/7134 completed (loss: 0.058264441788196564, acc: 0.9793814420700073)
[2024-12-17 04:09:04,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:05,048][root][INFO] - Training Epoch: 1/2, step 3955/7134 completed (loss: 0.0652221143245697, acc: 0.9814502596855164)
[2024-12-17 04:09:05,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:05,461][root][INFO] - Training Epoch: 1/2, step 3956/7134 completed (loss: 0.053784992545843124, acc: 0.9887999892234802)
[2024-12-17 04:09:05,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:05,861][root][INFO] - Training Epoch: 1/2, step 3957/7134 completed (loss: 0.05333367735147476, acc: 0.9864864945411682)
[2024-12-17 04:09:05,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:06,239][root][INFO] - Training Epoch: 1/2, step 3958/7134 completed (loss: 0.15884722769260406, acc: 0.9583333134651184)
[2024-12-17 04:09:06,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:06,648][root][INFO] - Training Epoch: 1/2, step 3959/7134 completed (loss: 0.04965786635875702, acc: 0.9846153855323792)
[2024-12-17 04:09:06,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:07,083][root][INFO] - Training Epoch: 1/2, step 3960/7134 completed (loss: 0.07367997616529465, acc: 0.9772079586982727)
[2024-12-17 04:09:07,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:07,501][root][INFO] - Training Epoch: 1/2, step 3961/7134 completed (loss: 0.034702979028224945, acc: 0.9880059957504272)
[2024-12-17 04:09:07,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:07,907][root][INFO] - Training Epoch: 1/2, step 3962/7134 completed (loss: 0.05239278823137283, acc: 0.9854369163513184)
[2024-12-17 04:09:07,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:08,371][root][INFO] - Training Epoch: 1/2, step 3963/7134 completed (loss: 0.12921349704265594, acc: 0.9750733375549316)
[2024-12-17 04:09:08,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:08,785][root][INFO] - Training Epoch: 1/2, step 3964/7134 completed (loss: 0.0927000492811203, acc: 0.9833333492279053)
[2024-12-17 04:09:08,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:09,211][root][INFO] - Training Epoch: 1/2, step 3965/7134 completed (loss: 0.07952557504177094, acc: 0.9814019799232483)
[2024-12-17 04:09:09,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:09,631][root][INFO] - Training Epoch: 1/2, step 3966/7134 completed (loss: 0.05581953376531601, acc: 0.9837545156478882)
[2024-12-17 04:09:09,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:10,072][root][INFO] - Training Epoch: 1/2, step 3967/7134 completed (loss: 0.14017824828624725, acc: 0.9670710563659668)
[2024-12-17 04:09:10,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:10,524][root][INFO] - Training Epoch: 1/2, step 3968/7134 completed (loss: 0.0472128763794899, acc: 0.9856957197189331)
[2024-12-17 04:09:10,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:10,885][root][INFO] - Training Epoch: 1/2, step 3969/7134 completed (loss: 0.1482555866241455, acc: 0.963350772857666)
[2024-12-17 04:09:10,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:11,291][root][INFO] - Training Epoch: 1/2, step 3970/7134 completed (loss: 0.09076017141342163, acc: 0.9784172773361206)
[2024-12-17 04:09:11,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:11,738][root][INFO] - Training Epoch: 1/2, step 3971/7134 completed (loss: 0.17573429644107819, acc: 0.9578005075454712)
[2024-12-17 04:09:11,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:12,159][root][INFO] - Training Epoch: 1/2, step 3972/7134 completed (loss: 0.26293590664863586, acc: 0.9432989954948425)
[2024-12-17 04:09:12,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:12,577][root][INFO] - Training Epoch: 1/2, step 3973/7134 completed (loss: 0.09279657155275345, acc: 0.9775474667549133)
[2024-12-17 04:09:12,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:13,006][root][INFO] - Training Epoch: 1/2, step 3974/7134 completed (loss: 0.16670401394367218, acc: 0.9539295434951782)
[2024-12-17 04:09:13,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:13,420][root][INFO] - Training Epoch: 1/2, step 3975/7134 completed (loss: 0.08949586749076843, acc: 0.9728096723556519)
[2024-12-17 04:09:13,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:13,865][root][INFO] - Training Epoch: 1/2, step 3976/7134 completed (loss: 0.17343683540821075, acc: 0.9631268382072449)
[2024-12-17 04:09:13,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:14,298][root][INFO] - Training Epoch: 1/2, step 3977/7134 completed (loss: 0.0575813427567482, acc: 0.9860869646072388)
[2024-12-17 04:09:14,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:14,714][root][INFO] - Training Epoch: 1/2, step 3978/7134 completed (loss: 0.05168960615992546, acc: 0.9857697486877441)
[2024-12-17 04:09:14,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:15,151][root][INFO] - Training Epoch: 1/2, step 3979/7134 completed (loss: 0.08663053810596466, acc: 0.9708561301231384)
[2024-12-17 04:09:15,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:15,564][root][INFO] - Training Epoch: 1/2, step 3980/7134 completed (loss: 0.059975817799568176, acc: 0.9878048896789551)
[2024-12-17 04:09:15,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:15,968][root][INFO] - Training Epoch: 1/2, step 3981/7134 completed (loss: 0.1023416668176651, acc: 0.9740061163902283)
[2024-12-17 04:09:16,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:16,386][root][INFO] - Training Epoch: 1/2, step 3982/7134 completed (loss: 0.13387718796730042, acc: 0.9670014381408691)
[2024-12-17 04:09:16,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:16,789][root][INFO] - Training Epoch: 1/2, step 3983/7134 completed (loss: 0.3541179597377777, acc: 0.9319148659706116)
[2024-12-17 04:09:16,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:17,212][root][INFO] - Training Epoch: 1/2, step 3984/7134 completed (loss: 0.11401743441820145, acc: 0.9701298475265503)
[2024-12-17 04:09:17,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:17,613][root][INFO] - Training Epoch: 1/2, step 3985/7134 completed (loss: 0.04557473957538605, acc: 0.987522304058075)
[2024-12-17 04:09:17,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:18,065][root][INFO] - Training Epoch: 1/2, step 3986/7134 completed (loss: 0.23412758111953735, acc: 0.9454545378684998)
[2024-12-17 04:09:18,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:18,499][root][INFO] - Training Epoch: 1/2, step 3987/7134 completed (loss: 0.10564816743135452, acc: 0.9692898392677307)
[2024-12-17 04:09:18,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:18,940][root][INFO] - Training Epoch: 1/2, step 3988/7134 completed (loss: 0.13081105053424835, acc: 0.9646017551422119)
[2024-12-17 04:09:19,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:19,292][root][INFO] - Training Epoch: 1/2, step 3989/7134 completed (loss: 0.2344004511833191, acc: 0.9424306750297546)
[2024-12-17 04:09:19,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:19,717][root][INFO] - Training Epoch: 1/2, step 3990/7134 completed (loss: 0.08628402650356293, acc: 0.9734659790992737)
[2024-12-17 04:09:19,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:20,101][root][INFO] - Training Epoch: 1/2, step 3991/7134 completed (loss: 0.0769757479429245, acc: 0.9900990128517151)
[2024-12-17 04:09:20,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:20,499][root][INFO] - Training Epoch: 1/2, step 3992/7134 completed (loss: 0.11597225069999695, acc: 0.9810810685157776)
[2024-12-17 04:09:20,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:20,893][root][INFO] - Training Epoch: 1/2, step 3993/7134 completed (loss: 0.09685128927230835, acc: 0.9701834917068481)
[2024-12-17 04:09:21,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:21,318][root][INFO] - Training Epoch: 1/2, step 3994/7134 completed (loss: 0.09743200242519379, acc: 0.976190447807312)
[2024-12-17 04:09:21,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:21,700][root][INFO] - Training Epoch: 1/2, step 3995/7134 completed (loss: 0.14067861437797546, acc: 0.9670542478561401)
[2024-12-17 04:09:21,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:22,069][root][INFO] - Training Epoch: 1/2, step 3996/7134 completed (loss: 0.07446311414241791, acc: 0.9856262803077698)
[2024-12-17 04:09:22,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:22,460][root][INFO] - Training Epoch: 1/2, step 3997/7134 completed (loss: 0.24317967891693115, acc: 0.9516483545303345)
[2024-12-17 04:09:22,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:22,817][root][INFO] - Training Epoch: 1/2, step 3998/7134 completed (loss: 0.12958906590938568, acc: 0.9737417697906494)
[2024-12-17 04:09:22,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:23,192][root][INFO] - Training Epoch: 1/2, step 3999/7134 completed (loss: 0.09013379365205765, acc: 0.9820359349250793)
[2024-12-17 04:09:23,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:23,602][root][INFO] - Training Epoch: 1/2, step 4000/7134 completed (loss: 0.09806981682777405, acc: 0.9787644743919373)
[2024-12-17 04:09:23,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:24,011][root][INFO] - Training Epoch: 1/2, step 4001/7134 completed (loss: 0.12195567041635513, acc: 0.9681908488273621)
[2024-12-17 04:09:24,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:24,422][root][INFO] - Training Epoch: 1/2, step 4002/7134 completed (loss: 0.12465009838342667, acc: 0.9734939932823181)
[2024-12-17 04:09:24,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:24,848][root][INFO] - Training Epoch: 1/2, step 4003/7134 completed (loss: 0.15607020258903503, acc: 0.9649446606636047)
[2024-12-17 04:09:24,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:25,258][root][INFO] - Training Epoch: 1/2, step 4004/7134 completed (loss: 0.09403881430625916, acc: 0.9720279574394226)
[2024-12-17 04:09:25,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:25,673][root][INFO] - Training Epoch: 1/2, step 4005/7134 completed (loss: 0.046863604336977005, acc: 0.9843013882637024)
[2024-12-17 04:09:25,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:26,138][root][INFO] - Training Epoch: 1/2, step 4006/7134 completed (loss: 0.06291545927524567, acc: 0.9843912720680237)
[2024-12-17 04:09:26,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:26,559][root][INFO] - Training Epoch: 1/2, step 4007/7134 completed (loss: 0.07576585561037064, acc: 0.9805097579956055)
[2024-12-17 04:09:26,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:27,011][root][INFO] - Training Epoch: 1/2, step 4008/7134 completed (loss: 0.05021852254867554, acc: 0.9862579107284546)
[2024-12-17 04:09:27,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:27,443][root][INFO] - Training Epoch: 1/2, step 4009/7134 completed (loss: 0.04038860648870468, acc: 0.989347517490387)
[2024-12-17 04:09:27,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:27,902][root][INFO] - Training Epoch: 1/2, step 4010/7134 completed (loss: 0.046041250228881836, acc: 0.9921700358390808)
[2024-12-17 04:09:28,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:28,375][root][INFO] - Training Epoch: 1/2, step 4011/7134 completed (loss: 0.0548589751124382, acc: 0.9893758296966553)
[2024-12-17 04:09:28,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:28,774][root][INFO] - Training Epoch: 1/2, step 4012/7134 completed (loss: 0.038469068706035614, acc: 0.9901130199432373)
[2024-12-17 04:09:28,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:29,207][root][INFO] - Training Epoch: 1/2, step 4013/7134 completed (loss: 0.028948185965418816, acc: 0.9903537034988403)
[2024-12-17 04:09:29,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:29,654][root][INFO] - Training Epoch: 1/2, step 4014/7134 completed (loss: 0.04480454698204994, acc: 0.9874607920646667)
[2024-12-17 04:09:29,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:30,081][root][INFO] - Training Epoch: 1/2, step 4015/7134 completed (loss: 0.053336165845394135, acc: 0.9784946441650391)
[2024-12-17 04:09:30,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:30,545][root][INFO] - Training Epoch: 1/2, step 4016/7134 completed (loss: 0.08086178451776505, acc: 0.9783163070678711)
[2024-12-17 04:09:30,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:31,001][root][INFO] - Training Epoch: 1/2, step 4017/7134 completed (loss: 0.07338675111532211, acc: 0.9849884510040283)
[2024-12-17 04:09:31,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:31,448][root][INFO] - Training Epoch: 1/2, step 4018/7134 completed (loss: 0.06787554174661636, acc: 0.9854545593261719)
[2024-12-17 04:09:31,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:31,887][root][INFO] - Training Epoch: 1/2, step 4019/7134 completed (loss: 0.07871592044830322, acc: 0.9784263968467712)
[2024-12-17 04:09:32,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:32,323][root][INFO] - Training Epoch: 1/2, step 4020/7134 completed (loss: 0.06407419592142105, acc: 0.9781420826911926)
[2024-12-17 04:09:32,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:32,786][root][INFO] - Training Epoch: 1/2, step 4021/7134 completed (loss: 0.06793780624866486, acc: 0.9839572310447693)
[2024-12-17 04:09:32,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:33,235][root][INFO] - Training Epoch: 1/2, step 4022/7134 completed (loss: 0.09213747084140778, acc: 0.9815950989723206)
[2024-12-17 04:09:33,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:33,701][root][INFO] - Training Epoch: 1/2, step 4023/7134 completed (loss: 0.06349031627178192, acc: 0.9811320900917053)
[2024-12-17 04:09:33,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:34,134][root][INFO] - Training Epoch: 1/2, step 4024/7134 completed (loss: 0.06591522693634033, acc: 0.9829396605491638)
[2024-12-17 04:09:34,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:34,568][root][INFO] - Training Epoch: 1/2, step 4025/7134 completed (loss: 0.07980377227067947, acc: 0.9830124378204346)
[2024-12-17 04:09:34,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:34,983][root][INFO] - Training Epoch: 1/2, step 4026/7134 completed (loss: 0.1113637387752533, acc: 0.9778761267662048)
[2024-12-17 04:09:35,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:35,414][root][INFO] - Training Epoch: 1/2, step 4027/7134 completed (loss: 0.07521437108516693, acc: 0.973621129989624)
[2024-12-17 04:09:35,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:35,862][root][INFO] - Training Epoch: 1/2, step 4028/7134 completed (loss: 0.07563193887472153, acc: 0.9759036302566528)
[2024-12-17 04:09:36,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:36,332][root][INFO] - Training Epoch: 1/2, step 4029/7134 completed (loss: 0.04291344806551933, acc: 0.9876998662948608)
[2024-12-17 04:09:36,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:36,776][root][INFO] - Training Epoch: 1/2, step 4030/7134 completed (loss: 0.039343852549791336, acc: 0.9897330403327942)
[2024-12-17 04:09:36,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:37,191][root][INFO] - Training Epoch: 1/2, step 4031/7134 completed (loss: 0.044459447264671326, acc: 0.9868035316467285)
[2024-12-17 04:09:37,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:37,629][root][INFO] - Training Epoch: 1/2, step 4032/7134 completed (loss: 0.08202605694532394, acc: 0.9825970530509949)
[2024-12-17 04:09:37,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:38,056][root][INFO] - Training Epoch: 1/2, step 4033/7134 completed (loss: 0.0410212017595768, acc: 0.9886792302131653)
[2024-12-17 04:09:38,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:38,489][root][INFO] - Training Epoch: 1/2, step 4034/7134 completed (loss: 0.02498534508049488, acc: 0.9939098954200745)
[2024-12-17 04:09:38,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:38,998][root][INFO] - Training Epoch: 1/2, step 4035/7134 completed (loss: 0.0750715509057045, acc: 0.9822904467582703)
[2024-12-17 04:09:39,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:39,430][root][INFO] - Training Epoch: 1/2, step 4036/7134 completed (loss: 0.05420990660786629, acc: 0.9816849827766418)
[2024-12-17 04:09:39,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:39,886][root][INFO] - Training Epoch: 1/2, step 4037/7134 completed (loss: 0.03326823562383652, acc: 0.9927797913551331)
[2024-12-17 04:09:39,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:40,310][root][INFO] - Training Epoch: 1/2, step 4038/7134 completed (loss: 0.08263763785362244, acc: 0.9779917597770691)
[2024-12-17 04:09:40,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:40,705][root][INFO] - Training Epoch: 1/2, step 4039/7134 completed (loss: 0.07235978543758392, acc: 0.9758865237236023)
[2024-12-17 04:09:40,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:41,123][root][INFO] - Training Epoch: 1/2, step 4040/7134 completed (loss: 0.04851143807172775, acc: 0.982758641242981)
[2024-12-17 04:09:41,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:41,566][root][INFO] - Training Epoch: 1/2, step 4041/7134 completed (loss: 0.053873248398303986, acc: 0.9852150678634644)
[2024-12-17 04:09:41,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:41,984][root][INFO] - Training Epoch: 1/2, step 4042/7134 completed (loss: 0.04698144271969795, acc: 0.9852941036224365)
[2024-12-17 04:09:42,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:42,365][root][INFO] - Training Epoch: 1/2, step 4043/7134 completed (loss: 0.038413796573877335, acc: 0.98531574010849)
[2024-12-17 04:09:42,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:42,789][root][INFO] - Training Epoch: 1/2, step 4044/7134 completed (loss: 0.028014305979013443, acc: 0.9911616444587708)
[2024-12-17 04:09:42,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:43,224][root][INFO] - Training Epoch: 1/2, step 4045/7134 completed (loss: 0.08645666390657425, acc: 0.9819444417953491)
[2024-12-17 04:09:43,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:43,649][root][INFO] - Training Epoch: 1/2, step 4046/7134 completed (loss: 0.052688512951135635, acc: 0.9848901033401489)
[2024-12-17 04:09:43,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:44,095][root][INFO] - Training Epoch: 1/2, step 4047/7134 completed (loss: 0.06504429131746292, acc: 0.9880668520927429)
[2024-12-17 04:09:44,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:44,547][root][INFO] - Training Epoch: 1/2, step 4048/7134 completed (loss: 0.03921925649046898, acc: 0.9860140085220337)
[2024-12-17 04:09:44,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:45,046][root][INFO] - Training Epoch: 1/2, step 4049/7134 completed (loss: 0.051286786794662476, acc: 0.9885057210922241)
[2024-12-17 04:09:45,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:45,470][root][INFO] - Training Epoch: 1/2, step 4050/7134 completed (loss: 0.06753337383270264, acc: 0.980141818523407)
[2024-12-17 04:09:45,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:45,918][root][INFO] - Training Epoch: 1/2, step 4051/7134 completed (loss: 0.10008304566144943, acc: 0.9784688949584961)
[2024-12-17 04:09:46,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:46,316][root][INFO] - Training Epoch: 1/2, step 4052/7134 completed (loss: 0.04387017711997032, acc: 0.985788106918335)
[2024-12-17 04:09:46,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:46,763][root][INFO] - Training Epoch: 1/2, step 4053/7134 completed (loss: 0.06264536827802658, acc: 0.9787798523902893)
[2024-12-17 04:09:46,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:47,212][root][INFO] - Training Epoch: 1/2, step 4054/7134 completed (loss: 0.05530362203717232, acc: 0.9879999756813049)
[2024-12-17 04:09:47,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:47,664][root][INFO] - Training Epoch: 1/2, step 4055/7134 completed (loss: 0.06537488102912903, acc: 0.981796145439148)
[2024-12-17 04:09:47,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:48,117][root][INFO] - Training Epoch: 1/2, step 4056/7134 completed (loss: 0.04795684292912483, acc: 0.9866666793823242)
[2024-12-17 04:09:48,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:48,586][root][INFO] - Training Epoch: 1/2, step 4057/7134 completed (loss: 0.07809681445360184, acc: 0.9860917925834656)
[2024-12-17 04:09:48,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:48,976][root][INFO] - Training Epoch: 1/2, step 4058/7134 completed (loss: 0.1655300259590149, acc: 0.9674952030181885)
[2024-12-17 04:09:49,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:49,384][root][INFO] - Training Epoch: 1/2, step 4059/7134 completed (loss: 0.08306907117366791, acc: 0.9781022071838379)
[2024-12-17 04:09:49,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:49,809][root][INFO] - Training Epoch: 1/2, step 4060/7134 completed (loss: 0.04561907425522804, acc: 0.9876352548599243)
[2024-12-17 04:09:49,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:50,248][root][INFO] - Training Epoch: 1/2, step 4061/7134 completed (loss: 0.041936300694942474, acc: 0.9928774833679199)
[2024-12-17 04:09:50,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:50,686][root][INFO] - Training Epoch: 1/2, step 4062/7134 completed (loss: 0.03460245206952095, acc: 0.9905511736869812)
[2024-12-17 04:09:50,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:51,098][root][INFO] - Training Epoch: 1/2, step 4063/7134 completed (loss: 0.04737216234207153, acc: 0.982332170009613)
[2024-12-17 04:09:51,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:51,532][root][INFO] - Training Epoch: 1/2, step 4064/7134 completed (loss: 0.02623765543103218, acc: 0.9878970980644226)
[2024-12-17 04:09:51,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:51,962][root][INFO] - Training Epoch: 1/2, step 4065/7134 completed (loss: 0.051241740584373474, acc: 0.9862068891525269)
[2024-12-17 04:09:52,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:52,398][root][INFO] - Training Epoch: 1/2, step 4066/7134 completed (loss: 0.03187001124024391, acc: 0.9930555820465088)
[2024-12-17 04:09:52,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:52,816][root][INFO] - Training Epoch: 1/2, step 4067/7134 completed (loss: 0.04417406767606735, acc: 0.9869281053543091)
[2024-12-17 04:09:52,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:53,233][root][INFO] - Training Epoch: 1/2, step 4068/7134 completed (loss: 0.04139172285795212, acc: 0.9870370626449585)
[2024-12-17 04:09:53,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:53,650][root][INFO] - Training Epoch: 1/2, step 4069/7134 completed (loss: 0.04685141518712044, acc: 0.9874804615974426)
[2024-12-17 04:09:53,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:54,103][root][INFO] - Training Epoch: 1/2, step 4070/7134 completed (loss: 0.04121921956539154, acc: 0.9863013625144958)
[2024-12-17 04:09:54,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:54,501][root][INFO] - Training Epoch: 1/2, step 4071/7134 completed (loss: 0.05682658404111862, acc: 0.9802306294441223)
[2024-12-17 04:09:54,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:54,927][root][INFO] - Training Epoch: 1/2, step 4072/7134 completed (loss: 0.034775618463754654, acc: 0.9870129823684692)
[2024-12-17 04:09:55,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:55,360][root][INFO] - Training Epoch: 1/2, step 4073/7134 completed (loss: 0.04138970747590065, acc: 0.9885057210922241)
[2024-12-17 04:09:55,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:55,793][root][INFO] - Training Epoch: 1/2, step 4074/7134 completed (loss: 0.057193461805582047, acc: 0.9856938719749451)
[2024-12-17 04:09:55,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:56,216][root][INFO] - Training Epoch: 1/2, step 4075/7134 completed (loss: 0.03127184882760048, acc: 0.9910045266151428)
[2024-12-17 04:09:56,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:56,657][root][INFO] - Training Epoch: 1/2, step 4076/7134 completed (loss: 0.02836645394563675, acc: 0.9927641153335571)
[2024-12-17 04:09:56,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:57,084][root][INFO] - Training Epoch: 1/2, step 4077/7134 completed (loss: 0.0662173256278038, acc: 0.9830795526504517)
[2024-12-17 04:09:57,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:57,497][root][INFO] - Training Epoch: 1/2, step 4078/7134 completed (loss: 0.03501405566930771, acc: 0.9871794581413269)
[2024-12-17 04:09:57,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:57,876][root][INFO] - Training Epoch: 1/2, step 4079/7134 completed (loss: 0.04029381275177002, acc: 0.9928698539733887)
[2024-12-17 04:09:57,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:58,280][root][INFO] - Training Epoch: 1/2, step 4080/7134 completed (loss: 0.022369980812072754, acc: 0.9952531456947327)
[2024-12-17 04:09:58,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:58,709][root][INFO] - Training Epoch: 1/2, step 4081/7134 completed (loss: 0.018025357276201248, acc: 0.9966996908187866)
[2024-12-17 04:09:58,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:59,113][root][INFO] - Training Epoch: 1/2, step 4082/7134 completed (loss: 0.10826628655195236, acc: 0.9704251289367676)
[2024-12-17 04:09:59,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:59,538][root][INFO] - Training Epoch: 1/2, step 4083/7134 completed (loss: 0.06874117255210876, acc: 0.9805389046669006)
[2024-12-17 04:09:59,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:09:59,959][root][INFO] - Training Epoch: 1/2, step 4084/7134 completed (loss: 0.1570126861333847, acc: 0.95686274766922)
[2024-12-17 04:10:00,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:00,385][root][INFO] - Training Epoch: 1/2, step 4085/7134 completed (loss: 0.06620734930038452, acc: 0.9878706336021423)
[2024-12-17 04:10:00,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:00,795][root][INFO] - Training Epoch: 1/2, step 4086/7134 completed (loss: 0.13427715003490448, acc: 0.972176730632782)
[2024-12-17 04:10:00,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:01,233][root][INFO] - Training Epoch: 1/2, step 4087/7134 completed (loss: 0.033055778592824936, acc: 0.9935400485992432)
[2024-12-17 04:10:01,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:01,663][root][INFO] - Training Epoch: 1/2, step 4088/7134 completed (loss: 0.12662462890148163, acc: 0.9713930487632751)
[2024-12-17 04:10:01,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:02,077][root][INFO] - Training Epoch: 1/2, step 4089/7134 completed (loss: 0.11917748302221298, acc: 0.9715808033943176)
[2024-12-17 04:10:02,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:02,522][root][INFO] - Training Epoch: 1/2, step 4090/7134 completed (loss: 0.13982395827770233, acc: 0.9683377146720886)
[2024-12-17 04:10:02,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:02,937][root][INFO] - Training Epoch: 1/2, step 4091/7134 completed (loss: 0.13350188732147217, acc: 0.9679595232009888)
[2024-12-17 04:10:03,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:03,384][root][INFO] - Training Epoch: 1/2, step 4092/7134 completed (loss: 0.10203107446432114, acc: 0.9768339991569519)
[2024-12-17 04:10:03,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:03,789][root][INFO] - Training Epoch: 1/2, step 4093/7134 completed (loss: 0.06184358894824982, acc: 0.9799635410308838)
[2024-12-17 04:10:03,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:04,205][root][INFO] - Training Epoch: 1/2, step 4094/7134 completed (loss: 0.10922946035861969, acc: 0.9699699878692627)
[2024-12-17 04:10:04,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:04,651][root][INFO] - Training Epoch: 1/2, step 4095/7134 completed (loss: 0.07812819629907608, acc: 0.9710564613342285)
[2024-12-17 04:10:04,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:05,033][root][INFO] - Training Epoch: 1/2, step 4096/7134 completed (loss: 0.11564940214157104, acc: 0.9791044592857361)
[2024-12-17 04:10:05,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:05,496][root][INFO] - Training Epoch: 1/2, step 4097/7134 completed (loss: 0.10621941089630127, acc: 0.9709677696228027)
[2024-12-17 04:10:05,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:05,919][root][INFO] - Training Epoch: 1/2, step 4098/7134 completed (loss: 0.07305485010147095, acc: 0.9837398529052734)
[2024-12-17 04:10:06,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:06,338][root][INFO] - Training Epoch: 1/2, step 4099/7134 completed (loss: 0.06572368741035461, acc: 0.9841549396514893)
[2024-12-17 04:10:06,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:06,800][root][INFO] - Training Epoch: 1/2, step 4100/7134 completed (loss: 0.022793008014559746, acc: 0.9909228682518005)
[2024-12-17 04:10:06,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:07,213][root][INFO] - Training Epoch: 1/2, step 4101/7134 completed (loss: 0.023318294435739517, acc: 0.9923954606056213)
[2024-12-17 04:10:07,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:07,630][root][INFO] - Training Epoch: 1/2, step 4102/7134 completed (loss: 0.06542876362800598, acc: 0.9817184805870056)
[2024-12-17 04:10:07,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:08,084][root][INFO] - Training Epoch: 1/2, step 4103/7134 completed (loss: 0.0204311590641737, acc: 0.9955157041549683)
[2024-12-17 04:10:08,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:08,516][root][INFO] - Training Epoch: 1/2, step 4104/7134 completed (loss: 0.042968712747097015, acc: 0.9864636063575745)
[2024-12-17 04:10:08,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:08,947][root][INFO] - Training Epoch: 1/2, step 4105/7134 completed (loss: 0.0404035747051239, acc: 0.9894259572029114)
[2024-12-17 04:10:09,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:09,357][root][INFO] - Training Epoch: 1/2, step 4106/7134 completed (loss: 0.06025128439068794, acc: 0.9861963391304016)
[2024-12-17 04:10:09,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:09,771][root][INFO] - Training Epoch: 1/2, step 4107/7134 completed (loss: 0.042383864521980286, acc: 0.9932773113250732)
[2024-12-17 04:10:09,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:10,170][root][INFO] - Training Epoch: 1/2, step 4108/7134 completed (loss: 0.05383722856640816, acc: 0.983818769454956)
[2024-12-17 04:10:10,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:10,584][root][INFO] - Training Epoch: 1/2, step 4109/7134 completed (loss: 0.0248702485114336, acc: 0.9903692007064819)
[2024-12-17 04:10:10,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:10,989][root][INFO] - Training Epoch: 1/2, step 4110/7134 completed (loss: 0.023695072159171104, acc: 0.9948979616165161)
[2024-12-17 04:10:11,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:11,417][root][INFO] - Training Epoch: 1/2, step 4111/7134 completed (loss: 0.0218181349337101, acc: 0.9952681660652161)
[2024-12-17 04:10:11,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:11,852][root][INFO] - Training Epoch: 1/2, step 4112/7134 completed (loss: 0.050111640244722366, acc: 0.9874551892280579)
[2024-12-17 04:10:11,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:12,282][root][INFO] - Training Epoch: 1/2, step 4113/7134 completed (loss: 0.04909762740135193, acc: 0.9829457402229309)
[2024-12-17 04:10:12,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:12,685][root][INFO] - Training Epoch: 1/2, step 4114/7134 completed (loss: 0.12798848748207092, acc: 0.9674796462059021)
[2024-12-17 04:10:12,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:13,089][root][INFO] - Training Epoch: 1/2, step 4115/7134 completed (loss: 0.1358068734407425, acc: 0.9664179086685181)
[2024-12-17 04:10:13,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:13,532][root][INFO] - Training Epoch: 1/2, step 4116/7134 completed (loss: 0.026388702914118767, acc: 0.990227997303009)
[2024-12-17 04:10:13,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:13,950][root][INFO] - Training Epoch: 1/2, step 4117/7134 completed (loss: 0.031072909012436867, acc: 0.9905362725257874)
[2024-12-17 04:10:14,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:14,355][root][INFO] - Training Epoch: 1/2, step 4118/7134 completed (loss: 0.04594791680574417, acc: 0.9852579832077026)
[2024-12-17 04:10:14,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:14,761][root][INFO] - Training Epoch: 1/2, step 4119/7134 completed (loss: 0.0966595783829689, acc: 0.9757673740386963)
[2024-12-17 04:10:14,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:15,154][root][INFO] - Training Epoch: 1/2, step 4120/7134 completed (loss: 0.05264357849955559, acc: 0.9884678721427917)
[2024-12-17 04:10:15,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:15,571][root][INFO] - Training Epoch: 1/2, step 4121/7134 completed (loss: 0.06635604053735733, acc: 0.9886363744735718)
[2024-12-17 04:10:15,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:15,986][root][INFO] - Training Epoch: 1/2, step 4122/7134 completed (loss: 0.024458302184939384, acc: 0.9942747950553894)
[2024-12-17 04:10:16,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:16,406][root][INFO] - Training Epoch: 1/2, step 4123/7134 completed (loss: 0.05278513953089714, acc: 0.9879336357116699)
[2024-12-17 04:10:16,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:16,846][root][INFO] - Training Epoch: 1/2, step 4124/7134 completed (loss: 0.04904276877641678, acc: 0.9886845946311951)
[2024-12-17 04:10:16,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:17,255][root][INFO] - Training Epoch: 1/2, step 4125/7134 completed (loss: 0.04116256907582283, acc: 0.9882352948188782)
[2024-12-17 04:10:17,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:17,676][root][INFO] - Training Epoch: 1/2, step 4126/7134 completed (loss: 0.04578172042965889, acc: 0.9900850057601929)
[2024-12-17 04:10:17,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:18,097][root][INFO] - Training Epoch: 1/2, step 4127/7134 completed (loss: 0.0423491932451725, acc: 0.9921875)
[2024-12-17 04:10:18,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:18,524][root][INFO] - Training Epoch: 1/2, step 4128/7134 completed (loss: 0.03151210397481918, acc: 0.9906103014945984)
[2024-12-17 04:10:18,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:18,973][root][INFO] - Training Epoch: 1/2, step 4129/7134 completed (loss: 0.04924072325229645, acc: 0.9866468906402588)
[2024-12-17 04:10:19,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:19,375][root][INFO] - Training Epoch: 1/2, step 4130/7134 completed (loss: 0.045244619250297546, acc: 0.9826589822769165)
[2024-12-17 04:10:19,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:19,784][root][INFO] - Training Epoch: 1/2, step 4131/7134 completed (loss: 0.0558832511305809, acc: 0.9833641648292542)
[2024-12-17 04:10:19,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:20,203][root][INFO] - Training Epoch: 1/2, step 4132/7134 completed (loss: 0.049181412905454636, acc: 0.9866071343421936)
[2024-12-17 04:10:20,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:20,598][root][INFO] - Training Epoch: 1/2, step 4133/7134 completed (loss: 0.06474034488201141, acc: 0.9833333492279053)
[2024-12-17 04:10:20,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:21,009][root][INFO] - Training Epoch: 1/2, step 4134/7134 completed (loss: 0.1162596121430397, acc: 0.9691942930221558)
[2024-12-17 04:10:21,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:21,449][root][INFO] - Training Epoch: 1/2, step 4135/7134 completed (loss: 0.040033627301454544, acc: 0.9875665903091431)
[2024-12-17 04:10:21,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:21,897][root][INFO] - Training Epoch: 1/2, step 4136/7134 completed (loss: 0.025052698329091072, acc: 0.991150438785553)
[2024-12-17 04:10:22,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:22,324][root][INFO] - Training Epoch: 1/2, step 4137/7134 completed (loss: 0.04639262333512306, acc: 0.98828125)
[2024-12-17 04:10:22,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:22,732][root][INFO] - Training Epoch: 1/2, step 4138/7134 completed (loss: 0.05725087970495224, acc: 0.9874607920646667)
[2024-12-17 04:10:22,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:23,132][root][INFO] - Training Epoch: 1/2, step 4139/7134 completed (loss: 0.05191148445010185, acc: 0.9849785566329956)
[2024-12-17 04:10:23,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:23,568][root][INFO] - Training Epoch: 1/2, step 4140/7134 completed (loss: 0.056993525475263596, acc: 0.9862068891525269)
[2024-12-17 04:10:23,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:24,037][root][INFO] - Training Epoch: 1/2, step 4141/7134 completed (loss: 0.12195289880037308, acc: 0.9684813618659973)
[2024-12-17 04:10:24,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:24,486][root][INFO] - Training Epoch: 1/2, step 4142/7134 completed (loss: 0.13103868067264557, acc: 0.9691075682640076)
[2024-12-17 04:10:24,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:24,963][root][INFO] - Training Epoch: 1/2, step 4143/7134 completed (loss: 0.06769116222858429, acc: 0.9836734533309937)
[2024-12-17 04:10:25,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:25,437][root][INFO] - Training Epoch: 1/2, step 4144/7134 completed (loss: 0.12025943398475647, acc: 0.962414562702179)
[2024-12-17 04:10:25,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:25,872][root][INFO] - Training Epoch: 1/2, step 4145/7134 completed (loss: 0.07092804461717606, acc: 0.9783393740653992)
[2024-12-17 04:10:25,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:26,249][root][INFO] - Training Epoch: 1/2, step 4146/7134 completed (loss: 0.15678974986076355, acc: 0.9575757384300232)
[2024-12-17 04:10:26,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:26,669][root][INFO] - Training Epoch: 1/2, step 4147/7134 completed (loss: 0.16382932662963867, acc: 0.9501915574073792)
[2024-12-17 04:10:26,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:27,086][root][INFO] - Training Epoch: 1/2, step 4148/7134 completed (loss: 0.31115177273750305, acc: 0.9208494424819946)
[2024-12-17 04:10:27,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:27,466][root][INFO] - Training Epoch: 1/2, step 4149/7134 completed (loss: 0.2505471110343933, acc: 0.9493333101272583)
[2024-12-17 04:10:27,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:27,879][root][INFO] - Training Epoch: 1/2, step 4150/7134 completed (loss: 0.21838243305683136, acc: 0.9336016178131104)
[2024-12-17 04:10:28,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:28,378][root][INFO] - Training Epoch: 1/2, step 4151/7134 completed (loss: 0.24760951101779938, acc: 0.9384058117866516)
[2024-12-17 04:10:28,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:28,807][root][INFO] - Training Epoch: 1/2, step 4152/7134 completed (loss: 0.11155864596366882, acc: 0.9644513130187988)
[2024-12-17 04:10:28,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:29,244][root][INFO] - Training Epoch: 1/2, step 4153/7134 completed (loss: 0.16389279067516327, acc: 0.9555214643478394)
[2024-12-17 04:10:29,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:29,708][root][INFO] - Training Epoch: 1/2, step 4154/7134 completed (loss: 0.1655346006155014, acc: 0.9444444179534912)
[2024-12-17 04:10:29,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:30,149][root][INFO] - Training Epoch: 1/2, step 4155/7134 completed (loss: 0.15646985173225403, acc: 0.958833634853363)
[2024-12-17 04:10:30,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:30,612][root][INFO] - Training Epoch: 1/2, step 4156/7134 completed (loss: 0.1463957577943802, acc: 0.9610570073127747)
[2024-12-17 04:10:30,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:31,034][root][INFO] - Training Epoch: 1/2, step 4157/7134 completed (loss: 0.10199911147356033, acc: 0.970059871673584)
[2024-12-17 04:10:31,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:31,474][root][INFO] - Training Epoch: 1/2, step 4158/7134 completed (loss: 0.23529917001724243, acc: 0.9357326626777649)
[2024-12-17 04:10:31,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:31,916][root][INFO] - Training Epoch: 1/2, step 4159/7134 completed (loss: 0.12552471458911896, acc: 0.9728353023529053)
[2024-12-17 04:10:32,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:32,360][root][INFO] - Training Epoch: 1/2, step 4160/7134 completed (loss: 0.16624753177165985, acc: 0.9509434103965759)
[2024-12-17 04:10:32,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:32,839][root][INFO] - Training Epoch: 1/2, step 4161/7134 completed (loss: 0.12589506804943085, acc: 0.9698795080184937)
[2024-12-17 04:10:32,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:33,281][root][INFO] - Training Epoch: 1/2, step 4162/7134 completed (loss: 0.13269232213497162, acc: 0.9582712650299072)
[2024-12-17 04:10:33,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:33,713][root][INFO] - Training Epoch: 1/2, step 4163/7134 completed (loss: 0.1432056725025177, acc: 0.9652042388916016)
[2024-12-17 04:10:33,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:34,133][root][INFO] - Training Epoch: 1/2, step 4164/7134 completed (loss: 0.09058646857738495, acc: 0.9825834631919861)
[2024-12-17 04:10:34,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:34,591][root][INFO] - Training Epoch: 1/2, step 4165/7134 completed (loss: 0.09689037501811981, acc: 0.9737827777862549)
[2024-12-17 04:10:34,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:35,036][root][INFO] - Training Epoch: 1/2, step 4166/7134 completed (loss: 0.09061457961797714, acc: 0.9735682606697083)
[2024-12-17 04:10:35,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:35,466][root][INFO] - Training Epoch: 1/2, step 4167/7134 completed (loss: 0.04431961476802826, acc: 0.984375)
[2024-12-17 04:10:35,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:35,903][root][INFO] - Training Epoch: 1/2, step 4168/7134 completed (loss: 0.07714813202619553, acc: 0.9774305820465088)
[2024-12-17 04:10:36,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:36,377][root][INFO] - Training Epoch: 1/2, step 4169/7134 completed (loss: 0.10906048119068146, acc: 0.971488893032074)
[2024-12-17 04:10:36,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:36,858][root][INFO] - Training Epoch: 1/2, step 4170/7134 completed (loss: 0.15813368558883667, acc: 0.9532908797264099)
[2024-12-17 04:10:36,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:37,351][root][INFO] - Training Epoch: 1/2, step 4171/7134 completed (loss: 0.05301414430141449, acc: 0.985005795955658)
[2024-12-17 04:10:37,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:37,780][root][INFO] - Training Epoch: 1/2, step 4172/7134 completed (loss: 0.08774662762880325, acc: 0.9788029789924622)
[2024-12-17 04:10:37,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:38,192][root][INFO] - Training Epoch: 1/2, step 4173/7134 completed (loss: 0.0979880541563034, acc: 0.9828326106071472)
[2024-12-17 04:10:38,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:38,600][root][INFO] - Training Epoch: 1/2, step 4174/7134 completed (loss: 0.02990829385817051, acc: 0.9885057210922241)
[2024-12-17 04:10:38,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:39,014][root][INFO] - Training Epoch: 1/2, step 4175/7134 completed (loss: 0.04927392676472664, acc: 0.9845361113548279)
[2024-12-17 04:10:39,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:39,447][root][INFO] - Training Epoch: 1/2, step 4176/7134 completed (loss: 0.03946579620242119, acc: 0.992548406124115)
[2024-12-17 04:10:39,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:39,917][root][INFO] - Training Epoch: 1/2, step 4177/7134 completed (loss: 0.046244386583566666, acc: 0.9881734848022461)
[2024-12-17 04:10:40,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:40,361][root][INFO] - Training Epoch: 1/2, step 4178/7134 completed (loss: 0.04853195697069168, acc: 0.9848942756652832)
[2024-12-17 04:10:40,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:40,844][root][INFO] - Training Epoch: 1/2, step 4179/7134 completed (loss: 0.04116188734769821, acc: 0.9855642914772034)
[2024-12-17 04:10:40,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:41,290][root][INFO] - Training Epoch: 1/2, step 4180/7134 completed (loss: 0.0318363793194294, acc: 0.991525411605835)
[2024-12-17 04:10:41,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:41,716][root][INFO] - Training Epoch: 1/2, step 4181/7134 completed (loss: 0.029737524688243866, acc: 0.9934747219085693)
[2024-12-17 04:10:41,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:42,147][root][INFO] - Training Epoch: 1/2, step 4182/7134 completed (loss: 0.0271161999553442, acc: 0.9902642369270325)
[2024-12-17 04:10:42,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:42,609][root][INFO] - Training Epoch: 1/2, step 4183/7134 completed (loss: 0.05800383538007736, acc: 0.9860917925834656)
[2024-12-17 04:10:42,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:43,031][root][INFO] - Training Epoch: 1/2, step 4184/7134 completed (loss: 0.06053965538740158, acc: 0.9840849041938782)
[2024-12-17 04:10:43,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:43,474][root][INFO] - Training Epoch: 1/2, step 4185/7134 completed (loss: 0.02477656677365303, acc: 0.9954338073730469)
[2024-12-17 04:10:43,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:43,937][root][INFO] - Training Epoch: 1/2, step 4186/7134 completed (loss: 0.10105443745851517, acc: 0.9795427322387695)
[2024-12-17 04:10:44,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:44,352][root][INFO] - Training Epoch: 1/2, step 4187/7134 completed (loss: 0.01934048719704151, acc: 0.99609375)
[2024-12-17 04:10:44,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:44,820][root][INFO] - Training Epoch: 1/2, step 4188/7134 completed (loss: 0.027722954750061035, acc: 0.9925000071525574)
[2024-12-17 04:10:44,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:45,265][root][INFO] - Training Epoch: 1/2, step 4189/7134 completed (loss: 0.030681513249874115, acc: 0.9944055676460266)
[2024-12-17 04:10:45,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:45,693][root][INFO] - Training Epoch: 1/2, step 4190/7134 completed (loss: 0.03478892892599106, acc: 0.9914772510528564)
[2024-12-17 04:10:45,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:46,028][root][INFO] - Training Epoch: 1/2, step 4191/7134 completed (loss: 0.038966428488492966, acc: 0.9930875301361084)
[2024-12-17 04:10:46,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:46,456][root][INFO] - Training Epoch: 1/2, step 4192/7134 completed (loss: 0.035801827907562256, acc: 0.9920127987861633)
[2024-12-17 04:10:46,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:46,897][root][INFO] - Training Epoch: 1/2, step 4193/7134 completed (loss: 0.045077044516801834, acc: 0.990641713142395)
[2024-12-17 04:10:46,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:47,347][root][INFO] - Training Epoch: 1/2, step 4194/7134 completed (loss: 0.018461184576153755, acc: 0.9924356937408447)
[2024-12-17 04:10:47,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:47,758][root][INFO] - Training Epoch: 1/2, step 4195/7134 completed (loss: 0.06520605087280273, acc: 0.9850948452949524)
[2024-12-17 04:10:47,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:48,156][root][INFO] - Training Epoch: 1/2, step 4196/7134 completed (loss: 0.028538869693875313, acc: 0.9896193742752075)
[2024-12-17 04:10:48,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:48,610][root][INFO] - Training Epoch: 1/2, step 4197/7134 completed (loss: 0.0510580912232399, acc: 0.9844760894775391)
[2024-12-17 04:10:48,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:49,051][root][INFO] - Training Epoch: 1/2, step 4198/7134 completed (loss: 0.03373167663812637, acc: 0.9902777671813965)
[2024-12-17 04:10:49,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:49,463][root][INFO] - Training Epoch: 1/2, step 4199/7134 completed (loss: 0.07033344358205795, acc: 0.9817517995834351)
[2024-12-17 04:10:49,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:49,866][root][INFO] - Training Epoch: 1/2, step 4200/7134 completed (loss: 0.07737927883863449, acc: 0.9784946441650391)
[2024-12-17 04:10:49,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:50,284][root][INFO] - Training Epoch: 1/2, step 4201/7134 completed (loss: 0.027647104114294052, acc: 0.9948630332946777)
[2024-12-17 04:10:50,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:50,748][root][INFO] - Training Epoch: 1/2, step 4202/7134 completed (loss: 0.06447051465511322, acc: 0.9864341020584106)
[2024-12-17 04:10:50,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:51,209][root][INFO] - Training Epoch: 1/2, step 4203/7134 completed (loss: 0.07682407647371292, acc: 0.9781591296195984)
[2024-12-17 04:10:51,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:51,624][root][INFO] - Training Epoch: 1/2, step 4204/7134 completed (loss: 0.13639694452285767, acc: 0.9663742780685425)
[2024-12-17 04:10:51,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:52,025][root][INFO] - Training Epoch: 1/2, step 4205/7134 completed (loss: 0.08474081754684448, acc: 0.9784172773361206)
[2024-12-17 04:10:52,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:52,470][root][INFO] - Training Epoch: 1/2, step 4206/7134 completed (loss: 0.1299060583114624, acc: 0.9717912673950195)
[2024-12-17 04:10:52,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:52,885][root][INFO] - Training Epoch: 1/2, step 4207/7134 completed (loss: 0.09424451738595963, acc: 0.9840764403343201)
[2024-12-17 04:10:52,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:53,278][root][INFO] - Training Epoch: 1/2, step 4208/7134 completed (loss: 0.12104859203100204, acc: 0.979266345500946)
[2024-12-17 04:10:53,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:53,696][root][INFO] - Training Epoch: 1/2, step 4209/7134 completed (loss: 0.1398569941520691, acc: 0.9716714024543762)
[2024-12-17 04:10:53,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:54,126][root][INFO] - Training Epoch: 1/2, step 4210/7134 completed (loss: 0.027254611253738403, acc: 0.9938650131225586)
[2024-12-17 04:10:54,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:54,442][root][INFO] - Training Epoch: 1/2, step 4211/7134 completed (loss: 0.0598539374768734, acc: 0.9907833933830261)
[2024-12-17 04:10:54,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:54,827][root][INFO] - Training Epoch: 1/2, step 4212/7134 completed (loss: 0.0642281174659729, acc: 0.9819967150688171)
[2024-12-17 04:10:54,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:55,272][root][INFO] - Training Epoch: 1/2, step 4213/7134 completed (loss: 0.034531623125076294, acc: 0.9899857044219971)
[2024-12-17 04:10:55,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:55,717][root][INFO] - Training Epoch: 1/2, step 4214/7134 completed (loss: 0.10458169132471085, acc: 0.9776119589805603)
[2024-12-17 04:10:55,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:56,100][root][INFO] - Training Epoch: 1/2, step 4215/7134 completed (loss: 0.07690377533435822, acc: 0.9868131875991821)
[2024-12-17 04:10:56,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:56,555][root][INFO] - Training Epoch: 1/2, step 4216/7134 completed (loss: 0.06677280366420746, acc: 0.9817184805870056)
[2024-12-17 04:10:56,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:56,940][root][INFO] - Training Epoch: 1/2, step 4217/7134 completed (loss: 0.04785716533660889, acc: 0.9846153855323792)
[2024-12-17 04:10:57,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:57,331][root][INFO] - Training Epoch: 1/2, step 4218/7134 completed (loss: 0.10447295010089874, acc: 0.9752577543258667)
[2024-12-17 04:10:57,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:57,660][root][INFO] - Training Epoch: 1/2, step 4219/7134 completed (loss: 0.08447474986314774, acc: 0.9759036302566528)
[2024-12-17 04:10:57,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:58,112][root][INFO] - Training Epoch: 1/2, step 4220/7134 completed (loss: 0.06508523225784302, acc: 0.9856114983558655)
[2024-12-17 04:10:58,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:58,555][root][INFO] - Training Epoch: 1/2, step 4221/7134 completed (loss: 0.049821026623249054, acc: 0.9876106381416321)
[2024-12-17 04:10:58,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:58,941][root][INFO] - Training Epoch: 1/2, step 4222/7134 completed (loss: 0.16097426414489746, acc: 0.9755555391311646)
[2024-12-17 04:10:59,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:59,353][root][INFO] - Training Epoch: 1/2, step 4223/7134 completed (loss: 0.09408534318208694, acc: 0.9748344421386719)
[2024-12-17 04:10:59,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:10:59,758][root][INFO] - Training Epoch: 1/2, step 4224/7134 completed (loss: 0.0936930701136589, acc: 0.9762418866157532)
[2024-12-17 04:10:59,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:00,187][root][INFO] - Training Epoch: 1/2, step 4225/7134 completed (loss: 0.14573605358600616, acc: 0.9626485705375671)
[2024-12-17 04:11:00,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:00,635][root][INFO] - Training Epoch: 1/2, step 4226/7134 completed (loss: 0.09383807331323624, acc: 0.9667943716049194)
[2024-12-17 04:11:00,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:01,007][root][INFO] - Training Epoch: 1/2, step 4227/7134 completed (loss: 0.15636734664440155, acc: 0.9705159664154053)
[2024-12-17 04:11:01,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:01,419][root][INFO] - Training Epoch: 1/2, step 4228/7134 completed (loss: 0.19738301634788513, acc: 0.9551724195480347)
[2024-12-17 04:11:01,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:01,823][root][INFO] - Training Epoch: 1/2, step 4229/7134 completed (loss: 0.12192351371049881, acc: 0.9811320900917053)
[2024-12-17 04:11:01,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:02,195][root][INFO] - Training Epoch: 1/2, step 4230/7134 completed (loss: 0.10029741376638412, acc: 0.9764705896377563)
[2024-12-17 04:11:02,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:02,628][root][INFO] - Training Epoch: 1/2, step 4231/7134 completed (loss: 0.22238929569721222, acc: 0.950276255607605)
[2024-12-17 04:11:02,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:03,053][root][INFO] - Training Epoch: 1/2, step 4232/7134 completed (loss: 0.14722684025764465, acc: 0.9557251930236816)
[2024-12-17 04:11:03,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:03,467][root][INFO] - Training Epoch: 1/2, step 4233/7134 completed (loss: 0.11166250705718994, acc: 0.9732888340950012)
[2024-12-17 04:11:03,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:03,878][root][INFO] - Training Epoch: 1/2, step 4234/7134 completed (loss: 0.1010444238781929, acc: 0.9793322682380676)
[2024-12-17 04:11:04,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:04,325][root][INFO] - Training Epoch: 1/2, step 4235/7134 completed (loss: 0.08791393786668777, acc: 0.9747235178947449)
[2024-12-17 04:11:04,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:04,716][root][INFO] - Training Epoch: 1/2, step 4236/7134 completed (loss: 0.028839807957410812, acc: 0.9949495196342468)
[2024-12-17 04:11:04,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:05,120][root][INFO] - Training Epoch: 1/2, step 4237/7134 completed (loss: 0.10713919252157211, acc: 0.969072163105011)
[2024-12-17 04:11:05,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:05,547][root][INFO] - Training Epoch: 1/2, step 4238/7134 completed (loss: 0.07761859893798828, acc: 0.9754500985145569)
[2024-12-17 04:11:05,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:05,945][root][INFO] - Training Epoch: 1/2, step 4239/7134 completed (loss: 0.044863589107990265, acc: 0.9904000163078308)
[2024-12-17 04:11:06,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:06,358][root][INFO] - Training Epoch: 1/2, step 4240/7134 completed (loss: 0.07942864298820496, acc: 0.9789983630180359)
[2024-12-17 04:11:06,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:06,778][root][INFO] - Training Epoch: 1/2, step 4241/7134 completed (loss: 0.037910111248493195, acc: 0.989154040813446)
[2024-12-17 04:11:06,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:07,148][root][INFO] - Training Epoch: 1/2, step 4242/7134 completed (loss: 0.10740876197814941, acc: 0.9732739329338074)
[2024-12-17 04:11:07,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:07,580][root][INFO] - Training Epoch: 1/2, step 4243/7134 completed (loss: 0.09945860505104065, acc: 0.9801084995269775)
[2024-12-17 04:11:07,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:07,942][root][INFO] - Training Epoch: 1/2, step 4244/7134 completed (loss: 0.0742592066526413, acc: 0.9889135360717773)
[2024-12-17 04:11:08,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:08,293][root][INFO] - Training Epoch: 1/2, step 4245/7134 completed (loss: 0.059316281229257584, acc: 0.9902200698852539)
[2024-12-17 04:11:08,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:08,715][root][INFO] - Training Epoch: 1/2, step 4246/7134 completed (loss: 0.07155527174472809, acc: 0.9825673699378967)
[2024-12-17 04:11:08,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:09,110][root][INFO] - Training Epoch: 1/2, step 4247/7134 completed (loss: 0.06721096485853195, acc: 0.9803921580314636)
[2024-12-17 04:11:09,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:09,521][root][INFO] - Training Epoch: 1/2, step 4248/7134 completed (loss: 0.10490138828754425, acc: 0.9711538553237915)
[2024-12-17 04:11:09,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:09,998][root][INFO] - Training Epoch: 1/2, step 4249/7134 completed (loss: 0.09091097116470337, acc: 0.9793650507926941)
[2024-12-17 04:11:10,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:10,367][root][INFO] - Training Epoch: 1/2, step 4250/7134 completed (loss: 0.12054356932640076, acc: 0.9745222926139832)
[2024-12-17 04:11:10,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:10,780][root][INFO] - Training Epoch: 1/2, step 4251/7134 completed (loss: 0.07264408469200134, acc: 0.9819079041481018)
[2024-12-17 04:11:10,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:11,187][root][INFO] - Training Epoch: 1/2, step 4252/7134 completed (loss: 0.08431881666183472, acc: 0.9761525988578796)
[2024-12-17 04:11:11,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:11,615][root][INFO] - Training Epoch: 1/2, step 4253/7134 completed (loss: 0.10832174867391586, acc: 0.9761388301849365)
[2024-12-17 04:11:11,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:11,998][root][INFO] - Training Epoch: 1/2, step 4254/7134 completed (loss: 0.0417967215180397, acc: 0.9925187230110168)
[2024-12-17 04:11:12,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:12,447][root][INFO] - Training Epoch: 1/2, step 4255/7134 completed (loss: 0.0644228383898735, acc: 0.9794520735740662)
[2024-12-17 04:11:12,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:12,855][root][INFO] - Training Epoch: 1/2, step 4256/7134 completed (loss: 0.07044187933206558, acc: 0.9796379804611206)
[2024-12-17 04:11:12,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:13,271][root][INFO] - Training Epoch: 1/2, step 4257/7134 completed (loss: 0.04395153000950813, acc: 0.9928698539733887)
[2024-12-17 04:11:13,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:13,682][root][INFO] - Training Epoch: 1/2, step 4258/7134 completed (loss: 0.02436729706823826, acc: 0.9961832165718079)
[2024-12-17 04:11:13,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:14,127][root][INFO] - Training Epoch: 1/2, step 4259/7134 completed (loss: 0.09481415897607803, acc: 0.9799426794052124)
[2024-12-17 04:11:14,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:14,563][root][INFO] - Training Epoch: 1/2, step 4260/7134 completed (loss: 0.045103177428245544, acc: 0.9875776171684265)
[2024-12-17 04:11:14,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:14,977][root][INFO] - Training Epoch: 1/2, step 4261/7134 completed (loss: 0.06046333536505699, acc: 0.980879545211792)
[2024-12-17 04:11:15,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:15,453][root][INFO] - Training Epoch: 1/2, step 4262/7134 completed (loss: 0.06566470861434937, acc: 0.9812206625938416)
[2024-12-17 04:11:15,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:15,871][root][INFO] - Training Epoch: 1/2, step 4263/7134 completed (loss: 0.10030996799468994, acc: 0.9864864945411682)
[2024-12-17 04:11:15,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:16,298][root][INFO] - Training Epoch: 1/2, step 4264/7134 completed (loss: 0.11043687164783478, acc: 0.9674593210220337)
[2024-12-17 04:11:16,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:16,740][root][INFO] - Training Epoch: 1/2, step 4265/7134 completed (loss: 0.05399773642420769, acc: 0.9835858345031738)
[2024-12-17 04:11:16,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:17,197][root][INFO] - Training Epoch: 1/2, step 4266/7134 completed (loss: 0.04632772505283356, acc: 0.9916167855262756)
[2024-12-17 04:11:17,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:17,663][root][INFO] - Training Epoch: 1/2, step 4267/7134 completed (loss: 0.057696323841810226, acc: 0.9842424392700195)
[2024-12-17 04:11:17,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:18,091][root][INFO] - Training Epoch: 1/2, step 4268/7134 completed (loss: 0.13682900369167328, acc: 0.9659318923950195)
[2024-12-17 04:11:18,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:18,541][root][INFO] - Training Epoch: 1/2, step 4269/7134 completed (loss: 0.18558108806610107, acc: 0.9510791301727295)
[2024-12-17 04:11:18,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:18,978][root][INFO] - Training Epoch: 1/2, step 4270/7134 completed (loss: 0.1055082306265831, acc: 0.96875)
[2024-12-17 04:11:19,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:19,436][root][INFO] - Training Epoch: 1/2, step 4271/7134 completed (loss: 0.06250397861003876, acc: 0.9813200235366821)
[2024-12-17 04:11:19,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:19,899][root][INFO] - Training Epoch: 1/2, step 4272/7134 completed (loss: 0.08201727271080017, acc: 0.9741784334182739)
[2024-12-17 04:11:20,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:20,347][root][INFO] - Training Epoch: 1/2, step 4273/7134 completed (loss: 0.0659157857298851, acc: 0.9774153232574463)
[2024-12-17 04:11:20,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:20,807][root][INFO] - Training Epoch: 1/2, step 4274/7134 completed (loss: 0.10917840152978897, acc: 0.9731308221817017)
[2024-12-17 04:11:20,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:21,241][root][INFO] - Training Epoch: 1/2, step 4275/7134 completed (loss: 0.041893694549798965, acc: 0.9873737096786499)
[2024-12-17 04:11:21,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:21,681][root][INFO] - Training Epoch: 1/2, step 4276/7134 completed (loss: 0.08323275297880173, acc: 0.9858247637748718)
[2024-12-17 04:11:21,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:22,088][root][INFO] - Training Epoch: 1/2, step 4277/7134 completed (loss: 0.04435791075229645, acc: 0.9873015880584717)
[2024-12-17 04:11:22,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:22,527][root][INFO] - Training Epoch: 1/2, step 4278/7134 completed (loss: 0.07983773201704025, acc: 0.9765431880950928)
[2024-12-17 04:11:22,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:22,945][root][INFO] - Training Epoch: 1/2, step 4279/7134 completed (loss: 0.09324127435684204, acc: 0.9747023582458496)
[2024-12-17 04:11:23,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:23,387][root][INFO] - Training Epoch: 1/2, step 4280/7134 completed (loss: 0.05316316336393356, acc: 0.9841269850730896)
[2024-12-17 04:11:23,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:23,863][root][INFO] - Training Epoch: 1/2, step 4281/7134 completed (loss: 0.07375434786081314, acc: 0.978960394859314)
[2024-12-17 04:11:23,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:24,298][root][INFO] - Training Epoch: 1/2, step 4282/7134 completed (loss: 0.03140736371278763, acc: 0.9907407164573669)
[2024-12-17 04:11:24,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:24,762][root][INFO] - Training Epoch: 1/2, step 4283/7134 completed (loss: 0.04154350608587265, acc: 0.9850917458534241)
[2024-12-17 04:11:24,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:25,172][root][INFO] - Training Epoch: 1/2, step 4284/7134 completed (loss: 0.07151790708303452, acc: 0.9764492511749268)
[2024-12-17 04:11:25,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:25,605][root][INFO] - Training Epoch: 1/2, step 4285/7134 completed (loss: 0.0842558741569519, acc: 0.9708904027938843)
[2024-12-17 04:11:25,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:26,008][root][INFO] - Training Epoch: 1/2, step 4286/7134 completed (loss: 0.0710776224732399, acc: 0.9766187071800232)
[2024-12-17 04:11:26,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:26,443][root][INFO] - Training Epoch: 1/2, step 4287/7134 completed (loss: 0.08658645302057266, acc: 0.9729381203651428)
[2024-12-17 04:11:26,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:26,914][root][INFO] - Training Epoch: 1/2, step 4288/7134 completed (loss: 0.07458651065826416, acc: 0.9815602898597717)
[2024-12-17 04:11:27,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:27,385][root][INFO] - Training Epoch: 1/2, step 4289/7134 completed (loss: 0.07757233083248138, acc: 0.9759398698806763)
[2024-12-17 04:11:27,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:27,839][root][INFO] - Training Epoch: 1/2, step 4290/7134 completed (loss: 0.07354791462421417, acc: 0.981055498123169)
[2024-12-17 04:11:27,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:28,283][root][INFO] - Training Epoch: 1/2, step 4291/7134 completed (loss: 0.040142204612493515, acc: 0.9880810379981995)
[2024-12-17 04:11:28,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:28,709][root][INFO] - Training Epoch: 1/2, step 4292/7134 completed (loss: 0.049143433570861816, acc: 0.9864457845687866)
[2024-12-17 04:11:28,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:29,135][root][INFO] - Training Epoch: 1/2, step 4293/7134 completed (loss: 0.05738718435168266, acc: 0.9838709831237793)
[2024-12-17 04:11:29,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:29,570][root][INFO] - Training Epoch: 1/2, step 4294/7134 completed (loss: 0.055693287402391434, acc: 0.983988344669342)
[2024-12-17 04:11:29,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:30,002][root][INFO] - Training Epoch: 1/2, step 4295/7134 completed (loss: 0.03785949572920799, acc: 0.989051103591919)
[2024-12-17 04:11:30,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:30,408][root][INFO] - Training Epoch: 1/2, step 4296/7134 completed (loss: 0.05464582517743111, acc: 0.9927007555961609)
[2024-12-17 04:11:30,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:30,819][root][INFO] - Training Epoch: 1/2, step 4297/7134 completed (loss: 0.029758628457784653, acc: 0.9953051805496216)
[2024-12-17 04:11:30,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:31,243][root][INFO] - Training Epoch: 1/2, step 4298/7134 completed (loss: 0.04695812612771988, acc: 0.9876203536987305)
[2024-12-17 04:11:31,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:31,642][root][INFO] - Training Epoch: 1/2, step 4299/7134 completed (loss: 0.04427320882678032, acc: 0.984240710735321)
[2024-12-17 04:11:31,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:32,042][root][INFO] - Training Epoch: 1/2, step 4300/7134 completed (loss: 0.04854468256235123, acc: 0.9824561476707458)
[2024-12-17 04:11:32,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:32,452][root][INFO] - Training Epoch: 1/2, step 4301/7134 completed (loss: 0.07495249807834625, acc: 0.9819672107696533)
[2024-12-17 04:11:32,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:32,876][root][INFO] - Training Epoch: 1/2, step 4302/7134 completed (loss: 0.04308026283979416, acc: 0.9895522594451904)
[2024-12-17 04:11:32,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:33,313][root][INFO] - Training Epoch: 1/2, step 4303/7134 completed (loss: 0.06627266108989716, acc: 0.9809069037437439)
[2024-12-17 04:11:33,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:33,753][root][INFO] - Training Epoch: 1/2, step 4304/7134 completed (loss: 0.041673436760902405, acc: 0.9851411581039429)
[2024-12-17 04:11:33,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:34,217][root][INFO] - Training Epoch: 1/2, step 4305/7134 completed (loss: 0.04952935874462128, acc: 0.9894366264343262)
[2024-12-17 04:11:34,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:34,660][root][INFO] - Training Epoch: 1/2, step 4306/7134 completed (loss: 0.10396069288253784, acc: 0.9829171895980835)
[2024-12-17 04:11:34,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:35,091][root][INFO] - Training Epoch: 1/2, step 4307/7134 completed (loss: 0.11265474557876587, acc: 0.9695023894309998)
[2024-12-17 04:11:35,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:35,544][root][INFO] - Training Epoch: 1/2, step 4308/7134 completed (loss: 0.07466468960046768, acc: 0.9791183471679688)
[2024-12-17 04:11:35,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:35,998][root][INFO] - Training Epoch: 1/2, step 4309/7134 completed (loss: 0.04714319482445717, acc: 0.9864364862442017)
[2024-12-17 04:11:36,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:36,439][root][INFO] - Training Epoch: 1/2, step 4310/7134 completed (loss: 0.06040353327989578, acc: 0.9835487604141235)
[2024-12-17 04:11:36,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:36,857][root][INFO] - Training Epoch: 1/2, step 4311/7134 completed (loss: 0.027637075632810593, acc: 0.991304337978363)
[2024-12-17 04:11:36,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:37,276][root][INFO] - Training Epoch: 1/2, step 4312/7134 completed (loss: 0.028120895847678185, acc: 0.9918256402015686)
[2024-12-17 04:11:37,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:37,721][root][INFO] - Training Epoch: 1/2, step 4313/7134 completed (loss: 0.04047182947397232, acc: 0.9896103739738464)
[2024-12-17 04:11:37,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:38,146][root][INFO] - Training Epoch: 1/2, step 4314/7134 completed (loss: 0.048784200102090836, acc: 0.9848942756652832)
[2024-12-17 04:11:38,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:38,580][root][INFO] - Training Epoch: 1/2, step 4315/7134 completed (loss: 0.06440908461809158, acc: 0.9803921580314636)
[2024-12-17 04:11:38,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:39,018][root][INFO] - Training Epoch: 1/2, step 4316/7134 completed (loss: 0.037002161145210266, acc: 0.9923469424247742)
[2024-12-17 04:11:39,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:39,455][root][INFO] - Training Epoch: 1/2, step 4317/7134 completed (loss: 0.05702793225646019, acc: 0.983890950679779)
[2024-12-17 04:11:39,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:39,890][root][INFO] - Training Epoch: 1/2, step 4318/7134 completed (loss: 0.047061048448085785, acc: 0.9854260087013245)
[2024-12-17 04:11:39,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:40,362][root][INFO] - Training Epoch: 1/2, step 4319/7134 completed (loss: 0.021963749080896378, acc: 0.9933110475540161)
[2024-12-17 04:11:40,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:40,774][root][INFO] - Training Epoch: 1/2, step 4320/7134 completed (loss: 0.04176340997219086, acc: 0.9878378510475159)
[2024-12-17 04:11:40,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:41,140][root][INFO] - Training Epoch: 1/2, step 4321/7134 completed (loss: 0.08673375099897385, acc: 0.9722864031791687)
[2024-12-17 04:11:41,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:41,582][root][INFO] - Training Epoch: 1/2, step 4322/7134 completed (loss: 0.06774824112653732, acc: 0.9811320900917053)
[2024-12-17 04:11:41,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:41,981][root][INFO] - Training Epoch: 1/2, step 4323/7134 completed (loss: 0.08960411697626114, acc: 0.9749518036842346)
[2024-12-17 04:11:42,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:42,369][root][INFO] - Training Epoch: 1/2, step 4324/7134 completed (loss: 0.023256676271557808, acc: 0.9941860437393188)
[2024-12-17 04:11:42,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:42,785][root][INFO] - Training Epoch: 1/2, step 4325/7134 completed (loss: 0.02849697135388851, acc: 0.9920254945755005)
[2024-12-17 04:11:42,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:43,207][root][INFO] - Training Epoch: 1/2, step 4326/7134 completed (loss: 0.05602666735649109, acc: 0.9788732528686523)
[2024-12-17 04:11:43,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:43,611][root][INFO] - Training Epoch: 1/2, step 4327/7134 completed (loss: 0.04882921278476715, acc: 0.9772727489471436)
[2024-12-17 04:11:43,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:44,040][root][INFO] - Training Epoch: 1/2, step 4328/7134 completed (loss: 0.09096018224954605, acc: 0.9755638837814331)
[2024-12-17 04:11:44,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:44,489][root][INFO] - Training Epoch: 1/2, step 4329/7134 completed (loss: 0.056762661784887314, acc: 0.9882044792175293)
[2024-12-17 04:11:44,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:44,872][root][INFO] - Training Epoch: 1/2, step 4330/7134 completed (loss: 0.08344124257564545, acc: 0.9765458703041077)
[2024-12-17 04:11:44,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:45,260][root][INFO] - Training Epoch: 1/2, step 4331/7134 completed (loss: 0.024341434240341187, acc: 0.9886685609817505)
[2024-12-17 04:11:45,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:45,675][root][INFO] - Training Epoch: 1/2, step 4332/7134 completed (loss: 0.0848911926150322, acc: 0.9695817232131958)
[2024-12-17 04:11:45,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:46,088][root][INFO] - Training Epoch: 1/2, step 4333/7134 completed (loss: 0.059767913073301315, acc: 0.9863429665565491)
[2024-12-17 04:11:46,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:46,532][root][INFO] - Training Epoch: 1/2, step 4334/7134 completed (loss: 0.08649227768182755, acc: 0.977544903755188)
[2024-12-17 04:11:46,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:46,938][root][INFO] - Training Epoch: 1/2, step 4335/7134 completed (loss: 0.048758674412965775, acc: 0.9879032373428345)
[2024-12-17 04:11:47,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:47,369][root][INFO] - Training Epoch: 1/2, step 4336/7134 completed (loss: 0.029775921255350113, acc: 0.9902912378311157)
[2024-12-17 04:11:47,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:47,780][root][INFO] - Training Epoch: 1/2, step 4337/7134 completed (loss: 0.061124809086322784, acc: 0.9873417615890503)
[2024-12-17 04:11:47,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:48,192][root][INFO] - Training Epoch: 1/2, step 4338/7134 completed (loss: 0.027585504576563835, acc: 0.9921011328697205)
[2024-12-17 04:11:48,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:48,606][root][INFO] - Training Epoch: 1/2, step 4339/7134 completed (loss: 0.07011750340461731, acc: 0.9795918464660645)
[2024-12-17 04:11:48,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:49,055][root][INFO] - Training Epoch: 1/2, step 4340/7134 completed (loss: 0.04974660277366638, acc: 0.9881756901741028)
[2024-12-17 04:11:49,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:49,480][root][INFO] - Training Epoch: 1/2, step 4341/7134 completed (loss: 0.06917210668325424, acc: 0.9836552739143372)
[2024-12-17 04:11:49,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:49,939][root][INFO] - Training Epoch: 1/2, step 4342/7134 completed (loss: 0.04910751059651375, acc: 0.9855769276618958)
[2024-12-17 04:11:50,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:50,361][root][INFO] - Training Epoch: 1/2, step 4343/7134 completed (loss: 0.03617327660322189, acc: 0.9933444261550903)
[2024-12-17 04:11:50,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:50,731][root][INFO] - Training Epoch: 1/2, step 4344/7134 completed (loss: 0.03711153194308281, acc: 0.9854469895362854)
[2024-12-17 04:11:50,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:51,099][root][INFO] - Training Epoch: 1/2, step 4345/7134 completed (loss: 0.03496348112821579, acc: 0.9875776171684265)
[2024-12-17 04:11:51,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:51,473][root][INFO] - Training Epoch: 1/2, step 4346/7134 completed (loss: 0.02510627917945385, acc: 0.9917184114456177)
[2024-12-17 04:11:51,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:51,891][root][INFO] - Training Epoch: 1/2, step 4347/7134 completed (loss: 0.06995773315429688, acc: 0.9816124439239502)
[2024-12-17 04:11:51,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:52,281][root][INFO] - Training Epoch: 1/2, step 4348/7134 completed (loss: 0.041465867310762405, acc: 0.9855999946594238)
[2024-12-17 04:11:52,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:52,651][root][INFO] - Training Epoch: 1/2, step 4349/7134 completed (loss: 0.03853464499115944, acc: 0.986143171787262)
[2024-12-17 04:11:52,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:53,085][root][INFO] - Training Epoch: 1/2, step 4350/7134 completed (loss: 0.042238421738147736, acc: 0.9869109988212585)
[2024-12-17 04:11:53,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:53,500][root][INFO] - Training Epoch: 1/2, step 4351/7134 completed (loss: 0.07097452878952026, acc: 0.9794238805770874)
[2024-12-17 04:11:53,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:53,934][root][INFO] - Training Epoch: 1/2, step 4352/7134 completed (loss: 0.06989846378564835, acc: 0.9784537553787231)
[2024-12-17 04:11:54,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:54,374][root][INFO] - Training Epoch: 1/2, step 4353/7134 completed (loss: 0.05407502129673958, acc: 0.9827814698219299)
[2024-12-17 04:11:54,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:54,813][root][INFO] - Training Epoch: 1/2, step 4354/7134 completed (loss: 0.045116156339645386, acc: 0.9879999756813049)
[2024-12-17 04:11:54,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:55,237][root][INFO] - Training Epoch: 1/2, step 4355/7134 completed (loss: 0.05166254937648773, acc: 0.987484335899353)
[2024-12-17 04:11:55,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:55,685][root][INFO] - Training Epoch: 1/2, step 4356/7134 completed (loss: 0.04441726207733154, acc: 0.9904420375823975)
[2024-12-17 04:11:55,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:56,130][root][INFO] - Training Epoch: 1/2, step 4357/7134 completed (loss: 0.09911032766103745, acc: 0.9700787663459778)
[2024-12-17 04:11:56,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:56,600][root][INFO] - Training Epoch: 1/2, step 4358/7134 completed (loss: 0.07143552601337433, acc: 0.9796407222747803)
[2024-12-17 04:11:56,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:57,025][root][INFO] - Training Epoch: 1/2, step 4359/7134 completed (loss: 0.06200018525123596, acc: 0.9873217344284058)
[2024-12-17 04:11:57,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:57,436][root][INFO] - Training Epoch: 1/2, step 4360/7134 completed (loss: 0.10072757303714752, acc: 0.9720670580863953)
[2024-12-17 04:11:57,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:57,868][root][INFO] - Training Epoch: 1/2, step 4361/7134 completed (loss: 0.04308443143963814, acc: 0.9841040372848511)
[2024-12-17 04:11:57,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:58,308][root][INFO] - Training Epoch: 1/2, step 4362/7134 completed (loss: 0.055444106459617615, acc: 0.9876695275306702)
[2024-12-17 04:11:58,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:58,744][root][INFO] - Training Epoch: 1/2, step 4363/7134 completed (loss: 0.04563849791884422, acc: 0.9884297251701355)
[2024-12-17 04:11:58,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:59,143][root][INFO] - Training Epoch: 1/2, step 4364/7134 completed (loss: 0.031774237751960754, acc: 0.987500011920929)
[2024-12-17 04:11:59,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:11:59,572][root][INFO] - Training Epoch: 1/2, step 4365/7134 completed (loss: 0.05909900367259979, acc: 0.9795597195625305)
[2024-12-17 04:11:59,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:00,021][root][INFO] - Training Epoch: 1/2, step 4366/7134 completed (loss: 0.07721718400716782, acc: 0.9755154848098755)
[2024-12-17 04:12:00,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:00,452][root][INFO] - Training Epoch: 1/2, step 4367/7134 completed (loss: 0.05036178603768349, acc: 0.9856733679771423)
[2024-12-17 04:12:00,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:00,903][root][INFO] - Training Epoch: 1/2, step 4368/7134 completed (loss: 0.03506883978843689, acc: 0.992443323135376)
[2024-12-17 04:12:01,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:01,323][root][INFO] - Training Epoch: 1/2, step 4369/7134 completed (loss: 0.03901126980781555, acc: 0.9900000095367432)
[2024-12-17 04:12:01,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:01,770][root][INFO] - Training Epoch: 1/2, step 4370/7134 completed (loss: 0.06911017745733261, acc: 0.9773013591766357)
[2024-12-17 04:12:01,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:02,216][root][INFO] - Training Epoch: 1/2, step 4371/7134 completed (loss: 0.05673345923423767, acc: 0.9854881167411804)
[2024-12-17 04:12:02,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:02,639][root][INFO] - Training Epoch: 1/2, step 4372/7134 completed (loss: 0.059553418308496475, acc: 0.9879518151283264)
[2024-12-17 04:12:02,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:03,092][root][INFO] - Training Epoch: 1/2, step 4373/7134 completed (loss: 0.0452180877327919, acc: 0.984542191028595)
[2024-12-17 04:12:03,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:03,523][root][INFO] - Training Epoch: 1/2, step 4374/7134 completed (loss: 0.048315469175577164, acc: 0.9856114983558655)
[2024-12-17 04:12:03,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:03,962][root][INFO] - Training Epoch: 1/2, step 4375/7134 completed (loss: 0.03769604489207268, acc: 0.9871299862861633)
[2024-12-17 04:12:04,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:04,381][root][INFO] - Training Epoch: 1/2, step 4376/7134 completed (loss: 0.05838633328676224, acc: 0.9796379804611206)
[2024-12-17 04:12:04,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:04,845][root][INFO] - Training Epoch: 1/2, step 4377/7134 completed (loss: 0.07333483546972275, acc: 0.983930766582489)
[2024-12-17 04:12:04,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:05,294][root][INFO] - Training Epoch: 1/2, step 4378/7134 completed (loss: 0.05186880752444267, acc: 0.9820261597633362)
[2024-12-17 04:12:05,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:05,751][root][INFO] - Training Epoch: 1/2, step 4379/7134 completed (loss: 0.10832527279853821, acc: 0.9734848737716675)
[2024-12-17 04:12:05,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:06,138][root][INFO] - Training Epoch: 1/2, step 4380/7134 completed (loss: 0.06608041375875473, acc: 0.9789842367172241)
[2024-12-17 04:12:06,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:06,591][root][INFO] - Training Epoch: 1/2, step 4381/7134 completed (loss: 0.03125077858567238, acc: 0.9875862002372742)
[2024-12-17 04:12:06,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:06,984][root][INFO] - Training Epoch: 1/2, step 4382/7134 completed (loss: 0.037398092448711395, acc: 0.9904610514640808)
[2024-12-17 04:12:07,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:07,424][root][INFO] - Training Epoch: 1/2, step 4383/7134 completed (loss: 0.07840278744697571, acc: 0.9779917597770691)
[2024-12-17 04:12:07,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:07,838][root][INFO] - Training Epoch: 1/2, step 4384/7134 completed (loss: 0.05001257732510567, acc: 0.983668327331543)
[2024-12-17 04:12:07,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:08,264][root][INFO] - Training Epoch: 1/2, step 4385/7134 completed (loss: 0.07874848693609238, acc: 0.9804432988166809)
[2024-12-17 04:12:08,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:08,698][root][INFO] - Training Epoch: 1/2, step 4386/7134 completed (loss: 0.07017458230257034, acc: 0.9798578023910522)
[2024-12-17 04:12:08,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:09,165][root][INFO] - Training Epoch: 1/2, step 4387/7134 completed (loss: 0.0741632729768753, acc: 0.977455735206604)
[2024-12-17 04:12:09,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:09,600][root][INFO] - Training Epoch: 1/2, step 4388/7134 completed (loss: 0.0749850869178772, acc: 0.9751552939414978)
[2024-12-17 04:12:09,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:10,013][root][INFO] - Training Epoch: 1/2, step 4389/7134 completed (loss: 0.09387408196926117, acc: 0.9771615266799927)
[2024-12-17 04:12:10,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:10,460][root][INFO] - Training Epoch: 1/2, step 4390/7134 completed (loss: 0.12288030982017517, acc: 0.9649369120597839)
[2024-12-17 04:12:10,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:10,868][root][INFO] - Training Epoch: 1/2, step 4391/7134 completed (loss: 0.12449242174625397, acc: 0.9625407457351685)
[2024-12-17 04:12:10,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:11,297][root][INFO] - Training Epoch: 1/2, step 4392/7134 completed (loss: 0.0493030846118927, acc: 0.9877451062202454)
[2024-12-17 04:12:11,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:11,743][root][INFO] - Training Epoch: 1/2, step 4393/7134 completed (loss: 0.0429471880197525, acc: 0.9915611743927002)
[2024-12-17 04:12:11,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:12,191][root][INFO] - Training Epoch: 1/2, step 4394/7134 completed (loss: 0.04769161343574524, acc: 0.9887164831161499)
[2024-12-17 04:12:12,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:12,607][root][INFO] - Training Epoch: 1/2, step 4395/7134 completed (loss: 0.09263905137777328, acc: 0.9623233675956726)
[2024-12-17 04:12:12,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:13,011][root][INFO] - Training Epoch: 1/2, step 4396/7134 completed (loss: 0.11479052901268005, acc: 0.9715447425842285)
[2024-12-17 04:12:13,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:13,409][root][INFO] - Training Epoch: 1/2, step 4397/7134 completed (loss: 0.06447891891002655, acc: 0.9882352948188782)
[2024-12-17 04:12:13,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:13,834][root][INFO] - Training Epoch: 1/2, step 4398/7134 completed (loss: 0.022981125861406326, acc: 0.9949495196342468)
[2024-12-17 04:12:13,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:14,249][root][INFO] - Training Epoch: 1/2, step 4399/7134 completed (loss: 0.08185974508523941, acc: 0.979099690914154)
[2024-12-17 04:12:14,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:14,705][root][INFO] - Training Epoch: 1/2, step 4400/7134 completed (loss: 0.12156008183956146, acc: 0.9739776849746704)
[2024-12-17 04:12:14,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:15,108][root][INFO] - Training Epoch: 1/2, step 4401/7134 completed (loss: 0.14995603263378143, acc: 0.960869550704956)
[2024-12-17 04:12:15,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:15,535][root][INFO] - Training Epoch: 1/2, step 4402/7134 completed (loss: 0.21416546404361725, acc: 0.9520348906517029)
[2024-12-17 04:12:15,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:15,993][root][INFO] - Training Epoch: 1/2, step 4403/7134 completed (loss: 0.26332759857177734, acc: 0.9443005323410034)
[2024-12-17 04:12:16,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:16,449][root][INFO] - Training Epoch: 1/2, step 4404/7134 completed (loss: 0.1705896258354187, acc: 0.958776593208313)
[2024-12-17 04:12:16,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:16,922][root][INFO] - Training Epoch: 1/2, step 4405/7134 completed (loss: 0.05066332966089249, acc: 0.9870410561561584)
[2024-12-17 04:12:17,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:17,404][root][INFO] - Training Epoch: 1/2, step 4406/7134 completed (loss: 0.058033958077430725, acc: 0.9832962155342102)
[2024-12-17 04:12:17,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:17,869][root][INFO] - Training Epoch: 1/2, step 4407/7134 completed (loss: 0.07759183645248413, acc: 0.981502890586853)
[2024-12-17 04:12:18,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:18,314][root][INFO] - Training Epoch: 1/2, step 4408/7134 completed (loss: 0.13839812576770782, acc: 0.9639115333557129)
[2024-12-17 04:12:18,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:18,751][root][INFO] - Training Epoch: 1/2, step 4409/7134 completed (loss: 0.113310806453228, acc: 0.9694376587867737)
[2024-12-17 04:12:18,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:19,143][root][INFO] - Training Epoch: 1/2, step 4410/7134 completed (loss: 0.12085484713315964, acc: 0.9623655676841736)
[2024-12-17 04:12:19,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:19,570][root][INFO] - Training Epoch: 1/2, step 4411/7134 completed (loss: 0.15233688056468964, acc: 0.9553956985473633)
[2024-12-17 04:12:19,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:19,986][root][INFO] - Training Epoch: 1/2, step 4412/7134 completed (loss: 0.21868647634983063, acc: 0.940119743347168)
[2024-12-17 04:12:20,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:20,413][root][INFO] - Training Epoch: 1/2, step 4413/7134 completed (loss: 0.1458015888929367, acc: 0.9591836929321289)
[2024-12-17 04:12:20,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:20,826][root][INFO] - Training Epoch: 1/2, step 4414/7134 completed (loss: 0.06093255802989006, acc: 0.9822275042533875)
[2024-12-17 04:12:20,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:21,260][root][INFO] - Training Epoch: 1/2, step 4415/7134 completed (loss: 0.09258128702640533, acc: 0.975093424320221)
[2024-12-17 04:12:21,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:21,715][root][INFO] - Training Epoch: 1/2, step 4416/7134 completed (loss: 0.07638650387525558, acc: 0.9813302159309387)
[2024-12-17 04:12:21,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:22,151][root][INFO] - Training Epoch: 1/2, step 4417/7134 completed (loss: 0.10786093771457672, acc: 0.9711538553237915)
[2024-12-17 04:12:22,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:22,583][root][INFO] - Training Epoch: 1/2, step 4418/7134 completed (loss: 0.08861609548330307, acc: 0.9739583134651184)
[2024-12-17 04:12:22,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:22,996][root][INFO] - Training Epoch: 1/2, step 4419/7134 completed (loss: 0.12498783320188522, acc: 0.9603365659713745)
[2024-12-17 04:12:23,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:23,438][root][INFO] - Training Epoch: 1/2, step 4420/7134 completed (loss: 0.1216355413198471, acc: 0.9668049812316895)
[2024-12-17 04:12:23,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:23,878][root][INFO] - Training Epoch: 1/2, step 4421/7134 completed (loss: 0.09754849225282669, acc: 0.9707536697387695)
[2024-12-17 04:12:23,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:24,311][root][INFO] - Training Epoch: 1/2, step 4422/7134 completed (loss: 0.13518698513507843, acc: 0.9654631018638611)
[2024-12-17 04:12:24,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:24,755][root][INFO] - Training Epoch: 1/2, step 4423/7134 completed (loss: 0.09784966707229614, acc: 0.9668949842453003)
[2024-12-17 04:12:24,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:25,201][root][INFO] - Training Epoch: 1/2, step 4424/7134 completed (loss: 0.09092926979064941, acc: 0.977477490901947)
[2024-12-17 04:12:25,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:25,678][root][INFO] - Training Epoch: 1/2, step 4425/7134 completed (loss: 0.07540565729141235, acc: 0.9777777791023254)
[2024-12-17 04:12:25,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:26,156][root][INFO] - Training Epoch: 1/2, step 4426/7134 completed (loss: 0.07962499558925629, acc: 0.9782833456993103)
[2024-12-17 04:12:26,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:26,525][root][INFO] - Training Epoch: 1/2, step 4427/7134 completed (loss: 0.18741923570632935, acc: 0.9566265344619751)
[2024-12-17 04:12:26,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:26,978][root][INFO] - Training Epoch: 1/2, step 4428/7134 completed (loss: 0.04332839697599411, acc: 0.9887323975563049)
[2024-12-17 04:12:27,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:27,323][root][INFO] - Training Epoch: 1/2, step 4429/7134 completed (loss: 0.11028061807155609, acc: 0.9613401889801025)
[2024-12-17 04:12:27,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:27,748][root][INFO] - Training Epoch: 1/2, step 4430/7134 completed (loss: 0.11492063105106354, acc: 0.9710366129875183)
[2024-12-17 04:12:27,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:28,152][root][INFO] - Training Epoch: 1/2, step 4431/7134 completed (loss: 0.11867028474807739, acc: 0.9642301797866821)
[2024-12-17 04:12:28,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:28,545][root][INFO] - Training Epoch: 1/2, step 4432/7134 completed (loss: 0.0532941035926342, acc: 0.9831029176712036)
[2024-12-17 04:12:28,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:29,025][root][INFO] - Training Epoch: 1/2, step 4433/7134 completed (loss: 0.07308796048164368, acc: 0.9836829900741577)
[2024-12-17 04:12:29,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:29,458][root][INFO] - Training Epoch: 1/2, step 4434/7134 completed (loss: 0.061601657420396805, acc: 0.9789789915084839)
[2024-12-17 04:12:29,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:29,874][root][INFO] - Training Epoch: 1/2, step 4435/7134 completed (loss: 0.054598722606897354, acc: 0.9852125644683838)
[2024-12-17 04:12:29,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:30,347][root][INFO] - Training Epoch: 1/2, step 4436/7134 completed (loss: 0.07956644147634506, acc: 0.9748603105545044)
[2024-12-17 04:12:30,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:30,787][root][INFO] - Training Epoch: 1/2, step 4437/7134 completed (loss: 0.04308317229151726, acc: 0.9842519760131836)
[2024-12-17 04:12:30,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:31,212][root][INFO] - Training Epoch: 1/2, step 4438/7134 completed (loss: 0.05113929510116577, acc: 0.9813559055328369)
[2024-12-17 04:12:31,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:31,630][root][INFO] - Training Epoch: 1/2, step 4439/7134 completed (loss: 0.0343514084815979, acc: 0.9869918823242188)
[2024-12-17 04:12:31,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:32,034][root][INFO] - Training Epoch: 1/2, step 4440/7134 completed (loss: 0.039842452853918076, acc: 0.9875690340995789)
[2024-12-17 04:12:32,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:32,509][root][INFO] - Training Epoch: 1/2, step 4441/7134 completed (loss: 0.06684328615665436, acc: 0.9831029176712036)
[2024-12-17 04:12:32,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:32,947][root][INFO] - Training Epoch: 1/2, step 4442/7134 completed (loss: 0.10566464811563492, acc: 0.9768339991569519)
[2024-12-17 04:12:33,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:33,391][root][INFO] - Training Epoch: 1/2, step 4443/7134 completed (loss: 0.08269304037094116, acc: 0.9807692170143127)
[2024-12-17 04:12:33,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:33,776][root][INFO] - Training Epoch: 1/2, step 4444/7134 completed (loss: 0.05843248590826988, acc: 0.9836868047714233)
[2024-12-17 04:12:33,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:34,174][root][INFO] - Training Epoch: 1/2, step 4445/7134 completed (loss: 0.08725901693105698, acc: 0.9748603105545044)
[2024-12-17 04:12:34,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:34,614][root][INFO] - Training Epoch: 1/2, step 4446/7134 completed (loss: 0.076142318546772, acc: 0.9806763529777527)
[2024-12-17 04:12:34,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:35,068][root][INFO] - Training Epoch: 1/2, step 4447/7134 completed (loss: 0.04836583882570267, acc: 0.9823113083839417)
[2024-12-17 04:12:35,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:35,466][root][INFO] - Training Epoch: 1/2, step 4448/7134 completed (loss: 0.05481453984975815, acc: 0.9853747487068176)
[2024-12-17 04:12:35,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:35,855][root][INFO] - Training Epoch: 1/2, step 4449/7134 completed (loss: 0.09780789166688919, acc: 0.9721189737319946)
[2024-12-17 04:12:35,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:36,299][root][INFO] - Training Epoch: 1/2, step 4450/7134 completed (loss: 0.14038990437984467, acc: 0.9599999785423279)
[2024-12-17 04:12:36,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:36,735][root][INFO] - Training Epoch: 1/2, step 4451/7134 completed (loss: 0.16093455255031586, acc: 0.9585406184196472)
[2024-12-17 04:12:36,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:37,176][root][INFO] - Training Epoch: 1/2, step 4452/7134 completed (loss: 0.0381743460893631, acc: 0.9887999892234802)
[2024-12-17 04:12:37,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:37,600][root][INFO] - Training Epoch: 1/2, step 4453/7134 completed (loss: 0.08211490511894226, acc: 0.9713114500045776)
[2024-12-17 04:12:37,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:38,018][root][INFO] - Training Epoch: 1/2, step 4454/7134 completed (loss: 0.0683899000287056, acc: 0.977337121963501)
[2024-12-17 04:12:38,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:38,419][root][INFO] - Training Epoch: 1/2, step 4455/7134 completed (loss: 0.15477988123893738, acc: 0.958563506603241)
[2024-12-17 04:12:38,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:38,840][root][INFO] - Training Epoch: 1/2, step 4456/7134 completed (loss: 0.04820149019360542, acc: 0.9870550036430359)
[2024-12-17 04:12:38,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:39,188][root][INFO] - Training Epoch: 1/2, step 4457/7134 completed (loss: 0.09709933400154114, acc: 0.9700374603271484)
[2024-12-17 04:12:39,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:39,619][root][INFO] - Training Epoch: 1/2, step 4458/7134 completed (loss: 0.03401599079370499, acc: 0.9934533834457397)
[2024-12-17 04:12:39,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:40,051][root][INFO] - Training Epoch: 1/2, step 4459/7134 completed (loss: 0.0339076928794384, acc: 0.9890109896659851)
[2024-12-17 04:12:40,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:40,475][root][INFO] - Training Epoch: 1/2, step 4460/7134 completed (loss: 0.03589735925197601, acc: 0.9877750873565674)
[2024-12-17 04:12:40,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:40,904][root][INFO] - Training Epoch: 1/2, step 4461/7134 completed (loss: 0.10247771441936493, acc: 0.9790897965431213)
[2024-12-17 04:12:40,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:41,346][root][INFO] - Training Epoch: 1/2, step 4462/7134 completed (loss: 0.017470916733145714, acc: 0.9986376166343689)
[2024-12-17 04:12:41,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:41,782][root][INFO] - Training Epoch: 1/2, step 4463/7134 completed (loss: 0.04718676954507828, acc: 0.9861634969711304)
[2024-12-17 04:12:41,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:42,239][root][INFO] - Training Epoch: 1/2, step 4464/7134 completed (loss: 0.06541529297828674, acc: 0.9780775904655457)
[2024-12-17 04:12:42,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:42,686][root][INFO] - Training Epoch: 1/2, step 4465/7134 completed (loss: 0.05204145237803459, acc: 0.9819587469100952)
[2024-12-17 04:12:42,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:43,131][root][INFO] - Training Epoch: 1/2, step 4466/7134 completed (loss: 0.03195522353053093, acc: 0.9913580417633057)
[2024-12-17 04:12:43,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:43,575][root][INFO] - Training Epoch: 1/2, step 4467/7134 completed (loss: 0.05138289928436279, acc: 0.9811557531356812)
[2024-12-17 04:12:43,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:44,003][root][INFO] - Training Epoch: 1/2, step 4468/7134 completed (loss: 0.02430569753050804, acc: 0.9904875159263611)
[2024-12-17 04:12:44,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:44,445][root][INFO] - Training Epoch: 1/2, step 4469/7134 completed (loss: 0.051154907792806625, acc: 0.981502890586853)
[2024-12-17 04:12:44,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:44,900][root][INFO] - Training Epoch: 1/2, step 4470/7134 completed (loss: 0.054389338940382004, acc: 0.9867403507232666)
[2024-12-17 04:12:45,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:45,340][root][INFO] - Training Epoch: 1/2, step 4471/7134 completed (loss: 0.019808299839496613, acc: 0.9914004802703857)
[2024-12-17 04:12:45,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:45,753][root][INFO] - Training Epoch: 1/2, step 4472/7134 completed (loss: 0.04061185568571091, acc: 0.9881423115730286)
[2024-12-17 04:12:45,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:46,173][root][INFO] - Training Epoch: 1/2, step 4473/7134 completed (loss: 0.10237496346235275, acc: 0.9663865566253662)
[2024-12-17 04:12:46,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:46,577][root][INFO] - Training Epoch: 1/2, step 4474/7134 completed (loss: 0.08545713126659393, acc: 0.9762901067733765)
[2024-12-17 04:12:46,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:47,027][root][INFO] - Training Epoch: 1/2, step 4475/7134 completed (loss: 0.16994205117225647, acc: 0.9578163623809814)
[2024-12-17 04:12:47,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:47,472][root][INFO] - Training Epoch: 1/2, step 4476/7134 completed (loss: 0.07076861709356308, acc: 0.9849108457565308)
[2024-12-17 04:12:47,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:47,907][root][INFO] - Training Epoch: 1/2, step 4477/7134 completed (loss: 0.016579709947109222, acc: 0.995110034942627)
[2024-12-17 04:12:48,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:48,348][root][INFO] - Training Epoch: 1/2, step 4478/7134 completed (loss: 0.034075621515512466, acc: 0.9913473129272461)
[2024-12-17 04:12:48,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:48,772][root][INFO] - Training Epoch: 1/2, step 4479/7134 completed (loss: 0.029114728793501854, acc: 0.993261456489563)
[2024-12-17 04:12:48,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:49,225][root][INFO] - Training Epoch: 1/2, step 4480/7134 completed (loss: 0.04150545597076416, acc: 0.985981285572052)
[2024-12-17 04:12:49,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:49,679][root][INFO] - Training Epoch: 1/2, step 4481/7134 completed (loss: 0.05404118821024895, acc: 0.9871495366096497)
[2024-12-17 04:12:49,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:50,124][root][INFO] - Training Epoch: 1/2, step 4482/7134 completed (loss: 0.018711883574724197, acc: 0.9952038526535034)
[2024-12-17 04:12:50,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:50,528][root][INFO] - Training Epoch: 1/2, step 4483/7134 completed (loss: 0.03601238131523132, acc: 0.98959881067276)
[2024-12-17 04:12:50,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:50,991][root][INFO] - Training Epoch: 1/2, step 4484/7134 completed (loss: 0.03576226532459259, acc: 0.9894179701805115)
[2024-12-17 04:12:51,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:51,400][root][INFO] - Training Epoch: 1/2, step 4485/7134 completed (loss: 0.03585407882928848, acc: 0.9938744306564331)
[2024-12-17 04:12:51,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:51,791][root][INFO] - Training Epoch: 1/2, step 4486/7134 completed (loss: 0.021055908873677254, acc: 0.9940298795700073)
[2024-12-17 04:12:51,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:52,221][root][INFO] - Training Epoch: 1/2, step 4487/7134 completed (loss: 0.018531393259763718, acc: 0.9917241334915161)
[2024-12-17 04:12:52,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:52,594][root][INFO] - Training Epoch: 1/2, step 4488/7134 completed (loss: 0.01920301839709282, acc: 0.9928057789802551)
[2024-12-17 04:12:52,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:53,019][root][INFO] - Training Epoch: 1/2, step 4489/7134 completed (loss: 0.03417891263961792, acc: 0.9896907210350037)
[2024-12-17 04:12:53,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:53,453][root][INFO] - Training Epoch: 1/2, step 4490/7134 completed (loss: 0.04661672189831734, acc: 0.9888888597488403)
[2024-12-17 04:12:53,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:53,859][root][INFO] - Training Epoch: 1/2, step 4491/7134 completed (loss: 0.01299043744802475, acc: 0.9981378316879272)
[2024-12-17 04:12:53,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:54,279][root][INFO] - Training Epoch: 1/2, step 4492/7134 completed (loss: 0.027185475453734398, acc: 0.9889705777168274)
[2024-12-17 04:12:54,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:54,696][root][INFO] - Training Epoch: 1/2, step 4493/7134 completed (loss: 0.026052257046103477, acc: 0.9889958500862122)
[2024-12-17 04:12:54,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:55,130][root][INFO] - Training Epoch: 1/2, step 4494/7134 completed (loss: 0.05287580192089081, acc: 0.9898697733879089)
[2024-12-17 04:12:55,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:55,573][root][INFO] - Training Epoch: 1/2, step 4495/7134 completed (loss: 0.032090526074171066, acc: 0.9910600185394287)
[2024-12-17 04:12:55,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:56,000][root][INFO] - Training Epoch: 1/2, step 4496/7134 completed (loss: 0.0439007468521595, acc: 0.9914529919624329)
[2024-12-17 04:12:56,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:56,408][root][INFO] - Training Epoch: 1/2, step 4497/7134 completed (loss: 0.026868237182497978, acc: 0.9920529723167419)
[2024-12-17 04:12:56,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:56,835][root][INFO] - Training Epoch: 1/2, step 4498/7134 completed (loss: 0.07095607370138168, acc: 0.9912917017936707)
[2024-12-17 04:12:56,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:57,248][root][INFO] - Training Epoch: 1/2, step 4499/7134 completed (loss: 0.03899684175848961, acc: 0.9947826266288757)
[2024-12-17 04:12:57,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:57,687][root][INFO] - Training Epoch: 1/2, step 4500/7134 completed (loss: 0.03152532875537872, acc: 0.9944055676460266)
[2024-12-17 04:12:57,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:58,103][root][INFO] - Training Epoch: 1/2, step 4501/7134 completed (loss: 0.024630848318338394, acc: 0.99452805519104)
[2024-12-17 04:12:58,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:58,500][root][INFO] - Training Epoch: 1/2, step 4502/7134 completed (loss: 0.03027431294322014, acc: 0.9940029978752136)
[2024-12-17 04:12:58,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:58,899][root][INFO] - Training Epoch: 1/2, step 4503/7134 completed (loss: 0.026650112122297287, acc: 0.995184600353241)
[2024-12-17 04:12:59,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:59,309][root][INFO] - Training Epoch: 1/2, step 4504/7134 completed (loss: 0.06813036650419235, acc: 0.980567991733551)
[2024-12-17 04:12:59,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:12:59,755][root][INFO] - Training Epoch: 1/2, step 4505/7134 completed (loss: 0.0654013454914093, acc: 0.9864864945411682)
[2024-12-17 04:12:59,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:00,177][root][INFO] - Training Epoch: 1/2, step 4506/7134 completed (loss: 0.03724641725420952, acc: 0.9909909963607788)
[2024-12-17 04:13:00,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:00,608][root][INFO] - Training Epoch: 1/2, step 4507/7134 completed (loss: 0.038194041699171066, acc: 0.9900426864624023)
[2024-12-17 04:13:00,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:01,023][root][INFO] - Training Epoch: 1/2, step 4508/7134 completed (loss: 0.04416196793317795, acc: 0.9900285005569458)
[2024-12-17 04:13:01,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:01,482][root][INFO] - Training Epoch: 1/2, step 4509/7134 completed (loss: 0.05811750143766403, acc: 0.982550323009491)
[2024-12-17 04:13:01,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:01,920][root][INFO] - Training Epoch: 1/2, step 4510/7134 completed (loss: 0.07116101682186127, acc: 0.9788434505462646)
[2024-12-17 04:13:02,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:02,368][root][INFO] - Training Epoch: 1/2, step 4511/7134 completed (loss: 0.08488108962774277, acc: 0.9774965047836304)
[2024-12-17 04:13:02,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:02,770][root][INFO] - Training Epoch: 1/2, step 4512/7134 completed (loss: 0.07970888912677765, acc: 0.9767025113105774)
[2024-12-17 04:13:02,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:03,210][root][INFO] - Training Epoch: 1/2, step 4513/7134 completed (loss: 0.043013282120227814, acc: 0.983146071434021)
[2024-12-17 04:13:03,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:03,644][root][INFO] - Training Epoch: 1/2, step 4514/7134 completed (loss: 0.12010068446397781, acc: 0.9737226366996765)
[2024-12-17 04:13:03,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:04,081][root][INFO] - Training Epoch: 1/2, step 4515/7134 completed (loss: 0.08849465101957321, acc: 0.9716417789459229)
[2024-12-17 04:13:04,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:04,508][root][INFO] - Training Epoch: 1/2, step 4516/7134 completed (loss: 0.05720493569970131, acc: 0.9828641414642334)
[2024-12-17 04:13:04,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:04,943][root][INFO] - Training Epoch: 1/2, step 4517/7134 completed (loss: 0.06483224034309387, acc: 0.9782330393791199)
[2024-12-17 04:13:05,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:05,395][root][INFO] - Training Epoch: 1/2, step 4518/7134 completed (loss: 0.08521708846092224, acc: 0.980867326259613)
[2024-12-17 04:13:05,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:05,850][root][INFO] - Training Epoch: 1/2, step 4519/7134 completed (loss: 0.04628415033221245, acc: 0.9891172647476196)
[2024-12-17 04:13:05,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:06,285][root][INFO] - Training Epoch: 1/2, step 4520/7134 completed (loss: 0.06875523179769516, acc: 0.9802259802818298)
[2024-12-17 04:13:06,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:06,747][root][INFO] - Training Epoch: 1/2, step 4521/7134 completed (loss: 0.05978107079863548, acc: 0.9807460904121399)
[2024-12-17 04:13:06,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:07,199][root][INFO] - Training Epoch: 1/2, step 4522/7134 completed (loss: 0.07978521287441254, acc: 0.9785894155502319)
[2024-12-17 04:13:07,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:07,674][root][INFO] - Training Epoch: 1/2, step 4523/7134 completed (loss: 0.04153117164969444, acc: 0.9869822263717651)
[2024-12-17 04:13:07,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:08,141][root][INFO] - Training Epoch: 1/2, step 4524/7134 completed (loss: 0.07632337510585785, acc: 0.9811066389083862)
[2024-12-17 04:13:08,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:08,581][root][INFO] - Training Epoch: 1/2, step 4525/7134 completed (loss: 0.05339791625738144, acc: 0.9844444394111633)
[2024-12-17 04:13:08,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:08,989][root][INFO] - Training Epoch: 1/2, step 4526/7134 completed (loss: 0.08328580856323242, acc: 0.9741935729980469)
[2024-12-17 04:13:09,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:09,468][root][INFO] - Training Epoch: 1/2, step 4527/7134 completed (loss: 0.05498730391263962, acc: 0.9821627736091614)
[2024-12-17 04:13:09,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:09,914][root][INFO] - Training Epoch: 1/2, step 4528/7134 completed (loss: 0.09628631919622421, acc: 0.9781491160392761)
[2024-12-17 04:13:10,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:10,304][root][INFO] - Training Epoch: 1/2, step 4529/7134 completed (loss: 0.10450085252523422, acc: 0.9753885865211487)
[2024-12-17 04:13:10,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:10,704][root][INFO] - Training Epoch: 1/2, step 4530/7134 completed (loss: 0.05358593538403511, acc: 0.9887955188751221)
[2024-12-17 04:13:10,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:11,148][root][INFO] - Training Epoch: 1/2, step 4531/7134 completed (loss: 0.05130988359451294, acc: 0.9910233616828918)
[2024-12-17 04:13:11,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:11,606][root][INFO] - Training Epoch: 1/2, step 4532/7134 completed (loss: 0.08025667816400528, acc: 0.980079710483551)
[2024-12-17 04:13:11,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:12,036][root][INFO] - Training Epoch: 1/2, step 4533/7134 completed (loss: 0.05929775908589363, acc: 0.982206404209137)
[2024-12-17 04:13:12,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:12,472][root][INFO] - Training Epoch: 1/2, step 4534/7134 completed (loss: 0.036938440054655075, acc: 0.9917840361595154)
[2024-12-17 04:13:12,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:12,901][root][INFO] - Training Epoch: 1/2, step 4535/7134 completed (loss: 0.05253574252128601, acc: 0.9851936101913452)
[2024-12-17 04:13:13,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:13,386][root][INFO] - Training Epoch: 1/2, step 4536/7134 completed (loss: 0.05500476434826851, acc: 0.982758641242981)
[2024-12-17 04:13:13,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:13,848][root][INFO] - Training Epoch: 1/2, step 4537/7134 completed (loss: 0.029079269617795944, acc: 0.9910614490509033)
[2024-12-17 04:13:13,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:14,313][root][INFO] - Training Epoch: 1/2, step 4538/7134 completed (loss: 0.06714741885662079, acc: 0.9804597496986389)
[2024-12-17 04:13:14,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:14,789][root][INFO] - Training Epoch: 1/2, step 4539/7134 completed (loss: 0.03803706541657448, acc: 0.9913700222969055)
[2024-12-17 04:13:14,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:15,243][root][INFO] - Training Epoch: 1/2, step 4540/7134 completed (loss: 0.06482065469026566, acc: 0.9826589822769165)
[2024-12-17 04:13:15,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:15,631][root][INFO] - Training Epoch: 1/2, step 4541/7134 completed (loss: 0.08940912038087845, acc: 0.9733059406280518)
[2024-12-17 04:13:15,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:16,006][root][INFO] - Training Epoch: 1/2, step 4542/7134 completed (loss: 0.09120739996433258, acc: 0.9740259647369385)
[2024-12-17 04:13:16,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:16,377][root][INFO] - Training Epoch: 1/2, step 4543/7134 completed (loss: 0.13769330084323883, acc: 0.9661319255828857)
[2024-12-17 04:13:16,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:16,798][root][INFO] - Training Epoch: 1/2, step 4544/7134 completed (loss: 0.08857428282499313, acc: 0.9756097793579102)
[2024-12-17 04:13:16,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:17,203][root][INFO] - Training Epoch: 1/2, step 4545/7134 completed (loss: 0.1022619977593422, acc: 0.9710982441902161)
[2024-12-17 04:13:17,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:17,612][root][INFO] - Training Epoch: 1/2, step 4546/7134 completed (loss: 0.0671473890542984, acc: 0.9865546226501465)
[2024-12-17 04:13:17,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:18,046][root][INFO] - Training Epoch: 1/2, step 4547/7134 completed (loss: 0.043960463255643845, acc: 0.987889289855957)
[2024-12-17 04:13:18,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:18,481][root][INFO] - Training Epoch: 1/2, step 4548/7134 completed (loss: 0.05575847998261452, acc: 0.9834162592887878)
[2024-12-17 04:13:18,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:18,871][root][INFO] - Training Epoch: 1/2, step 4549/7134 completed (loss: 0.0796755999326706, acc: 0.9763948321342468)
[2024-12-17 04:13:19,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:19,353][root][INFO] - Training Epoch: 1/2, step 4550/7134 completed (loss: 0.07034490257501602, acc: 0.979899525642395)
[2024-12-17 04:13:19,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:19,756][root][INFO] - Training Epoch: 1/2, step 4551/7134 completed (loss: 0.07370704412460327, acc: 0.9800000190734863)
[2024-12-17 04:13:19,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:20,155][root][INFO] - Training Epoch: 1/2, step 4552/7134 completed (loss: 0.06177866458892822, acc: 0.9809523820877075)
[2024-12-17 04:13:20,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:20,555][root][INFO] - Training Epoch: 1/2, step 4553/7134 completed (loss: 0.05327988415956497, acc: 0.9881556630134583)
[2024-12-17 04:13:20,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:20,942][root][INFO] - Training Epoch: 1/2, step 4554/7134 completed (loss: 0.06587574630975723, acc: 0.9855855703353882)
[2024-12-17 04:13:21,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:21,344][root][INFO] - Training Epoch: 1/2, step 4555/7134 completed (loss: 0.08572924137115479, acc: 0.9722991585731506)
[2024-12-17 04:13:21,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:21,814][root][INFO] - Training Epoch: 1/2, step 4556/7134 completed (loss: 0.06468722969293594, acc: 0.9789473414421082)
[2024-12-17 04:13:21,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:22,216][root][INFO] - Training Epoch: 1/2, step 4557/7134 completed (loss: 0.10826815664768219, acc: 0.974452555179596)
[2024-12-17 04:13:22,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:22,628][root][INFO] - Training Epoch: 1/2, step 4558/7134 completed (loss: 0.05605944246053696, acc: 0.9814814925193787)
[2024-12-17 04:13:22,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:23,044][root][INFO] - Training Epoch: 1/2, step 4559/7134 completed (loss: 0.08142344653606415, acc: 0.9831932783126831)
[2024-12-17 04:13:23,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:23,453][root][INFO] - Training Epoch: 1/2, step 4560/7134 completed (loss: 0.06950142234563828, acc: 0.97826087474823)
[2024-12-17 04:13:23,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:23,821][root][INFO] - Training Epoch: 1/2, step 4561/7134 completed (loss: 0.0769677609205246, acc: 0.9745097756385803)
[2024-12-17 04:13:23,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:24,242][root][INFO] - Training Epoch: 1/2, step 4562/7134 completed (loss: 0.06537622213363647, acc: 0.9779005646705627)
[2024-12-17 04:13:24,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:24,672][root][INFO] - Training Epoch: 1/2, step 4563/7134 completed (loss: 0.057726748287677765, acc: 0.9862595200538635)
[2024-12-17 04:13:24,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:25,122][root][INFO] - Training Epoch: 1/2, step 4564/7134 completed (loss: 0.0677645206451416, acc: 0.9802538752555847)
[2024-12-17 04:13:25,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:25,525][root][INFO] - Training Epoch: 1/2, step 4565/7134 completed (loss: 0.06595022231340408, acc: 0.9789674878120422)
[2024-12-17 04:13:25,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:25,937][root][INFO] - Training Epoch: 1/2, step 4566/7134 completed (loss: 0.0573178268969059, acc: 0.9856630563735962)
[2024-12-17 04:13:26,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:26,325][root][INFO] - Training Epoch: 1/2, step 4567/7134 completed (loss: 0.04344150796532631, acc: 0.9871323704719543)
[2024-12-17 04:13:26,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:26,711][root][INFO] - Training Epoch: 1/2, step 4568/7134 completed (loss: 0.06592325866222382, acc: 0.9816513657569885)
[2024-12-17 04:13:26,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:27,121][root][INFO] - Training Epoch: 1/2, step 4569/7134 completed (loss: 0.02658039703965187, acc: 0.9921568632125854)
[2024-12-17 04:13:27,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:27,553][root][INFO] - Training Epoch: 1/2, step 4570/7134 completed (loss: 0.03509576618671417, acc: 0.9868804812431335)
[2024-12-17 04:13:27,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:27,984][root][INFO] - Training Epoch: 1/2, step 4571/7134 completed (loss: 0.037157271057367325, acc: 0.9884467124938965)
[2024-12-17 04:13:28,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:28,409][root][INFO] - Training Epoch: 1/2, step 4572/7134 completed (loss: 0.0723562240600586, acc: 0.9797507524490356)
[2024-12-17 04:13:28,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:28,837][root][INFO] - Training Epoch: 1/2, step 4573/7134 completed (loss: 0.04587557539343834, acc: 0.9859943985939026)
[2024-12-17 04:13:28,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:29,271][root][INFO] - Training Epoch: 1/2, step 4574/7134 completed (loss: 0.031900353729724884, acc: 0.9911660552024841)
[2024-12-17 04:13:29,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:29,713][root][INFO] - Training Epoch: 1/2, step 4575/7134 completed (loss: 0.048751719295978546, acc: 0.9880319237709045)
[2024-12-17 04:13:29,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:30,141][root][INFO] - Training Epoch: 1/2, step 4576/7134 completed (loss: 0.029525741934776306, acc: 0.9962359070777893)
[2024-12-17 04:13:30,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:30,566][root][INFO] - Training Epoch: 1/2, step 4577/7134 completed (loss: 0.04343685135245323, acc: 0.9845505356788635)
[2024-12-17 04:13:30,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:31,026][root][INFO] - Training Epoch: 1/2, step 4578/7134 completed (loss: 0.03581652045249939, acc: 0.9883551597595215)
[2024-12-17 04:13:31,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:31,433][root][INFO] - Training Epoch: 1/2, step 4579/7134 completed (loss: 0.08286075294017792, acc: 0.9841521382331848)
[2024-12-17 04:13:31,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:31,848][root][INFO] - Training Epoch: 1/2, step 4580/7134 completed (loss: 0.024605179205536842, acc: 0.9940298795700073)
[2024-12-17 04:13:31,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:32,309][root][INFO] - Training Epoch: 1/2, step 4581/7134 completed (loss: 0.05713629350066185, acc: 0.9858906269073486)
[2024-12-17 04:13:32,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:32,734][root][INFO] - Training Epoch: 1/2, step 4582/7134 completed (loss: 0.03314802423119545, acc: 0.9901315569877625)
[2024-12-17 04:13:32,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:33,136][root][INFO] - Training Epoch: 1/2, step 4583/7134 completed (loss: 0.04522567242383957, acc: 0.9885621070861816)
[2024-12-17 04:13:33,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:33,545][root][INFO] - Training Epoch: 1/2, step 4584/7134 completed (loss: 0.030499165877699852, acc: 0.988727867603302)
[2024-12-17 04:13:33,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:33,972][root][INFO] - Training Epoch: 1/2, step 4585/7134 completed (loss: 0.054370928555727005, acc: 0.9854369163513184)
[2024-12-17 04:13:34,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:34,428][root][INFO] - Training Epoch: 1/2, step 4586/7134 completed (loss: 0.04723444581031799, acc: 0.9804941415786743)
[2024-12-17 04:13:34,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:34,860][root][INFO] - Training Epoch: 1/2, step 4587/7134 completed (loss: 0.043447110801935196, acc: 0.9876712560653687)
[2024-12-17 04:13:35,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:35,298][root][INFO] - Training Epoch: 1/2, step 4588/7134 completed (loss: 0.06483190506696701, acc: 0.9811046719551086)
[2024-12-17 04:13:35,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:35,705][root][INFO] - Training Epoch: 1/2, step 4589/7134 completed (loss: 0.07393822073936462, acc: 0.9745509028434753)
[2024-12-17 04:13:35,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:36,142][root][INFO] - Training Epoch: 1/2, step 4590/7134 completed (loss: 0.05767114832997322, acc: 0.9861878156661987)
[2024-12-17 04:13:36,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:36,589][root][INFO] - Training Epoch: 1/2, step 4591/7134 completed (loss: 0.060225993394851685, acc: 0.9828495979309082)
[2024-12-17 04:13:36,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:36,991][root][INFO] - Training Epoch: 1/2, step 4592/7134 completed (loss: 0.04550955444574356, acc: 0.9869375824928284)
[2024-12-17 04:13:37,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:37,417][root][INFO] - Training Epoch: 1/2, step 4593/7134 completed (loss: 0.04772510007023811, acc: 0.9896296262741089)
[2024-12-17 04:13:37,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:37,881][root][INFO] - Training Epoch: 1/2, step 4594/7134 completed (loss: 0.05940990149974823, acc: 0.9773333072662354)
[2024-12-17 04:13:37,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:38,308][root][INFO] - Training Epoch: 1/2, step 4595/7134 completed (loss: 0.04047469049692154, acc: 0.9866270422935486)
[2024-12-17 04:13:38,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:38,734][root][INFO] - Training Epoch: 1/2, step 4596/7134 completed (loss: 0.04580997675657272, acc: 0.9809523820877075)
[2024-12-17 04:13:38,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:39,175][root][INFO] - Training Epoch: 1/2, step 4597/7134 completed (loss: 0.03378945589065552, acc: 0.9927095770835876)
[2024-12-17 04:13:39,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:39,619][root][INFO] - Training Epoch: 1/2, step 4598/7134 completed (loss: 0.07281665503978729, acc: 0.979141116142273)
[2024-12-17 04:13:39,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:40,037][root][INFO] - Training Epoch: 1/2, step 4599/7134 completed (loss: 0.031815055757761, acc: 0.9904610514640808)
[2024-12-17 04:13:40,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:40,471][root][INFO] - Training Epoch: 1/2, step 4600/7134 completed (loss: 0.0419125035405159, acc: 0.9851149916648865)
[2024-12-17 04:13:40,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:40,946][root][INFO] - Training Epoch: 1/2, step 4601/7134 completed (loss: 0.0733116939663887, acc: 0.979139506816864)
[2024-12-17 04:13:41,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:41,381][root][INFO] - Training Epoch: 1/2, step 4602/7134 completed (loss: 0.06733225286006927, acc: 0.9768392443656921)
[2024-12-17 04:13:41,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:41,818][root][INFO] - Training Epoch: 1/2, step 4603/7134 completed (loss: 0.05999245494604111, acc: 0.9820689558982849)
[2024-12-17 04:13:41,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:42,239][root][INFO] - Training Epoch: 1/2, step 4604/7134 completed (loss: 0.04651525244116783, acc: 0.9839486479759216)
[2024-12-17 04:13:42,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:42,664][root][INFO] - Training Epoch: 1/2, step 4605/7134 completed (loss: 0.08887418359518051, acc: 0.971615731716156)
[2024-12-17 04:13:42,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:43,144][root][INFO] - Training Epoch: 1/2, step 4606/7134 completed (loss: 0.035413410514593124, acc: 0.9908257126808167)
[2024-12-17 04:13:43,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:43,543][root][INFO] - Training Epoch: 1/2, step 4607/7134 completed (loss: 0.022692371159791946, acc: 0.9898989796638489)
[2024-12-17 04:13:43,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:43,980][root][INFO] - Training Epoch: 1/2, step 4608/7134 completed (loss: 0.03190932795405388, acc: 0.9881481528282166)
[2024-12-17 04:13:44,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:44,397][root][INFO] - Training Epoch: 1/2, step 4609/7134 completed (loss: 0.033373843878507614, acc: 0.9944953918457031)
[2024-12-17 04:13:44,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:44,835][root][INFO] - Training Epoch: 1/2, step 4610/7134 completed (loss: 0.037787482142448425, acc: 0.9867197871208191)
[2024-12-17 04:13:44,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:45,257][root][INFO] - Training Epoch: 1/2, step 4611/7134 completed (loss: 0.025316985324025154, acc: 0.9890453815460205)
[2024-12-17 04:13:45,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:45,644][root][INFO] - Training Epoch: 1/2, step 4612/7134 completed (loss: 0.028242893517017365, acc: 0.9907063245773315)
[2024-12-17 04:13:45,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:46,062][root][INFO] - Training Epoch: 1/2, step 4613/7134 completed (loss: 0.036543115973472595, acc: 0.9878472089767456)
[2024-12-17 04:13:46,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:46,470][root][INFO] - Training Epoch: 1/2, step 4614/7134 completed (loss: 0.061448611319065094, acc: 0.9829545617103577)
[2024-12-17 04:13:46,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:46,935][root][INFO] - Training Epoch: 1/2, step 4615/7134 completed (loss: 0.06175614520907402, acc: 0.9796472191810608)
[2024-12-17 04:13:47,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:47,358][root][INFO] - Training Epoch: 1/2, step 4616/7134 completed (loss: 0.05793403461575508, acc: 0.9807692170143127)
[2024-12-17 04:13:47,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:47,764][root][INFO] - Training Epoch: 1/2, step 4617/7134 completed (loss: 0.033945418894290924, acc: 0.9894894957542419)
[2024-12-17 04:13:47,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:48,194][root][INFO] - Training Epoch: 1/2, step 4618/7134 completed (loss: 0.06474713981151581, acc: 0.9747572541236877)
[2024-12-17 04:13:48,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:48,640][root][INFO] - Training Epoch: 1/2, step 4619/7134 completed (loss: 0.03681221231818199, acc: 0.9879336357116699)
[2024-12-17 04:13:48,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:49,076][root][INFO] - Training Epoch: 1/2, step 4620/7134 completed (loss: 0.04528878256678581, acc: 0.9840579628944397)
[2024-12-17 04:13:49,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:49,500][root][INFO] - Training Epoch: 1/2, step 4621/7134 completed (loss: 0.026268646121025085, acc: 0.9922839403152466)
[2024-12-17 04:13:49,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:49,946][root][INFO] - Training Epoch: 1/2, step 4622/7134 completed (loss: 0.05837520211935043, acc: 0.9887640476226807)
[2024-12-17 04:13:50,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:50,380][root][INFO] - Training Epoch: 1/2, step 4623/7134 completed (loss: 0.07469155639410019, acc: 0.9790849685668945)
[2024-12-17 04:13:50,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:50,886][root][INFO] - Training Epoch: 1/2, step 4624/7134 completed (loss: 0.09245975315570831, acc: 0.9766803979873657)
[2024-12-17 04:13:51,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:51,301][root][INFO] - Training Epoch: 1/2, step 4625/7134 completed (loss: 0.1652287393808365, acc: 0.9605911374092102)
[2024-12-17 04:13:51,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:51,748][root][INFO] - Training Epoch: 1/2, step 4626/7134 completed (loss: 0.08551137149333954, acc: 0.9798657894134521)
[2024-12-17 04:13:51,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:52,177][root][INFO] - Training Epoch: 1/2, step 4627/7134 completed (loss: 0.11298343539237976, acc: 0.9772382378578186)
[2024-12-17 04:13:52,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:52,641][root][INFO] - Training Epoch: 1/2, step 4628/7134 completed (loss: 0.08281595259904861, acc: 0.9710144996643066)
[2024-12-17 04:13:52,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:53,075][root][INFO] - Training Epoch: 1/2, step 4629/7134 completed (loss: 0.09637370705604553, acc: 0.9743589758872986)
[2024-12-17 04:13:53,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:53,534][root][INFO] - Training Epoch: 1/2, step 4630/7134 completed (loss: 0.07686938345432281, acc: 0.9828269481658936)
[2024-12-17 04:13:53,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:53,982][root][INFO] - Training Epoch: 1/2, step 4631/7134 completed (loss: 0.08083730936050415, acc: 0.9745575189590454)
[2024-12-17 04:13:54,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:54,465][root][INFO] - Training Epoch: 1/2, step 4632/7134 completed (loss: 0.06577032804489136, acc: 0.9852941036224365)
[2024-12-17 04:13:54,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:54,916][root][INFO] - Training Epoch: 1/2, step 4633/7134 completed (loss: 0.0915486067533493, acc: 0.9768785834312439)
[2024-12-17 04:13:55,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:55,357][root][INFO] - Training Epoch: 1/2, step 4634/7134 completed (loss: 0.06947996467351913, acc: 0.9825242757797241)
[2024-12-17 04:13:55,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:55,766][root][INFO] - Training Epoch: 1/2, step 4635/7134 completed (loss: 0.09501922875642776, acc: 0.9832317233085632)
[2024-12-17 04:13:55,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:56,165][root][INFO] - Training Epoch: 1/2, step 4636/7134 completed (loss: 0.039940185844898224, acc: 0.9819587469100952)
[2024-12-17 04:13:56,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:56,603][root][INFO] - Training Epoch: 1/2, step 4637/7134 completed (loss: 0.06756246834993362, acc: 0.9838709831237793)
[2024-12-17 04:13:56,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:57,054][root][INFO] - Training Epoch: 1/2, step 4638/7134 completed (loss: 0.09010357409715652, acc: 0.9775429368019104)
[2024-12-17 04:13:57,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:57,511][root][INFO] - Training Epoch: 1/2, step 4639/7134 completed (loss: 0.08040497452020645, acc: 0.9817517995834351)
[2024-12-17 04:13:57,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:57,969][root][INFO] - Training Epoch: 1/2, step 4640/7134 completed (loss: 0.08070503175258636, acc: 0.9807692170143127)
[2024-12-17 04:13:58,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:58,405][root][INFO] - Training Epoch: 1/2, step 4641/7134 completed (loss: 0.049303341656923294, acc: 0.9857954382896423)
[2024-12-17 04:13:58,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:58,849][root][INFO] - Training Epoch: 1/2, step 4642/7134 completed (loss: 0.0353693924844265, acc: 0.9894179701805115)
[2024-12-17 04:13:58,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:59,311][root][INFO] - Training Epoch: 1/2, step 4643/7134 completed (loss: 0.04452633485198021, acc: 0.9905325174331665)
[2024-12-17 04:13:59,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:13:59,788][root][INFO] - Training Epoch: 1/2, step 4644/7134 completed (loss: 0.03776280954480171, acc: 0.9881656765937805)
[2024-12-17 04:13:59,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:00,231][root][INFO] - Training Epoch: 1/2, step 4645/7134 completed (loss: 0.034995123744010925, acc: 0.9916550517082214)
[2024-12-17 04:14:00,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:00,681][root][INFO] - Training Epoch: 1/2, step 4646/7134 completed (loss: 0.031737420707941055, acc: 0.9921507239341736)
[2024-12-17 04:14:00,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:01,145][root][INFO] - Training Epoch: 1/2, step 4647/7134 completed (loss: 0.09714832156896591, acc: 0.9791666865348816)
[2024-12-17 04:14:01,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:01,586][root][INFO] - Training Epoch: 1/2, step 4648/7134 completed (loss: 0.0454283207654953, acc: 0.9862825870513916)
[2024-12-17 04:14:01,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:02,039][root][INFO] - Training Epoch: 1/2, step 4649/7134 completed (loss: 0.07531560212373734, acc: 0.9772329330444336)
[2024-12-17 04:14:02,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:02,497][root][INFO] - Training Epoch: 1/2, step 4650/7134 completed (loss: 0.08623722940683365, acc: 0.9732142686843872)
[2024-12-17 04:14:02,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:02,980][root][INFO] - Training Epoch: 1/2, step 4651/7134 completed (loss: 0.16297438740730286, acc: 0.9594423174858093)
[2024-12-17 04:14:03,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:03,413][root][INFO] - Training Epoch: 1/2, step 4652/7134 completed (loss: 0.052640024572610855, acc: 0.9862805008888245)
[2024-12-17 04:14:03,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:03,884][root][INFO] - Training Epoch: 1/2, step 4653/7134 completed (loss: 0.07608843594789505, acc: 0.9806451797485352)
[2024-12-17 04:14:04,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:04,332][root][INFO] - Training Epoch: 1/2, step 4654/7134 completed (loss: 0.10396594554185867, acc: 0.9732034206390381)
[2024-12-17 04:14:04,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:04,772][root][INFO] - Training Epoch: 1/2, step 4655/7134 completed (loss: 0.07578491419553757, acc: 0.9863201379776001)
[2024-12-17 04:14:04,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:05,222][root][INFO] - Training Epoch: 1/2, step 4656/7134 completed (loss: 0.05055885389447212, acc: 0.9886363744735718)
[2024-12-17 04:14:05,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:05,645][root][INFO] - Training Epoch: 1/2, step 4657/7134 completed (loss: 0.07918237149715424, acc: 0.9759206771850586)
[2024-12-17 04:14:05,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:06,069][root][INFO] - Training Epoch: 1/2, step 4658/7134 completed (loss: 0.08152014017105103, acc: 0.975642740726471)
[2024-12-17 04:14:06,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:06,524][root][INFO] - Training Epoch: 1/2, step 4659/7134 completed (loss: 0.12401682138442993, acc: 0.9755784273147583)
[2024-12-17 04:14:06,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:06,966][root][INFO] - Training Epoch: 1/2, step 4660/7134 completed (loss: 0.14732882380485535, acc: 0.9655172228813171)
[2024-12-17 04:14:07,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:07,381][root][INFO] - Training Epoch: 1/2, step 4661/7134 completed (loss: 0.08449944853782654, acc: 0.9817073345184326)
[2024-12-17 04:14:07,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:07,798][root][INFO] - Training Epoch: 1/2, step 4662/7134 completed (loss: 0.10194838047027588, acc: 0.9812925457954407)
[2024-12-17 04:14:07,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:08,243][root][INFO] - Training Epoch: 1/2, step 4663/7134 completed (loss: 0.08169053494930267, acc: 0.9826202988624573)
[2024-12-17 04:14:08,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:08,691][root][INFO] - Training Epoch: 1/2, step 4664/7134 completed (loss: 0.05886303633451462, acc: 0.9841479659080505)
[2024-12-17 04:14:08,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:09,123][root][INFO] - Training Epoch: 1/2, step 4665/7134 completed (loss: 0.06556597352027893, acc: 0.9822646379470825)
[2024-12-17 04:14:09,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:09,586][root][INFO] - Training Epoch: 1/2, step 4666/7134 completed (loss: 0.09472478181123734, acc: 0.9765319228172302)
[2024-12-17 04:14:09,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:10,010][root][INFO] - Training Epoch: 1/2, step 4667/7134 completed (loss: 0.07847268134355545, acc: 0.979345977306366)
[2024-12-17 04:14:10,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:10,430][root][INFO] - Training Epoch: 1/2, step 4668/7134 completed (loss: 0.06783387064933777, acc: 0.9838709831237793)
[2024-12-17 04:14:10,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:10,865][root][INFO] - Training Epoch: 1/2, step 4669/7134 completed (loss: 0.04814484715461731, acc: 0.9866864085197449)
[2024-12-17 04:14:10,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:11,289][root][INFO] - Training Epoch: 1/2, step 4670/7134 completed (loss: 0.08060185611248016, acc: 0.9805068373680115)
[2024-12-17 04:14:11,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:11,713][root][INFO] - Training Epoch: 1/2, step 4671/7134 completed (loss: 0.07088130712509155, acc: 0.9830747246742249)
[2024-12-17 04:14:11,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:12,135][root][INFO] - Training Epoch: 1/2, step 4672/7134 completed (loss: 0.1008669063448906, acc: 0.9756097793579102)
[2024-12-17 04:14:12,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:12,560][root][INFO] - Training Epoch: 1/2, step 4673/7134 completed (loss: 0.08240880072116852, acc: 0.9781591296195984)
[2024-12-17 04:14:12,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:12,985][root][INFO] - Training Epoch: 1/2, step 4674/7134 completed (loss: 0.05756527557969093, acc: 0.9857369065284729)
[2024-12-17 04:14:13,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:13,423][root][INFO] - Training Epoch: 1/2, step 4675/7134 completed (loss: 0.07140430808067322, acc: 0.9821656346321106)
[2024-12-17 04:14:13,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:13,840][root][INFO] - Training Epoch: 1/2, step 4676/7134 completed (loss: 0.042522210627794266, acc: 0.9894578456878662)
[2024-12-17 04:14:13,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:14,233][root][INFO] - Training Epoch: 1/2, step 4677/7134 completed (loss: 0.07541540265083313, acc: 0.9758771657943726)
[2024-12-17 04:14:14,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:14,653][root][INFO] - Training Epoch: 1/2, step 4678/7134 completed (loss: 0.12010568380355835, acc: 0.9702823162078857)
[2024-12-17 04:14:14,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:15,094][root][INFO] - Training Epoch: 1/2, step 4679/7134 completed (loss: 0.06993156671524048, acc: 0.9834482669830322)
[2024-12-17 04:14:15,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:15,484][root][INFO] - Training Epoch: 1/2, step 4680/7134 completed (loss: 0.08760441839694977, acc: 0.9789719581604004)
[2024-12-17 04:14:15,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:15,886][root][INFO] - Training Epoch: 1/2, step 4681/7134 completed (loss: 0.04695932939648628, acc: 0.989230751991272)
[2024-12-17 04:14:15,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:16,361][root][INFO] - Training Epoch: 1/2, step 4682/7134 completed (loss: 0.03510840982198715, acc: 0.9878345727920532)
[2024-12-17 04:14:16,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:16,762][root][INFO] - Training Epoch: 1/2, step 4683/7134 completed (loss: 0.05951370298862457, acc: 0.9771754741668701)
[2024-12-17 04:14:16,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:17,220][root][INFO] - Training Epoch: 1/2, step 4684/7134 completed (loss: 0.0844263955950737, acc: 0.9779874086380005)
[2024-12-17 04:14:17,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:17,679][root][INFO] - Training Epoch: 1/2, step 4685/7134 completed (loss: 0.05329737067222595, acc: 0.9856557250022888)
[2024-12-17 04:14:17,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:18,150][root][INFO] - Training Epoch: 1/2, step 4686/7134 completed (loss: 0.045039523392915726, acc: 0.9860302805900574)
[2024-12-17 04:14:18,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:18,484][root][INFO] - Training Epoch: 1/2, step 4687/7134 completed (loss: 0.2447369396686554, acc: 0.9478527903556824)
[2024-12-17 04:14:18,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:18,924][root][INFO] - Training Epoch: 1/2, step 4688/7134 completed (loss: 0.2587287724018097, acc: 0.9363449811935425)
[2024-12-17 04:14:19,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:19,383][root][INFO] - Training Epoch: 1/2, step 4689/7134 completed (loss: 0.17575125396251678, acc: 0.9484536051750183)
[2024-12-17 04:14:19,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:19,829][root][INFO] - Training Epoch: 1/2, step 4690/7134 completed (loss: 0.11734350770711899, acc: 0.9748427867889404)
[2024-12-17 04:14:19,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:20,258][root][INFO] - Training Epoch: 1/2, step 4691/7134 completed (loss: 0.06333412230014801, acc: 0.9818593859672546)
[2024-12-17 04:14:20,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:20,587][root][INFO] - Training Epoch: 1/2, step 4692/7134 completed (loss: 0.19492188096046448, acc: 0.9447982907295227)
[2024-12-17 04:14:20,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:21,077][root][INFO] - Training Epoch: 1/2, step 4693/7134 completed (loss: 0.212583526968956, acc: 0.9503759145736694)
[2024-12-17 04:14:21,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:21,474][root][INFO] - Training Epoch: 1/2, step 4694/7134 completed (loss: 0.17430369555950165, acc: 0.9574036598205566)
[2024-12-17 04:14:21,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:21,909][root][INFO] - Training Epoch: 1/2, step 4695/7134 completed (loss: 0.11181414872407913, acc: 0.977011501789093)
[2024-12-17 04:14:22,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:22,343][root][INFO] - Training Epoch: 1/2, step 4696/7134 completed (loss: 0.05572144687175751, acc: 0.9866270422935486)
[2024-12-17 04:14:22,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:22,704][root][INFO] - Training Epoch: 1/2, step 4697/7134 completed (loss: 0.07620994001626968, acc: 0.981203019618988)
[2024-12-17 04:14:22,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:23,117][root][INFO] - Training Epoch: 1/2, step 4698/7134 completed (loss: 0.179533913731575, acc: 0.9541984796524048)
[2024-12-17 04:14:23,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:23,567][root][INFO] - Training Epoch: 1/2, step 4699/7134 completed (loss: 0.09116055071353912, acc: 0.9689213633537292)
[2024-12-17 04:14:23,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:24,014][root][INFO] - Training Epoch: 1/2, step 4700/7134 completed (loss: 0.09583386033773422, acc: 0.9731743931770325)
[2024-12-17 04:14:24,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:24,415][root][INFO] - Training Epoch: 1/2, step 4701/7134 completed (loss: 0.13663791120052338, acc: 0.9392971396446228)
[2024-12-17 04:14:24,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:24,873][root][INFO] - Training Epoch: 1/2, step 4702/7134 completed (loss: 0.05416443571448326, acc: 0.9840764403343201)
[2024-12-17 04:14:25,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:25,321][root][INFO] - Training Epoch: 1/2, step 4703/7134 completed (loss: 0.06825496256351471, acc: 0.9851351380348206)
[2024-12-17 04:14:25,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:25,762][root][INFO] - Training Epoch: 1/2, step 4704/7134 completed (loss: 0.04914185032248497, acc: 0.9906213283538818)
[2024-12-17 04:14:25,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:26,207][root][INFO] - Training Epoch: 1/2, step 4705/7134 completed (loss: 0.05670533329248428, acc: 0.9836257100105286)
[2024-12-17 04:14:26,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:26,679][root][INFO] - Training Epoch: 1/2, step 4706/7134 completed (loss: 0.10335438698530197, acc: 0.9719626307487488)
[2024-12-17 04:14:26,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:27,103][root][INFO] - Training Epoch: 1/2, step 4707/7134 completed (loss: 0.2443014681339264, acc: 0.9404761791229248)
[2024-12-17 04:14:27,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:27,511][root][INFO] - Training Epoch: 1/2, step 4708/7134 completed (loss: 0.048014700412750244, acc: 0.9812967777252197)
[2024-12-17 04:14:27,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:27,972][root][INFO] - Training Epoch: 1/2, step 4709/7134 completed (loss: 0.056128162890672684, acc: 0.9841897487640381)
[2024-12-17 04:14:28,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:28,416][root][INFO] - Training Epoch: 1/2, step 4710/7134 completed (loss: 0.07475806027650833, acc: 0.976710319519043)
[2024-12-17 04:14:28,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:28,877][root][INFO] - Training Epoch: 1/2, step 4711/7134 completed (loss: 0.09961804002523422, acc: 0.971137523651123)
[2024-12-17 04:14:28,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:29,293][root][INFO] - Training Epoch: 1/2, step 4712/7134 completed (loss: 0.14492811262607574, acc: 0.9681817889213562)
[2024-12-17 04:14:29,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:29,716][root][INFO] - Training Epoch: 1/2, step 4713/7134 completed (loss: 0.04403505474328995, acc: 0.9857142567634583)
[2024-12-17 04:14:29,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:30,076][root][INFO] - Training Epoch: 1/2, step 4714/7134 completed (loss: 0.07651849836111069, acc: 0.9738317728042603)
[2024-12-17 04:14:30,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:30,477][root][INFO] - Training Epoch: 1/2, step 4715/7134 completed (loss: 0.15419580042362213, acc: 0.9616204500198364)
[2024-12-17 04:14:30,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:30,864][root][INFO] - Training Epoch: 1/2, step 4716/7134 completed (loss: 0.029539331793785095, acc: 0.9939024448394775)
[2024-12-17 04:14:30,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:31,283][root][INFO] - Training Epoch: 1/2, step 4717/7134 completed (loss: 0.05218286067247391, acc: 0.9896296262741089)
[2024-12-17 04:14:31,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:31,688][root][INFO] - Training Epoch: 1/2, step 4718/7134 completed (loss: 0.054919835180044174, acc: 0.9867549538612366)
[2024-12-17 04:14:31,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:32,115][root][INFO] - Training Epoch: 1/2, step 4719/7134 completed (loss: 0.05680868402123451, acc: 0.983775794506073)
[2024-12-17 04:14:32,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:32,549][root][INFO] - Training Epoch: 1/2, step 4720/7134 completed (loss: 0.032385509461164474, acc: 0.9873772859573364)
[2024-12-17 04:14:32,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:32,956][root][INFO] - Training Epoch: 1/2, step 4721/7134 completed (loss: 0.01939631998538971, acc: 0.9913544654846191)
[2024-12-17 04:14:33,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:33,357][root][INFO] - Training Epoch: 1/2, step 4722/7134 completed (loss: 0.04974859580397606, acc: 0.9852070808410645)
[2024-12-17 04:14:33,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:33,807][root][INFO] - Training Epoch: 1/2, step 4723/7134 completed (loss: 0.02304850146174431, acc: 0.9923780560493469)
[2024-12-17 04:14:33,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:34,267][root][INFO] - Training Epoch: 1/2, step 4724/7134 completed (loss: 0.04134364053606987, acc: 0.9896449446678162)
[2024-12-17 04:14:34,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:34,696][root][INFO] - Training Epoch: 1/2, step 4725/7134 completed (loss: 0.02492671087384224, acc: 0.9934036731719971)
[2024-12-17 04:14:34,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:35,117][root][INFO] - Training Epoch: 1/2, step 4726/7134 completed (loss: 0.1024782732129097, acc: 0.9744681119918823)
[2024-12-17 04:14:35,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:35,527][root][INFO] - Training Epoch: 1/2, step 4727/7134 completed (loss: 0.03811280056834221, acc: 0.9921630024909973)
[2024-12-17 04:14:35,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:35,942][root][INFO] - Training Epoch: 1/2, step 4728/7134 completed (loss: 0.052065156400203705, acc: 0.9868203997612)
[2024-12-17 04:14:36,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:36,351][root][INFO] - Training Epoch: 1/2, step 4729/7134 completed (loss: 0.027851499617099762, acc: 0.9957746267318726)
[2024-12-17 04:14:36,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:36,764][root][INFO] - Training Epoch: 1/2, step 4730/7134 completed (loss: 0.03347405791282654, acc: 0.9892802238464355)
[2024-12-17 04:14:36,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:37,166][root][INFO] - Training Epoch: 1/2, step 4731/7134 completed (loss: 0.08519788831472397, acc: 0.9740458130836487)
[2024-12-17 04:14:37,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:37,579][root][INFO] - Training Epoch: 1/2, step 4732/7134 completed (loss: 0.07931970059871674, acc: 0.9818511605262756)
[2024-12-17 04:14:37,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:37,989][root][INFO] - Training Epoch: 1/2, step 4733/7134 completed (loss: 0.025584198534488678, acc: 0.993537962436676)
[2024-12-17 04:14:38,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:38,416][root][INFO] - Training Epoch: 1/2, step 4734/7134 completed (loss: 0.050397105515003204, acc: 0.9856915473937988)
[2024-12-17 04:14:38,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:38,848][root][INFO] - Training Epoch: 1/2, step 4735/7134 completed (loss: 0.05547061190009117, acc: 0.9879879951477051)
[2024-12-17 04:14:38,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:39,217][root][INFO] - Training Epoch: 1/2, step 4736/7134 completed (loss: 0.06211954727768898, acc: 0.9861932992935181)
[2024-12-17 04:14:39,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:39,642][root][INFO] - Training Epoch: 1/2, step 4737/7134 completed (loss: 0.04378575459122658, acc: 0.9890282154083252)
[2024-12-17 04:14:39,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:40,043][root][INFO] - Training Epoch: 1/2, step 4738/7134 completed (loss: 0.050036314874887466, acc: 0.9817906022071838)
[2024-12-17 04:14:40,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:40,439][root][INFO] - Training Epoch: 1/2, step 4739/7134 completed (loss: 0.12314032018184662, acc: 0.9680511355400085)
[2024-12-17 04:14:40,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:40,876][root][INFO] - Training Epoch: 1/2, step 4740/7134 completed (loss: 0.10070067644119263, acc: 0.976047933101654)
[2024-12-17 04:14:40,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:41,272][root][INFO] - Training Epoch: 1/2, step 4741/7134 completed (loss: 0.12087785452604294, acc: 0.9630314111709595)
[2024-12-17 04:14:41,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:41,700][root][INFO] - Training Epoch: 1/2, step 4742/7134 completed (loss: 0.1247151717543602, acc: 0.9716814160346985)
[2024-12-17 04:14:41,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:42,136][root][INFO] - Training Epoch: 1/2, step 4743/7134 completed (loss: 0.07386226207017899, acc: 0.9804270267486572)
[2024-12-17 04:14:42,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:42,540][root][INFO] - Training Epoch: 1/2, step 4744/7134 completed (loss: 0.06805188208818436, acc: 0.9876033067703247)
[2024-12-17 04:14:42,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:42,981][root][INFO] - Training Epoch: 1/2, step 4745/7134 completed (loss: 0.11116797477006912, acc: 0.9698996543884277)
[2024-12-17 04:14:43,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:43,392][root][INFO] - Training Epoch: 1/2, step 4746/7134 completed (loss: 0.09385038167238235, acc: 0.9816176295280457)
[2024-12-17 04:14:43,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:43,826][root][INFO] - Training Epoch: 1/2, step 4747/7134 completed (loss: 0.07274997979402542, acc: 0.9770580530166626)
[2024-12-17 04:14:43,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:44,260][root][INFO] - Training Epoch: 1/2, step 4748/7134 completed (loss: 0.10698379576206207, acc: 0.9675516486167908)
[2024-12-17 04:14:44,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:44,706][root][INFO] - Training Epoch: 1/2, step 4749/7134 completed (loss: 0.08951830118894577, acc: 0.9760000109672546)
[2024-12-17 04:14:44,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:45,132][root][INFO] - Training Epoch: 1/2, step 4750/7134 completed (loss: 0.11445949226617813, acc: 0.9749518036842346)
[2024-12-17 04:14:45,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:45,594][root][INFO] - Training Epoch: 1/2, step 4751/7134 completed (loss: 0.034156180918216705, acc: 0.9886845946311951)
[2024-12-17 04:14:45,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:46,032][root][INFO] - Training Epoch: 1/2, step 4752/7134 completed (loss: 0.08551491051912308, acc: 0.9784946441650391)
[2024-12-17 04:14:46,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:46,453][root][INFO] - Training Epoch: 1/2, step 4753/7134 completed (loss: 0.10239527374505997, acc: 0.9774096608161926)
[2024-12-17 04:14:46,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:46,868][root][INFO] - Training Epoch: 1/2, step 4754/7134 completed (loss: 0.0548538975417614, acc: 0.988252580165863)
[2024-12-17 04:14:46,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:47,299][root][INFO] - Training Epoch: 1/2, step 4755/7134 completed (loss: 0.07685588300228119, acc: 0.9819694757461548)
[2024-12-17 04:14:47,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:47,688][root][INFO] - Training Epoch: 1/2, step 4756/7134 completed (loss: 0.09592444449663162, acc: 0.9748954176902771)
[2024-12-17 04:14:47,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:48,162][root][INFO] - Training Epoch: 1/2, step 4757/7134 completed (loss: 0.055919770151376724, acc: 0.98392653465271)
[2024-12-17 04:14:48,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:48,596][root][INFO] - Training Epoch: 1/2, step 4758/7134 completed (loss: 0.0744391605257988, acc: 0.9789915680885315)
[2024-12-17 04:14:48,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:49,031][root][INFO] - Training Epoch: 1/2, step 4759/7134 completed (loss: 0.038893286138772964, acc: 0.9931034445762634)
[2024-12-17 04:14:49,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:49,444][root][INFO] - Training Epoch: 1/2, step 4760/7134 completed (loss: 0.07895273715257645, acc: 0.979296088218689)
[2024-12-17 04:14:49,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:49,885][root][INFO] - Training Epoch: 1/2, step 4761/7134 completed (loss: 0.06066686660051346, acc: 0.9908397197723389)
[2024-12-17 04:14:50,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:50,311][root][INFO] - Training Epoch: 1/2, step 4762/7134 completed (loss: 0.0750260204076767, acc: 0.9891892075538635)
[2024-12-17 04:14:50,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:50,723][root][INFO] - Training Epoch: 1/2, step 4763/7134 completed (loss: 0.06840498000383377, acc: 0.9832826852798462)
[2024-12-17 04:14:50,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:51,159][root][INFO] - Training Epoch: 1/2, step 4764/7134 completed (loss: 0.06110136955976486, acc: 0.982694685459137)
[2024-12-17 04:14:51,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:51,578][root][INFO] - Training Epoch: 1/2, step 4765/7134 completed (loss: 0.11171499639749527, acc: 0.9798561334609985)
[2024-12-17 04:14:51,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:52,015][root][INFO] - Training Epoch: 1/2, step 4766/7134 completed (loss: 0.07208854705095291, acc: 0.9897040128707886)
[2024-12-17 04:14:52,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:52,361][root][INFO] - Training Epoch: 1/2, step 4767/7134 completed (loss: 0.06309423595666885, acc: 0.974554717540741)
[2024-12-17 04:14:52,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:52,828][root][INFO] - Training Epoch: 1/2, step 4768/7134 completed (loss: 0.08051501214504242, acc: 0.9796748161315918)
[2024-12-17 04:14:52,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:53,223][root][INFO] - Training Epoch: 1/2, step 4769/7134 completed (loss: 0.09453538060188293, acc: 0.9839486479759216)
[2024-12-17 04:14:53,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:53,625][root][INFO] - Training Epoch: 1/2, step 4770/7134 completed (loss: 0.04249576851725578, acc: 0.9878787994384766)
[2024-12-17 04:14:53,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:54,029][root][INFO] - Training Epoch: 1/2, step 4771/7134 completed (loss: 0.12952691316604614, acc: 0.9709302186965942)
[2024-12-17 04:14:54,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:54,434][root][INFO] - Training Epoch: 1/2, step 4772/7134 completed (loss: 0.07557837665081024, acc: 0.9888357520103455)
[2024-12-17 04:14:54,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:54,837][root][INFO] - Training Epoch: 1/2, step 4773/7134 completed (loss: 0.05438689514994621, acc: 0.9849315285682678)
[2024-12-17 04:14:54,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:55,227][root][INFO] - Training Epoch: 1/2, step 4774/7134 completed (loss: 0.0687340572476387, acc: 0.9845505356788635)
[2024-12-17 04:14:55,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:55,632][root][INFO] - Training Epoch: 1/2, step 4775/7134 completed (loss: 0.08142451196908951, acc: 0.9806763529777527)
[2024-12-17 04:14:55,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:56,051][root][INFO] - Training Epoch: 1/2, step 4776/7134 completed (loss: 0.06029145419597626, acc: 0.9807383418083191)
[2024-12-17 04:14:56,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:56,498][root][INFO] - Training Epoch: 1/2, step 4777/7134 completed (loss: 0.051257647573947906, acc: 0.9883138537406921)
[2024-12-17 04:14:56,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:56,904][root][INFO] - Training Epoch: 1/2, step 4778/7134 completed (loss: 0.048176415264606476, acc: 0.9912472367286682)
[2024-12-17 04:14:57,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:57,356][root][INFO] - Training Epoch: 1/2, step 4779/7134 completed (loss: 0.05156734585762024, acc: 0.9852670431137085)
[2024-12-17 04:14:57,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:57,798][root][INFO] - Training Epoch: 1/2, step 4780/7134 completed (loss: 0.02757476456463337, acc: 0.9890965819358826)
[2024-12-17 04:14:57,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:58,220][root][INFO] - Training Epoch: 1/2, step 4781/7134 completed (loss: 0.0268566831946373, acc: 0.9921721816062927)
[2024-12-17 04:14:58,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:58,659][root][INFO] - Training Epoch: 1/2, step 4782/7134 completed (loss: 0.042639411985874176, acc: 0.9837925434112549)
[2024-12-17 04:14:58,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:59,077][root][INFO] - Training Epoch: 1/2, step 4783/7134 completed (loss: 0.08160160481929779, acc: 0.9786477088928223)
[2024-12-17 04:14:59,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:59,529][root][INFO] - Training Epoch: 1/2, step 4784/7134 completed (loss: 0.027557726949453354, acc: 0.9931787252426147)
[2024-12-17 04:14:59,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:14:59,937][root][INFO] - Training Epoch: 1/2, step 4785/7134 completed (loss: 0.08184255659580231, acc: 0.983146071434021)
[2024-12-17 04:15:00,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:00,349][root][INFO] - Training Epoch: 1/2, step 4786/7134 completed (loss: 0.04832431301474571, acc: 0.9813664555549622)
[2024-12-17 04:15:00,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:00,763][root][INFO] - Training Epoch: 1/2, step 4787/7134 completed (loss: 0.017250923439860344, acc: 0.9984177350997925)
[2024-12-17 04:15:00,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:01,176][root][INFO] - Training Epoch: 1/2, step 4788/7134 completed (loss: 0.038663458079099655, acc: 0.9822695255279541)
[2024-12-17 04:15:01,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:01,580][root][INFO] - Training Epoch: 1/2, step 4789/7134 completed (loss: 0.042963605374097824, acc: 0.9920381903648376)
[2024-12-17 04:15:01,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:02,028][root][INFO] - Training Epoch: 1/2, step 4790/7134 completed (loss: 0.033425360918045044, acc: 0.991847813129425)
[2024-12-17 04:15:02,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:02,438][root][INFO] - Training Epoch: 1/2, step 4791/7134 completed (loss: 0.02768581733107567, acc: 0.9906890392303467)
[2024-12-17 04:15:02,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:02,865][root][INFO] - Training Epoch: 1/2, step 4792/7134 completed (loss: 0.054435692727565765, acc: 0.9866220951080322)
[2024-12-17 04:15:02,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:03,226][root][INFO] - Training Epoch: 1/2, step 4793/7134 completed (loss: 0.10001774877309799, acc: 0.9698629975318909)
[2024-12-17 04:15:03,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:03,662][root][INFO] - Training Epoch: 1/2, step 4794/7134 completed (loss: 0.09666486829519272, acc: 0.977142870426178)
[2024-12-17 04:15:03,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:04,108][root][INFO] - Training Epoch: 1/2, step 4795/7134 completed (loss: 0.047730930149555206, acc: 0.9844632744789124)
[2024-12-17 04:15:04,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:04,507][root][INFO] - Training Epoch: 1/2, step 4796/7134 completed (loss: 0.05482149496674538, acc: 0.9795597195625305)
[2024-12-17 04:15:04,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:04,955][root][INFO] - Training Epoch: 1/2, step 4797/7134 completed (loss: 0.04265611618757248, acc: 0.9888198971748352)
[2024-12-17 04:15:05,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:05,377][root][INFO] - Training Epoch: 1/2, step 4798/7134 completed (loss: 0.055557288229465485, acc: 0.9880159497261047)
[2024-12-17 04:15:05,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:05,836][root][INFO] - Training Epoch: 1/2, step 4799/7134 completed (loss: 0.04415065422654152, acc: 0.9886845946311951)
[2024-12-17 04:15:05,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:06,247][root][INFO] - Training Epoch: 1/2, step 4800/7134 completed (loss: 0.04618122801184654, acc: 0.9865871667861938)
[2024-12-17 04:15:06,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:06,689][root][INFO] - Training Epoch: 1/2, step 4801/7134 completed (loss: 0.029298022389411926, acc: 0.9932126402854919)
[2024-12-17 04:15:06,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:07,137][root][INFO] - Training Epoch: 1/2, step 4802/7134 completed (loss: 0.060710933059453964, acc: 0.9790576100349426)
[2024-12-17 04:15:07,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:07,531][root][INFO] - Training Epoch: 1/2, step 4803/7134 completed (loss: 0.07283295691013336, acc: 0.979411780834198)
[2024-12-17 04:15:07,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:07,963][root][INFO] - Training Epoch: 1/2, step 4804/7134 completed (loss: 0.05739941447973251, acc: 0.9830769300460815)
[2024-12-17 04:15:08,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:08,403][root][INFO] - Training Epoch: 1/2, step 4805/7134 completed (loss: 0.061574872583150864, acc: 0.9902912378311157)
[2024-12-17 04:15:08,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:08,830][root][INFO] - Training Epoch: 1/2, step 4806/7134 completed (loss: 0.05032315477728844, acc: 0.9933444261550903)
[2024-12-17 04:15:08,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:09,216][root][INFO] - Training Epoch: 1/2, step 4807/7134 completed (loss: 0.08547494560480118, acc: 0.9817629456520081)
[2024-12-17 04:15:09,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:09,613][root][INFO] - Training Epoch: 1/2, step 4808/7134 completed (loss: 0.07446230947971344, acc: 0.978723406791687)
[2024-12-17 04:15:09,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:10,038][root][INFO] - Training Epoch: 1/2, step 4809/7134 completed (loss: 0.04117947071790695, acc: 0.9904761910438538)
[2024-12-17 04:15:10,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:10,486][root][INFO] - Training Epoch: 1/2, step 4810/7134 completed (loss: 0.07302489876747131, acc: 0.9885877370834351)
[2024-12-17 04:15:10,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:10,881][root][INFO] - Training Epoch: 1/2, step 4811/7134 completed (loss: 0.06974729150533676, acc: 0.9786821603775024)
[2024-12-17 04:15:10,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:11,305][root][INFO] - Training Epoch: 1/2, step 4812/7134 completed (loss: 0.11510765552520752, acc: 0.9791377186775208)
[2024-12-17 04:15:11,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:11,659][root][INFO] - Training Epoch: 1/2, step 4813/7134 completed (loss: 0.013095828704535961, acc: 0.9948052167892456)
[2024-12-17 04:15:11,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:12,078][root][INFO] - Training Epoch: 1/2, step 4814/7134 completed (loss: 0.050063781440258026, acc: 0.9897959232330322)
[2024-12-17 04:15:12,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:12,423][root][INFO] - Training Epoch: 1/2, step 4815/7134 completed (loss: 0.0177167858928442, acc: 0.9937888383865356)
[2024-12-17 04:15:12,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:12,837][root][INFO] - Training Epoch: 1/2, step 4816/7134 completed (loss: 0.026250680908560753, acc: 0.9950494766235352)
[2024-12-17 04:15:12,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:13,234][root][INFO] - Training Epoch: 1/2, step 4817/7134 completed (loss: 0.02851901762187481, acc: 0.9951807260513306)
[2024-12-17 04:15:13,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:13,702][root][INFO] - Training Epoch: 1/2, step 4818/7134 completed (loss: 0.02891116589307785, acc: 0.9938461780548096)
[2024-12-17 04:15:13,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:14,106][root][INFO] - Training Epoch: 1/2, step 4819/7134 completed (loss: 0.052715856581926346, acc: 0.9898580312728882)
[2024-12-17 04:15:14,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:14,554][root][INFO] - Training Epoch: 1/2, step 4820/7134 completed (loss: 0.0285996962338686, acc: 0.9884169697761536)
[2024-12-17 04:15:14,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:14,997][root][INFO] - Training Epoch: 1/2, step 4821/7134 completed (loss: 0.02828006073832512, acc: 0.99301677942276)
[2024-12-17 04:15:15,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:15,411][root][INFO] - Training Epoch: 1/2, step 4822/7134 completed (loss: 0.04532833397388458, acc: 0.9943289160728455)
[2024-12-17 04:15:15,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:15,877][root][INFO] - Training Epoch: 1/2, step 4823/7134 completed (loss: 0.07594025880098343, acc: 0.9794628620147705)
[2024-12-17 04:15:15,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:16,272][root][INFO] - Training Epoch: 1/2, step 4824/7134 completed (loss: 0.06734305620193481, acc: 0.9771689772605896)
[2024-12-17 04:15:16,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:16,682][root][INFO] - Training Epoch: 1/2, step 4825/7134 completed (loss: 0.025998562574386597, acc: 0.9908758997917175)
[2024-12-17 04:15:16,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:17,136][root][INFO] - Training Epoch: 1/2, step 4826/7134 completed (loss: 0.054133251309394836, acc: 0.9871244430541992)
[2024-12-17 04:15:17,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:17,532][root][INFO] - Training Epoch: 1/2, step 4827/7134 completed (loss: 0.04264844208955765, acc: 0.9896193742752075)
[2024-12-17 04:15:17,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:17,964][root][INFO] - Training Epoch: 1/2, step 4828/7134 completed (loss: 0.044219471514225006, acc: 0.9878493547439575)
[2024-12-17 04:15:18,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:18,424][root][INFO] - Training Epoch: 1/2, step 4829/7134 completed (loss: 0.02015102095901966, acc: 0.9935897588729858)
[2024-12-17 04:15:18,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:18,863][root][INFO] - Training Epoch: 1/2, step 4830/7134 completed (loss: 0.01880262792110443, acc: 0.9955621361732483)
[2024-12-17 04:15:18,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:19,310][root][INFO] - Training Epoch: 1/2, step 4831/7134 completed (loss: 0.01644613780081272, acc: 0.9941520690917969)
[2024-12-17 04:15:19,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:19,744][root][INFO] - Training Epoch: 1/2, step 4832/7134 completed (loss: 0.0214223712682724, acc: 0.9951140284538269)
[2024-12-17 04:15:19,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:20,220][root][INFO] - Training Epoch: 1/2, step 4833/7134 completed (loss: 0.022458955645561218, acc: 0.9936467409133911)
[2024-12-17 04:15:20,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:20,686][root][INFO] - Training Epoch: 1/2, step 4834/7134 completed (loss: 0.029061101377010345, acc: 0.9940476417541504)
[2024-12-17 04:15:20,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:21,115][root][INFO] - Training Epoch: 1/2, step 4835/7134 completed (loss: 0.021705709397792816, acc: 0.9932432174682617)
[2024-12-17 04:15:21,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:21,550][root][INFO] - Training Epoch: 1/2, step 4836/7134 completed (loss: 0.026265393942594528, acc: 0.9938931465148926)
[2024-12-17 04:15:21,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:21,947][root][INFO] - Training Epoch: 1/2, step 4837/7134 completed (loss: 0.11215633153915405, acc: 0.9724264740943909)
[2024-12-17 04:15:22,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:22,379][root][INFO] - Training Epoch: 1/2, step 4838/7134 completed (loss: 0.04220900312066078, acc: 0.988727867603302)
[2024-12-17 04:15:22,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:22,779][root][INFO] - Training Epoch: 1/2, step 4839/7134 completed (loss: 0.06792271137237549, acc: 0.979345977306366)
[2024-12-17 04:15:22,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:23,202][root][INFO] - Training Epoch: 1/2, step 4840/7134 completed (loss: 0.07067037373781204, acc: 0.9812138676643372)
[2024-12-17 04:15:23,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:23,596][root][INFO] - Training Epoch: 1/2, step 4841/7134 completed (loss: 0.046408962458372116, acc: 0.9880775213241577)
[2024-12-17 04:15:23,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:24,044][root][INFO] - Training Epoch: 1/2, step 4842/7134 completed (loss: 0.06520305573940277, acc: 0.9859693646430969)
[2024-12-17 04:15:24,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:24,487][root][INFO] - Training Epoch: 1/2, step 4843/7134 completed (loss: 0.051850736141204834, acc: 0.9806835055351257)
[2024-12-17 04:15:24,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:24,861][root][INFO] - Training Epoch: 1/2, step 4844/7134 completed (loss: 0.05753323435783386, acc: 0.9903069734573364)
[2024-12-17 04:15:24,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:25,298][root][INFO] - Training Epoch: 1/2, step 4845/7134 completed (loss: 0.060514241456985474, acc: 0.9808743000030518)
[2024-12-17 04:15:25,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:25,719][root][INFO] - Training Epoch: 1/2, step 4846/7134 completed (loss: 0.07044321298599243, acc: 0.9797297120094299)
[2024-12-17 04:15:25,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:26,116][root][INFO] - Training Epoch: 1/2, step 4847/7134 completed (loss: 0.04666757583618164, acc: 0.9878706336021423)
[2024-12-17 04:15:26,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:26,522][root][INFO] - Training Epoch: 1/2, step 4848/7134 completed (loss: 0.0354183129966259, acc: 0.9944751262664795)
[2024-12-17 04:15:26,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:26,909][root][INFO] - Training Epoch: 1/2, step 4849/7134 completed (loss: 0.04109932854771614, acc: 0.9866270422935486)
[2024-12-17 04:15:27,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:27,375][root][INFO] - Training Epoch: 1/2, step 4850/7134 completed (loss: 0.06724423170089722, acc: 0.9804161787033081)
[2024-12-17 04:15:27,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:27,835][root][INFO] - Training Epoch: 1/2, step 4851/7134 completed (loss: 0.06134852394461632, acc: 0.9766355156898499)
[2024-12-17 04:15:27,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:28,276][root][INFO] - Training Epoch: 1/2, step 4852/7134 completed (loss: 0.06032411381602287, acc: 0.9840213060379028)
[2024-12-17 04:15:28,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:28,686][root][INFO] - Training Epoch: 1/2, step 4853/7134 completed (loss: 0.11716308444738388, acc: 0.9714693427085876)
[2024-12-17 04:15:28,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:29,076][root][INFO] - Training Epoch: 1/2, step 4854/7134 completed (loss: 0.03699151426553726, acc: 0.9866666793823242)
[2024-12-17 04:15:29,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:29,514][root][INFO] - Training Epoch: 1/2, step 4855/7134 completed (loss: 0.05040664225816727, acc: 0.987908124923706)
[2024-12-17 04:15:29,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:29,974][root][INFO] - Training Epoch: 1/2, step 4856/7134 completed (loss: 0.0628725066781044, acc: 0.9821882843971252)
[2024-12-17 04:15:30,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:30,372][root][INFO] - Training Epoch: 1/2, step 4857/7134 completed (loss: 0.029948318377137184, acc: 0.9928057789802551)
[2024-12-17 04:15:30,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:30,803][root][INFO] - Training Epoch: 1/2, step 4858/7134 completed (loss: 0.048863962292671204, acc: 0.9843304753303528)
[2024-12-17 04:15:30,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:31,249][root][INFO] - Training Epoch: 1/2, step 4859/7134 completed (loss: 0.031128495931625366, acc: 0.9897040128707886)
[2024-12-17 04:15:31,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:31,673][root][INFO] - Training Epoch: 1/2, step 4860/7134 completed (loss: 0.052983012050390244, acc: 0.9918256402015686)
[2024-12-17 04:15:31,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:32,099][root][INFO] - Training Epoch: 1/2, step 4861/7134 completed (loss: 0.04976022243499756, acc: 0.9838274717330933)
[2024-12-17 04:15:32,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:32,519][root][INFO] - Training Epoch: 1/2, step 4862/7134 completed (loss: 0.034475766122341156, acc: 0.991416335105896)
[2024-12-17 04:15:32,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:32,938][root][INFO] - Training Epoch: 1/2, step 4863/7134 completed (loss: 0.041071902960538864, acc: 0.985401451587677)
[2024-12-17 04:15:33,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:33,346][root][INFO] - Training Epoch: 1/2, step 4864/7134 completed (loss: 0.06374654173851013, acc: 0.9769230484962463)
[2024-12-17 04:15:33,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:33,776][root][INFO] - Training Epoch: 1/2, step 4865/7134 completed (loss: 0.05886567756533623, acc: 0.9853479862213135)
[2024-12-17 04:15:33,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:34,236][root][INFO] - Training Epoch: 1/2, step 4866/7134 completed (loss: 0.0543166883289814, acc: 0.9844357967376709)
[2024-12-17 04:15:34,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:34,680][root][INFO] - Training Epoch: 1/2, step 4867/7134 completed (loss: 0.059083350002765656, acc: 0.9854497313499451)
[2024-12-17 04:15:34,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:35,107][root][INFO] - Training Epoch: 1/2, step 4868/7134 completed (loss: 0.0717962235212326, acc: 0.9844961166381836)
[2024-12-17 04:15:35,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:35,507][root][INFO] - Training Epoch: 1/2, step 4869/7134 completed (loss: 0.07967358082532883, acc: 0.9777777791023254)
[2024-12-17 04:15:35,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:35,943][root][INFO] - Training Epoch: 1/2, step 4870/7134 completed (loss: 0.03855163976550102, acc: 0.9882628917694092)
[2024-12-17 04:15:36,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:36,331][root][INFO] - Training Epoch: 1/2, step 4871/7134 completed (loss: 0.05458433926105499, acc: 0.9876543283462524)
[2024-12-17 04:15:36,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:36,740][root][INFO] - Training Epoch: 1/2, step 4872/7134 completed (loss: 0.040559202432632446, acc: 0.9888734221458435)
[2024-12-17 04:15:36,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:37,192][root][INFO] - Training Epoch: 1/2, step 4873/7134 completed (loss: 0.0431651808321476, acc: 0.984375)
[2024-12-17 04:15:37,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:37,633][root][INFO] - Training Epoch: 1/2, step 4874/7134 completed (loss: 0.033523887395858765, acc: 0.9874285459518433)
[2024-12-17 04:15:37,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:38,089][root][INFO] - Training Epoch: 1/2, step 4875/7134 completed (loss: 0.05391480773687363, acc: 0.9861303567886353)
[2024-12-17 04:15:38,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:38,458][root][INFO] - Training Epoch: 1/2, step 4876/7134 completed (loss: 0.0880337506532669, acc: 0.9788583517074585)
[2024-12-17 04:15:38,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:38,885][root][INFO] - Training Epoch: 1/2, step 4877/7134 completed (loss: 0.06502121686935425, acc: 0.9819355010986328)
[2024-12-17 04:15:38,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:39,287][root][INFO] - Training Epoch: 1/2, step 4878/7134 completed (loss: 0.06043348088860512, acc: 0.9793814420700073)
[2024-12-17 04:15:39,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:39,736][root][INFO] - Training Epoch: 1/2, step 4879/7134 completed (loss: 0.08875196427106857, acc: 0.9789156913757324)
[2024-12-17 04:15:39,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:40,181][root][INFO] - Training Epoch: 1/2, step 4880/7134 completed (loss: 0.025131216272711754, acc: 0.9922178983688354)
[2024-12-17 04:15:40,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:40,638][root][INFO] - Training Epoch: 1/2, step 4881/7134 completed (loss: 0.07019579410552979, acc: 0.9795620441436768)
[2024-12-17 04:15:40,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:41,054][root][INFO] - Training Epoch: 1/2, step 4882/7134 completed (loss: 0.06282743066549301, acc: 0.9819079041481018)
[2024-12-17 04:15:41,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:41,478][root][INFO] - Training Epoch: 1/2, step 4883/7134 completed (loss: 0.0563788041472435, acc: 0.9781022071838379)
[2024-12-17 04:15:41,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:41,910][root][INFO] - Training Epoch: 1/2, step 4884/7134 completed (loss: 0.01836961880326271, acc: 0.9923195242881775)
[2024-12-17 04:15:42,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:42,351][root][INFO] - Training Epoch: 1/2, step 4885/7134 completed (loss: 0.024613533169031143, acc: 0.9920844435691833)
[2024-12-17 04:15:42,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:42,773][root][INFO] - Training Epoch: 1/2, step 4886/7134 completed (loss: 0.03500670567154884, acc: 0.9948717951774597)
[2024-12-17 04:15:42,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:43,232][root][INFO] - Training Epoch: 1/2, step 4887/7134 completed (loss: 0.022467443719506264, acc: 0.9940263032913208)
[2024-12-17 04:15:43,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:43,717][root][INFO] - Training Epoch: 1/2, step 4888/7134 completed (loss: 0.06404557824134827, acc: 0.9876373410224915)
[2024-12-17 04:15:43,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:44,169][root][INFO] - Training Epoch: 1/2, step 4889/7134 completed (loss: 0.025287477299571037, acc: 0.9915764331817627)
[2024-12-17 04:15:44,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:44,595][root][INFO] - Training Epoch: 1/2, step 4890/7134 completed (loss: 0.07197437435388565, acc: 0.9809523820877075)
[2024-12-17 04:15:44,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:45,039][root][INFO] - Training Epoch: 1/2, step 4891/7134 completed (loss: 0.07517307251691818, acc: 0.9850746393203735)
[2024-12-17 04:15:45,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:45,465][root][INFO] - Training Epoch: 1/2, step 4892/7134 completed (loss: 0.07292857021093369, acc: 0.9781879186630249)
[2024-12-17 04:15:45,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:45,899][root][INFO] - Training Epoch: 1/2, step 4893/7134 completed (loss: 0.19877436757087708, acc: 0.9498680830001831)
[2024-12-17 04:15:46,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:46,345][root][INFO] - Training Epoch: 1/2, step 4894/7134 completed (loss: 0.03931117802858353, acc: 0.9870316982269287)
[2024-12-17 04:15:46,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:46,796][root][INFO] - Training Epoch: 1/2, step 4895/7134 completed (loss: 0.02883615717291832, acc: 0.9925000071525574)
[2024-12-17 04:15:46,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:47,219][root][INFO] - Training Epoch: 1/2, step 4896/7134 completed (loss: 0.020189443603157997, acc: 0.9901685118675232)
[2024-12-17 04:15:47,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:47,668][root][INFO] - Training Epoch: 1/2, step 4897/7134 completed (loss: 0.05670681595802307, acc: 0.9824561476707458)
[2024-12-17 04:15:47,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:48,127][root][INFO] - Training Epoch: 1/2, step 4898/7134 completed (loss: 0.05492304265499115, acc: 0.9861634969711304)
[2024-12-17 04:15:48,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:48,561][root][INFO] - Training Epoch: 1/2, step 4899/7134 completed (loss: 0.045943040400743484, acc: 0.9854439496994019)
[2024-12-17 04:15:48,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:48,996][root][INFO] - Training Epoch: 1/2, step 4900/7134 completed (loss: 0.046547241508960724, acc: 0.9894737005233765)
[2024-12-17 04:15:49,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:49,439][root][INFO] - Training Epoch: 1/2, step 4901/7134 completed (loss: 0.03924187272787094, acc: 0.9924812316894531)
[2024-12-17 04:15:49,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:49,886][root][INFO] - Training Epoch: 1/2, step 4902/7134 completed (loss: 0.02752932906150818, acc: 0.9920424222946167)
[2024-12-17 04:15:49,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:50,315][root][INFO] - Training Epoch: 1/2, step 4903/7134 completed (loss: 0.045485060662031174, acc: 0.9928315281867981)
[2024-12-17 04:15:50,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:50,755][root][INFO] - Training Epoch: 1/2, step 4904/7134 completed (loss: 0.034855764359235764, acc: 0.9895522594451904)
[2024-12-17 04:15:50,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:51,191][root][INFO] - Training Epoch: 1/2, step 4905/7134 completed (loss: 0.01426711492240429, acc: 0.9952229261398315)
[2024-12-17 04:15:51,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:51,608][root][INFO] - Training Epoch: 1/2, step 4906/7134 completed (loss: 0.0372701995074749, acc: 0.9915682673454285)
[2024-12-17 04:15:51,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:52,027][root][INFO] - Training Epoch: 1/2, step 4907/7134 completed (loss: 0.029767299070954323, acc: 0.9936708807945251)
[2024-12-17 04:15:52,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:52,455][root][INFO] - Training Epoch: 1/2, step 4908/7134 completed (loss: 0.03653035685420036, acc: 0.9919999837875366)
[2024-12-17 04:15:52,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:52,904][root][INFO] - Training Epoch: 1/2, step 4909/7134 completed (loss: 0.017525868490338326, acc: 0.9951377511024475)
[2024-12-17 04:15:53,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:53,333][root][INFO] - Training Epoch: 1/2, step 4910/7134 completed (loss: 0.0321824736893177, acc: 0.9921630024909973)
[2024-12-17 04:15:53,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:53,771][root][INFO] - Training Epoch: 1/2, step 4911/7134 completed (loss: 0.04154867306351662, acc: 0.9920844435691833)
[2024-12-17 04:15:53,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:54,219][root][INFO] - Training Epoch: 1/2, step 4912/7134 completed (loss: 0.0402928963303566, acc: 0.9878934621810913)
[2024-12-17 04:15:54,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:54,638][root][INFO] - Training Epoch: 1/2, step 4913/7134 completed (loss: 0.026120586320757866, acc: 0.9932432174682617)
[2024-12-17 04:15:54,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:55,061][root][INFO] - Training Epoch: 1/2, step 4914/7134 completed (loss: 0.03980477154254913, acc: 0.9877675771713257)
[2024-12-17 04:15:55,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:55,498][root][INFO] - Training Epoch: 1/2, step 4915/7134 completed (loss: 0.008976347744464874, acc: 0.996820330619812)
[2024-12-17 04:15:55,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:55,891][root][INFO] - Training Epoch: 1/2, step 4916/7134 completed (loss: 0.0803663358092308, acc: 0.9708737730979919)
[2024-12-17 04:15:55,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:56,325][root][INFO] - Training Epoch: 1/2, step 4917/7134 completed (loss: 0.06569202989339828, acc: 0.9860917925834656)
[2024-12-17 04:15:56,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:56,740][root][INFO] - Training Epoch: 1/2, step 4918/7134 completed (loss: 0.00702153192833066, acc: 0.998633861541748)
[2024-12-17 04:15:56,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:57,231][root][INFO] - Training Epoch: 1/2, step 4919/7134 completed (loss: 0.07379890233278275, acc: 0.9802631735801697)
[2024-12-17 04:15:57,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:57,678][root][INFO] - Training Epoch: 1/2, step 4920/7134 completed (loss: 0.08857280761003494, acc: 0.9806201457977295)
[2024-12-17 04:15:57,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:58,104][root][INFO] - Training Epoch: 1/2, step 4921/7134 completed (loss: 0.047261979430913925, acc: 0.9885222315788269)
[2024-12-17 04:15:58,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:58,547][root][INFO] - Training Epoch: 1/2, step 4922/7134 completed (loss: 0.03694866597652435, acc: 0.9891156554222107)
[2024-12-17 04:15:58,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:59,022][root][INFO] - Training Epoch: 1/2, step 4923/7134 completed (loss: 0.02981697954237461, acc: 0.9911894202232361)
[2024-12-17 04:15:59,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:59,431][root][INFO] - Training Epoch: 1/2, step 4924/7134 completed (loss: 0.059653859585523605, acc: 0.9860000014305115)
[2024-12-17 04:15:59,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:15:59,847][root][INFO] - Training Epoch: 1/2, step 4925/7134 completed (loss: 0.0543970912694931, acc: 0.9799714088439941)
[2024-12-17 04:15:59,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:00,288][root][INFO] - Training Epoch: 1/2, step 4926/7134 completed (loss: 0.028944559395313263, acc: 0.9870874881744385)
[2024-12-17 04:16:00,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:00,699][root][INFO] - Training Epoch: 1/2, step 4927/7134 completed (loss: 0.040835168212652206, acc: 0.9859943985939026)
[2024-12-17 04:16:00,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:01,127][root][INFO] - Training Epoch: 1/2, step 4928/7134 completed (loss: 0.031859222799539566, acc: 0.9907299876213074)
[2024-12-17 04:16:01,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:01,572][root][INFO] - Training Epoch: 1/2, step 4929/7134 completed (loss: 0.036528393626213074, acc: 0.987596869468689)
[2024-12-17 04:16:01,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:01,990][root][INFO] - Training Epoch: 1/2, step 4930/7134 completed (loss: 0.03853912279009819, acc: 0.9924585223197937)
[2024-12-17 04:16:02,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:02,438][root][INFO] - Training Epoch: 1/2, step 4931/7134 completed (loss: 0.08140653371810913, acc: 0.9847792983055115)
[2024-12-17 04:16:02,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:02,878][root][INFO] - Training Epoch: 1/2, step 4932/7134 completed (loss: 0.04823209345340729, acc: 0.9892037510871887)
[2024-12-17 04:16:02,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:03,310][root][INFO] - Training Epoch: 1/2, step 4933/7134 completed (loss: 0.06630419194698334, acc: 0.982694685459137)
[2024-12-17 04:16:03,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:03,749][root][INFO] - Training Epoch: 1/2, step 4934/7134 completed (loss: 0.02240060642361641, acc: 0.9918808937072754)
[2024-12-17 04:16:03,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:04,188][root][INFO] - Training Epoch: 1/2, step 4935/7134 completed (loss: 0.032137565314769745, acc: 0.9904240965843201)
[2024-12-17 04:16:04,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:04,636][root][INFO] - Training Epoch: 1/2, step 4936/7134 completed (loss: 0.04104272648692131, acc: 0.9876543283462524)
[2024-12-17 04:16:04,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:05,051][root][INFO] - Training Epoch: 1/2, step 4937/7134 completed (loss: 0.039839744567871094, acc: 0.9865471124649048)
[2024-12-17 04:16:05,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:05,500][root][INFO] - Training Epoch: 1/2, step 4938/7134 completed (loss: 0.029901908710598946, acc: 0.9905533194541931)
[2024-12-17 04:16:05,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:05,916][root][INFO] - Training Epoch: 1/2, step 4939/7134 completed (loss: 0.04288025572896004, acc: 0.985318124294281)
[2024-12-17 04:16:06,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:06,340][root][INFO] - Training Epoch: 1/2, step 4940/7134 completed (loss: 0.049354858696460724, acc: 0.989393949508667)
[2024-12-17 04:16:06,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:06,780][root][INFO] - Training Epoch: 1/2, step 4941/7134 completed (loss: 0.0400099940598011, acc: 0.9919246435165405)
[2024-12-17 04:16:06,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:07,222][root][INFO] - Training Epoch: 1/2, step 4942/7134 completed (loss: 0.03613366559147835, acc: 0.9906166195869446)
[2024-12-17 04:16:07,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:07,651][root][INFO] - Training Epoch: 1/2, step 4943/7134 completed (loss: 0.057482510805130005, acc: 0.9863201379776001)
[2024-12-17 04:16:07,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:08,066][root][INFO] - Training Epoch: 1/2, step 4944/7134 completed (loss: 0.042662378400564194, acc: 0.9873684048652649)
[2024-12-17 04:16:08,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:08,456][root][INFO] - Training Epoch: 1/2, step 4945/7134 completed (loss: 0.08852965384721756, acc: 0.9717742204666138)
[2024-12-17 04:16:08,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:08,860][root][INFO] - Training Epoch: 1/2, step 4946/7134 completed (loss: 0.0813484936952591, acc: 0.9736263751983643)
[2024-12-17 04:16:08,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:09,274][root][INFO] - Training Epoch: 1/2, step 4947/7134 completed (loss: 0.06082848832011223, acc: 0.9822616577148438)
[2024-12-17 04:16:09,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:09,656][root][INFO] - Training Epoch: 1/2, step 4948/7134 completed (loss: 0.0885707214474678, acc: 0.9786096215248108)
[2024-12-17 04:16:09,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:10,056][root][INFO] - Training Epoch: 1/2, step 4949/7134 completed (loss: 0.09123113751411438, acc: 0.9714285731315613)
[2024-12-17 04:16:10,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:10,465][root][INFO] - Training Epoch: 1/2, step 4950/7134 completed (loss: 0.04579491168260574, acc: 0.985989511013031)
[2024-12-17 04:16:10,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:10,882][root][INFO] - Training Epoch: 1/2, step 4951/7134 completed (loss: 0.07755523920059204, acc: 0.9800570011138916)
[2024-12-17 04:16:11,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:11,360][root][INFO] - Training Epoch: 1/2, step 4952/7134 completed (loss: 0.06504025310277939, acc: 0.9834437370300293)
[2024-12-17 04:16:11,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:11,719][root][INFO] - Training Epoch: 1/2, step 4953/7134 completed (loss: 0.017764301970601082, acc: 0.9956427216529846)
[2024-12-17 04:16:11,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:12,124][root][INFO] - Training Epoch: 1/2, step 4954/7134 completed (loss: 0.054718878120183945, acc: 0.9828571677207947)
[2024-12-17 04:16:12,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:12,517][root][INFO] - Training Epoch: 1/2, step 4955/7134 completed (loss: 0.0356568917632103, acc: 0.9882903695106506)
[2024-12-17 04:16:12,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:12,959][root][INFO] - Training Epoch: 1/2, step 4956/7134 completed (loss: 0.037194132804870605, acc: 0.9900426864624023)
[2024-12-17 04:16:13,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:13,395][root][INFO] - Training Epoch: 1/2, step 4957/7134 completed (loss: 0.031100668013095856, acc: 0.9911816716194153)
[2024-12-17 04:16:13,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:13,814][root][INFO] - Training Epoch: 1/2, step 4958/7134 completed (loss: 0.02193637192249298, acc: 0.9928057789802551)
[2024-12-17 04:16:13,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:14,252][root][INFO] - Training Epoch: 1/2, step 4959/7134 completed (loss: 0.031816110014915466, acc: 0.9867647290229797)
[2024-12-17 04:16:14,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:14,665][root][INFO] - Training Epoch: 1/2, step 4960/7134 completed (loss: 0.024547327309846878, acc: 0.9896551966667175)
[2024-12-17 04:16:14,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:15,086][root][INFO] - Training Epoch: 1/2, step 4961/7134 completed (loss: 0.01895974390208721, acc: 0.994535505771637)
[2024-12-17 04:16:15,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:15,494][root][INFO] - Training Epoch: 1/2, step 4962/7134 completed (loss: 0.01550558116286993, acc: 0.9922239780426025)
[2024-12-17 04:16:15,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:15,896][root][INFO] - Training Epoch: 1/2, step 4963/7134 completed (loss: 0.04790971055626869, acc: 0.9902597665786743)
[2024-12-17 04:16:16,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:16,297][root][INFO] - Training Epoch: 1/2, step 4964/7134 completed (loss: 0.02831987850368023, acc: 0.9902439117431641)
[2024-12-17 04:16:16,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:16,708][root][INFO] - Training Epoch: 1/2, step 4965/7134 completed (loss: 0.046125445514917374, acc: 0.9852941036224365)
[2024-12-17 04:16:16,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:17,099][root][INFO] - Training Epoch: 1/2, step 4966/7134 completed (loss: 0.06762497872114182, acc: 0.9861496090888977)
[2024-12-17 04:16:17,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:17,511][root][INFO] - Training Epoch: 1/2, step 4967/7134 completed (loss: 0.06711332499980927, acc: 0.986328125)
[2024-12-17 04:16:17,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:17,946][root][INFO] - Training Epoch: 1/2, step 4968/7134 completed (loss: 0.10284236818552017, acc: 0.9768683314323425)
[2024-12-17 04:16:18,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:18,393][root][INFO] - Training Epoch: 1/2, step 4969/7134 completed (loss: 0.10367146879434586, acc: 0.9725086092948914)
[2024-12-17 04:16:18,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:18,796][root][INFO] - Training Epoch: 1/2, step 4970/7134 completed (loss: 0.06299356371164322, acc: 0.9816053509712219)
[2024-12-17 04:16:18,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:19,216][root][INFO] - Training Epoch: 1/2, step 4971/7134 completed (loss: 0.029914578422904015, acc: 0.988135576248169)
[2024-12-17 04:16:19,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:19,640][root][INFO] - Training Epoch: 1/2, step 4972/7134 completed (loss: 0.030924737453460693, acc: 0.9901269674301147)
[2024-12-17 04:16:19,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:20,077][root][INFO] - Training Epoch: 1/2, step 4973/7134 completed (loss: 0.09303252398967743, acc: 0.9711934328079224)
[2024-12-17 04:16:20,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:20,475][root][INFO] - Training Epoch: 1/2, step 4974/7134 completed (loss: 0.09987570345401764, acc: 0.9759519100189209)
[2024-12-17 04:16:20,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:20,889][root][INFO] - Training Epoch: 1/2, step 4975/7134 completed (loss: 0.08547914773225784, acc: 0.9760383367538452)
[2024-12-17 04:16:21,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:21,259][root][INFO] - Training Epoch: 1/2, step 4976/7134 completed (loss: 0.06756800413131714, acc: 0.9742388725280762)
[2024-12-17 04:16:21,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:21,688][root][INFO] - Training Epoch: 1/2, step 4977/7134 completed (loss: 0.0925653800368309, acc: 0.976344108581543)
[2024-12-17 04:16:21,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:22,117][root][INFO] - Training Epoch: 1/2, step 4978/7134 completed (loss: 0.04385332763195038, acc: 0.9863353967666626)
[2024-12-17 04:16:22,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:22,517][root][INFO] - Training Epoch: 1/2, step 4979/7134 completed (loss: 0.12871123850345612, acc: 0.967051088809967)
[2024-12-17 04:16:22,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:22,957][root][INFO] - Training Epoch: 1/2, step 4980/7134 completed (loss: 0.10463589429855347, acc: 0.9758453965187073)
[2024-12-17 04:16:23,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:23,410][root][INFO] - Training Epoch: 1/2, step 4981/7134 completed (loss: 0.058009449392557144, acc: 0.9776714444160461)
[2024-12-17 04:16:23,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:23,831][root][INFO] - Training Epoch: 1/2, step 4982/7134 completed (loss: 0.12376686185598373, acc: 0.9635627269744873)
[2024-12-17 04:16:23,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:24,271][root][INFO] - Training Epoch: 1/2, step 4983/7134 completed (loss: 0.08229054510593414, acc: 0.9750778675079346)
[2024-12-17 04:16:24,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:24,610][root][INFO] - Training Epoch: 1/2, step 4984/7134 completed (loss: 0.09373228251934052, acc: 0.9833333492279053)
[2024-12-17 04:16:24,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:25,001][root][INFO] - Training Epoch: 1/2, step 4985/7134 completed (loss: 0.08058995753526688, acc: 0.9785932898521423)
[2024-12-17 04:16:25,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:25,416][root][INFO] - Training Epoch: 1/2, step 4986/7134 completed (loss: 0.1013011485338211, acc: 0.9777117371559143)
[2024-12-17 04:16:25,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:25,802][root][INFO] - Training Epoch: 1/2, step 4987/7134 completed (loss: 0.06035960838198662, acc: 0.9801192879676819)
[2024-12-17 04:16:25,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:26,223][root][INFO] - Training Epoch: 1/2, step 4988/7134 completed (loss: 0.04741848260164261, acc: 0.9893993139266968)
[2024-12-17 04:16:26,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:26,616][root][INFO] - Training Epoch: 1/2, step 4989/7134 completed (loss: 0.06419707089662552, acc: 0.9727723002433777)
[2024-12-17 04:16:26,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:27,024][root][INFO] - Training Epoch: 1/2, step 4990/7134 completed (loss: 0.06740420311689377, acc: 0.9780405163764954)
[2024-12-17 04:16:27,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:27,454][root][INFO] - Training Epoch: 1/2, step 4991/7134 completed (loss: 0.05721307173371315, acc: 0.9832496047019958)
[2024-12-17 04:16:27,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:27,883][root][INFO] - Training Epoch: 1/2, step 4992/7134 completed (loss: 0.1217300221323967, acc: 0.9759299755096436)
[2024-12-17 04:16:27,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:28,245][root][INFO] - Training Epoch: 1/2, step 4993/7134 completed (loss: 0.030702682211995125, acc: 0.9909502267837524)
[2024-12-17 04:16:28,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:28,697][root][INFO] - Training Epoch: 1/2, step 4994/7134 completed (loss: 0.03447968140244484, acc: 0.9886524677276611)
[2024-12-17 04:16:28,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:29,095][root][INFO] - Training Epoch: 1/2, step 4995/7134 completed (loss: 0.08343867212533951, acc: 0.9795918464660645)
[2024-12-17 04:16:29,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:29,506][root][INFO] - Training Epoch: 1/2, step 4996/7134 completed (loss: 0.06052299588918686, acc: 0.9870848655700684)
[2024-12-17 04:16:29,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:29,960][root][INFO] - Training Epoch: 1/2, step 4997/7134 completed (loss: 0.06841415166854858, acc: 0.9845890402793884)
[2024-12-17 04:16:30,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:30,343][root][INFO] - Training Epoch: 1/2, step 4998/7134 completed (loss: 0.10262622684240341, acc: 0.9808743000030518)
[2024-12-17 04:16:30,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:30,748][root][INFO] - Training Epoch: 1/2, step 4999/7134 completed (loss: 0.04166379198431969, acc: 0.9862306118011475)
[2024-12-17 04:16:30,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:31,127][root][INFO] - Training Epoch: 1/2, step 5000/7134 completed (loss: 0.0473276786506176, acc: 0.9906976819038391)
[2024-12-17 04:16:31,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:31,565][root][INFO] - Training Epoch: 1/2, step 5001/7134 completed (loss: 0.06981752067804337, acc: 0.9869186282157898)
[2024-12-17 04:16:31,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:31,981][root][INFO] - Training Epoch: 1/2, step 5002/7134 completed (loss: 0.06715226173400879, acc: 0.9832713603973389)
[2024-12-17 04:16:32,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:32,383][root][INFO] - Training Epoch: 1/2, step 5003/7134 completed (loss: 0.03838952258229256, acc: 0.9919999837875366)
[2024-12-17 04:16:32,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:32,753][root][INFO] - Training Epoch: 1/2, step 5004/7134 completed (loss: 0.022511929273605347, acc: 0.9955849647521973)
[2024-12-17 04:16:32,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:33,129][root][INFO] - Training Epoch: 1/2, step 5005/7134 completed (loss: 0.05983728915452957, acc: 0.9878048896789551)
[2024-12-17 04:16:33,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:33,570][root][INFO] - Training Epoch: 1/2, step 5006/7134 completed (loss: 0.044964730739593506, acc: 0.9838472604751587)
[2024-12-17 04:16:33,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:33,982][root][INFO] - Training Epoch: 1/2, step 5007/7134 completed (loss: 0.02581547573208809, acc: 0.991525411605835)
[2024-12-17 04:16:34,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:34,447][root][INFO] - Training Epoch: 1/2, step 5008/7134 completed (loss: 0.09985339641571045, acc: 0.9744094610214233)
[2024-12-17 04:16:34,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:34,866][root][INFO] - Training Epoch: 1/2, step 5009/7134 completed (loss: 0.07905126363039017, acc: 0.9875930547714233)
[2024-12-17 04:16:34,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:35,273][root][INFO] - Training Epoch: 1/2, step 5010/7134 completed (loss: 0.077227883040905, acc: 0.9838056564331055)
[2024-12-17 04:16:35,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:35,734][root][INFO] - Training Epoch: 1/2, step 5011/7134 completed (loss: 0.08074010908603668, acc: 0.9804878234863281)
[2024-12-17 04:16:35,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:36,107][root][INFO] - Training Epoch: 1/2, step 5012/7134 completed (loss: 0.08571969717741013, acc: 0.9741379022598267)
[2024-12-17 04:16:36,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:36,505][root][INFO] - Training Epoch: 1/2, step 5013/7134 completed (loss: 0.02876402996480465, acc: 0.991983950138092)
[2024-12-17 04:16:36,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:36,980][root][INFO] - Training Epoch: 1/2, step 5014/7134 completed (loss: 0.056615229696035385, acc: 0.9856557250022888)
[2024-12-17 04:16:37,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:37,421][root][INFO] - Training Epoch: 1/2, step 5015/7134 completed (loss: 0.09770334511995316, acc: 0.977931022644043)
[2024-12-17 04:16:37,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:37,822][root][INFO] - Training Epoch: 1/2, step 5016/7134 completed (loss: 0.02483394742012024, acc: 0.9909583926200867)
[2024-12-17 04:16:37,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:38,243][root][INFO] - Training Epoch: 1/2, step 5017/7134 completed (loss: 0.03483600169420242, acc: 0.9927927851676941)
[2024-12-17 04:16:38,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:38,654][root][INFO] - Training Epoch: 1/2, step 5018/7134 completed (loss: 0.051780443638563156, acc: 0.9804964661598206)
[2024-12-17 04:16:38,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:39,093][root][INFO] - Training Epoch: 1/2, step 5019/7134 completed (loss: 0.056973714381456375, acc: 0.9829059839248657)
[2024-12-17 04:16:39,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:39,554][root][INFO] - Training Epoch: 1/2, step 5020/7134 completed (loss: 0.041327036917209625, acc: 0.9862499833106995)
[2024-12-17 04:16:39,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:39,978][root][INFO] - Training Epoch: 1/2, step 5021/7134 completed (loss: 0.05062631890177727, acc: 0.9931350350379944)
[2024-12-17 04:16:40,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:40,406][root][INFO] - Training Epoch: 1/2, step 5022/7134 completed (loss: 0.05101253464818001, acc: 0.9907407164573669)
[2024-12-17 04:16:40,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:40,873][root][INFO] - Training Epoch: 1/2, step 5023/7134 completed (loss: 0.06356259435415268, acc: 0.9878419637680054)
[2024-12-17 04:16:41,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:41,315][root][INFO] - Training Epoch: 1/2, step 5024/7134 completed (loss: 0.04168999567627907, acc: 0.992277979850769)
[2024-12-17 04:16:41,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:41,746][root][INFO] - Training Epoch: 1/2, step 5025/7134 completed (loss: 0.028213953599333763, acc: 0.9927536249160767)
[2024-12-17 04:16:41,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:42,174][root][INFO] - Training Epoch: 1/2, step 5026/7134 completed (loss: 0.03724479675292969, acc: 0.9894921183586121)
[2024-12-17 04:16:42,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:42,573][root][INFO] - Training Epoch: 1/2, step 5027/7134 completed (loss: 0.0385243222117424, acc: 0.9890710115432739)
[2024-12-17 04:16:42,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:42,985][root][INFO] - Training Epoch: 1/2, step 5028/7134 completed (loss: 0.022545013576745987, acc: 0.9921630024909973)
[2024-12-17 04:16:43,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:43,393][root][INFO] - Training Epoch: 1/2, step 5029/7134 completed (loss: 0.025509141385555267, acc: 0.9886363744735718)
[2024-12-17 04:16:43,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:43,836][root][INFO] - Training Epoch: 1/2, step 5030/7134 completed (loss: 0.016757795587182045, acc: 0.9959072470664978)
[2024-12-17 04:16:43,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:44,245][root][INFO] - Training Epoch: 1/2, step 5031/7134 completed (loss: 0.08197471499443054, acc: 0.988095223903656)
[2024-12-17 04:16:44,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:44,649][root][INFO] - Training Epoch: 1/2, step 5032/7134 completed (loss: 0.03813476115465164, acc: 0.9902597665786743)
[2024-12-17 04:16:44,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:45,095][root][INFO] - Training Epoch: 1/2, step 5033/7134 completed (loss: 0.016472939401865005, acc: 0.995192289352417)
[2024-12-17 04:16:45,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:45,500][root][INFO] - Training Epoch: 1/2, step 5034/7134 completed (loss: 0.023520538583397865, acc: 0.9946808218955994)
[2024-12-17 04:16:45,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:45,914][root][INFO] - Training Epoch: 1/2, step 5035/7134 completed (loss: 0.006570677272975445, acc: 1.0)
[2024-12-17 04:16:46,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:46,334][root][INFO] - Training Epoch: 1/2, step 5036/7134 completed (loss: 0.05687833949923515, acc: 0.9821428656578064)
[2024-12-17 04:16:46,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:46,766][root][INFO] - Training Epoch: 1/2, step 5037/7134 completed (loss: 0.056193411350250244, acc: 0.9879356622695923)
[2024-12-17 04:16:46,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:47,158][root][INFO] - Training Epoch: 1/2, step 5038/7134 completed (loss: 0.05399809777736664, acc: 0.9844098091125488)
[2024-12-17 04:16:47,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:47,541][root][INFO] - Training Epoch: 1/2, step 5039/7134 completed (loss: 0.059407465159893036, acc: 0.982594907283783)
[2024-12-17 04:16:47,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:47,940][root][INFO] - Training Epoch: 1/2, step 5040/7134 completed (loss: 0.02157764881849289, acc: 0.990439772605896)
[2024-12-17 04:16:48,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:48,387][root][INFO] - Training Epoch: 1/2, step 5041/7134 completed (loss: 0.020231788977980614, acc: 0.9920424222946167)
[2024-12-17 04:16:48,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:48,814][root][INFO] - Training Epoch: 1/2, step 5042/7134 completed (loss: 0.06385545432567596, acc: 0.9860140085220337)
[2024-12-17 04:16:48,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:49,172][root][INFO] - Training Epoch: 1/2, step 5043/7134 completed (loss: 0.050698038190603256, acc: 0.9841897487640381)
[2024-12-17 04:16:49,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:49,600][root][INFO] - Training Epoch: 1/2, step 5044/7134 completed (loss: 0.027839934453368187, acc: 0.9941520690917969)
[2024-12-17 04:16:49,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:50,037][root][INFO] - Training Epoch: 1/2, step 5045/7134 completed (loss: 0.0996481403708458, acc: 0.9757738709449768)
[2024-12-17 04:16:50,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:50,412][root][INFO] - Training Epoch: 1/2, step 5046/7134 completed (loss: 0.0867091566324234, acc: 0.980701744556427)
[2024-12-17 04:16:50,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:50,799][root][INFO] - Training Epoch: 1/2, step 5047/7134 completed (loss: 0.08108271658420563, acc: 0.9801653027534485)
[2024-12-17 04:16:50,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:51,246][root][INFO] - Training Epoch: 1/2, step 5048/7134 completed (loss: 0.05982774868607521, acc: 0.9832572340965271)
[2024-12-17 04:16:51,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:51,645][root][INFO] - Training Epoch: 1/2, step 5049/7134 completed (loss: 0.06865505874156952, acc: 0.9795640110969543)
[2024-12-17 04:16:51,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:52,062][root][INFO] - Training Epoch: 1/2, step 5050/7134 completed (loss: 0.06923393160104752, acc: 0.9817159175872803)
[2024-12-17 04:16:52,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:52,483][root][INFO] - Training Epoch: 1/2, step 5051/7134 completed (loss: 0.06653944402933121, acc: 0.9840579628944397)
[2024-12-17 04:16:52,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:52,897][root][INFO] - Training Epoch: 1/2, step 5052/7134 completed (loss: 0.037983957678079605, acc: 0.9863636493682861)
[2024-12-17 04:16:53,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:53,308][root][INFO] - Training Epoch: 1/2, step 5053/7134 completed (loss: 0.10087908059358597, acc: 0.9773585200309753)
[2024-12-17 04:16:53,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:53,754][root][INFO] - Training Epoch: 1/2, step 5054/7134 completed (loss: 0.0818304643034935, acc: 0.9810725450515747)
[2024-12-17 04:16:53,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:54,132][root][INFO] - Training Epoch: 1/2, step 5055/7134 completed (loss: 0.03565504401922226, acc: 0.9857142567634583)
[2024-12-17 04:16:54,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:54,555][root][INFO] - Training Epoch: 1/2, step 5056/7134 completed (loss: 0.08811333030462265, acc: 0.9746031761169434)
[2024-12-17 04:16:54,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:55,003][root][INFO] - Training Epoch: 1/2, step 5057/7134 completed (loss: 0.08760587126016617, acc: 0.9829303026199341)
[2024-12-17 04:16:55,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:55,415][root][INFO] - Training Epoch: 1/2, step 5058/7134 completed (loss: 0.0885404422879219, acc: 0.97826087474823)
[2024-12-17 04:16:55,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:55,856][root][INFO] - Training Epoch: 1/2, step 5059/7134 completed (loss: 0.04819249361753464, acc: 0.9855832457542419)
[2024-12-17 04:16:55,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:56,293][root][INFO] - Training Epoch: 1/2, step 5060/7134 completed (loss: 0.031668782234191895, acc: 0.9910846948623657)
[2024-12-17 04:16:56,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:56,692][root][INFO] - Training Epoch: 1/2, step 5061/7134 completed (loss: 0.08243123441934586, acc: 0.9784017205238342)
[2024-12-17 04:16:56,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:57,109][root][INFO] - Training Epoch: 1/2, step 5062/7134 completed (loss: 0.07940937578678131, acc: 0.9811320900917053)
[2024-12-17 04:16:57,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:57,572][root][INFO] - Training Epoch: 1/2, step 5063/7134 completed (loss: 0.07495204359292984, acc: 0.9833055138587952)
[2024-12-17 04:16:57,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:58,031][root][INFO] - Training Epoch: 1/2, step 5064/7134 completed (loss: 0.0485825277864933, acc: 0.9863013625144958)
[2024-12-17 04:16:58,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:58,487][root][INFO] - Training Epoch: 1/2, step 5065/7134 completed (loss: 0.08038351684808731, acc: 0.9830747246742249)
[2024-12-17 04:16:58,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:58,910][root][INFO] - Training Epoch: 1/2, step 5066/7134 completed (loss: 0.07492399960756302, acc: 0.9833585619926453)
[2024-12-17 04:16:59,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:59,333][root][INFO] - Training Epoch: 1/2, step 5067/7134 completed (loss: 0.034578531980514526, acc: 0.9902533888816833)
[2024-12-17 04:16:59,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:16:59,784][root][INFO] - Training Epoch: 1/2, step 5068/7134 completed (loss: 0.06275486946105957, acc: 0.9826224446296692)
[2024-12-17 04:16:59,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:00,203][root][INFO] - Training Epoch: 1/2, step 5069/7134 completed (loss: 0.03179068863391876, acc: 0.9906250238418579)
[2024-12-17 04:17:00,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:00,591][root][INFO] - Training Epoch: 1/2, step 5070/7134 completed (loss: 0.04944055527448654, acc: 0.9798850417137146)
[2024-12-17 04:17:00,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:01,006][root][INFO] - Training Epoch: 1/2, step 5071/7134 completed (loss: 0.07963647693395615, acc: 0.9789621233940125)
[2024-12-17 04:17:01,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:01,433][root][INFO] - Training Epoch: 1/2, step 5072/7134 completed (loss: 0.07509247958660126, acc: 0.979924738407135)
[2024-12-17 04:17:01,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:01,844][root][INFO] - Training Epoch: 1/2, step 5073/7134 completed (loss: 0.08252102136611938, acc: 0.9767891764640808)
[2024-12-17 04:17:01,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:02,306][root][INFO] - Training Epoch: 1/2, step 5074/7134 completed (loss: 0.05898591876029968, acc: 0.9850746393203735)
[2024-12-17 04:17:02,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:02,743][root][INFO] - Training Epoch: 1/2, step 5075/7134 completed (loss: 0.07941225916147232, acc: 0.9825581312179565)
[2024-12-17 04:17:02,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:03,199][root][INFO] - Training Epoch: 1/2, step 5076/7134 completed (loss: 0.06203592196106911, acc: 0.9868420958518982)
[2024-12-17 04:17:03,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:03,646][root][INFO] - Training Epoch: 1/2, step 5077/7134 completed (loss: 0.04797028750181198, acc: 0.9857594966888428)
[2024-12-17 04:17:03,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:04,068][root][INFO] - Training Epoch: 1/2, step 5078/7134 completed (loss: 0.0998295396566391, acc: 0.9707112908363342)
[2024-12-17 04:17:04,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:04,486][root][INFO] - Training Epoch: 1/2, step 5079/7134 completed (loss: 0.037000078707933426, acc: 0.9904761910438538)
[2024-12-17 04:17:04,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:04,941][root][INFO] - Training Epoch: 1/2, step 5080/7134 completed (loss: 0.037698451429605484, acc: 0.9893617033958435)
[2024-12-17 04:17:05,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:05,376][root][INFO] - Training Epoch: 1/2, step 5081/7134 completed (loss: 0.02258419245481491, acc: 0.9932065010070801)
[2024-12-17 04:17:05,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:05,824][root][INFO] - Training Epoch: 1/2, step 5082/7134 completed (loss: 0.04876047745347023, acc: 0.9829931855201721)
[2024-12-17 04:17:05,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:06,238][root][INFO] - Training Epoch: 1/2, step 5083/7134 completed (loss: 0.05024556815624237, acc: 0.9873417615890503)
[2024-12-17 04:17:06,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:06,699][root][INFO] - Training Epoch: 1/2, step 5084/7134 completed (loss: 0.03038616105914116, acc: 0.9930555820465088)
[2024-12-17 04:17:06,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:07,159][root][INFO] - Training Epoch: 1/2, step 5085/7134 completed (loss: 0.07003019005060196, acc: 0.9834319353103638)
[2024-12-17 04:17:07,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:07,580][root][INFO] - Training Epoch: 1/2, step 5086/7134 completed (loss: 0.05401059612631798, acc: 0.987293541431427)
[2024-12-17 04:17:07,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:08,015][root][INFO] - Training Epoch: 1/2, step 5087/7134 completed (loss: 0.024576591327786446, acc: 0.9906291961669922)
[2024-12-17 04:17:08,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:08,428][root][INFO] - Training Epoch: 1/2, step 5088/7134 completed (loss: 0.01711096055805683, acc: 0.9956076145172119)
[2024-12-17 04:17:08,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:08,869][root][INFO] - Training Epoch: 1/2, step 5089/7134 completed (loss: 0.028553970158100128, acc: 0.9937655925750732)
[2024-12-17 04:17:08,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:09,314][root][INFO] - Training Epoch: 1/2, step 5090/7134 completed (loss: 0.03409329429268837, acc: 0.9906651377677917)
[2024-12-17 04:17:09,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:09,742][root][INFO] - Training Epoch: 1/2, step 5091/7134 completed (loss: 0.029331905767321587, acc: 0.992094874382019)
[2024-12-17 04:17:09,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:10,162][root][INFO] - Training Epoch: 1/2, step 5092/7134 completed (loss: 0.06062982603907585, acc: 0.9834024906158447)
[2024-12-17 04:17:10,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:10,572][root][INFO] - Training Epoch: 1/2, step 5093/7134 completed (loss: 0.03730272129178047, acc: 0.9875690340995789)
[2024-12-17 04:17:10,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:10,988][root][INFO] - Training Epoch: 1/2, step 5094/7134 completed (loss: 0.048246726393699646, acc: 0.9890909194946289)
[2024-12-17 04:17:11,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:11,388][root][INFO] - Training Epoch: 1/2, step 5095/7134 completed (loss: 0.15977811813354492, acc: 0.9703587889671326)
[2024-12-17 04:17:11,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:11,840][root][INFO] - Training Epoch: 1/2, step 5096/7134 completed (loss: 0.07993699610233307, acc: 0.9699422121047974)
[2024-12-17 04:17:11,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:12,291][root][INFO] - Training Epoch: 1/2, step 5097/7134 completed (loss: 0.07317822426557541, acc: 0.9829059839248657)
[2024-12-17 04:17:12,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:12,735][root][INFO] - Training Epoch: 1/2, step 5098/7134 completed (loss: 0.050456710159778595, acc: 0.9876265525817871)
[2024-12-17 04:17:12,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:13,190][root][INFO] - Training Epoch: 1/2, step 5099/7134 completed (loss: 0.05334306135773659, acc: 0.9838337302207947)
[2024-12-17 04:17:13,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:13,651][root][INFO] - Training Epoch: 1/2, step 5100/7134 completed (loss: 0.04928898066282272, acc: 0.9856828451156616)
[2024-12-17 04:17:13,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:14,103][root][INFO] - Training Epoch: 1/2, step 5101/7134 completed (loss: 0.04276547208428383, acc: 0.9871794581413269)
[2024-12-17 04:17:14,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:14,527][root][INFO] - Training Epoch: 1/2, step 5102/7134 completed (loss: 0.0663689598441124, acc: 0.9836289286613464)
[2024-12-17 04:17:14,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:14,995][root][INFO] - Training Epoch: 1/2, step 5103/7134 completed (loss: 0.06828764081001282, acc: 0.9793814420700073)
[2024-12-17 04:17:15,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:15,461][root][INFO] - Training Epoch: 1/2, step 5104/7134 completed (loss: 0.030494078993797302, acc: 0.9944629073143005)
[2024-12-17 04:17:15,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:15,856][root][INFO] - Training Epoch: 1/2, step 5105/7134 completed (loss: 0.035491086542606354, acc: 0.9910581111907959)
[2024-12-17 04:17:15,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:16,286][root][INFO] - Training Epoch: 1/2, step 5106/7134 completed (loss: 0.04013673961162567, acc: 0.9911110997200012)
[2024-12-17 04:17:16,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:16,709][root][INFO] - Training Epoch: 1/2, step 5107/7134 completed (loss: 0.11071817576885223, acc: 0.9762282371520996)
[2024-12-17 04:17:16,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:17,116][root][INFO] - Training Epoch: 1/2, step 5108/7134 completed (loss: 0.10145067423582077, acc: 0.9703832864761353)
[2024-12-17 04:17:17,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:17,583][root][INFO] - Training Epoch: 1/2, step 5109/7134 completed (loss: 0.0773659348487854, acc: 0.9756637215614319)
[2024-12-17 04:17:17,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:18,016][root][INFO] - Training Epoch: 1/2, step 5110/7134 completed (loss: 0.08680575340986252, acc: 0.9756410121917725)
[2024-12-17 04:17:18,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:18,431][root][INFO] - Training Epoch: 1/2, step 5111/7134 completed (loss: 0.0364883728325367, acc: 0.9876712560653687)
[2024-12-17 04:17:18,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:18,873][root][INFO] - Training Epoch: 1/2, step 5112/7134 completed (loss: 0.04531625658273697, acc: 0.9875466823577881)
[2024-12-17 04:17:18,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:19,266][root][INFO] - Training Epoch: 1/2, step 5113/7134 completed (loss: 0.07405351847410202, acc: 0.9791044592857361)
[2024-12-17 04:17:19,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:19,728][root][INFO] - Training Epoch: 1/2, step 5114/7134 completed (loss: 0.03751572594046593, acc: 0.9888734221458435)
[2024-12-17 04:17:19,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:20,155][root][INFO] - Training Epoch: 1/2, step 5115/7134 completed (loss: 0.023459333926439285, acc: 0.9948387145996094)
[2024-12-17 04:17:20,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:20,611][root][INFO] - Training Epoch: 1/2, step 5116/7134 completed (loss: 0.03856125473976135, acc: 0.9909090995788574)
[2024-12-17 04:17:20,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:21,030][root][INFO] - Training Epoch: 1/2, step 5117/7134 completed (loss: 0.033770374953746796, acc: 0.9902371168136597)
[2024-12-17 04:17:21,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:21,416][root][INFO] - Training Epoch: 1/2, step 5118/7134 completed (loss: 0.061179280281066895, acc: 0.9893778562545776)
[2024-12-17 04:17:21,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:21,847][root][INFO] - Training Epoch: 1/2, step 5119/7134 completed (loss: 0.057282429188489914, acc: 0.9862448573112488)
[2024-12-17 04:17:21,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:22,261][root][INFO] - Training Epoch: 1/2, step 5120/7134 completed (loss: 0.08944720774888992, acc: 0.9829843044281006)
[2024-12-17 04:17:22,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:22,681][root][INFO] - Training Epoch: 1/2, step 5121/7134 completed (loss: 0.0373617522418499, acc: 0.9930651783943176)
[2024-12-17 04:17:22,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:23,098][root][INFO] - Training Epoch: 1/2, step 5122/7134 completed (loss: 0.057708170264959335, acc: 0.9845288395881653)
[2024-12-17 04:17:23,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:23,543][root][INFO] - Training Epoch: 1/2, step 5123/7134 completed (loss: 0.03795422241091728, acc: 0.9903498291969299)
[2024-12-17 04:17:23,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:23,979][root][INFO] - Training Epoch: 1/2, step 5124/7134 completed (loss: 0.07065437734127045, acc: 0.9776397347450256)
[2024-12-17 04:17:24,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:24,409][root][INFO] - Training Epoch: 1/2, step 5125/7134 completed (loss: 0.04072396829724312, acc: 0.9921011328697205)
[2024-12-17 04:17:24,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:24,871][root][INFO] - Training Epoch: 1/2, step 5126/7134 completed (loss: 0.01991930603981018, acc: 0.9948717951774597)
[2024-12-17 04:17:25,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:25,313][root][INFO] - Training Epoch: 1/2, step 5127/7134 completed (loss: 0.05617348104715347, acc: 0.9874125719070435)
[2024-12-17 04:17:25,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:25,755][root][INFO] - Training Epoch: 1/2, step 5128/7134 completed (loss: 0.034544870257377625, acc: 0.9890109896659851)
[2024-12-17 04:17:25,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:26,181][root][INFO] - Training Epoch: 1/2, step 5129/7134 completed (loss: 0.06981285661458969, acc: 0.9764705896377563)
[2024-12-17 04:17:26,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:26,605][root][INFO] - Training Epoch: 1/2, step 5130/7134 completed (loss: 0.03200017288327217, acc: 0.9890795350074768)
[2024-12-17 04:17:26,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:27,049][root][INFO] - Training Epoch: 1/2, step 5131/7134 completed (loss: 0.0544193759560585, acc: 0.9886363744735718)
[2024-12-17 04:17:27,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:27,443][root][INFO] - Training Epoch: 1/2, step 5132/7134 completed (loss: 0.03006366454064846, acc: 0.9900990128517151)
[2024-12-17 04:17:27,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:27,895][root][INFO] - Training Epoch: 1/2, step 5133/7134 completed (loss: 0.08258821070194244, acc: 0.9736024737358093)
[2024-12-17 04:17:28,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:28,332][root][INFO] - Training Epoch: 1/2, step 5134/7134 completed (loss: 0.03197157010436058, acc: 0.9943714737892151)
[2024-12-17 04:17:28,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:28,746][root][INFO] - Training Epoch: 1/2, step 5135/7134 completed (loss: 0.06896389275789261, acc: 0.9842857122421265)
[2024-12-17 04:17:28,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:29,187][root][INFO] - Training Epoch: 1/2, step 5136/7134 completed (loss: 0.05372839421033859, acc: 0.9808743000030518)
[2024-12-17 04:17:29,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:29,616][root][INFO] - Training Epoch: 1/2, step 5137/7134 completed (loss: 0.032774899154901505, acc: 0.9926605224609375)
[2024-12-17 04:17:29,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:30,062][root][INFO] - Training Epoch: 1/2, step 5138/7134 completed (loss: 0.023548133671283722, acc: 0.9925000071525574)
[2024-12-17 04:17:30,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:30,464][root][INFO] - Training Epoch: 1/2, step 5139/7134 completed (loss: 0.031452156603336334, acc: 0.9871244430541992)
[2024-12-17 04:17:30,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:30,916][root][INFO] - Training Epoch: 1/2, step 5140/7134 completed (loss: 0.032203301787376404, acc: 0.9925768971443176)
[2024-12-17 04:17:30,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:31,228][root][INFO] - Training Epoch: 1/2, step 5141/7134 completed (loss: 0.07664327323436737, acc: 0.9806950092315674)
[2024-12-17 04:17:31,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:31,668][root][INFO] - Training Epoch: 1/2, step 5142/7134 completed (loss: 0.0460459366440773, acc: 0.9858823418617249)
[2024-12-17 04:17:31,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:32,117][root][INFO] - Training Epoch: 1/2, step 5143/7134 completed (loss: 0.05618638917803764, acc: 0.9860405921936035)
[2024-12-17 04:17:32,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:32,549][root][INFO] - Training Epoch: 1/2, step 5144/7134 completed (loss: 0.03439252823591232, acc: 0.9918319582939148)
[2024-12-17 04:17:32,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:33,012][root][INFO] - Training Epoch: 1/2, step 5145/7134 completed (loss: 0.031308211386203766, acc: 0.9918116927146912)
[2024-12-17 04:17:33,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:33,465][root][INFO] - Training Epoch: 1/2, step 5146/7134 completed (loss: 0.07489844411611557, acc: 0.9743589758872986)
[2024-12-17 04:17:33,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:33,871][root][INFO] - Training Epoch: 1/2, step 5147/7134 completed (loss: 0.02867320366203785, acc: 0.9890710115432739)
[2024-12-17 04:17:33,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:34,283][root][INFO] - Training Epoch: 1/2, step 5148/7134 completed (loss: 0.10559210926294327, acc: 0.974700391292572)
[2024-12-17 04:17:34,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:34,748][root][INFO] - Training Epoch: 1/2, step 5149/7134 completed (loss: 0.08128475397825241, acc: 0.9791044592857361)
[2024-12-17 04:17:34,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:35,175][root][INFO] - Training Epoch: 1/2, step 5150/7134 completed (loss: 0.09964603185653687, acc: 0.9726206064224243)
[2024-12-17 04:17:35,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:35,598][root][INFO] - Training Epoch: 1/2, step 5151/7134 completed (loss: 0.048269499093294144, acc: 0.9851484894752502)
[2024-12-17 04:17:35,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:36,034][root][INFO] - Training Epoch: 1/2, step 5152/7134 completed (loss: 0.05150964856147766, acc: 0.98525470495224)
[2024-12-17 04:17:36,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:36,472][root][INFO] - Training Epoch: 1/2, step 5153/7134 completed (loss: 0.040370646864175797, acc: 0.9890260696411133)
[2024-12-17 04:17:36,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:36,933][root][INFO] - Training Epoch: 1/2, step 5154/7134 completed (loss: 0.05184075981378555, acc: 0.9840728044509888)
[2024-12-17 04:17:37,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:37,366][root][INFO] - Training Epoch: 1/2, step 5155/7134 completed (loss: 0.05967748165130615, acc: 0.9864457845687866)
[2024-12-17 04:17:37,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:37,853][root][INFO] - Training Epoch: 1/2, step 5156/7134 completed (loss: 0.035931892693042755, acc: 0.9880834221839905)
[2024-12-17 04:17:37,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:38,293][root][INFO] - Training Epoch: 1/2, step 5157/7134 completed (loss: 0.09551289677619934, acc: 0.9743276238441467)
[2024-12-17 04:17:38,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:38,734][root][INFO] - Training Epoch: 1/2, step 5158/7134 completed (loss: 0.08560898900032043, acc: 0.9762611389160156)
[2024-12-17 04:17:38,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:39,160][root][INFO] - Training Epoch: 1/2, step 5159/7134 completed (loss: 0.028761081397533417, acc: 0.9921976327896118)
[2024-12-17 04:17:39,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:39,579][root][INFO] - Training Epoch: 1/2, step 5160/7134 completed (loss: 0.07164593040943146, acc: 0.9783861637115479)
[2024-12-17 04:17:39,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:40,005][root][INFO] - Training Epoch: 1/2, step 5161/7134 completed (loss: 0.13271905481815338, acc: 0.9622377753257751)
[2024-12-17 04:17:40,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:40,421][root][INFO] - Training Epoch: 1/2, step 5162/7134 completed (loss: 0.06173022836446762, acc: 0.9837925434112549)
[2024-12-17 04:17:40,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:40,855][root][INFO] - Training Epoch: 1/2, step 5163/7134 completed (loss: 0.03335835412144661, acc: 0.9929178357124329)
[2024-12-17 04:17:40,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:41,268][root][INFO] - Training Epoch: 1/2, step 5164/7134 completed (loss: 0.031008794903755188, acc: 0.9949579834938049)
[2024-12-17 04:17:41,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:41,725][root][INFO] - Training Epoch: 1/2, step 5165/7134 completed (loss: 0.05143929272890091, acc: 0.9864457845687866)
[2024-12-17 04:17:41,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:42,145][root][INFO] - Training Epoch: 1/2, step 5166/7134 completed (loss: 0.03694536164402962, acc: 0.9939117431640625)
[2024-12-17 04:17:42,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:42,560][root][INFO] - Training Epoch: 1/2, step 5167/7134 completed (loss: 0.09294866770505905, acc: 0.9727563858032227)
[2024-12-17 04:17:42,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:42,968][root][INFO] - Training Epoch: 1/2, step 5168/7134 completed (loss: 0.05574849992990494, acc: 0.9844720363616943)
[2024-12-17 04:17:43,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:43,403][root][INFO] - Training Epoch: 1/2, step 5169/7134 completed (loss: 0.07727079093456268, acc: 0.9797507524490356)
[2024-12-17 04:17:43,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:43,837][root][INFO] - Training Epoch: 1/2, step 5170/7134 completed (loss: 0.057973362505435944, acc: 0.9814569354057312)
[2024-12-17 04:17:43,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:44,201][root][INFO] - Training Epoch: 1/2, step 5171/7134 completed (loss: 0.043544840067625046, acc: 0.9850427508354187)
[2024-12-17 04:17:44,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:44,632][root][INFO] - Training Epoch: 1/2, step 5172/7134 completed (loss: 0.10562240332365036, acc: 0.9778534770011902)
[2024-12-17 04:17:44,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:45,036][root][INFO] - Training Epoch: 1/2, step 5173/7134 completed (loss: 0.06319214403629303, acc: 0.982677161693573)
[2024-12-17 04:17:45,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:45,475][root][INFO] - Training Epoch: 1/2, step 5174/7134 completed (loss: 0.029534827917814255, acc: 0.9936143159866333)
[2024-12-17 04:17:45,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:45,919][root][INFO] - Training Epoch: 1/2, step 5175/7134 completed (loss: 0.03239425644278526, acc: 0.9917126893997192)
[2024-12-17 04:17:46,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:46,362][root][INFO] - Training Epoch: 1/2, step 5176/7134 completed (loss: 0.04229465499520302, acc: 0.9863429665565491)
[2024-12-17 04:17:46,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:46,803][root][INFO] - Training Epoch: 1/2, step 5177/7134 completed (loss: 0.10723734647035599, acc: 0.9686956405639648)
[2024-12-17 04:17:46,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:47,216][root][INFO] - Training Epoch: 1/2, step 5178/7134 completed (loss: 0.1311265379190445, acc: 0.9721254110336304)
[2024-12-17 04:17:47,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:47,643][root][INFO] - Training Epoch: 1/2, step 5179/7134 completed (loss: 0.04949738457798958, acc: 0.9896449446678162)
[2024-12-17 04:17:47,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:48,047][root][INFO] - Training Epoch: 1/2, step 5180/7134 completed (loss: 0.07155723869800568, acc: 0.9812382459640503)
[2024-12-17 04:17:48,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:48,398][root][INFO] - Training Epoch: 1/2, step 5181/7134 completed (loss: 0.1052212342619896, acc: 0.9680851101875305)
[2024-12-17 04:17:48,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:48,797][root][INFO] - Training Epoch: 1/2, step 5182/7134 completed (loss: 0.20206207036972046, acc: 0.949999988079071)
[2024-12-17 04:17:48,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:49,229][root][INFO] - Training Epoch: 1/2, step 5183/7134 completed (loss: 0.07249504327774048, acc: 0.9834983348846436)
[2024-12-17 04:17:49,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:49,629][root][INFO] - Training Epoch: 1/2, step 5184/7134 completed (loss: 0.07308490574359894, acc: 0.9828850626945496)
[2024-12-17 04:17:49,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:50,037][root][INFO] - Training Epoch: 1/2, step 5185/7134 completed (loss: 0.04647481441497803, acc: 0.9879518151283264)
[2024-12-17 04:17:50,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:50,444][root][INFO] - Training Epoch: 1/2, step 5186/7134 completed (loss: 0.07355664670467377, acc: 0.9755600690841675)
[2024-12-17 04:17:50,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:50,846][root][INFO] - Training Epoch: 1/2, step 5187/7134 completed (loss: 0.03468252718448639, acc: 0.9923809766769409)
[2024-12-17 04:17:50,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:51,281][root][INFO] - Training Epoch: 1/2, step 5188/7134 completed (loss: 0.2357296496629715, acc: 0.9381818175315857)
[2024-12-17 04:17:51,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:51,588][root][INFO] - Training Epoch: 1/2, step 5189/7134 completed (loss: 0.19169706106185913, acc: 0.9591836929321289)
[2024-12-17 04:17:51,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:51,934][root][INFO] - Training Epoch: 1/2, step 5190/7134 completed (loss: 0.17010731995105743, acc: 0.9453681707382202)
[2024-12-17 04:17:52,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:52,387][root][INFO] - Training Epoch: 1/2, step 5191/7134 completed (loss: 0.1432073712348938, acc: 0.9648609161376953)
[2024-12-17 04:17:52,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:52,821][root][INFO] - Training Epoch: 1/2, step 5192/7134 completed (loss: 0.08083125203847885, acc: 0.9809750318527222)
[2024-12-17 04:17:52,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:53,248][root][INFO] - Training Epoch: 1/2, step 5193/7134 completed (loss: 0.06700335443019867, acc: 0.9783464670181274)
[2024-12-17 04:17:53,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:53,659][root][INFO] - Training Epoch: 1/2, step 5194/7134 completed (loss: 0.1508028656244278, acc: 0.9584158658981323)
[2024-12-17 04:17:53,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:54,029][root][INFO] - Training Epoch: 1/2, step 5195/7134 completed (loss: 0.09253279864788055, acc: 0.9758771657943726)
[2024-12-17 04:17:54,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:54,388][root][INFO] - Training Epoch: 1/2, step 5196/7134 completed (loss: 0.09174846112728119, acc: 0.980861246585846)
[2024-12-17 04:17:54,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:54,784][root][INFO] - Training Epoch: 1/2, step 5197/7134 completed (loss: 0.05950155109167099, acc: 0.9855967164039612)
[2024-12-17 04:17:54,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:55,165][root][INFO] - Training Epoch: 1/2, step 5198/7134 completed (loss: 0.07751139998435974, acc: 0.9854469895362854)
[2024-12-17 04:17:55,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:55,632][root][INFO] - Training Epoch: 1/2, step 5199/7134 completed (loss: 0.16132549941539764, acc: 0.9636628031730652)
[2024-12-17 04:17:55,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:56,046][root][INFO] - Training Epoch: 1/2, step 5200/7134 completed (loss: 0.10142605006694794, acc: 0.974459707736969)
[2024-12-17 04:17:56,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:56,488][root][INFO] - Training Epoch: 1/2, step 5201/7134 completed (loss: 0.09640273451805115, acc: 0.9746682643890381)
[2024-12-17 04:17:56,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:56,897][root][INFO] - Training Epoch: 1/2, step 5202/7134 completed (loss: 0.09454966336488724, acc: 0.9752747416496277)
[2024-12-17 04:17:56,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:57,337][root][INFO] - Training Epoch: 1/2, step 5203/7134 completed (loss: 0.10302548855543137, acc: 0.9727891087532043)
[2024-12-17 04:17:57,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:57,733][root][INFO] - Training Epoch: 1/2, step 5204/7134 completed (loss: 0.05002601817250252, acc: 0.985567033290863)
[2024-12-17 04:17:57,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:58,048][root][INFO] - Training Epoch: 1/2, step 5205/7134 completed (loss: 0.09117152541875839, acc: 0.9700374603271484)
[2024-12-17 04:17:58,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:58,500][root][INFO] - Training Epoch: 1/2, step 5206/7134 completed (loss: 0.10619167983531952, acc: 0.9678972959518433)
[2024-12-17 04:17:58,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:58,885][root][INFO] - Training Epoch: 1/2, step 5207/7134 completed (loss: 0.13134197890758514, acc: 0.9657947421073914)
[2024-12-17 04:17:58,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:59,372][root][INFO] - Training Epoch: 1/2, step 5208/7134 completed (loss: 0.037036556750535965, acc: 0.9920844435691833)
[2024-12-17 04:17:59,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:17:59,776][root][INFO] - Training Epoch: 1/2, step 5209/7134 completed (loss: 0.09246457368135452, acc: 0.9718875288963318)
[2024-12-17 04:17:59,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:00,250][root][INFO] - Training Epoch: 1/2, step 5210/7134 completed (loss: 0.038667649030685425, acc: 0.9893190860748291)
[2024-12-17 04:18:00,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:00,691][root][INFO] - Training Epoch: 1/2, step 5211/7134 completed (loss: 0.07352380454540253, acc: 0.9756944179534912)
[2024-12-17 04:18:00,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:01,042][root][INFO] - Training Epoch: 1/2, step 5212/7134 completed (loss: 0.12474483251571655, acc: 0.9590443968772888)
[2024-12-17 04:18:01,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:01,458][root][INFO] - Training Epoch: 1/2, step 5213/7134 completed (loss: 0.07186733931303024, acc: 0.9820144176483154)
[2024-12-17 04:18:01,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:01,856][root][INFO] - Training Epoch: 1/2, step 5214/7134 completed (loss: 0.15809760987758636, acc: 0.9527897238731384)
[2024-12-17 04:18:01,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:02,321][root][INFO] - Training Epoch: 1/2, step 5215/7134 completed (loss: 0.11704156547784805, acc: 0.969348669052124)
[2024-12-17 04:18:02,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:02,631][root][INFO] - Training Epoch: 1/2, step 5216/7134 completed (loss: 0.09470410645008087, acc: 0.9733840227127075)
[2024-12-17 04:18:02,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:03,004][root][INFO] - Training Epoch: 1/2, step 5217/7134 completed (loss: 0.09744872152805328, acc: 0.9817073345184326)
[2024-12-17 04:18:03,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:03,387][root][INFO] - Training Epoch: 1/2, step 5218/7134 completed (loss: 0.05157947912812233, acc: 0.9887640476226807)
[2024-12-17 04:18:03,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:03,768][root][INFO] - Training Epoch: 1/2, step 5219/7134 completed (loss: 0.06837597489356995, acc: 0.980629563331604)
[2024-12-17 04:18:03,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:04,127][root][INFO] - Training Epoch: 1/2, step 5220/7134 completed (loss: 0.11829658597707748, acc: 0.9660107493400574)
[2024-12-17 04:18:04,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:04,547][root][INFO] - Training Epoch: 1/2, step 5221/7134 completed (loss: 0.10218323767185211, acc: 0.9719626307487488)
[2024-12-17 04:18:04,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:04,832][root][INFO] - Training Epoch: 1/2, step 5222/7134 completed (loss: 0.046729110181331635, acc: 0.9875389337539673)
[2024-12-17 04:18:04,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:05,217][root][INFO] - Training Epoch: 1/2, step 5223/7134 completed (loss: 0.06787072122097015, acc: 0.981566846370697)
[2024-12-17 04:18:05,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:05,623][root][INFO] - Training Epoch: 1/2, step 5224/7134 completed (loss: 0.09026863425970078, acc: 0.9789103865623474)
[2024-12-17 04:18:05,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:06,053][root][INFO] - Training Epoch: 1/2, step 5225/7134 completed (loss: 0.08264792710542679, acc: 0.9773828983306885)
[2024-12-17 04:18:06,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:06,485][root][INFO] - Training Epoch: 1/2, step 5226/7134 completed (loss: 0.08547606319189072, acc: 0.9752883315086365)
[2024-12-17 04:18:06,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:06,935][root][INFO] - Training Epoch: 1/2, step 5227/7134 completed (loss: 0.04517132043838501, acc: 0.9870129823684692)
[2024-12-17 04:18:07,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:07,350][root][INFO] - Training Epoch: 1/2, step 5228/7134 completed (loss: 0.0671863779425621, acc: 0.9811046719551086)
[2024-12-17 04:18:07,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:07,773][root][INFO] - Training Epoch: 1/2, step 5229/7134 completed (loss: 0.059841979295015335, acc: 0.9806835055351257)
[2024-12-17 04:18:07,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:08,207][root][INFO] - Training Epoch: 1/2, step 5230/7134 completed (loss: 0.05218522995710373, acc: 0.9824798107147217)
[2024-12-17 04:18:08,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:08,672][root][INFO] - Training Epoch: 1/2, step 5231/7134 completed (loss: 0.02900308556854725, acc: 0.9936708807945251)
[2024-12-17 04:18:08,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:09,098][root][INFO] - Training Epoch: 1/2, step 5232/7134 completed (loss: 0.06121589615941048, acc: 0.9865471124649048)
[2024-12-17 04:18:09,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:09,566][root][INFO] - Training Epoch: 1/2, step 5233/7134 completed (loss: 0.056450553238391876, acc: 0.9864864945411682)
[2024-12-17 04:18:09,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:10,019][root][INFO] - Training Epoch: 1/2, step 5234/7134 completed (loss: 0.05019621551036835, acc: 0.9853121042251587)
[2024-12-17 04:18:10,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:10,420][root][INFO] - Training Epoch: 1/2, step 5235/7134 completed (loss: 0.04387380927801132, acc: 0.9848739504814148)
[2024-12-17 04:18:10,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:10,832][root][INFO] - Training Epoch: 1/2, step 5236/7134 completed (loss: 0.021008076146245003, acc: 0.9965277910232544)
[2024-12-17 04:18:10,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:11,260][root][INFO] - Training Epoch: 1/2, step 5237/7134 completed (loss: 0.01965174451470375, acc: 0.9928315281867981)
[2024-12-17 04:18:11,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:11,702][root][INFO] - Training Epoch: 1/2, step 5238/7134 completed (loss: 0.033230602741241455, acc: 0.9876760840415955)
[2024-12-17 04:18:11,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:12,085][root][INFO] - Training Epoch: 1/2, step 5239/7134 completed (loss: 0.047219596803188324, acc: 0.9864864945411682)
[2024-12-17 04:18:12,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:12,505][root][INFO] - Training Epoch: 1/2, step 5240/7134 completed (loss: 0.030740216374397278, acc: 0.9889349937438965)
[2024-12-17 04:18:12,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:12,945][root][INFO] - Training Epoch: 1/2, step 5241/7134 completed (loss: 0.06172215938568115, acc: 0.9843260049819946)
[2024-12-17 04:18:13,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:13,403][root][INFO] - Training Epoch: 1/2, step 5242/7134 completed (loss: 0.024694424122571945, acc: 0.9933884143829346)
[2024-12-17 04:18:13,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:13,826][root][INFO] - Training Epoch: 1/2, step 5243/7134 completed (loss: 0.0386747382581234, acc: 0.9913793206214905)
[2024-12-17 04:18:13,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:14,223][root][INFO] - Training Epoch: 1/2, step 5244/7134 completed (loss: 0.05213453620672226, acc: 0.9875862002372742)
[2024-12-17 04:18:14,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:14,721][root][INFO] - Training Epoch: 1/2, step 5245/7134 completed (loss: 0.032741647213697433, acc: 0.9895287752151489)
[2024-12-17 04:18:14,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:15,152][root][INFO] - Training Epoch: 1/2, step 5246/7134 completed (loss: 0.04976070299744606, acc: 0.9861963391304016)
[2024-12-17 04:18:15,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:15,576][root][INFO] - Training Epoch: 1/2, step 5247/7134 completed (loss: 0.025218935683369637, acc: 0.9944444298744202)
[2024-12-17 04:18:15,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:15,984][root][INFO] - Training Epoch: 1/2, step 5248/7134 completed (loss: 0.10815423727035522, acc: 0.9775280952453613)
[2024-12-17 04:18:16,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:16,395][root][INFO] - Training Epoch: 1/2, step 5249/7134 completed (loss: 0.030957557260990143, acc: 0.9905660152435303)
[2024-12-17 04:18:16,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:16,840][root][INFO] - Training Epoch: 1/2, step 5250/7134 completed (loss: 0.03926495462656021, acc: 0.9911727905273438)
[2024-12-17 04:18:16,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:17,274][root][INFO] - Training Epoch: 1/2, step 5251/7134 completed (loss: 0.05278801545500755, acc: 0.9830303192138672)
[2024-12-17 04:18:17,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:17,666][root][INFO] - Training Epoch: 1/2, step 5252/7134 completed (loss: 0.08437313884496689, acc: 0.9813084006309509)
[2024-12-17 04:18:17,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:18,092][root][INFO] - Training Epoch: 1/2, step 5253/7134 completed (loss: 0.025159824639558792, acc: 0.9967319965362549)
[2024-12-17 04:18:18,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:18,525][root][INFO] - Training Epoch: 1/2, step 5254/7134 completed (loss: 0.06491752713918686, acc: 0.979626476764679)
[2024-12-17 04:18:18,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:18,960][root][INFO] - Training Epoch: 1/2, step 5255/7134 completed (loss: 0.06354530900716782, acc: 0.9904109835624695)
[2024-12-17 04:18:19,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:19,399][root][INFO] - Training Epoch: 1/2, step 5256/7134 completed (loss: 0.061029065400362015, acc: 0.9876352548599243)
[2024-12-17 04:18:19,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:19,840][root][INFO] - Training Epoch: 1/2, step 5257/7134 completed (loss: 0.08698353171348572, acc: 0.9741247892379761)
[2024-12-17 04:18:19,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:20,280][root][INFO] - Training Epoch: 1/2, step 5258/7134 completed (loss: 0.07148178666830063, acc: 0.9821428656578064)
[2024-12-17 04:18:20,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:20,716][root][INFO] - Training Epoch: 1/2, step 5259/7134 completed (loss: 0.08478496223688126, acc: 0.982594907283783)
[2024-12-17 04:18:20,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:21,152][root][INFO] - Training Epoch: 1/2, step 5260/7134 completed (loss: 0.036640506237745285, acc: 0.9902439117431641)
[2024-12-17 04:18:21,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:21,557][root][INFO] - Training Epoch: 1/2, step 5261/7134 completed (loss: 0.08434227108955383, acc: 0.9750000238418579)
[2024-12-17 04:18:21,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:22,009][root][INFO] - Training Epoch: 1/2, step 5262/7134 completed (loss: 0.03922423720359802, acc: 0.9903448224067688)
[2024-12-17 04:18:22,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:22,412][root][INFO] - Training Epoch: 1/2, step 5263/7134 completed (loss: 0.06453194469213486, acc: 0.9824561476707458)
[2024-12-17 04:18:22,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:22,876][root][INFO] - Training Epoch: 1/2, step 5264/7134 completed (loss: 0.05213187634944916, acc: 0.9866342544555664)
[2024-12-17 04:18:23,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:23,341][root][INFO] - Training Epoch: 1/2, step 5265/7134 completed (loss: 0.05347421392798424, acc: 0.9860228896141052)
[2024-12-17 04:18:23,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:23,754][root][INFO] - Training Epoch: 1/2, step 5266/7134 completed (loss: 0.035924170166254044, acc: 0.9876712560653687)
[2024-12-17 04:18:23,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:24,147][root][INFO] - Training Epoch: 1/2, step 5267/7134 completed (loss: 0.0967143326997757, acc: 0.9751166701316833)
[2024-12-17 04:18:24,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:24,559][root][INFO] - Training Epoch: 1/2, step 5268/7134 completed (loss: 0.09277963638305664, acc: 0.9692898392677307)
[2024-12-17 04:18:24,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:24,984][root][INFO] - Training Epoch: 1/2, step 5269/7134 completed (loss: 0.12328514456748962, acc: 0.9749552607536316)
[2024-12-17 04:18:25,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:25,434][root][INFO] - Training Epoch: 1/2, step 5270/7134 completed (loss: 0.041268911212682724, acc: 0.9852941036224365)
[2024-12-17 04:18:25,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:25,867][root][INFO] - Training Epoch: 1/2, step 5271/7134 completed (loss: 0.10172583162784576, acc: 0.971781313419342)
[2024-12-17 04:18:25,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:26,289][root][INFO] - Training Epoch: 1/2, step 5272/7134 completed (loss: 0.039354439824819565, acc: 0.9853372573852539)
[2024-12-17 04:18:26,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:26,713][root][INFO] - Training Epoch: 1/2, step 5273/7134 completed (loss: 0.048519473522901535, acc: 0.9898132681846619)
[2024-12-17 04:18:26,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:27,131][root][INFO] - Training Epoch: 1/2, step 5274/7134 completed (loss: 0.08499310910701752, acc: 0.9761193990707397)
[2024-12-17 04:18:27,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:27,564][root][INFO] - Training Epoch: 1/2, step 5275/7134 completed (loss: 0.06370709836483002, acc: 0.9817184805870056)
[2024-12-17 04:18:27,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:27,965][root][INFO] - Training Epoch: 1/2, step 5276/7134 completed (loss: 0.07010409981012344, acc: 0.9760836958885193)
[2024-12-17 04:18:28,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:28,360][root][INFO] - Training Epoch: 1/2, step 5277/7134 completed (loss: 0.04884331300854683, acc: 0.9870316982269287)
[2024-12-17 04:18:28,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:28,785][root][INFO] - Training Epoch: 1/2, step 5278/7134 completed (loss: 0.09088841825723648, acc: 0.9694189429283142)
[2024-12-17 04:18:28,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:29,205][root][INFO] - Training Epoch: 1/2, step 5279/7134 completed (loss: 0.05925615876913071, acc: 0.9863813519477844)
[2024-12-17 04:18:29,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:29,629][root][INFO] - Training Epoch: 1/2, step 5280/7134 completed (loss: 0.07849356532096863, acc: 0.9850746393203735)
[2024-12-17 04:18:29,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:30,077][root][INFO] - Training Epoch: 1/2, step 5281/7134 completed (loss: 0.045699626207351685, acc: 0.9850249290466309)
[2024-12-17 04:18:30,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:30,487][root][INFO] - Training Epoch: 1/2, step 5282/7134 completed (loss: 0.05572208762168884, acc: 0.984308123588562)
[2024-12-17 04:18:30,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:30,925][root][INFO] - Training Epoch: 1/2, step 5283/7134 completed (loss: 0.038125306367874146, acc: 0.9890561103820801)
[2024-12-17 04:18:31,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:31,338][root][INFO] - Training Epoch: 1/2, step 5284/7134 completed (loss: 0.04848090931773186, acc: 0.9889349937438965)
[2024-12-17 04:18:31,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:31,790][root][INFO] - Training Epoch: 1/2, step 5285/7134 completed (loss: 0.0442734993994236, acc: 0.9917159676551819)
[2024-12-17 04:18:31,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:32,234][root][INFO] - Training Epoch: 1/2, step 5286/7134 completed (loss: 0.05299530550837517, acc: 0.9882352948188782)
[2024-12-17 04:18:32,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:32,673][root][INFO] - Training Epoch: 1/2, step 5287/7134 completed (loss: 0.05207286775112152, acc: 0.9823848009109497)
[2024-12-17 04:18:32,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:33,085][root][INFO] - Training Epoch: 1/2, step 5288/7134 completed (loss: 0.03471946716308594, acc: 0.9861963391304016)
[2024-12-17 04:18:33,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:33,528][root][INFO] - Training Epoch: 1/2, step 5289/7134 completed (loss: 0.05060497298836708, acc: 0.9830028414726257)
[2024-12-17 04:18:33,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:33,975][root][INFO] - Training Epoch: 1/2, step 5290/7134 completed (loss: 0.06031586229801178, acc: 0.9848101139068604)
[2024-12-17 04:18:34,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:34,427][root][INFO] - Training Epoch: 1/2, step 5291/7134 completed (loss: 0.0409599207341671, acc: 0.9939393997192383)
[2024-12-17 04:18:34,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:34,866][root][INFO] - Training Epoch: 1/2, step 5292/7134 completed (loss: 0.03267848119139671, acc: 0.991094172000885)
[2024-12-17 04:18:34,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:35,303][root][INFO] - Training Epoch: 1/2, step 5293/7134 completed (loss: 0.06770496815443039, acc: 0.9766423106193542)
[2024-12-17 04:18:35,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:35,743][root][INFO] - Training Epoch: 1/2, step 5294/7134 completed (loss: 0.06312273442745209, acc: 0.9818689227104187)
[2024-12-17 04:18:35,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:36,145][root][INFO] - Training Epoch: 1/2, step 5295/7134 completed (loss: 0.042842451483011246, acc: 0.9889705777168274)
[2024-12-17 04:18:36,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:36,584][root][INFO] - Training Epoch: 1/2, step 5296/7134 completed (loss: 0.04992463439702988, acc: 0.9847009778022766)
[2024-12-17 04:18:36,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:37,013][root][INFO] - Training Epoch: 1/2, step 5297/7134 completed (loss: 0.05568864569067955, acc: 0.9870689511299133)
[2024-12-17 04:18:37,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:37,496][root][INFO] - Training Epoch: 1/2, step 5298/7134 completed (loss: 0.04982282966375351, acc: 0.988034188747406)
[2024-12-17 04:18:37,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:37,896][root][INFO] - Training Epoch: 1/2, step 5299/7134 completed (loss: 0.035402439534664154, acc: 0.9903692007064819)
[2024-12-17 04:18:37,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:38,313][root][INFO] - Training Epoch: 1/2, step 5300/7134 completed (loss: 0.05309835076332092, acc: 0.9838472604751587)
[2024-12-17 04:18:38,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:38,722][root][INFO] - Training Epoch: 1/2, step 5301/7134 completed (loss: 0.043691787868738174, acc: 0.988252580165863)
[2024-12-17 04:18:38,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:39,169][root][INFO] - Training Epoch: 1/2, step 5302/7134 completed (loss: 0.07891826331615448, acc: 0.9832826852798462)
[2024-12-17 04:18:39,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:39,586][root][INFO] - Training Epoch: 1/2, step 5303/7134 completed (loss: 0.0886426568031311, acc: 0.9858406782150269)
[2024-12-17 04:18:39,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:39,997][root][INFO] - Training Epoch: 1/2, step 5304/7134 completed (loss: 0.09795990586280823, acc: 0.9783693552017212)
[2024-12-17 04:18:40,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:40,401][root][INFO] - Training Epoch: 1/2, step 5305/7134 completed (loss: 0.0858401283621788, acc: 0.9766423106193542)
[2024-12-17 04:18:40,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:40,839][root][INFO] - Training Epoch: 1/2, step 5306/7134 completed (loss: 0.06459411233663559, acc: 0.9819444417953491)
[2024-12-17 04:18:40,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:41,254][root][INFO] - Training Epoch: 1/2, step 5307/7134 completed (loss: 0.07510293275117874, acc: 0.9845678806304932)
[2024-12-17 04:18:41,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:41,653][root][INFO] - Training Epoch: 1/2, step 5308/7134 completed (loss: 0.08326086401939392, acc: 0.9848942756652832)
[2024-12-17 04:18:41,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:42,051][root][INFO] - Training Epoch: 1/2, step 5309/7134 completed (loss: 0.1422027200460434, acc: 0.9677996635437012)
[2024-12-17 04:18:42,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:42,492][root][INFO] - Training Epoch: 1/2, step 5310/7134 completed (loss: 0.11201541870832443, acc: 0.9748954176902771)
[2024-12-17 04:18:42,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:42,944][root][INFO] - Training Epoch: 1/2, step 5311/7134 completed (loss: 0.06795370578765869, acc: 0.9823434948921204)
[2024-12-17 04:18:43,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:43,331][root][INFO] - Training Epoch: 1/2, step 5312/7134 completed (loss: 0.07000815123319626, acc: 0.9812382459640503)
[2024-12-17 04:18:43,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:43,756][root][INFO] - Training Epoch: 1/2, step 5313/7134 completed (loss: 0.049401625990867615, acc: 0.9854280352592468)
[2024-12-17 04:18:43,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:44,165][root][INFO] - Training Epoch: 1/2, step 5314/7134 completed (loss: 0.0474429726600647, acc: 0.9878048896789551)
[2024-12-17 04:18:44,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:44,596][root][INFO] - Training Epoch: 1/2, step 5315/7134 completed (loss: 0.04452721029520035, acc: 0.9885433912277222)
[2024-12-17 04:18:44,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:45,001][root][INFO] - Training Epoch: 1/2, step 5316/7134 completed (loss: 0.05869282782077789, acc: 0.9848739504814148)
[2024-12-17 04:18:45,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:45,382][root][INFO] - Training Epoch: 1/2, step 5317/7134 completed (loss: 0.03880325332283974, acc: 0.9892473220825195)
[2024-12-17 04:18:45,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:45,774][root][INFO] - Training Epoch: 1/2, step 5318/7134 completed (loss: 0.03363386169075966, acc: 0.9913644194602966)
[2024-12-17 04:18:45,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:46,176][root][INFO] - Training Epoch: 1/2, step 5319/7134 completed (loss: 0.07276671379804611, acc: 0.9817517995834351)
[2024-12-17 04:18:46,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:46,597][root][INFO] - Training Epoch: 1/2, step 5320/7134 completed (loss: 0.04424956068396568, acc: 0.989130437374115)
[2024-12-17 04:18:46,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:47,005][root][INFO] - Training Epoch: 1/2, step 5321/7134 completed (loss: 0.03828299045562744, acc: 0.9891473054885864)
[2024-12-17 04:18:47,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:47,419][root][INFO] - Training Epoch: 1/2, step 5322/7134 completed (loss: 0.041820183396339417, acc: 0.9879336357116699)
[2024-12-17 04:18:47,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:47,840][root][INFO] - Training Epoch: 1/2, step 5323/7134 completed (loss: 0.050038233399391174, acc: 0.9848484992980957)
[2024-12-17 04:18:47,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:48,242][root][INFO] - Training Epoch: 1/2, step 5324/7134 completed (loss: 0.04253612831234932, acc: 0.989180862903595)
[2024-12-17 04:18:48,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:48,656][root][INFO] - Training Epoch: 1/2, step 5325/7134 completed (loss: 0.035163089632987976, acc: 0.991482138633728)
[2024-12-17 04:18:48,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:49,067][root][INFO] - Training Epoch: 1/2, step 5326/7134 completed (loss: 0.05536503344774246, acc: 0.9870967864990234)
[2024-12-17 04:18:49,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:49,474][root][INFO] - Training Epoch: 1/2, step 5327/7134 completed (loss: 0.05121788755059242, acc: 0.9883889555931091)
[2024-12-17 04:18:49,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:49,866][root][INFO] - Training Epoch: 1/2, step 5328/7134 completed (loss: 0.024776028469204903, acc: 0.9926605224609375)
[2024-12-17 04:18:49,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:50,273][root][INFO] - Training Epoch: 1/2, step 5329/7134 completed (loss: 0.06321702152490616, acc: 0.9805510640144348)
[2024-12-17 04:18:50,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:50,687][root][INFO] - Training Epoch: 1/2, step 5330/7134 completed (loss: 0.06252488493919373, acc: 0.981249988079071)
[2024-12-17 04:18:50,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:51,088][root][INFO] - Training Epoch: 1/2, step 5331/7134 completed (loss: 0.0578758604824543, acc: 0.985989511013031)
[2024-12-17 04:18:51,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:51,507][root][INFO] - Training Epoch: 1/2, step 5332/7134 completed (loss: 0.04181257262825966, acc: 0.9918699264526367)
[2024-12-17 04:18:51,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:51,906][root][INFO] - Training Epoch: 1/2, step 5333/7134 completed (loss: 0.021317757666110992, acc: 0.9937694668769836)
[2024-12-17 04:18:51,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:52,312][root][INFO] - Training Epoch: 1/2, step 5334/7134 completed (loss: 0.10655727982521057, acc: 0.9785605072975159)
[2024-12-17 04:18:52,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:52,710][root][INFO] - Training Epoch: 1/2, step 5335/7134 completed (loss: 0.06323880702257156, acc: 0.9856230020523071)
[2024-12-17 04:18:52,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:53,139][root][INFO] - Training Epoch: 1/2, step 5336/7134 completed (loss: 0.04815473034977913, acc: 0.9828125238418579)
[2024-12-17 04:18:53,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:53,588][root][INFO] - Training Epoch: 1/2, step 5337/7134 completed (loss: 0.07155748456716537, acc: 0.9777283072471619)
[2024-12-17 04:18:53,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:54,076][root][INFO] - Training Epoch: 1/2, step 5338/7134 completed (loss: 0.0506114661693573, acc: 0.9874429106712341)
[2024-12-17 04:18:54,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:54,485][root][INFO] - Training Epoch: 1/2, step 5339/7134 completed (loss: 0.07165005058050156, acc: 0.9792746305465698)
[2024-12-17 04:18:54,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:54,924][root][INFO] - Training Epoch: 1/2, step 5340/7134 completed (loss: 0.06944086402654648, acc: 0.9757365584373474)
[2024-12-17 04:18:55,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:55,351][root][INFO] - Training Epoch: 1/2, step 5341/7134 completed (loss: 0.03313380852341652, acc: 0.9920904040336609)
[2024-12-17 04:18:55,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:55,830][root][INFO] - Training Epoch: 1/2, step 5342/7134 completed (loss: 0.09958355873823166, acc: 0.9707057476043701)
[2024-12-17 04:18:55,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:56,276][root][INFO] - Training Epoch: 1/2, step 5343/7134 completed (loss: 0.0644783079624176, acc: 0.9815303683280945)
[2024-12-17 04:18:56,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:56,725][root][INFO] - Training Epoch: 1/2, step 5344/7134 completed (loss: 0.07497073709964752, acc: 0.9800000190734863)
[2024-12-17 04:18:56,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:57,157][root][INFO] - Training Epoch: 1/2, step 5345/7134 completed (loss: 0.04754131659865379, acc: 0.9839080572128296)
[2024-12-17 04:18:57,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:57,591][root][INFO] - Training Epoch: 1/2, step 5346/7134 completed (loss: 0.09200140833854675, acc: 0.9779643416404724)
[2024-12-17 04:18:57,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:58,042][root][INFO] - Training Epoch: 1/2, step 5347/7134 completed (loss: 0.046090029180049896, acc: 0.9814323782920837)
[2024-12-17 04:18:58,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:58,503][root][INFO] - Training Epoch: 1/2, step 5348/7134 completed (loss: 0.06394334882497787, acc: 0.9833794832229614)
[2024-12-17 04:18:59,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:59,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:18:59,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:00,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:00,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:00,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:01,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:01,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:01,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:02,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:02,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:02,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:03,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:03,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:03,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:04,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:04,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:04,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:05,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:05,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:05,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:06,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:06,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:06,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:07,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:07,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:08,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:08,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:08,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:09,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:09,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:10,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:10,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:10,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:11,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:11,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:11,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:12,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:12,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:12,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:13,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:13,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:14,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:14,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:14,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:15,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:15,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:16,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:16,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:17,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:17,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:17,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:18,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:18,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:19,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:19,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:19,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:20,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:20,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:21,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:21,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:21,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:22,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:22,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:22,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:23,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:23,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:23,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:24,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:24,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:24,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:25,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:25,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:26,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:26,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:26,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:27,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:27,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:27,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:28,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:28,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:28,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:29,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:29,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:29,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:30,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:30,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:31,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:31,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:32,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:32,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:32,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:33,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:33,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:33,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:34,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:34,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:34,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:34,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:35,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:35,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:35,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:36,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:36,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:37,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:37,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:37,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:37,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:38,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:38,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:39,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:39,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:39,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:40,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:40,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:41,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:41,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:41,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:41,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:42,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:42,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:42,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:43,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:43,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:44,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:44,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:44,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:45,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:45,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:45,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:46,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:46,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:46,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:47,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:47,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:47,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:48,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:48,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:49,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:49,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:50,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:50,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:50,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:51,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:51,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:51,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:52,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:52,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:53,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:53,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:53,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:54,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:54,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:54,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:55,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:55,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:55,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:56,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:56,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:56,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:57,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:57,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:57,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:58,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:58,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:58,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:59,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:19:59,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:00,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:00,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:00,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:01,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:01,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:01,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:02,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:02,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:03,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:03,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:03,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:04,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:04,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:05,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:05,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:05,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:06,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:06,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:06,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:07,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:07,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:07,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:08,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:08,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:09,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:09,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:09,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:10,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:10,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:11,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:11,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:11,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:12,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:12,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:12,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:13,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:13,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:14,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:14,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:14,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:14,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:15,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:15,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:15,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:16,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:16,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:16,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:17,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:17,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:17,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:18,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:18,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:19,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:19,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:19,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:20,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:20,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:20,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:21,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:21,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:21,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:22,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:22,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:22,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:23,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:23,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:23,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:24,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:24,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:24,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:25,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:25,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:25,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:26,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:26,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:26,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:27,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:27,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:28,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:28,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:29,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:29,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:29,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:30,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:30,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:30,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:31,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:31,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:32,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:32,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:32,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:33,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:33,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:33,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:34,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:34,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:34,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:35,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:35,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:36,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:36,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:36,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:37,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:37,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:38,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:38,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:38,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:39,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:39,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:39,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:40,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:40,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:41,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:41,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:42,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:42,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:42,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:43,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:43,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:44,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:44,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:44,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:45,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:45,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:45,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:46,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:46,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:47,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:47,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:48,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:48,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:48,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:49,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:49,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:49,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:49,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:50,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:50,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:51,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:51,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:51,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:52,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:52,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:52,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:53,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:53,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:54,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:54,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:54,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:55,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:55,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:55,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:56,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:56,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:56,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:57,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:57,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:57,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:58,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:58,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:59,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:59,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:20:59,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:00,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:00,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:00,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:01,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:01,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:01,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:02,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:02,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:02,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:03,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:03,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:04,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:04,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:04,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:05,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:05,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:06,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:06,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:06,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:06,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:07,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:07,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:07,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:08,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:08,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:08,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:09,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:09,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:09,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:10,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:11,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:11,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:12,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:12,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:13,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:13,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:14,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:14,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:14,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:15,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:15,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:15,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:16,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:16,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:17,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:17,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:17,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:17,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:18,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:18,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:18,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:19,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:19,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:19,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:20,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:20,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:20,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:21,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:21,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:21,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:22,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:22,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:22,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:23,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:23,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:24,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:24,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:24,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:25,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:25,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:25,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:26,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:26,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:27,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:27,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:27,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:27,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:28,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:28,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:28,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:29,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:29,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:29,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:30,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:30,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:30,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:31,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:31,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:31,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:32,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:32,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:32,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:33,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:33,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:33,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:34,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:34,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:35,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:35,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:35,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:36,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:36,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:36,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:37,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:37,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:37,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:37,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:38,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:38,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:38,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:39,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:39,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:40,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:40,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:40,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:41,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:41,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:41,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:42,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:42,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:42,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:43,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:43,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:44,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:44,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:44,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:45,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:45,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:45,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:46,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:46,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:46,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:47,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:47,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:47,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:48,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:48,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:48,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:49,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:49,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:49,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:50,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:50,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:50,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:51,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:51,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:51,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:52,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:52,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:53,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:53,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:53,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:54,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:54,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:55,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:55,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:55,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:56,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:56,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:57,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:57,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:57,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:58,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:58,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:59,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:59,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:21:59,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:00,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:00,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:00,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:01,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:01,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:02,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:02,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:02,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:03,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:03,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:03,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:04,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:04,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:05,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:05,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:05,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:06,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:06,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:06,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:07,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:07,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:07,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:08,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:08,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:09,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:09,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:09,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:10,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:10,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:10,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:11,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:11,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:11,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:12,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:12,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:12,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:13,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:13,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:13,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:14,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:14,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:15,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:15,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:15,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:15,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:16,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:16,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:17,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:17,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:17,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:18,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:18,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:18,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:19,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:19,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:20,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:20,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:20,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:21,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:21,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:22,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:22,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:22,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:23,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:23,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:23,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:24,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:24,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:24,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:25,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:25,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:25,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:26,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:26,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:27,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:27,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:27,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:28,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:28,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:28,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:29,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:29,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:30,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:30,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:30,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:31,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:31,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:32,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:32,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:32,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:33,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:33,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:34,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:34,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:34,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:35,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:35,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:36,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:36,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:36,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:37,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:37,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:37,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:38,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:38,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:39,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:39,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:39,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:40,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:40,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:41,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:41,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:41,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:42,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:42,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:42,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:43,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:43,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:43,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:44,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:44,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:45,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:45,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:46,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:46,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:46,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:47,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:47,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:48,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:49,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:49,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:50,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:50,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:50,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:51,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:51,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:52,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:52,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:52,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:53,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:53,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:54,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:54,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:54,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:55,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:55,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:56,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:56,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:57,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:57,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:58,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:58,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:58,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:59,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:59,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:59,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:22:59,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:00,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:00,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:01,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:01,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:02,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:02,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:02,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:03,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:03,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:04,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:04,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:04,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:04,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:05,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:05,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:05,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:06,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:06,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:07,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:07,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:08,139][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.0694, device='cuda:0') eval_epoch_loss=tensor(0.0671, device='cuda:0') eval_epoch_acc=tensor(0.9815, device='cuda:0')
[2024-12-17 04:23:08,141][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-17 04:23:08,141][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 04:23:08,396][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_1_step_5349_loss_0.06706485152244568/model.pt
[2024-12-17 04:23:08,399][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-12-17 04:23:08,400][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 0.06706485152244568
[2024-12-17 04:23:08,400][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.9814839959144592
[2024-12-17 04:23:08,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:08,844][root][INFO] - Training Epoch: 1/2, step 5349/7134 completed (loss: 0.08105511218309402, acc: 0.9767441749572754)
[2024-12-17 04:23:08,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:09,279][root][INFO] - Training Epoch: 1/2, step 5350/7134 completed (loss: 0.06268204003572464, acc: 0.9801849126815796)
[2024-12-17 04:23:09,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:09,693][root][INFO] - Training Epoch: 1/2, step 5351/7134 completed (loss: 0.08036419004201889, acc: 0.9764267802238464)
[2024-12-17 04:23:09,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:10,098][root][INFO] - Training Epoch: 1/2, step 5352/7134 completed (loss: 0.04890703037381172, acc: 0.9857697486877441)
[2024-12-17 04:23:10,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:10,558][root][INFO] - Training Epoch: 1/2, step 5353/7134 completed (loss: 0.023714331910014153, acc: 0.9921082258224487)
[2024-12-17 04:23:10,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:11,017][root][INFO] - Training Epoch: 1/2, step 5354/7134 completed (loss: 0.06911054998636246, acc: 0.9790748953819275)
[2024-12-17 04:23:11,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:11,456][root][INFO] - Training Epoch: 1/2, step 5355/7134 completed (loss: 0.09818749129772186, acc: 0.9763593673706055)
[2024-12-17 04:23:11,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:11,938][root][INFO] - Training Epoch: 1/2, step 5356/7134 completed (loss: 0.08240427076816559, acc: 0.975093424320221)
[2024-12-17 04:23:12,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:12,354][root][INFO] - Training Epoch: 1/2, step 5357/7134 completed (loss: 0.05496658384799957, acc: 0.9895470142364502)
[2024-12-17 04:23:12,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:12,802][root][INFO] - Training Epoch: 1/2, step 5358/7134 completed (loss: 0.0640842393040657, acc: 0.9889655113220215)
[2024-12-17 04:23:12,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:13,231][root][INFO] - Training Epoch: 1/2, step 5359/7134 completed (loss: 0.023449460044503212, acc: 0.9930070042610168)
[2024-12-17 04:23:13,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:13,660][root][INFO] - Training Epoch: 1/2, step 5360/7134 completed (loss: 0.02051512710750103, acc: 0.9917582273483276)
[2024-12-17 04:23:13,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:14,121][root][INFO] - Training Epoch: 1/2, step 5361/7134 completed (loss: 0.05564091354608536, acc: 0.9808382987976074)
[2024-12-17 04:23:14,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:14,570][root][INFO] - Training Epoch: 1/2, step 5362/7134 completed (loss: 0.04609088972210884, acc: 0.9850746393203735)
[2024-12-17 04:23:14,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:14,988][root][INFO] - Training Epoch: 1/2, step 5363/7134 completed (loss: 0.08532867580652237, acc: 0.9767441749572754)
[2024-12-17 04:23:15,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:15,417][root][INFO] - Training Epoch: 1/2, step 5364/7134 completed (loss: 0.04547129198908806, acc: 0.9857142567634583)
[2024-12-17 04:23:15,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:15,851][root][INFO] - Training Epoch: 1/2, step 5365/7134 completed (loss: 0.044388704001903534, acc: 0.9858906269073486)
[2024-12-17 04:23:15,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:16,241][root][INFO] - Training Epoch: 1/2, step 5366/7134 completed (loss: 0.07793564349412918, acc: 0.9826388955116272)
[2024-12-17 04:23:16,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:16,682][root][INFO] - Training Epoch: 1/2, step 5367/7134 completed (loss: 0.0445711687207222, acc: 0.983668327331543)
[2024-12-17 04:23:16,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:17,143][root][INFO] - Training Epoch: 1/2, step 5368/7134 completed (loss: 0.06193184107542038, acc: 0.9832776188850403)
[2024-12-17 04:23:17,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:17,563][root][INFO] - Training Epoch: 1/2, step 5369/7134 completed (loss: 0.04097558930516243, acc: 0.987261176109314)
[2024-12-17 04:23:17,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:17,999][root][INFO] - Training Epoch: 1/2, step 5370/7134 completed (loss: 0.0759134292602539, acc: 0.9843013882637024)
[2024-12-17 04:23:18,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:18,451][root][INFO] - Training Epoch: 1/2, step 5371/7134 completed (loss: 0.10140244662761688, acc: 0.9734219312667847)
[2024-12-17 04:23:18,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:18,892][root][INFO] - Training Epoch: 1/2, step 5372/7134 completed (loss: 0.02403462864458561, acc: 0.991584837436676)
[2024-12-17 04:23:18,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:19,295][root][INFO] - Training Epoch: 1/2, step 5373/7134 completed (loss: 0.09325435012578964, acc: 0.9707112908363342)
[2024-12-17 04:23:19,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:19,620][root][INFO] - Training Epoch: 1/2, step 5374/7134 completed (loss: 0.06967782229185104, acc: 0.9774919748306274)
[2024-12-17 04:23:19,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:20,027][root][INFO] - Training Epoch: 1/2, step 5375/7134 completed (loss: 0.06931433826684952, acc: 0.975095808506012)
[2024-12-17 04:23:20,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:20,456][root][INFO] - Training Epoch: 1/2, step 5376/7134 completed (loss: 0.04401664808392525, acc: 0.9843205809593201)
[2024-12-17 04:23:20,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:20,898][root][INFO] - Training Epoch: 1/2, step 5377/7134 completed (loss: 0.06034036725759506, acc: 0.9893778562545776)
[2024-12-17 04:23:21,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:21,357][root][INFO] - Training Epoch: 1/2, step 5378/7134 completed (loss: 0.02911103516817093, acc: 0.9927184581756592)
[2024-12-17 04:23:21,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:21,792][root][INFO] - Training Epoch: 1/2, step 5379/7134 completed (loss: 0.04920690134167671, acc: 0.9896238446235657)
[2024-12-17 04:23:21,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:22,204][root][INFO] - Training Epoch: 1/2, step 5380/7134 completed (loss: 0.05633481964468956, acc: 0.9841269850730896)
[2024-12-17 04:23:22,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:22,611][root][INFO] - Training Epoch: 1/2, step 5381/7134 completed (loss: 0.0570097453892231, acc: 0.9846583008766174)
[2024-12-17 04:23:22,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:23,021][root][INFO] - Training Epoch: 1/2, step 5382/7134 completed (loss: 0.025239067152142525, acc: 0.9931740760803223)
[2024-12-17 04:23:23,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:23,460][root][INFO] - Training Epoch: 1/2, step 5383/7134 completed (loss: 0.022387301549315453, acc: 0.9905303120613098)
[2024-12-17 04:23:23,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:23,924][root][INFO] - Training Epoch: 1/2, step 5384/7134 completed (loss: 0.020534634590148926, acc: 0.9940758347511292)
[2024-12-17 04:23:24,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:24,353][root][INFO] - Training Epoch: 1/2, step 5385/7134 completed (loss: 0.047544702887535095, acc: 0.9867899417877197)
[2024-12-17 04:23:24,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:24,785][root][INFO] - Training Epoch: 1/2, step 5386/7134 completed (loss: 0.0279412679374218, acc: 0.9943820238113403)
[2024-12-17 04:23:24,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:25,234][root][INFO] - Training Epoch: 1/2, step 5387/7134 completed (loss: 0.021338533610105515, acc: 0.9961904883384705)
[2024-12-17 04:23:25,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:25,676][root][INFO] - Training Epoch: 1/2, step 5388/7134 completed (loss: 0.02198355458676815, acc: 0.993686854839325)
[2024-12-17 04:23:25,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:26,089][root][INFO] - Training Epoch: 1/2, step 5389/7134 completed (loss: 0.036589328199625015, acc: 0.9888178706169128)
[2024-12-17 04:23:26,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:26,515][root][INFO] - Training Epoch: 1/2, step 5390/7134 completed (loss: 0.044682592153549194, acc: 0.9873217344284058)
[2024-12-17 04:23:26,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:26,898][root][INFO] - Training Epoch: 1/2, step 5391/7134 completed (loss: 0.07937092334032059, acc: 0.9828473329544067)
[2024-12-17 04:23:27,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:27,307][root][INFO] - Training Epoch: 1/2, step 5392/7134 completed (loss: 0.06881479918956757, acc: 0.9756097793579102)
[2024-12-17 04:23:27,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:27,743][root][INFO] - Training Epoch: 1/2, step 5393/7134 completed (loss: 0.04631819948554039, acc: 0.98046875)
[2024-12-17 04:23:27,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:28,125][root][INFO] - Training Epoch: 1/2, step 5394/7134 completed (loss: 0.07641204446554184, acc: 0.9702380895614624)
[2024-12-17 04:23:28,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:28,562][root][INFO] - Training Epoch: 1/2, step 5395/7134 completed (loss: 0.059984855353832245, acc: 0.9849170446395874)
[2024-12-17 04:23:28,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:28,983][root][INFO] - Training Epoch: 1/2, step 5396/7134 completed (loss: 0.06851129233837128, acc: 0.9819548726081848)
[2024-12-17 04:23:29,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:29,390][root][INFO] - Training Epoch: 1/2, step 5397/7134 completed (loss: 0.039054498076438904, acc: 0.9881556630134583)
[2024-12-17 04:23:29,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:29,834][root][INFO] - Training Epoch: 1/2, step 5398/7134 completed (loss: 0.0418156236410141, acc: 0.9896755218505859)
[2024-12-17 04:23:29,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:30,265][root][INFO] - Training Epoch: 1/2, step 5399/7134 completed (loss: 0.038899775594472885, acc: 0.9904240965843201)
[2024-12-17 04:23:30,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:30,689][root][INFO] - Training Epoch: 1/2, step 5400/7134 completed (loss: 0.11635978519916534, acc: 0.962382435798645)
[2024-12-17 04:23:30,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:31,110][root][INFO] - Training Epoch: 1/2, step 5401/7134 completed (loss: 0.040187541395425797, acc: 0.9903692007064819)
[2024-12-17 04:23:31,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:31,531][root][INFO] - Training Epoch: 1/2, step 5402/7134 completed (loss: 0.06927432119846344, acc: 0.9765051603317261)
[2024-12-17 04:23:31,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:31,904][root][INFO] - Training Epoch: 1/2, step 5403/7134 completed (loss: 0.0911252498626709, acc: 0.9722675085067749)
[2024-12-17 04:23:31,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:32,340][root][INFO] - Training Epoch: 1/2, step 5404/7134 completed (loss: 0.11644075810909271, acc: 0.9718120694160461)
[2024-12-17 04:23:32,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:32,831][root][INFO] - Training Epoch: 1/2, step 5405/7134 completed (loss: 0.06713949888944626, acc: 0.9790576100349426)
[2024-12-17 04:23:32,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:33,276][root][INFO] - Training Epoch: 1/2, step 5406/7134 completed (loss: 0.050181590020656586, acc: 0.9844054579734802)
[2024-12-17 04:23:33,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:33,668][root][INFO] - Training Epoch: 1/2, step 5407/7134 completed (loss: 0.0674915611743927, acc: 0.9830917716026306)
[2024-12-17 04:23:33,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:34,092][root][INFO] - Training Epoch: 1/2, step 5408/7134 completed (loss: 0.1031675785779953, acc: 0.9734789133071899)
[2024-12-17 04:23:34,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:34,507][root][INFO] - Training Epoch: 1/2, step 5409/7134 completed (loss: 0.12461575120687485, acc: 0.9773070812225342)
[2024-12-17 04:23:34,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:34,925][root][INFO] - Training Epoch: 1/2, step 5410/7134 completed (loss: 0.07535671442747116, acc: 0.9829396605491638)
[2024-12-17 04:23:35,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:35,350][root][INFO] - Training Epoch: 1/2, step 5411/7134 completed (loss: 0.1083250343799591, acc: 0.972423791885376)
[2024-12-17 04:23:35,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:35,804][root][INFO] - Training Epoch: 1/2, step 5412/7134 completed (loss: 0.15692675113677979, acc: 0.9653846025466919)
[2024-12-17 04:23:35,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:36,285][root][INFO] - Training Epoch: 1/2, step 5413/7134 completed (loss: 0.11120091378688812, acc: 0.9700000286102295)
[2024-12-17 04:23:36,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:36,742][root][INFO] - Training Epoch: 1/2, step 5414/7134 completed (loss: 0.16071289777755737, acc: 0.955012857913971)
[2024-12-17 04:23:36,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:37,163][root][INFO] - Training Epoch: 1/2, step 5415/7134 completed (loss: 0.10869336873292923, acc: 0.9699140191078186)
[2024-12-17 04:23:37,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:37,626][root][INFO] - Training Epoch: 1/2, step 5416/7134 completed (loss: 0.08744115382432938, acc: 0.9686411023139954)
[2024-12-17 04:23:37,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:38,079][root][INFO] - Training Epoch: 1/2, step 5417/7134 completed (loss: 0.059898409992456436, acc: 0.9800249934196472)
[2024-12-17 04:23:38,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:38,489][root][INFO] - Training Epoch: 1/2, step 5418/7134 completed (loss: 0.08295631408691406, acc: 0.9689807891845703)
[2024-12-17 04:23:38,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:38,903][root][INFO] - Training Epoch: 1/2, step 5419/7134 completed (loss: 0.1587817370891571, acc: 0.9593220353126526)
[2024-12-17 04:23:38,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:39,322][root][INFO] - Training Epoch: 1/2, step 5420/7134 completed (loss: 0.12747155129909515, acc: 0.9667832255363464)
[2024-12-17 04:23:39,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:39,768][root][INFO] - Training Epoch: 1/2, step 5421/7134 completed (loss: 0.1232578456401825, acc: 0.9672386646270752)
[2024-12-17 04:23:39,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:40,214][root][INFO] - Training Epoch: 1/2, step 5422/7134 completed (loss: 0.07763545215129852, acc: 0.9792899489402771)
[2024-12-17 04:23:40,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:40,565][root][INFO] - Training Epoch: 1/2, step 5423/7134 completed (loss: 0.1266569197177887, acc: 0.9677419066429138)
[2024-12-17 04:23:40,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:40,963][root][INFO] - Training Epoch: 1/2, step 5424/7134 completed (loss: 0.05220239982008934, acc: 0.9876760840415955)
[2024-12-17 04:23:41,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:41,337][root][INFO] - Training Epoch: 1/2, step 5425/7134 completed (loss: 0.06197250261902809, acc: 0.9805825352668762)
[2024-12-17 04:23:41,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:41,773][root][INFO] - Training Epoch: 1/2, step 5426/7134 completed (loss: 0.08706407248973846, acc: 0.9819276928901672)
[2024-12-17 04:23:41,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:42,192][root][INFO] - Training Epoch: 1/2, step 5427/7134 completed (loss: 0.035406116396188736, acc: 0.9905213117599487)
[2024-12-17 04:23:42,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:42,597][root][INFO] - Training Epoch: 1/2, step 5428/7134 completed (loss: 0.05870482325553894, acc: 0.9829642176628113)
[2024-12-17 04:23:42,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:42,982][root][INFO] - Training Epoch: 1/2, step 5429/7134 completed (loss: 0.09548552334308624, acc: 0.9711191058158875)
[2024-12-17 04:23:43,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:43,407][root][INFO] - Training Epoch: 1/2, step 5430/7134 completed (loss: 0.04635738208889961, acc: 0.9874607920646667)
[2024-12-17 04:23:43,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:43,782][root][INFO] - Training Epoch: 1/2, step 5431/7134 completed (loss: 0.04118756204843521, acc: 0.9867674708366394)
[2024-12-17 04:23:43,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:44,188][root][INFO] - Training Epoch: 1/2, step 5432/7134 completed (loss: 0.034017715603113174, acc: 0.9924670457839966)
[2024-12-17 04:23:44,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:44,571][root][INFO] - Training Epoch: 1/2, step 5433/7134 completed (loss: 0.055940426886081696, acc: 0.9878787994384766)
[2024-12-17 04:23:44,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:44,969][root][INFO] - Training Epoch: 1/2, step 5434/7134 completed (loss: 0.04637029394507408, acc: 0.9899396300315857)
[2024-12-17 04:23:45,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:45,347][root][INFO] - Training Epoch: 1/2, step 5435/7134 completed (loss: 0.049750473350286484, acc: 0.9769874215126038)
[2024-12-17 04:23:45,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:45,785][root][INFO] - Training Epoch: 1/2, step 5436/7134 completed (loss: 0.0511593297123909, acc: 0.9821958541870117)
[2024-12-17 04:23:45,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:46,206][root][INFO] - Training Epoch: 1/2, step 5437/7134 completed (loss: 0.02001621387898922, acc: 0.9965096116065979)
[2024-12-17 04:23:46,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:46,655][root][INFO] - Training Epoch: 1/2, step 5438/7134 completed (loss: 0.027927754446864128, acc: 0.9948320388793945)
[2024-12-17 04:23:46,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:47,079][root][INFO] - Training Epoch: 1/2, step 5439/7134 completed (loss: 0.05387413874268532, acc: 0.9840116500854492)
[2024-12-17 04:23:47,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:47,517][root][INFO] - Training Epoch: 1/2, step 5440/7134 completed (loss: 0.05433809757232666, acc: 0.9859514832496643)
[2024-12-17 04:23:47,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:47,951][root][INFO] - Training Epoch: 1/2, step 5441/7134 completed (loss: 0.04941838979721069, acc: 0.9889841079711914)
[2024-12-17 04:23:48,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:48,370][root][INFO] - Training Epoch: 1/2, step 5442/7134 completed (loss: 0.02763955108821392, acc: 0.9959404468536377)
[2024-12-17 04:23:48,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:48,764][root][INFO] - Training Epoch: 1/2, step 5443/7134 completed (loss: 0.060720160603523254, acc: 0.984375)
[2024-12-17 04:23:48,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:49,182][root][INFO] - Training Epoch: 1/2, step 5444/7134 completed (loss: 0.04540995880961418, acc: 0.9872262477874756)
[2024-12-17 04:23:49,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:49,617][root][INFO] - Training Epoch: 1/2, step 5445/7134 completed (loss: 0.05861566960811615, acc: 0.9890310764312744)
[2024-12-17 04:23:49,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:50,037][root][INFO] - Training Epoch: 1/2, step 5446/7134 completed (loss: 0.023697590455412865, acc: 0.9957982897758484)
[2024-12-17 04:23:50,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:50,441][root][INFO] - Training Epoch: 1/2, step 5447/7134 completed (loss: 0.040526509284973145, acc: 0.9871175289154053)
[2024-12-17 04:23:50,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:50,902][root][INFO] - Training Epoch: 1/2, step 5448/7134 completed (loss: 0.050223588943481445, acc: 0.9846368432044983)
[2024-12-17 04:23:51,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:51,326][root][INFO] - Training Epoch: 1/2, step 5449/7134 completed (loss: 0.020220013335347176, acc: 0.9929824471473694)
[2024-12-17 04:23:51,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:51,754][root][INFO] - Training Epoch: 1/2, step 5450/7134 completed (loss: 0.02764226123690605, acc: 0.9884169697761536)
[2024-12-17 04:23:51,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:52,165][root][INFO] - Training Epoch: 1/2, step 5451/7134 completed (loss: 0.05172210931777954, acc: 0.9829620122909546)
[2024-12-17 04:23:52,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:52,594][root][INFO] - Training Epoch: 1/2, step 5452/7134 completed (loss: 0.056752391159534454, acc: 0.9832041263580322)
[2024-12-17 04:23:52,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:53,037][root][INFO] - Training Epoch: 1/2, step 5453/7134 completed (loss: 0.06965359300374985, acc: 0.9815950989723206)
[2024-12-17 04:23:53,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:53,496][root][INFO] - Training Epoch: 1/2, step 5454/7134 completed (loss: 0.04078536480665207, acc: 0.9869621992111206)
[2024-12-17 04:23:53,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:53,939][root][INFO] - Training Epoch: 1/2, step 5455/7134 completed (loss: 0.10318811982870102, acc: 0.9772727489471436)
[2024-12-17 04:23:54,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:54,389][root][INFO] - Training Epoch: 1/2, step 5456/7134 completed (loss: 0.056159790605306625, acc: 0.983627200126648)
[2024-12-17 04:23:54,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:54,844][root][INFO] - Training Epoch: 1/2, step 5457/7134 completed (loss: 0.07466088235378265, acc: 0.9812080264091492)
[2024-12-17 04:23:54,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:55,287][root][INFO] - Training Epoch: 1/2, step 5458/7134 completed (loss: 0.05517711862921715, acc: 0.9834395051002502)
[2024-12-17 04:23:55,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:55,708][root][INFO] - Training Epoch: 1/2, step 5459/7134 completed (loss: 0.04340141639113426, acc: 0.9910581111907959)
[2024-12-17 04:23:55,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:56,126][root][INFO] - Training Epoch: 1/2, step 5460/7134 completed (loss: 0.051692016422748566, acc: 0.9888734221458435)
[2024-12-17 04:23:56,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:56,531][root][INFO] - Training Epoch: 1/2, step 5461/7134 completed (loss: 0.06469470262527466, acc: 0.9823399782180786)
[2024-12-17 04:23:56,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:56,983][root][INFO] - Training Epoch: 1/2, step 5462/7134 completed (loss: 0.024451417848467827, acc: 0.9928469061851501)
[2024-12-17 04:23:57,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:57,414][root][INFO] - Training Epoch: 1/2, step 5463/7134 completed (loss: 0.048912081867456436, acc: 0.9832060933113098)
[2024-12-17 04:23:57,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:57,844][root][INFO] - Training Epoch: 1/2, step 5464/7134 completed (loss: 0.05240507796406746, acc: 0.9867899417877197)
[2024-12-17 04:23:57,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:58,287][root][INFO] - Training Epoch: 1/2, step 5465/7134 completed (loss: 0.05972962826490402, acc: 0.9910314083099365)
[2024-12-17 04:23:58,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:58,732][root][INFO] - Training Epoch: 1/2, step 5466/7134 completed (loss: 0.043229978531599045, acc: 0.9884925484657288)
[2024-12-17 04:23:58,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:59,223][root][INFO] - Training Epoch: 1/2, step 5467/7134 completed (loss: 0.03127671405673027, acc: 0.9906103014945984)
[2024-12-17 04:23:59,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:23:59,673][root][INFO] - Training Epoch: 1/2, step 5468/7134 completed (loss: 0.038867074996232986, acc: 0.9907192587852478)
[2024-12-17 04:23:59,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:00,113][root][INFO] - Training Epoch: 1/2, step 5469/7134 completed (loss: 0.025808997452259064, acc: 0.9926380515098572)
[2024-12-17 04:24:00,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:00,573][root][INFO] - Training Epoch: 1/2, step 5470/7134 completed (loss: 0.021343685686588287, acc: 0.9963855147361755)
[2024-12-17 04:24:00,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:01,007][root][INFO] - Training Epoch: 1/2, step 5471/7134 completed (loss: 0.029580431059002876, acc: 0.9878378510475159)
[2024-12-17 04:24:01,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:01,448][root][INFO] - Training Epoch: 1/2, step 5472/7134 completed (loss: 0.03824184462428093, acc: 0.9887780547142029)
[2024-12-17 04:24:01,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:01,898][root][INFO] - Training Epoch: 1/2, step 5473/7134 completed (loss: 0.029861152172088623, acc: 0.9901840686798096)
[2024-12-17 04:24:02,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:02,319][root][INFO] - Training Epoch: 1/2, step 5474/7134 completed (loss: 0.04213689640164375, acc: 0.9885714054107666)
[2024-12-17 04:24:02,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:02,757][root][INFO] - Training Epoch: 1/2, step 5475/7134 completed (loss: 0.03640195354819298, acc: 0.9900426864624023)
[2024-12-17 04:24:02,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:03,171][root][INFO] - Training Epoch: 1/2, step 5476/7134 completed (loss: 0.022974824532866478, acc: 0.9927641153335571)
[2024-12-17 04:24:03,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:03,616][root][INFO] - Training Epoch: 1/2, step 5477/7134 completed (loss: 0.023808090016245842, acc: 0.9926108121871948)
[2024-12-17 04:24:03,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:04,097][root][INFO] - Training Epoch: 1/2, step 5478/7134 completed (loss: 0.06060105934739113, acc: 0.9811320900917053)
[2024-12-17 04:24:04,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:04,552][root][INFO] - Training Epoch: 1/2, step 5479/7134 completed (loss: 0.053606536239385605, acc: 0.98097825050354)
[2024-12-17 04:24:04,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:04,997][root][INFO] - Training Epoch: 1/2, step 5480/7134 completed (loss: 0.06697405874729156, acc: 0.9842105507850647)
[2024-12-17 04:24:05,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:05,410][root][INFO] - Training Epoch: 1/2, step 5481/7134 completed (loss: 0.04155105724930763, acc: 0.9878787994384766)
[2024-12-17 04:24:05,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:06,165][root][INFO] - Training Epoch: 1/2, step 5482/7134 completed (loss: 0.05456047132611275, acc: 0.9830713272094727)
[2024-12-17 04:24:06,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:06,654][root][INFO] - Training Epoch: 1/2, step 5483/7134 completed (loss: 0.06933115422725677, acc: 0.9805014133453369)
[2024-12-17 04:24:06,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:07,092][root][INFO] - Training Epoch: 1/2, step 5484/7134 completed (loss: 0.05294940993189812, acc: 0.9791377186775208)
[2024-12-17 04:24:07,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:07,500][root][INFO] - Training Epoch: 1/2, step 5485/7134 completed (loss: 0.07400941103696823, acc: 0.9818511605262756)
[2024-12-17 04:24:07,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:07,943][root][INFO] - Training Epoch: 1/2, step 5486/7134 completed (loss: 0.09716814011335373, acc: 0.9740484356880188)
[2024-12-17 04:24:08,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:08,344][root][INFO] - Training Epoch: 1/2, step 5487/7134 completed (loss: 0.03363143280148506, acc: 0.9918699264526367)
[2024-12-17 04:24:08,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:08,821][root][INFO] - Training Epoch: 1/2, step 5488/7134 completed (loss: 0.08658807724714279, acc: 0.9644736647605896)
[2024-12-17 04:24:08,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:09,278][root][INFO] - Training Epoch: 1/2, step 5489/7134 completed (loss: 0.05982360616326332, acc: 0.9845201373100281)
[2024-12-17 04:24:09,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:09,611][root][INFO] - Training Epoch: 1/2, step 5490/7134 completed (loss: 0.03885509818792343, acc: 0.9886105060577393)
[2024-12-17 04:24:09,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:10,016][root][INFO] - Training Epoch: 1/2, step 5491/7134 completed (loss: 0.03637099266052246, acc: 0.9897360801696777)
[2024-12-17 04:24:10,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:10,430][root][INFO] - Training Epoch: 1/2, step 5492/7134 completed (loss: 0.06960859149694443, acc: 0.9830795526504517)
[2024-12-17 04:24:10,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:10,836][root][INFO] - Training Epoch: 1/2, step 5493/7134 completed (loss: 0.07540899515151978, acc: 0.9755434989929199)
[2024-12-17 04:24:10,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:11,290][root][INFO] - Training Epoch: 1/2, step 5494/7134 completed (loss: 0.029807165265083313, acc: 0.9900426864624023)
[2024-12-17 04:24:11,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:11,686][root][INFO] - Training Epoch: 1/2, step 5495/7134 completed (loss: 0.029052022844552994, acc: 0.9910394549369812)
[2024-12-17 04:24:11,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:12,020][root][INFO] - Training Epoch: 1/2, step 5496/7134 completed (loss: 0.07142794877290726, acc: 0.9766536951065063)
[2024-12-17 04:24:12,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:12,427][root][INFO] - Training Epoch: 1/2, step 5497/7134 completed (loss: 0.0880141481757164, acc: 0.9765739440917969)
[2024-12-17 04:24:12,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:12,869][root][INFO] - Training Epoch: 1/2, step 5498/7134 completed (loss: 0.04214390739798546, acc: 0.9814323782920837)
[2024-12-17 04:24:13,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:13,288][root][INFO] - Training Epoch: 1/2, step 5499/7134 completed (loss: 0.051253315061330795, acc: 0.979899525642395)
[2024-12-17 04:24:13,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:13,703][root][INFO] - Training Epoch: 1/2, step 5500/7134 completed (loss: 0.05812080204486847, acc: 0.9863574504852295)
[2024-12-17 04:24:13,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:14,139][root][INFO] - Training Epoch: 1/2, step 5501/7134 completed (loss: 0.05061018094420433, acc: 0.9827160239219666)
[2024-12-17 04:24:14,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:14,575][root][INFO] - Training Epoch: 1/2, step 5502/7134 completed (loss: 0.05148330330848694, acc: 0.9797570705413818)
[2024-12-17 04:24:14,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:14,974][root][INFO] - Training Epoch: 1/2, step 5503/7134 completed (loss: 0.05824095010757446, acc: 0.9840954542160034)
[2024-12-17 04:24:15,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:15,418][root][INFO] - Training Epoch: 1/2, step 5504/7134 completed (loss: 0.04266892746090889, acc: 0.9878934621810913)
[2024-12-17 04:24:15,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:15,838][root][INFO] - Training Epoch: 1/2, step 5505/7134 completed (loss: 0.05753606557846069, acc: 0.9730496406555176)
[2024-12-17 04:24:15,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:16,275][root][INFO] - Training Epoch: 1/2, step 5506/7134 completed (loss: 0.0832613855600357, acc: 0.9757785201072693)
[2024-12-17 04:24:16,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:16,704][root][INFO] - Training Epoch: 1/2, step 5507/7134 completed (loss: 0.05719376727938652, acc: 0.9845938086509705)
[2024-12-17 04:24:16,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:17,151][root][INFO] - Training Epoch: 1/2, step 5508/7134 completed (loss: 0.039128512144088745, acc: 0.9918224215507507)
[2024-12-17 04:24:17,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:17,616][root][INFO] - Training Epoch: 1/2, step 5509/7134 completed (loss: 0.042769551277160645, acc: 0.9859648942947388)
[2024-12-17 04:24:17,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:18,073][root][INFO] - Training Epoch: 1/2, step 5510/7134 completed (loss: 0.06390964239835739, acc: 0.9820051193237305)
[2024-12-17 04:24:18,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:18,557][root][INFO] - Training Epoch: 1/2, step 5511/7134 completed (loss: 0.05858427658677101, acc: 0.9841628670692444)
[2024-12-17 04:24:18,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:18,998][root][INFO] - Training Epoch: 1/2, step 5512/7134 completed (loss: 0.029896097257733345, acc: 0.9881423115730286)
[2024-12-17 04:24:19,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:19,428][root][INFO] - Training Epoch: 1/2, step 5513/7134 completed (loss: 0.054244305938482285, acc: 0.9864130616188049)
[2024-12-17 04:24:19,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:19,870][root][INFO] - Training Epoch: 1/2, step 5514/7134 completed (loss: 0.15327169001102448, acc: 0.9664179086685181)
[2024-12-17 04:24:19,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:20,281][root][INFO] - Training Epoch: 1/2, step 5515/7134 completed (loss: 0.05316406488418579, acc: 0.9857346415519714)
[2024-12-17 04:24:20,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:20,678][root][INFO] - Training Epoch: 1/2, step 5516/7134 completed (loss: 0.049947693943977356, acc: 0.9901546835899353)
[2024-12-17 04:24:20,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:21,081][root][INFO] - Training Epoch: 1/2, step 5517/7134 completed (loss: 0.048083554953336716, acc: 0.9853723645210266)
[2024-12-17 04:24:21,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:21,520][root][INFO] - Training Epoch: 1/2, step 5518/7134 completed (loss: 0.0690573900938034, acc: 0.9836956262588501)
[2024-12-17 04:24:21,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:21,958][root][INFO] - Training Epoch: 1/2, step 5519/7134 completed (loss: 0.03220527246594429, acc: 0.9917241334915161)
[2024-12-17 04:24:22,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:22,399][root][INFO] - Training Epoch: 1/2, step 5520/7134 completed (loss: 0.030290966853499413, acc: 0.9932050108909607)
[2024-12-17 04:24:22,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:22,839][root][INFO] - Training Epoch: 1/2, step 5521/7134 completed (loss: 0.07273972034454346, acc: 0.9849246144294739)
[2024-12-17 04:24:22,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:23,276][root][INFO] - Training Epoch: 1/2, step 5522/7134 completed (loss: 0.08848886936903, acc: 0.9764705896377563)
[2024-12-17 04:24:23,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:23,677][root][INFO] - Training Epoch: 1/2, step 5523/7134 completed (loss: 0.06865581125020981, acc: 0.9873595237731934)
[2024-12-17 04:24:23,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:24,088][root][INFO] - Training Epoch: 1/2, step 5524/7134 completed (loss: 0.060272954404354095, acc: 0.9829721450805664)
[2024-12-17 04:24:24,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:24,543][root][INFO] - Training Epoch: 1/2, step 5525/7134 completed (loss: 0.04717931151390076, acc: 0.9838945865631104)
[2024-12-17 04:24:24,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:24,965][root][INFO] - Training Epoch: 1/2, step 5526/7134 completed (loss: 0.04845776781439781, acc: 0.9882179498672485)
[2024-12-17 04:24:25,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:25,386][root][INFO] - Training Epoch: 1/2, step 5527/7134 completed (loss: 0.06006681174039841, acc: 0.9831932783126831)
[2024-12-17 04:24:25,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:25,826][root][INFO] - Training Epoch: 1/2, step 5528/7134 completed (loss: 0.03806323930621147, acc: 0.9869822263717651)
[2024-12-17 04:24:25,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:26,283][root][INFO] - Training Epoch: 1/2, step 5529/7134 completed (loss: 0.06321053951978683, acc: 0.9846335649490356)
[2024-12-17 04:24:26,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:26,733][root][INFO] - Training Epoch: 1/2, step 5530/7134 completed (loss: 0.047453586012125015, acc: 0.9836065769195557)
[2024-12-17 04:24:26,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:27,183][root][INFO] - Training Epoch: 1/2, step 5531/7134 completed (loss: 0.074165478348732, acc: 0.9788293838500977)
[2024-12-17 04:24:27,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:27,645][root][INFO] - Training Epoch: 1/2, step 5532/7134 completed (loss: 0.08476816862821579, acc: 0.9740419983863831)
[2024-12-17 04:24:27,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:28,118][root][INFO] - Training Epoch: 1/2, step 5533/7134 completed (loss: 0.03225326910614967, acc: 0.9863945841789246)
[2024-12-17 04:24:28,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:28,587][root][INFO] - Training Epoch: 1/2, step 5534/7134 completed (loss: 0.054951731115579605, acc: 0.9871495366096497)
[2024-12-17 04:24:28,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:29,044][root][INFO] - Training Epoch: 1/2, step 5535/7134 completed (loss: 0.0435609295964241, acc: 0.9836779236793518)
[2024-12-17 04:24:29,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:29,480][root][INFO] - Training Epoch: 1/2, step 5536/7134 completed (loss: 0.03439278528094292, acc: 0.9930232763290405)
[2024-12-17 04:24:29,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:29,916][root][INFO] - Training Epoch: 1/2, step 5537/7134 completed (loss: 0.05790582299232483, acc: 0.9801633358001709)
[2024-12-17 04:24:30,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:30,366][root][INFO] - Training Epoch: 1/2, step 5538/7134 completed (loss: 0.03249974548816681, acc: 0.9943116903305054)
[2024-12-17 04:24:30,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:30,842][root][INFO] - Training Epoch: 1/2, step 5539/7134 completed (loss: 0.06398982554674149, acc: 0.9797297120094299)
[2024-12-17 04:24:30,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:31,296][root][INFO] - Training Epoch: 1/2, step 5540/7134 completed (loss: 0.060050372034311295, acc: 0.9815789461135864)
[2024-12-17 04:24:31,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:31,761][root][INFO] - Training Epoch: 1/2, step 5541/7134 completed (loss: 0.05407262220978737, acc: 0.9867021441459656)
[2024-12-17 04:24:31,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:32,202][root][INFO] - Training Epoch: 1/2, step 5542/7134 completed (loss: 0.04332069307565689, acc: 0.9885877370834351)
[2024-12-17 04:24:32,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:32,673][root][INFO] - Training Epoch: 1/2, step 5543/7134 completed (loss: 0.046802423894405365, acc: 0.9844789505004883)
[2024-12-17 04:24:32,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:33,130][root][INFO] - Training Epoch: 1/2, step 5544/7134 completed (loss: 0.033641915768384933, acc: 0.9881720542907715)
[2024-12-17 04:24:33,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:33,597][root][INFO] - Training Epoch: 1/2, step 5545/7134 completed (loss: 0.05235976725816727, acc: 0.9846994280815125)
[2024-12-17 04:24:33,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:34,039][root][INFO] - Training Epoch: 1/2, step 5546/7134 completed (loss: 0.0596841536462307, acc: 0.9878183603286743)
[2024-12-17 04:24:34,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:34,501][root][INFO] - Training Epoch: 1/2, step 5547/7134 completed (loss: 0.04260331392288208, acc: 0.9907833933830261)
[2024-12-17 04:24:34,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:34,939][root][INFO] - Training Epoch: 1/2, step 5548/7134 completed (loss: 0.043047524988651276, acc: 0.9860464930534363)
[2024-12-17 04:24:35,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:35,348][root][INFO] - Training Epoch: 1/2, step 5549/7134 completed (loss: 0.04856842756271362, acc: 0.9857142567634583)
[2024-12-17 04:24:35,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:35,799][root][INFO] - Training Epoch: 1/2, step 5550/7134 completed (loss: 0.028874721378087997, acc: 0.9882491230964661)
[2024-12-17 04:24:35,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:36,215][root][INFO] - Training Epoch: 1/2, step 5551/7134 completed (loss: 0.07092172652482986, acc: 0.9797022938728333)
[2024-12-17 04:24:36,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:36,659][root][INFO] - Training Epoch: 1/2, step 5552/7134 completed (loss: 0.04247220978140831, acc: 0.984542191028595)
[2024-12-17 04:24:36,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:37,098][root][INFO] - Training Epoch: 1/2, step 5553/7134 completed (loss: 0.05134901404380798, acc: 0.9876390695571899)
[2024-12-17 04:24:37,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:37,533][root][INFO] - Training Epoch: 1/2, step 5554/7134 completed (loss: 0.02998613379895687, acc: 0.995110034942627)
[2024-12-17 04:24:37,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:37,957][root][INFO] - Training Epoch: 1/2, step 5555/7134 completed (loss: 0.051946599036455154, acc: 0.9852941036224365)
[2024-12-17 04:24:38,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:38,367][root][INFO] - Training Epoch: 1/2, step 5556/7134 completed (loss: 0.060382697731256485, acc: 0.9792477488517761)
[2024-12-17 04:24:38,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:38,814][root][INFO] - Training Epoch: 1/2, step 5557/7134 completed (loss: 0.03583506494760513, acc: 0.994397759437561)
[2024-12-17 04:24:38,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:39,255][root][INFO] - Training Epoch: 1/2, step 5558/7134 completed (loss: 0.03014204651117325, acc: 0.9900621175765991)
[2024-12-17 04:24:39,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:39,690][root][INFO] - Training Epoch: 1/2, step 5559/7134 completed (loss: 0.04945084825158119, acc: 0.992546558380127)
[2024-12-17 04:24:39,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:40,142][root][INFO] - Training Epoch: 1/2, step 5560/7134 completed (loss: 0.07156924158334732, acc: 0.9805699586868286)
[2024-12-17 04:24:40,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:40,547][root][INFO] - Training Epoch: 1/2, step 5561/7134 completed (loss: 0.048953618854284286, acc: 0.992438554763794)
[2024-12-17 04:24:40,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:40,987][root][INFO] - Training Epoch: 1/2, step 5562/7134 completed (loss: 0.04756027087569237, acc: 0.9948805570602417)
[2024-12-17 04:24:41,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:41,425][root][INFO] - Training Epoch: 1/2, step 5563/7134 completed (loss: 0.0709313377737999, acc: 0.9879879951477051)
[2024-12-17 04:24:41,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:41,842][root][INFO] - Training Epoch: 1/2, step 5564/7134 completed (loss: 0.028208231553435326, acc: 0.9958158731460571)
[2024-12-17 04:24:41,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:42,285][root][INFO] - Training Epoch: 1/2, step 5565/7134 completed (loss: 0.01271303091198206, acc: 0.9953917264938354)
[2024-12-17 04:24:42,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:42,740][root][INFO] - Training Epoch: 1/2, step 5566/7134 completed (loss: 0.029006270691752434, acc: 0.9954075813293457)
[2024-12-17 04:24:42,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:43,209][root][INFO] - Training Epoch: 1/2, step 5567/7134 completed (loss: 0.02827180176973343, acc: 0.9931507110595703)
[2024-12-17 04:24:43,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:43,617][root][INFO] - Training Epoch: 1/2, step 5568/7134 completed (loss: 0.03269524872303009, acc: 0.9909793734550476)
[2024-12-17 04:24:43,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:44,095][root][INFO] - Training Epoch: 1/2, step 5569/7134 completed (loss: 0.025600051507353783, acc: 0.9954338073730469)
[2024-12-17 04:24:44,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:44,548][root][INFO] - Training Epoch: 1/2, step 5570/7134 completed (loss: 0.0379791334271431, acc: 0.9888198971748352)
[2024-12-17 04:24:44,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:44,975][root][INFO] - Training Epoch: 1/2, step 5571/7134 completed (loss: 0.051420170813798904, acc: 0.9866270422935486)
[2024-12-17 04:24:45,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:45,391][root][INFO] - Training Epoch: 1/2, step 5572/7134 completed (loss: 0.07367390394210815, acc: 0.9862637519836426)
[2024-12-17 04:24:45,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:45,868][root][INFO] - Training Epoch: 1/2, step 5573/7134 completed (loss: 0.05685893073678017, acc: 0.9854439496994019)
[2024-12-17 04:24:45,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:46,275][root][INFO] - Training Epoch: 1/2, step 5574/7134 completed (loss: 0.018645979464054108, acc: 0.9968253970146179)
[2024-12-17 04:24:46,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:46,713][root][INFO] - Training Epoch: 1/2, step 5575/7134 completed (loss: 0.040483877062797546, acc: 0.9840510487556458)
[2024-12-17 04:24:46,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:47,141][root][INFO] - Training Epoch: 1/2, step 5576/7134 completed (loss: 0.04419264569878578, acc: 0.9799426794052124)
[2024-12-17 04:24:47,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:47,570][root][INFO] - Training Epoch: 1/2, step 5577/7134 completed (loss: 0.06989341229200363, acc: 0.9842932224273682)
[2024-12-17 04:24:47,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:48,016][root][INFO] - Training Epoch: 1/2, step 5578/7134 completed (loss: 0.038635626435279846, acc: 0.9885222315788269)
[2024-12-17 04:24:48,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:48,462][root][INFO] - Training Epoch: 1/2, step 5579/7134 completed (loss: 0.03757128491997719, acc: 0.9861687421798706)
[2024-12-17 04:24:48,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:48,883][root][INFO] - Training Epoch: 1/2, step 5580/7134 completed (loss: 0.01983155496418476, acc: 0.9959072470664978)
[2024-12-17 04:24:48,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:49,321][root][INFO] - Training Epoch: 1/2, step 5581/7134 completed (loss: 0.01746348664164543, acc: 0.9960106611251831)
[2024-12-17 04:24:49,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:49,776][root][INFO] - Training Epoch: 1/2, step 5582/7134 completed (loss: 0.02651752158999443, acc: 0.9934810996055603)
[2024-12-17 04:24:49,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:50,229][root][INFO] - Training Epoch: 1/2, step 5583/7134 completed (loss: 0.03300747647881508, acc: 0.991183876991272)
[2024-12-17 04:24:50,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:50,652][root][INFO] - Training Epoch: 1/2, step 5584/7134 completed (loss: 0.03236677497625351, acc: 0.9881656765937805)
[2024-12-17 04:24:50,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:51,112][root][INFO] - Training Epoch: 1/2, step 5585/7134 completed (loss: 0.04215208441019058, acc: 0.9927272796630859)
[2024-12-17 04:24:51,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:51,528][root][INFO] - Training Epoch: 1/2, step 5586/7134 completed (loss: 0.05792972072958946, acc: 0.9840142130851746)
[2024-12-17 04:24:51,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:51,995][root][INFO] - Training Epoch: 1/2, step 5587/7134 completed (loss: 0.04272550344467163, acc: 0.9916782379150391)
[2024-12-17 04:24:52,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:52,452][root][INFO] - Training Epoch: 1/2, step 5588/7134 completed (loss: 0.024232937023043633, acc: 0.9924356937408447)
[2024-12-17 04:24:52,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:52,896][root][INFO] - Training Epoch: 1/2, step 5589/7134 completed (loss: 0.03109579347074032, acc: 0.9905362725257874)
[2024-12-17 04:24:53,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:53,332][root][INFO] - Training Epoch: 1/2, step 5590/7134 completed (loss: 0.03795784339308739, acc: 0.9873239398002625)
[2024-12-17 04:24:53,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:53,773][root][INFO] - Training Epoch: 1/2, step 5591/7134 completed (loss: 0.030539408326148987, acc: 0.9895287752151489)
[2024-12-17 04:24:53,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:54,190][root][INFO] - Training Epoch: 1/2, step 5592/7134 completed (loss: 0.02456546016037464, acc: 0.9945130348205566)
[2024-12-17 04:24:54,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:54,628][root][INFO] - Training Epoch: 1/2, step 5593/7134 completed (loss: 0.03426562622189522, acc: 0.9909326434135437)
[2024-12-17 04:24:54,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:55,066][root][INFO] - Training Epoch: 1/2, step 5594/7134 completed (loss: 0.01608412154018879, acc: 0.993261456489563)
[2024-12-17 04:24:55,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:55,501][root][INFO] - Training Epoch: 1/2, step 5595/7134 completed (loss: 0.05140966922044754, acc: 0.98525470495224)
[2024-12-17 04:24:55,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:55,946][root][INFO] - Training Epoch: 1/2, step 5596/7134 completed (loss: 0.03193976730108261, acc: 0.9892473220825195)
[2024-12-17 04:24:56,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:56,378][root][INFO] - Training Epoch: 1/2, step 5597/7134 completed (loss: 0.0662701204419136, acc: 0.9820936918258667)
[2024-12-17 04:24:56,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:56,813][root][INFO] - Training Epoch: 1/2, step 5598/7134 completed (loss: 0.03625982999801636, acc: 0.9888268113136292)
[2024-12-17 04:24:56,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:57,254][root][INFO] - Training Epoch: 1/2, step 5599/7134 completed (loss: 0.06277622282505035, acc: 0.9877049326896667)
[2024-12-17 04:24:57,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:57,713][root][INFO] - Training Epoch: 1/2, step 5600/7134 completed (loss: 0.035903267562389374, acc: 0.9914039969444275)
[2024-12-17 04:24:57,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:58,113][root][INFO] - Training Epoch: 1/2, step 5601/7134 completed (loss: 0.08049901574850082, acc: 0.9826086759567261)
[2024-12-17 04:24:58,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:58,543][root][INFO] - Training Epoch: 1/2, step 5602/7134 completed (loss: 0.07199621200561523, acc: 0.979066014289856)
[2024-12-17 04:24:58,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:58,944][root][INFO] - Training Epoch: 1/2, step 5603/7134 completed (loss: 0.013430452905595303, acc: 0.9967266917228699)
[2024-12-17 04:24:59,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:59,381][root][INFO] - Training Epoch: 1/2, step 5604/7134 completed (loss: 0.0783487930893898, acc: 0.971061110496521)
[2024-12-17 04:24:59,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:24:59,816][root][INFO] - Training Epoch: 1/2, step 5605/7134 completed (loss: 0.038956981152296066, acc: 0.9898132681846619)
[2024-12-17 04:24:59,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:00,226][root][INFO] - Training Epoch: 1/2, step 5606/7134 completed (loss: 0.058704592287540436, acc: 0.9829059839248657)
[2024-12-17 04:25:00,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:00,634][root][INFO] - Training Epoch: 1/2, step 5607/7134 completed (loss: 0.04003909230232239, acc: 0.9879699349403381)
[2024-12-17 04:25:00,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:01,038][root][INFO] - Training Epoch: 1/2, step 5608/7134 completed (loss: 0.04325335845351219, acc: 0.9852216839790344)
[2024-12-17 04:25:01,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:01,458][root][INFO] - Training Epoch: 1/2, step 5609/7134 completed (loss: 0.07394386827945709, acc: 0.9773913025856018)
[2024-12-17 04:25:01,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:01,836][root][INFO] - Training Epoch: 1/2, step 5610/7134 completed (loss: 0.037152212113142014, acc: 0.9919517040252686)
[2024-12-17 04:25:01,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:02,294][root][INFO] - Training Epoch: 1/2, step 5611/7134 completed (loss: 0.047728147357702255, acc: 0.9873417615890503)
[2024-12-17 04:25:02,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:02,728][root][INFO] - Training Epoch: 1/2, step 5612/7134 completed (loss: 0.05172431841492653, acc: 0.9831288456916809)
[2024-12-17 04:25:02,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:03,142][root][INFO] - Training Epoch: 1/2, step 5613/7134 completed (loss: 0.061913710087537766, acc: 0.980322003364563)
[2024-12-17 04:25:03,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:03,576][root][INFO] - Training Epoch: 1/2, step 5614/7134 completed (loss: 0.06625750660896301, acc: 0.9800000190734863)
[2024-12-17 04:25:03,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:04,016][root][INFO] - Training Epoch: 1/2, step 5615/7134 completed (loss: 0.07022161036729813, acc: 0.975095808506012)
[2024-12-17 04:25:04,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:04,449][root][INFO] - Training Epoch: 1/2, step 5616/7134 completed (loss: 0.043623801320791245, acc: 0.9851411581039429)
[2024-12-17 04:25:04,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:04,864][root][INFO] - Training Epoch: 1/2, step 5617/7134 completed (loss: 0.013055943883955479, acc: 0.9967532753944397)
[2024-12-17 04:25:04,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:05,290][root][INFO] - Training Epoch: 1/2, step 5618/7134 completed (loss: 0.061279065907001495, acc: 0.9821138381958008)
[2024-12-17 04:25:05,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:05,704][root][INFO] - Training Epoch: 1/2, step 5619/7134 completed (loss: 0.06469608843326569, acc: 0.9797160029411316)
[2024-12-17 04:25:05,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:06,136][root][INFO] - Training Epoch: 1/2, step 5620/7134 completed (loss: 0.038355227559804916, acc: 0.9869158864021301)
[2024-12-17 04:25:06,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:06,604][root][INFO] - Training Epoch: 1/2, step 5621/7134 completed (loss: 0.04193635657429695, acc: 0.9847522377967834)
[2024-12-17 04:25:06,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:07,037][root][INFO] - Training Epoch: 1/2, step 5622/7134 completed (loss: 0.07869422435760498, acc: 0.9863760471343994)
[2024-12-17 04:25:07,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:07,428][root][INFO] - Training Epoch: 1/2, step 5623/7134 completed (loss: 0.04963257536292076, acc: 0.9860627055168152)
[2024-12-17 04:25:07,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:07,864][root][INFO] - Training Epoch: 1/2, step 5624/7134 completed (loss: 0.06581170111894608, acc: 0.9836333990097046)
[2024-12-17 04:25:07,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:08,261][root][INFO] - Training Epoch: 1/2, step 5625/7134 completed (loss: 0.03176480159163475, acc: 0.9929412007331848)
[2024-12-17 04:25:08,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:08,665][root][INFO] - Training Epoch: 1/2, step 5626/7134 completed (loss: 0.03665456920862198, acc: 0.989847719669342)
[2024-12-17 04:25:08,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:09,078][root][INFO] - Training Epoch: 1/2, step 5627/7134 completed (loss: 0.13816332817077637, acc: 0.9684600830078125)
[2024-12-17 04:25:09,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:09,520][root][INFO] - Training Epoch: 1/2, step 5628/7134 completed (loss: 0.06936629116535187, acc: 0.9763205647468567)
[2024-12-17 04:25:09,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:09,941][root][INFO] - Training Epoch: 1/2, step 5629/7134 completed (loss: 0.062170736491680145, acc: 0.9771528840065002)
[2024-12-17 04:25:10,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:10,351][root][INFO] - Training Epoch: 1/2, step 5630/7134 completed (loss: 0.08894039690494537, acc: 0.9733059406280518)
[2024-12-17 04:25:10,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:10,752][root][INFO] - Training Epoch: 1/2, step 5631/7134 completed (loss: 0.11657837778329849, acc: 0.9635157585144043)
[2024-12-17 04:25:10,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:11,187][root][INFO] - Training Epoch: 1/2, step 5632/7134 completed (loss: 0.04963679239153862, acc: 0.9818511605262756)
[2024-12-17 04:25:11,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:11,591][root][INFO] - Training Epoch: 1/2, step 5633/7134 completed (loss: 0.09400705248117447, acc: 0.9706840515136719)
[2024-12-17 04:25:11,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:11,999][root][INFO] - Training Epoch: 1/2, step 5634/7134 completed (loss: 0.07145612686872482, acc: 0.9860383868217468)
[2024-12-17 04:25:12,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:12,437][root][INFO] - Training Epoch: 1/2, step 5635/7134 completed (loss: 0.02654596045613289, acc: 0.9949324131011963)
[2024-12-17 04:25:12,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:12,877][root][INFO] - Training Epoch: 1/2, step 5636/7134 completed (loss: 0.06031377613544464, acc: 0.9776358008384705)
[2024-12-17 04:25:12,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:13,303][root][INFO] - Training Epoch: 1/2, step 5637/7134 completed (loss: 0.06632354110479355, acc: 0.9814502596855164)
[2024-12-17 04:25:13,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:13,697][root][INFO] - Training Epoch: 1/2, step 5638/7134 completed (loss: 0.050077781081199646, acc: 0.986328125)
[2024-12-17 04:25:13,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:14,133][root][INFO] - Training Epoch: 1/2, step 5639/7134 completed (loss: 0.05030430853366852, acc: 0.9829059839248657)
[2024-12-17 04:25:14,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:14,549][root][INFO] - Training Epoch: 1/2, step 5640/7134 completed (loss: 0.0581519640982151, acc: 0.9821138381958008)
[2024-12-17 04:25:14,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:14,982][root][INFO] - Training Epoch: 1/2, step 5641/7134 completed (loss: 0.06088412553071976, acc: 0.9848484992980957)
[2024-12-17 04:25:15,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:15,379][root][INFO] - Training Epoch: 1/2, step 5642/7134 completed (loss: 0.08504325151443481, acc: 0.9833333492279053)
[2024-12-17 04:25:15,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:15,766][root][INFO] - Training Epoch: 1/2, step 5643/7134 completed (loss: 0.0800030380487442, acc: 0.9845132827758789)
[2024-12-17 04:25:15,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:16,190][root][INFO] - Training Epoch: 1/2, step 5644/7134 completed (loss: 0.05562848597764969, acc: 0.9837398529052734)
[2024-12-17 04:25:16,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:16,642][root][INFO] - Training Epoch: 1/2, step 5645/7134 completed (loss: 0.055556975305080414, acc: 0.9867452383041382)
[2024-12-17 04:25:16,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:17,063][root][INFO] - Training Epoch: 1/2, step 5646/7134 completed (loss: 0.06535788625478745, acc: 0.9824841022491455)
[2024-12-17 04:25:17,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:17,490][root][INFO] - Training Epoch: 1/2, step 5647/7134 completed (loss: 0.044173985719680786, acc: 0.9922480583190918)
[2024-12-17 04:25:17,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:17,908][root][INFO] - Training Epoch: 1/2, step 5648/7134 completed (loss: 0.10059524327516556, acc: 0.9776119589805603)
[2024-12-17 04:25:17,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:18,301][root][INFO] - Training Epoch: 1/2, step 5649/7134 completed (loss: 0.07998870313167572, acc: 0.9801223278045654)
[2024-12-17 04:25:18,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:18,717][root][INFO] - Training Epoch: 1/2, step 5650/7134 completed (loss: 0.042072467505931854, acc: 0.9845626354217529)
[2024-12-17 04:25:18,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:19,138][root][INFO] - Training Epoch: 1/2, step 5651/7134 completed (loss: 0.028572045266628265, acc: 0.9940828680992126)
[2024-12-17 04:25:19,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:19,583][root][INFO] - Training Epoch: 1/2, step 5652/7134 completed (loss: 0.052640192210674286, acc: 0.9823718070983887)
[2024-12-17 04:25:19,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:19,933][root][INFO] - Training Epoch: 1/2, step 5653/7134 completed (loss: 0.08536671847105026, acc: 0.9739583134651184)
[2024-12-17 04:25:20,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:20,336][root][INFO] - Training Epoch: 1/2, step 5654/7134 completed (loss: 0.039226170629262924, acc: 0.9894894957542419)
[2024-12-17 04:25:20,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:20,788][root][INFO] - Training Epoch: 1/2, step 5655/7134 completed (loss: 0.06925667822360992, acc: 0.9829931855201721)
[2024-12-17 04:25:20,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:21,194][root][INFO] - Training Epoch: 1/2, step 5656/7134 completed (loss: 0.03444064036011696, acc: 0.9923809766769409)
[2024-12-17 04:25:21,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:21,606][root][INFO] - Training Epoch: 1/2, step 5657/7134 completed (loss: 0.05277932062745094, acc: 0.9926793575286865)
[2024-12-17 04:25:21,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:22,049][root][INFO] - Training Epoch: 1/2, step 5658/7134 completed (loss: 0.07199312001466751, acc: 0.9737569093704224)
[2024-12-17 04:25:22,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:22,459][root][INFO] - Training Epoch: 1/2, step 5659/7134 completed (loss: 0.057602912187576294, acc: 0.9872340559959412)
[2024-12-17 04:25:22,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:22,880][root][INFO] - Training Epoch: 1/2, step 5660/7134 completed (loss: 0.03336181864142418, acc: 0.9834710955619812)
[2024-12-17 04:25:22,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:23,322][root][INFO] - Training Epoch: 1/2, step 5661/7134 completed (loss: 0.020579544827342033, acc: 0.9927007555961609)
[2024-12-17 04:25:23,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:23,749][root][INFO] - Training Epoch: 1/2, step 5662/7134 completed (loss: 0.03470686078071594, acc: 0.9935897588729858)
[2024-12-17 04:25:23,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:24,163][root][INFO] - Training Epoch: 1/2, step 5663/7134 completed (loss: 0.024011509492993355, acc: 0.9969183206558228)
[2024-12-17 04:25:24,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:24,576][root][INFO] - Training Epoch: 1/2, step 5664/7134 completed (loss: 0.08136285841464996, acc: 0.9851411581039429)
[2024-12-17 04:25:24,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:24,992][root][INFO] - Training Epoch: 1/2, step 5665/7134 completed (loss: 0.025513621047139168, acc: 0.9928673505783081)
[2024-12-17 04:25:25,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:25,439][root][INFO] - Training Epoch: 1/2, step 5666/7134 completed (loss: 0.022054007276892662, acc: 0.9903448224067688)
[2024-12-17 04:25:25,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:25,837][root][INFO] - Training Epoch: 1/2, step 5667/7134 completed (loss: 0.028347883373498917, acc: 0.996363639831543)
[2024-12-17 04:25:25,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:26,233][root][INFO] - Training Epoch: 1/2, step 5668/7134 completed (loss: 0.075906902551651, acc: 0.9784052968025208)
[2024-12-17 04:25:26,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:26,637][root][INFO] - Training Epoch: 1/2, step 5669/7134 completed (loss: 0.03115454874932766, acc: 0.9897360801696777)
[2024-12-17 04:25:26,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:27,045][root][INFO] - Training Epoch: 1/2, step 5670/7134 completed (loss: 0.025738632306456566, acc: 0.9933333396911621)
[2024-12-17 04:25:27,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:27,499][root][INFO] - Training Epoch: 1/2, step 5671/7134 completed (loss: 0.01761474832892418, acc: 0.9963099360466003)
[2024-12-17 04:25:27,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:27,942][root][INFO] - Training Epoch: 1/2, step 5672/7134 completed (loss: 0.03243943303823471, acc: 0.988959014415741)
[2024-12-17 04:25:28,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:28,322][root][INFO] - Training Epoch: 1/2, step 5673/7134 completed (loss: 0.02292824722826481, acc: 0.9955686926841736)
[2024-12-17 04:25:28,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:28,765][root][INFO] - Training Epoch: 1/2, step 5674/7134 completed (loss: 0.030623188242316246, acc: 0.9908257126808167)
[2024-12-17 04:25:28,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:29,163][root][INFO] - Training Epoch: 1/2, step 5675/7134 completed (loss: 0.039237815886735916, acc: 0.9900497794151306)
[2024-12-17 04:25:29,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:29,587][root][INFO] - Training Epoch: 1/2, step 5676/7134 completed (loss: 0.0822785496711731, acc: 0.9778106212615967)
[2024-12-17 04:25:29,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:30,013][root][INFO] - Training Epoch: 1/2, step 5677/7134 completed (loss: 0.047837842255830765, acc: 0.984375)
[2024-12-17 04:25:30,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:30,432][root][INFO] - Training Epoch: 1/2, step 5678/7134 completed (loss: 0.04484674707055092, acc: 0.9852941036224365)
[2024-12-17 04:25:30,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:30,884][root][INFO] - Training Epoch: 1/2, step 5679/7134 completed (loss: 0.09396681934595108, acc: 0.9721815586090088)
[2024-12-17 04:25:30,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:31,301][root][INFO] - Training Epoch: 1/2, step 5680/7134 completed (loss: 0.10337141901254654, acc: 0.9716840386390686)
[2024-12-17 04:25:31,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:31,720][root][INFO] - Training Epoch: 1/2, step 5681/7134 completed (loss: 0.06557632982730865, acc: 0.9803921580314636)
[2024-12-17 04:25:31,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:32,132][root][INFO] - Training Epoch: 1/2, step 5682/7134 completed (loss: 0.05381627380847931, acc: 0.98124098777771)
[2024-12-17 04:25:32,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:32,554][root][INFO] - Training Epoch: 1/2, step 5683/7134 completed (loss: 0.0775008574128151, acc: 0.9751098155975342)
[2024-12-17 04:25:32,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:33,029][root][INFO] - Training Epoch: 1/2, step 5684/7134 completed (loss: 0.07449903339147568, acc: 0.9831365942955017)
[2024-12-17 04:25:33,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:33,448][root][INFO] - Training Epoch: 1/2, step 5685/7134 completed (loss: 0.0880749374628067, acc: 0.9779411554336548)
[2024-12-17 04:25:33,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:33,903][root][INFO] - Training Epoch: 1/2, step 5686/7134 completed (loss: 0.10003811120986938, acc: 0.9729272127151489)
[2024-12-17 04:25:34,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:34,332][root][INFO] - Training Epoch: 1/2, step 5687/7134 completed (loss: 0.08860736340284348, acc: 0.9743589758872986)
[2024-12-17 04:25:34,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:34,788][root][INFO] - Training Epoch: 1/2, step 5688/7134 completed (loss: 0.08573900163173676, acc: 0.9759679436683655)
[2024-12-17 04:25:34,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:35,222][root][INFO] - Training Epoch: 1/2, step 5689/7134 completed (loss: 0.09456424415111542, acc: 0.9771689772605896)
[2024-12-17 04:25:35,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:35,683][root][INFO] - Training Epoch: 1/2, step 5690/7134 completed (loss: 0.04203975573182106, acc: 0.9929245114326477)
[2024-12-17 04:25:35,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:36,090][root][INFO] - Training Epoch: 1/2, step 5691/7134 completed (loss: 0.07958284020423889, acc: 0.9813664555549622)
[2024-12-17 04:25:36,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:36,539][root][INFO] - Training Epoch: 1/2, step 5692/7134 completed (loss: 0.0858234390616417, acc: 0.9825737476348877)
[2024-12-17 04:25:36,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:36,945][root][INFO] - Training Epoch: 1/2, step 5693/7134 completed (loss: 0.03244682401418686, acc: 0.9910045266151428)
[2024-12-17 04:25:37,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:37,381][root][INFO] - Training Epoch: 1/2, step 5694/7134 completed (loss: 0.05797990784049034, acc: 0.9840810298919678)
[2024-12-17 04:25:37,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:37,821][root][INFO] - Training Epoch: 1/2, step 5695/7134 completed (loss: 0.03332381695508957, acc: 0.9885386824607849)
[2024-12-17 04:25:37,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:38,269][root][INFO] - Training Epoch: 1/2, step 5696/7134 completed (loss: 0.0348624549806118, acc: 0.9905882477760315)
[2024-12-17 04:25:38,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:38,713][root][INFO] - Training Epoch: 1/2, step 5697/7134 completed (loss: 0.07699733227491379, acc: 0.9844852089881897)
[2024-12-17 04:25:38,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:39,154][root][INFO] - Training Epoch: 1/2, step 5698/7134 completed (loss: 0.07128413021564484, acc: 0.9795918464660645)
[2024-12-17 04:25:39,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:39,604][root][INFO] - Training Epoch: 1/2, step 5699/7134 completed (loss: 0.056568752974271774, acc: 0.9847133755683899)
[2024-12-17 04:25:39,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:40,047][root][INFO] - Training Epoch: 1/2, step 5700/7134 completed (loss: 0.04503941535949707, acc: 0.9872340559959412)
[2024-12-17 04:25:40,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:40,519][root][INFO] - Training Epoch: 1/2, step 5701/7134 completed (loss: 0.05851060152053833, acc: 0.9887359142303467)
[2024-12-17 04:25:40,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:40,961][root][INFO] - Training Epoch: 1/2, step 5702/7134 completed (loss: 0.05393889546394348, acc: 0.9878214001655579)
[2024-12-17 04:25:41,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:41,395][root][INFO] - Training Epoch: 1/2, step 5703/7134 completed (loss: 0.027614979073405266, acc: 0.9901546835899353)
[2024-12-17 04:25:41,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:41,835][root][INFO] - Training Epoch: 1/2, step 5704/7134 completed (loss: 0.059723999351263046, acc: 0.984308123588562)
[2024-12-17 04:25:41,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:42,210][root][INFO] - Training Epoch: 1/2, step 5705/7134 completed (loss: 0.03282885625958443, acc: 0.9892857074737549)
[2024-12-17 04:25:42,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:42,682][root][INFO] - Training Epoch: 1/2, step 5706/7134 completed (loss: 0.0349142923951149, acc: 0.9888142943382263)
[2024-12-17 04:25:42,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:43,111][root][INFO] - Training Epoch: 1/2, step 5707/7134 completed (loss: 0.06570300459861755, acc: 0.9788732528686523)
[2024-12-17 04:25:43,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:43,579][root][INFO] - Training Epoch: 1/2, step 5708/7134 completed (loss: 0.03262628614902496, acc: 0.9911110997200012)
[2024-12-17 04:25:43,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:44,021][root][INFO] - Training Epoch: 1/2, step 5709/7134 completed (loss: 0.06516711413860321, acc: 0.9835841059684753)
[2024-12-17 04:25:44,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:44,467][root][INFO] - Training Epoch: 1/2, step 5710/7134 completed (loss: 0.05724377930164337, acc: 0.9821882843971252)
[2024-12-17 04:25:44,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:44,901][root][INFO] - Training Epoch: 1/2, step 5711/7134 completed (loss: 0.07579007744789124, acc: 0.9869109988212585)
[2024-12-17 04:25:45,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:45,330][root][INFO] - Training Epoch: 1/2, step 5712/7134 completed (loss: 0.06646383553743362, acc: 0.9819999933242798)
[2024-12-17 04:25:45,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:45,802][root][INFO] - Training Epoch: 1/2, step 5713/7134 completed (loss: 0.021233651787042618, acc: 0.9949173927307129)
[2024-12-17 04:25:45,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:46,250][root][INFO] - Training Epoch: 1/2, step 5714/7134 completed (loss: 0.038983337581157684, acc: 0.9900373816490173)
[2024-12-17 04:25:46,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:46,656][root][INFO] - Training Epoch: 1/2, step 5715/7134 completed (loss: 0.09121086448431015, acc: 0.9851024150848389)
[2024-12-17 04:25:46,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:47,071][root][INFO] - Training Epoch: 1/2, step 5716/7134 completed (loss: 0.13908587396144867, acc: 0.9715808033943176)
[2024-12-17 04:25:47,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:47,497][root][INFO] - Training Epoch: 1/2, step 5717/7134 completed (loss: 0.11123056709766388, acc: 0.9766718745231628)
[2024-12-17 04:25:47,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:47,888][root][INFO] - Training Epoch: 1/2, step 5718/7134 completed (loss: 0.0627279132604599, acc: 0.9858044385910034)
[2024-12-17 04:25:47,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:48,288][root][INFO] - Training Epoch: 1/2, step 5719/7134 completed (loss: 0.033698663115501404, acc: 0.9940029978752136)
[2024-12-17 04:25:48,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:48,699][root][INFO] - Training Epoch: 1/2, step 5720/7134 completed (loss: 0.04393136128783226, acc: 0.9861830472946167)
[2024-12-17 04:25:48,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:49,107][root][INFO] - Training Epoch: 1/2, step 5721/7134 completed (loss: 0.0560462549328804, acc: 0.9855263233184814)
[2024-12-17 04:25:49,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:49,465][root][INFO] - Training Epoch: 1/2, step 5722/7134 completed (loss: 0.05975443869829178, acc: 0.9844789505004883)
[2024-12-17 04:25:49,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:49,910][root][INFO] - Training Epoch: 1/2, step 5723/7134 completed (loss: 0.07844632118940353, acc: 0.9727685451507568)
[2024-12-17 04:25:50,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:50,304][root][INFO] - Training Epoch: 1/2, step 5724/7134 completed (loss: 0.03449752926826477, acc: 0.9887999892234802)
[2024-12-17 04:25:50,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:50,735][root][INFO] - Training Epoch: 1/2, step 5725/7134 completed (loss: 0.035674843937158585, acc: 0.991428554058075)
[2024-12-17 04:25:50,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:51,151][root][INFO] - Training Epoch: 1/2, step 5726/7134 completed (loss: 0.0671805739402771, acc: 0.9877675771713257)
[2024-12-17 04:25:51,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:51,569][root][INFO] - Training Epoch: 1/2, step 5727/7134 completed (loss: 0.019920676946640015, acc: 0.9973261952400208)
[2024-12-17 04:25:51,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:51,967][root][INFO] - Training Epoch: 1/2, step 5728/7134 completed (loss: 0.016756851226091385, acc: 0.9964912533760071)
[2024-12-17 04:25:52,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:52,361][root][INFO] - Training Epoch: 1/2, step 5729/7134 completed (loss: 0.02584420144557953, acc: 0.9916666746139526)
[2024-12-17 04:25:52,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:52,759][root][INFO] - Training Epoch: 1/2, step 5730/7134 completed (loss: 0.086667001247406, acc: 0.9797979593276978)
[2024-12-17 04:25:52,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:53,192][root][INFO] - Training Epoch: 1/2, step 5731/7134 completed (loss: 0.06629568338394165, acc: 0.9817276000976562)
[2024-12-17 04:25:53,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:53,585][root][INFO] - Training Epoch: 1/2, step 5732/7134 completed (loss: 0.20295807719230652, acc: 0.9611650705337524)
[2024-12-17 04:25:53,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:54,009][root][INFO] - Training Epoch: 1/2, step 5733/7134 completed (loss: 0.03815196827054024, acc: 0.9890710115432739)
[2024-12-17 04:25:54,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:54,424][root][INFO] - Training Epoch: 1/2, step 5734/7134 completed (loss: 0.01557553093880415, acc: 0.996666669845581)
[2024-12-17 04:25:54,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:54,827][root][INFO] - Training Epoch: 1/2, step 5735/7134 completed (loss: 0.07370155304670334, acc: 0.9731183052062988)
[2024-12-17 04:25:54,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:55,278][root][INFO] - Training Epoch: 1/2, step 5736/7134 completed (loss: 0.07243682444095612, acc: 0.9774436354637146)
[2024-12-17 04:25:55,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:55,690][root][INFO] - Training Epoch: 1/2, step 5737/7134 completed (loss: 0.06620240211486816, acc: 0.981873095035553)
[2024-12-17 04:25:55,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:56,143][root][INFO] - Training Epoch: 1/2, step 5738/7134 completed (loss: 0.04894546419382095, acc: 0.984280526638031)
[2024-12-17 04:25:56,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:56,588][root][INFO] - Training Epoch: 1/2, step 5739/7134 completed (loss: 0.06541118770837784, acc: 0.9768421053886414)
[2024-12-17 04:25:56,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:57,019][root][INFO] - Training Epoch: 1/2, step 5740/7134 completed (loss: 0.045204199850559235, acc: 0.9884910583496094)
[2024-12-17 04:25:57,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:57,458][root][INFO] - Training Epoch: 1/2, step 5741/7134 completed (loss: 0.05583750084042549, acc: 0.9845956563949585)
[2024-12-17 04:25:57,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:57,891][root][INFO] - Training Epoch: 1/2, step 5742/7134 completed (loss: 0.05172061175107956, acc: 0.9776609539985657)
[2024-12-17 04:25:58,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:58,337][root][INFO] - Training Epoch: 1/2, step 5743/7134 completed (loss: 0.042368583381175995, acc: 0.9889705777168274)
[2024-12-17 04:25:58,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:58,713][root][INFO] - Training Epoch: 1/2, step 5744/7134 completed (loss: 0.02513904683291912, acc: 0.991631805896759)
[2024-12-17 04:25:58,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:59,160][root][INFO] - Training Epoch: 1/2, step 5745/7134 completed (loss: 0.04305729269981384, acc: 0.9857512712478638)
[2024-12-17 04:25:59,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:25:59,581][root][INFO] - Training Epoch: 1/2, step 5746/7134 completed (loss: 0.08426422625780106, acc: 0.9808823466300964)
[2024-12-17 04:25:59,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:00,004][root][INFO] - Training Epoch: 1/2, step 5747/7134 completed (loss: 0.03892102837562561, acc: 0.9889196753501892)
[2024-12-17 04:26:00,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:00,440][root][INFO] - Training Epoch: 1/2, step 5748/7134 completed (loss: 0.047452256083488464, acc: 0.9890310764312744)
[2024-12-17 04:26:00,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:00,881][root][INFO] - Training Epoch: 1/2, step 5749/7134 completed (loss: 0.04658355191349983, acc: 0.9921466112136841)
[2024-12-17 04:26:00,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:01,315][root][INFO] - Training Epoch: 1/2, step 5750/7134 completed (loss: 0.07084310799837112, acc: 0.9727723002433777)
[2024-12-17 04:26:01,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:01,752][root][INFO] - Training Epoch: 1/2, step 5751/7134 completed (loss: 0.08458906412124634, acc: 0.9794608354568481)
[2024-12-17 04:26:01,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:02,212][root][INFO] - Training Epoch: 1/2, step 5752/7134 completed (loss: 0.07152590900659561, acc: 0.9767981171607971)
[2024-12-17 04:26:02,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:02,643][root][INFO] - Training Epoch: 1/2, step 5753/7134 completed (loss: 0.08170069754123688, acc: 0.9765625)
[2024-12-17 04:26:02,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:03,111][root][INFO] - Training Epoch: 1/2, step 5754/7134 completed (loss: 0.08172894269227982, acc: 0.9757961630821228)
[2024-12-17 04:26:03,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:03,525][root][INFO] - Training Epoch: 1/2, step 5755/7134 completed (loss: 0.0646539106965065, acc: 0.9824304580688477)
[2024-12-17 04:26:03,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:03,956][root][INFO] - Training Epoch: 1/2, step 5756/7134 completed (loss: 0.05500424653291702, acc: 0.9827127456665039)
[2024-12-17 04:26:04,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:04,394][root][INFO] - Training Epoch: 1/2, step 5757/7134 completed (loss: 0.04096544533967972, acc: 0.9872286319732666)
[2024-12-17 04:26:04,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:04,805][root][INFO] - Training Epoch: 1/2, step 5758/7134 completed (loss: 0.05212625488638878, acc: 0.9823529124259949)
[2024-12-17 04:26:04,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:05,198][root][INFO] - Training Epoch: 1/2, step 5759/7134 completed (loss: 0.0603407584130764, acc: 0.9784366488456726)
[2024-12-17 04:26:05,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:05,635][root][INFO] - Training Epoch: 1/2, step 5760/7134 completed (loss: 0.03919025883078575, acc: 0.9908397197723389)
[2024-12-17 04:26:05,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:06,090][root][INFO] - Training Epoch: 1/2, step 5761/7134 completed (loss: 0.04987388104200363, acc: 0.9835164546966553)
[2024-12-17 04:26:06,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:06,525][root][INFO] - Training Epoch: 1/2, step 5762/7134 completed (loss: 0.06970001757144928, acc: 0.9835766553878784)
[2024-12-17 04:26:06,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:06,972][root][INFO] - Training Epoch: 1/2, step 5763/7134 completed (loss: 0.04426150768995285, acc: 0.9899623394012451)
[2024-12-17 04:26:07,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:07,360][root][INFO] - Training Epoch: 1/2, step 5764/7134 completed (loss: 0.042136237025260925, acc: 0.988034188747406)
[2024-12-17 04:26:07,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:07,782][root][INFO] - Training Epoch: 1/2, step 5765/7134 completed (loss: 0.022303013131022453, acc: 0.9929971694946289)
[2024-12-17 04:26:07,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:08,194][root][INFO] - Training Epoch: 1/2, step 5766/7134 completed (loss: 0.028831368312239647, acc: 0.9955157041549683)
[2024-12-17 04:26:08,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:08,626][root][INFO] - Training Epoch: 1/2, step 5767/7134 completed (loss: 0.02188972197473049, acc: 0.9930459260940552)
[2024-12-17 04:26:08,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:09,056][root][INFO] - Training Epoch: 1/2, step 5768/7134 completed (loss: 0.02892141044139862, acc: 0.9880239367485046)
[2024-12-17 04:26:09,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:09,502][root][INFO] - Training Epoch: 1/2, step 5769/7134 completed (loss: 0.018957087770104408, acc: 0.9934533834457397)
[2024-12-17 04:26:09,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:09,955][root][INFO] - Training Epoch: 1/2, step 5770/7134 completed (loss: 0.04274490475654602, acc: 0.9889841079711914)
[2024-12-17 04:26:10,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:10,374][root][INFO] - Training Epoch: 1/2, step 5771/7134 completed (loss: 0.08452945202589035, acc: 0.98097825050354)
[2024-12-17 04:26:10,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:10,813][root][INFO] - Training Epoch: 1/2, step 5772/7134 completed (loss: 0.02548595517873764, acc: 0.991304337978363)
[2024-12-17 04:26:10,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:11,259][root][INFO] - Training Epoch: 1/2, step 5773/7134 completed (loss: 0.023143194615840912, acc: 0.9933110475540161)
[2024-12-17 04:26:11,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:11,681][root][INFO] - Training Epoch: 1/2, step 5774/7134 completed (loss: 0.04787096008658409, acc: 0.9851632118225098)
[2024-12-17 04:26:11,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:12,092][root][INFO] - Training Epoch: 1/2, step 5775/7134 completed (loss: 0.0454833023250103, acc: 0.9884678721427917)
[2024-12-17 04:26:12,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:12,508][root][INFO] - Training Epoch: 1/2, step 5776/7134 completed (loss: 0.06606782227754593, acc: 0.9803370833396912)
[2024-12-17 04:26:12,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:12,949][root][INFO] - Training Epoch: 1/2, step 5777/7134 completed (loss: 0.08773529529571533, acc: 0.9839109182357788)
[2024-12-17 04:26:13,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:13,389][root][INFO] - Training Epoch: 1/2, step 5778/7134 completed (loss: 0.116449736058712, acc: 0.9695512652397156)
[2024-12-17 04:26:13,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:13,841][root][INFO] - Training Epoch: 1/2, step 5779/7134 completed (loss: 0.0467032752931118, acc: 0.9848693013191223)
[2024-12-17 04:26:13,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:14,303][root][INFO] - Training Epoch: 1/2, step 5780/7134 completed (loss: 0.03483626991510391, acc: 0.9880668520927429)
[2024-12-17 04:26:14,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:14,757][root][INFO] - Training Epoch: 1/2, step 5781/7134 completed (loss: 0.040425803512334824, acc: 0.988950252532959)
[2024-12-17 04:26:14,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:15,199][root][INFO] - Training Epoch: 1/2, step 5782/7134 completed (loss: 0.026110943406820297, acc: 0.9909326434135437)
[2024-12-17 04:26:15,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:15,638][root][INFO] - Training Epoch: 1/2, step 5783/7134 completed (loss: 0.04054485261440277, acc: 0.9880478382110596)
[2024-12-17 04:26:15,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:16,057][root][INFO] - Training Epoch: 1/2, step 5784/7134 completed (loss: 0.040886327624320984, acc: 0.9892328381538391)
[2024-12-17 04:26:16,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:16,468][root][INFO] - Training Epoch: 1/2, step 5785/7134 completed (loss: 0.0695190355181694, acc: 0.9757412672042847)
[2024-12-17 04:26:16,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:16,874][root][INFO] - Training Epoch: 1/2, step 5786/7134 completed (loss: 0.05723955109715462, acc: 0.9836065769195557)
[2024-12-17 04:26:17,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:17,316][root][INFO] - Training Epoch: 1/2, step 5787/7134 completed (loss: 0.03966671973466873, acc: 0.9875621795654297)
[2024-12-17 04:26:17,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:17,729][root][INFO] - Training Epoch: 1/2, step 5788/7134 completed (loss: 0.02332850731909275, acc: 0.9938461780548096)
[2024-12-17 04:26:17,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:18,169][root][INFO] - Training Epoch: 1/2, step 5789/7134 completed (loss: 0.0534895621240139, acc: 0.9863523840904236)
[2024-12-17 04:26:18,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:18,602][root][INFO] - Training Epoch: 1/2, step 5790/7134 completed (loss: 0.03682160750031471, acc: 0.9876373410224915)
[2024-12-17 04:26:18,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:19,036][root][INFO] - Training Epoch: 1/2, step 5791/7134 completed (loss: 0.07905608415603638, acc: 0.9810996651649475)
[2024-12-17 04:26:19,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:19,466][root][INFO] - Training Epoch: 1/2, step 5792/7134 completed (loss: 0.09957802295684814, acc: 0.9762309193611145)
[2024-12-17 04:26:19,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:19,913][root][INFO] - Training Epoch: 1/2, step 5793/7134 completed (loss: 0.09275378286838531, acc: 0.9779874086380005)
[2024-12-17 04:26:20,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:20,322][root][INFO] - Training Epoch: 1/2, step 5794/7134 completed (loss: 0.06140729784965515, acc: 0.9757575988769531)
[2024-12-17 04:26:20,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:20,747][root][INFO] - Training Epoch: 1/2, step 5795/7134 completed (loss: 0.13051506876945496, acc: 0.9600840210914612)
[2024-12-17 04:26:20,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:21,180][root][INFO] - Training Epoch: 1/2, step 5796/7134 completed (loss: 0.056400492787361145, acc: 0.9813874959945679)
[2024-12-17 04:26:21,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:21,600][root][INFO] - Training Epoch: 1/2, step 5797/7134 completed (loss: 0.06457728147506714, acc: 0.9760000109672546)
[2024-12-17 04:26:21,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:22,004][root][INFO] - Training Epoch: 1/2, step 5798/7134 completed (loss: 0.15565110743045807, acc: 0.9617391228675842)
[2024-12-17 04:26:22,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:22,399][root][INFO] - Training Epoch: 1/2, step 5799/7134 completed (loss: 0.09613434225320816, acc: 0.9704142212867737)
[2024-12-17 04:26:22,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:22,813][root][INFO] - Training Epoch: 1/2, step 5800/7134 completed (loss: 0.08548135310411453, acc: 0.9724264740943909)
[2024-12-17 04:26:22,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:23,237][root][INFO] - Training Epoch: 1/2, step 5801/7134 completed (loss: 0.07602939009666443, acc: 0.9756097793579102)
[2024-12-17 04:26:23,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:23,656][root][INFO] - Training Epoch: 1/2, step 5802/7134 completed (loss: 0.04776992276310921, acc: 0.9870610237121582)
[2024-12-17 04:26:23,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:24,112][root][INFO] - Training Epoch: 1/2, step 5803/7134 completed (loss: 0.03930125758051872, acc: 0.9872449040412903)
[2024-12-17 04:26:24,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:24,537][root][INFO] - Training Epoch: 1/2, step 5804/7134 completed (loss: 0.08801041543483734, acc: 0.9715832471847534)
[2024-12-17 04:26:24,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:24,963][root][INFO] - Training Epoch: 1/2, step 5805/7134 completed (loss: 0.07035472244024277, acc: 0.9812949895858765)
[2024-12-17 04:26:25,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:25,402][root][INFO] - Training Epoch: 1/2, step 5806/7134 completed (loss: 0.06634694337844849, acc: 0.9836065769195557)
[2024-12-17 04:26:25,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:25,838][root][INFO] - Training Epoch: 1/2, step 5807/7134 completed (loss: 0.08147959411144257, acc: 0.97579425573349)
[2024-12-17 04:26:25,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:26,299][root][INFO] - Training Epoch: 1/2, step 5808/7134 completed (loss: 0.053765248507261276, acc: 0.9803094267845154)
[2024-12-17 04:26:26,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:26,722][root][INFO] - Training Epoch: 1/2, step 5809/7134 completed (loss: 0.04911456257104874, acc: 0.9890350699424744)
[2024-12-17 04:26:26,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:27,149][root][INFO] - Training Epoch: 1/2, step 5810/7134 completed (loss: 0.05638231709599495, acc: 0.9817444086074829)
[2024-12-17 04:26:27,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:27,533][root][INFO] - Training Epoch: 1/2, step 5811/7134 completed (loss: 0.0645485445857048, acc: 0.9759036302566528)
[2024-12-17 04:26:27,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:27,938][root][INFO] - Training Epoch: 1/2, step 5812/7134 completed (loss: 0.019048791378736496, acc: 0.9966996908187866)
[2024-12-17 04:26:28,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:28,355][root][INFO] - Training Epoch: 1/2, step 5813/7134 completed (loss: 0.03327920660376549, acc: 0.9886792302131653)
[2024-12-17 04:26:28,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:28,843][root][INFO] - Training Epoch: 1/2, step 5814/7134 completed (loss: 0.028380267322063446, acc: 0.989847719669342)
[2024-12-17 04:26:28,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:29,261][root][INFO] - Training Epoch: 1/2, step 5815/7134 completed (loss: 0.03396392613649368, acc: 0.9905837774276733)
[2024-12-17 04:26:29,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:29,700][root][INFO] - Training Epoch: 1/2, step 5816/7134 completed (loss: 0.012500298209488392, acc: 0.9975062608718872)
[2024-12-17 04:26:29,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:30,114][root][INFO] - Training Epoch: 1/2, step 5817/7134 completed (loss: 0.07209837436676025, acc: 0.98740553855896)
[2024-12-17 04:26:30,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:30,540][root][INFO] - Training Epoch: 1/2, step 5818/7134 completed (loss: 0.06417232006788254, acc: 0.9822221994400024)
[2024-12-17 04:26:30,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:30,941][root][INFO] - Training Epoch: 1/2, step 5819/7134 completed (loss: 0.03759514540433884, acc: 0.9879310131072998)
[2024-12-17 04:26:31,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:31,336][root][INFO] - Training Epoch: 1/2, step 5820/7134 completed (loss: 0.06150931492447853, acc: 0.9793388247489929)
[2024-12-17 04:26:31,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:31,746][root][INFO] - Training Epoch: 1/2, step 5821/7134 completed (loss: 0.016155274584889412, acc: 0.9938367009162903)
[2024-12-17 04:26:31,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:32,164][root][INFO] - Training Epoch: 1/2, step 5822/7134 completed (loss: 0.039697714149951935, acc: 0.9854838848114014)
[2024-12-17 04:26:32,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:32,553][root][INFO] - Training Epoch: 1/2, step 5823/7134 completed (loss: 0.030986526980996132, acc: 0.9922239780426025)
[2024-12-17 04:26:32,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:32,984][root][INFO] - Training Epoch: 1/2, step 5824/7134 completed (loss: 0.024473924189805984, acc: 0.9953343868255615)
[2024-12-17 04:26:33,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:33,422][root][INFO] - Training Epoch: 1/2, step 5825/7134 completed (loss: 0.05108879879117012, acc: 0.9809688329696655)
[2024-12-17 04:26:33,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:33,864][root][INFO] - Training Epoch: 1/2, step 5826/7134 completed (loss: 0.019908729940652847, acc: 0.991134762763977)
[2024-12-17 04:26:33,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:34,269][root][INFO] - Training Epoch: 1/2, step 5827/7134 completed (loss: 0.03089839406311512, acc: 0.9865384697914124)
[2024-12-17 04:26:34,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:34,699][root][INFO] - Training Epoch: 1/2, step 5828/7134 completed (loss: 0.059522420167922974, acc: 0.9821693897247314)
[2024-12-17 04:26:34,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:35,126][root][INFO] - Training Epoch: 1/2, step 5829/7134 completed (loss: 0.045909252017736435, acc: 0.990777313709259)
[2024-12-17 04:26:35,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:35,511][root][INFO] - Training Epoch: 1/2, step 5830/7134 completed (loss: 0.03321560472249985, acc: 0.9943289160728455)
[2024-12-17 04:26:35,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:35,896][root][INFO] - Training Epoch: 1/2, step 5831/7134 completed (loss: 0.020832525566220284, acc: 0.9906976819038391)
[2024-12-17 04:26:35,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:36,312][root][INFO] - Training Epoch: 1/2, step 5832/7134 completed (loss: 0.06144443154335022, acc: 0.9797297120094299)
[2024-12-17 04:26:36,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:36,695][root][INFO] - Training Epoch: 1/2, step 5833/7134 completed (loss: 0.037534117698669434, acc: 0.9928315281867981)
[2024-12-17 04:26:36,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:37,110][root][INFO] - Training Epoch: 1/2, step 5834/7134 completed (loss: 0.03381074219942093, acc: 0.9916666746139526)
[2024-12-17 04:26:37,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:37,522][root][INFO] - Training Epoch: 1/2, step 5835/7134 completed (loss: 0.015997542068362236, acc: 0.9971098303794861)
[2024-12-17 04:26:37,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:37,948][root][INFO] - Training Epoch: 1/2, step 5836/7134 completed (loss: 0.03718269243836403, acc: 0.9870316982269287)
[2024-12-17 04:26:38,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:38,360][root][INFO] - Training Epoch: 1/2, step 5837/7134 completed (loss: 0.08324982970952988, acc: 0.9831081032752991)
[2024-12-17 04:26:38,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:38,780][root][INFO] - Training Epoch: 1/2, step 5838/7134 completed (loss: 0.05404985323548317, acc: 0.9901153445243835)
[2024-12-17 04:26:38,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:39,204][root][INFO] - Training Epoch: 1/2, step 5839/7134 completed (loss: 0.02499684877693653, acc: 0.9928571581840515)
[2024-12-17 04:26:39,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:39,615][root][INFO] - Training Epoch: 1/2, step 5840/7134 completed (loss: 0.02137262001633644, acc: 0.9936407208442688)
[2024-12-17 04:26:39,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:40,029][root][INFO] - Training Epoch: 1/2, step 5841/7134 completed (loss: 0.03751366585493088, acc: 0.9888357520103455)
[2024-12-17 04:26:40,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:40,432][root][INFO] - Training Epoch: 1/2, step 5842/7134 completed (loss: 0.037764810025691986, acc: 0.989130437374115)
[2024-12-17 04:26:40,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:40,864][root][INFO] - Training Epoch: 1/2, step 5843/7134 completed (loss: 0.04473888874053955, acc: 0.9879518151283264)
[2024-12-17 04:26:40,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:41,296][root][INFO] - Training Epoch: 1/2, step 5844/7134 completed (loss: 0.023126879706978798, acc: 0.991465151309967)
[2024-12-17 04:26:41,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:41,715][root][INFO] - Training Epoch: 1/2, step 5845/7134 completed (loss: 0.041019219905138016, acc: 0.9900285005569458)
[2024-12-17 04:26:41,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:42,141][root][INFO] - Training Epoch: 1/2, step 5846/7134 completed (loss: 0.04849772900342941, acc: 0.9849520921707153)
[2024-12-17 04:26:42,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:42,598][root][INFO] - Training Epoch: 1/2, step 5847/7134 completed (loss: 0.018475160002708435, acc: 0.9958791136741638)
[2024-12-17 04:26:42,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:43,025][root][INFO] - Training Epoch: 1/2, step 5848/7134 completed (loss: 0.07612164318561554, acc: 0.9836309552192688)
[2024-12-17 04:26:43,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:43,446][root][INFO] - Training Epoch: 1/2, step 5849/7134 completed (loss: 0.06996255367994308, acc: 0.9778761267662048)
[2024-12-17 04:26:43,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:43,866][root][INFO] - Training Epoch: 1/2, step 5850/7134 completed (loss: 0.027549056336283684, acc: 0.989313006401062)
[2024-12-17 04:26:44,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:44,299][root][INFO] - Training Epoch: 1/2, step 5851/7134 completed (loss: 0.03160976991057396, acc: 0.9884868264198303)
[2024-12-17 04:26:44,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:44,714][root][INFO] - Training Epoch: 1/2, step 5852/7134 completed (loss: 0.026113318279385567, acc: 0.9912408590316772)
[2024-12-17 04:26:44,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:45,148][root][INFO] - Training Epoch: 1/2, step 5853/7134 completed (loss: 0.058346472680568695, acc: 0.9864681959152222)
[2024-12-17 04:26:45,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:45,567][root][INFO] - Training Epoch: 1/2, step 5854/7134 completed (loss: 0.03179614618420601, acc: 0.991150438785553)
[2024-12-17 04:26:45,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:45,963][root][INFO] - Training Epoch: 1/2, step 5855/7134 completed (loss: 0.07767441868782043, acc: 0.9792746305465698)
[2024-12-17 04:26:46,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:46,380][root][INFO] - Training Epoch: 1/2, step 5856/7134 completed (loss: 0.08064278215169907, acc: 0.9803625345230103)
[2024-12-17 04:26:46,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:46,826][root][INFO] - Training Epoch: 1/2, step 5857/7134 completed (loss: 0.04299084469676018, acc: 0.9905213117599487)
[2024-12-17 04:26:46,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:47,215][root][INFO] - Training Epoch: 1/2, step 5858/7134 completed (loss: 0.030567670240998268, acc: 0.9926062822341919)
[2024-12-17 04:26:47,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:47,622][root][INFO] - Training Epoch: 1/2, step 5859/7134 completed (loss: 0.04672081395983696, acc: 0.98828125)
[2024-12-17 04:26:47,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:48,015][root][INFO] - Training Epoch: 1/2, step 5860/7134 completed (loss: 0.049668435007333755, acc: 0.9779614210128784)
[2024-12-17 04:26:48,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:48,399][root][INFO] - Training Epoch: 1/2, step 5861/7134 completed (loss: 0.033729106187820435, acc: 0.9878296256065369)
[2024-12-17 04:26:48,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:48,819][root][INFO] - Training Epoch: 1/2, step 5862/7134 completed (loss: 0.0604005828499794, acc: 0.9806867241859436)
[2024-12-17 04:26:48,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:49,217][root][INFO] - Training Epoch: 1/2, step 5863/7134 completed (loss: 0.04577578604221344, acc: 0.9873737096786499)
[2024-12-17 04:26:49,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:49,635][root][INFO] - Training Epoch: 1/2, step 5864/7134 completed (loss: 0.06568554043769836, acc: 0.985029935836792)
[2024-12-17 04:26:49,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:50,059][root][INFO] - Training Epoch: 1/2, step 5865/7134 completed (loss: 0.05723365396261215, acc: 0.9841269850730896)
[2024-12-17 04:26:50,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:50,509][root][INFO] - Training Epoch: 1/2, step 5866/7134 completed (loss: 0.03680367395281792, acc: 0.9894179701805115)
[2024-12-17 04:26:50,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:50,919][root][INFO] - Training Epoch: 1/2, step 5867/7134 completed (loss: 0.04324541985988617, acc: 0.9900826215744019)
[2024-12-17 04:26:51,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:51,336][root][INFO] - Training Epoch: 1/2, step 5868/7134 completed (loss: 0.04630216583609581, acc: 0.982758641242981)
[2024-12-17 04:26:51,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:51,731][root][INFO] - Training Epoch: 1/2, step 5869/7134 completed (loss: 0.07408647239208221, acc: 0.9776119589805603)
[2024-12-17 04:26:51,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:52,150][root][INFO] - Training Epoch: 1/2, step 5870/7134 completed (loss: 0.07769279927015305, acc: 0.9790794849395752)
[2024-12-17 04:26:52,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:52,538][root][INFO] - Training Epoch: 1/2, step 5871/7134 completed (loss: 0.032811690121889114, acc: 0.987261176109314)
[2024-12-17 04:26:52,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:52,943][root][INFO] - Training Epoch: 1/2, step 5872/7134 completed (loss: 0.04484330862760544, acc: 0.9847792983055115)
[2024-12-17 04:26:53,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:53,438][root][INFO] - Training Epoch: 1/2, step 5873/7134 completed (loss: 0.05289414897561073, acc: 0.984000027179718)
[2024-12-17 04:26:53,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:53,786][root][INFO] - Training Epoch: 1/2, step 5874/7134 completed (loss: 0.02172115072607994, acc: 0.9919678568840027)
[2024-12-17 04:26:53,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:54,154][root][INFO] - Training Epoch: 1/2, step 5875/7134 completed (loss: 0.05289284884929657, acc: 0.9805309772491455)
[2024-12-17 04:26:54,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:54,592][root][INFO] - Training Epoch: 1/2, step 5876/7134 completed (loss: 0.015610449947416782, acc: 0.9927184581756592)
[2024-12-17 04:26:54,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:55,008][root][INFO] - Training Epoch: 1/2, step 5877/7134 completed (loss: 0.07484418153762817, acc: 0.9847715497016907)
[2024-12-17 04:26:55,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:55,430][root][INFO] - Training Epoch: 1/2, step 5878/7134 completed (loss: 0.041868630796670914, acc: 0.9868420958518982)
[2024-12-17 04:26:55,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:55,830][root][INFO] - Training Epoch: 1/2, step 5879/7134 completed (loss: 0.061091456562280655, acc: 0.9771573543548584)
[2024-12-17 04:26:55,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:56,221][root][INFO] - Training Epoch: 1/2, step 5880/7134 completed (loss: 0.026340996846556664, acc: 0.9911110997200012)
[2024-12-17 04:26:56,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:56,639][root][INFO] - Training Epoch: 1/2, step 5881/7134 completed (loss: 0.01332085020840168, acc: 0.9961612224578857)
[2024-12-17 04:26:56,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:57,047][root][INFO] - Training Epoch: 1/2, step 5882/7134 completed (loss: 0.03886124864220619, acc: 0.9835293889045715)
[2024-12-17 04:26:57,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:57,447][root][INFO] - Training Epoch: 1/2, step 5883/7134 completed (loss: 0.06686130911111832, acc: 0.9850187301635742)
[2024-12-17 04:26:57,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:57,864][root][INFO] - Training Epoch: 1/2, step 5884/7134 completed (loss: 0.1067645400762558, acc: 0.9689781069755554)
[2024-12-17 04:26:57,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:58,269][root][INFO] - Training Epoch: 1/2, step 5885/7134 completed (loss: 0.10812004655599594, acc: 0.9728260636329651)
[2024-12-17 04:26:58,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:58,631][root][INFO] - Training Epoch: 1/2, step 5886/7134 completed (loss: 0.033691808581352234, acc: 0.9885714054107666)
[2024-12-17 04:26:58,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:59,027][root][INFO] - Training Epoch: 1/2, step 5887/7134 completed (loss: 0.04828909412026405, acc: 0.9915074110031128)
[2024-12-17 04:26:59,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:59,441][root][INFO] - Training Epoch: 1/2, step 5888/7134 completed (loss: 0.05434926599264145, acc: 0.9898648858070374)
[2024-12-17 04:26:59,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:26:59,774][root][INFO] - Training Epoch: 1/2, step 5889/7134 completed (loss: 0.04794240742921829, acc: 0.9821428656578064)
[2024-12-17 04:26:59,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:00,215][root][INFO] - Training Epoch: 1/2, step 5890/7134 completed (loss: 0.027337899431586266, acc: 0.9912587404251099)
[2024-12-17 04:27:00,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:00,636][root][INFO] - Training Epoch: 1/2, step 5891/7134 completed (loss: 0.052409667521715164, acc: 0.979742169380188)
[2024-12-17 04:27:00,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:01,081][root][INFO] - Training Epoch: 1/2, step 5892/7134 completed (loss: 0.07768724858760834, acc: 0.9854227304458618)
[2024-12-17 04:27:01,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:01,492][root][INFO] - Training Epoch: 1/2, step 5893/7134 completed (loss: 0.04981713742017746, acc: 0.982677161693573)
[2024-12-17 04:27:01,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:01,866][root][INFO] - Training Epoch: 1/2, step 5894/7134 completed (loss: 0.025561118498444557, acc: 0.9901639223098755)
[2024-12-17 04:27:01,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:02,267][root][INFO] - Training Epoch: 1/2, step 5895/7134 completed (loss: 0.020760906860232353, acc: 0.9928571581840515)
[2024-12-17 04:27:02,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:02,683][root][INFO] - Training Epoch: 1/2, step 5896/7134 completed (loss: 0.07540855556726456, acc: 0.9829931855201721)
[2024-12-17 04:27:02,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:03,120][root][INFO] - Training Epoch: 1/2, step 5897/7134 completed (loss: 0.02626746892929077, acc: 0.9917355179786682)
[2024-12-17 04:27:03,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:03,531][root][INFO] - Training Epoch: 1/2, step 5898/7134 completed (loss: 0.04905155301094055, acc: 0.9892241358757019)
[2024-12-17 04:27:03,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:03,881][root][INFO] - Training Epoch: 1/2, step 5899/7134 completed (loss: 0.024442549794912338, acc: 0.9940476417541504)
[2024-12-17 04:27:04,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:04,263][root][INFO] - Training Epoch: 1/2, step 5900/7134 completed (loss: 0.05181257426738739, acc: 0.9821428656578064)
[2024-12-17 04:27:04,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:04,712][root][INFO] - Training Epoch: 1/2, step 5901/7134 completed (loss: 0.06674421578645706, acc: 0.987500011920929)
[2024-12-17 04:27:04,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:05,148][root][INFO] - Training Epoch: 1/2, step 5902/7134 completed (loss: 0.08010990172624588, acc: 0.9768041372299194)
[2024-12-17 04:27:05,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:05,571][root][INFO] - Training Epoch: 1/2, step 5903/7134 completed (loss: 0.07166494429111481, acc: 0.9781022071838379)
[2024-12-17 04:27:05,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:06,012][root][INFO] - Training Epoch: 1/2, step 5904/7134 completed (loss: 0.04860839992761612, acc: 0.9849726557731628)
[2024-12-17 04:27:06,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:06,432][root][INFO] - Training Epoch: 1/2, step 5905/7134 completed (loss: 0.06655588001012802, acc: 0.9847009778022766)
[2024-12-17 04:27:06,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:06,891][root][INFO] - Training Epoch: 1/2, step 5906/7134 completed (loss: 0.08661626279354095, acc: 0.9766584634780884)
[2024-12-17 04:27:07,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:07,383][root][INFO] - Training Epoch: 1/2, step 5907/7134 completed (loss: 0.05469011142849922, acc: 0.983182430267334)
[2024-12-17 04:27:07,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:07,877][root][INFO] - Training Epoch: 1/2, step 5908/7134 completed (loss: 0.05948738381266594, acc: 0.9820972084999084)
[2024-12-17 04:27:08,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:08,480][root][INFO] - Training Epoch: 1/2, step 5909/7134 completed (loss: 0.07080106437206268, acc: 0.9783861637115479)
[2024-12-17 04:27:08,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:08,975][root][INFO] - Training Epoch: 1/2, step 5910/7134 completed (loss: 0.06400705128908157, acc: 0.9764216542243958)
[2024-12-17 04:27:09,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:09,393][root][INFO] - Training Epoch: 1/2, step 5911/7134 completed (loss: 0.049380552023649216, acc: 0.9900826215744019)
[2024-12-17 04:27:09,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:09,786][root][INFO] - Training Epoch: 1/2, step 5912/7134 completed (loss: 0.025491928681731224, acc: 0.9915611743927002)
[2024-12-17 04:27:09,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:10,248][root][INFO] - Training Epoch: 1/2, step 5913/7134 completed (loss: 0.09550613164901733, acc: 0.9836956262588501)
[2024-12-17 04:27:10,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:10,663][root][INFO] - Training Epoch: 1/2, step 5914/7134 completed (loss: 0.05111081525683403, acc: 0.9855538010597229)
[2024-12-17 04:27:10,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:11,117][root][INFO] - Training Epoch: 1/2, step 5915/7134 completed (loss: 0.06276331096887589, acc: 0.9829457402229309)
[2024-12-17 04:27:11,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:11,579][root][INFO] - Training Epoch: 1/2, step 5916/7134 completed (loss: 0.05698676407337189, acc: 0.9842725992202759)
[2024-12-17 04:27:11,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:11,957][root][INFO] - Training Epoch: 1/2, step 5917/7134 completed (loss: 0.050251178443431854, acc: 0.9861351847648621)
[2024-12-17 04:27:12,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:12,414][root][INFO] - Training Epoch: 1/2, step 5918/7134 completed (loss: 0.09810048341751099, acc: 0.9840348362922668)
[2024-12-17 04:27:12,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:12,837][root][INFO] - Training Epoch: 1/2, step 5919/7134 completed (loss: 0.0640348568558693, acc: 0.9772036671638489)
[2024-12-17 04:27:12,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:13,262][root][INFO] - Training Epoch: 1/2, step 5920/7134 completed (loss: 0.049992647022008896, acc: 0.9916805028915405)
[2024-12-17 04:27:13,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:13,700][root][INFO] - Training Epoch: 1/2, step 5921/7134 completed (loss: 0.0964638814330101, acc: 0.9770354628562927)
[2024-12-17 04:27:13,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:14,124][root][INFO] - Training Epoch: 1/2, step 5922/7134 completed (loss: 0.22625340521335602, acc: 0.945035457611084)
[2024-12-17 04:27:14,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:14,585][root][INFO] - Training Epoch: 1/2, step 5923/7134 completed (loss: 0.117520771920681, acc: 0.9707174301147461)
[2024-12-17 04:27:14,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:14,989][root][INFO] - Training Epoch: 1/2, step 5924/7134 completed (loss: 0.07908746600151062, acc: 0.9761336445808411)
[2024-12-17 04:27:15,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:15,348][root][INFO] - Training Epoch: 1/2, step 5925/7134 completed (loss: 0.21276293694972992, acc: 0.9618768095970154)
[2024-12-17 04:27:15,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:15,749][root][INFO] - Training Epoch: 1/2, step 5926/7134 completed (loss: 0.10307660698890686, acc: 0.9700000286102295)
[2024-12-17 04:27:15,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:16,144][root][INFO] - Training Epoch: 1/2, step 5927/7134 completed (loss: 0.10822835564613342, acc: 0.9665924310684204)
[2024-12-17 04:27:16,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:16,486][root][INFO] - Training Epoch: 1/2, step 5928/7134 completed (loss: 0.19610856473445892, acc: 0.9520547986030579)
[2024-12-17 04:27:16,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:16,898][root][INFO] - Training Epoch: 1/2, step 5929/7134 completed (loss: 0.08120188862085342, acc: 0.9738805890083313)
[2024-12-17 04:27:17,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:17,289][root][INFO] - Training Epoch: 1/2, step 5930/7134 completed (loss: 0.1188414916396141, acc: 0.9710467457771301)
[2024-12-17 04:27:17,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:17,686][root][INFO] - Training Epoch: 1/2, step 5931/7134 completed (loss: 0.06596604734659195, acc: 0.9848812222480774)
[2024-12-17 04:27:17,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:18,127][root][INFO] - Training Epoch: 1/2, step 5932/7134 completed (loss: 0.10104355961084366, acc: 0.9666666388511658)
[2024-12-17 04:27:18,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:18,507][root][INFO] - Training Epoch: 1/2, step 5933/7134 completed (loss: 0.14853566884994507, acc: 0.9601677060127258)
[2024-12-17 04:27:18,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:18,916][root][INFO] - Training Epoch: 1/2, step 5934/7134 completed (loss: 0.06009367108345032, acc: 0.9822379946708679)
[2024-12-17 04:27:19,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:19,317][root][INFO] - Training Epoch: 1/2, step 5935/7134 completed (loss: 0.06392914056777954, acc: 0.9864077568054199)
[2024-12-17 04:27:19,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:19,703][root][INFO] - Training Epoch: 1/2, step 5936/7134 completed (loss: 0.09602437913417816, acc: 0.9770290851593018)
[2024-12-17 04:27:19,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:20,121][root][INFO] - Training Epoch: 1/2, step 5937/7134 completed (loss: 0.03703300654888153, acc: 0.9872408509254456)
[2024-12-17 04:27:20,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:20,543][root][INFO] - Training Epoch: 1/2, step 5938/7134 completed (loss: 0.11983665078878403, acc: 0.971319317817688)
[2024-12-17 04:27:20,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:20,982][root][INFO] - Training Epoch: 1/2, step 5939/7134 completed (loss: 0.16243205964565277, acc: 0.9547511339187622)
[2024-12-17 04:27:21,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:21,442][root][INFO] - Training Epoch: 1/2, step 5940/7134 completed (loss: 0.08931738883256912, acc: 0.9737609624862671)
[2024-12-17 04:27:21,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:21,836][root][INFO] - Training Epoch: 1/2, step 5941/7134 completed (loss: 0.13698497414588928, acc: 0.96875)
[2024-12-17 04:27:21,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:22,274][root][INFO] - Training Epoch: 1/2, step 5942/7134 completed (loss: 0.020321186631917953, acc: 0.9923518300056458)
[2024-12-17 04:27:22,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:22,681][root][INFO] - Training Epoch: 1/2, step 5943/7134 completed (loss: 0.03693656250834465, acc: 0.9871244430541992)
[2024-12-17 04:27:22,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:23,148][root][INFO] - Training Epoch: 1/2, step 5944/7134 completed (loss: 0.07410391420125961, acc: 0.9790576100349426)
[2024-12-17 04:27:23,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:23,612][root][INFO] - Training Epoch: 1/2, step 5945/7134 completed (loss: 0.03794213756918907, acc: 0.9879879951477051)
[2024-12-17 04:27:23,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:24,019][root][INFO] - Training Epoch: 1/2, step 5946/7134 completed (loss: 0.049014102667570114, acc: 0.9836956262588501)
[2024-12-17 04:27:24,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:24,469][root][INFO] - Training Epoch: 1/2, step 5947/7134 completed (loss: 0.04290975257754326, acc: 0.9900867342948914)
[2024-12-17 04:27:24,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:24,893][root][INFO] - Training Epoch: 1/2, step 5948/7134 completed (loss: 0.07319200783967972, acc: 0.9760000109672546)
[2024-12-17 04:27:25,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:25,333][root][INFO] - Training Epoch: 1/2, step 5949/7134 completed (loss: 0.02636490762233734, acc: 0.9899623394012451)
[2024-12-17 04:27:25,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:25,731][root][INFO] - Training Epoch: 1/2, step 5950/7134 completed (loss: 0.1273096650838852, acc: 0.9619952440261841)
[2024-12-17 04:27:25,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:26,147][root][INFO] - Training Epoch: 1/2, step 5951/7134 completed (loss: 0.06853090226650238, acc: 0.9770444631576538)
[2024-12-17 04:27:26,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:26,595][root][INFO] - Training Epoch: 1/2, step 5952/7134 completed (loss: 0.17845755815505981, acc: 0.9624999761581421)
[2024-12-17 04:27:26,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:27,013][root][INFO] - Training Epoch: 1/2, step 5953/7134 completed (loss: 0.10434231907129288, acc: 0.9724518060684204)
[2024-12-17 04:27:27,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:27,435][root][INFO] - Training Epoch: 1/2, step 5954/7134 completed (loss: 0.03850506618618965, acc: 0.9949238300323486)
[2024-12-17 04:27:27,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:27,832][root][INFO] - Training Epoch: 1/2, step 5955/7134 completed (loss: 0.068135105073452, acc: 0.9857142567634583)
[2024-12-17 04:27:27,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:28,232][root][INFO] - Training Epoch: 1/2, step 5956/7134 completed (loss: 0.07534943521022797, acc: 0.9764705896377563)
[2024-12-17 04:27:28,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:28,632][root][INFO] - Training Epoch: 1/2, step 5957/7134 completed (loss: 0.06045673042535782, acc: 0.9835082292556763)
[2024-12-17 04:27:28,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:29,056][root][INFO] - Training Epoch: 1/2, step 5958/7134 completed (loss: 0.035769857466220856, acc: 0.9879194498062134)
[2024-12-17 04:27:29,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:29,498][root][INFO] - Training Epoch: 1/2, step 5959/7134 completed (loss: 0.04572539031505585, acc: 0.9866488575935364)
[2024-12-17 04:27:29,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:29,959][root][INFO] - Training Epoch: 1/2, step 5960/7134 completed (loss: 0.013602388091385365, acc: 0.9971910119056702)
[2024-12-17 04:27:30,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:30,323][root][INFO] - Training Epoch: 1/2, step 5961/7134 completed (loss: 0.062048666179180145, acc: 0.9774590134620667)
[2024-12-17 04:27:30,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:30,739][root][INFO] - Training Epoch: 1/2, step 5962/7134 completed (loss: 0.021510757505893707, acc: 0.9902439117431641)
[2024-12-17 04:27:30,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:31,163][root][INFO] - Training Epoch: 1/2, step 5963/7134 completed (loss: 0.020633447915315628, acc: 0.9902234673500061)
[2024-12-17 04:27:31,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:31,567][root][INFO] - Training Epoch: 1/2, step 5964/7134 completed (loss: 0.04074297100305557, acc: 0.9944547414779663)
[2024-12-17 04:27:31,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:31,986][root][INFO] - Training Epoch: 1/2, step 5965/7134 completed (loss: 0.05928407981991768, acc: 0.9865067601203918)
[2024-12-17 04:27:32,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:32,414][root][INFO] - Training Epoch: 1/2, step 5966/7134 completed (loss: 0.0631900504231453, acc: 0.9833564758300781)
[2024-12-17 04:27:32,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:32,850][root][INFO] - Training Epoch: 1/2, step 5967/7134 completed (loss: 0.049607496708631516, acc: 0.9925373196601868)
[2024-12-17 04:27:32,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:33,257][root][INFO] - Training Epoch: 1/2, step 5968/7134 completed (loss: 0.03368228301405907, acc: 0.990867555141449)
[2024-12-17 04:27:33,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:33,663][root][INFO] - Training Epoch: 1/2, step 5969/7134 completed (loss: 0.06482726335525513, acc: 0.9876161217689514)
[2024-12-17 04:27:33,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:34,069][root][INFO] - Training Epoch: 1/2, step 5970/7134 completed (loss: 0.05917938053607941, acc: 0.9877049326896667)
[2024-12-17 04:27:34,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:34,501][root][INFO] - Training Epoch: 1/2, step 5971/7134 completed (loss: 0.03126766160130501, acc: 0.9837092757225037)
[2024-12-17 04:27:34,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:34,945][root][INFO] - Training Epoch: 1/2, step 5972/7134 completed (loss: 0.09930448234081268, acc: 0.9794420003890991)
[2024-12-17 04:27:35,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:35,428][root][INFO] - Training Epoch: 1/2, step 5973/7134 completed (loss: 0.08317513763904572, acc: 0.971222996711731)
[2024-12-17 04:27:35,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:35,894][root][INFO] - Training Epoch: 1/2, step 5974/7134 completed (loss: 0.023715486750006676, acc: 0.9878683090209961)
[2024-12-17 04:27:35,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:36,292][root][INFO] - Training Epoch: 1/2, step 5975/7134 completed (loss: 0.01427486538887024, acc: 0.9941002726554871)
[2024-12-17 04:27:36,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:36,731][root][INFO] - Training Epoch: 1/2, step 5976/7134 completed (loss: 0.046165961772203445, acc: 0.9831288456916809)
[2024-12-17 04:27:36,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:37,174][root][INFO] - Training Epoch: 1/2, step 5977/7134 completed (loss: 0.017139695584774017, acc: 0.9950433969497681)
[2024-12-17 04:27:37,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:37,613][root][INFO] - Training Epoch: 1/2, step 5978/7134 completed (loss: 0.050744589418172836, acc: 0.9871794581413269)
[2024-12-17 04:27:37,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:37,980][root][INFO] - Training Epoch: 1/2, step 5979/7134 completed (loss: 0.055879127234220505, acc: 0.9851852059364319)
[2024-12-17 04:27:38,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:38,412][root][INFO] - Training Epoch: 1/2, step 5980/7134 completed (loss: 0.03800973668694496, acc: 0.9884763360023499)
[2024-12-17 04:27:38,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:38,911][root][INFO] - Training Epoch: 1/2, step 5981/7134 completed (loss: 0.039844367653131485, acc: 0.9872832298278809)
[2024-12-17 04:27:39,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:39,306][root][INFO] - Training Epoch: 1/2, step 5982/7134 completed (loss: 0.046347666531801224, acc: 0.9880715608596802)
[2024-12-17 04:27:39,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:39,732][root][INFO] - Training Epoch: 1/2, step 5983/7134 completed (loss: 0.04899148270487785, acc: 0.9861111044883728)
[2024-12-17 04:27:39,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:40,166][root][INFO] - Training Epoch: 1/2, step 5984/7134 completed (loss: 0.030804671347141266, acc: 0.9872340559959412)
[2024-12-17 04:27:40,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:40,624][root][INFO] - Training Epoch: 1/2, step 5985/7134 completed (loss: 0.044177282601594925, acc: 0.9887359142303467)
[2024-12-17 04:27:40,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:41,090][root][INFO] - Training Epoch: 1/2, step 5986/7134 completed (loss: 0.059120263904333115, acc: 0.9847133755683899)
[2024-12-17 04:27:41,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:41,540][root][INFO] - Training Epoch: 1/2, step 5987/7134 completed (loss: 0.06051832437515259, acc: 0.9825174808502197)
[2024-12-17 04:27:41,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:41,965][root][INFO] - Training Epoch: 1/2, step 5988/7134 completed (loss: 0.023797065019607544, acc: 0.9946666955947876)
[2024-12-17 04:27:42,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:42,412][root][INFO] - Training Epoch: 1/2, step 5989/7134 completed (loss: 0.07835923135280609, acc: 0.9852398633956909)
[2024-12-17 04:27:42,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:42,887][root][INFO] - Training Epoch: 1/2, step 5990/7134 completed (loss: 0.04716085270047188, acc: 0.9890410900115967)
[2024-12-17 04:27:43,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:43,245][root][INFO] - Training Epoch: 1/2, step 5991/7134 completed (loss: 0.08851859718561172, acc: 0.9832402467727661)
[2024-12-17 04:27:43,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:43,740][root][INFO] - Training Epoch: 1/2, step 5992/7134 completed (loss: 0.04254450649023056, acc: 0.9849012494087219)
[2024-12-17 04:27:43,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:44,168][root][INFO] - Training Epoch: 1/2, step 5993/7134 completed (loss: 0.034901589155197144, acc: 0.9902912378311157)
[2024-12-17 04:27:44,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:44,575][root][INFO] - Training Epoch: 1/2, step 5994/7134 completed (loss: 0.028835158795118332, acc: 0.9904943108558655)
[2024-12-17 04:27:44,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:45,032][root][INFO] - Training Epoch: 1/2, step 5995/7134 completed (loss: 0.018756220117211342, acc: 0.9929577708244324)
[2024-12-17 04:27:45,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:45,465][root][INFO] - Training Epoch: 1/2, step 5996/7134 completed (loss: 0.06972164660692215, acc: 0.9765258431434631)
[2024-12-17 04:27:45,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:45,898][root][INFO] - Training Epoch: 1/2, step 5997/7134 completed (loss: 0.04348571598529816, acc: 0.9919893145561218)
[2024-12-17 04:27:46,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:46,353][root][INFO] - Training Epoch: 1/2, step 5998/7134 completed (loss: 0.045612942427396774, acc: 0.9862843155860901)
[2024-12-17 04:27:46,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:46,756][root][INFO] - Training Epoch: 1/2, step 5999/7134 completed (loss: 0.026750968769192696, acc: 0.9938042163848877)
[2024-12-17 04:27:46,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:47,149][root][INFO] - Training Epoch: 1/2, step 6000/7134 completed (loss: 0.0476975291967392, acc: 0.9850249290466309)
[2024-12-17 04:27:47,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:47,593][root][INFO] - Training Epoch: 1/2, step 6001/7134 completed (loss: 0.024600042030215263, acc: 0.9923273921012878)
[2024-12-17 04:27:47,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:48,005][root][INFO] - Training Epoch: 1/2, step 6002/7134 completed (loss: 0.07077175378799438, acc: 0.9805068373680115)
[2024-12-17 04:27:48,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:48,463][root][INFO] - Training Epoch: 1/2, step 6003/7134 completed (loss: 0.045597273856401443, acc: 0.98531574010849)
[2024-12-17 04:27:48,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:48,890][root][INFO] - Training Epoch: 1/2, step 6004/7134 completed (loss: 0.039043523371219635, acc: 0.9860917925834656)
[2024-12-17 04:27:48,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:49,291][root][INFO] - Training Epoch: 1/2, step 6005/7134 completed (loss: 0.04615705832839012, acc: 0.9847792983055115)
[2024-12-17 04:27:49,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:49,704][root][INFO] - Training Epoch: 1/2, step 6006/7134 completed (loss: 0.06519358605146408, acc: 0.9767891764640808)
[2024-12-17 04:27:49,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:50,148][root][INFO] - Training Epoch: 1/2, step 6007/7134 completed (loss: 0.037483226507902145, acc: 0.9866443872451782)
[2024-12-17 04:27:50,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:50,580][root][INFO] - Training Epoch: 1/2, step 6008/7134 completed (loss: 0.05815005674958229, acc: 0.9807121753692627)
[2024-12-17 04:27:50,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:50,983][root][INFO] - Training Epoch: 1/2, step 6009/7134 completed (loss: 0.08916589617729187, acc: 0.9736024737358093)
[2024-12-17 04:27:51,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:51,415][root][INFO] - Training Epoch: 1/2, step 6010/7134 completed (loss: 0.07918626815080643, acc: 0.9783197641372681)
[2024-12-17 04:27:51,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:51,863][root][INFO] - Training Epoch: 1/2, step 6011/7134 completed (loss: 0.0686119794845581, acc: 0.9818652868270874)
[2024-12-17 04:27:51,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:52,284][root][INFO] - Training Epoch: 1/2, step 6012/7134 completed (loss: 0.047794539481401443, acc: 0.9820895791053772)
[2024-12-17 04:27:52,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:52,699][root][INFO] - Training Epoch: 1/2, step 6013/7134 completed (loss: 0.06197130307555199, acc: 0.98128342628479)
[2024-12-17 04:27:52,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:53,089][root][INFO] - Training Epoch: 1/2, step 6014/7134 completed (loss: 0.04760001227259636, acc: 0.9818511605262756)
[2024-12-17 04:27:53,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:53,525][root][INFO] - Training Epoch: 1/2, step 6015/7134 completed (loss: 0.08042019605636597, acc: 0.9752066135406494)
[2024-12-17 04:27:53,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:53,954][root][INFO] - Training Epoch: 1/2, step 6016/7134 completed (loss: 0.04606257379055023, acc: 0.9892473220825195)
[2024-12-17 04:27:54,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:54,310][root][INFO] - Training Epoch: 1/2, step 6017/7134 completed (loss: 0.046533454209566116, acc: 0.9900990128517151)
[2024-12-17 04:27:54,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:54,714][root][INFO] - Training Epoch: 1/2, step 6018/7134 completed (loss: 0.014632036909461021, acc: 0.9947368502616882)
[2024-12-17 04:27:54,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:55,070][root][INFO] - Training Epoch: 1/2, step 6019/7134 completed (loss: 0.0853443443775177, acc: 0.9655172228813171)
[2024-12-17 04:27:55,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:55,426][root][INFO] - Training Epoch: 1/2, step 6020/7134 completed (loss: 0.007557122502475977, acc: 1.0)
[2024-12-17 04:27:55,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:55,760][root][INFO] - Training Epoch: 1/2, step 6021/7134 completed (loss: 0.019425207749009132, acc: 0.9934640526771545)
[2024-12-17 04:27:55,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:56,116][root][INFO] - Training Epoch: 1/2, step 6022/7134 completed (loss: 0.03846137598156929, acc: 0.9852398633956909)
[2024-12-17 04:27:56,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:56,465][root][INFO] - Training Epoch: 1/2, step 6023/7134 completed (loss: 0.04418227821588516, acc: 0.989159882068634)
[2024-12-17 04:27:56,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:56,787][root][INFO] - Training Epoch: 1/2, step 6024/7134 completed (loss: 0.01449824683368206, acc: 0.9953488111495972)
[2024-12-17 04:27:56,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:57,170][root][INFO] - Training Epoch: 1/2, step 6025/7134 completed (loss: 0.027127020061016083, acc: 0.991631805896759)
[2024-12-17 04:27:57,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:57,472][root][INFO] - Training Epoch: 1/2, step 6026/7134 completed (loss: 0.02570227161049843, acc: 0.9942857027053833)
[2024-12-17 04:27:57,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:57,863][root][INFO] - Training Epoch: 1/2, step 6027/7134 completed (loss: 0.034076713025569916, acc: 0.9948586225509644)
[2024-12-17 04:27:57,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:58,232][root][INFO] - Training Epoch: 1/2, step 6028/7134 completed (loss: 0.03812073543667793, acc: 0.9911110997200012)
[2024-12-17 04:27:58,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:58,631][root][INFO] - Training Epoch: 1/2, step 6029/7134 completed (loss: 0.04055937007069588, acc: 0.9927797913551331)
[2024-12-17 04:27:58,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:59,006][root][INFO] - Training Epoch: 1/2, step 6030/7134 completed (loss: 0.06946323812007904, acc: 0.9885057210922241)
[2024-12-17 04:27:59,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:59,414][root][INFO] - Training Epoch: 1/2, step 6031/7134 completed (loss: 0.04975482448935509, acc: 0.9912280440330505)
[2024-12-17 04:27:59,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:27:59,773][root][INFO] - Training Epoch: 1/2, step 6032/7134 completed (loss: 0.02950517274439335, acc: 0.9949367046356201)
[2024-12-17 04:27:59,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:00,127][root][INFO] - Training Epoch: 1/2, step 6033/7134 completed (loss: 0.1070542186498642, acc: 0.9713114500045776)
[2024-12-17 04:28:00,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:00,449][root][INFO] - Training Epoch: 1/2, step 6034/7134 completed (loss: 0.06632786989212036, acc: 0.9836065769195557)
[2024-12-17 04:28:00,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:00,926][root][INFO] - Training Epoch: 1/2, step 6035/7134 completed (loss: 0.10858199000358582, acc: 0.9719298481941223)
[2024-12-17 04:28:01,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:01,397][root][INFO] - Training Epoch: 1/2, step 6036/7134 completed (loss: 0.08206004649400711, acc: 0.9706293940544128)
[2024-12-17 04:28:01,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:01,836][root][INFO] - Training Epoch: 1/2, step 6037/7134 completed (loss: 0.05782025307416916, acc: 0.9864406585693359)
[2024-12-17 04:28:01,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:02,300][root][INFO] - Training Epoch: 1/2, step 6038/7134 completed (loss: 0.052800774574279785, acc: 0.9821029305458069)
[2024-12-17 04:28:02,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:02,752][root][INFO] - Training Epoch: 1/2, step 6039/7134 completed (loss: 0.03075067512691021, acc: 0.990510106086731)
[2024-12-17 04:28:02,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:03,209][root][INFO] - Training Epoch: 1/2, step 6040/7134 completed (loss: 0.08937427401542664, acc: 0.9802494645118713)
[2024-12-17 04:28:03,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:03,640][root][INFO] - Training Epoch: 1/2, step 6041/7134 completed (loss: 0.06238984689116478, acc: 0.9829620122909546)
[2024-12-17 04:28:03,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:04,126][root][INFO] - Training Epoch: 1/2, step 6042/7134 completed (loss: 0.0379742756485939, acc: 0.9890000224113464)
[2024-12-17 04:28:04,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:04,589][root][INFO] - Training Epoch: 1/2, step 6043/7134 completed (loss: 0.04288623109459877, acc: 0.9856114983558655)
[2024-12-17 04:28:04,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:05,043][root][INFO] - Training Epoch: 1/2, step 6044/7134 completed (loss: 0.05670642480254173, acc: 0.9827160239219666)
[2024-12-17 04:28:05,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:05,478][root][INFO] - Training Epoch: 1/2, step 6045/7134 completed (loss: 0.06372932344675064, acc: 0.9846153855323792)
[2024-12-17 04:28:05,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:05,923][root][INFO] - Training Epoch: 1/2, step 6046/7134 completed (loss: 0.05892837047576904, acc: 0.9826689958572388)
[2024-12-17 04:28:06,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:06,383][root][INFO] - Training Epoch: 1/2, step 6047/7134 completed (loss: 0.11401929706335068, acc: 0.9696458578109741)
[2024-12-17 04:28:06,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:06,820][root][INFO] - Training Epoch: 1/2, step 6048/7134 completed (loss: 0.11663854122161865, acc: 0.9719439148902893)
[2024-12-17 04:28:06,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:07,244][root][INFO] - Training Epoch: 1/2, step 6049/7134 completed (loss: 0.044443193823099136, acc: 0.9846416115760803)
[2024-12-17 04:28:07,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:07,669][root][INFO] - Training Epoch: 1/2, step 6050/7134 completed (loss: 0.0869353860616684, acc: 0.9685362577438354)
[2024-12-17 04:28:07,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:08,133][root][INFO] - Training Epoch: 1/2, step 6051/7134 completed (loss: 0.10970479995012283, acc: 0.9719350337982178)
[2024-12-17 04:28:08,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:08,606][root][INFO] - Training Epoch: 1/2, step 6052/7134 completed (loss: 0.10756367444992065, acc: 0.9748822450637817)
[2024-12-17 04:28:08,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:09,061][root][INFO] - Training Epoch: 1/2, step 6053/7134 completed (loss: 0.05819745361804962, acc: 0.9813596606254578)
[2024-12-17 04:28:09,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:09,495][root][INFO] - Training Epoch: 1/2, step 6054/7134 completed (loss: 0.053504474461078644, acc: 0.990338146686554)
[2024-12-17 04:28:09,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:09,909][root][INFO] - Training Epoch: 1/2, step 6055/7134 completed (loss: 0.06321225315332413, acc: 0.9794628620147705)
[2024-12-17 04:28:10,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:10,302][root][INFO] - Training Epoch: 1/2, step 6056/7134 completed (loss: 0.08970635384321213, acc: 0.9746543765068054)
[2024-12-17 04:28:10,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:10,681][root][INFO] - Training Epoch: 1/2, step 6057/7134 completed (loss: 0.05821097642183304, acc: 0.9769737124443054)
[2024-12-17 04:28:10,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:11,066][root][INFO] - Training Epoch: 1/2, step 6058/7134 completed (loss: 0.02294258400797844, acc: 0.9909909963607788)
[2024-12-17 04:28:11,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:11,487][root][INFO] - Training Epoch: 1/2, step 6059/7134 completed (loss: 0.029974840581417084, acc: 0.9929328560829163)
[2024-12-17 04:28:11,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:11,933][root][INFO] - Training Epoch: 1/2, step 6060/7134 completed (loss: 0.044755734503269196, acc: 0.9864661693572998)
[2024-12-17 04:28:12,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:12,340][root][INFO] - Training Epoch: 1/2, step 6061/7134 completed (loss: 0.09988842159509659, acc: 0.9768875241279602)
[2024-12-17 04:28:12,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:12,771][root][INFO] - Training Epoch: 1/2, step 6062/7134 completed (loss: 0.09153468906879425, acc: 0.9702842235565186)
[2024-12-17 04:28:12,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:13,172][root][INFO] - Training Epoch: 1/2, step 6063/7134 completed (loss: 0.1465907096862793, acc: 0.9584086537361145)
[2024-12-17 04:28:13,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:13,610][root][INFO] - Training Epoch: 1/2, step 6064/7134 completed (loss: 0.060506537556648254, acc: 0.9797394871711731)
[2024-12-17 04:28:13,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:14,064][root][INFO] - Training Epoch: 1/2, step 6065/7134 completed (loss: 0.07469353079795837, acc: 0.9793438911437988)
[2024-12-17 04:28:14,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:14,486][root][INFO] - Training Epoch: 1/2, step 6066/7134 completed (loss: 0.0920790582895279, acc: 0.9719933867454529)
[2024-12-17 04:28:14,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:14,892][root][INFO] - Training Epoch: 1/2, step 6067/7134 completed (loss: 0.07335473597049713, acc: 0.9841269850730896)
[2024-12-17 04:28:15,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:15,391][root][INFO] - Training Epoch: 1/2, step 6068/7134 completed (loss: 0.13393044471740723, acc: 0.9649562239646912)
[2024-12-17 04:28:15,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:15,805][root][INFO] - Training Epoch: 1/2, step 6069/7134 completed (loss: 0.10183507204055786, acc: 0.9649634957313538)
[2024-12-17 04:28:15,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:16,257][root][INFO] - Training Epoch: 1/2, step 6070/7134 completed (loss: 0.1379215568304062, acc: 0.964047908782959)
[2024-12-17 04:28:16,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:16,686][root][INFO] - Training Epoch: 1/2, step 6071/7134 completed (loss: 0.07004108279943466, acc: 0.9811574816703796)
[2024-12-17 04:28:16,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:17,068][root][INFO] - Training Epoch: 1/2, step 6072/7134 completed (loss: 0.11764055490493774, acc: 0.970588207244873)
[2024-12-17 04:28:17,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:17,481][root][INFO] - Training Epoch: 1/2, step 6073/7134 completed (loss: 0.08807306736707687, acc: 0.977622389793396)
[2024-12-17 04:28:17,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:17,892][root][INFO] - Training Epoch: 1/2, step 6074/7134 completed (loss: 0.07714807242155075, acc: 0.9808823466300964)
[2024-12-17 04:28:17,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:18,334][root][INFO] - Training Epoch: 1/2, step 6075/7134 completed (loss: 0.07481151819229126, acc: 0.9796162843704224)
[2024-12-17 04:28:18,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:18,754][root][INFO] - Training Epoch: 1/2, step 6076/7134 completed (loss: 0.12625207006931305, acc: 0.9683908224105835)
[2024-12-17 04:28:18,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:19,172][root][INFO] - Training Epoch: 1/2, step 6077/7134 completed (loss: 0.09053459763526917, acc: 0.969648540019989)
[2024-12-17 04:28:19,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:19,610][root][INFO] - Training Epoch: 1/2, step 6078/7134 completed (loss: 0.1005830466747284, acc: 0.9746478796005249)
[2024-12-17 04:28:19,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:20,062][root][INFO] - Training Epoch: 1/2, step 6079/7134 completed (loss: 0.046717721968889236, acc: 0.9817517995834351)
[2024-12-17 04:28:20,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:20,474][root][INFO] - Training Epoch: 1/2, step 6080/7134 completed (loss: 0.05760163813829422, acc: 0.9844412803649902)
[2024-12-17 04:28:20,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:20,901][root][INFO] - Training Epoch: 1/2, step 6081/7134 completed (loss: 0.06219622120261192, acc: 0.9801526665687561)
[2024-12-17 04:28:21,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:21,321][root][INFO] - Training Epoch: 1/2, step 6082/7134 completed (loss: 0.05294010043144226, acc: 0.9888535141944885)
[2024-12-17 04:28:21,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:21,771][root][INFO] - Training Epoch: 1/2, step 6083/7134 completed (loss: 0.029823986813426018, acc: 0.9938575029373169)
[2024-12-17 04:28:21,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:22,177][root][INFO] - Training Epoch: 1/2, step 6084/7134 completed (loss: 0.07002215087413788, acc: 0.9779874086380005)
[2024-12-17 04:28:22,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:22,633][root][INFO] - Training Epoch: 1/2, step 6085/7134 completed (loss: 0.06379638612270355, acc: 0.9838998317718506)
[2024-12-17 04:28:22,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:23,105][root][INFO] - Training Epoch: 1/2, step 6086/7134 completed (loss: 0.042753107845783234, acc: 0.9887640476226807)
[2024-12-17 04:28:23,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:23,552][root][INFO] - Training Epoch: 1/2, step 6087/7134 completed (loss: 0.06307339668273926, acc: 0.9798741936683655)
[2024-12-17 04:28:23,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:23,965][root][INFO] - Training Epoch: 1/2, step 6088/7134 completed (loss: 0.03727011755108833, acc: 0.989276111125946)
[2024-12-17 04:28:24,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:24,430][root][INFO] - Training Epoch: 1/2, step 6089/7134 completed (loss: 0.05047564208507538, acc: 0.9862068891525269)
[2024-12-17 04:28:24,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:24,865][root][INFO] - Training Epoch: 1/2, step 6090/7134 completed (loss: 0.048618074506521225, acc: 0.9835391044616699)
[2024-12-17 04:28:24,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:25,278][root][INFO] - Training Epoch: 1/2, step 6091/7134 completed (loss: 0.062404755502939224, acc: 0.977707028388977)
[2024-12-17 04:28:25,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:25,680][root][INFO] - Training Epoch: 1/2, step 6092/7134 completed (loss: 0.06311827152967453, acc: 0.9888888597488403)
[2024-12-17 04:28:25,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:26,102][root][INFO] - Training Epoch: 1/2, step 6093/7134 completed (loss: 0.0806850865483284, acc: 0.9833024144172668)
[2024-12-17 04:28:26,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:26,509][root][INFO] - Training Epoch: 1/2, step 6094/7134 completed (loss: 0.03583863377571106, acc: 0.9901960492134094)
[2024-12-17 04:28:26,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:26,904][root][INFO] - Training Epoch: 1/2, step 6095/7134 completed (loss: 0.048339102417230606, acc: 0.9870689511299133)
[2024-12-17 04:28:27,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:27,370][root][INFO] - Training Epoch: 1/2, step 6096/7134 completed (loss: 0.049215707927942276, acc: 0.9832935333251953)
[2024-12-17 04:28:27,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:27,807][root][INFO] - Training Epoch: 1/2, step 6097/7134 completed (loss: 0.06731124222278595, acc: 0.9833794832229614)
[2024-12-17 04:28:27,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:28,245][root][INFO] - Training Epoch: 1/2, step 6098/7134 completed (loss: 0.0738007128238678, acc: 0.9871299862861633)
[2024-12-17 04:28:28,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:28,680][root][INFO] - Training Epoch: 1/2, step 6099/7134 completed (loss: 0.08295541256666183, acc: 0.9785932898521423)
[2024-12-17 04:28:28,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:29,048][root][INFO] - Training Epoch: 1/2, step 6100/7134 completed (loss: 0.11013083159923553, acc: 0.9756097793579102)
[2024-12-17 04:28:29,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:29,457][root][INFO] - Training Epoch: 1/2, step 6101/7134 completed (loss: 0.05470416694879532, acc: 0.97444087266922)
[2024-12-17 04:28:29,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:29,880][root][INFO] - Training Epoch: 1/2, step 6102/7134 completed (loss: 0.06658661365509033, acc: 0.9823943376541138)
[2024-12-17 04:28:30,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:30,325][root][INFO] - Training Epoch: 1/2, step 6103/7134 completed (loss: 0.05452462658286095, acc: 0.9777777791023254)
[2024-12-17 04:28:30,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:30,733][root][INFO] - Training Epoch: 1/2, step 6104/7134 completed (loss: 0.09684471786022186, acc: 0.9733333587646484)
[2024-12-17 04:28:30,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:31,170][root][INFO] - Training Epoch: 1/2, step 6105/7134 completed (loss: 0.08621279895305634, acc: 0.9791666865348816)
[2024-12-17 04:28:31,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:31,560][root][INFO] - Training Epoch: 1/2, step 6106/7134 completed (loss: 0.07795380055904388, acc: 0.980322003364563)
[2024-12-17 04:28:31,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:31,978][root][INFO] - Training Epoch: 1/2, step 6107/7134 completed (loss: 0.10335157066583633, acc: 0.9768907427787781)
[2024-12-17 04:28:32,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:32,380][root][INFO] - Training Epoch: 1/2, step 6108/7134 completed (loss: 0.0624794103205204, acc: 0.9799635410308838)
[2024-12-17 04:28:32,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:32,800][root][INFO] - Training Epoch: 1/2, step 6109/7134 completed (loss: 0.04811868071556091, acc: 0.9745762944221497)
[2024-12-17 04:28:32,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:33,223][root][INFO] - Training Epoch: 1/2, step 6110/7134 completed (loss: 0.12211092561483383, acc: 0.9636752009391785)
[2024-12-17 04:28:33,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:33,630][root][INFO] - Training Epoch: 1/2, step 6111/7134 completed (loss: 0.1192389503121376, acc: 0.9651474356651306)
[2024-12-17 04:28:33,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:34,074][root][INFO] - Training Epoch: 1/2, step 6112/7134 completed (loss: 0.06602134555578232, acc: 0.9765886068344116)
[2024-12-17 04:28:34,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:34,511][root][INFO] - Training Epoch: 1/2, step 6113/7134 completed (loss: 0.035075582563877106, acc: 0.987860381603241)
[2024-12-17 04:28:34,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:34,936][root][INFO] - Training Epoch: 1/2, step 6114/7134 completed (loss: 0.10173266381025314, acc: 0.9719008207321167)
[2024-12-17 04:28:35,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:35,362][root][INFO] - Training Epoch: 1/2, step 6115/7134 completed (loss: 0.0779808834195137, acc: 0.984674334526062)
[2024-12-17 04:28:35,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:35,739][root][INFO] - Training Epoch: 1/2, step 6116/7134 completed (loss: 0.1009829118847847, acc: 0.97826087474823)
[2024-12-17 04:28:35,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:36,174][root][INFO] - Training Epoch: 1/2, step 6117/7134 completed (loss: 0.10035478323698044, acc: 0.9808743000030518)
[2024-12-17 04:28:36,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:36,649][root][INFO] - Training Epoch: 1/2, step 6118/7134 completed (loss: 0.10775553435087204, acc: 0.9613970518112183)
[2024-12-17 04:28:36,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:37,089][root][INFO] - Training Epoch: 1/2, step 6119/7134 completed (loss: 0.05415941774845123, acc: 0.9807923436164856)
[2024-12-17 04:28:37,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:37,518][root][INFO] - Training Epoch: 1/2, step 6120/7134 completed (loss: 0.06298109143972397, acc: 0.9874776601791382)
[2024-12-17 04:28:37,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:37,966][root][INFO] - Training Epoch: 1/2, step 6121/7134 completed (loss: 0.06875094026327133, acc: 0.980215847492218)
[2024-12-17 04:28:38,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:38,403][root][INFO] - Training Epoch: 1/2, step 6122/7134 completed (loss: 0.03292395547032356, acc: 0.99245285987854)
[2024-12-17 04:28:38,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:38,829][root][INFO] - Training Epoch: 1/2, step 6123/7134 completed (loss: 0.1265697181224823, acc: 0.9688149690628052)
[2024-12-17 04:28:38,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:39,231][root][INFO] - Training Epoch: 1/2, step 6124/7134 completed (loss: 0.036376215517520905, acc: 0.9923076629638672)
[2024-12-17 04:28:39,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:39,679][root][INFO] - Training Epoch: 1/2, step 6125/7134 completed (loss: 0.1798613965511322, acc: 0.966265082359314)
[2024-12-17 04:28:39,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:40,095][root][INFO] - Training Epoch: 1/2, step 6126/7134 completed (loss: 0.08835136890411377, acc: 0.9764890074729919)
[2024-12-17 04:28:40,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:40,491][root][INFO] - Training Epoch: 1/2, step 6127/7134 completed (loss: 0.042637623846530914, acc: 0.9952380657196045)
[2024-12-17 04:28:40,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:40,918][root][INFO] - Training Epoch: 1/2, step 6128/7134 completed (loss: 0.06146513298153877, acc: 0.9838056564331055)
[2024-12-17 04:28:41,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:41,353][root][INFO] - Training Epoch: 1/2, step 6129/7134 completed (loss: 0.09937195479869843, acc: 0.9746835231781006)
[2024-12-17 04:28:41,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:41,766][root][INFO] - Training Epoch: 1/2, step 6130/7134 completed (loss: 0.04345272108912468, acc: 0.9928315281867981)
[2024-12-17 04:28:41,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:42,214][root][INFO] - Training Epoch: 1/2, step 6131/7134 completed (loss: 0.05983731895685196, acc: 0.9844311475753784)
[2024-12-17 04:28:42,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:42,617][root][INFO] - Training Epoch: 1/2, step 6132/7134 completed (loss: 0.08417613804340363, acc: 0.9765625)
[2024-12-17 04:28:42,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:43,073][root][INFO] - Training Epoch: 1/2, step 6133/7134 completed (loss: 0.06541117280721664, acc: 0.981796145439148)
[2024-12-17 04:28:43,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:43,495][root][INFO] - Training Epoch: 1/2, step 6134/7134 completed (loss: 0.11193732917308807, acc: 0.9693721532821655)
[2024-12-17 04:28:43,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:43,905][root][INFO] - Training Epoch: 1/2, step 6135/7134 completed (loss: 0.022879865020513535, acc: 0.996515691280365)
[2024-12-17 04:28:44,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:44,327][root][INFO] - Training Epoch: 1/2, step 6136/7134 completed (loss: 0.08345197141170502, acc: 0.9845938086509705)
[2024-12-17 04:28:44,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:44,727][root][INFO] - Training Epoch: 1/2, step 6137/7134 completed (loss: 0.08869205415248871, acc: 0.9797191619873047)
[2024-12-17 04:28:44,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:45,130][root][INFO] - Training Epoch: 1/2, step 6138/7134 completed (loss: 0.0713348537683487, acc: 0.9831029176712036)
[2024-12-17 04:28:45,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:45,527][root][INFO] - Training Epoch: 1/2, step 6139/7134 completed (loss: 0.09243056923151016, acc: 0.9740740656852722)
[2024-12-17 04:28:45,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:45,987][root][INFO] - Training Epoch: 1/2, step 6140/7134 completed (loss: 0.0567815862596035, acc: 0.9876325130462646)
[2024-12-17 04:28:46,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:46,350][root][INFO] - Training Epoch: 1/2, step 6141/7134 completed (loss: 0.11241889744997025, acc: 0.9785932898521423)
[2024-12-17 04:28:46,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:46,773][root][INFO] - Training Epoch: 1/2, step 6142/7134 completed (loss: 0.052916139364242554, acc: 0.9841726422309875)
[2024-12-17 04:28:46,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:47,204][root][INFO] - Training Epoch: 1/2, step 6143/7134 completed (loss: 0.052813176065683365, acc: 0.9878378510475159)
[2024-12-17 04:28:47,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:47,617][root][INFO] - Training Epoch: 1/2, step 6144/7134 completed (loss: 0.030944757163524628, acc: 0.9915966391563416)
[2024-12-17 04:28:47,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:48,061][root][INFO] - Training Epoch: 1/2, step 6145/7134 completed (loss: 0.08779322355985641, acc: 0.9828269481658936)
[2024-12-17 04:28:48,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:48,475][root][INFO] - Training Epoch: 1/2, step 6146/7134 completed (loss: 0.08156127482652664, acc: 0.9788838624954224)
[2024-12-17 04:28:48,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:48,892][root][INFO] - Training Epoch: 1/2, step 6147/7134 completed (loss: 0.07627306878566742, acc: 0.9801587462425232)
[2024-12-17 04:28:48,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:49,336][root][INFO] - Training Epoch: 1/2, step 6148/7134 completed (loss: 0.055438872426748276, acc: 0.981574535369873)
[2024-12-17 04:28:49,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:49,754][root][INFO] - Training Epoch: 1/2, step 6149/7134 completed (loss: 0.08475814759731293, acc: 0.9807074069976807)
[2024-12-17 04:28:49,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:50,175][root][INFO] - Training Epoch: 1/2, step 6150/7134 completed (loss: 0.06634975224733353, acc: 0.980701744556427)
[2024-12-17 04:28:50,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:50,567][root][INFO] - Training Epoch: 1/2, step 6151/7134 completed (loss: 0.03632212430238724, acc: 0.9890109896659851)
[2024-12-17 04:28:50,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:50,999][root][INFO] - Training Epoch: 1/2, step 6152/7134 completed (loss: 0.05919133871793747, acc: 0.9819004535675049)
[2024-12-17 04:28:51,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:51,445][root][INFO] - Training Epoch: 1/2, step 6153/7134 completed (loss: 0.0356406643986702, acc: 0.9913169145584106)
[2024-12-17 04:28:51,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:51,891][root][INFO] - Training Epoch: 1/2, step 6154/7134 completed (loss: 0.05269882082939148, acc: 0.9832636117935181)
[2024-12-17 04:28:51,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:52,322][root][INFO] - Training Epoch: 1/2, step 6155/7134 completed (loss: 0.06393580138683319, acc: 0.9836795330047607)
[2024-12-17 04:28:52,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:52,736][root][INFO] - Training Epoch: 1/2, step 6156/7134 completed (loss: 0.030841127038002014, acc: 0.9904912710189819)
[2024-12-17 04:28:52,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:53,169][root][INFO] - Training Epoch: 1/2, step 6157/7134 completed (loss: 0.03894037380814552, acc: 0.9874607920646667)
[2024-12-17 04:28:53,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:53,599][root][INFO] - Training Epoch: 1/2, step 6158/7134 completed (loss: 0.08582355827093124, acc: 0.9819168448448181)
[2024-12-17 04:28:53,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:54,042][root][INFO] - Training Epoch: 1/2, step 6159/7134 completed (loss: 0.10109366476535797, acc: 0.9734619855880737)
[2024-12-17 04:28:54,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:54,472][root][INFO] - Training Epoch: 1/2, step 6160/7134 completed (loss: 0.11316357553005219, acc: 0.9742424488067627)
[2024-12-17 04:28:54,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:54,923][root][INFO] - Training Epoch: 1/2, step 6161/7134 completed (loss: 0.07576900720596313, acc: 0.9806678295135498)
[2024-12-17 04:28:55,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:55,381][root][INFO] - Training Epoch: 1/2, step 6162/7134 completed (loss: 0.07646532356739044, acc: 0.978723406791687)
[2024-12-17 04:28:55,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:55,796][root][INFO] - Training Epoch: 1/2, step 6163/7134 completed (loss: 0.11477434635162354, acc: 0.9732142686843872)
[2024-12-17 04:28:55,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:56,236][root][INFO] - Training Epoch: 1/2, step 6164/7134 completed (loss: 0.11451338976621628, acc: 0.9660056829452515)
[2024-12-17 04:28:56,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:56,632][root][INFO] - Training Epoch: 1/2, step 6165/7134 completed (loss: 0.06477171182632446, acc: 0.9852398633956909)
[2024-12-17 04:28:56,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:57,050][root][INFO] - Training Epoch: 1/2, step 6166/7134 completed (loss: 0.05641518905758858, acc: 0.9859402179718018)
[2024-12-17 04:28:57,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:57,466][root][INFO] - Training Epoch: 1/2, step 6167/7134 completed (loss: 0.05265883728861809, acc: 0.9900990128517151)
[2024-12-17 04:28:57,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:57,927][root][INFO] - Training Epoch: 1/2, step 6168/7134 completed (loss: 0.06779954582452774, acc: 0.9832689762115479)
[2024-12-17 04:28:58,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:58,355][root][INFO] - Training Epoch: 1/2, step 6169/7134 completed (loss: 0.06274347007274628, acc: 0.9839650392532349)
[2024-12-17 04:28:58,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:58,746][root][INFO] - Training Epoch: 1/2, step 6170/7134 completed (loss: 0.03316598758101463, acc: 0.9886578321456909)
[2024-12-17 04:28:58,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:59,170][root][INFO] - Training Epoch: 1/2, step 6171/7134 completed (loss: 0.02540900744497776, acc: 0.9908015727996826)
[2024-12-17 04:28:59,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:59,563][root][INFO] - Training Epoch: 1/2, step 6172/7134 completed (loss: 0.04007315635681152, acc: 0.9879759550094604)
[2024-12-17 04:28:59,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:28:59,958][root][INFO] - Training Epoch: 1/2, step 6173/7134 completed (loss: 0.022254178300499916, acc: 0.9911634922027588)
[2024-12-17 04:29:00,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:00,372][root][INFO] - Training Epoch: 1/2, step 6174/7134 completed (loss: 0.017872905358672142, acc: 0.9912023544311523)
[2024-12-17 04:29:00,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:00,806][root][INFO] - Training Epoch: 1/2, step 6175/7134 completed (loss: 0.047990791499614716, acc: 0.9822485446929932)
[2024-12-17 04:29:00,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:01,208][root][INFO] - Training Epoch: 1/2, step 6176/7134 completed (loss: 0.048558201640844345, acc: 0.9811866879463196)
[2024-12-17 04:29:01,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:01,629][root][INFO] - Training Epoch: 1/2, step 6177/7134 completed (loss: 0.04613550007343292, acc: 0.9833759665489197)
[2024-12-17 04:29:01,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:02,032][root][INFO] - Training Epoch: 1/2, step 6178/7134 completed (loss: 0.025074737146496773, acc: 0.99262535572052)
[2024-12-17 04:29:02,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:02,448][root][INFO] - Training Epoch: 1/2, step 6179/7134 completed (loss: 0.06851673126220703, acc: 0.97826087474823)
[2024-12-17 04:29:02,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:02,825][root][INFO] - Training Epoch: 1/2, step 6180/7134 completed (loss: 0.19467948377132416, acc: 0.9490445852279663)
[2024-12-17 04:29:02,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:03,216][root][INFO] - Training Epoch: 1/2, step 6181/7134 completed (loss: 0.2825304865837097, acc: 0.9214876294136047)
[2024-12-17 04:29:03,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:03,644][root][INFO] - Training Epoch: 1/2, step 6182/7134 completed (loss: 0.06631460785865784, acc: 0.9795918464660645)
[2024-12-17 04:29:03,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:04,064][root][INFO] - Training Epoch: 1/2, step 6183/7134 completed (loss: 0.06993886083364487, acc: 0.9754977226257324)
[2024-12-17 04:29:04,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:04,478][root][INFO] - Training Epoch: 1/2, step 6184/7134 completed (loss: 0.14671383798122406, acc: 0.9657257795333862)
[2024-12-17 04:29:04,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:04,899][root][INFO] - Training Epoch: 1/2, step 6185/7134 completed (loss: 0.06364773958921432, acc: 0.9797794222831726)
[2024-12-17 04:29:04,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:05,307][root][INFO] - Training Epoch: 1/2, step 6186/7134 completed (loss: 0.05183137580752373, acc: 0.9807692170143127)
[2024-12-17 04:29:05,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:05,754][root][INFO] - Training Epoch: 1/2, step 6187/7134 completed (loss: 0.060361821204423904, acc: 0.9788359999656677)
[2024-12-17 04:29:05,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:06,185][root][INFO] - Training Epoch: 1/2, step 6188/7134 completed (loss: 0.08097874373197556, acc: 0.9788434505462646)
[2024-12-17 04:29:06,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:06,638][root][INFO] - Training Epoch: 1/2, step 6189/7134 completed (loss: 0.1516985446214676, acc: 0.9624819755554199)
[2024-12-17 04:29:06,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:07,052][root][INFO] - Training Epoch: 1/2, step 6190/7134 completed (loss: 0.13853782415390015, acc: 0.9568106532096863)
[2024-12-17 04:29:07,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:07,506][root][INFO] - Training Epoch: 1/2, step 6191/7134 completed (loss: 0.12154825776815414, acc: 0.9685314893722534)
[2024-12-17 04:29:07,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:07,969][root][INFO] - Training Epoch: 1/2, step 6192/7134 completed (loss: 0.05966600403189659, acc: 0.9828510284423828)
[2024-12-17 04:29:08,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:08,405][root][INFO] - Training Epoch: 1/2, step 6193/7134 completed (loss: 0.08592614531517029, acc: 0.9738406538963318)
[2024-12-17 04:29:08,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:08,838][root][INFO] - Training Epoch: 1/2, step 6194/7134 completed (loss: 0.09757199883460999, acc: 0.966926097869873)
[2024-12-17 04:29:08,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:09,227][root][INFO] - Training Epoch: 1/2, step 6195/7134 completed (loss: 0.12260838598012924, acc: 0.9569377899169922)
[2024-12-17 04:29:09,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:09,684][root][INFO] - Training Epoch: 1/2, step 6196/7134 completed (loss: 0.0838824212551117, acc: 0.9724518060684204)
[2024-12-17 04:29:09,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:10,123][root][INFO] - Training Epoch: 1/2, step 6197/7134 completed (loss: 0.11571811139583588, acc: 0.9682758450508118)
[2024-12-17 04:29:10,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:10,538][root][INFO] - Training Epoch: 1/2, step 6198/7134 completed (loss: 0.05205231159925461, acc: 0.9875518679618835)
[2024-12-17 04:29:10,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:11,023][root][INFO] - Training Epoch: 1/2, step 6199/7134 completed (loss: 0.06879629194736481, acc: 0.9814385175704956)
[2024-12-17 04:29:11,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:11,463][root][INFO] - Training Epoch: 1/2, step 6200/7134 completed (loss: 0.057169750332832336, acc: 0.9817073345184326)
[2024-12-17 04:29:11,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:11,912][root][INFO] - Training Epoch: 1/2, step 6201/7134 completed (loss: 0.044378798454999924, acc: 0.9877368807792664)
[2024-12-17 04:29:11,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:12,309][root][INFO] - Training Epoch: 1/2, step 6202/7134 completed (loss: 0.061928559094667435, acc: 0.9804772138595581)
[2024-12-17 04:29:12,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:12,746][root][INFO] - Training Epoch: 1/2, step 6203/7134 completed (loss: 0.03972277045249939, acc: 0.9872449040412903)
[2024-12-17 04:29:12,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:13,166][root][INFO] - Training Epoch: 1/2, step 6204/7134 completed (loss: 0.06820084154605865, acc: 0.984282910823822)
[2024-12-17 04:29:13,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:13,576][root][INFO] - Training Epoch: 1/2, step 6205/7134 completed (loss: 0.06033146753907204, acc: 0.9761092066764832)
[2024-12-17 04:29:13,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:13,970][root][INFO] - Training Epoch: 1/2, step 6206/7134 completed (loss: 0.04622119292616844, acc: 0.9855282306671143)
[2024-12-17 04:29:14,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:14,419][root][INFO] - Training Epoch: 1/2, step 6207/7134 completed (loss: 0.1728644222021103, acc: 0.951935887336731)
[2024-12-17 04:29:14,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:14,846][root][INFO] - Training Epoch: 1/2, step 6208/7134 completed (loss: 0.061325717717409134, acc: 0.9791666865348816)
[2024-12-17 04:29:14,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:15,291][root][INFO] - Training Epoch: 1/2, step 6209/7134 completed (loss: 0.08377355337142944, acc: 0.9780077338218689)
[2024-12-17 04:29:15,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:15,755][root][INFO] - Training Epoch: 1/2, step 6210/7134 completed (loss: 0.048734139651060104, acc: 0.9868131875991821)
[2024-12-17 04:29:15,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:16,197][root][INFO] - Training Epoch: 1/2, step 6211/7134 completed (loss: 0.07765372842550278, acc: 0.9769959449768066)
[2024-12-17 04:29:16,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:16,609][root][INFO] - Training Epoch: 1/2, step 6212/7134 completed (loss: 0.05671076849102974, acc: 0.9789473414421082)
[2024-12-17 04:29:16,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:17,000][root][INFO] - Training Epoch: 1/2, step 6213/7134 completed (loss: 0.03721316158771515, acc: 0.9916840195655823)
[2024-12-17 04:29:17,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:17,433][root][INFO] - Training Epoch: 1/2, step 6214/7134 completed (loss: 0.04641961678862572, acc: 0.9871630072593689)
[2024-12-17 04:29:17,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:17,888][root][INFO] - Training Epoch: 1/2, step 6215/7134 completed (loss: 0.060947202146053314, acc: 0.97926265001297)
[2024-12-17 04:29:18,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:18,249][root][INFO] - Training Epoch: 1/2, step 6216/7134 completed (loss: 0.06381317973136902, acc: 0.9851064085960388)
[2024-12-17 04:29:18,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:18,684][root][INFO] - Training Epoch: 1/2, step 6217/7134 completed (loss: 0.03747837617993355, acc: 0.9879194498062134)
[2024-12-17 04:29:18,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:19,139][root][INFO] - Training Epoch: 1/2, step 6218/7134 completed (loss: 0.0543898269534111, acc: 0.9832317233085632)
[2024-12-17 04:29:19,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:19,585][root][INFO] - Training Epoch: 1/2, step 6219/7134 completed (loss: 0.04954585060477257, acc: 0.9845288395881653)
[2024-12-17 04:29:19,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:19,975][root][INFO] - Training Epoch: 1/2, step 6220/7134 completed (loss: 0.06162393093109131, acc: 0.973809540271759)
[2024-12-17 04:29:20,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:20,398][root][INFO] - Training Epoch: 1/2, step 6221/7134 completed (loss: 0.015353708527982235, acc: 0.9982455968856812)
[2024-12-17 04:29:20,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:20,787][root][INFO] - Training Epoch: 1/2, step 6222/7134 completed (loss: 0.06302086263895035, acc: 0.9863387942314148)
[2024-12-17 04:29:20,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:21,218][root][INFO] - Training Epoch: 1/2, step 6223/7134 completed (loss: 0.055335067212581635, acc: 0.9829059839248657)
[2024-12-17 04:29:21,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:21,653][root][INFO] - Training Epoch: 1/2, step 6224/7134 completed (loss: 0.024844150990247726, acc: 0.9956458806991577)
[2024-12-17 04:29:21,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:22,098][root][INFO] - Training Epoch: 1/2, step 6225/7134 completed (loss: 0.03485431149601936, acc: 0.9897959232330322)
[2024-12-17 04:29:22,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:22,509][root][INFO] - Training Epoch: 1/2, step 6226/7134 completed (loss: 0.07625293731689453, acc: 0.9764088988304138)
[2024-12-17 04:29:22,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:22,956][root][INFO] - Training Epoch: 1/2, step 6227/7134 completed (loss: 0.029650969430804253, acc: 0.9892904758453369)
[2024-12-17 04:29:23,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:23,396][root][INFO] - Training Epoch: 1/2, step 6228/7134 completed (loss: 0.03708373010158539, acc: 0.9864864945411682)
[2024-12-17 04:29:23,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:23,841][root][INFO] - Training Epoch: 1/2, step 6229/7134 completed (loss: 0.07304584234952927, acc: 0.9814385175704956)
[2024-12-17 04:29:23,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:24,284][root][INFO] - Training Epoch: 1/2, step 6230/7134 completed (loss: 0.058185186237096786, acc: 0.9887780547142029)
[2024-12-17 04:29:24,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:24,676][root][INFO] - Training Epoch: 1/2, step 6231/7134 completed (loss: 0.025888092815876007, acc: 0.9935400485992432)
[2024-12-17 04:29:24,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:25,128][root][INFO] - Training Epoch: 1/2, step 6232/7134 completed (loss: 0.03933671861886978, acc: 0.9873737096786499)
[2024-12-17 04:29:25,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:25,565][root][INFO] - Training Epoch: 1/2, step 6233/7134 completed (loss: 0.034497059881687164, acc: 0.9879356622695923)
[2024-12-17 04:29:25,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:26,004][root][INFO] - Training Epoch: 1/2, step 6234/7134 completed (loss: 0.0776996985077858, acc: 0.9839572310447693)
[2024-12-17 04:29:26,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:26,416][root][INFO] - Training Epoch: 1/2, step 6235/7134 completed (loss: 0.039003439247608185, acc: 0.9947848916053772)
[2024-12-17 04:29:26,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:26,851][root][INFO] - Training Epoch: 1/2, step 6236/7134 completed (loss: 0.0500909760594368, acc: 0.9849931597709656)
[2024-12-17 04:29:26,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:27,277][root][INFO] - Training Epoch: 1/2, step 6237/7134 completed (loss: 0.046392008662223816, acc: 0.9877675771713257)
[2024-12-17 04:29:27,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:27,684][root][INFO] - Training Epoch: 1/2, step 6238/7134 completed (loss: 0.018648812547326088, acc: 0.9967690110206604)
[2024-12-17 04:29:27,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:28,141][root][INFO] - Training Epoch: 1/2, step 6239/7134 completed (loss: 0.04154729098081589, acc: 0.9868578314781189)
[2024-12-17 04:29:28,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:28,582][root][INFO] - Training Epoch: 1/2, step 6240/7134 completed (loss: 0.010247565805912018, acc: 0.9971791505813599)
[2024-12-17 04:29:28,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:29,012][root][INFO] - Training Epoch: 1/2, step 6241/7134 completed (loss: 0.016452891752123833, acc: 0.9936708807945251)
[2024-12-17 04:29:29,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:29,450][root][INFO] - Training Epoch: 1/2, step 6242/7134 completed (loss: 0.02169637568295002, acc: 0.9948979616165161)
[2024-12-17 04:29:29,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:29,869][root][INFO] - Training Epoch: 1/2, step 6243/7134 completed (loss: 0.026609357446432114, acc: 0.9888535141944885)
[2024-12-17 04:29:29,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:30,282][root][INFO] - Training Epoch: 1/2, step 6244/7134 completed (loss: 0.026207175105810165, acc: 0.9890260696411133)
[2024-12-17 04:29:30,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:30,694][root][INFO] - Training Epoch: 1/2, step 6245/7134 completed (loss: 0.031973838806152344, acc: 0.99589604139328)
[2024-12-17 04:29:30,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:31,133][root][INFO] - Training Epoch: 1/2, step 6246/7134 completed (loss: 0.037714604288339615, acc: 0.9855072498321533)
[2024-12-17 04:29:31,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:31,579][root][INFO] - Training Epoch: 1/2, step 6247/7134 completed (loss: 0.044005535542964935, acc: 0.9819276928901672)
[2024-12-17 04:29:31,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:32,011][root][INFO] - Training Epoch: 1/2, step 6248/7134 completed (loss: 0.06938047707080841, acc: 0.9828660488128662)
[2024-12-17 04:29:32,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:32,476][root][INFO] - Training Epoch: 1/2, step 6249/7134 completed (loss: 0.013060100376605988, acc: 0.9952830076217651)
[2024-12-17 04:29:32,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:32,895][root][INFO] - Training Epoch: 1/2, step 6250/7134 completed (loss: 0.007123730611056089, acc: 0.9965986609458923)
[2024-12-17 04:29:33,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:33,319][root][INFO] - Training Epoch: 1/2, step 6251/7134 completed (loss: 0.0367903895676136, acc: 0.9892638325691223)
[2024-12-17 04:29:33,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:33,729][root][INFO] - Training Epoch: 1/2, step 6252/7134 completed (loss: 0.03323175385594368, acc: 0.9935275316238403)
[2024-12-17 04:29:33,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:34,150][root][INFO] - Training Epoch: 1/2, step 6253/7134 completed (loss: 0.0319378599524498, acc: 0.9913793206214905)
[2024-12-17 04:29:34,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:34,551][root][INFO] - Training Epoch: 1/2, step 6254/7134 completed (loss: 0.036583393812179565, acc: 0.9930796027183533)
[2024-12-17 04:29:34,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:34,979][root][INFO] - Training Epoch: 1/2, step 6255/7134 completed (loss: 0.02806084416806698, acc: 0.9878048896789551)
[2024-12-17 04:29:35,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:35,402][root][INFO] - Training Epoch: 1/2, step 6256/7134 completed (loss: 0.014025156386196613, acc: 0.9957447052001953)
[2024-12-17 04:29:35,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:35,831][root][INFO] - Training Epoch: 1/2, step 6257/7134 completed (loss: 0.02348264306783676, acc: 0.9884892106056213)
[2024-12-17 04:29:35,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:36,222][root][INFO] - Training Epoch: 1/2, step 6258/7134 completed (loss: 0.019519055262207985, acc: 0.9936000108718872)
[2024-12-17 04:29:36,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:36,663][root][INFO] - Training Epoch: 1/2, step 6259/7134 completed (loss: 0.016319474205374718, acc: 0.9924924969673157)
[2024-12-17 04:29:36,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:37,076][root][INFO] - Training Epoch: 1/2, step 6260/7134 completed (loss: 0.019748849794268608, acc: 0.994966447353363)
[2024-12-17 04:29:37,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:37,516][root][INFO] - Training Epoch: 1/2, step 6261/7134 completed (loss: 0.029384400695562363, acc: 0.9923780560493469)
[2024-12-17 04:29:37,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:37,922][root][INFO] - Training Epoch: 1/2, step 6262/7134 completed (loss: 0.011088014580309391, acc: 0.9971305727958679)
[2024-12-17 04:29:38,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:38,319][root][INFO] - Training Epoch: 1/2, step 6263/7134 completed (loss: 0.014656422659754753, acc: 0.9970717430114746)
[2024-12-17 04:29:38,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:38,729][root][INFO] - Training Epoch: 1/2, step 6264/7134 completed (loss: 0.011816872283816338, acc: 0.9983579516410828)
[2024-12-17 04:29:38,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:39,158][root][INFO] - Training Epoch: 1/2, step 6265/7134 completed (loss: 0.017551416531205177, acc: 0.9970414042472839)
[2024-12-17 04:29:39,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:39,559][root][INFO] - Training Epoch: 1/2, step 6266/7134 completed (loss: 0.012827976606786251, acc: 0.9912587404251099)
[2024-12-17 04:29:39,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:39,963][root][INFO] - Training Epoch: 1/2, step 6267/7134 completed (loss: 0.015344266779720783, acc: 0.9983713626861572)
[2024-12-17 04:29:40,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:40,400][root][INFO] - Training Epoch: 1/2, step 6268/7134 completed (loss: 0.02374362014234066, acc: 0.9940476417541504)
[2024-12-17 04:29:40,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:40,811][root][INFO] - Training Epoch: 1/2, step 6269/7134 completed (loss: 0.017174767330288887, acc: 0.9978678226470947)
[2024-12-17 04:29:40,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:41,235][root][INFO] - Training Epoch: 1/2, step 6270/7134 completed (loss: 0.009468919597566128, acc: 0.9969325065612793)
[2024-12-17 04:29:41,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:41,660][root][INFO] - Training Epoch: 1/2, step 6271/7134 completed (loss: 0.02650458738207817, acc: 0.9933155179023743)
[2024-12-17 04:29:41,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:42,120][root][INFO] - Training Epoch: 1/2, step 6272/7134 completed (loss: 0.006006104871630669, acc: 0.997063159942627)
[2024-12-17 04:29:42,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:42,564][root][INFO] - Training Epoch: 1/2, step 6273/7134 completed (loss: 0.019555112347006798, acc: 0.99452805519104)
[2024-12-17 04:29:42,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:42,975][root][INFO] - Training Epoch: 1/2, step 6274/7134 completed (loss: 0.02089560776948929, acc: 0.995720386505127)
[2024-12-17 04:29:43,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:43,391][root][INFO] - Training Epoch: 1/2, step 6275/7134 completed (loss: 0.03661932423710823, acc: 0.9923896789550781)
[2024-12-17 04:29:43,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:43,759][root][INFO] - Training Epoch: 1/2, step 6276/7134 completed (loss: 0.042832620441913605, acc: 0.9894921183586121)
[2024-12-17 04:29:43,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:44,136][root][INFO] - Training Epoch: 1/2, step 6277/7134 completed (loss: 0.11716357618570328, acc: 0.9751130938529968)
[2024-12-17 04:29:44,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:44,550][root][INFO] - Training Epoch: 1/2, step 6278/7134 completed (loss: 0.013294389471411705, acc: 0.9950658082962036)
[2024-12-17 04:29:44,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:44,955][root][INFO] - Training Epoch: 1/2, step 6279/7134 completed (loss: 0.013986888341605663, acc: 0.9931507110595703)
[2024-12-17 04:29:45,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:45,360][root][INFO] - Training Epoch: 1/2, step 6280/7134 completed (loss: 0.031843628734350204, acc: 0.9912739992141724)
[2024-12-17 04:29:45,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:45,763][root][INFO] - Training Epoch: 1/2, step 6281/7134 completed (loss: 0.0444682240486145, acc: 0.9861351847648621)
[2024-12-17 04:29:45,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:46,180][root][INFO] - Training Epoch: 1/2, step 6282/7134 completed (loss: 0.01805567927658558, acc: 0.9952830076217651)
[2024-12-17 04:29:46,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:46,587][root][INFO] - Training Epoch: 1/2, step 6283/7134 completed (loss: 0.04012947902083397, acc: 0.9890829920768738)
[2024-12-17 04:29:46,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:46,984][root][INFO] - Training Epoch: 1/2, step 6284/7134 completed (loss: 0.04954449087381363, acc: 0.9846827387809753)
[2024-12-17 04:29:47,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:47,340][root][INFO] - Training Epoch: 1/2, step 6285/7134 completed (loss: 0.018443956971168518, acc: 0.9947506785392761)
[2024-12-17 04:29:47,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:47,734][root][INFO] - Training Epoch: 1/2, step 6286/7134 completed (loss: 0.021332964301109314, acc: 0.9917762875556946)
[2024-12-17 04:29:47,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:48,157][root][INFO] - Training Epoch: 1/2, step 6287/7134 completed (loss: 0.05148657411336899, acc: 0.9834558963775635)
[2024-12-17 04:29:48,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:48,562][root][INFO] - Training Epoch: 1/2, step 6288/7134 completed (loss: 0.010159137658774853, acc: 0.9967319965362549)
[2024-12-17 04:29:48,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:48,944][root][INFO] - Training Epoch: 1/2, step 6289/7134 completed (loss: 0.027212558314204216, acc: 0.9927927851676941)
[2024-12-17 04:29:49,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:49,359][root][INFO] - Training Epoch: 1/2, step 6290/7134 completed (loss: 0.05111319571733475, acc: 0.9872000217437744)
[2024-12-17 04:29:49,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:49,743][root][INFO] - Training Epoch: 1/2, step 6291/7134 completed (loss: 0.018400290980935097, acc: 0.9927272796630859)
[2024-12-17 04:29:49,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:50,147][root][INFO] - Training Epoch: 1/2, step 6292/7134 completed (loss: 0.042183421552181244, acc: 0.984054684638977)
[2024-12-17 04:29:50,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:50,572][root][INFO] - Training Epoch: 1/2, step 6293/7134 completed (loss: 0.051082685589790344, acc: 0.9846416115760803)
[2024-12-17 04:29:50,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:51,008][root][INFO] - Training Epoch: 1/2, step 6294/7134 completed (loss: 0.029675040394067764, acc: 0.9918962717056274)
[2024-12-17 04:29:51,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:51,416][root][INFO] - Training Epoch: 1/2, step 6295/7134 completed (loss: 0.033694081008434296, acc: 0.9891501069068909)
[2024-12-17 04:29:51,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:51,854][root][INFO] - Training Epoch: 1/2, step 6296/7134 completed (loss: 0.040665820240974426, acc: 0.9822834730148315)
[2024-12-17 04:29:51,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:52,266][root][INFO] - Training Epoch: 1/2, step 6297/7134 completed (loss: 0.028100457042455673, acc: 0.9868852496147156)
[2024-12-17 04:29:52,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:52,678][root][INFO] - Training Epoch: 1/2, step 6298/7134 completed (loss: 0.05296609178185463, acc: 0.9810996651649475)
[2024-12-17 04:29:52,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:53,097][root][INFO] - Training Epoch: 1/2, step 6299/7134 completed (loss: 0.08906371891498566, acc: 0.9792332053184509)
[2024-12-17 04:29:53,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:53,507][root][INFO] - Training Epoch: 1/2, step 6300/7134 completed (loss: 0.04837094619870186, acc: 0.9865996837615967)
[2024-12-17 04:29:53,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:53,953][root][INFO] - Training Epoch: 1/2, step 6301/7134 completed (loss: 0.02075606770813465, acc: 0.9954022765159607)
[2024-12-17 04:29:54,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:54,394][root][INFO] - Training Epoch: 1/2, step 6302/7134 completed (loss: 0.015797510743141174, acc: 0.9972375631332397)
[2024-12-17 04:29:54,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:54,871][root][INFO] - Training Epoch: 1/2, step 6303/7134 completed (loss: 0.017773371189832687, acc: 0.9968051314353943)
[2024-12-17 04:29:54,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:55,310][root][INFO] - Training Epoch: 1/2, step 6304/7134 completed (loss: 0.03562580421566963, acc: 0.9905405640602112)
[2024-12-17 04:29:55,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:55,737][root][INFO] - Training Epoch: 1/2, step 6305/7134 completed (loss: 0.019769348204135895, acc: 0.9967266917228699)
[2024-12-17 04:29:55,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:56,186][root][INFO] - Training Epoch: 1/2, step 6306/7134 completed (loss: 0.0576823428273201, acc: 0.9867947101593018)
[2024-12-17 04:29:56,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:56,622][root][INFO] - Training Epoch: 1/2, step 6307/7134 completed (loss: 0.07762688398361206, acc: 0.9858906269073486)
[2024-12-17 04:29:56,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:57,055][root][INFO] - Training Epoch: 1/2, step 6308/7134 completed (loss: 0.025676721706986427, acc: 0.9938575029373169)
[2024-12-17 04:29:57,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:57,469][root][INFO] - Training Epoch: 1/2, step 6309/7134 completed (loss: 0.017385208979249, acc: 0.9968000054359436)
[2024-12-17 04:29:57,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:57,884][root][INFO] - Training Epoch: 1/2, step 6310/7134 completed (loss: 0.13124126195907593, acc: 0.9780219793319702)
[2024-12-17 04:29:57,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:58,320][root][INFO] - Training Epoch: 1/2, step 6311/7134 completed (loss: 0.04687952250242233, acc: 0.9876998662948608)
[2024-12-17 04:29:58,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:58,740][root][INFO] - Training Epoch: 1/2, step 6312/7134 completed (loss: 0.04640044644474983, acc: 0.9889937043190002)
[2024-12-17 04:29:58,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:59,180][root][INFO] - Training Epoch: 1/2, step 6313/7134 completed (loss: 0.013822930864989758, acc: 0.9926380515098572)
[2024-12-17 04:29:59,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:29:59,631][root][INFO] - Training Epoch: 1/2, step 6314/7134 completed (loss: 0.02770240604877472, acc: 0.9924337863922119)
[2024-12-17 04:29:59,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:00,057][root][INFO] - Training Epoch: 1/2, step 6315/7134 completed (loss: 0.06799249351024628, acc: 0.9852458834648132)
[2024-12-17 04:30:00,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:00,488][root][INFO] - Training Epoch: 1/2, step 6316/7134 completed (loss: 0.035294052213430405, acc: 0.9886547923088074)
[2024-12-17 04:30:00,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:00,899][root][INFO] - Training Epoch: 1/2, step 6317/7134 completed (loss: 0.022745929658412933, acc: 0.9951534867286682)
[2024-12-17 04:30:01,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:01,315][root][INFO] - Training Epoch: 1/2, step 6318/7134 completed (loss: 0.020108791068196297, acc: 0.9920508861541748)
[2024-12-17 04:30:01,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:01,770][root][INFO] - Training Epoch: 1/2, step 6319/7134 completed (loss: 0.0161854550242424, acc: 0.9979423880577087)
[2024-12-17 04:30:01,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:02,238][root][INFO] - Training Epoch: 1/2, step 6320/7134 completed (loss: 0.03743310645222664, acc: 0.9857819676399231)
[2024-12-17 04:30:02,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:02,702][root][INFO] - Training Epoch: 1/2, step 6321/7134 completed (loss: 0.01630678027868271, acc: 0.9955357313156128)
[2024-12-17 04:30:02,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:03,154][root][INFO] - Training Epoch: 1/2, step 6322/7134 completed (loss: 0.0510745644569397, acc: 0.9898256063461304)
[2024-12-17 04:30:03,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:03,626][root][INFO] - Training Epoch: 1/2, step 6323/7134 completed (loss: 0.03543851897120476, acc: 0.9939939975738525)
[2024-12-17 04:30:03,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:04,069][root][INFO] - Training Epoch: 1/2, step 6324/7134 completed (loss: 0.021717099472880363, acc: 0.9933422207832336)
[2024-12-17 04:30:04,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:04,461][root][INFO] - Training Epoch: 1/2, step 6325/7134 completed (loss: 0.0473451130092144, acc: 0.9849056601524353)
[2024-12-17 04:30:04,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:04,874][root][INFO] - Training Epoch: 1/2, step 6326/7134 completed (loss: 0.0707995593547821, acc: 0.9775280952453613)
[2024-12-17 04:30:04,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:05,288][root][INFO] - Training Epoch: 1/2, step 6327/7134 completed (loss: 0.029666339978575706, acc: 0.9894459247589111)
[2024-12-17 04:30:05,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:05,706][root][INFO] - Training Epoch: 1/2, step 6328/7134 completed (loss: 0.03302479535341263, acc: 0.9920254945755005)
[2024-12-17 04:30:05,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:06,130][root][INFO] - Training Epoch: 1/2, step 6329/7134 completed (loss: 0.034729450941085815, acc: 0.9878787994384766)
[2024-12-17 04:30:06,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:06,534][root][INFO] - Training Epoch: 1/2, step 6330/7134 completed (loss: 0.04070920869708061, acc: 0.985111653804779)
[2024-12-17 04:30:06,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:06,943][root][INFO] - Training Epoch: 1/2, step 6331/7134 completed (loss: 0.026534123346209526, acc: 0.9911660552024841)
[2024-12-17 04:30:07,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:07,367][root][INFO] - Training Epoch: 1/2, step 6332/7134 completed (loss: 0.08587773889303207, acc: 0.9795538783073425)
[2024-12-17 04:30:07,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:07,783][root][INFO] - Training Epoch: 1/2, step 6333/7134 completed (loss: 0.05392788350582123, acc: 0.9809523820877075)
[2024-12-17 04:30:07,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:08,151][root][INFO] - Training Epoch: 1/2, step 6334/7134 completed (loss: 0.03768157958984375, acc: 0.9886363744735718)
[2024-12-17 04:30:08,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:08,567][root][INFO] - Training Epoch: 1/2, step 6335/7134 completed (loss: 0.024776970967650414, acc: 0.9932885766029358)
[2024-12-17 04:30:08,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:08,969][root][INFO] - Training Epoch: 1/2, step 6336/7134 completed (loss: 0.04314484819769859, acc: 0.9908257126808167)
[2024-12-17 04:30:09,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:09,389][root][INFO] - Training Epoch: 1/2, step 6337/7134 completed (loss: 0.013701962307095528, acc: 0.9981752038002014)
[2024-12-17 04:30:09,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:09,806][root][INFO] - Training Epoch: 1/2, step 6338/7134 completed (loss: 0.04243944585323334, acc: 0.9873617887496948)
[2024-12-17 04:30:09,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:10,214][root][INFO] - Training Epoch: 1/2, step 6339/7134 completed (loss: 0.040081270039081573, acc: 0.9861591458320618)
[2024-12-17 04:30:10,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:10,644][root][INFO] - Training Epoch: 1/2, step 6340/7134 completed (loss: 0.015688801184296608, acc: 0.992668628692627)
[2024-12-17 04:30:10,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:11,040][root][INFO] - Training Epoch: 1/2, step 6341/7134 completed (loss: 0.01726078800857067, acc: 0.9962049126625061)
[2024-12-17 04:30:11,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:11,498][root][INFO] - Training Epoch: 1/2, step 6342/7134 completed (loss: 0.027289943769574165, acc: 0.9892328381538391)
[2024-12-17 04:30:11,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:11,928][root][INFO] - Training Epoch: 1/2, step 6343/7134 completed (loss: 0.0387202687561512, acc: 0.9879518151283264)
[2024-12-17 04:30:12,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:12,378][root][INFO] - Training Epoch: 1/2, step 6344/7134 completed (loss: 0.027977366000413895, acc: 0.9876881241798401)
[2024-12-17 04:30:12,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:12,806][root][INFO] - Training Epoch: 1/2, step 6345/7134 completed (loss: 0.030431265011429787, acc: 0.9877049326896667)
[2024-12-17 04:30:12,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:13,215][root][INFO] - Training Epoch: 1/2, step 6346/7134 completed (loss: 0.06720505654811859, acc: 0.9814241528511047)
[2024-12-17 04:30:13,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:13,569][root][INFO] - Training Epoch: 1/2, step 6347/7134 completed (loss: 0.05005383491516113, acc: 0.9783549904823303)
[2024-12-17 04:30:13,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:13,983][root][INFO] - Training Epoch: 1/2, step 6348/7134 completed (loss: 0.11483434587717056, acc: 0.9756944179534912)
[2024-12-17 04:30:14,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:14,380][root][INFO] - Training Epoch: 1/2, step 6349/7134 completed (loss: 0.04511468484997749, acc: 0.9799635410308838)
[2024-12-17 04:30:14,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:14,802][root][INFO] - Training Epoch: 1/2, step 6350/7134 completed (loss: 0.06017922982573509, acc: 0.9782313108444214)
[2024-12-17 04:30:14,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:15,238][root][INFO] - Training Epoch: 1/2, step 6351/7134 completed (loss: 0.07402171194553375, acc: 0.9805970191955566)
[2024-12-17 04:30:15,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:15,663][root][INFO] - Training Epoch: 1/2, step 6352/7134 completed (loss: 0.13257326185703278, acc: 0.9643387794494629)
[2024-12-17 04:30:15,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:16,129][root][INFO] - Training Epoch: 1/2, step 6353/7134 completed (loss: 0.061330635100603104, acc: 0.9795022010803223)
[2024-12-17 04:30:16,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:16,584][root][INFO] - Training Epoch: 1/2, step 6354/7134 completed (loss: 0.02231498248875141, acc: 0.9958449006080627)
[2024-12-17 04:30:16,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:16,996][root][INFO] - Training Epoch: 1/2, step 6355/7134 completed (loss: 0.02583358623087406, acc: 0.9886731505393982)
[2024-12-17 04:30:17,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:17,400][root][INFO] - Training Epoch: 1/2, step 6356/7134 completed (loss: 0.037092793732881546, acc: 0.9925261735916138)
[2024-12-17 04:30:17,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:17,822][root][INFO] - Training Epoch: 1/2, step 6357/7134 completed (loss: 0.014673666097223759, acc: 0.9930555820465088)
[2024-12-17 04:30:17,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:18,282][root][INFO] - Training Epoch: 1/2, step 6358/7134 completed (loss: 0.026831839233636856, acc: 0.9915493130683899)
[2024-12-17 04:30:18,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:18,708][root][INFO] - Training Epoch: 1/2, step 6359/7134 completed (loss: 0.0765940472483635, acc: 0.9831932783126831)
[2024-12-17 04:30:18,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:19,150][root][INFO] - Training Epoch: 1/2, step 6360/7134 completed (loss: 0.029182761907577515, acc: 0.993630588054657)
[2024-12-17 04:30:19,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:19,573][root][INFO] - Training Epoch: 1/2, step 6361/7134 completed (loss: 0.07066366076469421, acc: 0.9817517995834351)
[2024-12-17 04:30:19,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:20,014][root][INFO] - Training Epoch: 1/2, step 6362/7134 completed (loss: 0.03208587318658829, acc: 0.9939024448394775)
[2024-12-17 04:30:20,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:20,452][root][INFO] - Training Epoch: 1/2, step 6363/7134 completed (loss: 0.051353201270103455, acc: 0.9897360801696777)
[2024-12-17 04:30:20,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:20,878][root][INFO] - Training Epoch: 1/2, step 6364/7134 completed (loss: 0.023633534088730812, acc: 0.9899857044219971)
[2024-12-17 04:30:20,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:21,301][root][INFO] - Training Epoch: 1/2, step 6365/7134 completed (loss: 0.040611136704683304, acc: 0.9898374080657959)
[2024-12-17 04:30:21,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:21,751][root][INFO] - Training Epoch: 1/2, step 6366/7134 completed (loss: 0.04588411748409271, acc: 0.9894319772720337)
[2024-12-17 04:30:21,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:22,158][root][INFO] - Training Epoch: 1/2, step 6367/7134 completed (loss: 0.06344970315694809, acc: 0.9810963869094849)
[2024-12-17 04:30:22,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:22,579][root][INFO] - Training Epoch: 1/2, step 6368/7134 completed (loss: 0.0799289345741272, acc: 0.9830508232116699)
[2024-12-17 04:30:22,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:23,022][root][INFO] - Training Epoch: 1/2, step 6369/7134 completed (loss: 0.06572925299406052, acc: 0.980289101600647)
[2024-12-17 04:30:23,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:23,472][root][INFO] - Training Epoch: 1/2, step 6370/7134 completed (loss: 0.14401230216026306, acc: 0.9630606770515442)
[2024-12-17 04:30:23,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:23,886][root][INFO] - Training Epoch: 1/2, step 6371/7134 completed (loss: 0.07615650445222855, acc: 0.9833794832229614)
[2024-12-17 04:30:23,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:24,279][root][INFO] - Training Epoch: 1/2, step 6372/7134 completed (loss: 0.17180636525154114, acc: 0.9596928954124451)
[2024-12-17 04:30:24,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:24,666][root][INFO] - Training Epoch: 1/2, step 6373/7134 completed (loss: 0.07229307293891907, acc: 0.9817850589752197)
[2024-12-17 04:30:24,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:25,091][root][INFO] - Training Epoch: 1/2, step 6374/7134 completed (loss: 0.03667380288243294, acc: 0.9896265268325806)
[2024-12-17 04:30:25,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:25,534][root][INFO] - Training Epoch: 1/2, step 6375/7134 completed (loss: 0.07601240277290344, acc: 0.9781771302223206)
[2024-12-17 04:30:25,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:25,928][root][INFO] - Training Epoch: 1/2, step 6376/7134 completed (loss: 0.03466002270579338, acc: 0.9889298677444458)
[2024-12-17 04:30:26,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:26,336][root][INFO] - Training Epoch: 1/2, step 6377/7134 completed (loss: 0.039516616612672806, acc: 0.9908424615859985)
[2024-12-17 04:30:26,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:26,797][root][INFO] - Training Epoch: 1/2, step 6378/7134 completed (loss: 0.06758958846330643, acc: 0.9785637855529785)
[2024-12-17 04:30:26,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:27,236][root][INFO] - Training Epoch: 1/2, step 6379/7134 completed (loss: 0.057496313005685806, acc: 0.9847715497016907)
[2024-12-17 04:30:27,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:27,703][root][INFO] - Training Epoch: 1/2, step 6380/7134 completed (loss: 0.0583169087767601, acc: 0.9895209670066833)
[2024-12-17 04:30:27,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:28,135][root][INFO] - Training Epoch: 1/2, step 6381/7134 completed (loss: 0.03654256463050842, acc: 0.989313006401062)
[2024-12-17 04:30:28,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:28,593][root][INFO] - Training Epoch: 1/2, step 6382/7134 completed (loss: 0.021038582548499107, acc: 0.9934297204017639)
[2024-12-17 04:30:28,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:29,040][root][INFO] - Training Epoch: 1/2, step 6383/7134 completed (loss: 0.06719239056110382, acc: 0.9905020594596863)
[2024-12-17 04:30:29,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:29,479][root][INFO] - Training Epoch: 1/2, step 6384/7134 completed (loss: 0.049276936799287796, acc: 0.9865471124649048)
[2024-12-17 04:30:29,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:29,905][root][INFO] - Training Epoch: 1/2, step 6385/7134 completed (loss: 0.08176812529563904, acc: 0.9892215728759766)
[2024-12-17 04:30:29,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:30,379][root][INFO] - Training Epoch: 1/2, step 6386/7134 completed (loss: 0.03753788396716118, acc: 0.9914529919624329)
[2024-12-17 04:30:30,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:30,822][root][INFO] - Training Epoch: 1/2, step 6387/7134 completed (loss: 0.06912315636873245, acc: 0.9822580814361572)
[2024-12-17 04:30:30,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:31,244][root][INFO] - Training Epoch: 1/2, step 6388/7134 completed (loss: 0.07346482574939728, acc: 0.9820359349250793)
[2024-12-17 04:30:31,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:31,708][root][INFO] - Training Epoch: 1/2, step 6389/7134 completed (loss: 0.07362552732229233, acc: 0.9841269850730896)
[2024-12-17 04:30:31,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:32,194][root][INFO] - Training Epoch: 1/2, step 6390/7134 completed (loss: 0.08171714097261429, acc: 0.9807692170143127)
[2024-12-17 04:30:32,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:32,626][root][INFO] - Training Epoch: 1/2, step 6391/7134 completed (loss: 0.08348578959703445, acc: 0.97567218542099)
[2024-12-17 04:30:32,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:33,081][root][INFO] - Training Epoch: 1/2, step 6392/7134 completed (loss: 0.06914687156677246, acc: 0.983589768409729)
[2024-12-17 04:30:33,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:33,550][root][INFO] - Training Epoch: 1/2, step 6393/7134 completed (loss: 0.04426756128668785, acc: 0.9874857664108276)
[2024-12-17 04:30:33,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:33,996][root][INFO] - Training Epoch: 1/2, step 6394/7134 completed (loss: 0.08469800651073456, acc: 0.9749652147293091)
[2024-12-17 04:30:34,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:34,460][root][INFO] - Training Epoch: 1/2, step 6395/7134 completed (loss: 0.0522678978741169, acc: 0.9876998662948608)
[2024-12-17 04:30:34,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:34,905][root][INFO] - Training Epoch: 1/2, step 6396/7134 completed (loss: 0.05163245648145676, acc: 0.9896789193153381)
[2024-12-17 04:30:35,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:35,370][root][INFO] - Training Epoch: 1/2, step 6397/7134 completed (loss: 0.03204130753874779, acc: 0.9900744557380676)
[2024-12-17 04:30:35,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:35,824][root][INFO] - Training Epoch: 1/2, step 6398/7134 completed (loss: 0.04963308945298195, acc: 0.9859353303909302)
[2024-12-17 04:30:35,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:36,278][root][INFO] - Training Epoch: 1/2, step 6399/7134 completed (loss: 0.07215377688407898, acc: 0.9837092757225037)
[2024-12-17 04:30:36,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:36,748][root][INFO] - Training Epoch: 1/2, step 6400/7134 completed (loss: 0.033043112605810165, acc: 0.9900285005569458)
[2024-12-17 04:30:36,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:37,214][root][INFO] - Training Epoch: 1/2, step 6401/7134 completed (loss: 0.04810158908367157, acc: 0.9826275706291199)
[2024-12-17 04:30:37,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:37,660][root][INFO] - Training Epoch: 1/2, step 6402/7134 completed (loss: 0.05825493857264519, acc: 0.9829738736152649)
[2024-12-17 04:30:37,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:38,075][root][INFO] - Training Epoch: 1/2, step 6403/7134 completed (loss: 0.03741798922419548, acc: 0.9923469424247742)
[2024-12-17 04:30:38,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:38,517][root][INFO] - Training Epoch: 1/2, step 6404/7134 completed (loss: 0.021168865263462067, acc: 0.9930459260940552)
[2024-12-17 04:30:38,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:39,035][root][INFO] - Training Epoch: 1/2, step 6405/7134 completed (loss: 0.027702288702130318, acc: 0.9924731254577637)
[2024-12-17 04:30:39,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:39,495][root][INFO] - Training Epoch: 1/2, step 6406/7134 completed (loss: 0.034002430737018585, acc: 0.9897377490997314)
[2024-12-17 04:30:39,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:39,955][root][INFO] - Training Epoch: 1/2, step 6407/7134 completed (loss: 0.027386769652366638, acc: 0.9908015727996826)
[2024-12-17 04:30:40,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:40,365][root][INFO] - Training Epoch: 1/2, step 6408/7134 completed (loss: 0.06630458682775497, acc: 0.9867060780525208)
[2024-12-17 04:30:40,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:40,785][root][INFO] - Training Epoch: 1/2, step 6409/7134 completed (loss: 0.0452556312084198, acc: 0.9947368502616882)
[2024-12-17 04:30:40,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:41,195][root][INFO] - Training Epoch: 1/2, step 6410/7134 completed (loss: 0.03301858529448509, acc: 0.9908088445663452)
[2024-12-17 04:30:41,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:41,591][root][INFO] - Training Epoch: 1/2, step 6411/7134 completed (loss: 0.04630192741751671, acc: 0.9899497628211975)
[2024-12-17 04:30:41,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:41,999][root][INFO] - Training Epoch: 1/2, step 6412/7134 completed (loss: 0.015339105390012264, acc: 0.9959999918937683)
[2024-12-17 04:30:42,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:42,443][root][INFO] - Training Epoch: 1/2, step 6413/7134 completed (loss: 0.04331798478960991, acc: 0.9880136847496033)
[2024-12-17 04:30:42,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:42,835][root][INFO] - Training Epoch: 1/2, step 6414/7134 completed (loss: 0.01595279388129711, acc: 0.995468258857727)
[2024-12-17 04:30:42,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:43,256][root][INFO] - Training Epoch: 1/2, step 6415/7134 completed (loss: 0.02292776107788086, acc: 0.9897304177284241)
[2024-12-17 04:30:43,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:43,676][root][INFO] - Training Epoch: 1/2, step 6416/7134 completed (loss: 0.057166632264852524, acc: 0.9810246825218201)
[2024-12-17 04:30:43,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:44,092][root][INFO] - Training Epoch: 1/2, step 6417/7134 completed (loss: 0.1178520992398262, acc: 0.9789103865623474)
[2024-12-17 04:30:44,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:44,529][root][INFO] - Training Epoch: 1/2, step 6418/7134 completed (loss: 0.11888167262077332, acc: 0.9705055952072144)
[2024-12-17 04:30:44,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:44,924][root][INFO] - Training Epoch: 1/2, step 6419/7134 completed (loss: 0.0746074914932251, acc: 0.9787928462028503)
[2024-12-17 04:30:45,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:45,356][root][INFO] - Training Epoch: 1/2, step 6420/7134 completed (loss: 0.047233134508132935, acc: 0.9870316982269287)
[2024-12-17 04:30:45,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:45,762][root][INFO] - Training Epoch: 1/2, step 6421/7134 completed (loss: 0.04801388084888458, acc: 0.9881129264831543)
[2024-12-17 04:30:45,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:46,192][root][INFO] - Training Epoch: 1/2, step 6422/7134 completed (loss: 0.052172061055898666, acc: 0.9835841059684753)
[2024-12-17 04:30:46,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:46,613][root][INFO] - Training Epoch: 1/2, step 6423/7134 completed (loss: 0.07201211154460907, acc: 0.9794721603393555)
[2024-12-17 04:30:46,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:47,060][root][INFO] - Training Epoch: 1/2, step 6424/7134 completed (loss: 0.06348263472318649, acc: 0.9836065769195557)
[2024-12-17 04:30:47,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:47,513][root][INFO] - Training Epoch: 1/2, step 6425/7134 completed (loss: 0.0495091937482357, acc: 0.9830508232116699)
[2024-12-17 04:30:47,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:47,971][root][INFO] - Training Epoch: 1/2, step 6426/7134 completed (loss: 0.03898478299379349, acc: 0.9881266355514526)
[2024-12-17 04:30:48,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:48,402][root][INFO] - Training Epoch: 1/2, step 6427/7134 completed (loss: 0.05380452051758766, acc: 0.9872159361839294)
[2024-12-17 04:30:48,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:48,849][root][INFO] - Training Epoch: 1/2, step 6428/7134 completed (loss: 0.030766984447836876, acc: 0.9888268113136292)
[2024-12-17 04:30:48,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:49,266][root][INFO] - Training Epoch: 1/2, step 6429/7134 completed (loss: 0.022963417693972588, acc: 0.9939393997192383)
[2024-12-17 04:30:49,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:49,717][root][INFO] - Training Epoch: 1/2, step 6430/7134 completed (loss: 0.046825915575027466, acc: 0.9856114983558655)
[2024-12-17 04:30:49,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:50,127][root][INFO] - Training Epoch: 1/2, step 6431/7134 completed (loss: 0.05791939049959183, acc: 0.9881578683853149)
[2024-12-17 04:30:50,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:50,530][root][INFO] - Training Epoch: 1/2, step 6432/7134 completed (loss: 0.23589423298835754, acc: 0.9494949579238892)
[2024-12-17 04:30:50,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:50,957][root][INFO] - Training Epoch: 1/2, step 6433/7134 completed (loss: 0.053493682295084, acc: 0.9822404384613037)
[2024-12-17 04:30:51,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:51,367][root][INFO] - Training Epoch: 1/2, step 6434/7134 completed (loss: 0.01598239876329899, acc: 0.9973368644714355)
[2024-12-17 04:30:51,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:51,837][root][INFO] - Training Epoch: 1/2, step 6435/7134 completed (loss: 0.04092607647180557, acc: 0.9896013736724854)
[2024-12-17 04:30:51,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:52,288][root][INFO] - Training Epoch: 1/2, step 6436/7134 completed (loss: 0.018464606255292892, acc: 0.9969087839126587)
[2024-12-17 04:30:52,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:52,724][root][INFO] - Training Epoch: 1/2, step 6437/7134 completed (loss: 0.04700641334056854, acc: 0.9933333396911621)
[2024-12-17 04:30:52,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:53,183][root][INFO] - Training Epoch: 1/2, step 6438/7134 completed (loss: 0.041591424494981766, acc: 0.9851668477058411)
[2024-12-17 04:30:53,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:53,604][root][INFO] - Training Epoch: 1/2, step 6439/7134 completed (loss: 0.05241331085562706, acc: 0.982677161693573)
[2024-12-17 04:30:53,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:54,072][root][INFO] - Training Epoch: 1/2, step 6440/7134 completed (loss: 0.04053584486246109, acc: 0.9844683408737183)
[2024-12-17 04:30:54,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:54,503][root][INFO] - Training Epoch: 1/2, step 6441/7134 completed (loss: 0.024833282455801964, acc: 0.9911373853683472)
[2024-12-17 04:30:54,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:54,984][root][INFO] - Training Epoch: 1/2, step 6442/7134 completed (loss: 0.032785020768642426, acc: 0.9954596757888794)
[2024-12-17 04:30:55,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:55,431][root][INFO] - Training Epoch: 1/2, step 6443/7134 completed (loss: 0.024642810225486755, acc: 0.9913366436958313)
[2024-12-17 04:30:55,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:55,890][root][INFO] - Training Epoch: 1/2, step 6444/7134 completed (loss: 0.0352536179125309, acc: 0.9902234673500061)
[2024-12-17 04:30:55,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:56,330][root][INFO] - Training Epoch: 1/2, step 6445/7134 completed (loss: 0.05685698240995407, acc: 0.9889025688171387)
[2024-12-17 04:30:56,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:56,781][root][INFO] - Training Epoch: 1/2, step 6446/7134 completed (loss: 0.03257272392511368, acc: 0.9940405488014221)
[2024-12-17 04:30:56,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:57,255][root][INFO] - Training Epoch: 1/2, step 6447/7134 completed (loss: 0.05555474013090134, acc: 0.9861910343170166)
[2024-12-17 04:30:57,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:57,691][root][INFO] - Training Epoch: 1/2, step 6448/7134 completed (loss: 0.10418597608804703, acc: 0.9719626307487488)
[2024-12-17 04:30:57,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:58,132][root][INFO] - Training Epoch: 1/2, step 6449/7134 completed (loss: 0.02775481715798378, acc: 0.9927536249160767)
[2024-12-17 04:30:58,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:58,589][root][INFO] - Training Epoch: 1/2, step 6450/7134 completed (loss: 0.02780533768236637, acc: 0.992559552192688)
[2024-12-17 04:30:58,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:59,128][root][INFO] - Training Epoch: 1/2, step 6451/7134 completed (loss: 0.05527867004275322, acc: 0.9853085279464722)
[2024-12-17 04:30:59,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:30:59,564][root][INFO] - Training Epoch: 1/2, step 6452/7134 completed (loss: 0.017612570896744728, acc: 0.9955406785011292)
[2024-12-17 04:30:59,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:00,000][root][INFO] - Training Epoch: 1/2, step 6453/7134 completed (loss: 0.03574686497449875, acc: 0.9892473220825195)
[2024-12-17 04:31:00,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:00,487][root][INFO] - Training Epoch: 1/2, step 6454/7134 completed (loss: 0.04921868070960045, acc: 0.9893993139266968)
[2024-12-17 04:31:00,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:00,913][root][INFO] - Training Epoch: 1/2, step 6455/7134 completed (loss: 0.021542074158787727, acc: 0.9932088255882263)
[2024-12-17 04:31:01,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:01,336][root][INFO] - Training Epoch: 1/2, step 6456/7134 completed (loss: 0.035828784108161926, acc: 0.9907975196838379)
[2024-12-17 04:31:01,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:01,780][root][INFO] - Training Epoch: 1/2, step 6457/7134 completed (loss: 0.02535085380077362, acc: 0.9955947399139404)
[2024-12-17 04:31:01,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:02,184][root][INFO] - Training Epoch: 1/2, step 6458/7134 completed (loss: 0.027603046968579292, acc: 0.9882352948188782)
[2024-12-17 04:31:02,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:02,615][root][INFO] - Training Epoch: 1/2, step 6459/7134 completed (loss: 0.0049836174584925175, acc: 0.9986225962638855)
[2024-12-17 04:31:02,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:03,084][root][INFO] - Training Epoch: 1/2, step 6460/7134 completed (loss: 0.021346209570765495, acc: 0.9940968155860901)
[2024-12-17 04:31:03,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:03,510][root][INFO] - Training Epoch: 1/2, step 6461/7134 completed (loss: 0.021737422794103622, acc: 0.9934297204017639)
[2024-12-17 04:31:03,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:03,937][root][INFO] - Training Epoch: 1/2, step 6462/7134 completed (loss: 0.04449585825204849, acc: 0.9852398633956909)
[2024-12-17 04:31:04,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:04,406][root][INFO] - Training Epoch: 1/2, step 6463/7134 completed (loss: 0.0365162193775177, acc: 0.9897494316101074)
[2024-12-17 04:31:04,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:04,835][root][INFO] - Training Epoch: 1/2, step 6464/7134 completed (loss: 0.03180713579058647, acc: 0.9921976327896118)
[2024-12-17 04:31:04,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:05,272][root][INFO] - Training Epoch: 1/2, step 6465/7134 completed (loss: 0.02810761146247387, acc: 0.9922879338264465)
[2024-12-17 04:31:05,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:05,690][root][INFO] - Training Epoch: 1/2, step 6466/7134 completed (loss: 0.0257481187582016, acc: 0.9920739531517029)
[2024-12-17 04:31:05,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:06,135][root][INFO] - Training Epoch: 1/2, step 6467/7134 completed (loss: 0.04577108472585678, acc: 0.981679379940033)
[2024-12-17 04:31:06,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:06,579][root][INFO] - Training Epoch: 1/2, step 6468/7134 completed (loss: 0.05461511388421059, acc: 0.9868667721748352)
[2024-12-17 04:31:06,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:07,043][root][INFO] - Training Epoch: 1/2, step 6469/7134 completed (loss: 0.05413755029439926, acc: 0.9841656684875488)
[2024-12-17 04:31:07,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:07,417][root][INFO] - Training Epoch: 1/2, step 6470/7134 completed (loss: 0.08358234167098999, acc: 0.97555011510849)
[2024-12-17 04:31:07,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:07,856][root][INFO] - Training Epoch: 1/2, step 6471/7134 completed (loss: 0.01889251172542572, acc: 0.9951140284538269)
[2024-12-17 04:31:07,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:08,324][root][INFO] - Training Epoch: 1/2, step 6472/7134 completed (loss: 0.05678686872124672, acc: 0.986997663974762)
[2024-12-17 04:31:08,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:08,761][root][INFO] - Training Epoch: 1/2, step 6473/7134 completed (loss: 0.02144482173025608, acc: 0.9946380853652954)
[2024-12-17 04:31:08,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:09,177][root][INFO] - Training Epoch: 1/2, step 6474/7134 completed (loss: 0.03913569450378418, acc: 0.9892328381538391)
[2024-12-17 04:31:09,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:09,562][root][INFO] - Training Epoch: 1/2, step 6475/7134 completed (loss: 0.05344822630286217, acc: 0.9883333444595337)
[2024-12-17 04:31:09,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:09,921][root][INFO] - Training Epoch: 1/2, step 6476/7134 completed (loss: 0.08019521832466125, acc: 0.9834983348846436)
[2024-12-17 04:31:10,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:10,321][root][INFO] - Training Epoch: 1/2, step 6477/7134 completed (loss: 0.033662162721157074, acc: 0.9851694703102112)
[2024-12-17 04:31:10,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:10,729][root][INFO] - Training Epoch: 1/2, step 6478/7134 completed (loss: 0.036175671964883804, acc: 0.9889298677444458)
[2024-12-17 04:31:10,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:11,149][root][INFO] - Training Epoch: 1/2, step 6479/7134 completed (loss: 0.026026982814073563, acc: 0.9932998418807983)
[2024-12-17 04:31:11,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:11,548][root][INFO] - Training Epoch: 1/2, step 6480/7134 completed (loss: 0.08421601355075836, acc: 0.9828178882598877)
[2024-12-17 04:31:11,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:11,987][root][INFO] - Training Epoch: 1/2, step 6481/7134 completed (loss: 0.0186920166015625, acc: 0.9914966225624084)
[2024-12-17 04:31:12,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:12,410][root][INFO] - Training Epoch: 1/2, step 6482/7134 completed (loss: 0.022069741040468216, acc: 0.9925000071525574)
[2024-12-17 04:31:12,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:12,825][root][INFO] - Training Epoch: 1/2, step 6483/7134 completed (loss: 0.0779566615819931, acc: 0.9819494485855103)
[2024-12-17 04:31:12,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:13,247][root][INFO] - Training Epoch: 1/2, step 6484/7134 completed (loss: 0.0345131941139698, acc: 0.9897360801696777)
[2024-12-17 04:31:13,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:13,716][root][INFO] - Training Epoch: 1/2, step 6485/7134 completed (loss: 0.035222236067056656, acc: 0.992094874382019)
[2024-12-17 04:31:13,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:14,120][root][INFO] - Training Epoch: 1/2, step 6486/7134 completed (loss: 0.1346483826637268, acc: 0.9690909385681152)
[2024-12-17 04:31:14,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:14,476][root][INFO] - Training Epoch: 1/2, step 6487/7134 completed (loss: 0.1916186660528183, acc: 0.9514170289039612)
[2024-12-17 04:31:14,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:14,860][root][INFO] - Training Epoch: 1/2, step 6488/7134 completed (loss: 0.10103192925453186, acc: 0.9718309640884399)
[2024-12-17 04:31:14,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:15,261][root][INFO] - Training Epoch: 1/2, step 6489/7134 completed (loss: 0.13823695480823517, acc: 0.9664179086685181)
[2024-12-17 04:31:15,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:15,630][root][INFO] - Training Epoch: 1/2, step 6490/7134 completed (loss: 0.0721542239189148, acc: 0.9828473329544067)
[2024-12-17 04:31:15,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:16,062][root][INFO] - Training Epoch: 1/2, step 6491/7134 completed (loss: 0.1045842170715332, acc: 0.9784075617790222)
[2024-12-17 04:31:16,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:16,504][root][INFO] - Training Epoch: 1/2, step 6492/7134 completed (loss: 0.04991072043776512, acc: 0.9818887710571289)
[2024-12-17 04:31:16,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:16,971][root][INFO] - Training Epoch: 1/2, step 6493/7134 completed (loss: 0.0901416540145874, acc: 0.9821882843971252)
[2024-12-17 04:31:17,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:17,370][root][INFO] - Training Epoch: 1/2, step 6494/7134 completed (loss: 0.06835398077964783, acc: 0.9797047972679138)
[2024-12-17 04:31:17,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:17,850][root][INFO] - Training Epoch: 1/2, step 6495/7134 completed (loss: 0.0631706714630127, acc: 0.9831697344779968)
[2024-12-17 04:31:17,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:18,300][root][INFO] - Training Epoch: 1/2, step 6496/7134 completed (loss: 0.04596884921193123, acc: 0.989924430847168)
[2024-12-17 04:31:18,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:18,722][root][INFO] - Training Epoch: 1/2, step 6497/7134 completed (loss: 0.14107662439346313, acc: 0.9704509973526001)
[2024-12-17 04:31:18,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:19,153][root][INFO] - Training Epoch: 1/2, step 6498/7134 completed (loss: 0.030711401253938675, acc: 0.992682933807373)
[2024-12-17 04:31:19,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:19,582][root][INFO] - Training Epoch: 1/2, step 6499/7134 completed (loss: 0.05085271596908569, acc: 0.9875466823577881)
[2024-12-17 04:31:19,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:20,046][root][INFO] - Training Epoch: 1/2, step 6500/7134 completed (loss: 0.09552779048681259, acc: 0.9691876769065857)
[2024-12-17 04:31:20,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:20,475][root][INFO] - Training Epoch: 1/2, step 6501/7134 completed (loss: 0.15215861797332764, acc: 0.9641943573951721)
[2024-12-17 04:31:20,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:20,977][root][INFO] - Training Epoch: 1/2, step 6502/7134 completed (loss: 0.04740277677774429, acc: 0.9869358539581299)
[2024-12-17 04:31:21,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:21,415][root][INFO] - Training Epoch: 1/2, step 6503/7134 completed (loss: 0.05465003475546837, acc: 0.9824047088623047)
[2024-12-17 04:31:21,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:21,820][root][INFO] - Training Epoch: 1/2, step 6504/7134 completed (loss: 0.06522335112094879, acc: 0.9842022061347961)
[2024-12-17 04:31:21,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:22,263][root][INFO] - Training Epoch: 1/2, step 6505/7134 completed (loss: 0.09634377062320709, acc: 0.9724637866020203)
[2024-12-17 04:31:22,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:22,732][root][INFO] - Training Epoch: 1/2, step 6506/7134 completed (loss: 0.08914601802825928, acc: 0.9739413857460022)
[2024-12-17 04:31:22,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:23,173][root][INFO] - Training Epoch: 1/2, step 6507/7134 completed (loss: 0.11700072139501572, acc: 0.9712556600570679)
[2024-12-17 04:31:23,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:23,629][root][INFO] - Training Epoch: 1/2, step 6508/7134 completed (loss: 0.06310461461544037, acc: 0.9894366264343262)
[2024-12-17 04:31:23,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:24,073][root][INFO] - Training Epoch: 1/2, step 6509/7134 completed (loss: 0.05126672610640526, acc: 0.9844961166381836)
[2024-12-17 04:31:24,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:24,564][root][INFO] - Training Epoch: 1/2, step 6510/7134 completed (loss: 0.0615205392241478, acc: 0.9809725284576416)
[2024-12-17 04:31:24,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:24,999][root][INFO] - Training Epoch: 1/2, step 6511/7134 completed (loss: 0.06630773842334747, acc: 0.9789473414421082)
[2024-12-17 04:31:25,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:25,370][root][INFO] - Training Epoch: 1/2, step 6512/7134 completed (loss: 0.03375094383955002, acc: 0.9923954606056213)
[2024-12-17 04:31:25,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:25,791][root][INFO] - Training Epoch: 1/2, step 6513/7134 completed (loss: 0.04772784560918808, acc: 0.9876543283462524)
[2024-12-17 04:31:25,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:26,203][root][INFO] - Training Epoch: 1/2, step 6514/7134 completed (loss: 0.0592958927154541, acc: 0.9801136255264282)
[2024-12-17 04:31:26,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:26,692][root][INFO] - Training Epoch: 1/2, step 6515/7134 completed (loss: 0.05835309624671936, acc: 0.9809644818305969)
[2024-12-17 04:31:26,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:27,153][root][INFO] - Training Epoch: 1/2, step 6516/7134 completed (loss: 0.10049915313720703, acc: 0.9748010635375977)
[2024-12-17 04:31:27,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:27,599][root][INFO] - Training Epoch: 1/2, step 6517/7134 completed (loss: 0.056280467659235, acc: 0.9842105507850647)
[2024-12-17 04:31:27,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:28,049][root][INFO] - Training Epoch: 1/2, step 6518/7134 completed (loss: 0.034437887370586395, acc: 0.9903448224067688)
[2024-12-17 04:31:28,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:28,471][root][INFO] - Training Epoch: 1/2, step 6519/7134 completed (loss: 0.05526217818260193, acc: 0.991134762763977)
[2024-12-17 04:31:28,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:28,882][root][INFO] - Training Epoch: 1/2, step 6520/7134 completed (loss: 0.03786466270685196, acc: 0.9906687140464783)
[2024-12-17 04:31:29,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:29,298][root][INFO] - Training Epoch: 1/2, step 6521/7134 completed (loss: 0.03454819694161415, acc: 0.9869791865348816)
[2024-12-17 04:31:29,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:29,704][root][INFO] - Training Epoch: 1/2, step 6522/7134 completed (loss: 0.04979399964213371, acc: 0.9777015447616577)
[2024-12-17 04:31:29,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:30,132][root][INFO] - Training Epoch: 1/2, step 6523/7134 completed (loss: 0.09804484993219376, acc: 0.9691470265388489)
[2024-12-17 04:31:30,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:30,579][root][INFO] - Training Epoch: 1/2, step 6524/7134 completed (loss: 0.08435728400945663, acc: 0.9832904934883118)
[2024-12-17 04:31:30,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:31,010][root][INFO] - Training Epoch: 1/2, step 6525/7134 completed (loss: 0.02929709292948246, acc: 0.9919678568840027)
[2024-12-17 04:31:31,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:31,483][root][INFO] - Training Epoch: 1/2, step 6526/7134 completed (loss: 0.05915413424372673, acc: 0.9833546876907349)
[2024-12-17 04:31:31,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:31,923][root][INFO] - Training Epoch: 1/2, step 6527/7134 completed (loss: 0.06097114458680153, acc: 0.9881305694580078)
[2024-12-17 04:31:32,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:32,315][root][INFO] - Training Epoch: 1/2, step 6528/7134 completed (loss: 0.08035778254270554, acc: 0.9801443815231323)
[2024-12-17 04:31:32,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:32,709][root][INFO] - Training Epoch: 1/2, step 6529/7134 completed (loss: 0.09400249272584915, acc: 0.981203019618988)
[2024-12-17 04:31:32,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:33,138][root][INFO] - Training Epoch: 1/2, step 6530/7134 completed (loss: 0.0559656098484993, acc: 0.984308123588562)
[2024-12-17 04:31:33,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:33,558][root][INFO] - Training Epoch: 1/2, step 6531/7134 completed (loss: 0.03453371673822403, acc: 0.9942196607589722)
[2024-12-17 04:31:33,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:34,000][root][INFO] - Training Epoch: 1/2, step 6532/7134 completed (loss: 0.0660322830080986, acc: 0.9824780821800232)
[2024-12-17 04:31:34,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:34,440][root][INFO] - Training Epoch: 1/2, step 6533/7134 completed (loss: 0.028628146275877953, acc: 0.9925373196601868)
[2024-12-17 04:31:34,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:34,848][root][INFO] - Training Epoch: 1/2, step 6534/7134 completed (loss: 0.05910152569413185, acc: 0.9879356622695923)
[2024-12-17 04:31:34,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:35,249][root][INFO] - Training Epoch: 1/2, step 6535/7134 completed (loss: 0.0339791364967823, acc: 0.9882903695106506)
[2024-12-17 04:31:35,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:35,672][root][INFO] - Training Epoch: 1/2, step 6536/7134 completed (loss: 0.049657899886369705, acc: 0.9861111044883728)
[2024-12-17 04:31:35,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:36,069][root][INFO] - Training Epoch: 1/2, step 6537/7134 completed (loss: 0.08071538805961609, acc: 0.9734513163566589)
[2024-12-17 04:31:36,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:36,479][root][INFO] - Training Epoch: 1/2, step 6538/7134 completed (loss: 0.08090359717607498, acc: 0.980461835861206)
[2024-12-17 04:31:36,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:36,869][root][INFO] - Training Epoch: 1/2, step 6539/7134 completed (loss: 0.0151010537520051, acc: 0.9969879388809204)
[2024-12-17 04:31:37,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:37,246][root][INFO] - Training Epoch: 1/2, step 6540/7134 completed (loss: 0.2819128930568695, acc: 0.931693971157074)
[2024-12-17 04:31:37,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:37,725][root][INFO] - Training Epoch: 1/2, step 6541/7134 completed (loss: 0.07637148350477219, acc: 0.9791666865348816)
[2024-12-17 04:31:37,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:38,179][root][INFO] - Training Epoch: 1/2, step 6542/7134 completed (loss: 0.06853345781564713, acc: 0.9728813767433167)
[2024-12-17 04:31:38,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:38,595][root][INFO] - Training Epoch: 1/2, step 6543/7134 completed (loss: 0.042036380618810654, acc: 0.9832285046577454)
[2024-12-17 04:31:38,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:39,030][root][INFO] - Training Epoch: 1/2, step 6544/7134 completed (loss: 0.05685931444168091, acc: 0.9920477271080017)
[2024-12-17 04:31:39,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:39,435][root][INFO] - Training Epoch: 1/2, step 6545/7134 completed (loss: 0.040268536657094955, acc: 0.9944238066673279)
[2024-12-17 04:31:39,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:39,818][root][INFO] - Training Epoch: 1/2, step 6546/7134 completed (loss: 0.0535501167178154, acc: 0.9853420257568359)
[2024-12-17 04:31:39,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:40,223][root][INFO] - Training Epoch: 1/2, step 6547/7134 completed (loss: 0.12355966866016388, acc: 0.9744463562965393)
[2024-12-17 04:31:40,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:40,568][root][INFO] - Training Epoch: 1/2, step 6548/7134 completed (loss: 0.028623729944229126, acc: 0.9940476417541504)
[2024-12-17 04:31:40,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:40,971][root][INFO] - Training Epoch: 1/2, step 6549/7134 completed (loss: 0.09699564427137375, acc: 0.9825242757797241)
[2024-12-17 04:31:41,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:41,373][root][INFO] - Training Epoch: 1/2, step 6550/7134 completed (loss: 0.09176205843687057, acc: 0.9784615635871887)
[2024-12-17 04:31:41,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:41,825][root][INFO] - Training Epoch: 1/2, step 6551/7134 completed (loss: 0.04031214863061905, acc: 0.9920273423194885)
[2024-12-17 04:31:41,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:42,287][root][INFO] - Training Epoch: 1/2, step 6552/7134 completed (loss: 0.034777816385030746, acc: 0.9930278658866882)
[2024-12-17 04:31:42,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:42,749][root][INFO] - Training Epoch: 1/2, step 6553/7134 completed (loss: 0.06221018359065056, acc: 0.9770992398262024)
[2024-12-17 04:31:42,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:43,214][root][INFO] - Training Epoch: 1/2, step 6554/7134 completed (loss: 0.04386867582798004, acc: 0.9870270490646362)
[2024-12-17 04:31:43,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:43,693][root][INFO] - Training Epoch: 1/2, step 6555/7134 completed (loss: 0.07602906227111816, acc: 0.9778671860694885)
[2024-12-17 04:31:43,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:44,128][root][INFO] - Training Epoch: 1/2, step 6556/7134 completed (loss: 0.055661603808403015, acc: 0.9852631688117981)
[2024-12-17 04:31:44,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:44,598][root][INFO] - Training Epoch: 1/2, step 6557/7134 completed (loss: 0.04731589928269386, acc: 0.9879032373428345)
[2024-12-17 04:31:44,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:45,079][root][INFO] - Training Epoch: 1/2, step 6558/7134 completed (loss: 0.06452871114015579, acc: 0.9847826361656189)
[2024-12-17 04:31:45,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:45,515][root][INFO] - Training Epoch: 1/2, step 6559/7134 completed (loss: 0.05353749915957451, acc: 0.9847434163093567)
[2024-12-17 04:31:45,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:46,052][root][INFO] - Training Epoch: 1/2, step 6560/7134 completed (loss: 0.048833273351192474, acc: 0.9833531379699707)
[2024-12-17 04:31:46,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:46,492][root][INFO] - Training Epoch: 1/2, step 6561/7134 completed (loss: 0.043182168155908585, acc: 0.9871345162391663)
[2024-12-17 04:31:46,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:46,929][root][INFO] - Training Epoch: 1/2, step 6562/7134 completed (loss: 0.056539442390203476, acc: 0.9820627570152283)
[2024-12-17 04:31:47,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:47,392][root][INFO] - Training Epoch: 1/2, step 6563/7134 completed (loss: 0.05356110632419586, acc: 0.9837020039558411)
[2024-12-17 04:31:47,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:47,859][root][INFO] - Training Epoch: 1/2, step 6564/7134 completed (loss: 0.06264322996139526, acc: 0.9851552248001099)
[2024-12-17 04:31:47,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:48,335][root][INFO] - Training Epoch: 1/2, step 6565/7134 completed (loss: 0.04825280234217644, acc: 0.9830867052078247)
[2024-12-17 04:31:48,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:48,830][root][INFO] - Training Epoch: 1/2, step 6566/7134 completed (loss: 0.045715197920799255, acc: 0.9848053455352783)
[2024-12-17 04:31:48,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:49,319][root][INFO] - Training Epoch: 1/2, step 6567/7134 completed (loss: 0.02824021875858307, acc: 0.9918946027755737)
[2024-12-17 04:31:49,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:49,775][root][INFO] - Training Epoch: 1/2, step 6568/7134 completed (loss: 0.03272360935807228, acc: 0.9911727905273438)
[2024-12-17 04:31:49,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:50,215][root][INFO] - Training Epoch: 1/2, step 6569/7134 completed (loss: 0.015351293608546257, acc: 0.9967032670974731)
[2024-12-17 04:31:50,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:50,666][root][INFO] - Training Epoch: 1/2, step 6570/7134 completed (loss: 0.022100985050201416, acc: 0.9953542351722717)
[2024-12-17 04:31:50,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:51,067][root][INFO] - Training Epoch: 1/2, step 6571/7134 completed (loss: 0.030940057709813118, acc: 0.9921466112136841)
[2024-12-17 04:31:51,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:51,505][root][INFO] - Training Epoch: 1/2, step 6572/7134 completed (loss: 0.046246640384197235, acc: 0.9878048896789551)
[2024-12-17 04:31:51,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:51,965][root][INFO] - Training Epoch: 1/2, step 6573/7134 completed (loss: 0.03674803674221039, acc: 0.9898419976234436)
[2024-12-17 04:31:52,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:52,434][root][INFO] - Training Epoch: 1/2, step 6574/7134 completed (loss: 0.023955775424838066, acc: 0.9918200373649597)
[2024-12-17 04:31:52,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:52,934][root][INFO] - Training Epoch: 1/2, step 6575/7134 completed (loss: 0.04788699001073837, acc: 0.9845303893089294)
[2024-12-17 04:31:53,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:53,387][root][INFO] - Training Epoch: 1/2, step 6576/7134 completed (loss: 0.021908683702349663, acc: 0.9947478771209717)
[2024-12-17 04:31:53,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:53,835][root][INFO] - Training Epoch: 1/2, step 6577/7134 completed (loss: 0.07014283537864685, acc: 0.9831932783126831)
[2024-12-17 04:31:53,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:54,463][root][INFO] - Training Epoch: 1/2, step 6578/7134 completed (loss: 0.03523072227835655, acc: 0.9902135133743286)
[2024-12-17 04:31:54,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:54,851][root][INFO] - Training Epoch: 1/2, step 6579/7134 completed (loss: 0.05267423763871193, acc: 0.9872958064079285)
[2024-12-17 04:31:54,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:55,307][root][INFO] - Training Epoch: 1/2, step 6580/7134 completed (loss: 0.040994782000780106, acc: 0.9905882477760315)
[2024-12-17 04:31:55,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:55,740][root][INFO] - Training Epoch: 1/2, step 6581/7134 completed (loss: 0.03568731248378754, acc: 0.9889298677444458)
[2024-12-17 04:31:55,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:56,136][root][INFO] - Training Epoch: 1/2, step 6582/7134 completed (loss: 0.06907844543457031, acc: 0.9798561334609985)
[2024-12-17 04:31:56,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:56,591][root][INFO] - Training Epoch: 1/2, step 6583/7134 completed (loss: 0.030034633353352547, acc: 0.991990864276886)
[2024-12-17 04:31:56,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:57,041][root][INFO] - Training Epoch: 1/2, step 6584/7134 completed (loss: 0.06085953488945961, acc: 0.9828641414642334)
[2024-12-17 04:31:57,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:57,483][root][INFO] - Training Epoch: 1/2, step 6585/7134 completed (loss: 0.05113223195075989, acc: 0.9835526347160339)
[2024-12-17 04:31:57,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:57,929][root][INFO] - Training Epoch: 1/2, step 6586/7134 completed (loss: 0.0482039637863636, acc: 0.9909326434135437)
[2024-12-17 04:31:58,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:58,379][root][INFO] - Training Epoch: 1/2, step 6587/7134 completed (loss: 0.07215334475040436, acc: 0.9823113083839417)
[2024-12-17 04:31:58,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:58,805][root][INFO] - Training Epoch: 1/2, step 6588/7134 completed (loss: 0.05797172337770462, acc: 0.9836478233337402)
[2024-12-17 04:31:58,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:59,235][root][INFO] - Training Epoch: 1/2, step 6589/7134 completed (loss: 0.047066278755664825, acc: 0.9847856163978577)
[2024-12-17 04:31:59,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:31:59,723][root][INFO] - Training Epoch: 1/2, step 6590/7134 completed (loss: 0.04873572289943695, acc: 0.9860302805900574)
[2024-12-17 04:31:59,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:00,191][root][INFO] - Training Epoch: 1/2, step 6591/7134 completed (loss: 0.045486729592084885, acc: 0.9851301312446594)
[2024-12-17 04:32:00,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:00,656][root][INFO] - Training Epoch: 1/2, step 6592/7134 completed (loss: 0.06862710416316986, acc: 0.9818388223648071)
[2024-12-17 04:32:00,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:01,070][root][INFO] - Training Epoch: 1/2, step 6593/7134 completed (loss: 0.05140379071235657, acc: 0.9878234267234802)
[2024-12-17 04:32:01,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:01,519][root][INFO] - Training Epoch: 1/2, step 6594/7134 completed (loss: 0.03754626587033272, acc: 0.9917840361595154)
[2024-12-17 04:32:01,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:01,955][root][INFO] - Training Epoch: 1/2, step 6595/7134 completed (loss: 0.06428422778844833, acc: 0.9836795330047607)
[2024-12-17 04:32:02,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:02,363][root][INFO] - Training Epoch: 1/2, step 6596/7134 completed (loss: 0.04623124748468399, acc: 0.987860381603241)
[2024-12-17 04:32:02,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:02,806][root][INFO] - Training Epoch: 1/2, step 6597/7134 completed (loss: 0.03701227903366089, acc: 0.9905660152435303)
[2024-12-17 04:32:02,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:03,247][root][INFO] - Training Epoch: 1/2, step 6598/7134 completed (loss: 0.049784887582063675, acc: 0.9865771532058716)
[2024-12-17 04:32:03,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:03,709][root][INFO] - Training Epoch: 1/2, step 6599/7134 completed (loss: 0.06763293594121933, acc: 0.9830917716026306)
[2024-12-17 04:32:03,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:04,115][root][INFO] - Training Epoch: 1/2, step 6600/7134 completed (loss: 0.07625584304332733, acc: 0.9778130054473877)
[2024-12-17 04:32:04,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:04,569][root][INFO] - Training Epoch: 1/2, step 6601/7134 completed (loss: 0.09228968620300293, acc: 0.9776995182037354)
[2024-12-17 04:32:04,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:05,013][root][INFO] - Training Epoch: 1/2, step 6602/7134 completed (loss: 0.05373862385749817, acc: 0.9843562245368958)
[2024-12-17 04:32:05,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:05,456][root][INFO] - Training Epoch: 1/2, step 6603/7134 completed (loss: 0.04300442337989807, acc: 0.9873772859573364)
[2024-12-17 04:32:05,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:05,826][root][INFO] - Training Epoch: 1/2, step 6604/7134 completed (loss: 0.07701138406991959, acc: 0.9798850417137146)
[2024-12-17 04:32:05,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:06,230][root][INFO] - Training Epoch: 1/2, step 6605/7134 completed (loss: 0.1164105236530304, acc: 0.9681881070137024)
[2024-12-17 04:32:06,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:06,692][root][INFO] - Training Epoch: 1/2, step 6606/7134 completed (loss: 0.03923715651035309, acc: 0.9886363744735718)
[2024-12-17 04:32:06,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:07,153][root][INFO] - Training Epoch: 1/2, step 6607/7134 completed (loss: 0.09642539918422699, acc: 0.9813829660415649)
[2024-12-17 04:32:07,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:07,610][root][INFO] - Training Epoch: 1/2, step 6608/7134 completed (loss: 0.0372491329908371, acc: 0.9880478382110596)
[2024-12-17 04:32:07,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:08,064][root][INFO] - Training Epoch: 1/2, step 6609/7134 completed (loss: 0.07491349428892136, acc: 0.97555011510849)
[2024-12-17 04:32:08,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:08,490][root][INFO] - Training Epoch: 1/2, step 6610/7134 completed (loss: 0.08636918663978577, acc: 0.9770889282226562)
[2024-12-17 04:32:08,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:08,887][root][INFO] - Training Epoch: 1/2, step 6611/7134 completed (loss: 0.13126066327095032, acc: 0.9676923155784607)
[2024-12-17 04:32:09,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:09,362][root][INFO] - Training Epoch: 1/2, step 6612/7134 completed (loss: 0.08133795112371445, acc: 0.9766627550125122)
[2024-12-17 04:32:09,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:09,849][root][INFO] - Training Epoch: 1/2, step 6613/7134 completed (loss: 0.04939344525337219, acc: 0.9851190447807312)
[2024-12-17 04:32:09,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:10,288][root][INFO] - Training Epoch: 1/2, step 6614/7134 completed (loss: 0.08778191357851028, acc: 0.9812981486320496)
[2024-12-17 04:32:10,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:10,726][root][INFO] - Training Epoch: 1/2, step 6615/7134 completed (loss: 0.052032481878995895, acc: 0.987270176410675)
[2024-12-17 04:32:10,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:11,187][root][INFO] - Training Epoch: 1/2, step 6616/7134 completed (loss: 0.04861923307180405, acc: 0.987089216709137)
[2024-12-17 04:32:11,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:11,636][root][INFO] - Training Epoch: 1/2, step 6617/7134 completed (loss: 0.04836894944310188, acc: 0.9884726405143738)
[2024-12-17 04:32:11,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:12,065][root][INFO] - Training Epoch: 1/2, step 6618/7134 completed (loss: 0.04368189349770546, acc: 0.9866270422935486)
[2024-12-17 04:32:12,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:12,531][root][INFO] - Training Epoch: 1/2, step 6619/7134 completed (loss: 0.04748702794313431, acc: 0.9865471124649048)
[2024-12-17 04:32:12,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:12,996][root][INFO] - Training Epoch: 1/2, step 6620/7134 completed (loss: 0.05328653007745743, acc: 0.9821183085441589)
[2024-12-17 04:32:13,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:13,437][root][INFO] - Training Epoch: 1/2, step 6621/7134 completed (loss: 0.05584970861673355, acc: 0.9861271381378174)
[2024-12-17 04:32:13,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:13,871][root][INFO] - Training Epoch: 1/2, step 6622/7134 completed (loss: 0.0482453927397728, acc: 0.9849726557731628)
[2024-12-17 04:32:13,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:14,307][root][INFO] - Training Epoch: 1/2, step 6623/7134 completed (loss: 0.024627577513456345, acc: 0.9911949634552002)
[2024-12-17 04:32:14,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:14,745][root][INFO] - Training Epoch: 1/2, step 6624/7134 completed (loss: 0.03677022084593773, acc: 0.98828125)
[2024-12-17 04:32:14,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:15,173][root][INFO] - Training Epoch: 1/2, step 6625/7134 completed (loss: 0.03682033345103264, acc: 0.9848693013191223)
[2024-12-17 04:32:15,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:15,628][root][INFO] - Training Epoch: 1/2, step 6626/7134 completed (loss: 0.017062896862626076, acc: 0.996363639831543)
[2024-12-17 04:32:15,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:16,100][root][INFO] - Training Epoch: 1/2, step 6627/7134 completed (loss: 0.03398490324616432, acc: 0.9913513660430908)
[2024-12-17 04:32:16,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:16,556][root][INFO] - Training Epoch: 1/2, step 6628/7134 completed (loss: 0.0641043409705162, acc: 0.9834319353103638)
[2024-12-17 04:32:16,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:16,957][root][INFO] - Training Epoch: 1/2, step 6629/7134 completed (loss: 0.06691385805606842, acc: 0.9871630072593689)
[2024-12-17 04:32:17,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:17,443][root][INFO] - Training Epoch: 1/2, step 6630/7134 completed (loss: 0.05918596312403679, acc: 0.9821627736091614)
[2024-12-17 04:32:17,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:17,883][root][INFO] - Training Epoch: 1/2, step 6631/7134 completed (loss: 0.05041714012622833, acc: 0.9803407788276672)
[2024-12-17 04:32:17,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:18,370][root][INFO] - Training Epoch: 1/2, step 6632/7134 completed (loss: 0.029565025120973587, acc: 0.9943757057189941)
[2024-12-17 04:32:18,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:18,798][root][INFO] - Training Epoch: 1/2, step 6633/7134 completed (loss: 0.06758888810873032, acc: 0.9853658676147461)
[2024-12-17 04:32:18,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:19,212][root][INFO] - Training Epoch: 1/2, step 6634/7134 completed (loss: 0.05508469417691231, acc: 0.9856887459754944)
[2024-12-17 04:32:19,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:19,610][root][INFO] - Training Epoch: 1/2, step 6635/7134 completed (loss: 0.12633059918880463, acc: 0.9731457829475403)
[2024-12-17 04:32:19,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:20,067][root][INFO] - Training Epoch: 1/2, step 6636/7134 completed (loss: 0.0607643723487854, acc: 0.982876718044281)
[2024-12-17 04:32:20,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:20,492][root][INFO] - Training Epoch: 1/2, step 6637/7134 completed (loss: 0.04204792156815529, acc: 0.9912663698196411)
[2024-12-17 04:32:20,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:20,923][root][INFO] - Training Epoch: 1/2, step 6638/7134 completed (loss: 0.02468063496053219, acc: 0.9949173927307129)
[2024-12-17 04:32:21,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:21,369][root][INFO] - Training Epoch: 1/2, step 6639/7134 completed (loss: 0.0455322265625, acc: 0.9910581111907959)
[2024-12-17 04:32:21,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:21,828][root][INFO] - Training Epoch: 1/2, step 6640/7134 completed (loss: 0.03562117740511894, acc: 0.9877488613128662)
[2024-12-17 04:32:21,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:22,279][root][INFO] - Training Epoch: 1/2, step 6641/7134 completed (loss: 0.1115671768784523, acc: 0.974208652973175)
[2024-12-17 04:32:22,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:22,720][root][INFO] - Training Epoch: 1/2, step 6642/7134 completed (loss: 0.053619395941495895, acc: 0.9849397540092468)
[2024-12-17 04:32:22,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:23,187][root][INFO] - Training Epoch: 1/2, step 6643/7134 completed (loss: 0.04988419637084007, acc: 0.9894319772720337)
[2024-12-17 04:32:23,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:23,643][root][INFO] - Training Epoch: 1/2, step 6644/7134 completed (loss: 0.08420806378126144, acc: 0.9837232828140259)
[2024-12-17 04:32:23,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:24,084][root][INFO] - Training Epoch: 1/2, step 6645/7134 completed (loss: 0.04186834394931793, acc: 0.9852579832077026)
[2024-12-17 04:32:24,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:24,569][root][INFO] - Training Epoch: 1/2, step 6646/7134 completed (loss: 0.04799563065171242, acc: 0.9867841601371765)
[2024-12-17 04:32:24,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:25,025][root][INFO] - Training Epoch: 1/2, step 6647/7134 completed (loss: 0.03967852145433426, acc: 0.989130437374115)
[2024-12-17 04:32:25,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:25,485][root][INFO] - Training Epoch: 1/2, step 6648/7134 completed (loss: 0.09905733168125153, acc: 0.9679999947547913)
[2024-12-17 04:32:25,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:25,952][root][INFO] - Training Epoch: 1/2, step 6649/7134 completed (loss: 0.08251255750656128, acc: 0.9775679111480713)
[2024-12-17 04:32:26,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:26,444][root][INFO] - Training Epoch: 1/2, step 6650/7134 completed (loss: 0.03213061764836311, acc: 0.9888392686843872)
[2024-12-17 04:32:26,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:26,926][root][INFO] - Training Epoch: 1/2, step 6651/7134 completed (loss: 0.02761852741241455, acc: 0.9945429563522339)
[2024-12-17 04:32:27,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:27,387][root][INFO] - Training Epoch: 1/2, step 6652/7134 completed (loss: 0.057849206030368805, acc: 0.979468584060669)
[2024-12-17 04:32:27,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:27,861][root][INFO] - Training Epoch: 1/2, step 6653/7134 completed (loss: 0.06360345333814621, acc: 0.9802847504615784)
[2024-12-17 04:32:27,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:28,300][root][INFO] - Training Epoch: 1/2, step 6654/7134 completed (loss: 0.08477248251438141, acc: 0.9844961166381836)
[2024-12-17 04:32:28,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:28,754][root][INFO] - Training Epoch: 1/2, step 6655/7134 completed (loss: 0.06991779059171677, acc: 0.9751861095428467)
[2024-12-17 04:32:28,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:29,183][root][INFO] - Training Epoch: 1/2, step 6656/7134 completed (loss: 0.05266721919178963, acc: 0.9821882843971252)
[2024-12-17 04:32:29,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:29,625][root][INFO] - Training Epoch: 1/2, step 6657/7134 completed (loss: 0.07049335539340973, acc: 0.9756097793579102)
[2024-12-17 04:32:29,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:30,087][root][INFO] - Training Epoch: 1/2, step 6658/7134 completed (loss: 0.027485691010951996, acc: 0.9909677505493164)
[2024-12-17 04:32:30,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:30,573][root][INFO] - Training Epoch: 1/2, step 6659/7134 completed (loss: 0.05304277315735817, acc: 0.984375)
[2024-12-17 04:32:30,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:31,026][root][INFO] - Training Epoch: 1/2, step 6660/7134 completed (loss: 0.034646689891815186, acc: 0.9930555820465088)
[2024-12-17 04:32:31,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:31,514][root][INFO] - Training Epoch: 1/2, step 6661/7134 completed (loss: 0.047672007232904434, acc: 0.9826732873916626)
[2024-12-17 04:32:31,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:31,933][root][INFO] - Training Epoch: 1/2, step 6662/7134 completed (loss: 0.07605976611375809, acc: 0.9742489457130432)
[2024-12-17 04:32:32,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:32,381][root][INFO] - Training Epoch: 1/2, step 6663/7134 completed (loss: 0.04666959121823311, acc: 0.9868852496147156)
[2024-12-17 04:32:32,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:32,799][root][INFO] - Training Epoch: 1/2, step 6664/7134 completed (loss: 0.14196336269378662, acc: 0.9594095945358276)
[2024-12-17 04:32:32,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:33,228][root][INFO] - Training Epoch: 1/2, step 6665/7134 completed (loss: 0.12874266505241394, acc: 0.9594155550003052)
[2024-12-17 04:32:33,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:33,693][root][INFO] - Training Epoch: 1/2, step 6666/7134 completed (loss: 0.037905238568782806, acc: 0.989847719669342)
[2024-12-17 04:32:33,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:34,117][root][INFO] - Training Epoch: 1/2, step 6667/7134 completed (loss: 0.05293283984065056, acc: 0.9840989112854004)
[2024-12-17 04:32:34,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:34,516][root][INFO] - Training Epoch: 1/2, step 6668/7134 completed (loss: 0.021680837497115135, acc: 0.9896013736724854)
[2024-12-17 04:32:34,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:34,915][root][INFO] - Training Epoch: 1/2, step 6669/7134 completed (loss: 0.04656507819890976, acc: 0.9832214713096619)
[2024-12-17 04:32:35,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:35,319][root][INFO] - Training Epoch: 1/2, step 6670/7134 completed (loss: 0.038361720740795135, acc: 0.9916387796401978)
[2024-12-17 04:32:35,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:35,751][root][INFO] - Training Epoch: 1/2, step 6671/7134 completed (loss: 0.030970288440585136, acc: 0.9941349029541016)
[2024-12-17 04:32:35,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:36,204][root][INFO] - Training Epoch: 1/2, step 6672/7134 completed (loss: 0.033803489059209824, acc: 0.9887429475784302)
[2024-12-17 04:32:36,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:36,634][root][INFO] - Training Epoch: 1/2, step 6673/7134 completed (loss: 0.04207157343626022, acc: 0.98531574010849)
[2024-12-17 04:32:36,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:37,053][root][INFO] - Training Epoch: 1/2, step 6674/7134 completed (loss: 0.029155729338526726, acc: 0.9922630786895752)
[2024-12-17 04:32:37,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:37,471][root][INFO] - Training Epoch: 1/2, step 6675/7134 completed (loss: 0.026079365983605385, acc: 0.9950617551803589)
[2024-12-17 04:32:37,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:37,892][root][INFO] - Training Epoch: 1/2, step 6676/7134 completed (loss: 0.04549363628029823, acc: 0.9832935333251953)
[2024-12-17 04:32:38,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:38,276][root][INFO] - Training Epoch: 1/2, step 6677/7134 completed (loss: 0.07018472254276276, acc: 0.9847328066825867)
[2024-12-17 04:32:38,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:38,692][root][INFO] - Training Epoch: 1/2, step 6678/7134 completed (loss: 0.018008902668952942, acc: 0.9946428537368774)
[2024-12-17 04:32:38,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:39,096][root][INFO] - Training Epoch: 1/2, step 6679/7134 completed (loss: 0.024742398411035538, acc: 0.9912663698196411)
[2024-12-17 04:32:39,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:39,498][root][INFO] - Training Epoch: 1/2, step 6680/7134 completed (loss: 0.020336242392659187, acc: 0.9945945739746094)
[2024-12-17 04:32:39,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:39,915][root][INFO] - Training Epoch: 1/2, step 6681/7134 completed (loss: 0.018016135320067406, acc: 0.9916840195655823)
[2024-12-17 04:32:40,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:40,321][root][INFO] - Training Epoch: 1/2, step 6682/7134 completed (loss: 0.057143308222293854, acc: 0.9906542301177979)
[2024-12-17 04:32:40,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:40,712][root][INFO] - Training Epoch: 1/2, step 6683/7134 completed (loss: 0.035374678671360016, acc: 0.9890109896659851)
[2024-12-17 04:32:40,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:41,130][root][INFO] - Training Epoch: 1/2, step 6684/7134 completed (loss: 0.04898359254002571, acc: 0.9928571581840515)
[2024-12-17 04:32:41,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:41,539][root][INFO] - Training Epoch: 1/2, step 6685/7134 completed (loss: 0.03750929981470108, acc: 0.9904580116271973)
[2024-12-17 04:32:41,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:41,955][root][INFO] - Training Epoch: 1/2, step 6686/7134 completed (loss: 0.08151694387197495, acc: 0.9834710955619812)
[2024-12-17 04:32:42,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:42,344][root][INFO] - Training Epoch: 1/2, step 6687/7134 completed (loss: 0.10243586450815201, acc: 0.9753086566925049)
[2024-12-17 04:32:42,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:42,803][root][INFO] - Training Epoch: 1/2, step 6688/7134 completed (loss: 0.10927340388298035, acc: 0.9742268323898315)
[2024-12-17 04:32:42,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:43,222][root][INFO] - Training Epoch: 1/2, step 6689/7134 completed (loss: 0.10937649011611938, acc: 0.9722772240638733)
[2024-12-17 04:32:43,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:43,617][root][INFO] - Training Epoch: 1/2, step 6690/7134 completed (loss: 0.16924262046813965, acc: 0.9515738487243652)
[2024-12-17 04:32:43,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:44,047][root][INFO] - Training Epoch: 1/2, step 6691/7134 completed (loss: 0.06206035614013672, acc: 0.9852700233459473)
[2024-12-17 04:32:44,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:44,426][root][INFO] - Training Epoch: 1/2, step 6692/7134 completed (loss: 0.04180978611111641, acc: 0.991525411605835)
[2024-12-17 04:32:44,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:44,837][root][INFO] - Training Epoch: 1/2, step 6693/7134 completed (loss: 0.054998863488435745, acc: 0.9867987036705017)
[2024-12-17 04:32:44,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:45,264][root][INFO] - Training Epoch: 1/2, step 6694/7134 completed (loss: 0.10535155236721039, acc: 0.9709480404853821)
[2024-12-17 04:32:45,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:45,684][root][INFO] - Training Epoch: 1/2, step 6695/7134 completed (loss: 0.04983096942305565, acc: 0.9822161197662354)
[2024-12-17 04:32:45,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:46,111][root][INFO] - Training Epoch: 1/2, step 6696/7134 completed (loss: 0.0954735204577446, acc: 0.9721361994743347)
[2024-12-17 04:32:46,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:46,525][root][INFO] - Training Epoch: 1/2, step 6697/7134 completed (loss: 0.07958472520112991, acc: 0.980327844619751)
[2024-12-17 04:32:46,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:46,940][root][INFO] - Training Epoch: 1/2, step 6698/7134 completed (loss: 0.03866571560502052, acc: 0.9866468906402588)
[2024-12-17 04:32:47,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:47,394][root][INFO] - Training Epoch: 1/2, step 6699/7134 completed (loss: 0.056321993470191956, acc: 0.9908883571624756)
[2024-12-17 04:32:47,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:47,829][root][INFO] - Training Epoch: 1/2, step 6700/7134 completed (loss: 0.10572925209999084, acc: 0.9761029481887817)
[2024-12-17 04:32:47,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:48,248][root][INFO] - Training Epoch: 1/2, step 6701/7134 completed (loss: 0.12164369970560074, acc: 0.9682539701461792)
[2024-12-17 04:32:48,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:48,640][root][INFO] - Training Epoch: 1/2, step 6702/7134 completed (loss: 0.05662652105093002, acc: 0.974459707736969)
[2024-12-17 04:32:48,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:49,071][root][INFO] - Training Epoch: 1/2, step 6703/7134 completed (loss: 0.11355271190404892, acc: 0.9703947305679321)
[2024-12-17 04:32:49,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:49,510][root][INFO] - Training Epoch: 1/2, step 6704/7134 completed (loss: 0.11737485229969025, acc: 0.9663648009300232)
[2024-12-17 04:32:49,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:49,948][root][INFO] - Training Epoch: 1/2, step 6705/7134 completed (loss: 0.06741148233413696, acc: 0.9830949306488037)
[2024-12-17 04:32:50,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:50,353][root][INFO] - Training Epoch: 1/2, step 6706/7134 completed (loss: 0.05430157855153084, acc: 0.9834710955619812)
[2024-12-17 04:32:50,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:50,784][root][INFO] - Training Epoch: 1/2, step 6707/7134 completed (loss: 0.12527437508106232, acc: 0.9644970297813416)
[2024-12-17 04:32:50,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:51,232][root][INFO] - Training Epoch: 1/2, step 6708/7134 completed (loss: 0.07073530554771423, acc: 0.9801980257034302)
[2024-12-17 04:32:51,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:51,657][root][INFO] - Training Epoch: 1/2, step 6709/7134 completed (loss: 0.04986802861094475, acc: 0.9880239367485046)
[2024-12-17 04:32:51,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:52,071][root][INFO] - Training Epoch: 1/2, step 6710/7134 completed (loss: 0.10466970503330231, acc: 0.9762340188026428)
[2024-12-17 04:32:52,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:52,525][root][INFO] - Training Epoch: 1/2, step 6711/7134 completed (loss: 0.04552783444523811, acc: 0.9904761910438538)
[2024-12-17 04:32:52,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:52,929][root][INFO] - Training Epoch: 1/2, step 6712/7134 completed (loss: 0.06040577217936516, acc: 0.9818456768989563)
[2024-12-17 04:32:53,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:53,453][root][INFO] - Training Epoch: 1/2, step 6713/7134 completed (loss: 0.05947526916861534, acc: 0.9826338887214661)
[2024-12-17 04:32:53,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:53,893][root][INFO] - Training Epoch: 1/2, step 6714/7134 completed (loss: 0.06242172792553902, acc: 0.97919762134552)
[2024-12-17 04:32:54,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:54,348][root][INFO] - Training Epoch: 1/2, step 6715/7134 completed (loss: 0.10266636312007904, acc: 0.9670329689979553)
[2024-12-17 04:32:54,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:54,797][root][INFO] - Training Epoch: 1/2, step 6716/7134 completed (loss: 0.030488111078739166, acc: 0.9880239367485046)
[2024-12-17 04:32:54,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:55,214][root][INFO] - Training Epoch: 1/2, step 6717/7134 completed (loss: 0.03923340141773224, acc: 0.9855072498321533)
[2024-12-17 04:32:55,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:55,624][root][INFO] - Training Epoch: 1/2, step 6718/7134 completed (loss: 0.0791727676987648, acc: 0.9772727489471436)
[2024-12-17 04:32:55,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:56,034][root][INFO] - Training Epoch: 1/2, step 6719/7134 completed (loss: 0.03711806237697601, acc: 0.9901960492134094)
[2024-12-17 04:32:56,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:56,454][root][INFO] - Training Epoch: 1/2, step 6720/7134 completed (loss: 0.0755699947476387, acc: 0.9874301552772522)
[2024-12-17 04:32:56,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:56,852][root][INFO] - Training Epoch: 1/2, step 6721/7134 completed (loss: 0.08245241641998291, acc: 0.9797191619873047)
[2024-12-17 04:32:56,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:57,228][root][INFO] - Training Epoch: 1/2, step 6722/7134 completed (loss: 0.11842438578605652, acc: 0.9701230525970459)
[2024-12-17 04:32:57,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:57,667][root][INFO] - Training Epoch: 1/2, step 6723/7134 completed (loss: 0.03781359642744064, acc: 0.987500011920929)
[2024-12-17 04:32:57,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:58,081][root][INFO] - Training Epoch: 1/2, step 6724/7134 completed (loss: 0.06064103543758392, acc: 0.9838945865631104)
[2024-12-17 04:32:58,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:58,457][root][INFO] - Training Epoch: 1/2, step 6725/7134 completed (loss: 0.04921212047338486, acc: 0.9829351305961609)
[2024-12-17 04:32:58,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:58,850][root][INFO] - Training Epoch: 1/2, step 6726/7134 completed (loss: 0.10898959636688232, acc: 0.9759036302566528)
[2024-12-17 04:32:58,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:59,290][root][INFO] - Training Epoch: 1/2, step 6727/7134 completed (loss: 0.07474612444639206, acc: 0.9841549396514893)
[2024-12-17 04:32:59,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:32:59,729][root][INFO] - Training Epoch: 1/2, step 6728/7134 completed (loss: 0.07284017652273178, acc: 0.9892473220825195)
[2024-12-17 04:32:59,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:00,180][root][INFO] - Training Epoch: 1/2, step 6729/7134 completed (loss: 0.038745202124118805, acc: 0.99048912525177)
[2024-12-17 04:33:00,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:00,636][root][INFO] - Training Epoch: 1/2, step 6730/7134 completed (loss: 0.057634465396404266, acc: 0.9874411225318909)
[2024-12-17 04:33:00,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:01,077][root][INFO] - Training Epoch: 1/2, step 6731/7134 completed (loss: 0.049872662872076035, acc: 0.9879336357116699)
[2024-12-17 04:33:01,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:01,483][root][INFO] - Training Epoch: 1/2, step 6732/7134 completed (loss: 0.062098994851112366, acc: 0.9827044010162354)
[2024-12-17 04:33:01,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:01,896][root][INFO] - Training Epoch: 1/2, step 6733/7134 completed (loss: 0.048023153096437454, acc: 0.9867172837257385)
[2024-12-17 04:33:02,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:02,323][root][INFO] - Training Epoch: 1/2, step 6734/7134 completed (loss: 0.08805697411298752, acc: 0.9757009148597717)
[2024-12-17 04:33:02,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:02,750][root][INFO] - Training Epoch: 1/2, step 6735/7134 completed (loss: 0.0690317451953888, acc: 0.9846389889717102)
[2024-12-17 04:33:02,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:03,210][root][INFO] - Training Epoch: 1/2, step 6736/7134 completed (loss: 0.05926745384931564, acc: 0.9860724210739136)
[2024-12-17 04:33:03,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:03,651][root][INFO] - Training Epoch: 1/2, step 6737/7134 completed (loss: 0.07411304861307144, acc: 0.9789302945137024)
[2024-12-17 04:33:03,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:04,095][root][INFO] - Training Epoch: 1/2, step 6738/7134 completed (loss: 0.06635581701993942, acc: 0.983208954334259)
[2024-12-17 04:33:04,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:04,485][root][INFO] - Training Epoch: 1/2, step 6739/7134 completed (loss: 0.04522627592086792, acc: 0.9889705777168274)
[2024-12-17 04:33:04,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:04,905][root][INFO] - Training Epoch: 1/2, step 6740/7134 completed (loss: 0.04911067336797714, acc: 0.9881154298782349)
[2024-12-17 04:33:04,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:05,315][root][INFO] - Training Epoch: 1/2, step 6741/7134 completed (loss: 0.03665914759039879, acc: 0.9927431344985962)
[2024-12-17 04:33:05,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:05,700][root][INFO] - Training Epoch: 1/2, step 6742/7134 completed (loss: 0.03295515105128288, acc: 0.9927849769592285)
[2024-12-17 04:33:05,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:06,155][root][INFO] - Training Epoch: 1/2, step 6743/7134 completed (loss: 0.027063613757491112, acc: 0.9931880235671997)
[2024-12-17 04:33:06,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:06,570][root][INFO] - Training Epoch: 1/2, step 6744/7134 completed (loss: 0.03655391186475754, acc: 0.9919871687889099)
[2024-12-17 04:33:06,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:06,975][root][INFO] - Training Epoch: 1/2, step 6745/7134 completed (loss: 0.020857371389865875, acc: 0.9958734512329102)
[2024-12-17 04:33:07,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:07,368][root][INFO] - Training Epoch: 1/2, step 6746/7134 completed (loss: 0.03348615765571594, acc: 0.9911816716194153)
[2024-12-17 04:33:07,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:07,781][root][INFO] - Training Epoch: 1/2, step 6747/7134 completed (loss: 0.05302007868885994, acc: 0.991304337978363)
[2024-12-17 04:33:07,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:08,256][root][INFO] - Training Epoch: 1/2, step 6748/7134 completed (loss: 0.027692994102835655, acc: 0.9921082258224487)
[2024-12-17 04:33:08,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:08,726][root][INFO] - Training Epoch: 1/2, step 6749/7134 completed (loss: 0.04029986262321472, acc: 0.9912853837013245)
[2024-12-17 04:33:08,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:09,181][root][INFO] - Training Epoch: 1/2, step 6750/7134 completed (loss: 0.02913280390202999, acc: 0.9919261932373047)
[2024-12-17 04:33:09,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:09,650][root][INFO] - Training Epoch: 1/2, step 6751/7134 completed (loss: 0.021384740248322487, acc: 0.9954338073730469)
[2024-12-17 04:33:09,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:10,065][root][INFO] - Training Epoch: 1/2, step 6752/7134 completed (loss: 0.012921154499053955, acc: 0.9985486268997192)
[2024-12-17 04:33:10,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:10,522][root][INFO] - Training Epoch: 1/2, step 6753/7134 completed (loss: 0.01590207777917385, acc: 0.9965596199035645)
[2024-12-17 04:33:10,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:10,944][root][INFO] - Training Epoch: 1/2, step 6754/7134 completed (loss: 0.01037432812154293, acc: 0.9987951517105103)
[2024-12-17 04:33:11,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:11,387][root][INFO] - Training Epoch: 1/2, step 6755/7134 completed (loss: 0.02020745910704136, acc: 0.9913793206214905)
[2024-12-17 04:33:11,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:11,817][root][INFO] - Training Epoch: 1/2, step 6756/7134 completed (loss: 0.007814666256308556, acc: 0.9973190426826477)
[2024-12-17 04:33:11,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:12,226][root][INFO] - Training Epoch: 1/2, step 6757/7134 completed (loss: 0.017344236373901367, acc: 0.9939024448394775)
[2024-12-17 04:33:12,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:12,657][root][INFO] - Training Epoch: 1/2, step 6758/7134 completed (loss: 0.026889413595199585, acc: 0.9922380447387695)
[2024-12-17 04:33:12,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:13,138][root][INFO] - Training Epoch: 1/2, step 6759/7134 completed (loss: 0.03457721695303917, acc: 0.9932885766029358)
[2024-12-17 04:33:13,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:13,583][root][INFO] - Training Epoch: 1/2, step 6760/7134 completed (loss: 0.060811374336481094, acc: 0.9881889820098877)
[2024-12-17 04:33:13,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:14,015][root][INFO] - Training Epoch: 1/2, step 6761/7134 completed (loss: 0.03936058282852173, acc: 0.9879518151283264)
[2024-12-17 04:33:14,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:14,458][root][INFO] - Training Epoch: 1/2, step 6762/7134 completed (loss: 0.05127635970711708, acc: 0.9865196347236633)
[2024-12-17 04:33:14,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:14,907][root][INFO] - Training Epoch: 1/2, step 6763/7134 completed (loss: 0.03171445056796074, acc: 0.9949811697006226)
[2024-12-17 04:33:15,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:15,312][root][INFO] - Training Epoch: 1/2, step 6764/7134 completed (loss: 0.019466154277324677, acc: 0.9956896305084229)
[2024-12-17 04:33:15,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:15,792][root][INFO] - Training Epoch: 1/2, step 6765/7134 completed (loss: 0.0228731632232666, acc: 0.9946737885475159)
[2024-12-17 04:33:15,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:16,216][root][INFO] - Training Epoch: 1/2, step 6766/7134 completed (loss: 0.016982993111014366, acc: 0.9944827556610107)
[2024-12-17 04:33:16,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:16,578][root][INFO] - Training Epoch: 1/2, step 6767/7134 completed (loss: 0.07330404967069626, acc: 0.9864864945411682)
[2024-12-17 04:33:16,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:17,017][root][INFO] - Training Epoch: 1/2, step 6768/7134 completed (loss: 0.02443823032081127, acc: 0.9923954606056213)
[2024-12-17 04:33:17,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:17,420][root][INFO] - Training Epoch: 1/2, step 6769/7134 completed (loss: 0.02207060158252716, acc: 0.9891975522041321)
[2024-12-17 04:33:17,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:17,866][root][INFO] - Training Epoch: 1/2, step 6770/7134 completed (loss: 0.05709906294941902, acc: 0.982550323009491)
[2024-12-17 04:33:17,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:18,301][root][INFO] - Training Epoch: 1/2, step 6771/7134 completed (loss: 0.04334375634789467, acc: 0.9873816967010498)
[2024-12-17 04:33:18,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:18,725][root][INFO] - Training Epoch: 1/2, step 6772/7134 completed (loss: 0.11080888658761978, acc: 0.9786096215248108)
[2024-12-17 04:33:18,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:19,120][root][INFO] - Training Epoch: 1/2, step 6773/7134 completed (loss: 0.04290531948208809, acc: 0.982594907283783)
[2024-12-17 04:33:19,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:19,544][root][INFO] - Training Epoch: 1/2, step 6774/7134 completed (loss: 0.06784158945083618, acc: 0.9856687784194946)
[2024-12-17 04:33:19,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:19,947][root][INFO] - Training Epoch: 1/2, step 6775/7134 completed (loss: 0.026597794145345688, acc: 0.9905481934547424)
[2024-12-17 04:33:20,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:20,362][root][INFO] - Training Epoch: 1/2, step 6776/7134 completed (loss: 0.04020804911851883, acc: 0.9914893507957458)
[2024-12-17 04:33:20,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:20,776][root][INFO] - Training Epoch: 1/2, step 6777/7134 completed (loss: 0.04378378018736839, acc: 0.9865771532058716)
[2024-12-17 04:33:20,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:21,216][root][INFO] - Training Epoch: 1/2, step 6778/7134 completed (loss: 0.08831840753555298, acc: 0.9762258529663086)
[2024-12-17 04:33:21,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:21,637][root][INFO] - Training Epoch: 1/2, step 6779/7134 completed (loss: 0.029776599258184433, acc: 0.9925373196601868)
[2024-12-17 04:33:21,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:22,061][root][INFO] - Training Epoch: 1/2, step 6780/7134 completed (loss: 0.018384937196969986, acc: 0.9925261735916138)
[2024-12-17 04:33:22,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:22,495][root][INFO] - Training Epoch: 1/2, step 6781/7134 completed (loss: 0.032531268894672394, acc: 0.9880239367485046)
[2024-12-17 04:33:22,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:22,911][root][INFO] - Training Epoch: 1/2, step 6782/7134 completed (loss: 0.03988637030124664, acc: 0.9913194179534912)
[2024-12-17 04:33:23,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:23,278][root][INFO] - Training Epoch: 1/2, step 6783/7134 completed (loss: 0.06173090264201164, acc: 0.9865642786026001)
[2024-12-17 04:33:23,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:23,711][root][INFO] - Training Epoch: 1/2, step 6784/7134 completed (loss: 0.04637005552649498, acc: 0.9883527159690857)
[2024-12-17 04:33:23,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:24,131][root][INFO] - Training Epoch: 1/2, step 6785/7134 completed (loss: 0.0292188860476017, acc: 0.9874213933944702)
[2024-12-17 04:33:24,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:24,580][root][INFO] - Training Epoch: 1/2, step 6786/7134 completed (loss: 0.010008977726101875, acc: 0.9985611438751221)
[2024-12-17 04:33:24,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:25,020][root][INFO] - Training Epoch: 1/2, step 6787/7134 completed (loss: 0.04126602038741112, acc: 0.9855263233184814)
[2024-12-17 04:33:25,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:25,437][root][INFO] - Training Epoch: 1/2, step 6788/7134 completed (loss: 0.03993112966418266, acc: 0.9874100685119629)
[2024-12-17 04:33:25,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:25,832][root][INFO] - Training Epoch: 1/2, step 6789/7134 completed (loss: 0.040445342659950256, acc: 0.9922178983688354)
[2024-12-17 04:33:25,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:26,263][root][INFO] - Training Epoch: 1/2, step 6790/7134 completed (loss: 0.09354440867900848, acc: 0.9784482717514038)
[2024-12-17 04:33:26,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:26,666][root][INFO] - Training Epoch: 1/2, step 6791/7134 completed (loss: 0.022617222741246223, acc: 0.9948892593383789)
[2024-12-17 04:33:26,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:27,081][root][INFO] - Training Epoch: 1/2, step 6792/7134 completed (loss: 0.03124627284705639, acc: 0.988990843296051)
[2024-12-17 04:33:27,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:27,516][root][INFO] - Training Epoch: 1/2, step 6793/7134 completed (loss: 0.03384877368807793, acc: 0.9852320551872253)
[2024-12-17 04:33:27,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:27,932][root][INFO] - Training Epoch: 1/2, step 6794/7134 completed (loss: 0.019184906035661697, acc: 0.9967159032821655)
[2024-12-17 04:33:28,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:28,360][root][INFO] - Training Epoch: 1/2, step 6795/7134 completed (loss: 0.01822243444621563, acc: 0.9948052167892456)
[2024-12-17 04:33:28,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:28,777][root][INFO] - Training Epoch: 1/2, step 6796/7134 completed (loss: 0.0262454804033041, acc: 0.992668628692627)
[2024-12-17 04:33:28,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:29,194][root][INFO] - Training Epoch: 1/2, step 6797/7134 completed (loss: 0.06797140091657639, acc: 0.9825327396392822)
[2024-12-17 04:33:29,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:29,611][root][INFO] - Training Epoch: 1/2, step 6798/7134 completed (loss: 0.04433159530162811, acc: 0.9834710955619812)
[2024-12-17 04:33:29,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:30,026][root][INFO] - Training Epoch: 1/2, step 6799/7134 completed (loss: 0.034347619861364365, acc: 0.9904240965843201)
[2024-12-17 04:33:30,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:30,431][root][INFO] - Training Epoch: 1/2, step 6800/7134 completed (loss: 0.05729323998093605, acc: 0.9861878156661987)
[2024-12-17 04:33:30,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:30,881][root][INFO] - Training Epoch: 1/2, step 6801/7134 completed (loss: 0.05559256300330162, acc: 0.9842519760131836)
[2024-12-17 04:33:30,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:31,295][root][INFO] - Training Epoch: 1/2, step 6802/7134 completed (loss: 0.027914797887206078, acc: 0.9956076145172119)
[2024-12-17 04:33:31,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:31,743][root][INFO] - Training Epoch: 1/2, step 6803/7134 completed (loss: 0.030942076817154884, acc: 0.9861634969711304)
[2024-12-17 04:33:31,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:32,147][root][INFO] - Training Epoch: 1/2, step 6804/7134 completed (loss: 0.030014213174581528, acc: 0.996874988079071)
[2024-12-17 04:33:32,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:32,594][root][INFO] - Training Epoch: 1/2, step 6805/7134 completed (loss: 0.05396386235952377, acc: 0.9871794581413269)
[2024-12-17 04:33:32,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:33,032][root][INFO] - Training Epoch: 1/2, step 6806/7134 completed (loss: 0.058715660125017166, acc: 0.9860759377479553)
[2024-12-17 04:33:33,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:33,499][root][INFO] - Training Epoch: 1/2, step 6807/7134 completed (loss: 0.02852945774793625, acc: 0.9913793206214905)
[2024-12-17 04:33:33,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:33,927][root][INFO] - Training Epoch: 1/2, step 6808/7134 completed (loss: 0.048486195504665375, acc: 0.9840510487556458)
[2024-12-17 04:33:34,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:34,371][root][INFO] - Training Epoch: 1/2, step 6809/7134 completed (loss: 0.06296626478433609, acc: 0.9878048896789551)
[2024-12-17 04:33:34,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:34,789][root][INFO] - Training Epoch: 1/2, step 6810/7134 completed (loss: 0.016057200729846954, acc: 0.9894737005233765)
[2024-12-17 04:33:34,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:35,248][root][INFO] - Training Epoch: 1/2, step 6811/7134 completed (loss: 0.05998162925243378, acc: 0.9829620122909546)
[2024-12-17 04:33:35,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:35,674][root][INFO] - Training Epoch: 1/2, step 6812/7134 completed (loss: 0.04271765798330307, acc: 0.987034022808075)
[2024-12-17 04:33:35,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:36,105][root][INFO] - Training Epoch: 1/2, step 6813/7134 completed (loss: 0.012612835504114628, acc: 0.997183084487915)
[2024-12-17 04:33:36,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:36,536][root][INFO] - Training Epoch: 1/2, step 6814/7134 completed (loss: 0.01789318397641182, acc: 0.9973118305206299)
[2024-12-17 04:33:36,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:36,975][root][INFO] - Training Epoch: 1/2, step 6815/7134 completed (loss: 0.03809352219104767, acc: 0.9894875288009644)
[2024-12-17 04:33:37,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:37,405][root][INFO] - Training Epoch: 1/2, step 6816/7134 completed (loss: 0.0395561046898365, acc: 0.9899665713310242)
[2024-12-17 04:33:37,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:37,849][root][INFO] - Training Epoch: 1/2, step 6817/7134 completed (loss: 0.06528699398040771, acc: 0.9863247871398926)
[2024-12-17 04:33:37,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:38,273][root][INFO] - Training Epoch: 1/2, step 6818/7134 completed (loss: 0.026727136224508286, acc: 0.9940029978752136)
[2024-12-17 04:33:38,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:38,700][root][INFO] - Training Epoch: 1/2, step 6819/7134 completed (loss: 0.06901394575834274, acc: 0.9784172773361206)
[2024-12-17 04:33:38,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:39,115][root][INFO] - Training Epoch: 1/2, step 6820/7134 completed (loss: 0.05120958387851715, acc: 0.9819819927215576)
[2024-12-17 04:33:39,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:39,499][root][INFO] - Training Epoch: 1/2, step 6821/7134 completed (loss: 0.05024118721485138, acc: 0.9878787994384766)
[2024-12-17 04:33:39,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:39,935][root][INFO] - Training Epoch: 1/2, step 6822/7134 completed (loss: 0.05834942311048508, acc: 0.9842932224273682)
[2024-12-17 04:33:40,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:40,365][root][INFO] - Training Epoch: 1/2, step 6823/7134 completed (loss: 0.04317836835980415, acc: 0.9842632412910461)
[2024-12-17 04:33:40,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:40,740][root][INFO] - Training Epoch: 1/2, step 6824/7134 completed (loss: 0.09741879999637604, acc: 0.9677419066429138)
[2024-12-17 04:33:40,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:41,144][root][INFO] - Training Epoch: 1/2, step 6825/7134 completed (loss: 0.03380676358938217, acc: 0.9878048896789551)
[2024-12-17 04:33:41,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:41,549][root][INFO] - Training Epoch: 1/2, step 6826/7134 completed (loss: 0.05502339079976082, acc: 0.9848484992980957)
[2024-12-17 04:33:41,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:41,977][root][INFO] - Training Epoch: 1/2, step 6827/7134 completed (loss: 0.12542477250099182, acc: 0.9703608155250549)
[2024-12-17 04:33:42,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:42,400][root][INFO] - Training Epoch: 1/2, step 6828/7134 completed (loss: 0.06642421334981918, acc: 0.9762773513793945)
[2024-12-17 04:33:42,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:42,837][root][INFO] - Training Epoch: 1/2, step 6829/7134 completed (loss: 0.07514561712741852, acc: 0.9836795330047607)
[2024-12-17 04:33:42,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:43,234][root][INFO] - Training Epoch: 1/2, step 6830/7134 completed (loss: 0.04021134227514267, acc: 0.9901153445243835)
[2024-12-17 04:33:43,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:43,655][root][INFO] - Training Epoch: 1/2, step 6831/7134 completed (loss: 0.05531686916947365, acc: 0.9825268983840942)
[2024-12-17 04:33:43,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:44,063][root][INFO] - Training Epoch: 1/2, step 6832/7134 completed (loss: 0.06328274309635162, acc: 0.9815157055854797)
[2024-12-17 04:33:44,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:44,478][root][INFO] - Training Epoch: 1/2, step 6833/7134 completed (loss: 0.06860578060150146, acc: 0.9855305552482605)
[2024-12-17 04:33:44,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:44,858][root][INFO] - Training Epoch: 1/2, step 6834/7134 completed (loss: 0.07460284978151321, acc: 0.9812606573104858)
[2024-12-17 04:33:44,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:45,274][root][INFO] - Training Epoch: 1/2, step 6835/7134 completed (loss: 0.038044508546590805, acc: 0.9870129823684692)
[2024-12-17 04:33:45,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:45,684][root][INFO] - Training Epoch: 1/2, step 6836/7134 completed (loss: 0.069256491959095, acc: 0.9824120402336121)
[2024-12-17 04:33:45,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:46,132][root][INFO] - Training Epoch: 1/2, step 6837/7134 completed (loss: 0.05090329796075821, acc: 0.9852761030197144)
[2024-12-17 04:33:46,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:46,543][root][INFO] - Training Epoch: 1/2, step 6838/7134 completed (loss: 0.08602994680404663, acc: 0.9757834672927856)
[2024-12-17 04:33:46,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:46,947][root][INFO] - Training Epoch: 1/2, step 6839/7134 completed (loss: 0.10685810446739197, acc: 0.9636963605880737)
[2024-12-17 04:33:47,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:47,351][root][INFO] - Training Epoch: 1/2, step 6840/7134 completed (loss: 0.07595600932836533, acc: 0.9799426794052124)
[2024-12-17 04:33:47,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:47,753][root][INFO] - Training Epoch: 1/2, step 6841/7134 completed (loss: 0.06557907909154892, acc: 0.9783549904823303)
[2024-12-17 04:33:47,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:48,205][root][INFO] - Training Epoch: 1/2, step 6842/7134 completed (loss: 0.05573870614171028, acc: 0.9849624037742615)
[2024-12-17 04:33:48,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:48,676][root][INFO] - Training Epoch: 1/2, step 6843/7134 completed (loss: 0.0789995789527893, acc: 0.9815043210983276)
[2024-12-17 04:33:48,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:49,102][root][INFO] - Training Epoch: 1/2, step 6844/7134 completed (loss: 0.058597907423973083, acc: 0.9827288389205933)
[2024-12-17 04:33:49,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:49,548][root][INFO] - Training Epoch: 1/2, step 6845/7134 completed (loss: 0.043603040277957916, acc: 0.9829931855201721)
[2024-12-17 04:33:49,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:49,973][root][INFO] - Training Epoch: 1/2, step 6846/7134 completed (loss: 0.049419425427913666, acc: 0.9856733679771423)
[2024-12-17 04:33:50,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:50,409][root][INFO] - Training Epoch: 1/2, step 6847/7134 completed (loss: 0.04314222186803818, acc: 0.989393949508667)
[2024-12-17 04:33:50,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:50,803][root][INFO] - Training Epoch: 1/2, step 6848/7134 completed (loss: 0.050655726343393326, acc: 0.9891892075538635)
[2024-12-17 04:33:50,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:51,221][root][INFO] - Training Epoch: 1/2, step 6849/7134 completed (loss: 0.0665169209241867, acc: 0.9845361113548279)
[2024-12-17 04:33:51,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:51,623][root][INFO] - Training Epoch: 1/2, step 6850/7134 completed (loss: 0.045145437121391296, acc: 0.9839816689491272)
[2024-12-17 04:33:51,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:52,061][root][INFO] - Training Epoch: 1/2, step 6851/7134 completed (loss: 0.07881350815296173, acc: 0.9774330258369446)
[2024-12-17 04:33:52,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:52,495][root][INFO] - Training Epoch: 1/2, step 6852/7134 completed (loss: 0.03980844095349312, acc: 0.9930070042610168)
[2024-12-17 04:33:52,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:52,969][root][INFO] - Training Epoch: 1/2, step 6853/7134 completed (loss: 0.04221184179186821, acc: 0.9917012453079224)
[2024-12-17 04:33:53,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:53,356][root][INFO] - Training Epoch: 1/2, step 6854/7134 completed (loss: 0.0295702051371336, acc: 0.9934924244880676)
[2024-12-17 04:33:53,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:53,765][root][INFO] - Training Epoch: 1/2, step 6855/7134 completed (loss: 0.018422909080982208, acc: 1.0)
[2024-12-17 04:33:53,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:54,198][root][INFO] - Training Epoch: 1/2, step 6856/7134 completed (loss: 0.012329697608947754, acc: 0.9985693693161011)
[2024-12-17 04:33:54,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:54,646][root][INFO] - Training Epoch: 1/2, step 6857/7134 completed (loss: 0.051204316318035126, acc: 0.9882698059082031)
[2024-12-17 04:33:54,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:55,057][root][INFO] - Training Epoch: 1/2, step 6858/7134 completed (loss: 0.009308038279414177, acc: 0.9963099360466003)
[2024-12-17 04:33:55,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:55,512][root][INFO] - Training Epoch: 1/2, step 6859/7134 completed (loss: 0.022767210379242897, acc: 0.9935979247093201)
[2024-12-17 04:33:55,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:55,943][root][INFO] - Training Epoch: 1/2, step 6860/7134 completed (loss: 0.02015291340649128, acc: 0.9929078221321106)
[2024-12-17 04:33:56,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:56,356][root][INFO] - Training Epoch: 1/2, step 6861/7134 completed (loss: 0.0201506856828928, acc: 0.9948096871376038)
[2024-12-17 04:33:56,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:56,805][root][INFO] - Training Epoch: 1/2, step 6862/7134 completed (loss: 0.04940468445420265, acc: 0.9866666793823242)
[2024-12-17 04:33:56,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:57,217][root][INFO] - Training Epoch: 1/2, step 6863/7134 completed (loss: 0.01916544698178768, acc: 0.9929378628730774)
[2024-12-17 04:33:57,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:57,664][root][INFO] - Training Epoch: 1/2, step 6864/7134 completed (loss: 0.024085156619548798, acc: 0.9933444261550903)
[2024-12-17 04:33:57,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:58,086][root][INFO] - Training Epoch: 1/2, step 6865/7134 completed (loss: 0.05624290183186531, acc: 0.985567033290863)
[2024-12-17 04:33:58,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:58,503][root][INFO] - Training Epoch: 1/2, step 6866/7134 completed (loss: 0.005449199583381414, acc: 0.9984802603721619)
[2024-12-17 04:33:58,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:58,922][root][INFO] - Training Epoch: 1/2, step 6867/7134 completed (loss: 0.012987958267331123, acc: 0.9944444298744202)
[2024-12-17 04:33:59,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:59,292][root][INFO] - Training Epoch: 1/2, step 6868/7134 completed (loss: 0.009596070274710655, acc: 0.9944598078727722)
[2024-12-17 04:33:59,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:33:59,672][root][INFO] - Training Epoch: 1/2, step 6869/7134 completed (loss: 0.013271133415400982, acc: 0.9957173466682434)
[2024-12-17 04:33:59,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:00,114][root][INFO] - Training Epoch: 1/2, step 6870/7134 completed (loss: 0.036100272089242935, acc: 0.9934853315353394)
[2024-12-17 04:34:00,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:00,563][root][INFO] - Training Epoch: 1/2, step 6871/7134 completed (loss: 0.00815114937722683, acc: 0.9962546825408936)
[2024-12-17 04:34:00,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:00,981][root][INFO] - Training Epoch: 1/2, step 6872/7134 completed (loss: 0.022123701870441437, acc: 0.9916897416114807)
[2024-12-17 04:34:01,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:01,423][root][INFO] - Training Epoch: 1/2, step 6873/7134 completed (loss: 0.015328925102949142, acc: 0.9929971694946289)
[2024-12-17 04:34:01,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:01,850][root][INFO] - Training Epoch: 1/2, step 6874/7134 completed (loss: 0.02223699912428856, acc: 0.9929078221321106)
[2024-12-17 04:34:01,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:02,281][root][INFO] - Training Epoch: 1/2, step 6875/7134 completed (loss: 0.03400639817118645, acc: 0.989180862903595)
[2024-12-17 04:34:02,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:02,709][root][INFO] - Training Epoch: 1/2, step 6876/7134 completed (loss: 0.043979208916425705, acc: 0.989847719669342)
[2024-12-17 04:34:02,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:03,155][root][INFO] - Training Epoch: 1/2, step 6877/7134 completed (loss: 0.027563946321606636, acc: 0.992977499961853)
[2024-12-17 04:34:03,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:03,587][root][INFO] - Training Epoch: 1/2, step 6878/7134 completed (loss: 0.02767658419907093, acc: 0.9940029978752136)
[2024-12-17 04:34:03,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:04,006][root][INFO] - Training Epoch: 1/2, step 6879/7134 completed (loss: 0.033784542232751846, acc: 0.991631805896759)
[2024-12-17 04:34:04,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:04,471][root][INFO] - Training Epoch: 1/2, step 6880/7134 completed (loss: 0.009517375379800797, acc: 0.9965075850486755)
[2024-12-17 04:34:04,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:04,918][root][INFO] - Training Epoch: 1/2, step 6881/7134 completed (loss: 0.054684631526470184, acc: 0.9890643954277039)
[2024-12-17 04:34:05,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:05,310][root][INFO] - Training Epoch: 1/2, step 6882/7134 completed (loss: 0.04505496099591255, acc: 0.9887217879295349)
[2024-12-17 04:34:05,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:05,756][root][INFO] - Training Epoch: 1/2, step 6883/7134 completed (loss: 0.035765036940574646, acc: 0.9917491674423218)
[2024-12-17 04:34:05,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:06,201][root][INFO] - Training Epoch: 1/2, step 6884/7134 completed (loss: 0.05942084640264511, acc: 0.986146092414856)
[2024-12-17 04:34:06,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:06,601][root][INFO] - Training Epoch: 1/2, step 6885/7134 completed (loss: 0.09793807566165924, acc: 0.984375)
[2024-12-17 04:34:06,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:07,066][root][INFO] - Training Epoch: 1/2, step 6886/7134 completed (loss: 0.03270408511161804, acc: 0.9873217344284058)
[2024-12-17 04:34:07,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:07,472][root][INFO] - Training Epoch: 1/2, step 6887/7134 completed (loss: 0.058912649750709534, acc: 0.9856262803077698)
[2024-12-17 04:34:07,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:07,920][root][INFO] - Training Epoch: 1/2, step 6888/7134 completed (loss: 0.026800669729709625, acc: 0.9933554530143738)
[2024-12-17 04:34:08,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:08,354][root][INFO] - Training Epoch: 1/2, step 6889/7134 completed (loss: 0.028993405401706696, acc: 0.992343008518219)
[2024-12-17 04:34:08,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:08,793][root][INFO] - Training Epoch: 1/2, step 6890/7134 completed (loss: 0.03906342759728432, acc: 0.9867899417877197)
[2024-12-17 04:34:08,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:09,210][root][INFO] - Training Epoch: 1/2, step 6891/7134 completed (loss: 0.03677986562252045, acc: 0.9866666793823242)
[2024-12-17 04:34:09,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:09,660][root][INFO] - Training Epoch: 1/2, step 6892/7134 completed (loss: 0.050514135509729385, acc: 0.9895833134651184)
[2024-12-17 04:34:09,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:10,093][root][INFO] - Training Epoch: 1/2, step 6893/7134 completed (loss: 0.06910518556833267, acc: 0.9766355156898499)
[2024-12-17 04:34:10,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:10,533][root][INFO] - Training Epoch: 1/2, step 6894/7134 completed (loss: 0.0752159133553505, acc: 0.9828947186470032)
[2024-12-17 04:34:10,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:10,981][root][INFO] - Training Epoch: 1/2, step 6895/7134 completed (loss: 0.05151382461190224, acc: 0.9796162843704224)
[2024-12-17 04:34:11,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:11,383][root][INFO] - Training Epoch: 1/2, step 6896/7134 completed (loss: 0.029950490221381187, acc: 0.991304337978363)
[2024-12-17 04:34:11,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:11,822][root][INFO] - Training Epoch: 1/2, step 6897/7134 completed (loss: 0.024627113714814186, acc: 0.9950920343399048)
[2024-12-17 04:34:11,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:12,234][root][INFO] - Training Epoch: 1/2, step 6898/7134 completed (loss: 0.024235667660832405, acc: 0.9917582273483276)
[2024-12-17 04:34:12,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:12,684][root][INFO] - Training Epoch: 1/2, step 6899/7134 completed (loss: 0.03156128525733948, acc: 0.9924623370170593)
[2024-12-17 04:34:12,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:13,128][root][INFO] - Training Epoch: 1/2, step 6900/7134 completed (loss: 0.04596661776304245, acc: 0.9787836074829102)
[2024-12-17 04:34:13,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:13,586][root][INFO] - Training Epoch: 1/2, step 6901/7134 completed (loss: 0.05798844248056412, acc: 0.9828269481658936)
[2024-12-17 04:34:13,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:14,058][root][INFO] - Training Epoch: 1/2, step 6902/7134 completed (loss: 0.03776886314153671, acc: 0.9875173568725586)
[2024-12-17 04:34:14,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:14,507][root][INFO] - Training Epoch: 1/2, step 6903/7134 completed (loss: 0.029321692883968353, acc: 0.9885931611061096)
[2024-12-17 04:34:14,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:14,965][root][INFO] - Training Epoch: 1/2, step 6904/7134 completed (loss: 0.01522163487970829, acc: 0.9950248599052429)
[2024-12-17 04:34:15,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:15,460][root][INFO] - Training Epoch: 1/2, step 6905/7134 completed (loss: 0.03640365228056908, acc: 0.9897698163986206)
[2024-12-17 04:34:15,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:15,934][root][INFO] - Training Epoch: 1/2, step 6906/7134 completed (loss: 0.05958022549748421, acc: 0.9892215728759766)
[2024-12-17 04:34:16,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:16,384][root][INFO] - Training Epoch: 1/2, step 6907/7134 completed (loss: 0.05042745918035507, acc: 0.9900744557380676)
[2024-12-17 04:34:16,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:16,822][root][INFO] - Training Epoch: 1/2, step 6908/7134 completed (loss: 0.02853330969810486, acc: 0.9922279715538025)
[2024-12-17 04:34:16,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:17,269][root][INFO] - Training Epoch: 1/2, step 6909/7134 completed (loss: 0.02732446789741516, acc: 0.9934210777282715)
[2024-12-17 04:34:17,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:17,706][root][INFO] - Training Epoch: 1/2, step 6910/7134 completed (loss: 0.030256835743784904, acc: 0.9898089170455933)
[2024-12-17 04:34:17,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:18,093][root][INFO] - Training Epoch: 1/2, step 6911/7134 completed (loss: 0.05874699726700783, acc: 0.9898256063461304)
[2024-12-17 04:34:18,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:18,545][root][INFO] - Training Epoch: 1/2, step 6912/7134 completed (loss: 0.039984509348869324, acc: 0.9925093650817871)
[2024-12-17 04:34:18,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:19,057][root][INFO] - Training Epoch: 1/2, step 6913/7134 completed (loss: 0.04173906892538071, acc: 0.9853836894035339)
[2024-12-17 04:34:19,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:19,480][root][INFO] - Training Epoch: 1/2, step 6914/7134 completed (loss: 0.07524542510509491, acc: 0.9865319728851318)
[2024-12-17 04:34:19,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:19,927][root][INFO] - Training Epoch: 1/2, step 6915/7134 completed (loss: 0.014722706750035286, acc: 0.9987046718597412)
[2024-12-17 04:34:20,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:20,386][root][INFO] - Training Epoch: 1/2, step 6916/7134 completed (loss: 0.042820293456315994, acc: 0.987730085849762)
[2024-12-17 04:34:20,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:20,867][root][INFO] - Training Epoch: 1/2, step 6917/7134 completed (loss: 0.07233618944883347, acc: 0.9823232293128967)
[2024-12-17 04:34:20,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:21,300][root][INFO] - Training Epoch: 1/2, step 6918/7134 completed (loss: 0.052678659558296204, acc: 0.9882903695106506)
[2024-12-17 04:34:21,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:21,740][root][INFO] - Training Epoch: 1/2, step 6919/7134 completed (loss: 0.046049538999795914, acc: 0.9896193742752075)
[2024-12-17 04:34:21,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:22,154][root][INFO] - Training Epoch: 1/2, step 6920/7134 completed (loss: 0.04160798341035843, acc: 0.9871794581413269)
[2024-12-17 04:34:22,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:22,622][root][INFO] - Training Epoch: 1/2, step 6921/7134 completed (loss: 0.07390086352825165, acc: 0.980369508266449)
[2024-12-17 04:34:22,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:23,021][root][INFO] - Training Epoch: 1/2, step 6922/7134 completed (loss: 0.07509427517652512, acc: 0.9828392863273621)
[2024-12-17 04:34:23,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:23,490][root][INFO] - Training Epoch: 1/2, step 6923/7134 completed (loss: 0.07035600394010544, acc: 0.9844357967376709)
[2024-12-17 04:34:23,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:23,934][root][INFO] - Training Epoch: 1/2, step 6924/7134 completed (loss: 0.051385775208473206, acc: 0.9863760471343994)
[2024-12-17 04:34:24,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:24,388][root][INFO] - Training Epoch: 1/2, step 6925/7134 completed (loss: 0.023667508736252785, acc: 0.9895833134651184)
[2024-12-17 04:34:24,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:24,821][root][INFO] - Training Epoch: 1/2, step 6926/7134 completed (loss: 0.0419122539460659, acc: 0.9855334758758545)
[2024-12-17 04:34:24,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:25,292][root][INFO] - Training Epoch: 1/2, step 6927/7134 completed (loss: 0.0802081972360611, acc: 0.9796162843704224)
[2024-12-17 04:34:25,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:25,702][root][INFO] - Training Epoch: 1/2, step 6928/7134 completed (loss: 0.08908481895923615, acc: 0.976516604423523)
[2024-12-17 04:34:25,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:26,199][root][INFO] - Training Epoch: 1/2, step 6929/7134 completed (loss: 0.06117262691259384, acc: 0.9887005686759949)
[2024-12-17 04:34:26,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:26,683][root][INFO] - Training Epoch: 1/2, step 6930/7134 completed (loss: 0.07893624901771545, acc: 0.985111653804779)
[2024-12-17 04:34:26,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:27,148][root][INFO] - Training Epoch: 1/2, step 6931/7134 completed (loss: 0.03955616056919098, acc: 0.992682933807373)
[2024-12-17 04:34:27,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:27,545][root][INFO] - Training Epoch: 1/2, step 6932/7134 completed (loss: 0.047375209629535675, acc: 0.9838235378265381)
[2024-12-17 04:34:27,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:27,983][root][INFO] - Training Epoch: 1/2, step 6933/7134 completed (loss: 0.08206493407487869, acc: 0.9780077338218689)
[2024-12-17 04:34:28,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:28,380][root][INFO] - Training Epoch: 1/2, step 6934/7134 completed (loss: 0.08233881741762161, acc: 0.9759229421615601)
[2024-12-17 04:34:28,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:28,844][root][INFO] - Training Epoch: 1/2, step 6935/7134 completed (loss: 0.05188192054629326, acc: 0.9895287752151489)
[2024-12-17 04:34:28,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:29,301][root][INFO] - Training Epoch: 1/2, step 6936/7134 completed (loss: 0.036156538873910904, acc: 0.9866666793823242)
[2024-12-17 04:34:29,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:29,726][root][INFO] - Training Epoch: 1/2, step 6937/7134 completed (loss: 0.144618958234787, acc: 0.9632224440574646)
[2024-12-17 04:34:29,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:30,173][root][INFO] - Training Epoch: 1/2, step 6938/7134 completed (loss: 0.11996731907129288, acc: 0.9703124761581421)
[2024-12-17 04:34:30,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:30,647][root][INFO] - Training Epoch: 1/2, step 6939/7134 completed (loss: 0.09403146803379059, acc: 0.9847009778022766)
[2024-12-17 04:34:30,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:31,064][root][INFO] - Training Epoch: 1/2, step 6940/7134 completed (loss: 0.0980488732457161, acc: 0.9743150472640991)
[2024-12-17 04:34:31,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:31,447][root][INFO] - Training Epoch: 1/2, step 6941/7134 completed (loss: 0.047679558396339417, acc: 0.9826388955116272)
[2024-12-17 04:34:31,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:31,866][root][INFO] - Training Epoch: 1/2, step 6942/7134 completed (loss: 0.06602587550878525, acc: 0.9780821800231934)
[2024-12-17 04:34:32,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:32,279][root][INFO] - Training Epoch: 1/2, step 6943/7134 completed (loss: 0.06257780641317368, acc: 0.9832636117935181)
[2024-12-17 04:34:32,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:32,741][root][INFO] - Training Epoch: 1/2, step 6944/7134 completed (loss: 0.04246906563639641, acc: 0.9888535141944885)
[2024-12-17 04:34:32,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:33,125][root][INFO] - Training Epoch: 1/2, step 6945/7134 completed (loss: 0.09121569991111755, acc: 0.9773123860359192)
[2024-12-17 04:34:33,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:33,505][root][INFO] - Training Epoch: 1/2, step 6946/7134 completed (loss: 0.04335116595029831, acc: 0.982807993888855)
[2024-12-17 04:34:33,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:33,916][root][INFO] - Training Epoch: 1/2, step 6947/7134 completed (loss: 0.05051445588469505, acc: 0.9847826361656189)
[2024-12-17 04:34:34,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:34,355][root][INFO] - Training Epoch: 1/2, step 6948/7134 completed (loss: 0.07086700201034546, acc: 0.9782244563102722)
[2024-12-17 04:34:34,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:34,766][root][INFO] - Training Epoch: 1/2, step 6949/7134 completed (loss: 0.08017541468143463, acc: 0.9786324501037598)
[2024-12-17 04:34:34,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:35,123][root][INFO] - Training Epoch: 1/2, step 6950/7134 completed (loss: 0.037934187799692154, acc: 0.9897959232330322)
[2024-12-17 04:34:35,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:35,542][root][INFO] - Training Epoch: 1/2, step 6951/7134 completed (loss: 0.033867187798023224, acc: 0.991525411605835)
[2024-12-17 04:34:35,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:35,892][root][INFO] - Training Epoch: 1/2, step 6952/7134 completed (loss: 0.02547607757151127, acc: 0.9929906725883484)
[2024-12-17 04:34:35,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:36,291][root][INFO] - Training Epoch: 1/2, step 6953/7134 completed (loss: 0.020503399893641472, acc: 0.9950819611549377)
[2024-12-17 04:34:36,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:36,694][root][INFO] - Training Epoch: 1/2, step 6954/7134 completed (loss: 0.07880735397338867, acc: 0.9829424023628235)
[2024-12-17 04:34:36,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:37,068][root][INFO] - Training Epoch: 1/2, step 6955/7134 completed (loss: 0.06848584115505219, acc: 0.9756097793579102)
[2024-12-17 04:34:37,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:37,515][root][INFO] - Training Epoch: 1/2, step 6956/7134 completed (loss: 0.05012848600745201, acc: 0.9893428087234497)
[2024-12-17 04:34:37,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:37,964][root][INFO] - Training Epoch: 1/2, step 6957/7134 completed (loss: 0.028182191774249077, acc: 0.9941291809082031)
[2024-12-17 04:34:38,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:38,384][root][INFO] - Training Epoch: 1/2, step 6958/7134 completed (loss: 0.0660281777381897, acc: 0.9805068373680115)
[2024-12-17 04:34:38,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:38,806][root][INFO] - Training Epoch: 1/2, step 6959/7134 completed (loss: 0.050265729427337646, acc: 0.9822616577148438)
[2024-12-17 04:34:38,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:39,212][root][INFO] - Training Epoch: 1/2, step 6960/7134 completed (loss: 0.05032312870025635, acc: 0.9869918823242188)
[2024-12-17 04:34:39,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:39,625][root][INFO] - Training Epoch: 1/2, step 6961/7134 completed (loss: 0.031248683109879494, acc: 0.9939393997192383)
[2024-12-17 04:34:39,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:40,043][root][INFO] - Training Epoch: 1/2, step 6962/7134 completed (loss: 0.03416658937931061, acc: 0.9930434823036194)
[2024-12-17 04:34:40,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:40,457][root][INFO] - Training Epoch: 1/2, step 6963/7134 completed (loss: 0.02852567657828331, acc: 0.9915825128555298)
[2024-12-17 04:34:40,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:40,867][root][INFO] - Training Epoch: 1/2, step 6964/7134 completed (loss: 0.04095551371574402, acc: 0.987364649772644)
[2024-12-17 04:34:40,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:41,279][root][INFO] - Training Epoch: 1/2, step 6965/7134 completed (loss: 0.024454552680253983, acc: 0.9926739931106567)
[2024-12-17 04:34:41,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:41,676][root][INFO] - Training Epoch: 1/2, step 6966/7134 completed (loss: 0.08161763846874237, acc: 0.9725685715675354)
[2024-12-17 04:34:41,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:42,082][root][INFO] - Training Epoch: 1/2, step 6967/7134 completed (loss: 0.026016339659690857, acc: 0.9924585223197937)
[2024-12-17 04:34:42,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:42,491][root][INFO] - Training Epoch: 1/2, step 6968/7134 completed (loss: 0.04125960171222687, acc: 0.9879310131072998)
[2024-12-17 04:34:42,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:42,895][root][INFO] - Training Epoch: 1/2, step 6969/7134 completed (loss: 0.0860363021492958, acc: 0.975051999092102)
[2024-12-17 04:34:43,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:43,309][root][INFO] - Training Epoch: 1/2, step 6970/7134 completed (loss: 0.08414635062217712, acc: 0.9810526371002197)
[2024-12-17 04:34:43,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:43,732][root][INFO] - Training Epoch: 1/2, step 6971/7134 completed (loss: 0.09839938580989838, acc: 0.9740932583808899)
[2024-12-17 04:34:43,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:44,145][root][INFO] - Training Epoch: 1/2, step 6972/7134 completed (loss: 0.026529991999268532, acc: 0.9910873174667358)
[2024-12-17 04:34:44,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:44,537][root][INFO] - Training Epoch: 1/2, step 6973/7134 completed (loss: 0.04865594953298569, acc: 0.9867841601371765)
[2024-12-17 04:34:44,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:44,937][root][INFO] - Training Epoch: 1/2, step 6974/7134 completed (loss: 0.037618234753608704, acc: 0.9879310131072998)
[2024-12-17 04:34:45,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:45,329][root][INFO] - Training Epoch: 1/2, step 6975/7134 completed (loss: 0.05708686634898186, acc: 0.989154040813446)
[2024-12-17 04:34:45,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:45,741][root][INFO] - Training Epoch: 1/2, step 6976/7134 completed (loss: 0.06068570539355278, acc: 0.9774696826934814)
[2024-12-17 04:34:45,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:46,141][root][INFO] - Training Epoch: 1/2, step 6977/7134 completed (loss: 0.04651803895831108, acc: 0.9868420958518982)
[2024-12-17 04:34:46,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:46,566][root][INFO] - Training Epoch: 1/2, step 6978/7134 completed (loss: 0.05261293053627014, acc: 0.9886178970336914)
[2024-12-17 04:34:46,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:47,011][root][INFO] - Training Epoch: 1/2, step 6979/7134 completed (loss: 0.07253733277320862, acc: 0.9725610017776489)
[2024-12-17 04:34:47,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:47,462][root][INFO] - Training Epoch: 1/2, step 6980/7134 completed (loss: 0.14943909645080566, acc: 0.9685534834861755)
[2024-12-17 04:34:47,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:47,922][root][INFO] - Training Epoch: 1/2, step 6981/7134 completed (loss: 0.10473408550024033, acc: 0.969348669052124)
[2024-12-17 04:34:48,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:48,390][root][INFO] - Training Epoch: 1/2, step 6982/7134 completed (loss: 0.11475449800491333, acc: 0.9756394624710083)
[2024-12-17 04:34:48,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:48,839][root][INFO] - Training Epoch: 1/2, step 6983/7134 completed (loss: 0.11869001388549805, acc: 0.9762611389160156)
[2024-12-17 04:34:48,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:49,290][root][INFO] - Training Epoch: 1/2, step 6984/7134 completed (loss: 0.05115717276930809, acc: 0.9871382713317871)
[2024-12-17 04:34:49,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:49,773][root][INFO] - Training Epoch: 1/2, step 6985/7134 completed (loss: 0.11720302700996399, acc: 0.9712820649147034)
[2024-12-17 04:34:49,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:50,224][root][INFO] - Training Epoch: 1/2, step 6986/7134 completed (loss: 0.05592171475291252, acc: 0.9806835055351257)
[2024-12-17 04:34:50,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:50,708][root][INFO] - Training Epoch: 1/2, step 6987/7134 completed (loss: 0.08788537979125977, acc: 0.9696969985961914)
[2024-12-17 04:34:50,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:51,081][root][INFO] - Training Epoch: 1/2, step 6988/7134 completed (loss: 0.05659879744052887, acc: 0.9821073412895203)
[2024-12-17 04:34:51,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:51,476][root][INFO] - Training Epoch: 1/2, step 6989/7134 completed (loss: 0.1192418709397316, acc: 0.9599999785423279)
[2024-12-17 04:34:51,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:51,865][root][INFO] - Training Epoch: 1/2, step 6990/7134 completed (loss: 0.0530393160879612, acc: 0.9866071343421936)
[2024-12-17 04:34:51,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:52,213][root][INFO] - Training Epoch: 1/2, step 6991/7134 completed (loss: 0.07267598062753677, acc: 0.9849624037742615)
[2024-12-17 04:34:52,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:52,585][root][INFO] - Training Epoch: 1/2, step 6992/7134 completed (loss: 0.08573003113269806, acc: 0.9789473414421082)
[2024-12-17 04:34:52,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:53,017][root][INFO] - Training Epoch: 1/2, step 6993/7134 completed (loss: 0.13279733061790466, acc: 0.965309202671051)
[2024-12-17 04:34:53,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:53,493][root][INFO] - Training Epoch: 1/2, step 6994/7134 completed (loss: 0.13691064715385437, acc: 0.9695023894309998)
[2024-12-17 04:34:53,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:53,931][root][INFO] - Training Epoch: 1/2, step 6995/7134 completed (loss: 0.06352691352367401, acc: 0.985602080821991)
[2024-12-17 04:34:54,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:54,341][root][INFO] - Training Epoch: 1/2, step 6996/7134 completed (loss: 0.042517486959695816, acc: 0.9886363744735718)
[2024-12-17 04:34:54,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:54,752][root][INFO] - Training Epoch: 1/2, step 6997/7134 completed (loss: 0.06597751379013062, acc: 0.9875389337539673)
[2024-12-17 04:34:54,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:55,089][root][INFO] - Training Epoch: 1/2, step 6998/7134 completed (loss: 0.1280316412448883, acc: 0.970588207244873)
[2024-12-17 04:34:55,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:55,552][root][INFO] - Training Epoch: 1/2, step 6999/7134 completed (loss: 0.03813893720507622, acc: 0.9882352948188782)
[2024-12-17 04:34:55,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:55,884][root][INFO] - Training Epoch: 1/2, step 7000/7134 completed (loss: 0.052449747920036316, acc: 0.9851694703102112)
[2024-12-17 04:34:55,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:56,320][root][INFO] - Training Epoch: 1/2, step 7001/7134 completed (loss: 0.10909555107355118, acc: 0.9774096608161926)
[2024-12-17 04:34:56,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:56,771][root][INFO] - Training Epoch: 1/2, step 7002/7134 completed (loss: 0.03125501424074173, acc: 0.9959431886672974)
[2024-12-17 04:34:56,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:57,218][root][INFO] - Training Epoch: 1/2, step 7003/7134 completed (loss: 0.040980637073516846, acc: 0.9868565201759338)
[2024-12-17 04:34:57,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:57,676][root][INFO] - Training Epoch: 1/2, step 7004/7134 completed (loss: 0.09263619035482407, acc: 0.9803149700164795)
[2024-12-17 04:34:57,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:58,138][root][INFO] - Training Epoch: 1/2, step 7005/7134 completed (loss: 0.0686616599559784, acc: 0.9784075617790222)
[2024-12-17 04:34:58,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:58,590][root][INFO] - Training Epoch: 1/2, step 7006/7134 completed (loss: 0.04865136370062828, acc: 0.9876881241798401)
[2024-12-17 04:34:58,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:59,032][root][INFO] - Training Epoch: 1/2, step 7007/7134 completed (loss: 0.05351511389017105, acc: 0.985029935836792)
[2024-12-17 04:34:59,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:59,462][root][INFO] - Training Epoch: 1/2, step 7008/7134 completed (loss: 0.04584936425089836, acc: 0.9852034449577332)
[2024-12-17 04:34:59,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:34:59,916][root][INFO] - Training Epoch: 1/2, step 7009/7134 completed (loss: 0.05435957759618759, acc: 0.9803240895271301)
[2024-12-17 04:35:00,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:00,327][root][INFO] - Training Epoch: 1/2, step 7010/7134 completed (loss: 0.03918154165148735, acc: 0.9892141819000244)
[2024-12-17 04:35:00,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:00,786][root][INFO] - Training Epoch: 1/2, step 7011/7134 completed (loss: 0.04482957348227501, acc: 0.9855769276618958)
[2024-12-17 04:35:00,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:01,188][root][INFO] - Training Epoch: 1/2, step 7012/7134 completed (loss: 0.07800103724002838, acc: 0.9854227304458618)
[2024-12-17 04:35:01,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:01,646][root][INFO] - Training Epoch: 1/2, step 7013/7134 completed (loss: 0.016592131927609444, acc: 0.9913544654846191)
[2024-12-17 04:35:01,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:02,059][root][INFO] - Training Epoch: 1/2, step 7014/7134 completed (loss: 0.04152913764119148, acc: 0.9935587644577026)
[2024-12-17 04:35:02,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:02,463][root][INFO] - Training Epoch: 1/2, step 7015/7134 completed (loss: 0.041399162262678146, acc: 0.9821109175682068)
[2024-12-17 04:35:02,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:02,921][root][INFO] - Training Epoch: 1/2, step 7016/7134 completed (loss: 0.07050535082817078, acc: 0.9754335284233093)
[2024-12-17 04:35:03,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:03,282][root][INFO] - Training Epoch: 1/2, step 7017/7134 completed (loss: 0.04997885227203369, acc: 0.9834024906158447)
[2024-12-17 04:35:03,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:03,701][root][INFO] - Training Epoch: 1/2, step 7018/7134 completed (loss: 0.05793396756052971, acc: 0.9891473054885864)
[2024-12-17 04:35:03,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:04,092][root][INFO] - Training Epoch: 1/2, step 7019/7134 completed (loss: 0.13675832748413086, acc: 0.9678362607955933)
[2024-12-17 04:35:04,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:04,499][root][INFO] - Training Epoch: 1/2, step 7020/7134 completed (loss: 0.034313999116420746, acc: 0.9901269674301147)
[2024-12-17 04:35:04,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:04,968][root][INFO] - Training Epoch: 1/2, step 7021/7134 completed (loss: 0.04219648987054825, acc: 0.9880749583244324)
[2024-12-17 04:35:05,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:05,364][root][INFO] - Training Epoch: 1/2, step 7022/7134 completed (loss: 0.16480495035648346, acc: 0.9537037014961243)
[2024-12-17 04:35:05,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:05,747][root][INFO] - Training Epoch: 1/2, step 7023/7134 completed (loss: 0.10794167220592499, acc: 0.9713603854179382)
[2024-12-17 04:35:05,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:06,099][root][INFO] - Training Epoch: 1/2, step 7024/7134 completed (loss: 0.04729819297790527, acc: 0.987261176109314)
[2024-12-17 04:35:06,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:06,500][root][INFO] - Training Epoch: 1/2, step 7025/7134 completed (loss: 0.1615559607744217, acc: 0.9586206674575806)
[2024-12-17 04:35:06,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:06,892][root][INFO] - Training Epoch: 1/2, step 7026/7134 completed (loss: 0.1402057409286499, acc: 0.9575289487838745)
[2024-12-17 04:35:07,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:07,267][root][INFO] - Training Epoch: 1/2, step 7027/7134 completed (loss: 0.05134131759405136, acc: 0.9817073345184326)
[2024-12-17 04:35:07,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:07,691][root][INFO] - Training Epoch: 1/2, step 7028/7134 completed (loss: 0.03450823947787285, acc: 0.9927361011505127)
[2024-12-17 04:35:07,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:08,064][root][INFO] - Training Epoch: 1/2, step 7029/7134 completed (loss: 0.038096170872449875, acc: 0.988399088382721)
[2024-12-17 04:35:08,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:08,459][root][INFO] - Training Epoch: 1/2, step 7030/7134 completed (loss: 0.15786732733249664, acc: 0.971563994884491)
[2024-12-17 04:35:08,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:08,856][root][INFO] - Training Epoch: 1/2, step 7031/7134 completed (loss: 0.09412162005901337, acc: 0.9695431590080261)
[2024-12-17 04:35:08,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:09,220][root][INFO] - Training Epoch: 1/2, step 7032/7134 completed (loss: 0.1159827783703804, acc: 0.9620596170425415)
[2024-12-17 04:35:09,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:09,583][root][INFO] - Training Epoch: 1/2, step 7033/7134 completed (loss: 0.07092738151550293, acc: 0.9765396118164062)
[2024-12-17 04:35:09,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:09,980][root][INFO] - Training Epoch: 1/2, step 7034/7134 completed (loss: 0.123515285551548, acc: 0.9646643400192261)
[2024-12-17 04:35:10,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:10,383][root][INFO] - Training Epoch: 1/2, step 7035/7134 completed (loss: 0.13307462632656097, acc: 0.9642857313156128)
[2024-12-17 04:35:10,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:10,739][root][INFO] - Training Epoch: 1/2, step 7036/7134 completed (loss: 0.07561156898736954, acc: 0.9711934328079224)
[2024-12-17 04:35:10,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:11,087][root][INFO] - Training Epoch: 1/2, step 7037/7134 completed (loss: 0.06327962130308151, acc: 0.96875)
[2024-12-17 04:35:11,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:11,479][root][INFO] - Training Epoch: 1/2, step 7038/7134 completed (loss: 0.14433419704437256, acc: 0.9498680830001831)
[2024-12-17 04:35:11,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:11,890][root][INFO] - Training Epoch: 1/2, step 7039/7134 completed (loss: 0.054917797446250916, acc: 0.9855072498321533)
[2024-12-17 04:35:11,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:12,266][root][INFO] - Training Epoch: 1/2, step 7040/7134 completed (loss: 0.1819208413362503, acc: 0.9396551847457886)
[2024-12-17 04:35:12,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:12,636][root][INFO] - Training Epoch: 1/2, step 7041/7134 completed (loss: 0.13995079696178436, acc: 0.9496855139732361)
[2024-12-17 04:35:12,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:13,025][root][INFO] - Training Epoch: 1/2, step 7042/7134 completed (loss: 0.11014425754547119, acc: 0.9692307710647583)
[2024-12-17 04:35:13,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:13,386][root][INFO] - Training Epoch: 1/2, step 7043/7134 completed (loss: 0.12153521925210953, acc: 0.9653333425521851)
[2024-12-17 04:35:13,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:13,758][root][INFO] - Training Epoch: 1/2, step 7044/7134 completed (loss: 0.12208757549524307, acc: 0.9602446556091309)
[2024-12-17 04:35:13,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:14,172][root][INFO] - Training Epoch: 1/2, step 7045/7134 completed (loss: 0.037875548005104065, acc: 0.988095223903656)
[2024-12-17 04:35:14,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:14,628][root][INFO] - Training Epoch: 1/2, step 7046/7134 completed (loss: 0.09594760835170746, acc: 0.9740437269210815)
[2024-12-17 04:35:14,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:15,072][root][INFO] - Training Epoch: 1/2, step 7047/7134 completed (loss: 0.09210130572319031, acc: 0.9726190567016602)
[2024-12-17 04:35:15,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:15,512][root][INFO] - Training Epoch: 1/2, step 7048/7134 completed (loss: 0.01495406311005354, acc: 0.9964747428894043)
[2024-12-17 04:35:15,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:15,965][root][INFO] - Training Epoch: 1/2, step 7049/7134 completed (loss: 0.04143073409795761, acc: 0.9879679083824158)
[2024-12-17 04:35:16,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:16,386][root][INFO] - Training Epoch: 1/2, step 7050/7134 completed (loss: 0.03955766186118126, acc: 0.9883419871330261)
[2024-12-17 04:35:16,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:16,836][root][INFO] - Training Epoch: 1/2, step 7051/7134 completed (loss: 0.0727720558643341, acc: 0.983565092086792)
[2024-12-17 04:35:16,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:17,290][root][INFO] - Training Epoch: 1/2, step 7052/7134 completed (loss: 0.059035249054431915, acc: 0.9840213060379028)
[2024-12-17 04:35:17,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:17,763][root][INFO] - Training Epoch: 1/2, step 7053/7134 completed (loss: 0.03194988891482353, acc: 0.9939098954200745)
[2024-12-17 04:35:17,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:18,221][root][INFO] - Training Epoch: 1/2, step 7054/7134 completed (loss: 0.06828133761882782, acc: 0.9810126423835754)
[2024-12-17 04:35:18,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:18,670][root][INFO] - Training Epoch: 1/2, step 7055/7134 completed (loss: 0.03913838416337967, acc: 0.9859693646430969)
[2024-12-17 04:35:18,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:19,142][root][INFO] - Training Epoch: 1/2, step 7056/7134 completed (loss: 0.06221719831228256, acc: 0.9795918464660645)
[2024-12-17 04:35:19,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:19,606][root][INFO] - Training Epoch: 1/2, step 7057/7134 completed (loss: 0.13653236627578735, acc: 0.9712328910827637)
[2024-12-17 04:35:19,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:20,048][root][INFO] - Training Epoch: 1/2, step 7058/7134 completed (loss: 0.09809204936027527, acc: 0.9685039520263672)
[2024-12-17 04:35:20,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:20,479][root][INFO] - Training Epoch: 1/2, step 7059/7134 completed (loss: 0.022970732301473618, acc: 0.994413435459137)
[2024-12-17 04:35:20,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:20,897][root][INFO] - Training Epoch: 1/2, step 7060/7134 completed (loss: 0.08448775857686996, acc: 0.977419376373291)
[2024-12-17 04:35:21,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:21,332][root][INFO] - Training Epoch: 1/2, step 7061/7134 completed (loss: 0.050811219960451126, acc: 0.984375)
[2024-12-17 04:35:21,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:21,754][root][INFO] - Training Epoch: 1/2, step 7062/7134 completed (loss: 0.12802602350711823, acc: 0.9688888788223267)
[2024-12-17 04:35:21,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:22,190][root][INFO] - Training Epoch: 1/2, step 7063/7134 completed (loss: 0.08028854429721832, acc: 0.9830065369606018)
[2024-12-17 04:35:22,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:22,661][root][INFO] - Training Epoch: 1/2, step 7064/7134 completed (loss: 0.03635978698730469, acc: 0.9896142482757568)
[2024-12-17 04:35:22,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:23,112][root][INFO] - Training Epoch: 1/2, step 7065/7134 completed (loss: 0.031122056767344475, acc: 0.9918887615203857)
[2024-12-17 04:35:23,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:23,574][root][INFO] - Training Epoch: 1/2, step 7066/7134 completed (loss: 0.03690212965011597, acc: 0.9916765689849854)
[2024-12-17 04:35:23,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:24,011][root][INFO] - Training Epoch: 1/2, step 7067/7134 completed (loss: 0.03859630227088928, acc: 0.9859872460365295)
[2024-12-17 04:35:24,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:24,475][root][INFO] - Training Epoch: 1/2, step 7068/7134 completed (loss: 0.02929631620645523, acc: 0.9903498291969299)
[2024-12-17 04:35:24,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:24,958][root][INFO] - Training Epoch: 1/2, step 7069/7134 completed (loss: 0.031860534101724625, acc: 0.990138053894043)
[2024-12-17 04:35:25,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:25,394][root][INFO] - Training Epoch: 1/2, step 7070/7134 completed (loss: 0.03126092255115509, acc: 0.9945130348205566)
[2024-12-17 04:35:25,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:25,821][root][INFO] - Training Epoch: 1/2, step 7071/7134 completed (loss: 0.06541751325130463, acc: 0.9887217879295349)
[2024-12-17 04:35:25,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:26,257][root][INFO] - Training Epoch: 1/2, step 7072/7134 completed (loss: 0.04982783645391464, acc: 0.9842424392700195)
[2024-12-17 04:35:26,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:26,730][root][INFO] - Training Epoch: 1/2, step 7073/7134 completed (loss: 0.041556164622306824, acc: 0.9863481521606445)
[2024-12-17 04:35:26,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:27,120][root][INFO] - Training Epoch: 1/2, step 7074/7134 completed (loss: 0.053506895899772644, acc: 0.9866156578063965)
[2024-12-17 04:35:27,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:27,547][root][INFO] - Training Epoch: 1/2, step 7075/7134 completed (loss: 0.03420304134488106, acc: 0.9865471124649048)
[2024-12-17 04:35:27,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:27,945][root][INFO] - Training Epoch: 1/2, step 7076/7134 completed (loss: 0.07752497494220734, acc: 0.9743589758872986)
[2024-12-17 04:35:28,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:28,335][root][INFO] - Training Epoch: 1/2, step 7077/7134 completed (loss: 0.05933167040348053, acc: 0.980327844619751)
[2024-12-17 04:35:28,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:28,756][root][INFO] - Training Epoch: 1/2, step 7078/7134 completed (loss: 0.03763198107481003, acc: 0.9839743375778198)
[2024-12-17 04:35:28,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:29,150][root][INFO] - Training Epoch: 1/2, step 7079/7134 completed (loss: 0.05313347280025482, acc: 0.9802955389022827)
[2024-12-17 04:35:29,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:29,540][root][INFO] - Training Epoch: 1/2, step 7080/7134 completed (loss: 0.04902147501707077, acc: 0.985049843788147)
[2024-12-17 04:35:29,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:29,975][root][INFO] - Training Epoch: 1/2, step 7081/7134 completed (loss: 0.05349603667855263, acc: 0.9845722317695618)
[2024-12-17 04:35:30,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:30,391][root][INFO] - Training Epoch: 1/2, step 7082/7134 completed (loss: 0.04948960244655609, acc: 0.9822294116020203)
[2024-12-17 04:35:30,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:30,803][root][INFO] - Training Epoch: 1/2, step 7083/7134 completed (loss: 0.024786578491330147, acc: 0.9933110475540161)
[2024-12-17 04:35:30,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:31,223][root][INFO] - Training Epoch: 1/2, step 7084/7134 completed (loss: 0.05040436610579491, acc: 0.9869375824928284)
[2024-12-17 04:35:31,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:31,626][root][INFO] - Training Epoch: 1/2, step 7085/7134 completed (loss: 0.06047211214900017, acc: 0.9876543283462524)
[2024-12-17 04:35:31,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:32,059][root][INFO] - Training Epoch: 1/2, step 7086/7134 completed (loss: 0.048419393599033356, acc: 0.9849520921707153)
[2024-12-17 04:35:32,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:32,470][root][INFO] - Training Epoch: 1/2, step 7087/7134 completed (loss: 0.04520029202103615, acc: 0.9889094233512878)
[2024-12-17 04:35:32,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:32,889][root][INFO] - Training Epoch: 1/2, step 7088/7134 completed (loss: 0.06300103664398193, acc: 0.9850993156433105)
[2024-12-17 04:35:32,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:33,298][root][INFO] - Training Epoch: 1/2, step 7089/7134 completed (loss: 0.1126687228679657, acc: 0.977707028388977)
[2024-12-17 04:35:33,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:33,728][root][INFO] - Training Epoch: 1/2, step 7090/7134 completed (loss: 0.03706232085824013, acc: 0.989159882068634)
[2024-12-17 04:35:33,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:34,141][root][INFO] - Training Epoch: 1/2, step 7091/7134 completed (loss: 0.011492040939629078, acc: 0.9944289922714233)
[2024-12-17 04:35:34,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:34,568][root][INFO] - Training Epoch: 1/2, step 7092/7134 completed (loss: 0.05325164645910263, acc: 0.9811320900917053)
[2024-12-17 04:35:34,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:34,937][root][INFO] - Training Epoch: 1/2, step 7093/7134 completed (loss: 0.07976566255092621, acc: 0.9722222089767456)
[2024-12-17 04:35:35,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:35,335][root][INFO] - Training Epoch: 1/2, step 7094/7134 completed (loss: 0.032575733959674835, acc: 0.9884792566299438)
[2024-12-17 04:35:35,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:35,744][root][INFO] - Training Epoch: 1/2, step 7095/7134 completed (loss: 0.03842815384268761, acc: 0.9917355179786682)
[2024-12-17 04:35:35,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:36,139][root][INFO] - Training Epoch: 1/2, step 7096/7134 completed (loss: 0.06292086839675903, acc: 0.9848739504814148)
[2024-12-17 04:35:36,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:36,560][root][INFO] - Training Epoch: 1/2, step 7097/7134 completed (loss: 0.06920591741800308, acc: 0.9812679886817932)
[2024-12-17 04:35:36,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:36,967][root][INFO] - Training Epoch: 1/2, step 7098/7134 completed (loss: 0.03482037037611008, acc: 0.9871588945388794)
[2024-12-17 04:35:37,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:37,335][root][INFO] - Training Epoch: 1/2, step 7099/7134 completed (loss: 0.053988683968782425, acc: 0.9846153855323792)
[2024-12-17 04:35:37,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:37,750][root][INFO] - Training Epoch: 1/2, step 7100/7134 completed (loss: 0.09009438008069992, acc: 0.9767441749572754)
[2024-12-17 04:35:37,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:38,122][root][INFO] - Training Epoch: 1/2, step 7101/7134 completed (loss: 0.11330187320709229, acc: 0.980322003364563)
[2024-12-17 04:35:38,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:38,552][root][INFO] - Training Epoch: 1/2, step 7102/7134 completed (loss: 0.01767299696803093, acc: 0.998062014579773)
[2024-12-17 04:35:38,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:38,973][root][INFO] - Training Epoch: 1/2, step 7103/7134 completed (loss: 0.04138309136033058, acc: 0.9879032373428345)
[2024-12-17 04:35:39,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:39,374][root][INFO] - Training Epoch: 1/2, step 7104/7134 completed (loss: 0.025275778025388718, acc: 0.9958847761154175)
[2024-12-17 04:35:39,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:39,785][root][INFO] - Training Epoch: 1/2, step 7105/7134 completed (loss: 0.05003887787461281, acc: 0.9866666793823242)
[2024-12-17 04:35:39,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:40,195][root][INFO] - Training Epoch: 1/2, step 7106/7134 completed (loss: 0.03000251203775406, acc: 0.9916527271270752)
[2024-12-17 04:35:40,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:40,633][root][INFO] - Training Epoch: 1/2, step 7107/7134 completed (loss: 0.033761508762836456, acc: 0.989130437374115)
[2024-12-17 04:35:40,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:41,047][root][INFO] - Training Epoch: 1/2, step 7108/7134 completed (loss: 0.04017993435263634, acc: 0.9883333444595337)
[2024-12-17 04:35:41,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:41,451][root][INFO] - Training Epoch: 1/2, step 7109/7134 completed (loss: 0.08101234585046768, acc: 0.9699812531471252)
[2024-12-17 04:35:41,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:41,875][root][INFO] - Training Epoch: 1/2, step 7110/7134 completed (loss: 0.03782973065972328, acc: 0.9813559055328369)
[2024-12-17 04:35:41,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:42,259][root][INFO] - Training Epoch: 1/2, step 7111/7134 completed (loss: 0.07200255990028381, acc: 0.9778270721435547)
[2024-12-17 04:35:42,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:42,673][root][INFO] - Training Epoch: 1/2, step 7112/7134 completed (loss: 0.04088154062628746, acc: 0.9835391044616699)
[2024-12-17 04:35:42,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:43,109][root][INFO] - Training Epoch: 1/2, step 7113/7134 completed (loss: 0.09930165112018585, acc: 0.9684542417526245)
[2024-12-17 04:35:43,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:43,504][root][INFO] - Training Epoch: 1/2, step 7114/7134 completed (loss: 0.04531558230519295, acc: 0.9885277152061462)
[2024-12-17 04:35:43,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:43,895][root][INFO] - Training Epoch: 1/2, step 7115/7134 completed (loss: 0.051095254719257355, acc: 0.9841269850730896)
[2024-12-17 04:35:44,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:44,317][root][INFO] - Training Epoch: 1/2, step 7116/7134 completed (loss: 0.03799394145607948, acc: 0.9859402179718018)
[2024-12-17 04:35:44,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:44,710][root][INFO] - Training Epoch: 1/2, step 7117/7134 completed (loss: 0.026156848296523094, acc: 0.9950000047683716)
[2024-12-17 04:35:44,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:45,133][root][INFO] - Training Epoch: 1/2, step 7118/7134 completed (loss: 0.06551308184862137, acc: 0.9825581312179565)
[2024-12-17 04:35:45,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:45,529][root][INFO] - Training Epoch: 1/2, step 7119/7134 completed (loss: 0.01946631446480751, acc: 0.9950900077819824)
[2024-12-17 04:35:45,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:45,893][root][INFO] - Training Epoch: 1/2, step 7120/7134 completed (loss: 0.07161902636289597, acc: 0.9836448431015015)
[2024-12-17 04:35:45,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:46,284][root][INFO] - Training Epoch: 1/2, step 7121/7134 completed (loss: 0.03568969666957855, acc: 0.9894366264343262)
[2024-12-17 04:35:46,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:46,679][root][INFO] - Training Epoch: 1/2, step 7122/7134 completed (loss: 0.04901370406150818, acc: 0.9839572310447693)
[2024-12-17 04:35:46,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:47,047][root][INFO] - Training Epoch: 1/2, step 7123/7134 completed (loss: 0.04105973243713379, acc: 0.9853658676147461)
[2024-12-17 04:35:47,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:47,480][root][INFO] - Training Epoch: 1/2, step 7124/7134 completed (loss: 0.042445093393325806, acc: 0.9831144213676453)
[2024-12-17 04:35:47,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:47,854][root][INFO] - Training Epoch: 1/2, step 7125/7134 completed (loss: 0.03214967995882034, acc: 0.9900497794151306)
[2024-12-17 04:35:47,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:48,277][root][INFO] - Training Epoch: 1/2, step 7126/7134 completed (loss: 0.10015333443880081, acc: 0.9730185270309448)
[2024-12-17 04:35:48,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:48,659][root][INFO] - Training Epoch: 1/2, step 7127/7134 completed (loss: 0.024813015013933182, acc: 0.993630588054657)
[2024-12-17 04:35:48,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:49,057][root][INFO] - Training Epoch: 1/2, step 7128/7134 completed (loss: 0.047542598098516464, acc: 0.9804878234863281)
[2024-12-17 04:35:49,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:49,460][root][INFO] - Training Epoch: 1/2, step 7129/7134 completed (loss: 0.09232994168996811, acc: 0.9686800837516785)
[2024-12-17 04:35:49,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:49,874][root][INFO] - Training Epoch: 1/2, step 7130/7134 completed (loss: 0.1357695460319519, acc: 0.9571428298950195)
[2024-12-17 04:35:50,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:50,288][root][INFO] - Training Epoch: 1/2, step 7131/7134 completed (loss: 0.031183017417788506, acc: 0.9860788583755493)
[2024-12-17 04:35:51,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:51,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:51,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:52,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:52,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:52,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:53,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:53,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:53,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:54,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:54,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:55,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:55,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:55,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:56,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:56,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:56,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:57,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:57,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:57,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:58,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:58,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:59,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:59,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:35:59,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:00,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:00,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:00,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:01,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:01,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:02,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:02,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:03,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:03,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:03,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:04,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:04,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:04,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:05,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:05,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:05,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:06,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:06,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:07,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:07,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:07,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:08,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:08,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:09,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:09,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:09,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:10,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:10,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:11,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:11,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:11,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:12,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:12,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:12,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:13,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:13,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:13,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:14,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:14,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:15,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:15,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:15,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:16,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:16,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:17,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:17,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:17,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:18,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:18,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:19,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:19,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:19,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:20,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:20,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:20,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:21,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:21,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:21,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:22,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:22,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:23,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:23,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:24,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:24,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:24,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:25,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:25,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:25,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:26,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:26,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:27,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:27,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:27,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:28,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:28,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:28,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:29,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:29,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:30,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:30,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:30,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:31,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:31,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:31,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:32,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:32,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:33,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:33,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:33,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:34,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:34,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:35,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:35,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:35,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:35,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:36,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:36,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:37,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:37,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:37,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:38,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:38,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:39,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:39,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:39,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:40,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:40,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:41,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:41,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:41,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:42,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:42,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:43,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:43,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:43,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:44,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:44,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:45,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:45,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:45,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:46,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:46,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:46,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:47,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:47,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:47,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:48,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:48,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:48,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:49,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:49,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:50,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:50,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:50,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:51,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:51,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:51,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:52,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:52,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:53,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:53,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:54,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:54,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:54,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:55,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:55,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:56,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:56,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:56,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:57,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:57,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:58,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:58,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:59,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:59,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:36:59,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:00,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:00,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:00,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:01,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:01,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:02,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:02,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:03,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:03,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:03,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:04,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:04,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:04,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:05,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:05,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:06,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:06,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:06,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:07,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:07,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:07,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:08,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:08,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:08,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:09,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:09,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:09,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:10,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:10,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:10,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:11,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:11,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:12,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:12,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:13,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:13,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:13,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:13,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:14,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:14,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:14,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:15,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:15,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:16,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:16,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:16,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:17,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:17,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:17,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:18,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:18,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:18,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:19,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:19,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:19,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:20,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:20,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:20,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:21,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:21,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:21,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:22,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:22,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:23,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:23,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:24,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:24,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:25,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:25,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:25,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:26,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:26,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:26,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:27,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:27,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:28,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:28,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:28,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:29,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:29,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:29,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:30,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:30,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:31,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:31,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:31,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:32,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:32,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:32,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:33,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:33,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:34,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:34,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:34,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:35,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:35,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:36,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:36,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:36,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:37,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:37,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:37,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:38,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:38,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:39,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:39,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:40,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:40,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:40,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:41,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:41,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:42,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:42,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:42,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:43,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:43,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:44,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:44,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:44,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:45,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:45,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:45,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:46,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:46,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:46,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:47,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:47,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:48,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:48,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:48,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:49,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:49,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:49,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:50,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:50,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:50,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:51,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:51,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:52,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:52,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:53,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:53,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:53,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:54,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:54,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:54,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:55,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:55,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:56,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:56,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:56,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:57,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:57,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:57,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:58,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:58,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:58,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:59,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:37:59,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:00,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:00,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:00,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:01,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:01,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:02,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:02,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:03,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:03,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:03,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:04,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:04,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:04,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:05,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:05,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:05,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:06,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:06,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:06,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:07,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:07,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:08,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:08,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:09,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:10,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:10,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:11,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:11,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:11,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:12,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:12,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:13,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:13,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:13,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:14,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:14,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:14,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:15,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:15,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:15,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:16,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:16,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:16,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:17,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:17,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:17,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:18,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:18,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:18,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:19,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:19,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:19,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:20,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:20,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:20,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:21,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:21,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:21,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:22,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:22,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:22,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:23,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:23,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:24,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:24,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:24,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:25,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:25,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:25,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:26,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:26,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:27,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:27,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:27,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:28,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:28,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:28,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:29,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:29,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:29,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:30,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:30,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:30,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:31,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:31,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:31,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:32,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:32,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:32,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:33,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:33,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:33,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:34,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:34,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:34,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:34,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:35,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:35,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:35,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:35,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:36,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:36,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:37,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:37,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:37,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:38,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:38,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:39,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:39,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:39,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:39,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:40,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:40,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:40,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:41,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:41,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:42,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:42,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:42,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:43,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:43,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:43,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:44,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:44,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:44,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:45,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:45,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:45,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:46,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:46,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:46,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:47,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:47,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:47,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:48,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:48,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:48,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:49,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:49,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:49,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:50,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:50,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:51,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:51,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:51,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:52,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:52,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:52,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:53,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:53,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:53,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:54,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:54,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:55,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:55,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:55,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:56,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:56,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:57,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:57,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:57,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:58,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:58,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:59,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:38:59,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:00,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:00,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:00,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:01,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:01,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:01,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:02,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:02,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:03,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:03,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:03,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:04,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:04,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:04,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:05,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:05,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:05,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:06,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:06,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:07,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:07,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:07,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:08,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:08,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:08,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:09,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:09,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:10,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:10,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:11,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:11,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:11,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:12,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:12,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:12,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:13,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:13,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:13,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:14,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:14,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:15,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:15,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:15,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:16,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:16,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:16,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:17,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:17,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:18,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:18,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:18,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:19,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:19,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:19,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:20,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:20,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:21,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:21,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:21,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:22,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:22,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:22,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:23,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:23,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:23,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:24,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:24,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:25,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:25,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:25,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:26,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:26,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:26,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:27,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:27,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:27,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:28,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:28,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:29,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:29,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:29,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:30,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:30,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:31,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:31,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:31,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:32,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:32,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:32,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:33,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:33,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:33,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:34,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:34,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:34,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:34,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:35,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:35,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:35,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:36,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:36,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:36,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:37,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:37,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:37,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:38,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:38,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:38,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:39,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:39,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:40,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:40,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:40,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:41,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:41,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:41,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:42,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:42,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:42,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:43,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:43,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:44,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:45,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:45,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:46,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:46,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:46,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:47,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:47,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:48,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:48,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:49,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:49,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:49,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:50,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:50,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:50,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:51,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:51,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:52,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:52,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:52,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:53,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:53,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:54,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:54,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:54,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:54,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:55,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:55,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:55,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:56,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:56,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:57,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:57,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:57,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:58,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:58,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:58,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:59,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:39:59,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:00,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:00,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:00,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:01,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:01,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:02,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:02,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:02,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:03,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:03,883][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.0648, device='cuda:0') eval_epoch_loss=tensor(0.0628, device='cuda:0') eval_epoch_acc=tensor(0.9827, device='cuda:0')
[2024-12-17 04:40:03,885][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-17 04:40:03,885][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 04:40:04,138][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_1_step_7132_loss_0.06280764937400818/model.pt
[2024-12-17 04:40:04,142][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-12-17 04:40:04,142][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 0.06280764937400818
[2024-12-17 04:40:04,143][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.9827002882957458
[2024-12-17 04:40:04,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:04,525][root][INFO] - Training Epoch: 1/2, step 7132/7134 completed (loss: 0.02994398958981037, acc: 0.9898989796638489)
[2024-12-17 04:40:04,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:04,906][root][INFO] - Training Epoch: 1/2, step 7133/7134 completed (loss: 0.008228790946304798, acc: 0.9981516003608704)
[2024-12-17 04:40:05,517][slam_llm.utils.train_utils][INFO] - Epoch 1: train_perplexity=1.9609, train_epoch_loss=0.6734, epoch time 4128.544600855559s
[2024-12-17 04:40:05,518][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 14 GB
[2024-12-17 04:40:05,518][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 30 GB
[2024-12-17 04:40:05,518][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 14 GB
[2024-12-17 04:40:05,518][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 6
[2024-12-17 04:40:05,518][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 7 GB
[2024-12-17 04:40:06,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:06,604][root][INFO] - Training Epoch: 2/2, step 0/7134 completed (loss: 0.04114434868097305, acc: 0.9851411581039429)
[2024-12-17 04:40:06,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:07,053][root][INFO] - Training Epoch: 2/2, step 1/7134 completed (loss: 0.03233722224831581, acc: 0.9944211840629578)
[2024-12-17 04:40:07,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:07,484][root][INFO] - Training Epoch: 2/2, step 2/7134 completed (loss: 0.027787836268544197, acc: 0.993306577205658)
[2024-12-17 04:40:07,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:07,939][root][INFO] - Training Epoch: 2/2, step 3/7134 completed (loss: 0.016921423375606537, acc: 0.994878351688385)
[2024-12-17 04:40:08,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:08,379][root][INFO] - Training Epoch: 2/2, step 4/7134 completed (loss: 0.043262649327516556, acc: 0.9877216815948486)
[2024-12-17 04:40:08,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:08,842][root][INFO] - Training Epoch: 2/2, step 5/7134 completed (loss: 0.03235391899943352, acc: 0.9936548471450806)
[2024-12-17 04:40:08,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:09,281][root][INFO] - Training Epoch: 2/2, step 6/7134 completed (loss: 0.024711787700653076, acc: 0.9903692007064819)
[2024-12-17 04:40:09,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:09,740][root][INFO] - Training Epoch: 2/2, step 7/7134 completed (loss: 0.052234336733818054, acc: 0.9863013625144958)
[2024-12-17 04:40:09,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:10,205][root][INFO] - Training Epoch: 2/2, step 8/7134 completed (loss: 0.08452185988426208, acc: 0.9766162037849426)
[2024-12-17 04:40:10,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:10,624][root][INFO] - Training Epoch: 2/2, step 9/7134 completed (loss: 0.019254464656114578, acc: 0.9922480583190918)
[2024-12-17 04:40:10,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:11,173][root][INFO] - Training Epoch: 2/2, step 10/7134 completed (loss: 0.0517207495868206, acc: 0.9857752323150635)
[2024-12-17 04:40:11,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:11,610][root][INFO] - Training Epoch: 2/2, step 11/7134 completed (loss: 0.016321690753102303, acc: 0.9943714737892151)
[2024-12-17 04:40:11,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:12,077][root][INFO] - Training Epoch: 2/2, step 12/7134 completed (loss: 0.021150881424546242, acc: 0.9946164488792419)
[2024-12-17 04:40:12,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:12,503][root][INFO] - Training Epoch: 2/2, step 13/7134 completed (loss: 0.033666763454675674, acc: 0.9903714060783386)
[2024-12-17 04:40:12,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:12,943][root][INFO] - Training Epoch: 2/2, step 14/7134 completed (loss: 0.02545774169266224, acc: 0.9949579834938049)
[2024-12-17 04:40:13,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:13,372][root][INFO] - Training Epoch: 2/2, step 15/7134 completed (loss: 0.027566000819206238, acc: 0.9948365092277527)
[2024-12-17 04:40:13,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:13,800][root][INFO] - Training Epoch: 2/2, step 16/7134 completed (loss: 0.005406378768384457, acc: 1.0)
[2024-12-17 04:40:13,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:14,213][root][INFO] - Training Epoch: 2/2, step 17/7134 completed (loss: 0.0971747413277626, acc: 0.9756757020950317)
[2024-12-17 04:40:14,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:14,651][root][INFO] - Training Epoch: 2/2, step 18/7134 completed (loss: 0.019177082926034927, acc: 0.9957386255264282)
[2024-12-17 04:40:14,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:15,079][root][INFO] - Training Epoch: 2/2, step 19/7134 completed (loss: 0.04896845668554306, acc: 0.9834482669830322)
[2024-12-17 04:40:15,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:15,492][root][INFO] - Training Epoch: 2/2, step 20/7134 completed (loss: 0.020037127658724785, acc: 0.9947368502616882)
[2024-12-17 04:40:15,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:15,950][root][INFO] - Training Epoch: 2/2, step 21/7134 completed (loss: 0.01320140901952982, acc: 0.9961340427398682)
[2024-12-17 04:40:16,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:16,409][root][INFO] - Training Epoch: 2/2, step 22/7134 completed (loss: 0.0056209443137049675, acc: 1.0)
[2024-12-17 04:40:16,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:16,847][root][INFO] - Training Epoch: 2/2, step 23/7134 completed (loss: 0.02085500955581665, acc: 0.9945651888847351)
[2024-12-17 04:40:16,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:17,278][root][INFO] - Training Epoch: 2/2, step 24/7134 completed (loss: 0.01746731624007225, acc: 0.9944289922714233)
[2024-12-17 04:40:17,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:17,754][root][INFO] - Training Epoch: 2/2, step 25/7134 completed (loss: 0.024937884882092476, acc: 0.9928977489471436)
[2024-12-17 04:40:17,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:18,205][root][INFO] - Training Epoch: 2/2, step 26/7134 completed (loss: 0.02287381701171398, acc: 0.9896755218505859)
[2024-12-17 04:40:18,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:18,647][root][INFO] - Training Epoch: 2/2, step 27/7134 completed (loss: 0.014335029758512974, acc: 0.9970458149909973)
[2024-12-17 04:40:18,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:19,121][root][INFO] - Training Epoch: 2/2, step 28/7134 completed (loss: 0.06760777533054352, acc: 0.9771084189414978)
[2024-12-17 04:40:19,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:19,581][root][INFO] - Training Epoch: 2/2, step 29/7134 completed (loss: 0.059696704149246216, acc: 0.9844192862510681)
[2024-12-17 04:40:19,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:20,054][root][INFO] - Training Epoch: 2/2, step 30/7134 completed (loss: 0.02473294362425804, acc: 0.993220329284668)
[2024-12-17 04:40:20,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:20,513][root][INFO] - Training Epoch: 2/2, step 31/7134 completed (loss: 0.038130149245262146, acc: 0.9862288236618042)
[2024-12-17 04:40:20,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:20,976][root][INFO] - Training Epoch: 2/2, step 32/7134 completed (loss: 0.06112547963857651, acc: 0.981794536113739)
[2024-12-17 04:40:21,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:21,361][root][INFO] - Training Epoch: 2/2, step 33/7134 completed (loss: 0.12280238419771194, acc: 0.9780876636505127)
[2024-12-17 04:40:21,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:21,827][root][INFO] - Training Epoch: 2/2, step 34/7134 completed (loss: 0.054492510855197906, acc: 0.9882766604423523)
[2024-12-17 04:40:21,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:22,333][root][INFO] - Training Epoch: 2/2, step 35/7134 completed (loss: 0.06062204763293266, acc: 0.9868049025535583)
[2024-12-17 04:40:22,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:22,816][root][INFO] - Training Epoch: 2/2, step 36/7134 completed (loss: 0.04396567493677139, acc: 0.9934853315353394)
[2024-12-17 04:40:22,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:23,286][root][INFO] - Training Epoch: 2/2, step 37/7134 completed (loss: 0.03734775632619858, acc: 0.9887359142303467)
[2024-12-17 04:40:23,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:23,696][root][INFO] - Training Epoch: 2/2, step 38/7134 completed (loss: 0.028587665408849716, acc: 0.9895833134651184)
[2024-12-17 04:40:23,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:24,169][root][INFO] - Training Epoch: 2/2, step 39/7134 completed (loss: 0.009730938822031021, acc: 0.9972936511039734)
[2024-12-17 04:40:24,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:24,577][root][INFO] - Training Epoch: 2/2, step 40/7134 completed (loss: 0.01565404422581196, acc: 0.9955157041549683)
[2024-12-17 04:40:24,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:24,993][root][INFO] - Training Epoch: 2/2, step 41/7134 completed (loss: 0.022798525169491768, acc: 0.9930651783943176)
[2024-12-17 04:40:25,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:25,455][root][INFO] - Training Epoch: 2/2, step 42/7134 completed (loss: 0.05734667181968689, acc: 0.9901823401451111)
[2024-12-17 04:40:25,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:25,882][root][INFO] - Training Epoch: 2/2, step 43/7134 completed (loss: 0.011505834758281708, acc: 0.996129035949707)
[2024-12-17 04:40:25,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:26,311][root][INFO] - Training Epoch: 2/2, step 44/7134 completed (loss: 0.05223040655255318, acc: 0.9898089170455933)
[2024-12-17 04:40:26,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:26,790][root][INFO] - Training Epoch: 2/2, step 45/7134 completed (loss: 0.05118041858077049, acc: 0.9902492165565491)
[2024-12-17 04:40:26,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:27,217][root][INFO] - Training Epoch: 2/2, step 46/7134 completed (loss: 0.06362015008926392, acc: 0.9866666793823242)
[2024-12-17 04:40:27,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:27,684][root][INFO] - Training Epoch: 2/2, step 47/7134 completed (loss: 0.06841716915369034, acc: 0.9855700135231018)
[2024-12-17 04:40:27,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:28,178][root][INFO] - Training Epoch: 2/2, step 48/7134 completed (loss: 0.026336345821619034, acc: 0.9955056309700012)
[2024-12-17 04:40:28,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:28,638][root][INFO] - Training Epoch: 2/2, step 49/7134 completed (loss: 0.026264043524861336, acc: 0.9958847761154175)
[2024-12-17 04:40:28,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:29,135][root][INFO] - Training Epoch: 2/2, step 50/7134 completed (loss: 0.014454075135290623, acc: 0.9942330121994019)
[2024-12-17 04:40:29,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:29,579][root][INFO] - Training Epoch: 2/2, step 51/7134 completed (loss: 0.01789463311433792, acc: 0.9936548471450806)
[2024-12-17 04:40:29,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:29,993][root][INFO] - Training Epoch: 2/2, step 52/7134 completed (loss: 0.015296878293156624, acc: 0.995121955871582)
[2024-12-17 04:40:30,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:30,409][root][INFO] - Training Epoch: 2/2, step 53/7134 completed (loss: 0.019365370273590088, acc: 0.9947506785392761)
[2024-12-17 04:40:30,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:30,883][root][INFO] - Training Epoch: 2/2, step 54/7134 completed (loss: 0.011230659671127796, acc: 0.9965477585792542)
[2024-12-17 04:40:31,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:31,325][root][INFO] - Training Epoch: 2/2, step 55/7134 completed (loss: 0.017707979306578636, acc: 0.9961928725242615)
[2024-12-17 04:40:31,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:31,776][root][INFO] - Training Epoch: 2/2, step 56/7134 completed (loss: 0.017182616516947746, acc: 0.9928571581840515)
[2024-12-17 04:40:31,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:32,235][root][INFO] - Training Epoch: 2/2, step 57/7134 completed (loss: 0.0656759962439537, acc: 0.9838509559631348)
[2024-12-17 04:40:32,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:32,708][root][INFO] - Training Epoch: 2/2, step 58/7134 completed (loss: 0.04880208149552345, acc: 0.9884763360023499)
[2024-12-17 04:40:32,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:33,173][root][INFO] - Training Epoch: 2/2, step 59/7134 completed (loss: 0.024361440911889076, acc: 0.991725742816925)
[2024-12-17 04:40:33,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:33,647][root][INFO] - Training Epoch: 2/2, step 60/7134 completed (loss: 0.039053257554769516, acc: 0.9872159361839294)
[2024-12-17 04:40:33,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:34,092][root][INFO] - Training Epoch: 2/2, step 61/7134 completed (loss: 0.04133537411689758, acc: 0.993880033493042)
[2024-12-17 04:40:34,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:34,540][root][INFO] - Training Epoch: 2/2, step 62/7134 completed (loss: 0.025939851999282837, acc: 0.9923760890960693)
[2024-12-17 04:40:34,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:35,001][root][INFO] - Training Epoch: 2/2, step 63/7134 completed (loss: 0.057774923741817474, acc: 0.9887920022010803)
[2024-12-17 04:40:35,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:35,475][root][INFO] - Training Epoch: 2/2, step 64/7134 completed (loss: 0.024338556453585625, acc: 0.9879032373428345)
[2024-12-17 04:40:35,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:35,947][root][INFO] - Training Epoch: 2/2, step 65/7134 completed (loss: 0.06213109940290451, acc: 0.9754299521446228)
[2024-12-17 04:40:36,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:36,387][root][INFO] - Training Epoch: 2/2, step 66/7134 completed (loss: 0.05492306873202324, acc: 0.9856630563735962)
[2024-12-17 04:40:36,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:36,865][root][INFO] - Training Epoch: 2/2, step 67/7134 completed (loss: 0.038122110068798065, acc: 0.9816993474960327)
[2024-12-17 04:40:36,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:37,322][root][INFO] - Training Epoch: 2/2, step 68/7134 completed (loss: 0.05855134129524231, acc: 0.9832258224487305)
[2024-12-17 04:40:37,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:37,783][root][INFO] - Training Epoch: 2/2, step 69/7134 completed (loss: 0.052380435168743134, acc: 0.9788029789924622)
[2024-12-17 04:40:37,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:38,230][root][INFO] - Training Epoch: 2/2, step 70/7134 completed (loss: 0.043742116540670395, acc: 0.9877192974090576)
[2024-12-17 04:40:38,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:38,667][root][INFO] - Training Epoch: 2/2, step 71/7134 completed (loss: 0.02782289870083332, acc: 0.9915966391563416)
[2024-12-17 04:40:38,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:39,126][root][INFO] - Training Epoch: 2/2, step 72/7134 completed (loss: 0.041626133024692535, acc: 0.9872123003005981)
[2024-12-17 04:40:39,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:39,558][root][INFO] - Training Epoch: 2/2, step 73/7134 completed (loss: 0.03290075436234474, acc: 0.991847813129425)
[2024-12-17 04:40:39,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:40,000][root][INFO] - Training Epoch: 2/2, step 74/7134 completed (loss: 0.031193796545267105, acc: 0.9902507066726685)
[2024-12-17 04:40:40,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:40,492][root][INFO] - Training Epoch: 2/2, step 75/7134 completed (loss: 0.06246518716216087, acc: 0.9850522875785828)
[2024-12-17 04:40:40,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:40,957][root][INFO] - Training Epoch: 2/2, step 76/7134 completed (loss: 0.02528265118598938, acc: 0.989924430847168)
[2024-12-17 04:40:41,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:41,407][root][INFO] - Training Epoch: 2/2, step 77/7134 completed (loss: 0.034272149205207825, acc: 0.9874686598777771)
[2024-12-17 04:40:41,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:41,864][root][INFO] - Training Epoch: 2/2, step 78/7134 completed (loss: 0.06805504858493805, acc: 0.9779874086380005)
[2024-12-17 04:40:41,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:42,290][root][INFO] - Training Epoch: 2/2, step 79/7134 completed (loss: 0.05629358068108559, acc: 0.9845678806304932)
[2024-12-17 04:40:42,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:42,740][root][INFO] - Training Epoch: 2/2, step 80/7134 completed (loss: 0.04109131917357445, acc: 0.9921875)
[2024-12-17 04:40:42,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:43,200][root][INFO] - Training Epoch: 2/2, step 81/7134 completed (loss: 0.04542778059840202, acc: 0.9869109988212585)
[2024-12-17 04:40:43,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:43,681][root][INFO] - Training Epoch: 2/2, step 82/7134 completed (loss: 0.05212724953889847, acc: 0.9844412803649902)
[2024-12-17 04:40:43,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:44,139][root][INFO] - Training Epoch: 2/2, step 83/7134 completed (loss: 0.04517795145511627, acc: 0.9820051193237305)
[2024-12-17 04:40:44,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:44,605][root][INFO] - Training Epoch: 2/2, step 84/7134 completed (loss: 0.03910423442721367, acc: 0.9879102110862732)
[2024-12-17 04:40:44,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:45,051][root][INFO] - Training Epoch: 2/2, step 85/7134 completed (loss: 0.05270770564675331, acc: 0.9856801629066467)
[2024-12-17 04:40:45,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:45,490][root][INFO] - Training Epoch: 2/2, step 86/7134 completed (loss: 0.037303004413843155, acc: 0.9839449524879456)
[2024-12-17 04:40:45,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:45,950][root][INFO] - Training Epoch: 2/2, step 87/7134 completed (loss: 0.12626616656780243, acc: 0.9676945805549622)
[2024-12-17 04:40:46,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:46,417][root][INFO] - Training Epoch: 2/2, step 88/7134 completed (loss: 0.10272647440433502, acc: 0.9737206101417542)
[2024-12-17 04:40:46,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:46,876][root][INFO] - Training Epoch: 2/2, step 89/7134 completed (loss: 0.03918900340795517, acc: 0.9884467124938965)
[2024-12-17 04:40:46,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:47,321][root][INFO] - Training Epoch: 2/2, step 90/7134 completed (loss: 0.044883184134960175, acc: 0.9842657446861267)
[2024-12-17 04:40:47,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:47,748][root][INFO] - Training Epoch: 2/2, step 91/7134 completed (loss: 0.05334040895104408, acc: 0.9836734533309937)
[2024-12-17 04:40:47,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:48,217][root][INFO] - Training Epoch: 2/2, step 92/7134 completed (loss: 0.0672072172164917, acc: 0.9775596261024475)
[2024-12-17 04:40:48,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:48,668][root][INFO] - Training Epoch: 2/2, step 93/7134 completed (loss: 0.04048299789428711, acc: 0.9862259030342102)
[2024-12-17 04:40:48,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:49,028][root][INFO] - Training Epoch: 2/2, step 94/7134 completed (loss: 0.08683052659034729, acc: 0.9698376059532166)
[2024-12-17 04:40:49,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:49,496][root][INFO] - Training Epoch: 2/2, step 95/7134 completed (loss: 0.04849421605467796, acc: 0.9861809015274048)
[2024-12-17 04:40:49,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:49,936][root][INFO] - Training Epoch: 2/2, step 96/7134 completed (loss: 0.034636255353689194, acc: 0.9832402467727661)
[2024-12-17 04:40:50,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:50,366][root][INFO] - Training Epoch: 2/2, step 97/7134 completed (loss: 0.22704678773880005, acc: 0.9457831382751465)
[2024-12-17 04:40:50,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:50,829][root][INFO] - Training Epoch: 2/2, step 98/7134 completed (loss: 0.09511057287454605, acc: 0.9741100072860718)
[2024-12-17 04:40:50,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:51,249][root][INFO] - Training Epoch: 2/2, step 99/7134 completed (loss: 0.06281094998121262, acc: 0.9834862351417542)
[2024-12-17 04:40:51,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:51,733][root][INFO] - Training Epoch: 2/2, step 100/7134 completed (loss: 0.03908812999725342, acc: 0.9846153855323792)
[2024-12-17 04:40:51,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:52,162][root][INFO] - Training Epoch: 2/2, step 101/7134 completed (loss: 0.05535983294248581, acc: 0.9802631735801697)
[2024-12-17 04:40:52,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:52,620][root][INFO] - Training Epoch: 2/2, step 102/7134 completed (loss: 0.0355977863073349, acc: 0.9877899885177612)
[2024-12-17 04:40:52,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:53,029][root][INFO] - Training Epoch: 2/2, step 103/7134 completed (loss: 0.05690274387598038, acc: 0.9816666841506958)
[2024-12-17 04:40:53,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:53,488][root][INFO] - Training Epoch: 2/2, step 104/7134 completed (loss: 0.056614313274621964, acc: 0.9864048361778259)
[2024-12-17 04:40:53,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:53,951][root][INFO] - Training Epoch: 2/2, step 105/7134 completed (loss: 0.0548805296421051, acc: 0.9820554852485657)
[2024-12-17 04:40:54,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:54,420][root][INFO] - Training Epoch: 2/2, step 106/7134 completed (loss: 0.07367423176765442, acc: 0.9774153232574463)
[2024-12-17 04:40:54,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:54,875][root][INFO] - Training Epoch: 2/2, step 107/7134 completed (loss: 0.1997564733028412, acc: 0.9383954405784607)
[2024-12-17 04:40:55,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:55,350][root][INFO] - Training Epoch: 2/2, step 108/7134 completed (loss: 0.057561252266168594, acc: 0.9856114983558655)
[2024-12-17 04:40:55,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:55,757][root][INFO] - Training Epoch: 2/2, step 109/7134 completed (loss: 0.04743294417858124, acc: 0.9852941036224365)
[2024-12-17 04:40:55,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:56,247][root][INFO] - Training Epoch: 2/2, step 110/7134 completed (loss: 0.06364774703979492, acc: 0.9811986088752747)
[2024-12-17 04:40:56,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:56,680][root][INFO] - Training Epoch: 2/2, step 111/7134 completed (loss: 0.05755080282688141, acc: 0.9825783967971802)
[2024-12-17 04:40:56,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:57,101][root][INFO] - Training Epoch: 2/2, step 112/7134 completed (loss: 0.06193428859114647, acc: 0.9830508232116699)
[2024-12-17 04:40:57,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:57,556][root][INFO] - Training Epoch: 2/2, step 113/7134 completed (loss: 0.04588240757584572, acc: 0.9911392331123352)
[2024-12-17 04:40:57,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:58,007][root][INFO] - Training Epoch: 2/2, step 114/7134 completed (loss: 0.04721887409687042, acc: 0.9854111671447754)
[2024-12-17 04:40:58,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:58,388][root][INFO] - Training Epoch: 2/2, step 115/7134 completed (loss: 0.10123548656702042, acc: 0.9632545709609985)
[2024-12-17 04:40:58,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:58,879][root][INFO] - Training Epoch: 2/2, step 116/7134 completed (loss: 0.06326692551374435, acc: 0.9811543226242065)
[2024-12-17 04:40:59,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:59,314][root][INFO] - Training Epoch: 2/2, step 117/7134 completed (loss: 0.02848869189620018, acc: 0.990304708480835)
[2024-12-17 04:40:59,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:40:59,813][root][INFO] - Training Epoch: 2/2, step 118/7134 completed (loss: 0.04342232272028923, acc: 0.9859693646430969)
[2024-12-17 04:40:59,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:00,286][root][INFO] - Training Epoch: 2/2, step 119/7134 completed (loss: 0.05627695471048355, acc: 0.9830508232116699)
[2024-12-17 04:41:00,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:00,718][root][INFO] - Training Epoch: 2/2, step 120/7134 completed (loss: 0.021215027198195457, acc: 0.993446946144104)
[2024-12-17 04:41:00,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:01,143][root][INFO] - Training Epoch: 2/2, step 121/7134 completed (loss: 0.0442642942070961, acc: 0.9920739531517029)
[2024-12-17 04:41:01,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:01,599][root][INFO] - Training Epoch: 2/2, step 122/7134 completed (loss: 0.0470193475484848, acc: 0.9880794882774353)
[2024-12-17 04:41:01,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:02,006][root][INFO] - Training Epoch: 2/2, step 123/7134 completed (loss: 0.022381458431482315, acc: 0.9924924969673157)
[2024-12-17 04:41:02,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:02,408][root][INFO] - Training Epoch: 2/2, step 124/7134 completed (loss: 0.04628600925207138, acc: 0.9862068891525269)
[2024-12-17 04:41:02,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:02,890][root][INFO] - Training Epoch: 2/2, step 125/7134 completed (loss: 0.04802671819925308, acc: 0.9867256879806519)
[2024-12-17 04:41:03,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:03,342][root][INFO] - Training Epoch: 2/2, step 126/7134 completed (loss: 0.03105900064110756, acc: 0.9893333315849304)
[2024-12-17 04:41:03,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:03,814][root][INFO] - Training Epoch: 2/2, step 127/7134 completed (loss: 0.032075297087430954, acc: 0.990123450756073)
[2024-12-17 04:41:03,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:04,274][root][INFO] - Training Epoch: 2/2, step 128/7134 completed (loss: 0.05007624998688698, acc: 0.9896193742752075)
[2024-12-17 04:41:04,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:04,752][root][INFO] - Training Epoch: 2/2, step 129/7134 completed (loss: 0.03938588127493858, acc: 0.9852941036224365)
[2024-12-17 04:41:04,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:05,199][root][INFO] - Training Epoch: 2/2, step 130/7134 completed (loss: 0.03885383531451225, acc: 0.9868420958518982)
[2024-12-17 04:41:05,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:05,653][root][INFO] - Training Epoch: 2/2, step 131/7134 completed (loss: 0.01692831702530384, acc: 0.996052622795105)
[2024-12-17 04:41:05,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:06,089][root][INFO] - Training Epoch: 2/2, step 132/7134 completed (loss: 0.035879723727703094, acc: 0.9840348362922668)
[2024-12-17 04:41:06,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:06,511][root][INFO] - Training Epoch: 2/2, step 133/7134 completed (loss: 0.015976186841726303, acc: 0.9966722130775452)
[2024-12-17 04:41:06,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:06,957][root][INFO] - Training Epoch: 2/2, step 134/7134 completed (loss: 0.039128147065639496, acc: 0.9893805384635925)
[2024-12-17 04:41:07,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:07,421][root][INFO] - Training Epoch: 2/2, step 135/7134 completed (loss: 0.03393777087330818, acc: 0.9900000095367432)
[2024-12-17 04:41:07,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:07,875][root][INFO] - Training Epoch: 2/2, step 136/7134 completed (loss: 0.023365069180727005, acc: 0.9964157938957214)
[2024-12-17 04:41:07,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:08,350][root][INFO] - Training Epoch: 2/2, step 137/7134 completed (loss: 0.04768317565321922, acc: 0.9889298677444458)
[2024-12-17 04:41:08,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:08,820][root][INFO] - Training Epoch: 2/2, step 138/7134 completed (loss: 0.04780975356698036, acc: 0.9860935807228088)
[2024-12-17 04:41:08,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:09,301][root][INFO] - Training Epoch: 2/2, step 139/7134 completed (loss: 0.05551636591553688, acc: 0.9859334826469421)
[2024-12-17 04:41:09,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:09,754][root][INFO] - Training Epoch: 2/2, step 140/7134 completed (loss: 0.024133944883942604, acc: 0.9940298795700073)
[2024-12-17 04:41:09,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:10,191][root][INFO] - Training Epoch: 2/2, step 141/7134 completed (loss: 0.01257234439253807, acc: 0.9964622855186462)
[2024-12-17 04:41:10,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:10,655][root][INFO] - Training Epoch: 2/2, step 142/7134 completed (loss: 0.07516301423311234, acc: 0.9847009778022766)
[2024-12-17 04:41:10,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:11,108][root][INFO] - Training Epoch: 2/2, step 143/7134 completed (loss: 0.02566698007285595, acc: 0.9960886836051941)
[2024-12-17 04:41:11,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:11,566][root][INFO] - Training Epoch: 2/2, step 144/7134 completed (loss: 0.10783098638057709, acc: 0.9749582409858704)
[2024-12-17 04:41:11,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:12,008][root][INFO] - Training Epoch: 2/2, step 145/7134 completed (loss: 0.1422443836927414, acc: 0.9647887349128723)
[2024-12-17 04:41:12,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:12,467][root][INFO] - Training Epoch: 2/2, step 146/7134 completed (loss: 0.10307444632053375, acc: 0.9715099930763245)
[2024-12-17 04:41:12,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:12,894][root][INFO] - Training Epoch: 2/2, step 147/7134 completed (loss: 0.08561240881681442, acc: 0.9792027473449707)
[2024-12-17 04:41:13,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:13,311][root][INFO] - Training Epoch: 2/2, step 148/7134 completed (loss: 0.15100334584712982, acc: 0.9466357231140137)
[2024-12-17 04:41:13,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:13,751][root][INFO] - Training Epoch: 2/2, step 149/7134 completed (loss: 0.12179316580295563, acc: 0.9729032516479492)
[2024-12-17 04:41:13,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:14,216][root][INFO] - Training Epoch: 2/2, step 150/7134 completed (loss: 0.0958561897277832, acc: 0.9759358167648315)
[2024-12-17 04:41:14,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:14,684][root][INFO] - Training Epoch: 2/2, step 151/7134 completed (loss: 0.09660089761018753, acc: 0.9749403595924377)
[2024-12-17 04:41:14,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:15,164][root][INFO] - Training Epoch: 2/2, step 152/7134 completed (loss: 0.04691353812813759, acc: 0.9863325953483582)
[2024-12-17 04:41:15,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:15,650][root][INFO] - Training Epoch: 2/2, step 153/7134 completed (loss: 0.10144156217575073, acc: 0.9734637141227722)
[2024-12-17 04:41:15,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:16,067][root][INFO] - Training Epoch: 2/2, step 154/7134 completed (loss: 0.07489871978759766, acc: 0.975683867931366)
[2024-12-17 04:41:16,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:16,542][root][INFO] - Training Epoch: 2/2, step 155/7134 completed (loss: 0.08188970386981964, acc: 0.9766233563423157)
[2024-12-17 04:41:16,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:17,024][root][INFO] - Training Epoch: 2/2, step 156/7134 completed (loss: 0.05227590724825859, acc: 0.9871645569801331)
[2024-12-17 04:41:17,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:17,520][root][INFO] - Training Epoch: 2/2, step 157/7134 completed (loss: 0.08868242055177689, acc: 0.9759036302566528)
[2024-12-17 04:41:17,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:18,003][root][INFO] - Training Epoch: 2/2, step 158/7134 completed (loss: 0.033205561339855194, acc: 0.9881109595298767)
[2024-12-17 04:41:18,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:18,470][root][INFO] - Training Epoch: 2/2, step 159/7134 completed (loss: 0.06266745924949646, acc: 0.9826839566230774)
[2024-12-17 04:41:18,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:18,931][root][INFO] - Training Epoch: 2/2, step 160/7134 completed (loss: 0.07381932437419891, acc: 0.9736841917037964)
[2024-12-17 04:41:19,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:19,329][root][INFO] - Training Epoch: 2/2, step 161/7134 completed (loss: 0.028478913009166718, acc: 0.9912790656089783)
[2024-12-17 04:41:19,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:19,717][root][INFO] - Training Epoch: 2/2, step 162/7134 completed (loss: 0.05401891469955444, acc: 0.9820972084999084)
[2024-12-17 04:41:19,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:20,197][root][INFO] - Training Epoch: 2/2, step 163/7134 completed (loss: 0.08211624622344971, acc: 0.9807976484298706)
[2024-12-17 04:41:20,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:20,629][root][INFO] - Training Epoch: 2/2, step 164/7134 completed (loss: 0.05658489093184471, acc: 0.9851064085960388)
[2024-12-17 04:41:20,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:21,035][root][INFO] - Training Epoch: 2/2, step 165/7134 completed (loss: 0.11484633386135101, acc: 0.9736841917037964)
[2024-12-17 04:41:21,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:21,416][root][INFO] - Training Epoch: 2/2, step 166/7134 completed (loss: 0.0571809746325016, acc: 0.9910447597503662)
[2024-12-17 04:41:21,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:21,867][root][INFO] - Training Epoch: 2/2, step 167/7134 completed (loss: 0.5057879686355591, acc: 0.903743326663971)
[2024-12-17 04:41:22,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:22,230][root][INFO] - Training Epoch: 2/2, step 168/7134 completed (loss: 1.4276642799377441, acc: 0.6941176652908325)
[2024-12-17 04:41:22,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:22,606][root][INFO] - Training Epoch: 2/2, step 169/7134 completed (loss: 0.8134011626243591, acc: 0.7899159789085388)
[2024-12-17 04:41:22,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:23,019][root][INFO] - Training Epoch: 2/2, step 170/7134 completed (loss: 0.3900093138217926, acc: 0.8842504620552063)
[2024-12-17 04:41:23,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:23,419][root][INFO] - Training Epoch: 2/2, step 171/7134 completed (loss: 0.47869089245796204, acc: 0.8863636255264282)
[2024-12-17 04:41:23,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:23,831][root][INFO] - Training Epoch: 2/2, step 172/7134 completed (loss: 0.30783402919769287, acc: 0.90220046043396)
[2024-12-17 04:41:23,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:24,214][root][INFO] - Training Epoch: 2/2, step 173/7134 completed (loss: 0.24558371305465698, acc: 0.9336283206939697)
[2024-12-17 04:41:24,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:24,618][root][INFO] - Training Epoch: 2/2, step 174/7134 completed (loss: 0.19781146943569183, acc: 0.9542253613471985)
[2024-12-17 04:41:24,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:25,048][root][INFO] - Training Epoch: 2/2, step 175/7134 completed (loss: 0.15955083072185516, acc: 0.9581817984580994)
[2024-12-17 04:41:25,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:25,530][root][INFO] - Training Epoch: 2/2, step 176/7134 completed (loss: 0.19787633419036865, acc: 0.947826087474823)
[2024-12-17 04:41:25,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:25,966][root][INFO] - Training Epoch: 2/2, step 177/7134 completed (loss: 0.2353014051914215, acc: 0.9407407641410828)
[2024-12-17 04:41:26,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:26,342][root][INFO] - Training Epoch: 2/2, step 178/7134 completed (loss: 0.1528112292289734, acc: 0.9534883499145508)
[2024-12-17 04:41:26,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:26,792][root][INFO] - Training Epoch: 2/2, step 179/7134 completed (loss: 0.1215904951095581, acc: 0.967117965221405)
[2024-12-17 04:41:26,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:27,255][root][INFO] - Training Epoch: 2/2, step 180/7134 completed (loss: 0.09427710622549057, acc: 0.9781491160392761)
[2024-12-17 04:41:27,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:27,671][root][INFO] - Training Epoch: 2/2, step 181/7134 completed (loss: 0.08262264728546143, acc: 0.9762845635414124)
[2024-12-17 04:41:27,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:28,159][root][INFO] - Training Epoch: 2/2, step 182/7134 completed (loss: 0.04503346607089043, acc: 0.990231990814209)
[2024-12-17 04:41:28,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:28,611][root][INFO] - Training Epoch: 2/2, step 183/7134 completed (loss: 0.055828727781772614, acc: 0.9850136041641235)
[2024-12-17 04:41:28,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:29,094][root][INFO] - Training Epoch: 2/2, step 184/7134 completed (loss: 0.08071933686733246, acc: 0.9861751198768616)
[2024-12-17 04:41:29,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:29,539][root][INFO] - Training Epoch: 2/2, step 185/7134 completed (loss: 0.05900362506508827, acc: 0.9828326106071472)
[2024-12-17 04:41:29,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:29,996][root][INFO] - Training Epoch: 2/2, step 186/7134 completed (loss: 0.084695003926754, acc: 0.9775640964508057)
[2024-12-17 04:41:30,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:30,427][root][INFO] - Training Epoch: 2/2, step 187/7134 completed (loss: 0.08388721942901611, acc: 0.9790502786636353)
[2024-12-17 04:41:30,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:30,866][root][INFO] - Training Epoch: 2/2, step 188/7134 completed (loss: 0.12634803354740143, acc: 0.9611111283302307)
[2024-12-17 04:41:30,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:31,226][root][INFO] - Training Epoch: 2/2, step 189/7134 completed (loss: 0.07073905318975449, acc: 0.982692301273346)
[2024-12-17 04:41:31,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:31,696][root][INFO] - Training Epoch: 2/2, step 190/7134 completed (loss: 0.15069755911827087, acc: 0.9703587889671326)
[2024-12-17 04:41:31,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:32,094][root][INFO] - Training Epoch: 2/2, step 191/7134 completed (loss: 0.06591960787773132, acc: 0.9871794581413269)
[2024-12-17 04:41:32,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:32,573][root][INFO] - Training Epoch: 2/2, step 192/7134 completed (loss: 0.017957035452127457, acc: 0.993127167224884)
[2024-12-17 04:41:32,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:33,018][root][INFO] - Training Epoch: 2/2, step 193/7134 completed (loss: 0.0683216080069542, acc: 0.9771811962127686)
[2024-12-17 04:41:33,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:33,472][root][INFO] - Training Epoch: 2/2, step 194/7134 completed (loss: 0.05933177471160889, acc: 0.9813486337661743)
[2024-12-17 04:41:33,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:33,899][root][INFO] - Training Epoch: 2/2, step 195/7134 completed (loss: 0.07189527153968811, acc: 0.9815126061439514)
[2024-12-17 04:41:33,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:34,352][root][INFO] - Training Epoch: 2/2, step 196/7134 completed (loss: 0.08031202852725983, acc: 0.9826202988624573)
[2024-12-17 04:41:34,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:34,810][root][INFO] - Training Epoch: 2/2, step 197/7134 completed (loss: 0.049610115587711334, acc: 0.9886040091514587)
[2024-12-17 04:41:34,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:35,267][root][INFO] - Training Epoch: 2/2, step 198/7134 completed (loss: 0.04122548550367355, acc: 0.98591548204422)
[2024-12-17 04:41:35,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:35,697][root][INFO] - Training Epoch: 2/2, step 199/7134 completed (loss: 0.075677290558815, acc: 0.9753694534301758)
[2024-12-17 04:41:35,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:36,168][root][INFO] - Training Epoch: 2/2, step 200/7134 completed (loss: 0.020274708047509193, acc: 0.9946308732032776)
[2024-12-17 04:41:36,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:36,609][root][INFO] - Training Epoch: 2/2, step 201/7134 completed (loss: 0.0520675890147686, acc: 0.9845505356788635)
[2024-12-17 04:41:36,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:37,082][root][INFO] - Training Epoch: 2/2, step 202/7134 completed (loss: 0.0489376038312912, acc: 0.9820689558982849)
[2024-12-17 04:41:37,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:37,526][root][INFO] - Training Epoch: 2/2, step 203/7134 completed (loss: 0.06866969168186188, acc: 0.9807162284851074)
[2024-12-17 04:41:37,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:37,971][root][INFO] - Training Epoch: 2/2, step 204/7134 completed (loss: 0.05660076066851616, acc: 0.978723406791687)
[2024-12-17 04:41:38,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:38,432][root][INFO] - Training Epoch: 2/2, step 205/7134 completed (loss: 0.06802745908498764, acc: 0.9767140746116638)
[2024-12-17 04:41:38,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:38,903][root][INFO] - Training Epoch: 2/2, step 206/7134 completed (loss: 0.11672830581665039, acc: 0.971107542514801)
[2024-12-17 04:41:39,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:39,333][root][INFO] - Training Epoch: 2/2, step 207/7134 completed (loss: 0.07367420196533203, acc: 0.9829351305961609)
[2024-12-17 04:41:39,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:39,785][root][INFO] - Training Epoch: 2/2, step 208/7134 completed (loss: 0.13645586371421814, acc: 0.9627450704574585)
[2024-12-17 04:41:39,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:40,237][root][INFO] - Training Epoch: 2/2, step 209/7134 completed (loss: 0.1444290727376938, acc: 0.9637305736541748)
[2024-12-17 04:41:40,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:40,700][root][INFO] - Training Epoch: 2/2, step 210/7134 completed (loss: 0.10711026936769485, acc: 0.9699879884719849)
[2024-12-17 04:41:40,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:41,108][root][INFO] - Training Epoch: 2/2, step 211/7134 completed (loss: 0.14858700335025787, acc: 0.9624183177947998)
[2024-12-17 04:41:41,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:41,528][root][INFO] - Training Epoch: 2/2, step 212/7134 completed (loss: 0.18784227967262268, acc: 0.9628099203109741)
[2024-12-17 04:41:41,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:41,962][root][INFO] - Training Epoch: 2/2, step 213/7134 completed (loss: 0.0945158302783966, acc: 0.9757281541824341)
[2024-12-17 04:41:42,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:42,362][root][INFO] - Training Epoch: 2/2, step 214/7134 completed (loss: 0.09033239632844925, acc: 0.9807692170143127)
[2024-12-17 04:41:42,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:42,791][root][INFO] - Training Epoch: 2/2, step 215/7134 completed (loss: 0.06335215270519257, acc: 0.984375)
[2024-12-17 04:41:42,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:43,215][root][INFO] - Training Epoch: 2/2, step 216/7134 completed (loss: 0.05729175731539726, acc: 0.9861111044883728)
[2024-12-17 04:41:43,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:43,692][root][INFO] - Training Epoch: 2/2, step 217/7134 completed (loss: 0.06748942285776138, acc: 0.9806060791015625)
[2024-12-17 04:41:43,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:44,141][root][INFO] - Training Epoch: 2/2, step 218/7134 completed (loss: 0.037345271557569504, acc: 0.9872773289680481)
[2024-12-17 04:41:44,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:44,564][root][INFO] - Training Epoch: 2/2, step 219/7134 completed (loss: 0.05086904764175415, acc: 0.9922027587890625)
[2024-12-17 04:41:44,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:44,981][root][INFO] - Training Epoch: 2/2, step 220/7134 completed (loss: 0.05221101641654968, acc: 0.9895397424697876)
[2024-12-17 04:41:45,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:45,426][root][INFO] - Training Epoch: 2/2, step 221/7134 completed (loss: 0.045639265328645706, acc: 0.9880596995353699)
[2024-12-17 04:41:45,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:45,903][root][INFO] - Training Epoch: 2/2, step 222/7134 completed (loss: 0.05102965608239174, acc: 0.981675386428833)
[2024-12-17 04:41:46,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:46,341][root][INFO] - Training Epoch: 2/2, step 223/7134 completed (loss: 0.08822973817586899, acc: 0.973042368888855)
[2024-12-17 04:41:46,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:46,780][root][INFO] - Training Epoch: 2/2, step 224/7134 completed (loss: 0.13254418969154358, acc: 0.9675745964050293)
[2024-12-17 04:41:46,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:47,226][root][INFO] - Training Epoch: 2/2, step 225/7134 completed (loss: 0.12012515217065811, acc: 0.9704749584197998)
[2024-12-17 04:41:47,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:47,681][root][INFO] - Training Epoch: 2/2, step 226/7134 completed (loss: 0.06225870922207832, acc: 0.9889975786209106)
[2024-12-17 04:41:47,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:48,135][root][INFO] - Training Epoch: 2/2, step 227/7134 completed (loss: 0.14977777004241943, acc: 0.96277916431427)
[2024-12-17 04:41:48,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:48,600][root][INFO] - Training Epoch: 2/2, step 228/7134 completed (loss: 0.08243205398321152, acc: 0.9782923460006714)
[2024-12-17 04:41:48,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:49,063][root][INFO] - Training Epoch: 2/2, step 229/7134 completed (loss: 0.10238214582204819, acc: 0.9721518754959106)
[2024-12-17 04:41:49,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:49,519][root][INFO] - Training Epoch: 2/2, step 230/7134 completed (loss: 0.06165416166186333, acc: 0.9815725088119507)
[2024-12-17 04:41:49,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:49,962][root][INFO] - Training Epoch: 2/2, step 231/7134 completed (loss: 0.052534084767103195, acc: 0.9811676144599915)
[2024-12-17 04:41:50,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:50,400][root][INFO] - Training Epoch: 2/2, step 232/7134 completed (loss: 0.049532681703567505, acc: 0.9868203997612)
[2024-12-17 04:41:50,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:50,833][root][INFO] - Training Epoch: 2/2, step 233/7134 completed (loss: 0.06532905250787735, acc: 0.9857369065284729)
[2024-12-17 04:41:50,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:51,270][root][INFO] - Training Epoch: 2/2, step 234/7134 completed (loss: 0.07522454857826233, acc: 0.9814189076423645)
[2024-12-17 04:41:51,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:51,738][root][INFO] - Training Epoch: 2/2, step 235/7134 completed (loss: 0.10927581042051315, acc: 0.9786324501037598)
[2024-12-17 04:41:51,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:52,177][root][INFO] - Training Epoch: 2/2, step 236/7134 completed (loss: 0.03879529610276222, acc: 0.987500011920929)
[2024-12-17 04:41:52,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:52,611][root][INFO] - Training Epoch: 2/2, step 237/7134 completed (loss: 0.0816236287355423, acc: 0.9791356325149536)
[2024-12-17 04:41:52,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:53,004][root][INFO] - Training Epoch: 2/2, step 238/7134 completed (loss: 0.08362575620412827, acc: 0.983208954334259)
[2024-12-17 04:41:53,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:53,425][root][INFO] - Training Epoch: 2/2, step 239/7134 completed (loss: 0.026128290221095085, acc: 0.9894958138465881)
[2024-12-17 04:41:53,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:53,847][root][INFO] - Training Epoch: 2/2, step 240/7134 completed (loss: 0.06905703991651535, acc: 0.9788135886192322)
[2024-12-17 04:41:53,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:54,275][root][INFO] - Training Epoch: 2/2, step 241/7134 completed (loss: 0.11251916736364365, acc: 0.979066014289856)
[2024-12-17 04:41:54,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:54,682][root][INFO] - Training Epoch: 2/2, step 242/7134 completed (loss: 0.08894116431474686, acc: 0.9705372452735901)
[2024-12-17 04:41:54,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:55,087][root][INFO] - Training Epoch: 2/2, step 243/7134 completed (loss: 0.10089753568172455, acc: 0.9727891087532043)
[2024-12-17 04:41:55,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:55,514][root][INFO] - Training Epoch: 2/2, step 244/7134 completed (loss: 0.026980094611644745, acc: 0.9894419312477112)
[2024-12-17 04:41:55,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:55,956][root][INFO] - Training Epoch: 2/2, step 245/7134 completed (loss: 0.1004793718457222, acc: 0.9824868440628052)
[2024-12-17 04:41:56,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:56,388][root][INFO] - Training Epoch: 2/2, step 246/7134 completed (loss: 0.051235392689704895, acc: 0.9842271208763123)
[2024-12-17 04:41:56,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:56,827][root][INFO] - Training Epoch: 2/2, step 247/7134 completed (loss: 0.07932458072900772, acc: 0.9782214164733887)
[2024-12-17 04:41:56,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:57,266][root][INFO] - Training Epoch: 2/2, step 248/7134 completed (loss: 0.04535987973213196, acc: 0.9806201457977295)
[2024-12-17 04:41:57,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:57,631][root][INFO] - Training Epoch: 2/2, step 249/7134 completed (loss: 0.047879792749881744, acc: 0.9812332391738892)
[2024-12-17 04:41:57,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:58,050][root][INFO] - Training Epoch: 2/2, step 250/7134 completed (loss: 0.07374878227710724, acc: 0.9794303774833679)
[2024-12-17 04:41:58,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:58,465][root][INFO] - Training Epoch: 2/2, step 251/7134 completed (loss: 0.0583607479929924, acc: 0.9829059839248657)
[2024-12-17 04:41:58,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:58,878][root][INFO] - Training Epoch: 2/2, step 252/7134 completed (loss: 0.025489607825875282, acc: 0.9918032884597778)
[2024-12-17 04:41:59,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:59,324][root][INFO] - Training Epoch: 2/2, step 253/7134 completed (loss: 0.027599336579442024, acc: 0.9928698539733887)
[2024-12-17 04:41:59,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:41:59,751][root][INFO] - Training Epoch: 2/2, step 254/7134 completed (loss: 0.0407211072742939, acc: 0.9857142567634583)
[2024-12-17 04:41:59,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:00,173][root][INFO] - Training Epoch: 2/2, step 255/7134 completed (loss: 0.06361454725265503, acc: 0.9809941649436951)
[2024-12-17 04:42:00,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:00,557][root][INFO] - Training Epoch: 2/2, step 256/7134 completed (loss: 0.09540532529354095, acc: 0.9742646813392639)
[2024-12-17 04:42:00,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:01,031][root][INFO] - Training Epoch: 2/2, step 257/7134 completed (loss: 0.060950350016355515, acc: 0.9846625924110413)
[2024-12-17 04:42:01,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:01,445][root][INFO] - Training Epoch: 2/2, step 258/7134 completed (loss: 0.04838220775127411, acc: 0.9818181991577148)
[2024-12-17 04:42:01,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:01,877][root][INFO] - Training Epoch: 2/2, step 259/7134 completed (loss: 0.04196912795305252, acc: 0.9821717739105225)
[2024-12-17 04:42:02,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:02,336][root][INFO] - Training Epoch: 2/2, step 260/7134 completed (loss: 0.051300518214702606, acc: 0.9830795526504517)
[2024-12-17 04:42:02,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:02,769][root][INFO] - Training Epoch: 2/2, step 261/7134 completed (loss: 0.0395347960293293, acc: 0.9918200373649597)
[2024-12-17 04:42:02,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:03,150][root][INFO] - Training Epoch: 2/2, step 262/7134 completed (loss: 0.022603461518883705, acc: 0.9900166392326355)
[2024-12-17 04:42:03,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:03,573][root][INFO] - Training Epoch: 2/2, step 263/7134 completed (loss: 0.05093914270401001, acc: 0.984674334526062)
[2024-12-17 04:42:03,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:04,035][root][INFO] - Training Epoch: 2/2, step 264/7134 completed (loss: 0.0450853556394577, acc: 0.9883177280426025)
[2024-12-17 04:42:04,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:04,502][root][INFO] - Training Epoch: 2/2, step 265/7134 completed (loss: 0.06930787861347198, acc: 0.9819587469100952)
[2024-12-17 04:42:04,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:04,964][root][INFO] - Training Epoch: 2/2, step 266/7134 completed (loss: 0.04327886551618576, acc: 0.9862385392189026)
[2024-12-17 04:42:05,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:05,454][root][INFO] - Training Epoch: 2/2, step 267/7134 completed (loss: 0.05007471144199371, acc: 0.982758641242981)
[2024-12-17 04:42:05,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:05,937][root][INFO] - Training Epoch: 2/2, step 268/7134 completed (loss: 0.06837540119886398, acc: 0.9844357967376709)
[2024-12-17 04:42:06,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:06,396][root][INFO] - Training Epoch: 2/2, step 269/7134 completed (loss: 0.04740729182958603, acc: 0.9819193482398987)
[2024-12-17 04:42:06,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:06,825][root][INFO] - Training Epoch: 2/2, step 270/7134 completed (loss: 0.03784239664673805, acc: 0.9940298795700073)
[2024-12-17 04:42:06,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:07,283][root][INFO] - Training Epoch: 2/2, step 271/7134 completed (loss: 0.04462936148047447, acc: 0.9848675727844238)
[2024-12-17 04:42:07,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:07,734][root][INFO] - Training Epoch: 2/2, step 272/7134 completed (loss: 0.047538455575704575, acc: 0.9809160232543945)
[2024-12-17 04:42:07,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:08,191][root][INFO] - Training Epoch: 2/2, step 273/7134 completed (loss: 0.029815735295414925, acc: 0.9880239367485046)
[2024-12-17 04:42:08,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:08,602][root][INFO] - Training Epoch: 2/2, step 274/7134 completed (loss: 0.024944890290498734, acc: 0.993122398853302)
[2024-12-17 04:42:08,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:09,079][root][INFO] - Training Epoch: 2/2, step 275/7134 completed (loss: 0.040938202291727066, acc: 0.9872390031814575)
[2024-12-17 04:42:09,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:09,551][root][INFO] - Training Epoch: 2/2, step 276/7134 completed (loss: 0.02742168866097927, acc: 0.9902557730674744)
[2024-12-17 04:42:09,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:09,998][root][INFO] - Training Epoch: 2/2, step 277/7134 completed (loss: 0.047009315341711044, acc: 0.9845559597015381)
[2024-12-17 04:42:10,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:10,447][root][INFO] - Training Epoch: 2/2, step 278/7134 completed (loss: 0.03001444786787033, acc: 0.992337167263031)
[2024-12-17 04:42:10,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:10,925][root][INFO] - Training Epoch: 2/2, step 279/7134 completed (loss: 0.034741755574941635, acc: 0.9881889820098877)
[2024-12-17 04:42:11,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:11,346][root][INFO] - Training Epoch: 2/2, step 280/7134 completed (loss: 0.06689444929361343, acc: 0.9731183052062988)
[2024-12-17 04:42:11,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:11,793][root][INFO] - Training Epoch: 2/2, step 281/7134 completed (loss: 0.05935037508606911, acc: 0.9819999933242798)
[2024-12-17 04:42:11,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:12,240][root][INFO] - Training Epoch: 2/2, step 282/7134 completed (loss: 0.07118219882249832, acc: 0.9786259531974792)
[2024-12-17 04:42:12,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:12,679][root][INFO] - Training Epoch: 2/2, step 283/7134 completed (loss: 0.06983167678117752, acc: 0.9830220937728882)
[2024-12-17 04:42:12,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:13,132][root][INFO] - Training Epoch: 2/2, step 284/7134 completed (loss: 0.027828119695186615, acc: 0.9899328947067261)
[2024-12-17 04:42:13,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:13,576][root][INFO] - Training Epoch: 2/2, step 285/7134 completed (loss: 0.029711512848734856, acc: 0.9876543283462524)
[2024-12-17 04:42:13,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:14,018][root][INFO] - Training Epoch: 2/2, step 286/7134 completed (loss: 0.061738815158605576, acc: 0.982300877571106)
[2024-12-17 04:42:14,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:14,458][root][INFO] - Training Epoch: 2/2, step 287/7134 completed (loss: 0.042556554079055786, acc: 0.9871588945388794)
[2024-12-17 04:42:14,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:14,900][root][INFO] - Training Epoch: 2/2, step 288/7134 completed (loss: 0.07018707692623138, acc: 0.979742169380188)
[2024-12-17 04:42:15,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:15,376][root][INFO] - Training Epoch: 2/2, step 289/7134 completed (loss: 0.03777268901467323, acc: 0.9801084995269775)
[2024-12-17 04:42:15,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:15,832][root][INFO] - Training Epoch: 2/2, step 290/7134 completed (loss: 0.04603496193885803, acc: 0.9878419637680054)
[2024-12-17 04:42:15,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:16,286][root][INFO] - Training Epoch: 2/2, step 291/7134 completed (loss: 0.08003845810890198, acc: 0.9802631735801697)
[2024-12-17 04:42:16,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:16,730][root][INFO] - Training Epoch: 2/2, step 292/7134 completed (loss: 0.0780528262257576, acc: 0.9754601120948792)
[2024-12-17 04:42:16,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:17,178][root][INFO] - Training Epoch: 2/2, step 293/7134 completed (loss: 0.055519264191389084, acc: 0.9879518151283264)
[2024-12-17 04:42:17,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:17,633][root][INFO] - Training Epoch: 2/2, step 294/7134 completed (loss: 0.05240859091281891, acc: 0.9805068373680115)
[2024-12-17 04:42:17,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:18,102][root][INFO] - Training Epoch: 2/2, step 295/7134 completed (loss: 0.06913822889328003, acc: 0.9761092066764832)
[2024-12-17 04:42:18,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:18,550][root][INFO] - Training Epoch: 2/2, step 296/7134 completed (loss: 0.03799047693610191, acc: 0.9906976819038391)
[2024-12-17 04:42:18,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:19,001][root][INFO] - Training Epoch: 2/2, step 297/7134 completed (loss: 0.03087191842496395, acc: 0.9928951859474182)
[2024-12-17 04:42:19,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:19,438][root][INFO] - Training Epoch: 2/2, step 298/7134 completed (loss: 0.03027866780757904, acc: 0.9904000163078308)
[2024-12-17 04:42:19,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:19,857][root][INFO] - Training Epoch: 2/2, step 299/7134 completed (loss: 0.05422675237059593, acc: 0.9789473414421082)
[2024-12-17 04:42:20,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:20,311][root][INFO] - Training Epoch: 2/2, step 300/7134 completed (loss: 0.04395837336778641, acc: 0.9886731505393982)
[2024-12-17 04:42:20,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:20,768][root][INFO] - Training Epoch: 2/2, step 301/7134 completed (loss: 0.03508925065398216, acc: 0.9844412803649902)
[2024-12-17 04:42:20,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:21,179][root][INFO] - Training Epoch: 2/2, step 302/7134 completed (loss: 0.06815969944000244, acc: 0.9824561476707458)
[2024-12-17 04:42:21,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:21,611][root][INFO] - Training Epoch: 2/2, step 303/7134 completed (loss: 0.04343992844223976, acc: 0.984466016292572)
[2024-12-17 04:42:21,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:22,014][root][INFO] - Training Epoch: 2/2, step 304/7134 completed (loss: 0.030628902837634087, acc: 0.9925925731658936)
[2024-12-17 04:42:22,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:22,448][root][INFO] - Training Epoch: 2/2, step 305/7134 completed (loss: 0.021479027345776558, acc: 0.9936407208442688)
[2024-12-17 04:42:22,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:22,861][root][INFO] - Training Epoch: 2/2, step 306/7134 completed (loss: 0.00966745987534523, acc: 0.9981883764266968)
[2024-12-17 04:42:22,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:23,293][root][INFO] - Training Epoch: 2/2, step 307/7134 completed (loss: 0.06182806193828583, acc: 0.982206404209137)
[2024-12-17 04:42:23,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:23,720][root][INFO] - Training Epoch: 2/2, step 308/7134 completed (loss: 0.024291370064020157, acc: 0.9950658082962036)
[2024-12-17 04:42:23,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:24,170][root][INFO] - Training Epoch: 2/2, step 309/7134 completed (loss: 0.051949393004179, acc: 0.982758641242981)
[2024-12-17 04:42:24,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:24,643][root][INFO] - Training Epoch: 2/2, step 310/7134 completed (loss: 0.031328652054071426, acc: 0.988304078578949)
[2024-12-17 04:42:24,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:25,068][root][INFO] - Training Epoch: 2/2, step 311/7134 completed (loss: 0.027714235708117485, acc: 0.9860031008720398)
[2024-12-17 04:42:25,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:25,485][root][INFO] - Training Epoch: 2/2, step 312/7134 completed (loss: 0.02012380212545395, acc: 0.9948006868362427)
[2024-12-17 04:42:25,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:25,918][root][INFO] - Training Epoch: 2/2, step 313/7134 completed (loss: 0.04194936156272888, acc: 0.9895651936531067)
[2024-12-17 04:42:26,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:26,344][root][INFO] - Training Epoch: 2/2, step 314/7134 completed (loss: 0.035539768636226654, acc: 0.9921875)
[2024-12-17 04:42:26,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:26,777][root][INFO] - Training Epoch: 2/2, step 315/7134 completed (loss: 0.04266146197915077, acc: 0.9885246157646179)
[2024-12-17 04:42:26,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:27,207][root][INFO] - Training Epoch: 2/2, step 316/7134 completed (loss: 0.06029140576720238, acc: 0.9891696572303772)
[2024-12-17 04:42:27,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:27,661][root][INFO] - Training Epoch: 2/2, step 317/7134 completed (loss: 0.009012897498905659, acc: 0.9986467957496643)
[2024-12-17 04:42:27,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:28,130][root][INFO] - Training Epoch: 2/2, step 318/7134 completed (loss: 0.06412098556756973, acc: 0.9853479862213135)
[2024-12-17 04:42:28,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:28,571][root][INFO] - Training Epoch: 2/2, step 319/7134 completed (loss: 0.04998072609305382, acc: 0.9901823401451111)
[2024-12-17 04:42:28,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:29,027][root][INFO] - Training Epoch: 2/2, step 320/7134 completed (loss: 0.029015904292464256, acc: 0.9928673505783081)
[2024-12-17 04:42:29,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:29,506][root][INFO] - Training Epoch: 2/2, step 321/7134 completed (loss: 0.09482059627771378, acc: 0.9782886505126953)
[2024-12-17 04:42:29,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:29,977][root][INFO] - Training Epoch: 2/2, step 322/7134 completed (loss: 0.050136856734752655, acc: 0.9849849939346313)
[2024-12-17 04:42:30,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:30,413][root][INFO] - Training Epoch: 2/2, step 323/7134 completed (loss: 0.053984563797712326, acc: 0.9871630072593689)
[2024-12-17 04:42:30,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:30,883][root][INFO] - Training Epoch: 2/2, step 324/7134 completed (loss: 0.08059772104024887, acc: 0.9792865514755249)
[2024-12-17 04:42:31,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:31,346][root][INFO] - Training Epoch: 2/2, step 325/7134 completed (loss: 0.03213293477892876, acc: 0.9884318709373474)
[2024-12-17 04:42:31,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:31,784][root][INFO] - Training Epoch: 2/2, step 326/7134 completed (loss: 0.03843971714377403, acc: 0.9902557730674744)
[2024-12-17 04:42:31,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:32,269][root][INFO] - Training Epoch: 2/2, step 327/7134 completed (loss: 0.05716225504875183, acc: 0.9887387156486511)
[2024-12-17 04:42:32,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:32,755][root][INFO] - Training Epoch: 2/2, step 328/7134 completed (loss: 0.03601853922009468, acc: 0.9925925731658936)
[2024-12-17 04:42:32,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:33,229][root][INFO] - Training Epoch: 2/2, step 329/7134 completed (loss: 0.02360578440129757, acc: 0.9952996373176575)
[2024-12-17 04:42:33,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:33,697][root][INFO] - Training Epoch: 2/2, step 330/7134 completed (loss: 0.039822544902563095, acc: 0.9838871955871582)
[2024-12-17 04:42:33,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:34,148][root][INFO] - Training Epoch: 2/2, step 331/7134 completed (loss: 0.04191902279853821, acc: 0.9897377490997314)
[2024-12-17 04:42:34,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:34,592][root][INFO] - Training Epoch: 2/2, step 332/7134 completed (loss: 0.021337656304240227, acc: 0.9929161667823792)
[2024-12-17 04:42:34,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:35,018][root][INFO] - Training Epoch: 2/2, step 333/7134 completed (loss: 0.050617609173059464, acc: 0.9841849207878113)
[2024-12-17 04:42:35,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:35,460][root][INFO] - Training Epoch: 2/2, step 334/7134 completed (loss: 0.0207647867500782, acc: 0.9936628937721252)
[2024-12-17 04:42:35,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:35,915][root][INFO] - Training Epoch: 2/2, step 335/7134 completed (loss: 0.023800818249583244, acc: 0.9956331849098206)
[2024-12-17 04:42:36,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:36,369][root][INFO] - Training Epoch: 2/2, step 336/7134 completed (loss: 0.06046586483716965, acc: 0.9856287240982056)
[2024-12-17 04:42:36,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:36,813][root][INFO] - Training Epoch: 2/2, step 337/7134 completed (loss: 0.033398810774087906, acc: 0.9892638325691223)
[2024-12-17 04:42:36,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:37,256][root][INFO] - Training Epoch: 2/2, step 338/7134 completed (loss: 0.06286359578371048, acc: 0.983627200126648)
[2024-12-17 04:42:37,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:37,700][root][INFO] - Training Epoch: 2/2, step 339/7134 completed (loss: 0.025380481034517288, acc: 0.9950000047683716)
[2024-12-17 04:42:37,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:38,122][root][INFO] - Training Epoch: 2/2, step 340/7134 completed (loss: 0.039607852697372437, acc: 0.9898219108581543)
[2024-12-17 04:42:38,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:38,597][root][INFO] - Training Epoch: 2/2, step 341/7134 completed (loss: 0.026655491441488266, acc: 0.9936948418617249)
[2024-12-17 04:42:38,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:39,053][root][INFO] - Training Epoch: 2/2, step 342/7134 completed (loss: 0.019392773509025574, acc: 0.9939393997192383)
[2024-12-17 04:42:39,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:39,492][root][INFO] - Training Epoch: 2/2, step 343/7134 completed (loss: 0.03865087777376175, acc: 0.9943289160728455)
[2024-12-17 04:42:39,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:39,899][root][INFO] - Training Epoch: 2/2, step 344/7134 completed (loss: 0.018080078065395355, acc: 0.9963503479957581)
[2024-12-17 04:42:40,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:40,334][root][INFO] - Training Epoch: 2/2, step 345/7134 completed (loss: 0.033701494336128235, acc: 0.9892857074737549)
[2024-12-17 04:42:40,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:40,797][root][INFO] - Training Epoch: 2/2, step 346/7134 completed (loss: 0.032346516847610474, acc: 0.995230495929718)
[2024-12-17 04:42:40,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:41,251][root][INFO] - Training Epoch: 2/2, step 347/7134 completed (loss: 0.022083912044763565, acc: 0.9957924485206604)
[2024-12-17 04:42:41,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:41,710][root][INFO] - Training Epoch: 2/2, step 348/7134 completed (loss: 0.017934877425432205, acc: 0.998643159866333)
[2024-12-17 04:42:41,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:42,136][root][INFO] - Training Epoch: 2/2, step 349/7134 completed (loss: 0.037314046174287796, acc: 0.9865771532058716)
[2024-12-17 04:42:42,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:42,648][root][INFO] - Training Epoch: 2/2, step 350/7134 completed (loss: 0.044405192136764526, acc: 0.9855595827102661)
[2024-12-17 04:42:42,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:43,151][root][INFO] - Training Epoch: 2/2, step 351/7134 completed (loss: 0.03541906177997589, acc: 0.9898219108581543)
[2024-12-17 04:42:43,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:43,601][root][INFO] - Training Epoch: 2/2, step 352/7134 completed (loss: 0.02402234822511673, acc: 0.9945651888847351)
[2024-12-17 04:42:43,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:44,075][root][INFO] - Training Epoch: 2/2, step 353/7134 completed (loss: 0.027978796511888504, acc: 0.9906914830207825)
[2024-12-17 04:42:44,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:44,529][root][INFO] - Training Epoch: 2/2, step 354/7134 completed (loss: 0.018532905727624893, acc: 0.9976717233657837)
[2024-12-17 04:42:44,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:44,969][root][INFO] - Training Epoch: 2/2, step 355/7134 completed (loss: 0.06212395429611206, acc: 0.9902234673500061)
[2024-12-17 04:42:45,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:45,432][root][INFO] - Training Epoch: 2/2, step 356/7134 completed (loss: 0.033989522606134415, acc: 0.9920634627342224)
[2024-12-17 04:42:45,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:45,931][root][INFO] - Training Epoch: 2/2, step 357/7134 completed (loss: 0.026201320812106133, acc: 0.991094172000885)
[2024-12-17 04:42:46,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:46,366][root][INFO] - Training Epoch: 2/2, step 358/7134 completed (loss: 0.04614394158124924, acc: 0.9877216815948486)
[2024-12-17 04:42:46,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:46,824][root][INFO] - Training Epoch: 2/2, step 359/7134 completed (loss: 0.022258538752794266, acc: 0.9905405640602112)
[2024-12-17 04:42:46,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:47,244][root][INFO] - Training Epoch: 2/2, step 360/7134 completed (loss: 0.021838605403900146, acc: 0.9924699068069458)
[2024-12-17 04:42:47,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:47,670][root][INFO] - Training Epoch: 2/2, step 361/7134 completed (loss: 0.034043166786432266, acc: 0.9941262602806091)
[2024-12-17 04:42:47,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:48,085][root][INFO] - Training Epoch: 2/2, step 362/7134 completed (loss: 0.03025401569902897, acc: 0.9895209670066833)
[2024-12-17 04:42:48,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:48,546][root][INFO] - Training Epoch: 2/2, step 363/7134 completed (loss: 0.053387295454740524, acc: 0.98828125)
[2024-12-17 04:42:48,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:48,949][root][INFO] - Training Epoch: 2/2, step 364/7134 completed (loss: 0.026399539783596992, acc: 0.9906542301177979)
[2024-12-17 04:42:49,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:49,408][root][INFO] - Training Epoch: 2/2, step 365/7134 completed (loss: 0.025394761934876442, acc: 0.9931129217147827)
[2024-12-17 04:42:49,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:49,839][root][INFO] - Training Epoch: 2/2, step 366/7134 completed (loss: 0.03296651691198349, acc: 0.9874607920646667)
[2024-12-17 04:42:49,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:50,297][root][INFO] - Training Epoch: 2/2, step 367/7134 completed (loss: 0.021714404225349426, acc: 0.9925000071525574)
[2024-12-17 04:42:50,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:50,726][root][INFO] - Training Epoch: 2/2, step 368/7134 completed (loss: 0.013135075569152832, acc: 0.9970282316207886)
[2024-12-17 04:42:50,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:51,139][root][INFO] - Training Epoch: 2/2, step 369/7134 completed (loss: 0.023849794641137123, acc: 0.9908116459846497)
[2024-12-17 04:42:51,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:51,601][root][INFO] - Training Epoch: 2/2, step 370/7134 completed (loss: 0.05965155363082886, acc: 0.9868995547294617)
[2024-12-17 04:42:51,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:52,028][root][INFO] - Training Epoch: 2/2, step 371/7134 completed (loss: 0.033018551766872406, acc: 0.9894737005233765)
[2024-12-17 04:42:52,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:52,456][root][INFO] - Training Epoch: 2/2, step 372/7134 completed (loss: 0.030819585546851158, acc: 0.9910846948623657)
[2024-12-17 04:42:52,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:52,902][root][INFO] - Training Epoch: 2/2, step 373/7134 completed (loss: 0.018912525847554207, acc: 0.994020938873291)
[2024-12-17 04:42:53,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:53,349][root][INFO] - Training Epoch: 2/2, step 374/7134 completed (loss: 0.02484964020550251, acc: 0.9919614195823669)
[2024-12-17 04:42:53,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:53,775][root][INFO] - Training Epoch: 2/2, step 375/7134 completed (loss: 0.049814846366643906, acc: 0.9906291961669922)
[2024-12-17 04:42:53,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:54,232][root][INFO] - Training Epoch: 2/2, step 376/7134 completed (loss: 0.05964129790663719, acc: 0.9806896448135376)
[2024-12-17 04:42:54,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:54,678][root][INFO] - Training Epoch: 2/2, step 377/7134 completed (loss: 0.05182797834277153, acc: 0.9848693013191223)
[2024-12-17 04:42:54,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:55,121][root][INFO] - Training Epoch: 2/2, step 378/7134 completed (loss: 0.029767194762825966, acc: 0.9877384305000305)
[2024-12-17 04:42:55,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:55,578][root][INFO] - Training Epoch: 2/2, step 379/7134 completed (loss: 0.022726550698280334, acc: 0.9937185645103455)
[2024-12-17 04:42:55,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:56,035][root][INFO] - Training Epoch: 2/2, step 380/7134 completed (loss: 0.064444400370121, acc: 0.9816031455993652)
[2024-12-17 04:42:56,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:56,520][root][INFO] - Training Epoch: 2/2, step 381/7134 completed (loss: 0.05056782439351082, acc: 0.9896640777587891)
[2024-12-17 04:42:56,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:56,968][root][INFO] - Training Epoch: 2/2, step 382/7134 completed (loss: 0.032569896429777145, acc: 0.9910141229629517)
[2024-12-17 04:42:57,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:57,392][root][INFO] - Training Epoch: 2/2, step 383/7134 completed (loss: 0.043626826256513596, acc: 0.9867674708366394)
[2024-12-17 04:42:57,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:57,806][root][INFO] - Training Epoch: 2/2, step 384/7134 completed (loss: 0.029243439435958862, acc: 0.9919893145561218)
[2024-12-17 04:42:57,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:58,228][root][INFO] - Training Epoch: 2/2, step 385/7134 completed (loss: 0.022422686219215393, acc: 0.9968602657318115)
[2024-12-17 04:42:58,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:58,583][root][INFO] - Training Epoch: 2/2, step 386/7134 completed (loss: 0.015413166023790836, acc: 0.9959100484848022)
[2024-12-17 04:42:58,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:59,039][root][INFO] - Training Epoch: 2/2, step 387/7134 completed (loss: 0.03820798173546791, acc: 0.9883381724357605)
[2024-12-17 04:42:59,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:59,495][root][INFO] - Training Epoch: 2/2, step 388/7134 completed (loss: 0.017573393881320953, acc: 0.9964788556098938)
[2024-12-17 04:42:59,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:42:59,971][root][INFO] - Training Epoch: 2/2, step 389/7134 completed (loss: 0.06392230093479156, acc: 0.9862259030342102)
[2024-12-17 04:43:00,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:00,415][root][INFO] - Training Epoch: 2/2, step 390/7134 completed (loss: 0.029881693422794342, acc: 0.9967637658119202)
[2024-12-17 04:43:00,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:00,825][root][INFO] - Training Epoch: 2/2, step 391/7134 completed (loss: 0.04863566532731056, acc: 0.9829931855201721)
[2024-12-17 04:43:00,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:01,283][root][INFO] - Training Epoch: 2/2, step 392/7134 completed (loss: 0.03406968340277672, acc: 0.9866666793823242)
[2024-12-17 04:43:01,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:01,700][root][INFO] - Training Epoch: 2/2, step 393/7134 completed (loss: 0.027279645204544067, acc: 0.9902777671813965)
[2024-12-17 04:43:01,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:02,100][root][INFO] - Training Epoch: 2/2, step 394/7134 completed (loss: 0.04818836227059364, acc: 0.9863813519477844)
[2024-12-17 04:43:02,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:02,516][root][INFO] - Training Epoch: 2/2, step 395/7134 completed (loss: 0.0746627077460289, acc: 0.9862825870513916)
[2024-12-17 04:43:02,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:02,933][root][INFO] - Training Epoch: 2/2, step 396/7134 completed (loss: 0.026581235229969025, acc: 0.9892473220825195)
[2024-12-17 04:43:03,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:03,396][root][INFO] - Training Epoch: 2/2, step 397/7134 completed (loss: 0.08939950913190842, acc: 0.9801587462425232)
[2024-12-17 04:43:03,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:03,860][root][INFO] - Training Epoch: 2/2, step 398/7134 completed (loss: 0.027565481141209602, acc: 0.9948453903198242)
[2024-12-17 04:43:03,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:04,279][root][INFO] - Training Epoch: 2/2, step 399/7134 completed (loss: 0.057064153254032135, acc: 0.9873217344284058)
[2024-12-17 04:43:04,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:04,744][root][INFO] - Training Epoch: 2/2, step 400/7134 completed (loss: 0.09195933490991592, acc: 0.983582079410553)
[2024-12-17 04:43:04,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:05,212][root][INFO] - Training Epoch: 2/2, step 401/7134 completed (loss: 0.04853087663650513, acc: 0.9865196347236633)
[2024-12-17 04:43:05,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:05,709][root][INFO] - Training Epoch: 2/2, step 402/7134 completed (loss: 0.03105117939412594, acc: 0.9898605942726135)
[2024-12-17 04:43:05,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:06,204][root][INFO] - Training Epoch: 2/2, step 403/7134 completed (loss: 0.03667379543185234, acc: 0.9935204982757568)
[2024-12-17 04:43:06,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:06,651][root][INFO] - Training Epoch: 2/2, step 404/7134 completed (loss: 0.052729371935129166, acc: 0.9884615540504456)
[2024-12-17 04:43:06,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:07,138][root][INFO] - Training Epoch: 2/2, step 405/7134 completed (loss: 0.08663171529769897, acc: 0.9813084006309509)
[2024-12-17 04:43:07,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:07,595][root][INFO] - Training Epoch: 2/2, step 406/7134 completed (loss: 0.05304491147398949, acc: 0.9841269850730896)
[2024-12-17 04:43:07,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:07,987][root][INFO] - Training Epoch: 2/2, step 407/7134 completed (loss: 0.12254507094621658, acc: 0.9661017060279846)
[2024-12-17 04:43:08,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:08,465][root][INFO] - Training Epoch: 2/2, step 408/7134 completed (loss: 0.09116929024457932, acc: 0.9766803979873657)
[2024-12-17 04:43:08,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:08,921][root][INFO] - Training Epoch: 2/2, step 409/7134 completed (loss: 0.06114278733730316, acc: 0.9849056601524353)
[2024-12-17 04:43:09,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:09,407][root][INFO] - Training Epoch: 2/2, step 410/7134 completed (loss: 0.06554879993200302, acc: 0.9777448177337646)
[2024-12-17 04:43:09,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:09,880][root][INFO] - Training Epoch: 2/2, step 411/7134 completed (loss: 0.05496622622013092, acc: 0.9873417615890503)
[2024-12-17 04:43:09,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:10,357][root][INFO] - Training Epoch: 2/2, step 412/7134 completed (loss: 0.0364864245057106, acc: 0.9897025227546692)
[2024-12-17 04:43:10,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:10,788][root][INFO] - Training Epoch: 2/2, step 413/7134 completed (loss: 0.046813011169433594, acc: 0.9879840016365051)
[2024-12-17 04:43:10,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:11,205][root][INFO] - Training Epoch: 2/2, step 414/7134 completed (loss: 0.041000135242938995, acc: 0.9896142482757568)
[2024-12-17 04:43:11,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:11,662][root][INFO] - Training Epoch: 2/2, step 415/7134 completed (loss: 0.045041684061288834, acc: 0.9907407164573669)
[2024-12-17 04:43:11,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:12,147][root][INFO] - Training Epoch: 2/2, step 416/7134 completed (loss: 0.0407826267182827, acc: 0.9893742799758911)
[2024-12-17 04:43:12,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:12,601][root][INFO] - Training Epoch: 2/2, step 417/7134 completed (loss: 0.08120562881231308, acc: 0.97826087474823)
[2024-12-17 04:43:12,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:13,081][root][INFO] - Training Epoch: 2/2, step 418/7134 completed (loss: 0.031054506078362465, acc: 0.991963267326355)
[2024-12-17 04:43:13,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:13,552][root][INFO] - Training Epoch: 2/2, step 419/7134 completed (loss: 0.04604180529713631, acc: 0.9863523840904236)
[2024-12-17 04:43:13,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:13,966][root][INFO] - Training Epoch: 2/2, step 420/7134 completed (loss: 0.03141653165221214, acc: 0.9881556630134583)
[2024-12-17 04:43:14,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:14,393][root][INFO] - Training Epoch: 2/2, step 421/7134 completed (loss: 0.024867167696356773, acc: 0.9904458522796631)
[2024-12-17 04:43:14,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:14,827][root][INFO] - Training Epoch: 2/2, step 422/7134 completed (loss: 0.03086388297379017, acc: 0.9911764860153198)
[2024-12-17 04:43:14,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:15,287][root][INFO] - Training Epoch: 2/2, step 423/7134 completed (loss: 0.016674190759658813, acc: 0.9942857027053833)
[2024-12-17 04:43:15,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:15,696][root][INFO] - Training Epoch: 2/2, step 424/7134 completed (loss: 0.037027399986982346, acc: 0.9841772317886353)
[2024-12-17 04:43:15,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:16,128][root][INFO] - Training Epoch: 2/2, step 425/7134 completed (loss: 0.011023473925888538, acc: 0.9970930218696594)
[2024-12-17 04:43:16,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:16,559][root][INFO] - Training Epoch: 2/2, step 426/7134 completed (loss: 0.014027837663888931, acc: 0.9958217144012451)
[2024-12-17 04:43:16,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:16,981][root][INFO] - Training Epoch: 2/2, step 427/7134 completed (loss: 0.019335651770234108, acc: 0.9954476356506348)
[2024-12-17 04:43:17,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:17,426][root][INFO] - Training Epoch: 2/2, step 428/7134 completed (loss: 0.028976788744330406, acc: 0.9924699068069458)
[2024-12-17 04:43:17,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:17,856][root][INFO] - Training Epoch: 2/2, step 429/7134 completed (loss: 0.03561949357390404, acc: 0.9888712167739868)
[2024-12-17 04:43:17,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:18,289][root][INFO] - Training Epoch: 2/2, step 430/7134 completed (loss: 0.023088401183485985, acc: 0.9928264021873474)
[2024-12-17 04:43:18,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:18,714][root][INFO] - Training Epoch: 2/2, step 431/7134 completed (loss: 0.02543066255748272, acc: 0.9956772327423096)
[2024-12-17 04:43:18,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:19,137][root][INFO] - Training Epoch: 2/2, step 432/7134 completed (loss: 0.0187459047883749, acc: 0.9963436722755432)
[2024-12-17 04:43:19,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:19,605][root][INFO] - Training Epoch: 2/2, step 433/7134 completed (loss: 0.01902446709573269, acc: 0.9959239363670349)
[2024-12-17 04:43:19,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:20,048][root][INFO] - Training Epoch: 2/2, step 434/7134 completed (loss: 0.030259067192673683, acc: 0.9926793575286865)
[2024-12-17 04:43:20,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:20,512][root][INFO] - Training Epoch: 2/2, step 435/7134 completed (loss: 0.02007152885198593, acc: 0.9971631169319153)
[2024-12-17 04:43:20,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:20,944][root][INFO] - Training Epoch: 2/2, step 436/7134 completed (loss: 0.027570689097046852, acc: 0.9960629940032959)
[2024-12-17 04:43:21,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:21,353][root][INFO] - Training Epoch: 2/2, step 437/7134 completed (loss: 0.04610620439052582, acc: 0.9911660552024841)
[2024-12-17 04:43:21,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:21,801][root][INFO] - Training Epoch: 2/2, step 438/7134 completed (loss: 0.02211836911737919, acc: 0.9942307472229004)
[2024-12-17 04:43:21,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:22,266][root][INFO] - Training Epoch: 2/2, step 439/7134 completed (loss: 0.03782059997320175, acc: 0.9869109988212585)
[2024-12-17 04:43:22,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:22,679][root][INFO] - Training Epoch: 2/2, step 440/7134 completed (loss: 0.03821419179439545, acc: 0.984402060508728)
[2024-12-17 04:43:22,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:23,114][root][INFO] - Training Epoch: 2/2, step 441/7134 completed (loss: 0.006168878637254238, acc: 1.0)
[2024-12-17 04:43:23,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:23,542][root][INFO] - Training Epoch: 2/2, step 442/7134 completed (loss: 0.019253043457865715, acc: 0.9925373196601868)
[2024-12-17 04:43:23,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:23,992][root][INFO] - Training Epoch: 2/2, step 443/7134 completed (loss: 0.006644997745752335, acc: 1.0)
[2024-12-17 04:43:24,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:24,393][root][INFO] - Training Epoch: 2/2, step 444/7134 completed (loss: 0.011355924420058727, acc: 0.996666669845581)
[2024-12-17 04:43:24,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:24,832][root][INFO] - Training Epoch: 2/2, step 445/7134 completed (loss: 0.026306116953492165, acc: 0.991253674030304)
[2024-12-17 04:43:24,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:25,283][root][INFO] - Training Epoch: 2/2, step 446/7134 completed (loss: 0.014074593782424927, acc: 0.9958217144012451)
[2024-12-17 04:43:25,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:25,719][root][INFO] - Training Epoch: 2/2, step 447/7134 completed (loss: 0.01214880682528019, acc: 0.9986130595207214)
[2024-12-17 04:43:25,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:26,194][root][INFO] - Training Epoch: 2/2, step 448/7134 completed (loss: 0.054626498371362686, acc: 0.9846547245979309)
[2024-12-17 04:43:26,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:26,665][root][INFO] - Training Epoch: 2/2, step 449/7134 completed (loss: 0.13223814964294434, acc: 0.977748692035675)
[2024-12-17 04:43:26,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:27,142][root][INFO] - Training Epoch: 2/2, step 450/7134 completed (loss: 0.06484542042016983, acc: 0.9840764403343201)
[2024-12-17 04:43:27,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:27,620][root][INFO] - Training Epoch: 2/2, step 451/7134 completed (loss: 0.12637020647525787, acc: 0.9690844416618347)
[2024-12-17 04:43:27,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:28,089][root][INFO] - Training Epoch: 2/2, step 452/7134 completed (loss: 0.06657256186008453, acc: 0.9726027250289917)
[2024-12-17 04:43:28,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:28,504][root][INFO] - Training Epoch: 2/2, step 453/7134 completed (loss: 0.05304591730237007, acc: 0.9798164963722229)
[2024-12-17 04:43:28,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:28,995][root][INFO] - Training Epoch: 2/2, step 454/7134 completed (loss: 0.08973897248506546, acc: 0.979547917842865)
[2024-12-17 04:43:29,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:29,455][root][INFO] - Training Epoch: 2/2, step 455/7134 completed (loss: 0.10297952592372894, acc: 0.9725490212440491)
[2024-12-17 04:43:29,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:29,901][root][INFO] - Training Epoch: 2/2, step 456/7134 completed (loss: 0.028752638027071953, acc: 0.9915013909339905)
[2024-12-17 04:43:30,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:30,356][root][INFO] - Training Epoch: 2/2, step 457/7134 completed (loss: 0.03307046368718147, acc: 0.9899328947067261)
[2024-12-17 04:43:30,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:30,786][root][INFO] - Training Epoch: 2/2, step 458/7134 completed (loss: 0.05155017971992493, acc: 0.9880715608596802)
[2024-12-17 04:43:30,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:31,244][root][INFO] - Training Epoch: 2/2, step 459/7134 completed (loss: 0.08559233695268631, acc: 0.9807407259941101)
[2024-12-17 04:43:31,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:31,692][root][INFO] - Training Epoch: 2/2, step 460/7134 completed (loss: 0.07271065562963486, acc: 0.9842519760131836)
[2024-12-17 04:43:31,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:32,169][root][INFO] - Training Epoch: 2/2, step 461/7134 completed (loss: 0.030200837180018425, acc: 0.9901823401451111)
[2024-12-17 04:43:32,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:32,700][root][INFO] - Training Epoch: 2/2, step 462/7134 completed (loss: 0.09399911761283875, acc: 0.9731308221817017)
[2024-12-17 04:43:32,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:33,182][root][INFO] - Training Epoch: 2/2, step 463/7134 completed (loss: 0.05679459124803543, acc: 0.9836888313293457)
[2024-12-17 04:43:33,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:33,647][root][INFO] - Training Epoch: 2/2, step 464/7134 completed (loss: 0.05715883895754814, acc: 0.9830028414726257)
[2024-12-17 04:43:33,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:34,078][root][INFO] - Training Epoch: 2/2, step 465/7134 completed (loss: 0.08198295533657074, acc: 0.9817232489585876)
[2024-12-17 04:43:34,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:34,543][root][INFO] - Training Epoch: 2/2, step 466/7134 completed (loss: 0.09366240352392197, acc: 0.9742599725723267)
[2024-12-17 04:43:34,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:35,010][root][INFO] - Training Epoch: 2/2, step 467/7134 completed (loss: 0.13869509100914001, acc: 0.9603623747825623)
[2024-12-17 04:43:35,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:35,401][root][INFO] - Training Epoch: 2/2, step 468/7134 completed (loss: 0.19776113331317902, acc: 0.95323246717453)
[2024-12-17 04:43:35,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:35,846][root][INFO] - Training Epoch: 2/2, step 469/7134 completed (loss: 0.057981181889772415, acc: 0.9812679886817932)
[2024-12-17 04:43:35,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:36,279][root][INFO] - Training Epoch: 2/2, step 470/7134 completed (loss: 0.0744757279753685, acc: 0.9823129177093506)
[2024-12-17 04:43:36,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:36,731][root][INFO] - Training Epoch: 2/2, step 471/7134 completed (loss: 0.07847262918949127, acc: 0.9798816442489624)
[2024-12-17 04:43:36,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:37,160][root][INFO] - Training Epoch: 2/2, step 472/7134 completed (loss: 0.10078568011522293, acc: 0.9750733375549316)
[2024-12-17 04:43:37,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:37,645][root][INFO] - Training Epoch: 2/2, step 473/7134 completed (loss: 0.05222059786319733, acc: 0.9830247163772583)
[2024-12-17 04:43:37,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:38,099][root][INFO] - Training Epoch: 2/2, step 474/7134 completed (loss: 0.09702995419502258, acc: 0.9749670624732971)
[2024-12-17 04:43:38,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:38,536][root][INFO] - Training Epoch: 2/2, step 475/7134 completed (loss: 0.11239340156316757, acc: 0.9779411554336548)
[2024-12-17 04:43:38,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:38,981][root][INFO] - Training Epoch: 2/2, step 476/7134 completed (loss: 0.07765114307403564, acc: 0.9699140191078186)
[2024-12-17 04:43:39,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:39,468][root][INFO] - Training Epoch: 2/2, step 477/7134 completed (loss: 0.06770149618387222, acc: 0.9792175889015198)
[2024-12-17 04:43:39,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:39,918][root][INFO] - Training Epoch: 2/2, step 478/7134 completed (loss: 0.1291462928056717, acc: 0.9640591740608215)
[2024-12-17 04:43:40,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:40,339][root][INFO] - Training Epoch: 2/2, step 479/7134 completed (loss: 0.037061505019664764, acc: 0.9899569749832153)
[2024-12-17 04:43:40,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:40,757][root][INFO] - Training Epoch: 2/2, step 480/7134 completed (loss: 0.02902529388666153, acc: 0.9912408590316772)
[2024-12-17 04:43:40,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:41,220][root][INFO] - Training Epoch: 2/2, step 481/7134 completed (loss: 0.03767804801464081, acc: 0.9908854365348816)
[2024-12-17 04:43:41,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:41,646][root][INFO] - Training Epoch: 2/2, step 482/7134 completed (loss: 0.01972593367099762, acc: 0.9957143068313599)
[2024-12-17 04:43:41,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:42,106][root][INFO] - Training Epoch: 2/2, step 483/7134 completed (loss: 0.013367349281907082, acc: 0.996314525604248)
[2024-12-17 04:43:42,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:42,542][root][INFO] - Training Epoch: 2/2, step 484/7134 completed (loss: 0.07115436345338821, acc: 0.9852941036224365)
[2024-12-17 04:43:42,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:42,982][root][INFO] - Training Epoch: 2/2, step 485/7134 completed (loss: 0.10158871114253998, acc: 0.97579425573349)
[2024-12-17 04:43:43,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:43,414][root][INFO] - Training Epoch: 2/2, step 486/7134 completed (loss: 0.04654774069786072, acc: 0.9884868264198303)
[2024-12-17 04:43:43,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:43,846][root][INFO] - Training Epoch: 2/2, step 487/7134 completed (loss: 0.0307230893522501, acc: 0.9941262602806091)
[2024-12-17 04:43:43,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:44,270][root][INFO] - Training Epoch: 2/2, step 488/7134 completed (loss: 0.09893286228179932, acc: 0.9764492511749268)
[2024-12-17 04:43:44,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:44,706][root][INFO] - Training Epoch: 2/2, step 489/7134 completed (loss: 0.07027119398117065, acc: 0.9831932783126831)
[2024-12-17 04:43:44,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:45,136][root][INFO] - Training Epoch: 2/2, step 490/7134 completed (loss: 0.05242704600095749, acc: 0.9904761910438538)
[2024-12-17 04:43:45,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:45,546][root][INFO] - Training Epoch: 2/2, step 491/7134 completed (loss: 0.03331770747900009, acc: 0.9934210777282715)
[2024-12-17 04:43:45,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:45,973][root][INFO] - Training Epoch: 2/2, step 492/7134 completed (loss: 0.01375510822981596, acc: 0.9969742894172668)
[2024-12-17 04:43:46,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:46,430][root][INFO] - Training Epoch: 2/2, step 493/7134 completed (loss: 0.06306450814008713, acc: 0.9770773649215698)
[2024-12-17 04:43:46,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:46,863][root][INFO] - Training Epoch: 2/2, step 494/7134 completed (loss: 0.026672611013054848, acc: 0.9921875)
[2024-12-17 04:43:46,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:47,272][root][INFO] - Training Epoch: 2/2, step 495/7134 completed (loss: 0.03211453557014465, acc: 0.9921568632125854)
[2024-12-17 04:43:47,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:47,686][root][INFO] - Training Epoch: 2/2, step 496/7134 completed (loss: 0.06489527970552444, acc: 0.9837398529052734)
[2024-12-17 04:43:47,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:48,121][root][INFO] - Training Epoch: 2/2, step 497/7134 completed (loss: 0.0723937377333641, acc: 0.9806201457977295)
[2024-12-17 04:43:48,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:48,562][root][INFO] - Training Epoch: 2/2, step 498/7134 completed (loss: 0.029536085203289986, acc: 0.9919871687889099)
[2024-12-17 04:43:48,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:49,032][root][INFO] - Training Epoch: 2/2, step 499/7134 completed (loss: 0.017783157527446747, acc: 0.9944367408752441)
[2024-12-17 04:43:49,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:49,468][root][INFO] - Training Epoch: 2/2, step 500/7134 completed (loss: 0.03385375440120697, acc: 0.9879999756813049)
[2024-12-17 04:43:49,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:49,932][root][INFO] - Training Epoch: 2/2, step 501/7134 completed (loss: 0.016307897865772247, acc: 0.9972299337387085)
[2024-12-17 04:43:50,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:50,348][root][INFO] - Training Epoch: 2/2, step 502/7134 completed (loss: 0.017493540421128273, acc: 0.9969419240951538)
[2024-12-17 04:43:50,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:50,786][root][INFO] - Training Epoch: 2/2, step 503/7134 completed (loss: 0.04079759865999222, acc: 0.9852349162101746)
[2024-12-17 04:43:50,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:51,237][root][INFO] - Training Epoch: 2/2, step 504/7134 completed (loss: 0.01686098240315914, acc: 0.994413435459137)
[2024-12-17 04:43:51,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:51,669][root][INFO] - Training Epoch: 2/2, step 505/7134 completed (loss: 0.01352690439671278, acc: 0.9947643876075745)
[2024-12-17 04:43:51,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:52,138][root][INFO] - Training Epoch: 2/2, step 506/7134 completed (loss: 0.03572269529104233, acc: 0.9875621795654297)
[2024-12-17 04:43:52,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:52,602][root][INFO] - Training Epoch: 2/2, step 507/7134 completed (loss: 0.042055170983076096, acc: 0.9947368502616882)
[2024-12-17 04:43:52,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:53,048][root][INFO] - Training Epoch: 2/2, step 508/7134 completed (loss: 0.04166368767619133, acc: 0.9874301552772522)
[2024-12-17 04:43:53,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:53,520][root][INFO] - Training Epoch: 2/2, step 509/7134 completed (loss: 0.044595811516046524, acc: 0.9876352548599243)
[2024-12-17 04:43:53,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:53,949][root][INFO] - Training Epoch: 2/2, step 510/7134 completed (loss: 0.09721235185861588, acc: 0.9854469895362854)
[2024-12-17 04:43:54,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:54,366][root][INFO] - Training Epoch: 2/2, step 511/7134 completed (loss: 0.03818377107381821, acc: 0.995110034942627)
[2024-12-17 04:43:54,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:54,803][root][INFO] - Training Epoch: 2/2, step 512/7134 completed (loss: 0.10975346714258194, acc: 0.9739478826522827)
[2024-12-17 04:43:54,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:55,217][root][INFO] - Training Epoch: 2/2, step 513/7134 completed (loss: 0.08995014429092407, acc: 0.9759036302566528)
[2024-12-17 04:43:55,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:55,598][root][INFO] - Training Epoch: 2/2, step 514/7134 completed (loss: 0.0898783802986145, acc: 0.9698492288589478)
[2024-12-17 04:43:55,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:56,079][root][INFO] - Training Epoch: 2/2, step 515/7134 completed (loss: 0.03704571723937988, acc: 0.9900990128517151)
[2024-12-17 04:43:56,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:56,465][root][INFO] - Training Epoch: 2/2, step 516/7134 completed (loss: 0.024948619306087494, acc: 0.9954233169555664)
[2024-12-17 04:43:56,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:56,900][root][INFO] - Training Epoch: 2/2, step 517/7134 completed (loss: 0.10169631242752075, acc: 0.9767025113105774)
[2024-12-17 04:43:57,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:57,367][root][INFO] - Training Epoch: 2/2, step 518/7134 completed (loss: 0.027217449620366096, acc: 0.9925037622451782)
[2024-12-17 04:43:57,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:57,794][root][INFO] - Training Epoch: 2/2, step 519/7134 completed (loss: 0.03070307895541191, acc: 0.9896907210350037)
[2024-12-17 04:43:57,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:58,226][root][INFO] - Training Epoch: 2/2, step 520/7134 completed (loss: 0.019665569067001343, acc: 0.9905063509941101)
[2024-12-17 04:43:58,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:58,666][root][INFO] - Training Epoch: 2/2, step 521/7134 completed (loss: 0.045785192400217056, acc: 0.9866488575935364)
[2024-12-17 04:43:58,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:59,113][root][INFO] - Training Epoch: 2/2, step 522/7134 completed (loss: 0.03010900877416134, acc: 0.9946380853652954)
[2024-12-17 04:43:59,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:43:59,587][root][INFO] - Training Epoch: 2/2, step 523/7134 completed (loss: 0.03415561467409134, acc: 0.9897660613059998)
[2024-12-17 04:43:59,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:00,046][root][INFO] - Training Epoch: 2/2, step 524/7134 completed (loss: 0.04968062788248062, acc: 0.9892473220825195)
[2024-12-17 04:44:00,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:00,469][root][INFO] - Training Epoch: 2/2, step 525/7134 completed (loss: 0.07671574503183365, acc: 0.9814528822898865)
[2024-12-17 04:44:00,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:00,923][root][INFO] - Training Epoch: 2/2, step 526/7134 completed (loss: 0.0395333431661129, acc: 0.9904109835624695)
[2024-12-17 04:44:01,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:01,344][root][INFO] - Training Epoch: 2/2, step 527/7134 completed (loss: 0.04681505635380745, acc: 0.9925373196601868)
[2024-12-17 04:44:01,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:01,807][root][INFO] - Training Epoch: 2/2, step 528/7134 completed (loss: 0.006006356328725815, acc: 0.9979879260063171)
[2024-12-17 04:44:01,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:02,271][root][INFO] - Training Epoch: 2/2, step 529/7134 completed (loss: 0.059451207518577576, acc: 0.9825396537780762)
[2024-12-17 04:44:02,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:02,697][root][INFO] - Training Epoch: 2/2, step 530/7134 completed (loss: 0.03933122381567955, acc: 0.9879931211471558)
[2024-12-17 04:44:02,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:03,082][root][INFO] - Training Epoch: 2/2, step 531/7134 completed (loss: 0.09307309985160828, acc: 0.9863247871398926)
[2024-12-17 04:44:03,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:03,510][root][INFO] - Training Epoch: 2/2, step 532/7134 completed (loss: 0.021362625062465668, acc: 0.9937629699707031)
[2024-12-17 04:44:03,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:03,935][root][INFO] - Training Epoch: 2/2, step 533/7134 completed (loss: 0.07227817177772522, acc: 0.9810996651649475)
[2024-12-17 04:44:04,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:04,395][root][INFO] - Training Epoch: 2/2, step 534/7134 completed (loss: 0.021023308858275414, acc: 0.9972527623176575)
[2024-12-17 04:44:04,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:04,858][root][INFO] - Training Epoch: 2/2, step 535/7134 completed (loss: 0.040613528341054916, acc: 0.9894551634788513)
[2024-12-17 04:44:04,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:05,307][root][INFO] - Training Epoch: 2/2, step 536/7134 completed (loss: 0.03084673173725605, acc: 0.9897810220718384)
[2024-12-17 04:44:05,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:05,725][root][INFO] - Training Epoch: 2/2, step 537/7134 completed (loss: 0.051130302250385284, acc: 0.9823269248008728)
[2024-12-17 04:44:05,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:06,148][root][INFO] - Training Epoch: 2/2, step 538/7134 completed (loss: 0.03502171114087105, acc: 0.9881305694580078)
[2024-12-17 04:44:06,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:06,570][root][INFO] - Training Epoch: 2/2, step 539/7134 completed (loss: 0.04543803632259369, acc: 0.9844290614128113)
[2024-12-17 04:44:06,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:06,977][root][INFO] - Training Epoch: 2/2, step 540/7134 completed (loss: 0.03635263442993164, acc: 0.991919219493866)
[2024-12-17 04:44:07,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:07,426][root][INFO] - Training Epoch: 2/2, step 541/7134 completed (loss: 0.05706179514527321, acc: 0.9867021441459656)
[2024-12-17 04:44:07,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:07,835][root][INFO] - Training Epoch: 2/2, step 542/7134 completed (loss: 0.0794176384806633, acc: 0.9812206625938416)
[2024-12-17 04:44:07,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:08,243][root][INFO] - Training Epoch: 2/2, step 543/7134 completed (loss: 0.08441624045372009, acc: 0.9746835231781006)
[2024-12-17 04:44:08,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:08,696][root][INFO] - Training Epoch: 2/2, step 544/7134 completed (loss: 0.05971034988760948, acc: 0.9826498627662659)
[2024-12-17 04:44:08,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:09,149][root][INFO] - Training Epoch: 2/2, step 545/7134 completed (loss: 0.06310596317052841, acc: 0.9871175289154053)
[2024-12-17 04:44:09,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:09,584][root][INFO] - Training Epoch: 2/2, step 546/7134 completed (loss: 0.1109418198466301, acc: 0.9669030904769897)
[2024-12-17 04:44:09,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:10,040][root][INFO] - Training Epoch: 2/2, step 547/7134 completed (loss: 0.06463253498077393, acc: 0.9869375824928284)
[2024-12-17 04:44:10,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:10,486][root][INFO] - Training Epoch: 2/2, step 548/7134 completed (loss: 0.03749190270900726, acc: 0.9895697236061096)
[2024-12-17 04:44:10,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:10,943][root][INFO] - Training Epoch: 2/2, step 549/7134 completed (loss: 0.0811409056186676, acc: 0.9767080545425415)
[2024-12-17 04:44:11,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:11,373][root][INFO] - Training Epoch: 2/2, step 550/7134 completed (loss: 0.05961392819881439, acc: 0.9846416115760803)
[2024-12-17 04:44:11,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:11,799][root][INFO] - Training Epoch: 2/2, step 551/7134 completed (loss: 0.06662441790103912, acc: 0.9760589599609375)
[2024-12-17 04:44:11,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:12,245][root][INFO] - Training Epoch: 2/2, step 552/7134 completed (loss: 0.036561351269483566, acc: 0.9900285005569458)
[2024-12-17 04:44:12,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:12,611][root][INFO] - Training Epoch: 2/2, step 553/7134 completed (loss: 0.054563067853450775, acc: 0.9824561476707458)
[2024-12-17 04:44:12,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:13,075][root][INFO] - Training Epoch: 2/2, step 554/7134 completed (loss: 0.06968063116073608, acc: 0.9786019921302795)
[2024-12-17 04:44:13,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:13,503][root][INFO] - Training Epoch: 2/2, step 555/7134 completed (loss: 0.05992470681667328, acc: 0.9763033390045166)
[2024-12-17 04:44:13,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:13,943][root][INFO] - Training Epoch: 2/2, step 556/7134 completed (loss: 0.04246843606233597, acc: 0.9900990128517151)
[2024-12-17 04:44:14,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:14,379][root][INFO] - Training Epoch: 2/2, step 557/7134 completed (loss: 0.07121932506561279, acc: 0.9729272127151489)
[2024-12-17 04:44:14,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:14,816][root][INFO] - Training Epoch: 2/2, step 558/7134 completed (loss: 0.02273426204919815, acc: 0.9929078221321106)
[2024-12-17 04:44:14,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:15,272][root][INFO] - Training Epoch: 2/2, step 559/7134 completed (loss: 0.09735674411058426, acc: 0.9686609506607056)
[2024-12-17 04:44:15,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:15,700][root][INFO] - Training Epoch: 2/2, step 560/7134 completed (loss: 0.04837401583790779, acc: 0.9894551634788513)
[2024-12-17 04:44:15,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:16,176][root][INFO] - Training Epoch: 2/2, step 561/7134 completed (loss: 0.0688871219754219, acc: 0.9795657992362976)
[2024-12-17 04:44:16,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:16,605][root][INFO] - Training Epoch: 2/2, step 562/7134 completed (loss: 0.03531273826956749, acc: 0.990728497505188)
[2024-12-17 04:44:16,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:17,011][root][INFO] - Training Epoch: 2/2, step 563/7134 completed (loss: 0.08434488624334335, acc: 0.982594907283783)
[2024-12-17 04:44:17,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:17,463][root][INFO] - Training Epoch: 2/2, step 564/7134 completed (loss: 0.05115117132663727, acc: 0.9814586043357849)
[2024-12-17 04:44:17,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:17,862][root][INFO] - Training Epoch: 2/2, step 565/7134 completed (loss: 0.0695628896355629, acc: 0.979899525642395)
[2024-12-17 04:44:17,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:18,283][root][INFO] - Training Epoch: 2/2, step 566/7134 completed (loss: 0.10067816078662872, acc: 0.9605568647384644)
[2024-12-17 04:44:18,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:18,735][root][INFO] - Training Epoch: 2/2, step 567/7134 completed (loss: 0.0507630817592144, acc: 0.9901823401451111)
[2024-12-17 04:44:18,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:19,170][root][INFO] - Training Epoch: 2/2, step 568/7134 completed (loss: 0.052213143557310104, acc: 0.98562091588974)
[2024-12-17 04:44:19,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:19,608][root][INFO] - Training Epoch: 2/2, step 569/7134 completed (loss: 0.02468210458755493, acc: 0.9925925731658936)
[2024-12-17 04:44:19,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:20,101][root][INFO] - Training Epoch: 2/2, step 570/7134 completed (loss: 0.03912379592657089, acc: 0.9847238659858704)
[2024-12-17 04:44:20,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:20,561][root][INFO] - Training Epoch: 2/2, step 571/7134 completed (loss: 0.023222757503390312, acc: 0.992443323135376)
[2024-12-17 04:44:20,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:21,010][root][INFO] - Training Epoch: 2/2, step 572/7134 completed (loss: 0.027456849813461304, acc: 0.9948520064353943)
[2024-12-17 04:44:21,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:21,457][root][INFO] - Training Epoch: 2/2, step 573/7134 completed (loss: 0.01804611273109913, acc: 0.9936061501502991)
[2024-12-17 04:44:21,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:21,877][root][INFO] - Training Epoch: 2/2, step 574/7134 completed (loss: 0.023305455222725868, acc: 0.9960474371910095)
[2024-12-17 04:44:22,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:22,359][root][INFO] - Training Epoch: 2/2, step 575/7134 completed (loss: 0.021663418039679527, acc: 0.9948586225509644)
[2024-12-17 04:44:22,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:22,799][root][INFO] - Training Epoch: 2/2, step 576/7134 completed (loss: 0.02355639822781086, acc: 0.9962871074676514)
[2024-12-17 04:44:22,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:23,248][root][INFO] - Training Epoch: 2/2, step 577/7134 completed (loss: 0.028624938800930977, acc: 0.9868247509002686)
[2024-12-17 04:44:23,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:23,720][root][INFO] - Training Epoch: 2/2, step 578/7134 completed (loss: 0.04120226949453354, acc: 0.988399088382721)
[2024-12-17 04:44:23,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:24,165][root][INFO] - Training Epoch: 2/2, step 579/7134 completed (loss: 0.07502175867557526, acc: 0.9781771302223206)
[2024-12-17 04:44:24,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:24,602][root][INFO] - Training Epoch: 2/2, step 580/7134 completed (loss: 0.06533533334732056, acc: 0.9791937470436096)
[2024-12-17 04:44:24,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:25,026][root][INFO] - Training Epoch: 2/2, step 581/7134 completed (loss: 0.03421524539589882, acc: 0.991631805896759)
[2024-12-17 04:44:25,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:25,490][root][INFO] - Training Epoch: 2/2, step 582/7134 completed (loss: 0.0268331877887249, acc: 0.9928143620491028)
[2024-12-17 04:44:25,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:25,951][root][INFO] - Training Epoch: 2/2, step 583/7134 completed (loss: 0.031071968376636505, acc: 0.9857142567634583)
[2024-12-17 04:44:26,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:26,413][root][INFO] - Training Epoch: 2/2, step 584/7134 completed (loss: 0.020895859226584435, acc: 0.9928229451179504)
[2024-12-17 04:44:26,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:26,862][root][INFO] - Training Epoch: 2/2, step 585/7134 completed (loss: 0.025421258062124252, acc: 0.9915459156036377)
[2024-12-17 04:44:26,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:27,284][root][INFO] - Training Epoch: 2/2, step 586/7134 completed (loss: 0.02970663085579872, acc: 0.9895697236061096)
[2024-12-17 04:44:27,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:27,724][root][INFO] - Training Epoch: 2/2, step 587/7134 completed (loss: 0.038129985332489014, acc: 0.9885641932487488)
[2024-12-17 04:44:27,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:28,189][root][INFO] - Training Epoch: 2/2, step 588/7134 completed (loss: 0.026949618011713028, acc: 0.9937205910682678)
[2024-12-17 04:44:28,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:28,642][root][INFO] - Training Epoch: 2/2, step 589/7134 completed (loss: 0.02967107854783535, acc: 0.9897210001945496)
[2024-12-17 04:44:28,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:29,089][root][INFO] - Training Epoch: 2/2, step 590/7134 completed (loss: 0.02249797061085701, acc: 0.9924812316894531)
[2024-12-17 04:44:29,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:29,536][root][INFO] - Training Epoch: 2/2, step 591/7134 completed (loss: 0.03414733707904816, acc: 0.991525411605835)
[2024-12-17 04:44:29,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:29,965][root][INFO] - Training Epoch: 2/2, step 592/7134 completed (loss: 0.03151397034525871, acc: 0.9936548471450806)
[2024-12-17 04:44:30,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:30,409][root][INFO] - Training Epoch: 2/2, step 593/7134 completed (loss: 0.03128563240170479, acc: 0.9881889820098877)
[2024-12-17 04:44:30,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:30,873][root][INFO] - Training Epoch: 2/2, step 594/7134 completed (loss: 0.059182778000831604, acc: 0.9861634969711304)
[2024-12-17 04:44:30,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:31,351][root][INFO] - Training Epoch: 2/2, step 595/7134 completed (loss: 0.04096531495451927, acc: 0.9873577952384949)
[2024-12-17 04:44:31,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:31,789][root][INFO] - Training Epoch: 2/2, step 596/7134 completed (loss: 0.026175785809755325, acc: 0.9896907210350037)
[2024-12-17 04:44:31,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:32,267][root][INFO] - Training Epoch: 2/2, step 597/7134 completed (loss: 0.1227930411696434, acc: 0.9789196252822876)
[2024-12-17 04:44:32,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:32,719][root][INFO] - Training Epoch: 2/2, step 598/7134 completed (loss: 0.04105423390865326, acc: 0.9864681959152222)
[2024-12-17 04:44:32,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:33,158][root][INFO] - Training Epoch: 2/2, step 599/7134 completed (loss: 0.04714943468570709, acc: 0.9862155318260193)
[2024-12-17 04:44:33,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:33,628][root][INFO] - Training Epoch: 2/2, step 600/7134 completed (loss: 0.048028454184532166, acc: 0.9915764331817627)
[2024-12-17 04:44:33,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:34,104][root][INFO] - Training Epoch: 2/2, step 601/7134 completed (loss: 0.050150249153375626, acc: 0.9806362390518188)
[2024-12-17 04:44:34,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:34,556][root][INFO] - Training Epoch: 2/2, step 602/7134 completed (loss: 0.05696145072579384, acc: 0.9860788583755493)
[2024-12-17 04:44:34,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:35,004][root][INFO] - Training Epoch: 2/2, step 603/7134 completed (loss: 0.03713185340166092, acc: 0.9858611822128296)
[2024-12-17 04:44:35,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:35,407][root][INFO] - Training Epoch: 2/2, step 604/7134 completed (loss: 0.04393994063138962, acc: 0.985358715057373)
[2024-12-17 04:44:35,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:35,859][root][INFO] - Training Epoch: 2/2, step 605/7134 completed (loss: 0.04552014544606209, acc: 0.9831606149673462)
[2024-12-17 04:44:35,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:36,316][root][INFO] - Training Epoch: 2/2, step 606/7134 completed (loss: 0.10475196689367294, acc: 0.9752781391143799)
[2024-12-17 04:44:36,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:36,769][root][INFO] - Training Epoch: 2/2, step 607/7134 completed (loss: 0.03693103790283203, acc: 0.9906542301177979)
[2024-12-17 04:44:36,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:37,227][root][INFO] - Training Epoch: 2/2, step 608/7134 completed (loss: 0.028762610629200935, acc: 0.9909326434135437)
[2024-12-17 04:44:37,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:37,692][root][INFO] - Training Epoch: 2/2, step 609/7134 completed (loss: 0.04045645892620087, acc: 0.9871194362640381)
[2024-12-17 04:44:37,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:38,159][root][INFO] - Training Epoch: 2/2, step 610/7134 completed (loss: 0.05371837317943573, acc: 0.9860935807228088)
[2024-12-17 04:44:38,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:38,609][root][INFO] - Training Epoch: 2/2, step 611/7134 completed (loss: 0.026041505858302116, acc: 0.992682933807373)
[2024-12-17 04:44:38,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:39,042][root][INFO] - Training Epoch: 2/2, step 612/7134 completed (loss: 0.030735157430171967, acc: 0.9868074059486389)
[2024-12-17 04:44:39,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:39,512][root][INFO] - Training Epoch: 2/2, step 613/7134 completed (loss: 0.05056796222925186, acc: 0.9777256846427917)
[2024-12-17 04:44:39,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:39,969][root][INFO] - Training Epoch: 2/2, step 614/7134 completed (loss: 0.023428555577993393, acc: 0.9932050108909607)
[2024-12-17 04:44:40,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:40,422][root][INFO] - Training Epoch: 2/2, step 615/7134 completed (loss: 0.019621459767222404, acc: 0.9938650131225586)
[2024-12-17 04:44:40,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:40,908][root][INFO] - Training Epoch: 2/2, step 616/7134 completed (loss: 0.031257398426532745, acc: 0.9897727370262146)
[2024-12-17 04:44:41,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:41,374][root][INFO] - Training Epoch: 2/2, step 617/7134 completed (loss: 0.03347054496407509, acc: 0.9908883571624756)
[2024-12-17 04:44:41,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:41,834][root][INFO] - Training Epoch: 2/2, step 618/7134 completed (loss: 0.03134053573012352, acc: 0.990641713142395)
[2024-12-17 04:44:41,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:42,228][root][INFO] - Training Epoch: 2/2, step 619/7134 completed (loss: 0.04385928064584732, acc: 0.9919028282165527)
[2024-12-17 04:44:42,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:42,683][root][INFO] - Training Epoch: 2/2, step 620/7134 completed (loss: 0.07568144053220749, acc: 0.9824841022491455)
[2024-12-17 04:44:42,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:43,136][root][INFO] - Training Epoch: 2/2, step 621/7134 completed (loss: 0.05529618635773659, acc: 0.9878234267234802)
[2024-12-17 04:44:43,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:43,578][root][INFO] - Training Epoch: 2/2, step 622/7134 completed (loss: 0.048187676817178726, acc: 0.9827833771705627)
[2024-12-17 04:44:43,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:43,985][root][INFO] - Training Epoch: 2/2, step 623/7134 completed (loss: 0.07095680385828018, acc: 0.9868804812431335)
[2024-12-17 04:44:44,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:44,452][root][INFO] - Training Epoch: 2/2, step 624/7134 completed (loss: 0.03450377658009529, acc: 0.9918919205665588)
[2024-12-17 04:44:44,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:44,914][root][INFO] - Training Epoch: 2/2, step 625/7134 completed (loss: 0.049520689994096756, acc: 0.9881266355514526)
[2024-12-17 04:44:45,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:45,322][root][INFO] - Training Epoch: 2/2, step 626/7134 completed (loss: 0.08207443356513977, acc: 0.9862542748451233)
[2024-12-17 04:44:45,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:45,751][root][INFO] - Training Epoch: 2/2, step 627/7134 completed (loss: 0.038326799869537354, acc: 0.9882006049156189)
[2024-12-17 04:44:45,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:46,183][root][INFO] - Training Epoch: 2/2, step 628/7134 completed (loss: 0.03238920122385025, acc: 0.9889042973518372)
[2024-12-17 04:44:46,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:46,622][root][INFO] - Training Epoch: 2/2, step 629/7134 completed (loss: 0.047625910490751266, acc: 0.9899857044219971)
[2024-12-17 04:44:46,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:47,091][root][INFO] - Training Epoch: 2/2, step 630/7134 completed (loss: 0.03402100130915642, acc: 0.984455943107605)
[2024-12-17 04:44:47,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:47,522][root][INFO] - Training Epoch: 2/2, step 631/7134 completed (loss: 0.027077458798885345, acc: 0.9894737005233765)
[2024-12-17 04:44:47,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:47,984][root][INFO] - Training Epoch: 2/2, step 632/7134 completed (loss: 0.029255608096718788, acc: 0.9886731505393982)
[2024-12-17 04:44:48,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:48,408][root][INFO] - Training Epoch: 2/2, step 633/7134 completed (loss: 0.04290151223540306, acc: 0.9883889555931091)
[2024-12-17 04:44:48,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:48,827][root][INFO] - Training Epoch: 2/2, step 634/7134 completed (loss: 0.027452683076262474, acc: 0.9920886158943176)
[2024-12-17 04:44:48,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:49,276][root][INFO] - Training Epoch: 2/2, step 635/7134 completed (loss: 0.041452061384916306, acc: 0.9862595200538635)
[2024-12-17 04:44:49,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:49,715][root][INFO] - Training Epoch: 2/2, step 636/7134 completed (loss: 0.06276406347751617, acc: 0.9889655113220215)
[2024-12-17 04:44:49,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:50,128][root][INFO] - Training Epoch: 2/2, step 637/7134 completed (loss: 0.03278723731637001, acc: 0.9869646430015564)
[2024-12-17 04:44:50,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:50,547][root][INFO] - Training Epoch: 2/2, step 638/7134 completed (loss: 0.05800529941916466, acc: 0.9859594106674194)
[2024-12-17 04:44:50,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:50,966][root][INFO] - Training Epoch: 2/2, step 639/7134 completed (loss: 0.04114409163594246, acc: 0.9883333444595337)
[2024-12-17 04:44:51,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:51,373][root][INFO] - Training Epoch: 2/2, step 640/7134 completed (loss: 0.05253538861870766, acc: 0.9878261089324951)
[2024-12-17 04:44:51,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:51,789][root][INFO] - Training Epoch: 2/2, step 641/7134 completed (loss: 0.035877641290426254, acc: 0.9836333990097046)
[2024-12-17 04:44:51,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:52,221][root][INFO] - Training Epoch: 2/2, step 642/7134 completed (loss: 0.02579343691468239, acc: 0.9914966225624084)
[2024-12-17 04:44:52,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:52,659][root][INFO] - Training Epoch: 2/2, step 643/7134 completed (loss: 0.021700864657759666, acc: 0.9961488842964172)
[2024-12-17 04:44:52,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:53,144][root][INFO] - Training Epoch: 2/2, step 644/7134 completed (loss: 0.027471425011754036, acc: 0.9961389899253845)
[2024-12-17 04:44:53,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:53,554][root][INFO] - Training Epoch: 2/2, step 645/7134 completed (loss: 0.021850410848855972, acc: 0.9915825128555298)
[2024-12-17 04:44:53,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:53,981][root][INFO] - Training Epoch: 2/2, step 646/7134 completed (loss: 0.04683743044734001, acc: 0.9908257126808167)
[2024-12-17 04:44:54,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:54,401][root][INFO] - Training Epoch: 2/2, step 647/7134 completed (loss: 0.007557791657745838, acc: 0.9983079433441162)
[2024-12-17 04:44:54,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:54,831][root][INFO] - Training Epoch: 2/2, step 648/7134 completed (loss: 0.10180461406707764, acc: 0.9720767736434937)
[2024-12-17 04:44:54,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:55,275][root][INFO] - Training Epoch: 2/2, step 649/7134 completed (loss: 0.05845251306891441, acc: 0.9846153855323792)
[2024-12-17 04:44:55,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:55,705][root][INFO] - Training Epoch: 2/2, step 650/7134 completed (loss: 0.05765511468052864, acc: 0.9843013882637024)
[2024-12-17 04:44:55,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:56,134][root][INFO] - Training Epoch: 2/2, step 651/7134 completed (loss: 0.10993126779794693, acc: 0.9709480404853821)
[2024-12-17 04:44:56,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:56,578][root][INFO] - Training Epoch: 2/2, step 652/7134 completed (loss: 0.03458806127309799, acc: 0.9879724979400635)
[2024-12-17 04:44:56,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:57,003][root][INFO] - Training Epoch: 2/2, step 653/7134 completed (loss: 0.03481833636760712, acc: 0.9872340559959412)
[2024-12-17 04:44:57,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:57,412][root][INFO] - Training Epoch: 2/2, step 654/7134 completed (loss: 0.12578006088733673, acc: 0.9654427766799927)
[2024-12-17 04:44:57,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:57,856][root][INFO] - Training Epoch: 2/2, step 655/7134 completed (loss: 0.062480378895998, acc: 0.9778226017951965)
[2024-12-17 04:44:57,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:58,281][root][INFO] - Training Epoch: 2/2, step 656/7134 completed (loss: 0.07756344228982925, acc: 0.9762532711029053)
[2024-12-17 04:44:58,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:58,741][root][INFO] - Training Epoch: 2/2, step 657/7134 completed (loss: 0.06337021291255951, acc: 0.9759229421615601)
[2024-12-17 04:44:58,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:59,177][root][INFO] - Training Epoch: 2/2, step 658/7134 completed (loss: 0.05431121587753296, acc: 0.9881423115730286)
[2024-12-17 04:44:59,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:44:59,632][root][INFO] - Training Epoch: 2/2, step 659/7134 completed (loss: 0.019996289163827896, acc: 0.9956011772155762)
[2024-12-17 04:44:59,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:00,102][root][INFO] - Training Epoch: 2/2, step 660/7134 completed (loss: 0.06190921738743782, acc: 0.9780701994895935)
[2024-12-17 04:45:00,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:00,585][root][INFO] - Training Epoch: 2/2, step 661/7134 completed (loss: 0.11008322238922119, acc: 0.9801255464553833)
[2024-12-17 04:45:00,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:01,061][root][INFO] - Training Epoch: 2/2, step 662/7134 completed (loss: 0.04985969513654709, acc: 0.9798927903175354)
[2024-12-17 04:45:01,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:01,570][root][INFO] - Training Epoch: 2/2, step 663/7134 completed (loss: 0.0706232488155365, acc: 0.985409677028656)
[2024-12-17 04:45:01,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:02,005][root][INFO] - Training Epoch: 2/2, step 664/7134 completed (loss: 0.05474860966205597, acc: 0.9933333396911621)
[2024-12-17 04:45:02,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:02,446][root][INFO] - Training Epoch: 2/2, step 665/7134 completed (loss: 0.06822146475315094, acc: 0.983849287033081)
[2024-12-17 04:45:02,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:02,934][root][INFO] - Training Epoch: 2/2, step 666/7134 completed (loss: 0.08233940601348877, acc: 0.9793956279754639)
[2024-12-17 04:45:03,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:03,387][root][INFO] - Training Epoch: 2/2, step 667/7134 completed (loss: 0.06674480438232422, acc: 0.9837996959686279)
[2024-12-17 04:45:03,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:03,840][root][INFO] - Training Epoch: 2/2, step 668/7134 completed (loss: 0.04501904174685478, acc: 0.9911280274391174)
[2024-12-17 04:45:03,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:04,323][root][INFO] - Training Epoch: 2/2, step 669/7134 completed (loss: 0.04454495385289192, acc: 0.9890859723091125)
[2024-12-17 04:45:04,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:04,823][root][INFO] - Training Epoch: 2/2, step 670/7134 completed (loss: 0.063408762216568, acc: 0.9825462102890015)
[2024-12-17 04:45:04,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:05,316][root][INFO] - Training Epoch: 2/2, step 671/7134 completed (loss: 0.04886835813522339, acc: 0.9828510284423828)
[2024-12-17 04:45:05,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:05,731][root][INFO] - Training Epoch: 2/2, step 672/7134 completed (loss: 0.06682149320840836, acc: 0.9836065769195557)
[2024-12-17 04:45:05,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:06,182][root][INFO] - Training Epoch: 2/2, step 673/7134 completed (loss: 0.05853034183382988, acc: 0.9864864945411682)
[2024-12-17 04:45:06,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:06,639][root][INFO] - Training Epoch: 2/2, step 674/7134 completed (loss: 0.0636567771434784, acc: 0.9834087491035461)
[2024-12-17 04:45:06,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:07,114][root][INFO] - Training Epoch: 2/2, step 675/7134 completed (loss: 0.08199257403612137, acc: 0.9843546152114868)
[2024-12-17 04:45:07,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:07,572][root][INFO] - Training Epoch: 2/2, step 676/7134 completed (loss: 0.04410351812839508, acc: 0.9869822263717651)
[2024-12-17 04:45:07,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:08,048][root][INFO] - Training Epoch: 2/2, step 677/7134 completed (loss: 0.018559562042355537, acc: 0.995067834854126)
[2024-12-17 04:45:08,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:08,508][root][INFO] - Training Epoch: 2/2, step 678/7134 completed (loss: 0.034982163459062576, acc: 0.9932705163955688)
[2024-12-17 04:45:08,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:08,911][root][INFO] - Training Epoch: 2/2, step 679/7134 completed (loss: 0.017766699194908142, acc: 0.9943289160728455)
[2024-12-17 04:45:09,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:09,366][root][INFO] - Training Epoch: 2/2, step 680/7134 completed (loss: 0.07904960960149765, acc: 0.9811320900917053)
[2024-12-17 04:45:09,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:09,840][root][INFO] - Training Epoch: 2/2, step 681/7134 completed (loss: 0.05748995020985603, acc: 0.9865030646324158)
[2024-12-17 04:45:09,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:10,264][root][INFO] - Training Epoch: 2/2, step 682/7134 completed (loss: 0.04679425433278084, acc: 0.9884726405143738)
[2024-12-17 04:45:10,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:10,737][root][INFO] - Training Epoch: 2/2, step 683/7134 completed (loss: 0.054081689566373825, acc: 0.9849108457565308)
[2024-12-17 04:45:10,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:11,203][root][INFO] - Training Epoch: 2/2, step 684/7134 completed (loss: 0.041976310312747955, acc: 0.9861496090888977)
[2024-12-17 04:45:11,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:11,657][root][INFO] - Training Epoch: 2/2, step 685/7134 completed (loss: 0.03257213160395622, acc: 0.9900249242782593)
[2024-12-17 04:45:11,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:12,120][root][INFO] - Training Epoch: 2/2, step 686/7134 completed (loss: 0.029528694227337837, acc: 0.9947159886360168)
[2024-12-17 04:45:12,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:12,578][root][INFO] - Training Epoch: 2/2, step 687/7134 completed (loss: 0.04262106120586395, acc: 0.9845260977745056)
[2024-12-17 04:45:12,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:13,036][root][INFO] - Training Epoch: 2/2, step 688/7134 completed (loss: 0.01338241808116436, acc: 0.9970414042472839)
[2024-12-17 04:45:13,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:13,458][root][INFO] - Training Epoch: 2/2, step 689/7134 completed (loss: 0.01955752819776535, acc: 0.9931623935699463)
[2024-12-17 04:45:13,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:13,892][root][INFO] - Training Epoch: 2/2, step 690/7134 completed (loss: 0.02830306813120842, acc: 0.9904610514640808)
[2024-12-17 04:45:13,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:14,315][root][INFO] - Training Epoch: 2/2, step 691/7134 completed (loss: 0.04723189398646355, acc: 0.9856321811676025)
[2024-12-17 04:45:14,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:14,778][root][INFO] - Training Epoch: 2/2, step 692/7134 completed (loss: 0.06085922569036484, acc: 0.9786666631698608)
[2024-12-17 04:45:14,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:15,202][root][INFO] - Training Epoch: 2/2, step 693/7134 completed (loss: 0.05407573655247688, acc: 0.9757673740386963)
[2024-12-17 04:45:15,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:15,656][root][INFO] - Training Epoch: 2/2, step 694/7134 completed (loss: 0.07008279860019684, acc: 0.9824817776679993)
[2024-12-17 04:45:15,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:16,110][root][INFO] - Training Epoch: 2/2, step 695/7134 completed (loss: 0.08704778552055359, acc: 0.9810671210289001)
[2024-12-17 04:45:16,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:16,545][root][INFO] - Training Epoch: 2/2, step 696/7134 completed (loss: 0.07973425835371017, acc: 0.9805825352668762)
[2024-12-17 04:45:16,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:17,008][root][INFO] - Training Epoch: 2/2, step 697/7134 completed (loss: 0.040470853447914124, acc: 0.9925558567047119)
[2024-12-17 04:45:17,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:17,413][root][INFO] - Training Epoch: 2/2, step 698/7134 completed (loss: 0.015722867101430893, acc: 0.9951140284538269)
[2024-12-17 04:45:17,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:17,888][root][INFO] - Training Epoch: 2/2, step 699/7134 completed (loss: 0.023176832124590874, acc: 0.9953271150588989)
[2024-12-17 04:45:18,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:18,319][root][INFO] - Training Epoch: 2/2, step 700/7134 completed (loss: 0.05086935684084892, acc: 0.986940324306488)
[2024-12-17 04:45:18,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:18,737][root][INFO] - Training Epoch: 2/2, step 701/7134 completed (loss: 0.04407899081707001, acc: 0.9858155846595764)
[2024-12-17 04:45:18,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:19,172][root][INFO] - Training Epoch: 2/2, step 702/7134 completed (loss: 0.04104156792163849, acc: 0.9821428656578064)
[2024-12-17 04:45:19,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:19,587][root][INFO] - Training Epoch: 2/2, step 703/7134 completed (loss: 0.04103977233171463, acc: 0.9886914491653442)
[2024-12-17 04:45:19,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:20,049][root][INFO] - Training Epoch: 2/2, step 704/7134 completed (loss: 0.039526306092739105, acc: 0.9863221645355225)
[2024-12-17 04:45:20,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:20,520][root][INFO] - Training Epoch: 2/2, step 705/7134 completed (loss: 0.07657457888126373, acc: 0.9776536226272583)
[2024-12-17 04:45:20,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:20,989][root][INFO] - Training Epoch: 2/2, step 706/7134 completed (loss: 0.02262449450790882, acc: 0.9934354424476624)
[2024-12-17 04:45:21,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:21,437][root][INFO] - Training Epoch: 2/2, step 707/7134 completed (loss: 0.03238268196582794, acc: 0.9904076457023621)
[2024-12-17 04:45:21,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:21,914][root][INFO] - Training Epoch: 2/2, step 708/7134 completed (loss: 0.028888216242194176, acc: 0.9900867342948914)
[2024-12-17 04:45:22,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:22,361][root][INFO] - Training Epoch: 2/2, step 709/7134 completed (loss: 0.02972576580941677, acc: 0.9916467666625977)
[2024-12-17 04:45:22,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:22,830][root][INFO] - Training Epoch: 2/2, step 710/7134 completed (loss: 0.02879583276808262, acc: 0.9927361011505127)
[2024-12-17 04:45:22,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:23,270][root][INFO] - Training Epoch: 2/2, step 711/7134 completed (loss: 0.02906278893351555, acc: 0.9893742799758911)
[2024-12-17 04:45:23,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:23,715][root][INFO] - Training Epoch: 2/2, step 712/7134 completed (loss: 0.037202466279268265, acc: 0.9914529919624329)
[2024-12-17 04:45:23,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:24,183][root][INFO] - Training Epoch: 2/2, step 713/7134 completed (loss: 0.01923699676990509, acc: 0.9942330121994019)
[2024-12-17 04:45:24,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:24,532][root][INFO] - Training Epoch: 2/2, step 714/7134 completed (loss: 0.02863527461886406, acc: 0.9855072498321533)
[2024-12-17 04:45:24,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:25,008][root][INFO] - Training Epoch: 2/2, step 715/7134 completed (loss: 0.019850170239806175, acc: 0.9928977489471436)
[2024-12-17 04:45:25,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:25,461][root][INFO] - Training Epoch: 2/2, step 716/7134 completed (loss: 0.020770935341715813, acc: 0.9943116903305054)
[2024-12-17 04:45:25,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:25,901][root][INFO] - Training Epoch: 2/2, step 717/7134 completed (loss: 0.03755929693579674, acc: 0.992414653301239)
[2024-12-17 04:45:25,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:26,373][root][INFO] - Training Epoch: 2/2, step 718/7134 completed (loss: 0.025520745664834976, acc: 0.9912280440330505)
[2024-12-17 04:45:26,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:26,797][root][INFO] - Training Epoch: 2/2, step 719/7134 completed (loss: 0.011557563208043575, acc: 0.998275876045227)
[2024-12-17 04:45:26,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:27,272][root][INFO] - Training Epoch: 2/2, step 720/7134 completed (loss: 0.024573590606451035, acc: 0.9899749159812927)
[2024-12-17 04:45:27,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:27,746][root][INFO] - Training Epoch: 2/2, step 721/7134 completed (loss: 0.03587353974580765, acc: 0.98591548204422)
[2024-12-17 04:45:27,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:28,240][root][INFO] - Training Epoch: 2/2, step 722/7134 completed (loss: 0.03106909804046154, acc: 0.9883313775062561)
[2024-12-17 04:45:28,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:28,708][root][INFO] - Training Epoch: 2/2, step 723/7134 completed (loss: 0.01451654639095068, acc: 0.9975786805152893)
[2024-12-17 04:45:28,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:29,139][root][INFO] - Training Epoch: 2/2, step 724/7134 completed (loss: 0.022475387901067734, acc: 0.995708167552948)
[2024-12-17 04:45:29,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:29,603][root][INFO] - Training Epoch: 2/2, step 725/7134 completed (loss: 0.018429119139909744, acc: 0.9927641153335571)
[2024-12-17 04:45:29,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:30,060][root][INFO] - Training Epoch: 2/2, step 726/7134 completed (loss: 0.025237128138542175, acc: 0.9930264949798584)
[2024-12-17 04:45:30,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:30,506][root][INFO] - Training Epoch: 2/2, step 727/7134 completed (loss: 0.009380700066685677, acc: 0.9971140027046204)
[2024-12-17 04:45:30,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:30,953][root][INFO] - Training Epoch: 2/2, step 728/7134 completed (loss: 0.012207923457026482, acc: 0.997245192527771)
[2024-12-17 04:45:31,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:31,413][root][INFO] - Training Epoch: 2/2, step 729/7134 completed (loss: 0.010989257134497166, acc: 0.9944367408752441)
[2024-12-17 04:45:31,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:31,867][root][INFO] - Training Epoch: 2/2, step 730/7134 completed (loss: 0.023367684334516525, acc: 0.993514895439148)
[2024-12-17 04:45:31,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:32,334][root][INFO] - Training Epoch: 2/2, step 731/7134 completed (loss: 0.0365152545273304, acc: 0.9906666874885559)
[2024-12-17 04:45:32,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:32,766][root][INFO] - Training Epoch: 2/2, step 732/7134 completed (loss: 0.0703001543879509, acc: 0.9735848903656006)
[2024-12-17 04:45:32,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:33,156][root][INFO] - Training Epoch: 2/2, step 733/7134 completed (loss: 0.04095655679702759, acc: 0.9822379946708679)
[2024-12-17 04:45:33,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:33,569][root][INFO] - Training Epoch: 2/2, step 734/7134 completed (loss: 0.011841733939945698, acc: 0.9984639286994934)
[2024-12-17 04:45:33,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:34,006][root][INFO] - Training Epoch: 2/2, step 735/7134 completed (loss: 0.020966144278645515, acc: 0.9887459874153137)
[2024-12-17 04:45:34,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:34,427][root][INFO] - Training Epoch: 2/2, step 736/7134 completed (loss: 0.038089390844106674, acc: 0.9824175834655762)
[2024-12-17 04:45:34,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:34,857][root][INFO] - Training Epoch: 2/2, step 737/7134 completed (loss: 0.12121085822582245, acc: 0.9716024398803711)
[2024-12-17 04:45:34,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:35,277][root][INFO] - Training Epoch: 2/2, step 738/7134 completed (loss: 0.012371283024549484, acc: 0.9942307472229004)
[2024-12-17 04:45:35,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:35,705][root][INFO] - Training Epoch: 2/2, step 739/7134 completed (loss: 0.024213312193751335, acc: 0.9926605224609375)
[2024-12-17 04:45:35,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:36,125][root][INFO] - Training Epoch: 2/2, step 740/7134 completed (loss: 0.015180245973169804, acc: 0.9952380657196045)
[2024-12-17 04:45:36,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:36,554][root][INFO] - Training Epoch: 2/2, step 741/7134 completed (loss: 0.025327177718281746, acc: 0.9921135902404785)
[2024-12-17 04:45:36,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:36,972][root][INFO] - Training Epoch: 2/2, step 742/7134 completed (loss: 0.021347245201468468, acc: 0.9937106966972351)
[2024-12-17 04:45:37,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:37,413][root][INFO] - Training Epoch: 2/2, step 743/7134 completed (loss: 0.05506058782339096, acc: 0.9849397540092468)
[2024-12-17 04:45:37,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:37,823][root][INFO] - Training Epoch: 2/2, step 744/7134 completed (loss: 0.02714749425649643, acc: 0.988095223903656)
[2024-12-17 04:45:37,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:38,247][root][INFO] - Training Epoch: 2/2, step 745/7134 completed (loss: 0.027984343469142914, acc: 0.9924471378326416)
[2024-12-17 04:45:38,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:38,678][root][INFO] - Training Epoch: 2/2, step 746/7134 completed (loss: 0.04556019976735115, acc: 0.9835796356201172)
[2024-12-17 04:45:38,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:39,058][root][INFO] - Training Epoch: 2/2, step 747/7134 completed (loss: 0.14633499085903168, acc: 0.9717608094215393)
[2024-12-17 04:45:39,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:39,524][root][INFO] - Training Epoch: 2/2, step 748/7134 completed (loss: 0.030864810571074486, acc: 0.9909774661064148)
[2024-12-17 04:45:39,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:39,967][root][INFO] - Training Epoch: 2/2, step 749/7134 completed (loss: 0.02019554004073143, acc: 0.9927954077720642)
[2024-12-17 04:45:40,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:40,513][root][INFO] - Training Epoch: 2/2, step 750/7134 completed (loss: 0.048555802553892136, acc: 0.9891892075538635)
[2024-12-17 04:45:40,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:40,950][root][INFO] - Training Epoch: 2/2, step 751/7134 completed (loss: 0.060601405799388885, acc: 0.9812606573104858)
[2024-12-17 04:45:41,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:41,375][root][INFO] - Training Epoch: 2/2, step 752/7134 completed (loss: 0.07825683802366257, acc: 0.9879879951477051)
[2024-12-17 04:45:41,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:41,830][root][INFO] - Training Epoch: 2/2, step 753/7134 completed (loss: 0.05257326364517212, acc: 0.9814189076423645)
[2024-12-17 04:45:41,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:42,296][root][INFO] - Training Epoch: 2/2, step 754/7134 completed (loss: 0.026020964607596397, acc: 0.993966817855835)
[2024-12-17 04:45:42,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:42,787][root][INFO] - Training Epoch: 2/2, step 755/7134 completed (loss: 0.07834392786026001, acc: 0.9818481802940369)
[2024-12-17 04:45:42,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:43,243][root][INFO] - Training Epoch: 2/2, step 756/7134 completed (loss: 0.04481619596481323, acc: 0.9869158864021301)
[2024-12-17 04:45:43,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:43,663][root][INFO] - Training Epoch: 2/2, step 757/7134 completed (loss: 0.027302011847496033, acc: 0.992337167263031)
[2024-12-17 04:45:43,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:44,090][root][INFO] - Training Epoch: 2/2, step 758/7134 completed (loss: 0.03869868814945221, acc: 0.9862306118011475)
[2024-12-17 04:45:44,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:44,498][root][INFO] - Training Epoch: 2/2, step 759/7134 completed (loss: 0.04530736058950424, acc: 0.9825581312179565)
[2024-12-17 04:45:44,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:44,925][root][INFO] - Training Epoch: 2/2, step 760/7134 completed (loss: 0.011152258142828941, acc: 0.9965338110923767)
[2024-12-17 04:45:45,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:45,341][root][INFO] - Training Epoch: 2/2, step 761/7134 completed (loss: 0.022720901295542717, acc: 0.992175281047821)
[2024-12-17 04:45:45,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:45,754][root][INFO] - Training Epoch: 2/2, step 762/7134 completed (loss: 0.02377856895327568, acc: 0.9946236610412598)
[2024-12-17 04:45:45,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:46,168][root][INFO] - Training Epoch: 2/2, step 763/7134 completed (loss: 0.06112978607416153, acc: 0.9853420257568359)
[2024-12-17 04:45:46,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:46,597][root][INFO] - Training Epoch: 2/2, step 764/7134 completed (loss: 0.030009470880031586, acc: 0.9928264021873474)
[2024-12-17 04:45:46,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:47,050][root][INFO] - Training Epoch: 2/2, step 765/7134 completed (loss: 0.01735525205731392, acc: 0.9941434860229492)
[2024-12-17 04:45:47,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:47,502][root][INFO] - Training Epoch: 2/2, step 766/7134 completed (loss: 0.013071324676275253, acc: 0.998516321182251)
[2024-12-17 04:45:47,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:47,933][root][INFO] - Training Epoch: 2/2, step 767/7134 completed (loss: 0.021597053855657578, acc: 0.9956076145172119)
[2024-12-17 04:45:48,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:48,367][root][INFO] - Training Epoch: 2/2, step 768/7134 completed (loss: 0.03663541376590729, acc: 0.9872521162033081)
[2024-12-17 04:45:48,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:48,801][root][INFO] - Training Epoch: 2/2, step 769/7134 completed (loss: 0.01804335229098797, acc: 0.9928366541862488)
[2024-12-17 04:45:48,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:49,211][root][INFO] - Training Epoch: 2/2, step 770/7134 completed (loss: 0.027775468304753304, acc: 0.992343008518219)
[2024-12-17 04:45:49,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:49,645][root][INFO] - Training Epoch: 2/2, step 771/7134 completed (loss: 0.028248460963368416, acc: 0.9920791983604431)
[2024-12-17 04:45:49,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:50,057][root][INFO] - Training Epoch: 2/2, step 772/7134 completed (loss: 0.040160201489925385, acc: 0.9916247725486755)
[2024-12-17 04:45:50,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:50,517][root][INFO] - Training Epoch: 2/2, step 773/7134 completed (loss: 0.021992821246385574, acc: 0.9935732483863831)
[2024-12-17 04:45:50,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:50,930][root][INFO] - Training Epoch: 2/2, step 774/7134 completed (loss: 0.022926483303308487, acc: 0.9916943311691284)
[2024-12-17 04:45:51,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:51,394][root][INFO] - Training Epoch: 2/2, step 775/7134 completed (loss: 0.017858020961284637, acc: 0.9946737885475159)
[2024-12-17 04:45:51,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:51,828][root][INFO] - Training Epoch: 2/2, step 776/7134 completed (loss: 0.030045608058571815, acc: 0.9926035404205322)
[2024-12-17 04:45:51,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:52,235][root][INFO] - Training Epoch: 2/2, step 777/7134 completed (loss: 0.02829895168542862, acc: 0.995184600353241)
[2024-12-17 04:45:52,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:52,666][root][INFO] - Training Epoch: 2/2, step 778/7134 completed (loss: 0.047198712825775146, acc: 0.9903846383094788)
[2024-12-17 04:45:52,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:53,099][root][INFO] - Training Epoch: 2/2, step 779/7134 completed (loss: 0.06035645678639412, acc: 0.9810218811035156)
[2024-12-17 04:45:53,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:53,546][root][INFO] - Training Epoch: 2/2, step 780/7134 completed (loss: 0.04399113729596138, acc: 0.9873257279396057)
[2024-12-17 04:45:53,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:54,037][root][INFO] - Training Epoch: 2/2, step 781/7134 completed (loss: 0.053286146372556686, acc: 0.9792429804801941)
[2024-12-17 04:45:54,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:54,457][root][INFO] - Training Epoch: 2/2, step 782/7134 completed (loss: 0.06135435402393341, acc: 0.9810126423835754)
[2024-12-17 04:45:54,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:54,923][root][INFO] - Training Epoch: 2/2, step 783/7134 completed (loss: 0.03205632045865059, acc: 0.9898089170455933)
[2024-12-17 04:45:55,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:55,398][root][INFO] - Training Epoch: 2/2, step 784/7134 completed (loss: 0.05196167901158333, acc: 0.9817296266555786)
[2024-12-17 04:45:55,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:55,862][root][INFO] - Training Epoch: 2/2, step 785/7134 completed (loss: 0.03059571608901024, acc: 0.9899665713310242)
[2024-12-17 04:45:56,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:56,320][root][INFO] - Training Epoch: 2/2, step 786/7134 completed (loss: 0.057691145688295364, acc: 0.9907063245773315)
[2024-12-17 04:45:56,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:56,771][root][INFO] - Training Epoch: 2/2, step 787/7134 completed (loss: 0.00845281220972538, acc: 0.9963503479957581)
[2024-12-17 04:45:56,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:57,233][root][INFO] - Training Epoch: 2/2, step 788/7134 completed (loss: 0.060575660318136215, acc: 0.9809104204177856)
[2024-12-17 04:45:57,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:57,676][root][INFO] - Training Epoch: 2/2, step 789/7134 completed (loss: 0.0425293892621994, acc: 0.9908397197723389)
[2024-12-17 04:45:57,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:58,111][root][INFO] - Training Epoch: 2/2, step 790/7134 completed (loss: 0.1062636524438858, acc: 0.9822485446929932)
[2024-12-17 04:45:58,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:58,533][root][INFO] - Training Epoch: 2/2, step 791/7134 completed (loss: 0.0713605284690857, acc: 0.9822134375572205)
[2024-12-17 04:45:58,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:58,950][root][INFO] - Training Epoch: 2/2, step 792/7134 completed (loss: 0.046335190534591675, acc: 0.9860896468162537)
[2024-12-17 04:45:59,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:59,381][root][INFO] - Training Epoch: 2/2, step 793/7134 completed (loss: 0.016709795221686363, acc: 0.9926035404205322)
[2024-12-17 04:45:59,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:45:59,808][root][INFO] - Training Epoch: 2/2, step 794/7134 completed (loss: 0.03785599768161774, acc: 0.9930070042610168)
[2024-12-17 04:45:59,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:00,188][root][INFO] - Training Epoch: 2/2, step 795/7134 completed (loss: 0.07140687853097916, acc: 0.9750778675079346)
[2024-12-17 04:46:00,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:00,598][root][INFO] - Training Epoch: 2/2, step 796/7134 completed (loss: 0.07801292091608047, acc: 0.9823232293128967)
[2024-12-17 04:46:00,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:00,996][root][INFO] - Training Epoch: 2/2, step 797/7134 completed (loss: 0.044452860951423645, acc: 0.9859437942504883)
[2024-12-17 04:46:01,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:01,365][root][INFO] - Training Epoch: 2/2, step 798/7134 completed (loss: 0.024190710857510567, acc: 0.9920634627342224)
[2024-12-17 04:46:01,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:01,741][root][INFO] - Training Epoch: 2/2, step 799/7134 completed (loss: 0.03394515812397003, acc: 0.9870967864990234)
[2024-12-17 04:46:01,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:02,147][root][INFO] - Training Epoch: 2/2, step 800/7134 completed (loss: 0.055201951414346695, acc: 0.9888268113136292)
[2024-12-17 04:46:02,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:02,585][root][INFO] - Training Epoch: 2/2, step 801/7134 completed (loss: 0.07004914432764053, acc: 0.9855999946594238)
[2024-12-17 04:46:02,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:03,030][root][INFO] - Training Epoch: 2/2, step 802/7134 completed (loss: 0.04744267091155052, acc: 0.990338146686554)
[2024-12-17 04:46:03,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:03,467][root][INFO] - Training Epoch: 2/2, step 803/7134 completed (loss: 0.03463996201753616, acc: 0.987500011920929)
[2024-12-17 04:46:03,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:03,882][root][INFO] - Training Epoch: 2/2, step 804/7134 completed (loss: 0.038425564765930176, acc: 0.9959266781806946)
[2024-12-17 04:46:04,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:04,312][root][INFO] - Training Epoch: 2/2, step 805/7134 completed (loss: 0.05267462879419327, acc: 0.9756554365158081)
[2024-12-17 04:46:04,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:04,759][root][INFO] - Training Epoch: 2/2, step 806/7134 completed (loss: 0.01930948719382286, acc: 0.9972066879272461)
[2024-12-17 04:46:04,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:05,269][root][INFO] - Training Epoch: 2/2, step 807/7134 completed (loss: 0.04407800734043121, acc: 0.9878345727920532)
[2024-12-17 04:46:05,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:05,793][root][INFO] - Training Epoch: 2/2, step 808/7134 completed (loss: 0.026510346680879593, acc: 0.9928143620491028)
[2024-12-17 04:46:05,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:06,233][root][INFO] - Training Epoch: 2/2, step 809/7134 completed (loss: 0.021812086924910545, acc: 0.9940564632415771)
[2024-12-17 04:46:06,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:06,661][root][INFO] - Training Epoch: 2/2, step 810/7134 completed (loss: 0.05264933407306671, acc: 0.9838056564331055)
[2024-12-17 04:46:06,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:07,069][root][INFO] - Training Epoch: 2/2, step 811/7134 completed (loss: 0.10882096737623215, acc: 0.9701230525970459)
[2024-12-17 04:46:07,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:07,521][root][INFO] - Training Epoch: 2/2, step 812/7134 completed (loss: 0.03822946548461914, acc: 0.9861286282539368)
[2024-12-17 04:46:07,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:07,968][root][INFO] - Training Epoch: 2/2, step 813/7134 completed (loss: 0.0335422083735466, acc: 0.9912917017936707)
[2024-12-17 04:46:08,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:08,435][root][INFO] - Training Epoch: 2/2, step 814/7134 completed (loss: 0.03813895955681801, acc: 0.9870967864990234)
[2024-12-17 04:46:08,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:08,900][root][INFO] - Training Epoch: 2/2, step 815/7134 completed (loss: 0.05440191552042961, acc: 0.9829984307289124)
[2024-12-17 04:46:09,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:09,376][root][INFO] - Training Epoch: 2/2, step 816/7134 completed (loss: 0.06326055526733398, acc: 0.9864406585693359)
[2024-12-17 04:46:09,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:09,809][root][INFO] - Training Epoch: 2/2, step 817/7134 completed (loss: 0.0512639582157135, acc: 0.9872029423713684)
[2024-12-17 04:46:09,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:10,241][root][INFO] - Training Epoch: 2/2, step 818/7134 completed (loss: 0.055255305022001266, acc: 0.9828178882598877)
[2024-12-17 04:46:10,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:10,659][root][INFO] - Training Epoch: 2/2, step 819/7134 completed (loss: 0.046655066311359406, acc: 0.9936000108718872)
[2024-12-17 04:46:10,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:11,110][root][INFO] - Training Epoch: 2/2, step 820/7134 completed (loss: 0.04322351515293121, acc: 0.9907264113426208)
[2024-12-17 04:46:11,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:11,579][root][INFO] - Training Epoch: 2/2, step 821/7134 completed (loss: 0.040285274386405945, acc: 0.9906166195869446)
[2024-12-17 04:46:11,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:11,993][root][INFO] - Training Epoch: 2/2, step 822/7134 completed (loss: 0.028144536539912224, acc: 0.9921507239341736)
[2024-12-17 04:46:12,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:12,415][root][INFO] - Training Epoch: 2/2, step 823/7134 completed (loss: 0.023727701976895332, acc: 0.9887429475784302)
[2024-12-17 04:46:12,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:12,834][root][INFO] - Training Epoch: 2/2, step 824/7134 completed (loss: 0.06469590961933136, acc: 0.9840989112854004)
[2024-12-17 04:46:12,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:13,299][root][INFO] - Training Epoch: 2/2, step 825/7134 completed (loss: 0.04649226740002632, acc: 0.9881423115730286)
[2024-12-17 04:46:13,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:13,764][root][INFO] - Training Epoch: 2/2, step 826/7134 completed (loss: 0.0401846207678318, acc: 0.9891008138656616)
[2024-12-17 04:46:13,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:14,203][root][INFO] - Training Epoch: 2/2, step 827/7134 completed (loss: 0.040503717958927155, acc: 0.9868766665458679)
[2024-12-17 04:46:14,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:14,616][root][INFO] - Training Epoch: 2/2, step 828/7134 completed (loss: 0.04366504028439522, acc: 0.9891135096549988)
[2024-12-17 04:46:14,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:15,038][root][INFO] - Training Epoch: 2/2, step 829/7134 completed (loss: 0.03457307815551758, acc: 0.9902912378311157)
[2024-12-17 04:46:15,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:15,502][root][INFO] - Training Epoch: 2/2, step 830/7134 completed (loss: 0.026855139061808586, acc: 0.9883720874786377)
[2024-12-17 04:46:15,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:15,941][root][INFO] - Training Epoch: 2/2, step 831/7134 completed (loss: 0.026528391987085342, acc: 0.9931507110595703)
[2024-12-17 04:46:16,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:16,374][root][INFO] - Training Epoch: 2/2, step 832/7134 completed (loss: 0.09806101769208908, acc: 0.9778156876564026)
[2024-12-17 04:46:16,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:16,833][root][INFO] - Training Epoch: 2/2, step 833/7134 completed (loss: 0.02153662219643593, acc: 0.9915966391563416)
[2024-12-17 04:46:16,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:17,282][root][INFO] - Training Epoch: 2/2, step 834/7134 completed (loss: 0.031150350347161293, acc: 0.9944055676460266)
[2024-12-17 04:46:17,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:17,750][root][INFO] - Training Epoch: 2/2, step 835/7134 completed (loss: 0.04647223278880119, acc: 0.988811194896698)
[2024-12-17 04:46:17,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:18,226][root][INFO] - Training Epoch: 2/2, step 836/7134 completed (loss: 0.03658529371023178, acc: 0.9860788583755493)
[2024-12-17 04:46:18,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:18,668][root][INFO] - Training Epoch: 2/2, step 837/7134 completed (loss: 0.03609544038772583, acc: 0.9931880235671997)
[2024-12-17 04:46:18,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:19,105][root][INFO] - Training Epoch: 2/2, step 838/7134 completed (loss: 0.023004088550806046, acc: 0.9904610514640808)
[2024-12-17 04:46:19,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:19,565][root][INFO] - Training Epoch: 2/2, step 839/7134 completed (loss: 0.02242681011557579, acc: 0.9928229451179504)
[2024-12-17 04:46:19,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:19,999][root][INFO] - Training Epoch: 2/2, step 840/7134 completed (loss: 0.04236384481191635, acc: 0.9888424277305603)
[2024-12-17 04:46:20,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:20,447][root][INFO] - Training Epoch: 2/2, step 841/7134 completed (loss: 0.03893183916807175, acc: 0.9889349937438965)
[2024-12-17 04:46:20,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:20,935][root][INFO] - Training Epoch: 2/2, step 842/7134 completed (loss: 0.026524990797042847, acc: 0.993261456489563)
[2024-12-17 04:46:21,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:21,390][root][INFO] - Training Epoch: 2/2, step 843/7134 completed (loss: 0.02837410569190979, acc: 0.9944367408752441)
[2024-12-17 04:46:21,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:21,804][root][INFO] - Training Epoch: 2/2, step 844/7134 completed (loss: 0.033796004951000214, acc: 0.9889415502548218)
[2024-12-17 04:46:21,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:22,218][root][INFO] - Training Epoch: 2/2, step 845/7134 completed (loss: 0.05038446933031082, acc: 0.9858406782150269)
[2024-12-17 04:46:22,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:22,669][root][INFO] - Training Epoch: 2/2, step 846/7134 completed (loss: 0.027505602687597275, acc: 0.9925816059112549)
[2024-12-17 04:46:22,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:23,123][root][INFO] - Training Epoch: 2/2, step 847/7134 completed (loss: 0.02633889764547348, acc: 0.99615877866745)
[2024-12-17 04:46:23,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:23,564][root][INFO] - Training Epoch: 2/2, step 848/7134 completed (loss: 0.05808139219880104, acc: 0.9864029884338379)
[2024-12-17 04:46:23,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:24,016][root][INFO] - Training Epoch: 2/2, step 849/7134 completed (loss: 0.03761226311326027, acc: 0.990326464176178)
[2024-12-17 04:46:24,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:24,477][root][INFO] - Training Epoch: 2/2, step 850/7134 completed (loss: 0.017359577119350433, acc: 0.991946280002594)
[2024-12-17 04:46:24,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:24,939][root][INFO] - Training Epoch: 2/2, step 851/7134 completed (loss: 0.039104100316762924, acc: 0.9868593811988831)
[2024-12-17 04:46:25,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:25,405][root][INFO] - Training Epoch: 2/2, step 852/7134 completed (loss: 0.015728723257780075, acc: 0.9963369965553284)
[2024-12-17 04:46:25,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:25,887][root][INFO] - Training Epoch: 2/2, step 853/7134 completed (loss: 0.026814915239810944, acc: 0.9900881052017212)
[2024-12-17 04:46:26,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:26,322][root][INFO] - Training Epoch: 2/2, step 854/7134 completed (loss: 0.03814251348376274, acc: 0.9925373196601868)
[2024-12-17 04:46:26,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:26,796][root][INFO] - Training Epoch: 2/2, step 855/7134 completed (loss: 0.04342449828982353, acc: 0.9882903695106506)
[2024-12-17 04:46:26,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:27,238][root][INFO] - Training Epoch: 2/2, step 856/7134 completed (loss: 0.02263624593615532, acc: 0.9939467310905457)
[2024-12-17 04:46:27,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:27,660][root][INFO] - Training Epoch: 2/2, step 857/7134 completed (loss: 0.03235531970858574, acc: 0.988252580165863)
[2024-12-17 04:46:27,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:28,110][root][INFO] - Training Epoch: 2/2, step 858/7134 completed (loss: 0.05035470426082611, acc: 0.9863184094429016)
[2024-12-17 04:46:28,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:28,569][root][INFO] - Training Epoch: 2/2, step 859/7134 completed (loss: 0.055562444031238556, acc: 0.9845971465110779)
[2024-12-17 04:46:28,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:29,016][root][INFO] - Training Epoch: 2/2, step 860/7134 completed (loss: 0.047169189900159836, acc: 0.983565092086792)
[2024-12-17 04:46:29,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:29,482][root][INFO] - Training Epoch: 2/2, step 861/7134 completed (loss: 0.07670633494853973, acc: 0.9794149398803711)
[2024-12-17 04:46:29,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:29,919][root][INFO] - Training Epoch: 2/2, step 862/7134 completed (loss: 0.04159227013587952, acc: 0.9867629408836365)
[2024-12-17 04:46:30,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:30,389][root][INFO] - Training Epoch: 2/2, step 863/7134 completed (loss: 0.0441431924700737, acc: 0.9895226955413818)
[2024-12-17 04:46:30,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:30,849][root][INFO] - Training Epoch: 2/2, step 864/7134 completed (loss: 0.08169674873352051, acc: 0.9805309772491455)
[2024-12-17 04:46:30,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:31,315][root][INFO] - Training Epoch: 2/2, step 865/7134 completed (loss: 0.08960624784231186, acc: 0.9732360243797302)
[2024-12-17 04:46:31,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:31,774][root][INFO] - Training Epoch: 2/2, step 866/7134 completed (loss: 0.05848343297839165, acc: 0.9822221994400024)
[2024-12-17 04:46:31,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:32,206][root][INFO] - Training Epoch: 2/2, step 867/7134 completed (loss: 0.06947869062423706, acc: 0.9762202501296997)
[2024-12-17 04:46:32,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:32,670][root][INFO] - Training Epoch: 2/2, step 868/7134 completed (loss: 0.08345521241426468, acc: 0.9790576100349426)
[2024-12-17 04:46:32,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:33,041][root][INFO] - Training Epoch: 2/2, step 869/7134 completed (loss: 0.06744057685136795, acc: 0.9713375568389893)
[2024-12-17 04:46:33,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:33,480][root][INFO] - Training Epoch: 2/2, step 870/7134 completed (loss: 0.0330355130136013, acc: 0.9851751923561096)
[2024-12-17 04:46:33,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:33,897][root][INFO] - Training Epoch: 2/2, step 871/7134 completed (loss: 0.06926931440830231, acc: 0.9837133288383484)
[2024-12-17 04:46:33,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:34,323][root][INFO] - Training Epoch: 2/2, step 872/7134 completed (loss: 0.05316174775362015, acc: 0.9874411225318909)
[2024-12-17 04:46:34,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:34,769][root][INFO] - Training Epoch: 2/2, step 873/7134 completed (loss: 0.07361533492803574, acc: 0.9845070242881775)
[2024-12-17 04:46:34,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:35,225][root][INFO] - Training Epoch: 2/2, step 874/7134 completed (loss: 0.04837551340460777, acc: 0.9861325025558472)
[2024-12-17 04:46:35,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:35,643][root][INFO] - Training Epoch: 2/2, step 875/7134 completed (loss: 0.029747871682047844, acc: 0.9926793575286865)
[2024-12-17 04:46:35,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:36,078][root][INFO] - Training Epoch: 2/2, step 876/7134 completed (loss: 0.027320144698023796, acc: 0.988304078578949)
[2024-12-17 04:46:36,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:36,532][root][INFO] - Training Epoch: 2/2, step 877/7134 completed (loss: 0.08016042411327362, acc: 0.9814569354057312)
[2024-12-17 04:46:36,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:36,963][root][INFO] - Training Epoch: 2/2, step 878/7134 completed (loss: 0.04672430828213692, acc: 0.9867374300956726)
[2024-12-17 04:46:37,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:37,391][root][INFO] - Training Epoch: 2/2, step 879/7134 completed (loss: 0.06342914700508118, acc: 0.9898107647895813)
[2024-12-17 04:46:37,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:37,817][root][INFO] - Training Epoch: 2/2, step 880/7134 completed (loss: 0.011197670362889767, acc: 0.9970887899398804)
[2024-12-17 04:46:37,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:38,237][root][INFO] - Training Epoch: 2/2, step 881/7134 completed (loss: 0.021719086915254593, acc: 0.9959920048713684)
[2024-12-17 04:46:38,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:38,670][root][INFO] - Training Epoch: 2/2, step 882/7134 completed (loss: 0.028627172112464905, acc: 0.9874100685119629)
[2024-12-17 04:46:38,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:39,087][root][INFO] - Training Epoch: 2/2, step 883/7134 completed (loss: 0.053064655512571335, acc: 0.9862385392189026)
[2024-12-17 04:46:39,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:39,508][root][INFO] - Training Epoch: 2/2, step 884/7134 completed (loss: 0.04528966546058655, acc: 0.9825737476348877)
[2024-12-17 04:46:39,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:39,939][root][INFO] - Training Epoch: 2/2, step 885/7134 completed (loss: 0.013190575875341892, acc: 0.9971910119056702)
[2024-12-17 04:46:40,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:40,387][root][INFO] - Training Epoch: 2/2, step 886/7134 completed (loss: 0.04975489154458046, acc: 0.9902533888816833)
[2024-12-17 04:46:40,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:40,759][root][INFO] - Training Epoch: 2/2, step 887/7134 completed (loss: 0.04171674698591232, acc: 0.9946902394294739)
[2024-12-17 04:46:40,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:41,186][root][INFO] - Training Epoch: 2/2, step 888/7134 completed (loss: 0.0514453761279583, acc: 0.987860381603241)
[2024-12-17 04:46:41,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:41,582][root][INFO] - Training Epoch: 2/2, step 889/7134 completed (loss: 0.024812402203679085, acc: 0.9933333396911621)
[2024-12-17 04:46:41,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:42,003][root][INFO] - Training Epoch: 2/2, step 890/7134 completed (loss: 0.05749150365591049, acc: 0.9881154298782349)
[2024-12-17 04:46:42,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:42,454][root][INFO] - Training Epoch: 2/2, step 891/7134 completed (loss: 0.061300743371248245, acc: 0.9874826073646545)
[2024-12-17 04:46:42,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:42,877][root][INFO] - Training Epoch: 2/2, step 892/7134 completed (loss: 0.05534745752811432, acc: 0.9883720874786377)
[2024-12-17 04:46:42,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:43,280][root][INFO] - Training Epoch: 2/2, step 893/7134 completed (loss: 0.053422193974256516, acc: 0.9845201373100281)
[2024-12-17 04:46:43,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:43,726][root][INFO] - Training Epoch: 2/2, step 894/7134 completed (loss: 0.04211904853582382, acc: 0.9916201233863831)
[2024-12-17 04:46:43,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:44,126][root][INFO] - Training Epoch: 2/2, step 895/7134 completed (loss: 0.023667607456445694, acc: 0.9914529919624329)
[2024-12-17 04:46:44,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:44,545][root][INFO] - Training Epoch: 2/2, step 896/7134 completed (loss: 0.027982641011476517, acc: 0.9959999918937683)
[2024-12-17 04:46:44,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:45,005][root][INFO] - Training Epoch: 2/2, step 897/7134 completed (loss: 0.027795135974884033, acc: 0.9930362105369568)
[2024-12-17 04:46:45,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:45,468][root][INFO] - Training Epoch: 2/2, step 898/7134 completed (loss: 0.01618998683989048, acc: 0.9962639808654785)
[2024-12-17 04:46:45,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:45,933][root][INFO] - Training Epoch: 2/2, step 899/7134 completed (loss: 0.027054037898778915, acc: 0.9912935495376587)
[2024-12-17 04:46:46,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:46,356][root][INFO] - Training Epoch: 2/2, step 900/7134 completed (loss: 0.021369609981775284, acc: 0.9929676651954651)
[2024-12-17 04:46:46,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:46,810][root][INFO] - Training Epoch: 2/2, step 901/7134 completed (loss: 0.026533205062150955, acc: 0.9906666874885559)
[2024-12-17 04:46:46,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:47,224][root][INFO] - Training Epoch: 2/2, step 902/7134 completed (loss: 0.016711367294192314, acc: 0.9942611455917358)
[2024-12-17 04:46:47,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:47,676][root][INFO] - Training Epoch: 2/2, step 903/7134 completed (loss: 0.010326252318918705, acc: 0.998678982257843)
[2024-12-17 04:46:47,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:48,143][root][INFO] - Training Epoch: 2/2, step 904/7134 completed (loss: 0.013940458185970783, acc: 0.99609375)
[2024-12-17 04:46:48,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:48,608][root][INFO] - Training Epoch: 2/2, step 905/7134 completed (loss: 0.012534953653812408, acc: 0.9959568977355957)
[2024-12-17 04:46:48,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:49,052][root][INFO] - Training Epoch: 2/2, step 906/7134 completed (loss: 0.025174828246235847, acc: 0.9932975769042969)
[2024-12-17 04:46:49,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:49,497][root][INFO] - Training Epoch: 2/2, step 907/7134 completed (loss: 0.02033926732838154, acc: 0.9947368502616882)
[2024-12-17 04:46:49,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:49,948][root][INFO] - Training Epoch: 2/2, step 908/7134 completed (loss: 0.021105902269482613, acc: 0.9947984218597412)
[2024-12-17 04:46:50,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:50,366][root][INFO] - Training Epoch: 2/2, step 909/7134 completed (loss: 0.03670273348689079, acc: 0.9879879951477051)
[2024-12-17 04:46:50,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:50,830][root][INFO] - Training Epoch: 2/2, step 910/7134 completed (loss: 0.038444634526968, acc: 0.9879840016365051)
[2024-12-17 04:46:50,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:51,273][root][INFO] - Training Epoch: 2/2, step 911/7134 completed (loss: 0.02274639718234539, acc: 0.9930070042610168)
[2024-12-17 04:46:51,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:51,740][root][INFO] - Training Epoch: 2/2, step 912/7134 completed (loss: 0.046971485018730164, acc: 0.9899117350578308)
[2024-12-17 04:46:51,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:52,226][root][INFO] - Training Epoch: 2/2, step 913/7134 completed (loss: 0.022250810638070107, acc: 0.9937185645103455)
[2024-12-17 04:46:52,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:52,667][root][INFO] - Training Epoch: 2/2, step 914/7134 completed (loss: 0.030691375955939293, acc: 0.9872449040412903)
[2024-12-17 04:46:52,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:53,093][root][INFO] - Training Epoch: 2/2, step 915/7134 completed (loss: 0.06918232142925262, acc: 0.9870550036430359)
[2024-12-17 04:46:53,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:53,535][root][INFO] - Training Epoch: 2/2, step 916/7134 completed (loss: 0.025807669386267662, acc: 0.9895287752151489)
[2024-12-17 04:46:53,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:53,973][root][INFO] - Training Epoch: 2/2, step 917/7134 completed (loss: 0.0607282780110836, acc: 0.9834087491035461)
[2024-12-17 04:46:54,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:54,404][root][INFO] - Training Epoch: 2/2, step 918/7134 completed (loss: 0.01636471040546894, acc: 0.9954057931900024)
[2024-12-17 04:46:54,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:54,807][root][INFO] - Training Epoch: 2/2, step 919/7134 completed (loss: 0.016629809513688087, acc: 0.9898989796638489)
[2024-12-17 04:46:54,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:55,239][root][INFO] - Training Epoch: 2/2, step 920/7134 completed (loss: 0.0341624915599823, acc: 0.9887955188751221)
[2024-12-17 04:46:55,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:55,656][root][INFO] - Training Epoch: 2/2, step 921/7134 completed (loss: 0.02913317084312439, acc: 0.9918699264526367)
[2024-12-17 04:46:55,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:56,083][root][INFO] - Training Epoch: 2/2, step 922/7134 completed (loss: 0.05451874062418938, acc: 0.9786885380744934)
[2024-12-17 04:46:56,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:56,527][root][INFO] - Training Epoch: 2/2, step 923/7134 completed (loss: 0.0443476065993309, acc: 0.988095223903656)
[2024-12-17 04:46:56,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:57,036][root][INFO] - Training Epoch: 2/2, step 924/7134 completed (loss: 0.010191488079726696, acc: 0.9963768124580383)
[2024-12-17 04:46:57,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:57,510][root][INFO] - Training Epoch: 2/2, step 925/7134 completed (loss: 0.042825907468795776, acc: 0.9897210001945496)
[2024-12-17 04:46:57,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:57,989][root][INFO] - Training Epoch: 2/2, step 926/7134 completed (loss: 0.03687754645943642, acc: 0.995006263256073)
[2024-12-17 04:46:58,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:58,442][root][INFO] - Training Epoch: 2/2, step 927/7134 completed (loss: 0.06407831609249115, acc: 0.991830050945282)
[2024-12-17 04:46:58,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:58,898][root][INFO] - Training Epoch: 2/2, step 928/7134 completed (loss: 0.03015557862818241, acc: 0.990138053894043)
[2024-12-17 04:46:59,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:59,369][root][INFO] - Training Epoch: 2/2, step 929/7134 completed (loss: 0.020895181223750114, acc: 0.9952606558799744)
[2024-12-17 04:46:59,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:46:59,826][root][INFO] - Training Epoch: 2/2, step 930/7134 completed (loss: 0.03998866677284241, acc: 0.9879032373428345)
[2024-12-17 04:46:59,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:00,265][root][INFO] - Training Epoch: 2/2, step 931/7134 completed (loss: 0.06579794734716415, acc: 0.9876543283462524)
[2024-12-17 04:47:00,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:00,680][root][INFO] - Training Epoch: 2/2, step 932/7134 completed (loss: 0.032598067075014114, acc: 0.9899713397026062)
[2024-12-17 04:47:00,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:01,117][root][INFO] - Training Epoch: 2/2, step 933/7134 completed (loss: 0.03218748793005943, acc: 0.994358241558075)
[2024-12-17 04:47:01,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:01,563][root][INFO] - Training Epoch: 2/2, step 934/7134 completed (loss: 0.018155135214328766, acc: 0.9908376932144165)
[2024-12-17 04:47:01,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:02,013][root][INFO] - Training Epoch: 2/2, step 935/7134 completed (loss: 0.02585146389901638, acc: 0.9916527271270752)
[2024-12-17 04:47:02,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:02,449][root][INFO] - Training Epoch: 2/2, step 936/7134 completed (loss: 0.04293116554617882, acc: 0.9894551634788513)
[2024-12-17 04:47:02,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:02,891][root][INFO] - Training Epoch: 2/2, step 937/7134 completed (loss: 0.05088726803660393, acc: 0.9876760840415955)
[2024-12-17 04:47:03,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:03,340][root][INFO] - Training Epoch: 2/2, step 938/7134 completed (loss: 0.02563031204044819, acc: 0.9928366541862488)
[2024-12-17 04:47:03,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:03,760][root][INFO] - Training Epoch: 2/2, step 939/7134 completed (loss: 0.036441199481487274, acc: 0.9875389337539673)
[2024-12-17 04:47:03,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:04,224][root][INFO] - Training Epoch: 2/2, step 940/7134 completed (loss: 0.03407752513885498, acc: 0.9871244430541992)
[2024-12-17 04:47:04,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:04,688][root][INFO] - Training Epoch: 2/2, step 941/7134 completed (loss: 0.022295458242297173, acc: 0.9944827556610107)
[2024-12-17 04:47:04,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:05,135][root][INFO] - Training Epoch: 2/2, step 942/7134 completed (loss: 0.03810170665383339, acc: 0.9927431344985962)
[2024-12-17 04:47:05,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:05,577][root][INFO] - Training Epoch: 2/2, step 943/7134 completed (loss: 0.02225165255367756, acc: 0.990867555141449)
[2024-12-17 04:47:05,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:05,997][root][INFO] - Training Epoch: 2/2, step 944/7134 completed (loss: 0.03614683449268341, acc: 0.9910045266151428)
[2024-12-17 04:47:06,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:06,425][root][INFO] - Training Epoch: 2/2, step 945/7134 completed (loss: 0.034976452589035034, acc: 0.9916083812713623)
[2024-12-17 04:47:06,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:06,854][root][INFO] - Training Epoch: 2/2, step 946/7134 completed (loss: 0.006661854684352875, acc: 1.0)
[2024-12-17 04:47:06,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:07,264][root][INFO] - Training Epoch: 2/2, step 947/7134 completed (loss: 0.04044072702527046, acc: 0.9896729588508606)
[2024-12-17 04:47:07,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:07,705][root][INFO] - Training Epoch: 2/2, step 948/7134 completed (loss: 0.02983061410486698, acc: 0.9902642369270325)
[2024-12-17 04:47:07,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:08,198][root][INFO] - Training Epoch: 2/2, step 949/7134 completed (loss: 0.01618591509759426, acc: 0.9943898916244507)
[2024-12-17 04:47:08,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:08,655][root][INFO] - Training Epoch: 2/2, step 950/7134 completed (loss: 0.031428106129169464, acc: 0.9922839403152466)
[2024-12-17 04:47:08,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:09,072][root][INFO] - Training Epoch: 2/2, step 951/7134 completed (loss: 0.019296035170555115, acc: 0.9929577708244324)
[2024-12-17 04:47:09,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:09,499][root][INFO] - Training Epoch: 2/2, step 952/7134 completed (loss: 0.054965827614068985, acc: 0.9833610653877258)
[2024-12-17 04:47:09,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:09,976][root][INFO] - Training Epoch: 2/2, step 953/7134 completed (loss: 0.06924127787351608, acc: 0.979141116142273)
[2024-12-17 04:47:10,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:10,436][root][INFO] - Training Epoch: 2/2, step 954/7134 completed (loss: 0.03938567265868187, acc: 0.9897210001945496)
[2024-12-17 04:47:10,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:10,909][root][INFO] - Training Epoch: 2/2, step 955/7134 completed (loss: 0.02884429134428501, acc: 0.9946452379226685)
[2024-12-17 04:47:11,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:11,356][root][INFO] - Training Epoch: 2/2, step 956/7134 completed (loss: 0.02784890867769718, acc: 0.9878048896789551)
[2024-12-17 04:47:11,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:11,815][root][INFO] - Training Epoch: 2/2, step 957/7134 completed (loss: 0.02061418443918228, acc: 0.9920364022254944)
[2024-12-17 04:47:11,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:12,237][root][INFO] - Training Epoch: 2/2, step 958/7134 completed (loss: 0.05326469615101814, acc: 0.9871323704719543)
[2024-12-17 04:47:12,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:12,669][root][INFO] - Training Epoch: 2/2, step 959/7134 completed (loss: 0.08824538439512253, acc: 0.98128342628479)
[2024-12-17 04:47:12,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:13,099][root][INFO] - Training Epoch: 2/2, step 960/7134 completed (loss: 0.07531421631574631, acc: 0.9792060256004333)
[2024-12-17 04:47:13,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:13,547][root][INFO] - Training Epoch: 2/2, step 961/7134 completed (loss: 0.03800205886363983, acc: 0.9851751923561096)
[2024-12-17 04:47:13,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:14,026][root][INFO] - Training Epoch: 2/2, step 962/7134 completed (loss: 0.10236051678657532, acc: 0.9793103337287903)
[2024-12-17 04:47:14,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:14,459][root][INFO] - Training Epoch: 2/2, step 963/7134 completed (loss: 0.06604188680648804, acc: 0.9786585569381714)
[2024-12-17 04:47:14,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:14,897][root][INFO] - Training Epoch: 2/2, step 964/7134 completed (loss: 0.14141976833343506, acc: 0.9640179872512817)
[2024-12-17 04:47:15,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:15,333][root][INFO] - Training Epoch: 2/2, step 965/7134 completed (loss: 0.0970410406589508, acc: 0.9684361815452576)
[2024-12-17 04:47:15,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:15,745][root][INFO] - Training Epoch: 2/2, step 966/7134 completed (loss: 0.05124064162373543, acc: 0.9934425950050354)
[2024-12-17 04:47:15,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:16,202][root][INFO] - Training Epoch: 2/2, step 967/7134 completed (loss: 0.04210566729307175, acc: 0.9836289286613464)
[2024-12-17 04:47:16,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:16,610][root][INFO] - Training Epoch: 2/2, step 968/7134 completed (loss: 0.07286731898784637, acc: 0.9721670150756836)
[2024-12-17 04:47:16,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:17,025][root][INFO] - Training Epoch: 2/2, step 969/7134 completed (loss: 0.04528345167636871, acc: 0.9894419312477112)
[2024-12-17 04:47:17,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:17,422][root][INFO] - Training Epoch: 2/2, step 970/7134 completed (loss: 0.07426943629980087, acc: 0.9809160232543945)
[2024-12-17 04:47:17,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:17,876][root][INFO] - Training Epoch: 2/2, step 971/7134 completed (loss: 0.03456399217247963, acc: 0.987730085849762)
[2024-12-17 04:47:17,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:18,352][root][INFO] - Training Epoch: 2/2, step 972/7134 completed (loss: 0.046085748821496964, acc: 0.9850560426712036)
[2024-12-17 04:47:18,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:18,796][root][INFO] - Training Epoch: 2/2, step 973/7134 completed (loss: 0.10537844151258469, acc: 0.9756410121917725)
[2024-12-17 04:47:18,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:19,281][root][INFO] - Training Epoch: 2/2, step 974/7134 completed (loss: 0.057703897356987, acc: 0.9828962087631226)
[2024-12-17 04:47:19,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:19,726][root][INFO] - Training Epoch: 2/2, step 975/7134 completed (loss: 0.07284355163574219, acc: 0.9856459498405457)
[2024-12-17 04:47:19,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:20,179][root][INFO] - Training Epoch: 2/2, step 976/7134 completed (loss: 0.05352409556508064, acc: 0.9844236969947815)
[2024-12-17 04:47:20,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:20,637][root][INFO] - Training Epoch: 2/2, step 977/7134 completed (loss: 0.05839172750711441, acc: 0.9837662577629089)
[2024-12-17 04:47:20,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:21,089][root][INFO] - Training Epoch: 2/2, step 978/7134 completed (loss: 0.02679263800382614, acc: 0.9927797913551331)
[2024-12-17 04:47:21,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:21,540][root][INFO] - Training Epoch: 2/2, step 979/7134 completed (loss: 0.04997352883219719, acc: 0.9879679083824158)
[2024-12-17 04:47:21,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:21,985][root][INFO] - Training Epoch: 2/2, step 980/7134 completed (loss: 0.06840675324201584, acc: 0.9787499904632568)
[2024-12-17 04:47:22,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:22,414][root][INFO] - Training Epoch: 2/2, step 981/7134 completed (loss: 0.13273866474628448, acc: 0.9758842587471008)
[2024-12-17 04:47:22,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:22,877][root][INFO] - Training Epoch: 2/2, step 982/7134 completed (loss: 0.03310326114296913, acc: 0.9901685118675232)
[2024-12-17 04:47:22,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:23,313][root][INFO] - Training Epoch: 2/2, step 983/7134 completed (loss: 0.0694832056760788, acc: 0.9863013625144958)
[2024-12-17 04:47:23,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:23,738][root][INFO] - Training Epoch: 2/2, step 984/7134 completed (loss: 0.05691635608673096, acc: 0.9871323704719543)
[2024-12-17 04:47:23,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:24,199][root][INFO] - Training Epoch: 2/2, step 985/7134 completed (loss: 0.03126765415072441, acc: 0.9897959232330322)
[2024-12-17 04:47:24,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:24,652][root][INFO] - Training Epoch: 2/2, step 986/7134 completed (loss: 0.02277921885251999, acc: 0.9943342804908752)
[2024-12-17 04:47:24,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:25,082][root][INFO] - Training Epoch: 2/2, step 987/7134 completed (loss: 0.03221810236573219, acc: 0.9951768517494202)
[2024-12-17 04:47:25,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:25,503][root][INFO] - Training Epoch: 2/2, step 988/7134 completed (loss: 0.10509233921766281, acc: 0.9750346541404724)
[2024-12-17 04:47:25,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:25,960][root][INFO] - Training Epoch: 2/2, step 989/7134 completed (loss: 0.04835683852434158, acc: 0.9791377186775208)
[2024-12-17 04:47:26,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:26,414][root][INFO] - Training Epoch: 2/2, step 990/7134 completed (loss: 0.05220789834856987, acc: 0.9873577952384949)
[2024-12-17 04:47:26,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:26,855][root][INFO] - Training Epoch: 2/2, step 991/7134 completed (loss: 0.07200813293457031, acc: 0.9765258431434631)
[2024-12-17 04:47:26,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:27,333][root][INFO] - Training Epoch: 2/2, step 992/7134 completed (loss: 0.04515860602259636, acc: 0.9855263233184814)
[2024-12-17 04:47:27,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:27,767][root][INFO] - Training Epoch: 2/2, step 993/7134 completed (loss: 0.05042974650859833, acc: 0.9852700233459473)
[2024-12-17 04:47:27,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:28,253][root][INFO] - Training Epoch: 2/2, step 994/7134 completed (loss: 0.04562709480524063, acc: 0.9876126050949097)
[2024-12-17 04:47:28,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:28,692][root][INFO] - Training Epoch: 2/2, step 995/7134 completed (loss: 0.0487096905708313, acc: 0.9845678806304932)
[2024-12-17 04:47:28,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:29,129][root][INFO] - Training Epoch: 2/2, step 996/7134 completed (loss: 0.06160948798060417, acc: 0.9818435907363892)
[2024-12-17 04:47:29,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:29,566][root][INFO] - Training Epoch: 2/2, step 997/7134 completed (loss: 0.04210742190480232, acc: 0.9885386824607849)
[2024-12-17 04:47:29,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:29,998][root][INFO] - Training Epoch: 2/2, step 998/7134 completed (loss: 0.04518866911530495, acc: 0.98591548204422)
[2024-12-17 04:47:30,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:30,421][root][INFO] - Training Epoch: 2/2, step 999/7134 completed (loss: 0.019254636019468307, acc: 0.9946236610412598)
[2024-12-17 04:47:30,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:30,843][root][INFO] - Training Epoch: 2/2, step 1000/7134 completed (loss: 0.04000463709235191, acc: 0.9863013625144958)
[2024-12-17 04:47:30,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:31,258][root][INFO] - Training Epoch: 2/2, step 1001/7134 completed (loss: 0.06903881579637527, acc: 0.9777777791023254)
[2024-12-17 04:47:31,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:31,715][root][INFO] - Training Epoch: 2/2, step 1002/7134 completed (loss: 0.04944714903831482, acc: 0.9900142550468445)
[2024-12-17 04:47:31,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:32,170][root][INFO] - Training Epoch: 2/2, step 1003/7134 completed (loss: 0.041500262916088104, acc: 0.9866270422935486)
[2024-12-17 04:47:32,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:32,591][root][INFO] - Training Epoch: 2/2, step 1004/7134 completed (loss: 0.07067043334245682, acc: 0.9814432859420776)
[2024-12-17 04:47:32,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:33,037][root][INFO] - Training Epoch: 2/2, step 1005/7134 completed (loss: 0.08682481944561005, acc: 0.9817880988121033)
[2024-12-17 04:47:33,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:33,461][root][INFO] - Training Epoch: 2/2, step 1006/7134 completed (loss: 0.04418426379561424, acc: 0.9888579249382019)
[2024-12-17 04:47:33,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:33,895][root][INFO] - Training Epoch: 2/2, step 1007/7134 completed (loss: 0.07346785813570023, acc: 0.9795918464660645)
[2024-12-17 04:47:34,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:34,335][root][INFO] - Training Epoch: 2/2, step 1008/7134 completed (loss: 0.03513334318995476, acc: 0.9886524677276611)
[2024-12-17 04:47:34,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:34,763][root][INFO] - Training Epoch: 2/2, step 1009/7134 completed (loss: 0.06345374882221222, acc: 0.9875665903091431)
[2024-12-17 04:47:34,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:35,190][root][INFO] - Training Epoch: 2/2, step 1010/7134 completed (loss: 0.05484755337238312, acc: 0.97826087474823)
[2024-12-17 04:47:35,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:35,629][root][INFO] - Training Epoch: 2/2, step 1011/7134 completed (loss: 0.038430895656347275, acc: 0.9861687421798706)
[2024-12-17 04:47:35,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:36,060][root][INFO] - Training Epoch: 2/2, step 1012/7134 completed (loss: 0.0522896908223629, acc: 0.9858356714248657)
[2024-12-17 04:47:36,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:36,511][root][INFO] - Training Epoch: 2/2, step 1013/7134 completed (loss: 0.055187731981277466, acc: 0.984240710735321)
[2024-12-17 04:47:36,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:36,939][root][INFO] - Training Epoch: 2/2, step 1014/7134 completed (loss: 0.04199682176113129, acc: 0.9868637323379517)
[2024-12-17 04:47:37,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:37,376][root][INFO] - Training Epoch: 2/2, step 1015/7134 completed (loss: 0.04925134778022766, acc: 0.9879518151283264)
[2024-12-17 04:47:37,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:37,814][root][INFO] - Training Epoch: 2/2, step 1016/7134 completed (loss: 0.05987727269530296, acc: 0.9847036600112915)
[2024-12-17 04:47:37,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:38,278][root][INFO] - Training Epoch: 2/2, step 1017/7134 completed (loss: 0.015408129431307316, acc: 0.9959731698036194)
[2024-12-17 04:47:38,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:38,714][root][INFO] - Training Epoch: 2/2, step 1018/7134 completed (loss: 0.055624596774578094, acc: 0.9868228435516357)
[2024-12-17 04:47:38,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:39,142][root][INFO] - Training Epoch: 2/2, step 1019/7134 completed (loss: 0.04299120232462883, acc: 0.9839743375778198)
[2024-12-17 04:47:39,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:39,556][root][INFO] - Training Epoch: 2/2, step 1020/7134 completed (loss: 0.016189230605959892, acc: 0.9970149397850037)
[2024-12-17 04:47:39,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:39,988][root][INFO] - Training Epoch: 2/2, step 1021/7134 completed (loss: 0.020213453099131584, acc: 0.993630588054657)
[2024-12-17 04:47:40,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:40,450][root][INFO] - Training Epoch: 2/2, step 1022/7134 completed (loss: 0.030996767804026604, acc: 0.9894598126411438)
[2024-12-17 04:47:40,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:40,884][root][INFO] - Training Epoch: 2/2, step 1023/7134 completed (loss: 0.040486495941877365, acc: 0.9909909963607788)
[2024-12-17 04:47:41,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:41,307][root][INFO] - Training Epoch: 2/2, step 1024/7134 completed (loss: 0.052078813314437866, acc: 0.985637366771698)
[2024-12-17 04:47:41,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:41,724][root][INFO] - Training Epoch: 2/2, step 1025/7134 completed (loss: 0.025191042572259903, acc: 0.9964413046836853)
[2024-12-17 04:47:41,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:42,162][root][INFO] - Training Epoch: 2/2, step 1026/7134 completed (loss: 0.04586781933903694, acc: 0.9894737005233765)
[2024-12-17 04:47:42,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:42,599][root][INFO] - Training Epoch: 2/2, step 1027/7134 completed (loss: 0.008462951518595219, acc: 0.9986467957496643)
[2024-12-17 04:47:42,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:43,034][root][INFO] - Training Epoch: 2/2, step 1028/7134 completed (loss: 0.019505025818943977, acc: 0.9955157041549683)
[2024-12-17 04:47:43,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:43,487][root][INFO] - Training Epoch: 2/2, step 1029/7134 completed (loss: 0.018704641610383987, acc: 0.9955423474311829)
[2024-12-17 04:47:43,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:43,921][root][INFO] - Training Epoch: 2/2, step 1030/7134 completed (loss: 0.012063574977219105, acc: 0.9959568977355957)
[2024-12-17 04:47:44,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:44,346][root][INFO] - Training Epoch: 2/2, step 1031/7134 completed (loss: 0.033692870289087296, acc: 0.9908536672592163)
[2024-12-17 04:47:44,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:44,802][root][INFO] - Training Epoch: 2/2, step 1032/7134 completed (loss: 0.03523535281419754, acc: 0.9930875301361084)
[2024-12-17 04:47:44,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:45,267][root][INFO] - Training Epoch: 2/2, step 1033/7134 completed (loss: 0.02706463448703289, acc: 0.9928264021873474)
[2024-12-17 04:47:45,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:45,720][root][INFO] - Training Epoch: 2/2, step 1034/7134 completed (loss: 0.032010793685913086, acc: 0.9918962717056274)
[2024-12-17 04:47:45,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:46,159][root][INFO] - Training Epoch: 2/2, step 1035/7134 completed (loss: 0.15701313316822052, acc: 0.9649122953414917)
[2024-12-17 04:47:46,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:46,551][root][INFO] - Training Epoch: 2/2, step 1036/7134 completed (loss: 0.13154548406600952, acc: 0.9644444584846497)
[2024-12-17 04:47:46,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:47,025][root][INFO] - Training Epoch: 2/2, step 1037/7134 completed (loss: 0.026260854676365852, acc: 0.9952380657196045)
[2024-12-17 04:47:47,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:47,492][root][INFO] - Training Epoch: 2/2, step 1038/7134 completed (loss: 0.015588388778269291, acc: 0.994966447353363)
[2024-12-17 04:47:47,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:47,908][root][INFO] - Training Epoch: 2/2, step 1039/7134 completed (loss: 0.024077430367469788, acc: 0.9917184114456177)
[2024-12-17 04:47:48,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:48,369][root][INFO] - Training Epoch: 2/2, step 1040/7134 completed (loss: 0.011850167997181416, acc: 0.9982876777648926)
[2024-12-17 04:47:48,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:48,802][root][INFO] - Training Epoch: 2/2, step 1041/7134 completed (loss: 0.03951548784971237, acc: 0.9922118186950684)
[2024-12-17 04:47:48,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:49,255][root][INFO] - Training Epoch: 2/2, step 1042/7134 completed (loss: 0.04202574864029884, acc: 0.9897435903549194)
[2024-12-17 04:47:49,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:49,720][root][INFO] - Training Epoch: 2/2, step 1043/7134 completed (loss: 0.024030447006225586, acc: 0.9927797913551331)
[2024-12-17 04:47:49,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:50,156][root][INFO] - Training Epoch: 2/2, step 1044/7134 completed (loss: 0.045695867389440536, acc: 0.9904109835624695)
[2024-12-17 04:47:50,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:50,549][root][INFO] - Training Epoch: 2/2, step 1045/7134 completed (loss: 0.08945909142494202, acc: 0.9822294116020203)
[2024-12-17 04:47:50,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:50,972][root][INFO] - Training Epoch: 2/2, step 1046/7134 completed (loss: 0.04198920726776123, acc: 0.9864864945411682)
[2024-12-17 04:47:51,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:51,418][root][INFO] - Training Epoch: 2/2, step 1047/7134 completed (loss: 0.06435801833868027, acc: 0.9822221994400024)
[2024-12-17 04:47:51,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:51,935][root][INFO] - Training Epoch: 2/2, step 1048/7134 completed (loss: 0.016640745103359222, acc: 0.9956011772155762)
[2024-12-17 04:47:52,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:52,367][root][INFO] - Training Epoch: 2/2, step 1049/7134 completed (loss: 0.03560163080692291, acc: 0.9897511005401611)
[2024-12-17 04:47:52,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:52,820][root][INFO] - Training Epoch: 2/2, step 1050/7134 completed (loss: 0.04760713130235672, acc: 0.9808743000030518)
[2024-12-17 04:47:52,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:53,282][root][INFO] - Training Epoch: 2/2, step 1051/7134 completed (loss: 0.02346966415643692, acc: 0.9917808175086975)
[2024-12-17 04:47:53,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:53,712][root][INFO] - Training Epoch: 2/2, step 1052/7134 completed (loss: 0.05772955343127251, acc: 0.9822294116020203)
[2024-12-17 04:47:53,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:54,130][root][INFO] - Training Epoch: 2/2, step 1053/7134 completed (loss: 0.021414371207356453, acc: 0.9901408553123474)
[2024-12-17 04:47:54,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:54,582][root][INFO] - Training Epoch: 2/2, step 1054/7134 completed (loss: 0.02597757987678051, acc: 0.9920529723167419)
[2024-12-17 04:47:54,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:55,008][root][INFO] - Training Epoch: 2/2, step 1055/7134 completed (loss: 0.09227558970451355, acc: 0.9689579010009766)
[2024-12-17 04:47:55,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:55,456][root][INFO] - Training Epoch: 2/2, step 1056/7134 completed (loss: 0.06868229806423187, acc: 0.9765493869781494)
[2024-12-17 04:47:55,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:55,899][root][INFO] - Training Epoch: 2/2, step 1057/7134 completed (loss: 0.03812645375728607, acc: 0.986994206905365)
[2024-12-17 04:47:56,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:56,356][root][INFO] - Training Epoch: 2/2, step 1058/7134 completed (loss: 0.03588477522134781, acc: 0.991304337978363)
[2024-12-17 04:47:56,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:56,812][root][INFO] - Training Epoch: 2/2, step 1059/7134 completed (loss: 0.04264150187373161, acc: 0.9896774291992188)
[2024-12-17 04:47:56,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:57,255][root][INFO] - Training Epoch: 2/2, step 1060/7134 completed (loss: 0.037619173526763916, acc: 0.9873816967010498)
[2024-12-17 04:47:57,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:57,725][root][INFO] - Training Epoch: 2/2, step 1061/7134 completed (loss: 0.05762645974755287, acc: 0.9840116500854492)
[2024-12-17 04:47:57,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:58,145][root][INFO] - Training Epoch: 2/2, step 1062/7134 completed (loss: 0.03993428498506546, acc: 0.989830493927002)
[2024-12-17 04:47:58,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:58,584][root][INFO] - Training Epoch: 2/2, step 1063/7134 completed (loss: 0.019259151071310043, acc: 0.9967585206031799)
[2024-12-17 04:47:58,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:59,058][root][INFO] - Training Epoch: 2/2, step 1064/7134 completed (loss: 0.04843481257557869, acc: 0.9907407164573669)
[2024-12-17 04:47:59,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:59,504][root][INFO] - Training Epoch: 2/2, step 1065/7134 completed (loss: 0.01920846663415432, acc: 0.9932249188423157)
[2024-12-17 04:47:59,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:47:59,928][root][INFO] - Training Epoch: 2/2, step 1066/7134 completed (loss: 0.06058117002248764, acc: 0.9848993420600891)
[2024-12-17 04:48:00,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:00,360][root][INFO] - Training Epoch: 2/2, step 1067/7134 completed (loss: 0.02127440832555294, acc: 0.9969183206558228)
[2024-12-17 04:48:00,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:00,780][root][INFO] - Training Epoch: 2/2, step 1068/7134 completed (loss: 0.0353168249130249, acc: 0.9906191229820251)
[2024-12-17 04:48:00,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:01,228][root][INFO] - Training Epoch: 2/2, step 1069/7134 completed (loss: 0.03150877729058266, acc: 0.989983320236206)
[2024-12-17 04:48:01,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:01,665][root][INFO] - Training Epoch: 2/2, step 1070/7134 completed (loss: 0.037292759865522385, acc: 0.9901477694511414)
[2024-12-17 04:48:01,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:02,122][root][INFO] - Training Epoch: 2/2, step 1071/7134 completed (loss: 0.015825366601347923, acc: 0.993306577205658)
[2024-12-17 04:48:02,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:02,571][root][INFO] - Training Epoch: 2/2, step 1072/7134 completed (loss: 0.003106368938460946, acc: 1.0)
[2024-12-17 04:48:02,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:03,008][root][INFO] - Training Epoch: 2/2, step 1073/7134 completed (loss: 0.008177580311894417, acc: 0.9956772327423096)
[2024-12-17 04:48:03,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:03,426][root][INFO] - Training Epoch: 2/2, step 1074/7134 completed (loss: 0.06433595716953278, acc: 0.9792746305465698)
[2024-12-17 04:48:03,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:03,906][root][INFO] - Training Epoch: 2/2, step 1075/7134 completed (loss: 0.09234065562486649, acc: 0.9852670431137085)
[2024-12-17 04:48:03,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:04,353][root][INFO] - Training Epoch: 2/2, step 1076/7134 completed (loss: 0.08844911307096481, acc: 0.9760638475418091)
[2024-12-17 04:48:04,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:04,772][root][INFO] - Training Epoch: 2/2, step 1077/7134 completed (loss: 0.10393977165222168, acc: 0.9684684872627258)
[2024-12-17 04:48:04,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:05,230][root][INFO] - Training Epoch: 2/2, step 1078/7134 completed (loss: 0.09973908960819244, acc: 0.9725363254547119)
[2024-12-17 04:48:05,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:05,681][root][INFO] - Training Epoch: 2/2, step 1079/7134 completed (loss: 0.031055696308612823, acc: 0.9861591458320618)
[2024-12-17 04:48:05,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:06,111][root][INFO] - Training Epoch: 2/2, step 1080/7134 completed (loss: 0.05517302826046944, acc: 0.9887217879295349)
[2024-12-17 04:48:06,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:06,560][root][INFO] - Training Epoch: 2/2, step 1081/7134 completed (loss: 0.024178877472877502, acc: 0.9957924485206604)
[2024-12-17 04:48:06,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:07,064][root][INFO] - Training Epoch: 2/2, step 1082/7134 completed (loss: 0.0222177617251873, acc: 0.9938334822654724)
[2024-12-17 04:48:07,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:07,537][root][INFO] - Training Epoch: 2/2, step 1083/7134 completed (loss: 0.029906941577792168, acc: 0.989830493927002)
[2024-12-17 04:48:07,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:08,036][root][INFO] - Training Epoch: 2/2, step 1084/7134 completed (loss: 0.02637398988008499, acc: 0.9913259148597717)
[2024-12-17 04:48:08,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:08,482][root][INFO] - Training Epoch: 2/2, step 1085/7134 completed (loss: 0.0351218655705452, acc: 0.9879518151283264)
[2024-12-17 04:48:08,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:08,894][root][INFO] - Training Epoch: 2/2, step 1086/7134 completed (loss: 0.061653029173612595, acc: 0.9792060256004333)
[2024-12-17 04:48:09,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:09,351][root][INFO] - Training Epoch: 2/2, step 1087/7134 completed (loss: 0.035228509455919266, acc: 0.9853658676147461)
[2024-12-17 04:48:09,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:09,775][root][INFO] - Training Epoch: 2/2, step 1088/7134 completed (loss: 0.025018958374857903, acc: 0.9958100318908691)
[2024-12-17 04:48:09,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:10,203][root][INFO] - Training Epoch: 2/2, step 1089/7134 completed (loss: 0.05199332907795906, acc: 0.9895678162574768)
[2024-12-17 04:48:10,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:10,652][root][INFO] - Training Epoch: 2/2, step 1090/7134 completed (loss: 0.03661163151264191, acc: 0.9906396269798279)
[2024-12-17 04:48:10,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:11,077][root][INFO] - Training Epoch: 2/2, step 1091/7134 completed (loss: 0.0236535482108593, acc: 0.9939117431640625)
[2024-12-17 04:48:11,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:11,539][root][INFO] - Training Epoch: 2/2, step 1092/7134 completed (loss: 0.015483889728784561, acc: 0.9956647157669067)
[2024-12-17 04:48:11,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:11,983][root][INFO] - Training Epoch: 2/2, step 1093/7134 completed (loss: 0.08049672842025757, acc: 0.9749216437339783)
[2024-12-17 04:48:12,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:12,416][root][INFO] - Training Epoch: 2/2, step 1094/7134 completed (loss: 0.0664949044585228, acc: 0.975836455821991)
[2024-12-17 04:48:12,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:12,903][root][INFO] - Training Epoch: 2/2, step 1095/7134 completed (loss: 0.04414423555135727, acc: 0.9853836894035339)
[2024-12-17 04:48:13,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:13,385][root][INFO] - Training Epoch: 2/2, step 1096/7134 completed (loss: 0.0375041663646698, acc: 0.9911392331123352)
[2024-12-17 04:48:13,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:13,839][root][INFO] - Training Epoch: 2/2, step 1097/7134 completed (loss: 0.06716122478246689, acc: 0.983146071434021)
[2024-12-17 04:48:13,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:14,278][root][INFO] - Training Epoch: 2/2, step 1098/7134 completed (loss: 0.02204151265323162, acc: 0.993819534778595)
[2024-12-17 04:48:14,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:14,732][root][INFO] - Training Epoch: 2/2, step 1099/7134 completed (loss: 0.03537387773394585, acc: 0.9935897588729858)
[2024-12-17 04:48:14,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:15,202][root][INFO] - Training Epoch: 2/2, step 1100/7134 completed (loss: 0.040555864572525024, acc: 0.989130437374115)
[2024-12-17 04:48:15,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:15,667][root][INFO] - Training Epoch: 2/2, step 1101/7134 completed (loss: 0.032870739698410034, acc: 0.9883117079734802)
[2024-12-17 04:48:15,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:16,092][root][INFO] - Training Epoch: 2/2, step 1102/7134 completed (loss: 0.053431302309036255, acc: 0.9882583022117615)
[2024-12-17 04:48:16,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:16,563][root][INFO] - Training Epoch: 2/2, step 1103/7134 completed (loss: 0.10376528650522232, acc: 0.9760000109672546)
[2024-12-17 04:48:16,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:16,991][root][INFO] - Training Epoch: 2/2, step 1104/7134 completed (loss: 0.0344095379114151, acc: 0.9884726405143738)
[2024-12-17 04:48:17,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:17,437][root][INFO] - Training Epoch: 2/2, step 1105/7134 completed (loss: 0.0471106693148613, acc: 0.986522912979126)
[2024-12-17 04:48:17,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:17,867][root][INFO] - Training Epoch: 2/2, step 1106/7134 completed (loss: 0.04815148562192917, acc: 0.9862259030342102)
[2024-12-17 04:48:18,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:18,348][root][INFO] - Training Epoch: 2/2, step 1107/7134 completed (loss: 0.029810696840286255, acc: 0.991793692111969)
[2024-12-17 04:48:18,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:18,806][root][INFO] - Training Epoch: 2/2, step 1108/7134 completed (loss: 0.022117063403129578, acc: 0.9909793734550476)
[2024-12-17 04:48:18,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:19,265][root][INFO] - Training Epoch: 2/2, step 1109/7134 completed (loss: 0.054061856120824814, acc: 0.9804469347000122)
[2024-12-17 04:48:19,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:19,693][root][INFO] - Training Epoch: 2/2, step 1110/7134 completed (loss: 0.05381738767027855, acc: 0.9868938326835632)
[2024-12-17 04:48:19,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:20,120][root][INFO] - Training Epoch: 2/2, step 1111/7134 completed (loss: 0.043159838765859604, acc: 0.9848066568374634)
[2024-12-17 04:48:20,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:20,537][root][INFO] - Training Epoch: 2/2, step 1112/7134 completed (loss: 0.0469086579978466, acc: 0.9882352948188782)
[2024-12-17 04:48:20,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:20,974][root][INFO] - Training Epoch: 2/2, step 1113/7134 completed (loss: 0.037425387650728226, acc: 0.9871299862861633)
[2024-12-17 04:48:21,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:21,430][root][INFO] - Training Epoch: 2/2, step 1114/7134 completed (loss: 0.045524146407842636, acc: 0.9854192137718201)
[2024-12-17 04:48:21,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:21,869][root][INFO] - Training Epoch: 2/2, step 1115/7134 completed (loss: 0.03728720545768738, acc: 0.9889937043190002)
[2024-12-17 04:48:21,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:22,284][root][INFO] - Training Epoch: 2/2, step 1116/7134 completed (loss: 0.017548950389027596, acc: 0.9944030046463013)
[2024-12-17 04:48:22,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:22,707][root][INFO] - Training Epoch: 2/2, step 1117/7134 completed (loss: 0.030982408672571182, acc: 0.9907975196838379)
[2024-12-17 04:48:22,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:23,140][root][INFO] - Training Epoch: 2/2, step 1118/7134 completed (loss: 0.05451992154121399, acc: 0.9896551966667175)
[2024-12-17 04:48:23,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:23,579][root][INFO] - Training Epoch: 2/2, step 1119/7134 completed (loss: 0.03692671284079552, acc: 0.9857819676399231)
[2024-12-17 04:48:23,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:24,028][root][INFO] - Training Epoch: 2/2, step 1120/7134 completed (loss: 0.04795185849070549, acc: 0.9858490824699402)
[2024-12-17 04:48:24,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:24,451][root][INFO] - Training Epoch: 2/2, step 1121/7134 completed (loss: 0.04558338224887848, acc: 0.9807976484298706)
[2024-12-17 04:48:24,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:24,829][root][INFO] - Training Epoch: 2/2, step 1122/7134 completed (loss: 0.039028413593769073, acc: 0.9902912378311157)
[2024-12-17 04:48:24,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:25,246][root][INFO] - Training Epoch: 2/2, step 1123/7134 completed (loss: 0.034774065017700195, acc: 0.9919742941856384)
[2024-12-17 04:48:25,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:25,680][root][INFO] - Training Epoch: 2/2, step 1124/7134 completed (loss: 0.02386597916483879, acc: 0.99071204662323)
[2024-12-17 04:48:25,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:26,113][root][INFO] - Training Epoch: 2/2, step 1125/7134 completed (loss: 0.019989337772130966, acc: 0.9932340979576111)
[2024-12-17 04:48:26,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:26,537][root][INFO] - Training Epoch: 2/2, step 1126/7134 completed (loss: 0.03880080208182335, acc: 0.988950252532959)
[2024-12-17 04:48:26,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:26,976][root][INFO] - Training Epoch: 2/2, step 1127/7134 completed (loss: 0.019741710275411606, acc: 0.9936000108718872)
[2024-12-17 04:48:27,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:27,396][root][INFO] - Training Epoch: 2/2, step 1128/7134 completed (loss: 0.03833698481321335, acc: 0.9913194179534912)
[2024-12-17 04:48:27,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:27,789][root][INFO] - Training Epoch: 2/2, step 1129/7134 completed (loss: 0.04212608560919762, acc: 0.9887892603874207)
[2024-12-17 04:48:27,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:28,234][root][INFO] - Training Epoch: 2/2, step 1130/7134 completed (loss: 0.026268811896443367, acc: 0.9903069734573364)
[2024-12-17 04:48:28,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:28,713][root][INFO] - Training Epoch: 2/2, step 1131/7134 completed (loss: 0.04758787900209427, acc: 0.9917452931404114)
[2024-12-17 04:48:28,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:29,129][root][INFO] - Training Epoch: 2/2, step 1132/7134 completed (loss: 0.10114197432994843, acc: 0.9785605072975159)
[2024-12-17 04:48:29,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:29,590][root][INFO] - Training Epoch: 2/2, step 1133/7134 completed (loss: 0.10549560934305191, acc: 0.9757489562034607)
[2024-12-17 04:48:29,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:30,032][root][INFO] - Training Epoch: 2/2, step 1134/7134 completed (loss: 0.056661032140254974, acc: 0.9825436472892761)
[2024-12-17 04:48:30,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:30,436][root][INFO] - Training Epoch: 2/2, step 1135/7134 completed (loss: 0.06938183307647705, acc: 0.979200005531311)
[2024-12-17 04:48:30,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:30,890][root][INFO] - Training Epoch: 2/2, step 1136/7134 completed (loss: 0.07018805295228958, acc: 0.9809523820877075)
[2024-12-17 04:48:30,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:31,250][root][INFO] - Training Epoch: 2/2, step 1137/7134 completed (loss: 0.04761979356408119, acc: 0.9818181991577148)
[2024-12-17 04:48:31,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:31,719][root][INFO] - Training Epoch: 2/2, step 1138/7134 completed (loss: 0.05070336163043976, acc: 0.9849726557731628)
[2024-12-17 04:48:31,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:32,137][root][INFO] - Training Epoch: 2/2, step 1139/7134 completed (loss: 0.09894135594367981, acc: 0.9747048616409302)
[2024-12-17 04:48:32,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:32,561][root][INFO] - Training Epoch: 2/2, step 1140/7134 completed (loss: 0.03492280840873718, acc: 0.9874686598777771)
[2024-12-17 04:48:32,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:32,989][root][INFO] - Training Epoch: 2/2, step 1141/7134 completed (loss: 0.02905791625380516, acc: 0.9906322956085205)
[2024-12-17 04:48:33,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:33,436][root][INFO] - Training Epoch: 2/2, step 1142/7134 completed (loss: 0.04980379343032837, acc: 0.9921875)
[2024-12-17 04:48:33,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:33,869][root][INFO] - Training Epoch: 2/2, step 1143/7134 completed (loss: 0.07552502304315567, acc: 0.9791377186775208)
[2024-12-17 04:48:33,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:34,315][root][INFO] - Training Epoch: 2/2, step 1144/7134 completed (loss: 0.06430744379758835, acc: 0.9825000166893005)
[2024-12-17 04:48:34,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:34,776][root][INFO] - Training Epoch: 2/2, step 1145/7134 completed (loss: 0.03432377427816391, acc: 0.9916067123413086)
[2024-12-17 04:48:34,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:35,193][root][INFO] - Training Epoch: 2/2, step 1146/7134 completed (loss: 0.03021983802318573, acc: 0.9909420013427734)
[2024-12-17 04:48:35,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:35,624][root][INFO] - Training Epoch: 2/2, step 1147/7134 completed (loss: 0.02218771167099476, acc: 0.9950124621391296)
[2024-12-17 04:48:35,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:36,059][root][INFO] - Training Epoch: 2/2, step 1148/7134 completed (loss: 0.05045098811388016, acc: 0.988054633140564)
[2024-12-17 04:48:36,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:36,487][root][INFO] - Training Epoch: 2/2, step 1149/7134 completed (loss: 0.0791013166308403, acc: 0.9758241772651672)
[2024-12-17 04:48:36,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:36,935][root][INFO] - Training Epoch: 2/2, step 1150/7134 completed (loss: 0.03842727094888687, acc: 0.9906976819038391)
[2024-12-17 04:48:37,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:37,349][root][INFO] - Training Epoch: 2/2, step 1151/7134 completed (loss: 0.011065649800002575, acc: 1.0)
[2024-12-17 04:48:37,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:37,773][root][INFO] - Training Epoch: 2/2, step 1152/7134 completed (loss: 0.022254029288887978, acc: 0.9948717951774597)
[2024-12-17 04:48:37,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:38,218][root][INFO] - Training Epoch: 2/2, step 1153/7134 completed (loss: 0.08092483878135681, acc: 0.9795640110969543)
[2024-12-17 04:48:38,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:38,637][root][INFO] - Training Epoch: 2/2, step 1154/7134 completed (loss: 0.04843733087182045, acc: 0.9893805384635925)
[2024-12-17 04:48:38,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:39,086][root][INFO] - Training Epoch: 2/2, step 1155/7134 completed (loss: 0.06418511271476746, acc: 0.9714912176132202)
[2024-12-17 04:48:39,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:39,542][root][INFO] - Training Epoch: 2/2, step 1156/7134 completed (loss: 0.023494785651564598, acc: 0.9907833933830261)
[2024-12-17 04:48:39,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:39,982][root][INFO] - Training Epoch: 2/2, step 1157/7134 completed (loss: 0.060643427073955536, acc: 0.9779286980628967)
[2024-12-17 04:48:40,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:40,407][root][INFO] - Training Epoch: 2/2, step 1158/7134 completed (loss: 0.06055931746959686, acc: 0.9881656765937805)
[2024-12-17 04:48:40,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:40,868][root][INFO] - Training Epoch: 2/2, step 1159/7134 completed (loss: 0.05609573423862457, acc: 0.9858155846595764)
[2024-12-17 04:48:41,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:41,334][root][INFO] - Training Epoch: 2/2, step 1160/7134 completed (loss: 0.0309609342366457, acc: 0.9910714030265808)
[2024-12-17 04:48:41,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:41,768][root][INFO] - Training Epoch: 2/2, step 1161/7134 completed (loss: 0.09232445806264877, acc: 0.9787928462028503)
[2024-12-17 04:48:41,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:42,183][root][INFO] - Training Epoch: 2/2, step 1162/7134 completed (loss: 0.02580578625202179, acc: 0.9933884143829346)
[2024-12-17 04:48:42,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:42,600][root][INFO] - Training Epoch: 2/2, step 1163/7134 completed (loss: 0.051733631640672684, acc: 0.988054633140564)
[2024-12-17 04:48:42,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:43,053][root][INFO] - Training Epoch: 2/2, step 1164/7134 completed (loss: 0.09241840243339539, acc: 0.9791377186775208)
[2024-12-17 04:48:43,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:43,541][root][INFO] - Training Epoch: 2/2, step 1165/7134 completed (loss: 0.028051190078258514, acc: 0.9932157397270203)
[2024-12-17 04:48:43,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:43,968][root][INFO] - Training Epoch: 2/2, step 1166/7134 completed (loss: 0.026613764464855194, acc: 0.9903978109359741)
[2024-12-17 04:48:44,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:44,410][root][INFO] - Training Epoch: 2/2, step 1167/7134 completed (loss: 0.015504796989262104, acc: 0.9980353713035583)
[2024-12-17 04:48:44,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:44,877][root][INFO] - Training Epoch: 2/2, step 1168/7134 completed (loss: 0.014160506427288055, acc: 0.9947368502616882)
[2024-12-17 04:48:45,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:45,327][root][INFO] - Training Epoch: 2/2, step 1169/7134 completed (loss: 0.03937578946352005, acc: 0.9851351380348206)
[2024-12-17 04:48:45,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:45,776][root][INFO] - Training Epoch: 2/2, step 1170/7134 completed (loss: 0.02574952319264412, acc: 0.9943820238113403)
[2024-12-17 04:48:45,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:46,147][root][INFO] - Training Epoch: 2/2, step 1171/7134 completed (loss: 0.018686935305595398, acc: 0.994991660118103)
[2024-12-17 04:48:46,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:46,567][root][INFO] - Training Epoch: 2/2, step 1172/7134 completed (loss: 0.02950308471918106, acc: 0.9909228682518005)
[2024-12-17 04:48:46,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:46,993][root][INFO] - Training Epoch: 2/2, step 1173/7134 completed (loss: 0.0651385709643364, acc: 0.9855072498321533)
[2024-12-17 04:48:47,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:47,412][root][INFO] - Training Epoch: 2/2, step 1174/7134 completed (loss: 0.026148730888962746, acc: 0.9939939975738525)
[2024-12-17 04:48:47,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:47,858][root][INFO] - Training Epoch: 2/2, step 1175/7134 completed (loss: 0.03176116570830345, acc: 0.9927536249160767)
[2024-12-17 04:48:47,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:48,297][root][INFO] - Training Epoch: 2/2, step 1176/7134 completed (loss: 0.016644908115267754, acc: 0.9982876777648926)
[2024-12-17 04:48:48,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:48,709][root][INFO] - Training Epoch: 2/2, step 1177/7134 completed (loss: 0.011270437389612198, acc: 0.9960784316062927)
[2024-12-17 04:48:48,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:49,116][root][INFO] - Training Epoch: 2/2, step 1178/7134 completed (loss: 0.012104381807148457, acc: 0.9953271150588989)
[2024-12-17 04:48:49,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:49,568][root][INFO] - Training Epoch: 2/2, step 1179/7134 completed (loss: 0.019959857687354088, acc: 0.9961758852005005)
[2024-12-17 04:48:49,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:50,046][root][INFO] - Training Epoch: 2/2, step 1180/7134 completed (loss: 0.019207973033189774, acc: 0.9945255517959595)
[2024-12-17 04:48:50,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:50,482][root][INFO] - Training Epoch: 2/2, step 1181/7134 completed (loss: 0.02353278547525406, acc: 0.9899280667304993)
[2024-12-17 04:48:50,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:50,895][root][INFO] - Training Epoch: 2/2, step 1182/7134 completed (loss: 0.008897906169295311, acc: 0.9982905983924866)
[2024-12-17 04:48:51,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:51,357][root][INFO] - Training Epoch: 2/2, step 1183/7134 completed (loss: 0.009573428891599178, acc: 0.9985315799713135)
[2024-12-17 04:48:51,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:51,826][root][INFO] - Training Epoch: 2/2, step 1184/7134 completed (loss: 0.04554164782166481, acc: 0.9942775368690491)
[2024-12-17 04:48:51,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:52,258][root][INFO] - Training Epoch: 2/2, step 1185/7134 completed (loss: 0.007966420613229275, acc: 0.9969924688339233)
[2024-12-17 04:48:52,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:52,700][root][INFO] - Training Epoch: 2/2, step 1186/7134 completed (loss: 0.024709489196538925, acc: 0.9961089491844177)
[2024-12-17 04:48:52,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:53,139][root][INFO] - Training Epoch: 2/2, step 1187/7134 completed (loss: 0.022037139162421227, acc: 0.9930747747421265)
[2024-12-17 04:48:53,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:53,606][root][INFO] - Training Epoch: 2/2, step 1188/7134 completed (loss: 0.016046572476625443, acc: 0.9986807107925415)
[2024-12-17 04:48:53,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:54,042][root][INFO] - Training Epoch: 2/2, step 1189/7134 completed (loss: 0.011891979724168777, acc: 0.9971098303794861)
[2024-12-17 04:48:54,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:54,460][root][INFO] - Training Epoch: 2/2, step 1190/7134 completed (loss: 0.013874922879040241, acc: 0.9949109554290771)
[2024-12-17 04:48:54,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:54,891][root][INFO] - Training Epoch: 2/2, step 1191/7134 completed (loss: 0.03597614914178848, acc: 0.9926144480705261)
[2024-12-17 04:48:54,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:55,330][root][INFO] - Training Epoch: 2/2, step 1192/7134 completed (loss: 0.01837468519806862, acc: 0.993446946144104)
[2024-12-17 04:48:55,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:55,767][root][INFO] - Training Epoch: 2/2, step 1193/7134 completed (loss: 0.04468914866447449, acc: 0.9920254945755005)
[2024-12-17 04:48:55,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:56,193][root][INFO] - Training Epoch: 2/2, step 1194/7134 completed (loss: 0.04580382630228996, acc: 0.9890109896659851)
[2024-12-17 04:48:56,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:56,638][root][INFO] - Training Epoch: 2/2, step 1195/7134 completed (loss: 0.03967295214533806, acc: 0.9852941036224365)
[2024-12-17 04:48:56,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:57,096][root][INFO] - Training Epoch: 2/2, step 1196/7134 completed (loss: 0.07889185100793839, acc: 0.980327844619751)
[2024-12-17 04:48:57,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:57,524][root][INFO] - Training Epoch: 2/2, step 1197/7134 completed (loss: 0.041533928364515305, acc: 0.9853372573852539)
[2024-12-17 04:48:57,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:57,975][root][INFO] - Training Epoch: 2/2, step 1198/7134 completed (loss: 0.031416937708854675, acc: 0.9884892106056213)
[2024-12-17 04:48:58,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:58,445][root][INFO] - Training Epoch: 2/2, step 1199/7134 completed (loss: 0.021245157346129417, acc: 0.9955817461013794)
[2024-12-17 04:48:58,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:58,871][root][INFO] - Training Epoch: 2/2, step 1200/7134 completed (loss: 0.02372424490749836, acc: 0.9917864203453064)
[2024-12-17 04:48:58,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:59,328][root][INFO] - Training Epoch: 2/2, step 1201/7134 completed (loss: 0.0328887403011322, acc: 0.9882179498672485)
[2024-12-17 04:48:59,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:48:59,794][root][INFO] - Training Epoch: 2/2, step 1202/7134 completed (loss: 0.04093853756785393, acc: 0.9865410327911377)
[2024-12-17 04:48:59,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:00,222][root][INFO] - Training Epoch: 2/2, step 1203/7134 completed (loss: 0.006527260411530733, acc: 1.0)
[2024-12-17 04:49:00,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:00,643][root][INFO] - Training Epoch: 2/2, step 1204/7134 completed (loss: 0.037419673055410385, acc: 0.986940324306488)
[2024-12-17 04:49:00,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:01,087][root][INFO] - Training Epoch: 2/2, step 1205/7134 completed (loss: 0.07285627722740173, acc: 0.983098566532135)
[2024-12-17 04:49:01,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:01,544][root][INFO] - Training Epoch: 2/2, step 1206/7134 completed (loss: 0.03443154692649841, acc: 0.9925558567047119)
[2024-12-17 04:49:01,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:02,000][root][INFO] - Training Epoch: 2/2, step 1207/7134 completed (loss: 0.03832395747303963, acc: 0.9912060499191284)
[2024-12-17 04:49:02,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:02,437][root][INFO] - Training Epoch: 2/2, step 1208/7134 completed (loss: 0.0554390586912632, acc: 0.97947758436203)
[2024-12-17 04:49:02,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:02,870][root][INFO] - Training Epoch: 2/2, step 1209/7134 completed (loss: 0.11333641409873962, acc: 0.972577691078186)
[2024-12-17 04:49:02,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:03,311][root][INFO] - Training Epoch: 2/2, step 1210/7134 completed (loss: 0.08238139748573303, acc: 0.9776714444160461)
[2024-12-17 04:49:03,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:03,737][root][INFO] - Training Epoch: 2/2, step 1211/7134 completed (loss: 0.11481999605894089, acc: 0.9653179049491882)
[2024-12-17 04:49:03,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:04,158][root][INFO] - Training Epoch: 2/2, step 1212/7134 completed (loss: 0.0889245942234993, acc: 0.9817073345184326)
[2024-12-17 04:49:04,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:04,620][root][INFO] - Training Epoch: 2/2, step 1213/7134 completed (loss: 0.03312429413199425, acc: 0.9886845946311951)
[2024-12-17 04:49:04,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:05,053][root][INFO] - Training Epoch: 2/2, step 1214/7134 completed (loss: 0.08009988814592361, acc: 0.9784615635871887)
[2024-12-17 04:49:05,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:05,509][root][INFO] - Training Epoch: 2/2, step 1215/7134 completed (loss: 0.06825460493564606, acc: 0.9806896448135376)
[2024-12-17 04:49:05,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:05,952][root][INFO] - Training Epoch: 2/2, step 1216/7134 completed (loss: 0.03479494899511337, acc: 0.9927007555961609)
[2024-12-17 04:49:06,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:06,412][root][INFO] - Training Epoch: 2/2, step 1217/7134 completed (loss: 0.05791919305920601, acc: 0.9886363744735718)
[2024-12-17 04:49:06,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:06,888][root][INFO] - Training Epoch: 2/2, step 1218/7134 completed (loss: 0.11105021834373474, acc: 0.9716417789459229)
[2024-12-17 04:49:07,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:07,357][root][INFO] - Training Epoch: 2/2, step 1219/7134 completed (loss: 0.11078229546546936, acc: 0.9683655500411987)
[2024-12-17 04:49:07,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:07,831][root][INFO] - Training Epoch: 2/2, step 1220/7134 completed (loss: 0.09112554788589478, acc: 0.9822335243225098)
[2024-12-17 04:49:07,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:08,326][root][INFO] - Training Epoch: 2/2, step 1221/7134 completed (loss: 0.06335121393203735, acc: 0.9835526347160339)
[2024-12-17 04:49:08,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:08,805][root][INFO] - Training Epoch: 2/2, step 1222/7134 completed (loss: 0.07000233978033066, acc: 0.9821215867996216)
[2024-12-17 04:49:08,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:09,276][root][INFO] - Training Epoch: 2/2, step 1223/7134 completed (loss: 0.15857131779193878, acc: 0.9684499502182007)
[2024-12-17 04:49:09,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:09,746][root][INFO] - Training Epoch: 2/2, step 1224/7134 completed (loss: 0.05623076111078262, acc: 0.9889624714851379)
[2024-12-17 04:49:09,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:10,213][root][INFO] - Training Epoch: 2/2, step 1225/7134 completed (loss: 0.07026202231645584, acc: 0.9818388223648071)
[2024-12-17 04:49:10,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:10,681][root][INFO] - Training Epoch: 2/2, step 1226/7134 completed (loss: 0.1113591194152832, acc: 0.9698188900947571)
[2024-12-17 04:49:10,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:11,128][root][INFO] - Training Epoch: 2/2, step 1227/7134 completed (loss: 0.12751887738704681, acc: 0.959785521030426)
[2024-12-17 04:49:11,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:11,583][root][INFO] - Training Epoch: 2/2, step 1228/7134 completed (loss: 0.1090727299451828, acc: 0.9742489457130432)
[2024-12-17 04:49:11,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:12,039][root][INFO] - Training Epoch: 2/2, step 1229/7134 completed (loss: 0.04819061607122421, acc: 0.9867947101593018)
[2024-12-17 04:49:12,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:12,514][root][INFO] - Training Epoch: 2/2, step 1230/7134 completed (loss: 0.08268524706363678, acc: 0.9717513918876648)
[2024-12-17 04:49:12,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:13,019][root][INFO] - Training Epoch: 2/2, step 1231/7134 completed (loss: 0.06673819571733475, acc: 0.9834539890289307)
[2024-12-17 04:49:13,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:13,543][root][INFO] - Training Epoch: 2/2, step 1232/7134 completed (loss: 0.0739092007279396, acc: 0.9787007570266724)
[2024-12-17 04:49:13,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:14,018][root][INFO] - Training Epoch: 2/2, step 1233/7134 completed (loss: 0.12852118909358978, acc: 0.9676300287246704)
[2024-12-17 04:49:14,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:14,483][root][INFO] - Training Epoch: 2/2, step 1234/7134 completed (loss: 0.04453449323773384, acc: 0.989130437374115)
[2024-12-17 04:49:14,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:14,948][root][INFO] - Training Epoch: 2/2, step 1235/7134 completed (loss: 0.0792398452758789, acc: 0.9844124913215637)
[2024-12-17 04:49:15,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:15,411][root][INFO] - Training Epoch: 2/2, step 1236/7134 completed (loss: 0.1343597173690796, acc: 0.9590044021606445)
[2024-12-17 04:49:15,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:15,884][root][INFO] - Training Epoch: 2/2, step 1237/7134 completed (loss: 0.07905373722314835, acc: 0.9798136353492737)
[2024-12-17 04:49:16,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:16,349][root][INFO] - Training Epoch: 2/2, step 1238/7134 completed (loss: 0.12358176708221436, acc: 0.9577874541282654)
[2024-12-17 04:49:16,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:16,826][root][INFO] - Training Epoch: 2/2, step 1239/7134 completed (loss: 0.09426156431436539, acc: 0.9713876843452454)
[2024-12-17 04:49:16,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:17,295][root][INFO] - Training Epoch: 2/2, step 1240/7134 completed (loss: 0.09505118429660797, acc: 0.9735449552536011)
[2024-12-17 04:49:17,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:17,708][root][INFO] - Training Epoch: 2/2, step 1241/7134 completed (loss: 0.07228315621614456, acc: 0.9678714871406555)
[2024-12-17 04:49:17,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:18,185][root][INFO] - Training Epoch: 2/2, step 1242/7134 completed (loss: 0.06656959652900696, acc: 0.979567289352417)
[2024-12-17 04:49:18,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:18,664][root][INFO] - Training Epoch: 2/2, step 1243/7134 completed (loss: 0.06114064157009125, acc: 0.9853556752204895)
[2024-12-17 04:49:18,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:19,117][root][INFO] - Training Epoch: 2/2, step 1244/7134 completed (loss: 0.08079993724822998, acc: 0.9850993156433105)
[2024-12-17 04:49:19,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:19,606][root][INFO] - Training Epoch: 2/2, step 1245/7134 completed (loss: 0.06939524412155151, acc: 0.983627200126648)
[2024-12-17 04:49:19,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:20,053][root][INFO] - Training Epoch: 2/2, step 1246/7134 completed (loss: 0.09911004453897476, acc: 0.9691912531852722)
[2024-12-17 04:49:20,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:20,502][root][INFO] - Training Epoch: 2/2, step 1247/7134 completed (loss: 0.040479876101017, acc: 0.9898697733879089)
[2024-12-17 04:49:20,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:20,951][root][INFO] - Training Epoch: 2/2, step 1248/7134 completed (loss: 0.06998027116060257, acc: 0.9748283624649048)
[2024-12-17 04:49:21,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:21,371][root][INFO] - Training Epoch: 2/2, step 1249/7134 completed (loss: 0.04140216112136841, acc: 0.9911032319068909)
[2024-12-17 04:49:21,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:21,800][root][INFO] - Training Epoch: 2/2, step 1250/7134 completed (loss: 0.02662491425871849, acc: 0.9900850057601929)
[2024-12-17 04:49:21,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:22,238][root][INFO] - Training Epoch: 2/2, step 1251/7134 completed (loss: 0.025734515860676765, acc: 0.9876543283462524)
[2024-12-17 04:49:22,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:22,672][root][INFO] - Training Epoch: 2/2, step 1252/7134 completed (loss: 0.030984457582235336, acc: 0.9922839403152466)
[2024-12-17 04:49:22,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:23,107][root][INFO] - Training Epoch: 2/2, step 1253/7134 completed (loss: 0.06635495275259018, acc: 0.9864864945411682)
[2024-12-17 04:49:23,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:23,549][root][INFO] - Training Epoch: 2/2, step 1254/7134 completed (loss: 0.08162856847047806, acc: 0.9757575988769531)
[2024-12-17 04:49:23,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:23,975][root][INFO] - Training Epoch: 2/2, step 1255/7134 completed (loss: 0.05059210583567619, acc: 0.9897959232330322)
[2024-12-17 04:49:24,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:24,399][root][INFO] - Training Epoch: 2/2, step 1256/7134 completed (loss: 0.043956268578767776, acc: 0.9871382713317871)
[2024-12-17 04:49:24,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:24,840][root][INFO] - Training Epoch: 2/2, step 1257/7134 completed (loss: 0.024827919900417328, acc: 0.9919224381446838)
[2024-12-17 04:49:24,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:25,286][root][INFO] - Training Epoch: 2/2, step 1258/7134 completed (loss: 0.0561983548104763, acc: 0.980966329574585)
[2024-12-17 04:49:25,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:25,713][root][INFO] - Training Epoch: 2/2, step 1259/7134 completed (loss: 0.07067886739969254, acc: 0.9828326106071472)
[2024-12-17 04:49:25,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:26,148][root][INFO] - Training Epoch: 2/2, step 1260/7134 completed (loss: 0.024381792172789574, acc: 0.9927745461463928)
[2024-12-17 04:49:26,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:26,605][root][INFO] - Training Epoch: 2/2, step 1261/7134 completed (loss: 0.03575268015265465, acc: 0.9881305694580078)
[2024-12-17 04:49:26,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:27,001][root][INFO] - Training Epoch: 2/2, step 1262/7134 completed (loss: 0.010184467770159245, acc: 0.9963369965553284)
[2024-12-17 04:49:27,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:27,410][root][INFO] - Training Epoch: 2/2, step 1263/7134 completed (loss: 0.012647693045437336, acc: 0.9957143068313599)
[2024-12-17 04:49:27,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:27,854][root][INFO] - Training Epoch: 2/2, step 1264/7134 completed (loss: 0.02338920347392559, acc: 0.9922118186950684)
[2024-12-17 04:49:28,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:28,335][root][INFO] - Training Epoch: 2/2, step 1265/7134 completed (loss: 0.025639940053224564, acc: 0.9912280440330505)
[2024-12-17 04:49:28,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:28,774][root][INFO] - Training Epoch: 2/2, step 1266/7134 completed (loss: 0.02956935577094555, acc: 0.9913941621780396)
[2024-12-17 04:49:28,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:29,201][root][INFO] - Training Epoch: 2/2, step 1267/7134 completed (loss: 0.03011985495686531, acc: 0.9931034445762634)
[2024-12-17 04:49:29,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:29,655][root][INFO] - Training Epoch: 2/2, step 1268/7134 completed (loss: 0.041163962334394455, acc: 0.9881831407546997)
[2024-12-17 04:49:29,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:30,097][root][INFO] - Training Epoch: 2/2, step 1269/7134 completed (loss: 0.08740954101085663, acc: 0.9706896543502808)
[2024-12-17 04:49:30,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:30,567][root][INFO] - Training Epoch: 2/2, step 1270/7134 completed (loss: 0.024710968136787415, acc: 0.9888424277305603)
[2024-12-17 04:49:30,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:30,968][root][INFO] - Training Epoch: 2/2, step 1271/7134 completed (loss: 0.08152986317873001, acc: 0.9777777791023254)
[2024-12-17 04:49:31,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:31,424][root][INFO] - Training Epoch: 2/2, step 1272/7134 completed (loss: 0.01793704740703106, acc: 0.9947159886360168)
[2024-12-17 04:49:31,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:31,852][root][INFO] - Training Epoch: 2/2, step 1273/7134 completed (loss: 0.024938879534602165, acc: 0.9951612949371338)
[2024-12-17 04:49:31,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:32,294][root][INFO] - Training Epoch: 2/2, step 1274/7134 completed (loss: 0.028257325291633606, acc: 0.9915540814399719)
[2024-12-17 04:49:32,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:32,715][root][INFO] - Training Epoch: 2/2, step 1275/7134 completed (loss: 0.02655799686908722, acc: 0.9892280101776123)
[2024-12-17 04:49:32,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:33,132][root][INFO] - Training Epoch: 2/2, step 1276/7134 completed (loss: 0.018085889518260956, acc: 0.9951612949371338)
[2024-12-17 04:49:33,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:33,547][root][INFO] - Training Epoch: 2/2, step 1277/7134 completed (loss: 0.02881026640534401, acc: 0.9903069734573364)
[2024-12-17 04:49:33,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:34,004][root][INFO] - Training Epoch: 2/2, step 1278/7134 completed (loss: 0.05304219201207161, acc: 0.9828926920890808)
[2024-12-17 04:49:34,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:34,441][root][INFO] - Training Epoch: 2/2, step 1279/7134 completed (loss: 0.06533698737621307, acc: 0.9826302528381348)
[2024-12-17 04:49:34,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:34,871][root][INFO] - Training Epoch: 2/2, step 1280/7134 completed (loss: 0.06151273846626282, acc: 0.9842312932014465)
[2024-12-17 04:49:34,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:35,291][root][INFO] - Training Epoch: 2/2, step 1281/7134 completed (loss: 0.062343768775463104, acc: 0.9759036302566528)
[2024-12-17 04:49:35,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:35,752][root][INFO] - Training Epoch: 2/2, step 1282/7134 completed (loss: 0.10559895634651184, acc: 0.9759358167648315)
[2024-12-17 04:49:35,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:36,226][root][INFO] - Training Epoch: 2/2, step 1283/7134 completed (loss: 0.08308659493923187, acc: 0.9823943376541138)
[2024-12-17 04:49:36,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:36,678][root][INFO] - Training Epoch: 2/2, step 1284/7134 completed (loss: 0.057095468044281006, acc: 0.9863760471343994)
[2024-12-17 04:49:36,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:37,098][root][INFO] - Training Epoch: 2/2, step 1285/7134 completed (loss: 0.0662490501999855, acc: 0.9870129823684692)
[2024-12-17 04:49:37,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:37,554][root][INFO] - Training Epoch: 2/2, step 1286/7134 completed (loss: 0.03330538794398308, acc: 0.9899857044219971)
[2024-12-17 04:49:37,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:37,968][root][INFO] - Training Epoch: 2/2, step 1287/7134 completed (loss: 0.08486729115247726, acc: 0.9867109656333923)
[2024-12-17 04:49:38,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:38,408][root][INFO] - Training Epoch: 2/2, step 1288/7134 completed (loss: 0.05150877311825752, acc: 0.989847719669342)
[2024-12-17 04:49:38,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:38,841][root][INFO] - Training Epoch: 2/2, step 1289/7134 completed (loss: 0.05370189622044563, acc: 0.9882746934890747)
[2024-12-17 04:49:38,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:39,287][root][INFO] - Training Epoch: 2/2, step 1290/7134 completed (loss: 0.0364542230963707, acc: 0.9915493130683899)
[2024-12-17 04:49:39,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:39,768][root][INFO] - Training Epoch: 2/2, step 1291/7134 completed (loss: 0.03922518342733383, acc: 0.9944211840629578)
[2024-12-17 04:49:39,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:40,201][root][INFO] - Training Epoch: 2/2, step 1292/7134 completed (loss: 0.04275709018111229, acc: 0.9870129823684692)
[2024-12-17 04:49:40,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:40,658][root][INFO] - Training Epoch: 2/2, step 1293/7134 completed (loss: 0.04392938315868378, acc: 0.9883585572242737)
[2024-12-17 04:49:40,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:41,107][root][INFO] - Training Epoch: 2/2, step 1294/7134 completed (loss: 0.051642414182424545, acc: 0.9882965087890625)
[2024-12-17 04:49:41,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:41,568][root][INFO] - Training Epoch: 2/2, step 1295/7134 completed (loss: 0.05042657628655434, acc: 0.9898132681846619)
[2024-12-17 04:49:41,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:42,035][root][INFO] - Training Epoch: 2/2, step 1296/7134 completed (loss: 0.02531474642455578, acc: 0.9933628439903259)
[2024-12-17 04:49:42,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:42,421][root][INFO] - Training Epoch: 2/2, step 1297/7134 completed (loss: 0.04020038619637489, acc: 0.987525999546051)
[2024-12-17 04:49:42,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:42,848][root][INFO] - Training Epoch: 2/2, step 1298/7134 completed (loss: 0.09045787155628204, acc: 0.980215847492218)
[2024-12-17 04:49:42,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:43,265][root][INFO] - Training Epoch: 2/2, step 1299/7134 completed (loss: 0.032216109335422516, acc: 0.9973958134651184)
[2024-12-17 04:49:43,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:43,731][root][INFO] - Training Epoch: 2/2, step 1300/7134 completed (loss: 0.034442272037267685, acc: 0.9902557730674744)
[2024-12-17 04:49:43,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:44,177][root][INFO] - Training Epoch: 2/2, step 1301/7134 completed (loss: 0.012100480496883392, acc: 0.997032642364502)
[2024-12-17 04:49:44,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:44,648][root][INFO] - Training Epoch: 2/2, step 1302/7134 completed (loss: 0.04988008365035057, acc: 0.9877232313156128)
[2024-12-17 04:49:44,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:45,129][root][INFO] - Training Epoch: 2/2, step 1303/7134 completed (loss: 0.050676099956035614, acc: 0.9879807829856873)
[2024-12-17 04:49:45,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:45,572][root][INFO] - Training Epoch: 2/2, step 1304/7134 completed (loss: 0.07811949402093887, acc: 0.9855072498321533)
[2024-12-17 04:49:45,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:46,039][root][INFO] - Training Epoch: 2/2, step 1305/7134 completed (loss: 0.04284023493528366, acc: 0.9885786771774292)
[2024-12-17 04:49:46,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:46,513][root][INFO] - Training Epoch: 2/2, step 1306/7134 completed (loss: 0.07015367597341537, acc: 0.9817906022071838)
[2024-12-17 04:49:46,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:46,932][root][INFO] - Training Epoch: 2/2, step 1307/7134 completed (loss: 0.03338183835148811, acc: 0.9921011328697205)
[2024-12-17 04:49:47,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:47,383][root][INFO] - Training Epoch: 2/2, step 1308/7134 completed (loss: 0.05498569458723068, acc: 0.9849624037742615)
[2024-12-17 04:49:47,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:47,851][root][INFO] - Training Epoch: 2/2, step 1309/7134 completed (loss: 0.045922812074422836, acc: 0.9868420958518982)
[2024-12-17 04:49:47,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:48,320][root][INFO] - Training Epoch: 2/2, step 1310/7134 completed (loss: 0.05371054261922836, acc: 0.9809523820877075)
[2024-12-17 04:49:48,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:48,774][root][INFO] - Training Epoch: 2/2, step 1311/7134 completed (loss: 0.049312129616737366, acc: 0.9886877536773682)
[2024-12-17 04:49:48,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:49,237][root][INFO] - Training Epoch: 2/2, step 1312/7134 completed (loss: 0.09084869176149368, acc: 0.9811320900917053)
[2024-12-17 04:49:49,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:49,708][root][INFO] - Training Epoch: 2/2, step 1313/7134 completed (loss: 0.07266886532306671, acc: 0.9759206771850586)
[2024-12-17 04:49:49,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:50,134][root][INFO] - Training Epoch: 2/2, step 1314/7134 completed (loss: 0.039933595806360245, acc: 0.9894737005233765)
[2024-12-17 04:49:50,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:50,574][root][INFO] - Training Epoch: 2/2, step 1315/7134 completed (loss: 0.14010950922966003, acc: 0.9693333506584167)
[2024-12-17 04:49:50,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:51,025][root][INFO] - Training Epoch: 2/2, step 1316/7134 completed (loss: 0.043374884873628616, acc: 0.9887005686759949)
[2024-12-17 04:49:51,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:51,356][root][INFO] - Training Epoch: 2/2, step 1317/7134 completed (loss: 0.11633316427469254, acc: 0.9674796462059021)
[2024-12-17 04:49:51,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:51,791][root][INFO] - Training Epoch: 2/2, step 1318/7134 completed (loss: 0.060525983572006226, acc: 0.9863760471343994)
[2024-12-17 04:49:51,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:52,157][root][INFO] - Training Epoch: 2/2, step 1319/7134 completed (loss: 0.12360337376594543, acc: 0.9748283624649048)
[2024-12-17 04:49:52,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:52,566][root][INFO] - Training Epoch: 2/2, step 1320/7134 completed (loss: 0.12519189715385437, acc: 0.9723126888275146)
[2024-12-17 04:49:52,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:53,060][root][INFO] - Training Epoch: 2/2, step 1321/7134 completed (loss: 0.03346080332994461, acc: 0.9901960492134094)
[2024-12-17 04:49:53,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:53,502][root][INFO] - Training Epoch: 2/2, step 1322/7134 completed (loss: 0.0672074630856514, acc: 0.9819967150688171)
[2024-12-17 04:49:53,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:53,948][root][INFO] - Training Epoch: 2/2, step 1323/7134 completed (loss: 0.05783139541745186, acc: 0.9839285612106323)
[2024-12-17 04:49:54,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:54,387][root][INFO] - Training Epoch: 2/2, step 1324/7134 completed (loss: 0.038129258900880814, acc: 0.9884868264198303)
[2024-12-17 04:49:54,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:54,806][root][INFO] - Training Epoch: 2/2, step 1325/7134 completed (loss: 0.04845215380191803, acc: 0.9909297227859497)
[2024-12-17 04:49:54,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:55,281][root][INFO] - Training Epoch: 2/2, step 1326/7134 completed (loss: 0.057035740464925766, acc: 0.9868276715278625)
[2024-12-17 04:49:55,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:55,745][root][INFO] - Training Epoch: 2/2, step 1327/7134 completed (loss: 0.05861648917198181, acc: 0.9820089936256409)
[2024-12-17 04:49:55,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:56,194][root][INFO] - Training Epoch: 2/2, step 1328/7134 completed (loss: 0.06800613552331924, acc: 0.9837209582328796)
[2024-12-17 04:49:56,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:56,640][root][INFO] - Training Epoch: 2/2, step 1329/7134 completed (loss: 0.07162488996982574, acc: 0.9779005646705627)
[2024-12-17 04:49:56,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:57,077][root][INFO] - Training Epoch: 2/2, step 1330/7134 completed (loss: 0.03312227502465248, acc: 0.9914236664772034)
[2024-12-17 04:49:57,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:57,539][root][INFO] - Training Epoch: 2/2, step 1331/7134 completed (loss: 0.021898727864027023, acc: 0.9934853315353394)
[2024-12-17 04:49:57,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:57,924][root][INFO] - Training Epoch: 2/2, step 1332/7134 completed (loss: 0.021422414109110832, acc: 0.9934498071670532)
[2024-12-17 04:49:58,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:58,394][root][INFO] - Training Epoch: 2/2, step 1333/7134 completed (loss: 0.06318148970603943, acc: 0.9795918464660645)
[2024-12-17 04:49:58,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:58,862][root][INFO] - Training Epoch: 2/2, step 1334/7134 completed (loss: 0.09988957643508911, acc: 0.9736024737358093)
[2024-12-17 04:49:58,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:59,290][root][INFO] - Training Epoch: 2/2, step 1335/7134 completed (loss: 0.11962831020355225, acc: 0.9813581705093384)
[2024-12-17 04:49:59,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:49:59,735][root][INFO] - Training Epoch: 2/2, step 1336/7134 completed (loss: 0.03368324413895607, acc: 0.9905277490615845)
[2024-12-17 04:49:59,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:00,214][root][INFO] - Training Epoch: 2/2, step 1337/7134 completed (loss: 0.01784115470945835, acc: 0.995398759841919)
[2024-12-17 04:50:00,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:00,647][root][INFO] - Training Epoch: 2/2, step 1338/7134 completed (loss: 0.0617525540292263, acc: 0.9839357137680054)
[2024-12-17 04:50:00,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:01,066][root][INFO] - Training Epoch: 2/2, step 1339/7134 completed (loss: 0.07094927877187729, acc: 0.9775280952453613)
[2024-12-17 04:50:01,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:01,492][root][INFO] - Training Epoch: 2/2, step 1340/7134 completed (loss: 0.08167150616645813, acc: 0.9806259274482727)
[2024-12-17 04:50:01,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:01,895][root][INFO] - Training Epoch: 2/2, step 1341/7134 completed (loss: 0.06289011985063553, acc: 0.9858757257461548)
[2024-12-17 04:50:01,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:02,318][root][INFO] - Training Epoch: 2/2, step 1342/7134 completed (loss: 0.01332219410687685, acc: 0.9967793822288513)
[2024-12-17 04:50:02,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:02,774][root][INFO] - Training Epoch: 2/2, step 1343/7134 completed (loss: 0.06998065114021301, acc: 0.9856887459754944)
[2024-12-17 04:50:02,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:03,190][root][INFO] - Training Epoch: 2/2, step 1344/7134 completed (loss: 0.0485195517539978, acc: 0.9841628670692444)
[2024-12-17 04:50:03,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:03,587][root][INFO] - Training Epoch: 2/2, step 1345/7134 completed (loss: 0.051076311618089676, acc: 0.9867374300956726)
[2024-12-17 04:50:03,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:04,074][root][INFO] - Training Epoch: 2/2, step 1346/7134 completed (loss: 0.06671686470508575, acc: 0.9906542301177979)
[2024-12-17 04:50:04,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:04,504][root][INFO] - Training Epoch: 2/2, step 1347/7134 completed (loss: 0.05558403208851814, acc: 0.9843205809593201)
[2024-12-17 04:50:04,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:04,950][root][INFO] - Training Epoch: 2/2, step 1348/7134 completed (loss: 0.030505189672112465, acc: 0.9921362996101379)
[2024-12-17 04:50:05,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:05,390][root][INFO] - Training Epoch: 2/2, step 1349/7134 completed (loss: 0.028295448049902916, acc: 0.9914529919624329)
[2024-12-17 04:50:05,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:05,814][root][INFO] - Training Epoch: 2/2, step 1350/7134 completed (loss: 0.029258351773023605, acc: 0.9942113161087036)
[2024-12-17 04:50:05,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:06,231][root][INFO] - Training Epoch: 2/2, step 1351/7134 completed (loss: 0.02367318794131279, acc: 0.990176796913147)
[2024-12-17 04:50:06,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:06,650][root][INFO] - Training Epoch: 2/2, step 1352/7134 completed (loss: 0.03684549778699875, acc: 0.9910714030265808)
[2024-12-17 04:50:06,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:07,067][root][INFO] - Training Epoch: 2/2, step 1353/7134 completed (loss: 0.03310311958193779, acc: 0.9961685538291931)
[2024-12-17 04:50:07,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:07,510][root][INFO] - Training Epoch: 2/2, step 1354/7134 completed (loss: 0.012715427204966545, acc: 0.9983792304992676)
[2024-12-17 04:50:07,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:07,959][root][INFO] - Training Epoch: 2/2, step 1355/7134 completed (loss: 0.01684817671775818, acc: 0.9937694668769836)
[2024-12-17 04:50:08,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:08,420][root][INFO] - Training Epoch: 2/2, step 1356/7134 completed (loss: 0.014218680560588837, acc: 0.996052622795105)
[2024-12-17 04:50:08,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:08,871][root][INFO] - Training Epoch: 2/2, step 1357/7134 completed (loss: 0.01241584774106741, acc: 0.994955837726593)
[2024-12-17 04:50:08,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:09,340][root][INFO] - Training Epoch: 2/2, step 1358/7134 completed (loss: 0.037254977971315384, acc: 0.9922077655792236)
[2024-12-17 04:50:09,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:09,775][root][INFO] - Training Epoch: 2/2, step 1359/7134 completed (loss: 0.020858779549598694, acc: 0.9959514141082764)
[2024-12-17 04:50:09,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:10,209][root][INFO] - Training Epoch: 2/2, step 1360/7134 completed (loss: 0.006723112892359495, acc: 0.9986559152603149)
[2024-12-17 04:50:10,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:10,675][root][INFO] - Training Epoch: 2/2, step 1361/7134 completed (loss: 0.010701715014874935, acc: 0.9985401630401611)
[2024-12-17 04:50:10,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:11,127][root][INFO] - Training Epoch: 2/2, step 1362/7134 completed (loss: 0.015065218321979046, acc: 0.9972677826881409)
[2024-12-17 04:50:11,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:11,601][root][INFO] - Training Epoch: 2/2, step 1363/7134 completed (loss: 0.016875380650162697, acc: 0.9946380853652954)
[2024-12-17 04:50:11,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:12,038][root][INFO] - Training Epoch: 2/2, step 1364/7134 completed (loss: 0.010252104140818119, acc: 0.9957143068313599)
[2024-12-17 04:50:12,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:12,445][root][INFO] - Training Epoch: 2/2, step 1365/7134 completed (loss: 0.0038595334626734257, acc: 1.0)
[2024-12-17 04:50:12,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:12,900][root][INFO] - Training Epoch: 2/2, step 1366/7134 completed (loss: 0.006597086787223816, acc: 0.9982143044471741)
[2024-12-17 04:50:13,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:13,320][root][INFO] - Training Epoch: 2/2, step 1367/7134 completed (loss: 0.01226284820586443, acc: 0.998275876045227)
[2024-12-17 04:50:13,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:13,777][root][INFO] - Training Epoch: 2/2, step 1368/7134 completed (loss: 0.06733110547065735, acc: 0.9847561120986938)
[2024-12-17 04:50:13,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:14,198][root][INFO] - Training Epoch: 2/2, step 1369/7134 completed (loss: 0.04811478033661842, acc: 0.9877408146858215)
[2024-12-17 04:50:14,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:14,642][root][INFO] - Training Epoch: 2/2, step 1370/7134 completed (loss: 0.04137361794710159, acc: 0.992414653301239)
[2024-12-17 04:50:14,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:15,091][root][INFO] - Training Epoch: 2/2, step 1371/7134 completed (loss: 0.032000795006752014, acc: 0.9956331849098206)
[2024-12-17 04:50:15,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:15,511][root][INFO] - Training Epoch: 2/2, step 1372/7134 completed (loss: 0.07078870385885239, acc: 0.9925093650817871)
[2024-12-17 04:50:15,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:15,963][root][INFO] - Training Epoch: 2/2, step 1373/7134 completed (loss: 0.015839023515582085, acc: 0.998031497001648)
[2024-12-17 04:50:16,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:16,397][root][INFO] - Training Epoch: 2/2, step 1374/7134 completed (loss: 0.02820572443306446, acc: 0.9900990128517151)
[2024-12-17 04:50:16,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:16,795][root][INFO] - Training Epoch: 2/2, step 1375/7134 completed (loss: 0.061083197593688965, acc: 0.9855769276618958)
[2024-12-17 04:50:16,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:17,216][root][INFO] - Training Epoch: 2/2, step 1376/7134 completed (loss: 0.06600021570920944, acc: 0.9791231751441956)
[2024-12-17 04:50:17,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:17,658][root][INFO] - Training Epoch: 2/2, step 1377/7134 completed (loss: 0.031037718057632446, acc: 0.9905882477760315)
[2024-12-17 04:50:17,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:18,037][root][INFO] - Training Epoch: 2/2, step 1378/7134 completed (loss: 0.06532767415046692, acc: 0.9785575270652771)
[2024-12-17 04:50:18,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:18,423][root][INFO] - Training Epoch: 2/2, step 1379/7134 completed (loss: 0.049817442893981934, acc: 0.9870967864990234)
[2024-12-17 04:50:18,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:18,854][root][INFO] - Training Epoch: 2/2, step 1380/7134 completed (loss: 0.03613629192113876, acc: 0.9869158864021301)
[2024-12-17 04:50:18,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:19,327][root][INFO] - Training Epoch: 2/2, step 1381/7134 completed (loss: 0.05606036260724068, acc: 0.9850746393203735)
[2024-12-17 04:50:19,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:19,741][root][INFO] - Training Epoch: 2/2, step 1382/7134 completed (loss: 0.05405857041478157, acc: 0.9841269850730896)
[2024-12-17 04:50:19,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:20,192][root][INFO] - Training Epoch: 2/2, step 1383/7134 completed (loss: 0.032477717846632004, acc: 0.9827883243560791)
[2024-12-17 04:50:20,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:20,611][root][INFO] - Training Epoch: 2/2, step 1384/7134 completed (loss: 0.06244213879108429, acc: 0.9750415682792664)
[2024-12-17 04:50:20,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:21,038][root][INFO] - Training Epoch: 2/2, step 1385/7134 completed (loss: 0.07450903952121735, acc: 0.9816513657569885)
[2024-12-17 04:50:21,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:21,478][root][INFO] - Training Epoch: 2/2, step 1386/7134 completed (loss: 0.0432472750544548, acc: 0.9896755218505859)
[2024-12-17 04:50:21,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:21,910][root][INFO] - Training Epoch: 2/2, step 1387/7134 completed (loss: 0.04698585718870163, acc: 0.9885386824607849)
[2024-12-17 04:50:22,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:22,334][root][INFO] - Training Epoch: 2/2, step 1388/7134 completed (loss: 0.05133701115846634, acc: 0.9829642176628113)
[2024-12-17 04:50:22,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:22,763][root][INFO] - Training Epoch: 2/2, step 1389/7134 completed (loss: 0.04228314757347107, acc: 0.9886547923088074)
[2024-12-17 04:50:22,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:23,201][root][INFO] - Training Epoch: 2/2, step 1390/7134 completed (loss: 0.04049628973007202, acc: 0.9843993782997131)
[2024-12-17 04:50:23,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:23,637][root][INFO] - Training Epoch: 2/2, step 1391/7134 completed (loss: 0.07593753933906555, acc: 0.9806678295135498)
[2024-12-17 04:50:23,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:24,081][root][INFO] - Training Epoch: 2/2, step 1392/7134 completed (loss: 0.03728896751999855, acc: 0.9844290614128113)
[2024-12-17 04:50:24,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:24,507][root][INFO] - Training Epoch: 2/2, step 1393/7134 completed (loss: 0.03637654706835747, acc: 0.9884792566299438)
[2024-12-17 04:50:24,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:24,916][root][INFO] - Training Epoch: 2/2, step 1394/7134 completed (loss: 0.020829012617468834, acc: 0.9920634627342224)
[2024-12-17 04:50:25,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:25,307][root][INFO] - Training Epoch: 2/2, step 1395/7134 completed (loss: 0.05308939144015312, acc: 0.990138053894043)
[2024-12-17 04:50:25,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:25,710][root][INFO] - Training Epoch: 2/2, step 1396/7134 completed (loss: 0.05169473960995674, acc: 0.9797297120094299)
[2024-12-17 04:50:25,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:26,122][root][INFO] - Training Epoch: 2/2, step 1397/7134 completed (loss: 0.09007390588521957, acc: 0.9713321924209595)
[2024-12-17 04:50:26,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:26,521][root][INFO] - Training Epoch: 2/2, step 1398/7134 completed (loss: 0.021713757887482643, acc: 0.9918864369392395)
[2024-12-17 04:50:26,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:26,952][root][INFO] - Training Epoch: 2/2, step 1399/7134 completed (loss: 0.07492569088935852, acc: 0.9818840622901917)
[2024-12-17 04:50:27,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:27,391][root][INFO] - Training Epoch: 2/2, step 1400/7134 completed (loss: 0.034260865300893784, acc: 0.9912739992141724)
[2024-12-17 04:50:27,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:27,823][root][INFO] - Training Epoch: 2/2, step 1401/7134 completed (loss: 0.019413631409406662, acc: 0.9934102296829224)
[2024-12-17 04:50:27,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:28,231][root][INFO] - Training Epoch: 2/2, step 1402/7134 completed (loss: 0.02447066642343998, acc: 0.9913644194602966)
[2024-12-17 04:50:28,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:28,678][root][INFO] - Training Epoch: 2/2, step 1403/7134 completed (loss: 0.02471638284623623, acc: 0.9906291961669922)
[2024-12-17 04:50:28,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:29,137][root][INFO] - Training Epoch: 2/2, step 1404/7134 completed (loss: 0.019863776862621307, acc: 0.9946949481964111)
[2024-12-17 04:50:29,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:29,562][root][INFO] - Training Epoch: 2/2, step 1405/7134 completed (loss: 0.03311775252223015, acc: 0.9857549667358398)
[2024-12-17 04:50:29,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:30,021][root][INFO] - Training Epoch: 2/2, step 1406/7134 completed (loss: 0.007038833107799292, acc: 0.9985632300376892)
[2024-12-17 04:50:30,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:30,483][root][INFO] - Training Epoch: 2/2, step 1407/7134 completed (loss: 0.02009964920580387, acc: 0.9934810996055603)
[2024-12-17 04:50:30,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:30,929][root][INFO] - Training Epoch: 2/2, step 1408/7134 completed (loss: 0.02429809235036373, acc: 0.9887820482254028)
[2024-12-17 04:50:31,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:31,368][root][INFO] - Training Epoch: 2/2, step 1409/7134 completed (loss: 0.016389423981308937, acc: 0.995529055595398)
[2024-12-17 04:50:31,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:31,859][root][INFO] - Training Epoch: 2/2, step 1410/7134 completed (loss: 0.028898663818836212, acc: 0.9934895634651184)
[2024-12-17 04:50:31,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:32,318][root][INFO] - Training Epoch: 2/2, step 1411/7134 completed (loss: 0.01077949721366167, acc: 0.9960106611251831)
[2024-12-17 04:50:32,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:32,791][root][INFO] - Training Epoch: 2/2, step 1412/7134 completed (loss: 0.012651130557060242, acc: 0.9952493906021118)
[2024-12-17 04:50:32,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:33,249][root][INFO] - Training Epoch: 2/2, step 1413/7134 completed (loss: 0.01836754009127617, acc: 0.9942445755004883)
[2024-12-17 04:50:33,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:33,701][root][INFO] - Training Epoch: 2/2, step 1414/7134 completed (loss: 0.012539186514914036, acc: 0.9953271150588989)
[2024-12-17 04:50:33,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:34,135][root][INFO] - Training Epoch: 2/2, step 1415/7134 completed (loss: 0.020737892016768456, acc: 0.9900662302970886)
[2024-12-17 04:50:34,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:34,602][root][INFO] - Training Epoch: 2/2, step 1416/7134 completed (loss: 0.014036579988896847, acc: 0.9957864880561829)
[2024-12-17 04:50:34,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:35,068][root][INFO] - Training Epoch: 2/2, step 1417/7134 completed (loss: 0.012151883915066719, acc: 0.9965986609458923)
[2024-12-17 04:50:35,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:35,521][root][INFO] - Training Epoch: 2/2, step 1418/7134 completed (loss: 0.021092068403959274, acc: 0.9942747950553894)
[2024-12-17 04:50:35,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:35,985][root][INFO] - Training Epoch: 2/2, step 1419/7134 completed (loss: 0.029311412945389748, acc: 0.9919028282165527)
[2024-12-17 04:50:36,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:36,423][root][INFO] - Training Epoch: 2/2, step 1420/7134 completed (loss: 0.014835607260465622, acc: 0.9946091771125793)
[2024-12-17 04:50:36,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:36,890][root][INFO] - Training Epoch: 2/2, step 1421/7134 completed (loss: 0.016930902376770973, acc: 0.9935897588729858)
[2024-12-17 04:50:37,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:37,354][root][INFO] - Training Epoch: 2/2, step 1422/7134 completed (loss: 0.05747257545590401, acc: 0.9871794581413269)
[2024-12-17 04:50:37,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:37,804][root][INFO] - Training Epoch: 2/2, step 1423/7134 completed (loss: 0.03987594321370125, acc: 0.9897959232330322)
[2024-12-17 04:50:37,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:38,244][root][INFO] - Training Epoch: 2/2, step 1424/7134 completed (loss: 0.07483765482902527, acc: 0.9714828729629517)
[2024-12-17 04:50:38,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:38,686][root][INFO] - Training Epoch: 2/2, step 1425/7134 completed (loss: 0.04432784393429756, acc: 0.9836065769195557)
[2024-12-17 04:50:38,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:39,146][root][INFO] - Training Epoch: 2/2, step 1426/7134 completed (loss: 0.033604755997657776, acc: 0.9871465563774109)
[2024-12-17 04:50:39,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:39,614][root][INFO] - Training Epoch: 2/2, step 1427/7134 completed (loss: 0.04735193029046059, acc: 0.984674334526062)
[2024-12-17 04:50:39,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:40,025][root][INFO] - Training Epoch: 2/2, step 1428/7134 completed (loss: 0.25012141466140747, acc: 0.9365558624267578)
[2024-12-17 04:50:40,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:40,475][root][INFO] - Training Epoch: 2/2, step 1429/7134 completed (loss: 0.033693358302116394, acc: 0.987525999546051)
[2024-12-17 04:50:40,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:40,946][root][INFO] - Training Epoch: 2/2, step 1430/7134 completed (loss: 0.060760412365198135, acc: 0.9815497994422913)
[2024-12-17 04:50:41,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:41,380][root][INFO] - Training Epoch: 2/2, step 1431/7134 completed (loss: 0.024355793371796608, acc: 0.9891451597213745)
[2024-12-17 04:50:41,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:41,834][root][INFO] - Training Epoch: 2/2, step 1432/7134 completed (loss: 0.023477204144001007, acc: 0.9897040128707886)
[2024-12-17 04:50:41,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:42,286][root][INFO] - Training Epoch: 2/2, step 1433/7134 completed (loss: 0.036145154386758804, acc: 0.9895287752151489)
[2024-12-17 04:50:42,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:42,723][root][INFO] - Training Epoch: 2/2, step 1434/7134 completed (loss: 0.056490153074264526, acc: 0.9812583923339844)
[2024-12-17 04:50:42,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:43,192][root][INFO] - Training Epoch: 2/2, step 1435/7134 completed (loss: 0.06243496388196945, acc: 0.9794721603393555)
[2024-12-17 04:50:43,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:43,638][root][INFO] - Training Epoch: 2/2, step 1436/7134 completed (loss: 0.09762312471866608, acc: 0.9619289636611938)
[2024-12-17 04:50:43,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:44,069][root][INFO] - Training Epoch: 2/2, step 1437/7134 completed (loss: 0.04547823220491409, acc: 0.9805014133453369)
[2024-12-17 04:50:44,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:44,526][root][INFO] - Training Epoch: 2/2, step 1438/7134 completed (loss: 0.05355772748589516, acc: 0.9868612885475159)
[2024-12-17 04:50:44,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:44,990][root][INFO] - Training Epoch: 2/2, step 1439/7134 completed (loss: 0.03074003756046295, acc: 0.9870129823684692)
[2024-12-17 04:50:45,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:45,406][root][INFO] - Training Epoch: 2/2, step 1440/7134 completed (loss: 0.08924398571252823, acc: 0.9672977328300476)
[2024-12-17 04:50:45,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:45,859][root][INFO] - Training Epoch: 2/2, step 1441/7134 completed (loss: 0.025222839787602425, acc: 0.992668628692627)
[2024-12-17 04:50:45,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:46,243][root][INFO] - Training Epoch: 2/2, step 1442/7134 completed (loss: 0.030052348971366882, acc: 0.9880383014678955)
[2024-12-17 04:50:46,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:46,676][root][INFO] - Training Epoch: 2/2, step 1443/7134 completed (loss: 0.07200826704502106, acc: 0.9789103865623474)
[2024-12-17 04:50:46,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:47,117][root][INFO] - Training Epoch: 2/2, step 1444/7134 completed (loss: 0.04701220616698265, acc: 0.9863813519477844)
[2024-12-17 04:50:47,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:47,581][root][INFO] - Training Epoch: 2/2, step 1445/7134 completed (loss: 0.065308578312397, acc: 0.981697142124176)
[2024-12-17 04:50:47,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:48,012][root][INFO] - Training Epoch: 2/2, step 1446/7134 completed (loss: 0.030843742191791534, acc: 0.991465151309967)
[2024-12-17 04:50:48,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:48,445][root][INFO] - Training Epoch: 2/2, step 1447/7134 completed (loss: 0.050945039838552475, acc: 0.980141818523407)
[2024-12-17 04:50:48,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:48,836][root][INFO] - Training Epoch: 2/2, step 1448/7134 completed (loss: 0.07137829065322876, acc: 0.9809321761131287)
[2024-12-17 04:50:48,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:49,278][root][INFO] - Training Epoch: 2/2, step 1449/7134 completed (loss: 0.07429426908493042, acc: 0.9789325594902039)
[2024-12-17 04:50:49,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:49,700][root][INFO] - Training Epoch: 2/2, step 1450/7134 completed (loss: 0.02630297653377056, acc: 0.9912917017936707)
[2024-12-17 04:50:49,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:50,125][root][INFO] - Training Epoch: 2/2, step 1451/7134 completed (loss: 0.024844050407409668, acc: 0.9912152290344238)
[2024-12-17 04:50:50,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:50,565][root][INFO] - Training Epoch: 2/2, step 1452/7134 completed (loss: 0.0818648636341095, acc: 0.984375)
[2024-12-17 04:50:50,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:50,967][root][INFO] - Training Epoch: 2/2, step 1453/7134 completed (loss: 0.06361047923564911, acc: 0.9841521382331848)
[2024-12-17 04:50:51,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:51,422][root][INFO] - Training Epoch: 2/2, step 1454/7134 completed (loss: 0.0777478739619255, acc: 0.9771198034286499)
[2024-12-17 04:50:51,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:51,856][root][INFO] - Training Epoch: 2/2, step 1455/7134 completed (loss: 0.07168418169021606, acc: 0.9834862351417542)
[2024-12-17 04:50:51,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:52,291][root][INFO] - Training Epoch: 2/2, step 1456/7134 completed (loss: 0.028873484581708908, acc: 0.9934498071670532)
[2024-12-17 04:50:52,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:52,724][root][INFO] - Training Epoch: 2/2, step 1457/7134 completed (loss: 0.03963012620806694, acc: 0.9891473054885864)
[2024-12-17 04:50:52,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:53,160][root][INFO] - Training Epoch: 2/2, step 1458/7134 completed (loss: 0.01628071255981922, acc: 0.9970545172691345)
[2024-12-17 04:50:53,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:53,597][root][INFO] - Training Epoch: 2/2, step 1459/7134 completed (loss: 0.04036705195903778, acc: 0.9875665903091431)
[2024-12-17 04:50:53,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:54,051][root][INFO] - Training Epoch: 2/2, step 1460/7134 completed (loss: 0.06820335239171982, acc: 0.9776315689086914)
[2024-12-17 04:50:54,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:54,478][root][INFO] - Training Epoch: 2/2, step 1461/7134 completed (loss: 0.04811092093586922, acc: 0.980861246585846)
[2024-12-17 04:50:54,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:54,916][root][INFO] - Training Epoch: 2/2, step 1462/7134 completed (loss: 0.07243424654006958, acc: 0.9841269850730896)
[2024-12-17 04:50:55,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:55,362][root][INFO] - Training Epoch: 2/2, step 1463/7134 completed (loss: 0.0746469721198082, acc: 0.9790794849395752)
[2024-12-17 04:50:55,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:55,802][root][INFO] - Training Epoch: 2/2, step 1464/7134 completed (loss: 0.11521182954311371, acc: 0.9759759902954102)
[2024-12-17 04:50:55,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:56,241][root][INFO] - Training Epoch: 2/2, step 1465/7134 completed (loss: 0.0452653132379055, acc: 0.9890282154083252)
[2024-12-17 04:50:56,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:56,684][root][INFO] - Training Epoch: 2/2, step 1466/7134 completed (loss: 0.015548708848655224, acc: 0.9971671104431152)
[2024-12-17 04:50:56,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:57,121][root][INFO] - Training Epoch: 2/2, step 1467/7134 completed (loss: 0.011572329327464104, acc: 0.9956772327423096)
[2024-12-17 04:50:57,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:57,572][root][INFO] - Training Epoch: 2/2, step 1468/7134 completed (loss: 0.03455759584903717, acc: 0.9881109595298767)
[2024-12-17 04:50:57,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:58,008][root][INFO] - Training Epoch: 2/2, step 1469/7134 completed (loss: 0.020524339750409126, acc: 0.9973081946372986)
[2024-12-17 04:50:58,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:58,442][root][INFO] - Training Epoch: 2/2, step 1470/7134 completed (loss: 0.04719066992402077, acc: 0.9841040372848511)
[2024-12-17 04:50:58,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:58,868][root][INFO] - Training Epoch: 2/2, step 1471/7134 completed (loss: 0.026882687583565712, acc: 0.9875665903091431)
[2024-12-17 04:50:58,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:59,319][root][INFO] - Training Epoch: 2/2, step 1472/7134 completed (loss: 0.024496687576174736, acc: 0.99245285987854)
[2024-12-17 04:50:59,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:50:59,749][root][INFO] - Training Epoch: 2/2, step 1473/7134 completed (loss: 0.040664225816726685, acc: 0.9851632118225098)
[2024-12-17 04:50:59,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:00,172][root][INFO] - Training Epoch: 2/2, step 1474/7134 completed (loss: 0.05674663186073303, acc: 0.9832214713096619)
[2024-12-17 04:51:00,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:00,629][root][INFO] - Training Epoch: 2/2, step 1475/7134 completed (loss: 0.05160462483763695, acc: 0.9881266355514526)
[2024-12-17 04:51:00,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:01,058][root][INFO] - Training Epoch: 2/2, step 1476/7134 completed (loss: 0.03170352429151535, acc: 0.9875776171684265)
[2024-12-17 04:51:01,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:01,478][root][INFO] - Training Epoch: 2/2, step 1477/7134 completed (loss: 0.03883602097630501, acc: 0.9912739992141724)
[2024-12-17 04:51:01,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:01,919][root][INFO] - Training Epoch: 2/2, step 1478/7134 completed (loss: 0.0432831272482872, acc: 0.9912408590316772)
[2024-12-17 04:51:02,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:02,361][root][INFO] - Training Epoch: 2/2, step 1479/7134 completed (loss: 0.022913185879588127, acc: 0.9928160905838013)
[2024-12-17 04:51:02,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:02,803][root][INFO] - Training Epoch: 2/2, step 1480/7134 completed (loss: 0.017443424090743065, acc: 0.9935064911842346)
[2024-12-17 04:51:02,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:03,264][root][INFO] - Training Epoch: 2/2, step 1481/7134 completed (loss: 0.03415564075112343, acc: 0.996052622795105)
[2024-12-17 04:51:03,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:03,726][root][INFO] - Training Epoch: 2/2, step 1482/7134 completed (loss: 0.04518650844693184, acc: 0.9872159361839294)
[2024-12-17 04:51:03,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:04,160][root][INFO] - Training Epoch: 2/2, step 1483/7134 completed (loss: 0.03506710007786751, acc: 0.9905213117599487)
[2024-12-17 04:51:04,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:04,617][root][INFO] - Training Epoch: 2/2, step 1484/7134 completed (loss: 0.05526571720838547, acc: 0.9841040372848511)
[2024-12-17 04:51:04,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:05,075][root][INFO] - Training Epoch: 2/2, step 1485/7134 completed (loss: 0.030237408354878426, acc: 0.992414653301239)
[2024-12-17 04:51:05,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:05,510][root][INFO] - Training Epoch: 2/2, step 1486/7134 completed (loss: 0.040528614073991776, acc: 0.9905277490615845)
[2024-12-17 04:51:05,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:05,961][root][INFO] - Training Epoch: 2/2, step 1487/7134 completed (loss: 0.025655701756477356, acc: 0.9908496737480164)
[2024-12-17 04:51:06,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:06,437][root][INFO] - Training Epoch: 2/2, step 1488/7134 completed (loss: 0.03417035564780235, acc: 0.9893048405647278)
[2024-12-17 04:51:06,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:06,879][root][INFO] - Training Epoch: 2/2, step 1489/7134 completed (loss: 0.04002734273672104, acc: 0.985981285572052)
[2024-12-17 04:51:07,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:07,364][root][INFO] - Training Epoch: 2/2, step 1490/7134 completed (loss: 0.017842169851064682, acc: 0.9947090148925781)
[2024-12-17 04:51:07,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:07,815][root][INFO] - Training Epoch: 2/2, step 1491/7134 completed (loss: 0.019564781337976456, acc: 0.9954022765159607)
[2024-12-17 04:51:07,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:08,260][root][INFO] - Training Epoch: 2/2, step 1492/7134 completed (loss: 0.04396406561136246, acc: 0.9895591735839844)
[2024-12-17 04:51:08,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:08,714][root][INFO] - Training Epoch: 2/2, step 1493/7134 completed (loss: 0.0350312776863575, acc: 0.9930875301361084)
[2024-12-17 04:51:08,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:09,185][root][INFO] - Training Epoch: 2/2, step 1494/7134 completed (loss: 0.025308694690465927, acc: 0.9914841651916504)
[2024-12-17 04:51:09,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:09,641][root][INFO] - Training Epoch: 2/2, step 1495/7134 completed (loss: 0.028664369136095047, acc: 0.9916167855262756)
[2024-12-17 04:51:09,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:10,100][root][INFO] - Training Epoch: 2/2, step 1496/7134 completed (loss: 0.04463334009051323, acc: 0.9914529919624329)
[2024-12-17 04:51:10,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:10,574][root][INFO] - Training Epoch: 2/2, step 1497/7134 completed (loss: 0.030619116500020027, acc: 0.9920814633369446)
[2024-12-17 04:51:10,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:11,001][root][INFO] - Training Epoch: 2/2, step 1498/7134 completed (loss: 0.011061129160225391, acc: 0.9973649382591248)
[2024-12-17 04:51:11,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:11,478][root][INFO] - Training Epoch: 2/2, step 1499/7134 completed (loss: 0.029083669185638428, acc: 0.991696298122406)
[2024-12-17 04:51:11,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:11,896][root][INFO] - Training Epoch: 2/2, step 1500/7134 completed (loss: 0.01669340953230858, acc: 0.9950330853462219)
[2024-12-17 04:51:12,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:12,387][root][INFO] - Training Epoch: 2/2, step 1501/7134 completed (loss: 0.032826945185661316, acc: 0.991150438785553)
[2024-12-17 04:51:12,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:12,845][root][INFO] - Training Epoch: 2/2, step 1502/7134 completed (loss: 0.048430800437927246, acc: 0.9864712357521057)
[2024-12-17 04:51:12,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:13,259][root][INFO] - Training Epoch: 2/2, step 1503/7134 completed (loss: 0.06635843962430954, acc: 0.9786931872367859)
[2024-12-17 04:51:13,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:13,694][root][INFO] - Training Epoch: 2/2, step 1504/7134 completed (loss: 0.013628381304442883, acc: 0.9949685335159302)
[2024-12-17 04:51:13,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:14,116][root][INFO] - Training Epoch: 2/2, step 1505/7134 completed (loss: 0.02694432996213436, acc: 0.9937694668769836)
[2024-12-17 04:51:14,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:14,575][root][INFO] - Training Epoch: 2/2, step 1506/7134 completed (loss: 0.050931137055158615, acc: 0.9832826852798462)
[2024-12-17 04:51:14,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:15,035][root][INFO] - Training Epoch: 2/2, step 1507/7134 completed (loss: 0.03217295557260513, acc: 0.9921466112136841)
[2024-12-17 04:51:15,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:15,515][root][INFO] - Training Epoch: 2/2, step 1508/7134 completed (loss: 0.016414660960435867, acc: 0.9934354424476624)
[2024-12-17 04:51:15,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:15,979][root][INFO] - Training Epoch: 2/2, step 1509/7134 completed (loss: 0.018524600192904472, acc: 0.994397759437561)
[2024-12-17 04:51:16,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:16,454][root][INFO] - Training Epoch: 2/2, step 1510/7134 completed (loss: 0.07880300283432007, acc: 0.9750000238418579)
[2024-12-17 04:51:16,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:16,912][root][INFO] - Training Epoch: 2/2, step 1511/7134 completed (loss: 0.06749989092350006, acc: 0.9843971729278564)
[2024-12-17 04:51:17,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:17,369][root][INFO] - Training Epoch: 2/2, step 1512/7134 completed (loss: 0.025001924484968185, acc: 0.9923896789550781)
[2024-12-17 04:51:17,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:17,800][root][INFO] - Training Epoch: 2/2, step 1513/7134 completed (loss: 0.02374238893389702, acc: 0.9907407164573669)
[2024-12-17 04:51:17,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:18,263][root][INFO] - Training Epoch: 2/2, step 1514/7134 completed (loss: 0.05309028923511505, acc: 0.991304337978363)
[2024-12-17 04:51:18,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:18,715][root][INFO] - Training Epoch: 2/2, step 1515/7134 completed (loss: 0.040271561592817307, acc: 0.9906542301177979)
[2024-12-17 04:51:18,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:19,071][root][INFO] - Training Epoch: 2/2, step 1516/7134 completed (loss: 0.053109873086214066, acc: 0.9829059839248657)
[2024-12-17 04:51:19,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:19,484][root][INFO] - Training Epoch: 2/2, step 1517/7134 completed (loss: 0.03931916877627373, acc: 0.9894958138465881)
[2024-12-17 04:51:19,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:19,899][root][INFO] - Training Epoch: 2/2, step 1518/7134 completed (loss: 0.03616292029619217, acc: 0.9903614521026611)
[2024-12-17 04:51:20,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:20,337][root][INFO] - Training Epoch: 2/2, step 1519/7134 completed (loss: 0.01749962382018566, acc: 0.9953917264938354)
[2024-12-17 04:51:20,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:20,802][root][INFO] - Training Epoch: 2/2, step 1520/7134 completed (loss: 0.04912998154759407, acc: 0.9843993782997131)
[2024-12-17 04:51:20,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:21,307][root][INFO] - Training Epoch: 2/2, step 1521/7134 completed (loss: 0.08681400865316391, acc: 0.9720670580863953)
[2024-12-17 04:51:21,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:21,738][root][INFO] - Training Epoch: 2/2, step 1522/7134 completed (loss: 0.094849593937397, acc: 0.9710982441902161)
[2024-12-17 04:51:21,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:22,188][root][INFO] - Training Epoch: 2/2, step 1523/7134 completed (loss: 0.1101587563753128, acc: 0.9670165181159973)
[2024-12-17 04:51:22,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:22,581][root][INFO] - Training Epoch: 2/2, step 1524/7134 completed (loss: 0.029577704146504402, acc: 0.9932885766029358)
[2024-12-17 04:51:22,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:23,034][root][INFO] - Training Epoch: 2/2, step 1525/7134 completed (loss: 0.029578477144241333, acc: 0.9932126402854919)
[2024-12-17 04:51:23,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:23,516][root][INFO] - Training Epoch: 2/2, step 1526/7134 completed (loss: 0.10159197449684143, acc: 0.9680696725845337)
[2024-12-17 04:51:23,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:24,012][root][INFO] - Training Epoch: 2/2, step 1527/7134 completed (loss: 0.10331021994352341, acc: 0.9716193675994873)
[2024-12-17 04:51:24,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:24,510][root][INFO] - Training Epoch: 2/2, step 1528/7134 completed (loss: 0.06333130598068237, acc: 0.977455735206604)
[2024-12-17 04:51:24,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:24,976][root][INFO] - Training Epoch: 2/2, step 1529/7134 completed (loss: 0.03637612238526344, acc: 0.9881094098091125)
[2024-12-17 04:51:25,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:25,395][root][INFO] - Training Epoch: 2/2, step 1530/7134 completed (loss: 0.06075681000947952, acc: 0.9827916026115417)
[2024-12-17 04:51:25,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:25,811][root][INFO] - Training Epoch: 2/2, step 1531/7134 completed (loss: 0.18934445083141327, acc: 0.957446813583374)
[2024-12-17 04:51:25,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:26,293][root][INFO] - Training Epoch: 2/2, step 1532/7134 completed (loss: 0.04004829749464989, acc: 0.9884393215179443)
[2024-12-17 04:51:26,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:26,734][root][INFO] - Training Epoch: 2/2, step 1533/7134 completed (loss: 0.036808986216783524, acc: 0.9847856163978577)
[2024-12-17 04:51:26,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:27,193][root][INFO] - Training Epoch: 2/2, step 1534/7134 completed (loss: 0.055197518318891525, acc: 0.9847645163536072)
[2024-12-17 04:51:27,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:27,689][root][INFO] - Training Epoch: 2/2, step 1535/7134 completed (loss: 0.036253150552511215, acc: 0.9868263602256775)
[2024-12-17 04:51:27,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:28,145][root][INFO] - Training Epoch: 2/2, step 1536/7134 completed (loss: 0.03008020855486393, acc: 0.9898862242698669)
[2024-12-17 04:51:28,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:28,564][root][INFO] - Training Epoch: 2/2, step 1537/7134 completed (loss: 0.05230138078331947, acc: 0.9842932224273682)
[2024-12-17 04:51:28,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:28,998][root][INFO] - Training Epoch: 2/2, step 1538/7134 completed (loss: 0.058558039367198944, acc: 0.98591548204422)
[2024-12-17 04:51:29,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:29,445][root][INFO] - Training Epoch: 2/2, step 1539/7134 completed (loss: 0.028939805924892426, acc: 0.990777313709259)
[2024-12-17 04:51:29,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:29,902][root][INFO] - Training Epoch: 2/2, step 1540/7134 completed (loss: 0.02124066837131977, acc: 0.9959785342216492)
[2024-12-17 04:51:30,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:30,350][root][INFO] - Training Epoch: 2/2, step 1541/7134 completed (loss: 0.06575985997915268, acc: 0.9836478233337402)
[2024-12-17 04:51:30,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:30,834][root][INFO] - Training Epoch: 2/2, step 1542/7134 completed (loss: 0.032685499638319016, acc: 0.9919137358665466)
[2024-12-17 04:51:30,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:31,289][root][INFO] - Training Epoch: 2/2, step 1543/7134 completed (loss: 0.02850261516869068, acc: 0.991256833076477)
[2024-12-17 04:51:31,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:31,747][root][INFO] - Training Epoch: 2/2, step 1544/7134 completed (loss: 0.02265889383852482, acc: 0.9915048480033875)
[2024-12-17 04:51:31,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:32,178][root][INFO] - Training Epoch: 2/2, step 1545/7134 completed (loss: 0.04036523029208183, acc: 0.9885222315788269)
[2024-12-17 04:51:32,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:32,652][root][INFO] - Training Epoch: 2/2, step 1546/7134 completed (loss: 0.08333167433738708, acc: 0.9803646802902222)
[2024-12-17 04:51:32,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:33,098][root][INFO] - Training Epoch: 2/2, step 1547/7134 completed (loss: 0.048083286732435226, acc: 0.9880596995353699)
[2024-12-17 04:51:33,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:33,566][root][INFO] - Training Epoch: 2/2, step 1548/7134 completed (loss: 0.03900236263871193, acc: 0.9886234402656555)
[2024-12-17 04:51:33,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:34,035][root][INFO] - Training Epoch: 2/2, step 1549/7134 completed (loss: 0.04126165062189102, acc: 0.9878183603286743)
[2024-12-17 04:51:34,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:34,498][root][INFO] - Training Epoch: 2/2, step 1550/7134 completed (loss: 0.02789970301091671, acc: 0.9873257279396057)
[2024-12-17 04:51:34,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:34,929][root][INFO] - Training Epoch: 2/2, step 1551/7134 completed (loss: 0.025422068312764168, acc: 0.9922077655792236)
[2024-12-17 04:51:35,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:35,406][root][INFO] - Training Epoch: 2/2, step 1552/7134 completed (loss: 0.02941112406551838, acc: 0.9903017282485962)
[2024-12-17 04:51:35,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:35,827][root][INFO] - Training Epoch: 2/2, step 1553/7134 completed (loss: 0.03773276135325432, acc: 0.9895969033241272)
[2024-12-17 04:51:35,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:36,332][root][INFO] - Training Epoch: 2/2, step 1554/7134 completed (loss: 0.04357878491282463, acc: 0.9864712357521057)
[2024-12-17 04:51:36,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:36,790][root][INFO] - Training Epoch: 2/2, step 1555/7134 completed (loss: 0.037844136357307434, acc: 0.9876819849014282)
[2024-12-17 04:51:36,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:37,249][root][INFO] - Training Epoch: 2/2, step 1556/7134 completed (loss: 0.026002684608101845, acc: 0.9917743802070618)
[2024-12-17 04:51:37,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:37,735][root][INFO] - Training Epoch: 2/2, step 1557/7134 completed (loss: 0.02220432460308075, acc: 0.9921700358390808)
[2024-12-17 04:51:37,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:38,162][root][INFO] - Training Epoch: 2/2, step 1558/7134 completed (loss: 0.03673788905143738, acc: 0.9859353303909302)
[2024-12-17 04:51:38,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:38,606][root][INFO] - Training Epoch: 2/2, step 1559/7134 completed (loss: 0.01216768566519022, acc: 0.9973226189613342)
[2024-12-17 04:51:38,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:39,066][root][INFO] - Training Epoch: 2/2, step 1560/7134 completed (loss: 0.029714131727814674, acc: 0.9923760890960693)
[2024-12-17 04:51:39,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:39,542][root][INFO] - Training Epoch: 2/2, step 1561/7134 completed (loss: 0.08477690070867538, acc: 0.9783315062522888)
[2024-12-17 04:51:39,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:39,982][root][INFO] - Training Epoch: 2/2, step 1562/7134 completed (loss: 0.03918886184692383, acc: 0.9878970980644226)
[2024-12-17 04:51:40,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:40,422][root][INFO] - Training Epoch: 2/2, step 1563/7134 completed (loss: 0.040717821568250656, acc: 0.9897142648696899)
[2024-12-17 04:51:40,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:40,873][root][INFO] - Training Epoch: 2/2, step 1564/7134 completed (loss: 0.0776042714715004, acc: 0.9814356565475464)
[2024-12-17 04:51:40,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:41,273][root][INFO] - Training Epoch: 2/2, step 1565/7134 completed (loss: 0.05829857662320137, acc: 0.9798319339752197)
[2024-12-17 04:51:41,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:41,695][root][INFO] - Training Epoch: 2/2, step 1566/7134 completed (loss: 0.03924078494310379, acc: 0.9849520921707153)
[2024-12-17 04:51:41,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:42,196][root][INFO] - Training Epoch: 2/2, step 1567/7134 completed (loss: 0.04132186621427536, acc: 0.9837905168533325)
[2024-12-17 04:51:42,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:42,640][root][INFO] - Training Epoch: 2/2, step 1568/7134 completed (loss: 0.04577207937836647, acc: 0.9857988357543945)
[2024-12-17 04:51:42,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:43,094][root][INFO] - Training Epoch: 2/2, step 1569/7134 completed (loss: 0.053104206919670105, acc: 0.9853801131248474)
[2024-12-17 04:51:43,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:43,574][root][INFO] - Training Epoch: 2/2, step 1570/7134 completed (loss: 0.10679926723241806, acc: 0.9790518283843994)
[2024-12-17 04:51:43,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:44,002][root][INFO] - Training Epoch: 2/2, step 1571/7134 completed (loss: 0.053571898490190506, acc: 0.9845789074897766)
[2024-12-17 04:51:44,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:44,474][root][INFO] - Training Epoch: 2/2, step 1572/7134 completed (loss: 0.037611182779073715, acc: 0.9858657121658325)
[2024-12-17 04:51:44,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:44,892][root][INFO] - Training Epoch: 2/2, step 1573/7134 completed (loss: 0.024419385939836502, acc: 0.9912917017936707)
[2024-12-17 04:51:44,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:45,364][root][INFO] - Training Epoch: 2/2, step 1574/7134 completed (loss: 0.047420863062143326, acc: 0.9901531934738159)
[2024-12-17 04:51:45,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:45,804][root][INFO] - Training Epoch: 2/2, step 1575/7134 completed (loss: 0.04441361129283905, acc: 0.9900221824645996)
[2024-12-17 04:51:45,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:46,252][root][INFO] - Training Epoch: 2/2, step 1576/7134 completed (loss: 0.05565014109015465, acc: 0.9848130941390991)
[2024-12-17 04:51:46,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:46,697][root][INFO] - Training Epoch: 2/2, step 1577/7134 completed (loss: 0.035726312547922134, acc: 0.9905771613121033)
[2024-12-17 04:51:46,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:47,144][root][INFO] - Training Epoch: 2/2, step 1578/7134 completed (loss: 0.037167321890592575, acc: 0.9851149916648865)
[2024-12-17 04:51:47,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:47,634][root][INFO] - Training Epoch: 2/2, step 1579/7134 completed (loss: 0.030383288860321045, acc: 0.9919354915618896)
[2024-12-17 04:51:47,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:48,098][root][INFO] - Training Epoch: 2/2, step 1580/7134 completed (loss: 0.07246475666761398, acc: 0.9812775254249573)
[2024-12-17 04:51:48,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:48,493][root][INFO] - Training Epoch: 2/2, step 1581/7134 completed (loss: 0.0860038474202156, acc: 0.9783950448036194)
[2024-12-17 04:51:48,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:48,957][root][INFO] - Training Epoch: 2/2, step 1582/7134 completed (loss: 0.06143993139266968, acc: 0.9827855825424194)
[2024-12-17 04:51:49,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:49,415][root][INFO] - Training Epoch: 2/2, step 1583/7134 completed (loss: 0.03751327842473984, acc: 0.9871060252189636)
[2024-12-17 04:51:49,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:49,907][root][INFO] - Training Epoch: 2/2, step 1584/7134 completed (loss: 0.033878881484270096, acc: 0.9892933368682861)
[2024-12-17 04:51:50,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:50,368][root][INFO] - Training Epoch: 2/2, step 1585/7134 completed (loss: 0.03291284292936325, acc: 0.9882214665412903)
[2024-12-17 04:51:50,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:50,804][root][INFO] - Training Epoch: 2/2, step 1586/7134 completed (loss: 0.06857986748218536, acc: 0.9857482314109802)
[2024-12-17 04:51:50,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:51,279][root][INFO] - Training Epoch: 2/2, step 1587/7134 completed (loss: 0.027704013511538506, acc: 0.9921507239341736)
[2024-12-17 04:51:51,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:51,728][root][INFO] - Training Epoch: 2/2, step 1588/7134 completed (loss: 0.06715991348028183, acc: 0.9853528738021851)
[2024-12-17 04:51:51,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:52,175][root][INFO] - Training Epoch: 2/2, step 1589/7134 completed (loss: 0.039144087582826614, acc: 0.989924430847168)
[2024-12-17 04:51:52,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:52,618][root][INFO] - Training Epoch: 2/2, step 1590/7134 completed (loss: 0.035182494670152664, acc: 0.9894259572029114)
[2024-12-17 04:51:52,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:53,034][root][INFO] - Training Epoch: 2/2, step 1591/7134 completed (loss: 0.03939640149474144, acc: 0.989847719669342)
[2024-12-17 04:51:53,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:53,523][root][INFO] - Training Epoch: 2/2, step 1592/7134 completed (loss: 0.024027548730373383, acc: 0.9942938685417175)
[2024-12-17 04:51:53,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:54,015][root][INFO] - Training Epoch: 2/2, step 1593/7134 completed (loss: 0.0418330617249012, acc: 0.9873563051223755)
[2024-12-17 04:51:54,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:54,454][root][INFO] - Training Epoch: 2/2, step 1594/7134 completed (loss: 0.02591477334499359, acc: 0.9900826215744019)
[2024-12-17 04:51:54,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:54,895][root][INFO] - Training Epoch: 2/2, step 1595/7134 completed (loss: 0.03251640126109123, acc: 0.9928315281867981)
[2024-12-17 04:51:54,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:55,328][root][INFO] - Training Epoch: 2/2, step 1596/7134 completed (loss: 0.055515047162771225, acc: 0.98740154504776)
[2024-12-17 04:51:55,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:55,761][root][INFO] - Training Epoch: 2/2, step 1597/7134 completed (loss: 0.017662962898612022, acc: 0.9957020282745361)
[2024-12-17 04:51:55,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:56,173][root][INFO] - Training Epoch: 2/2, step 1598/7134 completed (loss: 0.07779840379953384, acc: 0.9820359349250793)
[2024-12-17 04:51:56,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:56,615][root][INFO] - Training Epoch: 2/2, step 1599/7134 completed (loss: 0.10721400380134583, acc: 0.9801653027534485)
[2024-12-17 04:51:56,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:57,072][root][INFO] - Training Epoch: 2/2, step 1600/7134 completed (loss: 0.06352797150611877, acc: 0.9849884510040283)
[2024-12-17 04:51:57,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:57,496][root][INFO] - Training Epoch: 2/2, step 1601/7134 completed (loss: 0.03157823532819748, acc: 0.9903714060783386)
[2024-12-17 04:51:57,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:57,961][root][INFO] - Training Epoch: 2/2, step 1602/7134 completed (loss: 0.05007471889257431, acc: 0.993966817855835)
[2024-12-17 04:51:58,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:58,354][root][INFO] - Training Epoch: 2/2, step 1603/7134 completed (loss: 0.06129258871078491, acc: 0.9846547245979309)
[2024-12-17 04:51:58,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:58,805][root][INFO] - Training Epoch: 2/2, step 1604/7134 completed (loss: 0.027019144967198372, acc: 0.9933686852455139)
[2024-12-17 04:51:58,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:59,247][root][INFO] - Training Epoch: 2/2, step 1605/7134 completed (loss: 0.042337290942668915, acc: 0.9869621992111206)
[2024-12-17 04:51:59,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:51:59,672][root][INFO] - Training Epoch: 2/2, step 1606/7134 completed (loss: 0.016838284209370613, acc: 0.9969372153282166)
[2024-12-17 04:51:59,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:00,092][root][INFO] - Training Epoch: 2/2, step 1607/7134 completed (loss: 0.017548125237226486, acc: 0.9938900470733643)
[2024-12-17 04:52:00,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:00,568][root][INFO] - Training Epoch: 2/2, step 1608/7134 completed (loss: 0.018789300695061684, acc: 0.9944238066673279)
[2024-12-17 04:52:00,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:01,016][root][INFO] - Training Epoch: 2/2, step 1609/7134 completed (loss: 0.05576551333069801, acc: 0.9906542301177979)
[2024-12-17 04:52:01,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:01,460][root][INFO] - Training Epoch: 2/2, step 1610/7134 completed (loss: 0.06699742376804352, acc: 0.9833055138587952)
[2024-12-17 04:52:01,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:01,895][root][INFO] - Training Epoch: 2/2, step 1611/7134 completed (loss: 0.05001420900225639, acc: 0.9867724776268005)
[2024-12-17 04:52:02,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:02,335][root][INFO] - Training Epoch: 2/2, step 1612/7134 completed (loss: 0.063236765563488, acc: 0.9847328066825867)
[2024-12-17 04:52:02,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:02,776][root][INFO] - Training Epoch: 2/2, step 1613/7134 completed (loss: 0.045798409730196, acc: 0.990777313709259)
[2024-12-17 04:52:02,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:03,215][root][INFO] - Training Epoch: 2/2, step 1614/7134 completed (loss: 0.04170358180999756, acc: 0.9908257126808167)
[2024-12-17 04:52:03,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:03,705][root][INFO] - Training Epoch: 2/2, step 1615/7134 completed (loss: 0.04036135599017143, acc: 0.9879194498062134)
[2024-12-17 04:52:03,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:04,161][root][INFO] - Training Epoch: 2/2, step 1616/7134 completed (loss: 0.02358034998178482, acc: 0.9956709742546082)
[2024-12-17 04:52:04,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:04,645][root][INFO] - Training Epoch: 2/2, step 1617/7134 completed (loss: 0.04370038956403732, acc: 0.9937597513198853)
[2024-12-17 04:52:04,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:05,081][root][INFO] - Training Epoch: 2/2, step 1618/7134 completed (loss: 0.07980865985155106, acc: 0.9754385948181152)
[2024-12-17 04:52:05,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:05,569][root][INFO] - Training Epoch: 2/2, step 1619/7134 completed (loss: 0.04292406141757965, acc: 0.9877384305000305)
[2024-12-17 04:52:05,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:06,007][root][INFO] - Training Epoch: 2/2, step 1620/7134 completed (loss: 0.06590356677770615, acc: 0.9803328514099121)
[2024-12-17 04:52:06,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:06,501][root][INFO] - Training Epoch: 2/2, step 1621/7134 completed (loss: 0.07954643666744232, acc: 0.9797297120094299)
[2024-12-17 04:52:06,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:06,940][root][INFO] - Training Epoch: 2/2, step 1622/7134 completed (loss: 0.042454883456230164, acc: 0.9888579249382019)
[2024-12-17 04:52:07,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:07,396][root][INFO] - Training Epoch: 2/2, step 1623/7134 completed (loss: 0.04167022183537483, acc: 0.9915730357170105)
[2024-12-17 04:52:07,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:07,847][root][INFO] - Training Epoch: 2/2, step 1624/7134 completed (loss: 0.05799628794193268, acc: 0.98531574010849)
[2024-12-17 04:52:07,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:08,298][root][INFO] - Training Epoch: 2/2, step 1625/7134 completed (loss: 0.022750098258256912, acc: 0.9928774833679199)
[2024-12-17 04:52:08,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:08,729][root][INFO] - Training Epoch: 2/2, step 1626/7134 completed (loss: 0.0922776609659195, acc: 0.9791666865348816)
[2024-12-17 04:52:08,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:09,163][root][INFO] - Training Epoch: 2/2, step 1627/7134 completed (loss: 0.03766369819641113, acc: 0.9908758997917175)
[2024-12-17 04:52:09,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:09,622][root][INFO] - Training Epoch: 2/2, step 1628/7134 completed (loss: 0.017144825309515, acc: 0.9956268072128296)
[2024-12-17 04:52:09,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:10,046][root][INFO] - Training Epoch: 2/2, step 1629/7134 completed (loss: 0.02837778814136982, acc: 0.9890909194946289)
[2024-12-17 04:52:10,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:10,502][root][INFO] - Training Epoch: 2/2, step 1630/7134 completed (loss: 0.023400701582431793, acc: 0.9925925731658936)
[2024-12-17 04:52:10,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:10,950][root][INFO] - Training Epoch: 2/2, step 1631/7134 completed (loss: 0.05208926275372505, acc: 0.9839228391647339)
[2024-12-17 04:52:11,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:11,376][root][INFO] - Training Epoch: 2/2, step 1632/7134 completed (loss: 0.020164312794804573, acc: 0.9950248599052429)
[2024-12-17 04:52:11,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:11,818][root][INFO] - Training Epoch: 2/2, step 1633/7134 completed (loss: 0.0366649366915226, acc: 0.9905808568000793)
[2024-12-17 04:52:11,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:12,252][root][INFO] - Training Epoch: 2/2, step 1634/7134 completed (loss: 0.0245779138058424, acc: 0.992343008518219)
[2024-12-17 04:52:12,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:12,663][root][INFO] - Training Epoch: 2/2, step 1635/7134 completed (loss: 0.02046310529112816, acc: 0.9898167252540588)
[2024-12-17 04:52:12,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:13,089][root][INFO] - Training Epoch: 2/2, step 1636/7134 completed (loss: 0.0396546870470047, acc: 0.9847618937492371)
[2024-12-17 04:52:13,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:13,533][root][INFO] - Training Epoch: 2/2, step 1637/7134 completed (loss: 0.0177597813308239, acc: 0.9957627058029175)
[2024-12-17 04:52:13,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:13,989][root][INFO] - Training Epoch: 2/2, step 1638/7134 completed (loss: 0.07717429101467133, acc: 0.979626476764679)
[2024-12-17 04:52:14,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:14,433][root][INFO] - Training Epoch: 2/2, step 1639/7134 completed (loss: 0.11791754513978958, acc: 0.9748892188072205)
[2024-12-17 04:52:14,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:14,897][root][INFO] - Training Epoch: 2/2, step 1640/7134 completed (loss: 0.05117775872349739, acc: 0.9847561120986938)
[2024-12-17 04:52:15,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:15,324][root][INFO] - Training Epoch: 2/2, step 1641/7134 completed (loss: 0.02150612138211727, acc: 0.9899425506591797)
[2024-12-17 04:52:15,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:15,775][root][INFO] - Training Epoch: 2/2, step 1642/7134 completed (loss: 0.08715441823005676, acc: 0.9750000238418579)
[2024-12-17 04:52:15,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:16,205][root][INFO] - Training Epoch: 2/2, step 1643/7134 completed (loss: 0.10409386456012726, acc: 0.9722703695297241)
[2024-12-17 04:52:16,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:16,682][root][INFO] - Training Epoch: 2/2, step 1644/7134 completed (loss: 0.05888577178120613, acc: 0.9843546152114868)
[2024-12-17 04:52:16,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:17,125][root][INFO] - Training Epoch: 2/2, step 1645/7134 completed (loss: 0.07645442336797714, acc: 0.9841954112052917)
[2024-12-17 04:52:17,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:17,598][root][INFO] - Training Epoch: 2/2, step 1646/7134 completed (loss: 0.06972233951091766, acc: 0.9824281334877014)
[2024-12-17 04:52:17,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:18,060][root][INFO] - Training Epoch: 2/2, step 1647/7134 completed (loss: 0.02680234983563423, acc: 0.9888017773628235)
[2024-12-17 04:52:18,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:18,521][root][INFO] - Training Epoch: 2/2, step 1648/7134 completed (loss: 0.07260435074567795, acc: 0.9827127456665039)
[2024-12-17 04:52:18,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:18,986][root][INFO] - Training Epoch: 2/2, step 1649/7134 completed (loss: 0.030689064413309097, acc: 0.9922308325767517)
[2024-12-17 04:52:19,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:19,456][root][INFO] - Training Epoch: 2/2, step 1650/7134 completed (loss: 0.03246269002556801, acc: 0.9871134161949158)
[2024-12-17 04:52:19,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:19,922][root][INFO] - Training Epoch: 2/2, step 1651/7134 completed (loss: 0.059203360229730606, acc: 0.9845132827758789)
[2024-12-17 04:52:20,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:20,402][root][INFO] - Training Epoch: 2/2, step 1652/7134 completed (loss: 0.02597901225090027, acc: 0.9934569001197815)
[2024-12-17 04:52:20,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:20,871][root][INFO] - Training Epoch: 2/2, step 1653/7134 completed (loss: 0.034341000020504, acc: 0.9887920022010803)
[2024-12-17 04:52:21,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:21,384][root][INFO] - Training Epoch: 2/2, step 1654/7134 completed (loss: 0.05501510947942734, acc: 0.9806320071220398)
[2024-12-17 04:52:21,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:21,856][root][INFO] - Training Epoch: 2/2, step 1655/7134 completed (loss: 0.043010029941797256, acc: 0.9876084327697754)
[2024-12-17 04:52:21,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:22,314][root][INFO] - Training Epoch: 2/2, step 1656/7134 completed (loss: 0.05598685145378113, acc: 0.9842342138290405)
[2024-12-17 04:52:22,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:22,818][root][INFO] - Training Epoch: 2/2, step 1657/7134 completed (loss: 0.03600968420505524, acc: 0.990867555141449)
[2024-12-17 04:52:22,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:23,302][root][INFO] - Training Epoch: 2/2, step 1658/7134 completed (loss: 0.022856686264276505, acc: 0.9959183931350708)
[2024-12-17 04:52:23,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:23,772][root][INFO] - Training Epoch: 2/2, step 1659/7134 completed (loss: 0.06410736590623856, acc: 0.9800947904586792)
[2024-12-17 04:52:23,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:24,261][root][INFO] - Training Epoch: 2/2, step 1660/7134 completed (loss: 0.040133461356163025, acc: 0.9915459156036377)
[2024-12-17 04:52:24,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:24,746][root][INFO] - Training Epoch: 2/2, step 1661/7134 completed (loss: 0.049567319452762604, acc: 0.9868708848953247)
[2024-12-17 04:52:24,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:25,218][root][INFO] - Training Epoch: 2/2, step 1662/7134 completed (loss: 0.05171708017587662, acc: 0.9872746467590332)
[2024-12-17 04:52:25,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:25,714][root][INFO] - Training Epoch: 2/2, step 1663/7134 completed (loss: 0.03734074905514717, acc: 0.990750253200531)
[2024-12-17 04:52:25,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:26,164][root][INFO] - Training Epoch: 2/2, step 1664/7134 completed (loss: 0.020263446494936943, acc: 0.9928486347198486)
[2024-12-17 04:52:26,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:26,640][root][INFO] - Training Epoch: 2/2, step 1665/7134 completed (loss: 0.04037228971719742, acc: 0.9884892106056213)
[2024-12-17 04:52:26,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:27,266][root][INFO] - Training Epoch: 2/2, step 1666/7134 completed (loss: 0.020985418930649757, acc: 0.9930139780044556)
[2024-12-17 04:52:27,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:27,773][root][INFO] - Training Epoch: 2/2, step 1667/7134 completed (loss: 0.043331045657396317, acc: 0.9857482314109802)
[2024-12-17 04:52:27,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:28,252][root][INFO] - Training Epoch: 2/2, step 1668/7134 completed (loss: 0.0321958102285862, acc: 0.9915966391563416)
[2024-12-17 04:52:28,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:28,782][root][INFO] - Training Epoch: 2/2, step 1669/7134 completed (loss: 0.02699388563632965, acc: 0.9887005686759949)
[2024-12-17 04:52:28,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:29,304][root][INFO] - Training Epoch: 2/2, step 1670/7134 completed (loss: 0.06236036866903305, acc: 0.9856870174407959)
[2024-12-17 04:52:29,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:29,789][root][INFO] - Training Epoch: 2/2, step 1671/7134 completed (loss: 0.06523488461971283, acc: 0.9856630563735962)
[2024-12-17 04:52:29,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:30,244][root][INFO] - Training Epoch: 2/2, step 1672/7134 completed (loss: 0.046629972755908966, acc: 0.9893758296966553)
[2024-12-17 04:52:30,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:30,713][root][INFO] - Training Epoch: 2/2, step 1673/7134 completed (loss: 0.0657341405749321, acc: 0.9852150678634644)
[2024-12-17 04:52:30,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:31,148][root][INFO] - Training Epoch: 2/2, step 1674/7134 completed (loss: 0.046076152473688126, acc: 0.9916201233863831)
[2024-12-17 04:52:31,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:31,608][root][INFO] - Training Epoch: 2/2, step 1675/7134 completed (loss: 0.09243196249008179, acc: 0.9782313108444214)
[2024-12-17 04:52:31,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:32,051][root][INFO] - Training Epoch: 2/2, step 1676/7134 completed (loss: 0.03921737149357796, acc: 0.9834254384040833)
[2024-12-17 04:52:32,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:32,508][root][INFO] - Training Epoch: 2/2, step 1677/7134 completed (loss: 0.0824582427740097, acc: 0.9770867228507996)
[2024-12-17 04:52:32,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:32,976][root][INFO] - Training Epoch: 2/2, step 1678/7134 completed (loss: 0.026307322084903717, acc: 0.9917808175086975)
[2024-12-17 04:52:33,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:33,427][root][INFO] - Training Epoch: 2/2, step 1679/7134 completed (loss: 0.06552242487668991, acc: 0.9795022010803223)
[2024-12-17 04:52:33,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:33,889][root][INFO] - Training Epoch: 2/2, step 1680/7134 completed (loss: 0.042365796864032745, acc: 0.9919571280479431)
[2024-12-17 04:52:34,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:34,328][root][INFO] - Training Epoch: 2/2, step 1681/7134 completed (loss: 0.041580334305763245, acc: 0.9914772510528564)
[2024-12-17 04:52:34,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:34,779][root][INFO] - Training Epoch: 2/2, step 1682/7134 completed (loss: 0.07843475043773651, acc: 0.9769452214241028)
[2024-12-17 04:52:34,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:35,217][root][INFO] - Training Epoch: 2/2, step 1683/7134 completed (loss: 0.044001538306474686, acc: 0.9902912378311157)
[2024-12-17 04:52:35,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:35,658][root][INFO] - Training Epoch: 2/2, step 1684/7134 completed (loss: 0.04332544282078743, acc: 0.982876718044281)
[2024-12-17 04:52:35,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:36,099][root][INFO] - Training Epoch: 2/2, step 1685/7134 completed (loss: 0.0779498815536499, acc: 0.9819193482398987)
[2024-12-17 04:52:36,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:36,531][root][INFO] - Training Epoch: 2/2, step 1686/7134 completed (loss: 0.04136024788022041, acc: 0.9864864945411682)
[2024-12-17 04:52:36,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:36,965][root][INFO] - Training Epoch: 2/2, step 1687/7134 completed (loss: 0.03199266642332077, acc: 0.9866920113563538)
[2024-12-17 04:52:37,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:37,380][root][INFO] - Training Epoch: 2/2, step 1688/7134 completed (loss: 0.06836292892694473, acc: 0.9860896468162537)
[2024-12-17 04:52:37,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:37,802][root][INFO] - Training Epoch: 2/2, step 1689/7134 completed (loss: 0.034310683608055115, acc: 0.9913420081138611)
[2024-12-17 04:52:37,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:38,245][root][INFO] - Training Epoch: 2/2, step 1690/7134 completed (loss: 0.020089145749807358, acc: 0.9959349632263184)
[2024-12-17 04:52:38,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:38,661][root][INFO] - Training Epoch: 2/2, step 1691/7134 completed (loss: 0.011926207691431046, acc: 0.996688723564148)
[2024-12-17 04:52:38,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:39,085][root][INFO] - Training Epoch: 2/2, step 1692/7134 completed (loss: 0.04478151351213455, acc: 0.9814502596855164)
[2024-12-17 04:52:39,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:39,539][root][INFO] - Training Epoch: 2/2, step 1693/7134 completed (loss: 0.03368241339921951, acc: 0.992514967918396)
[2024-12-17 04:52:39,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:39,973][root][INFO] - Training Epoch: 2/2, step 1694/7134 completed (loss: 0.03368530422449112, acc: 0.9874804615974426)
[2024-12-17 04:52:40,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:40,417][root][INFO] - Training Epoch: 2/2, step 1695/7134 completed (loss: 0.01075291819870472, acc: 0.9981982111930847)
[2024-12-17 04:52:40,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:40,823][root][INFO] - Training Epoch: 2/2, step 1696/7134 completed (loss: 0.05582481622695923, acc: 0.9832496047019958)
[2024-12-17 04:52:40,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:41,261][root][INFO] - Training Epoch: 2/2, step 1697/7134 completed (loss: 0.034985512495040894, acc: 0.9890453815460205)
[2024-12-17 04:52:41,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:41,699][root][INFO] - Training Epoch: 2/2, step 1698/7134 completed (loss: 0.023535728454589844, acc: 0.9921630024909973)
[2024-12-17 04:52:41,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:42,165][root][INFO] - Training Epoch: 2/2, step 1699/7134 completed (loss: 0.04176140949130058, acc: 0.9844290614128113)
[2024-12-17 04:52:42,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:42,639][root][INFO] - Training Epoch: 2/2, step 1700/7134 completed (loss: 0.04508763179183006, acc: 0.9838998317718506)
[2024-12-17 04:52:42,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:43,069][root][INFO] - Training Epoch: 2/2, step 1701/7134 completed (loss: 0.04173699766397476, acc: 0.9902642369270325)
[2024-12-17 04:52:43,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:43,508][root][INFO] - Training Epoch: 2/2, step 1702/7134 completed (loss: 0.05150600150227547, acc: 0.9813664555549622)
[2024-12-17 04:52:43,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:43,953][root][INFO] - Training Epoch: 2/2, step 1703/7134 completed (loss: 0.04999121278524399, acc: 0.9903314709663391)
[2024-12-17 04:52:44,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:44,396][root][INFO] - Training Epoch: 2/2, step 1704/7134 completed (loss: 0.09662122279405594, acc: 0.9741848111152649)
[2024-12-17 04:52:44,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:44,843][root][INFO] - Training Epoch: 2/2, step 1705/7134 completed (loss: 0.05524146184325218, acc: 0.9842209219932556)
[2024-12-17 04:52:44,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:45,193][root][INFO] - Training Epoch: 2/2, step 1706/7134 completed (loss: 0.05308777093887329, acc: 0.9848484992980957)
[2024-12-17 04:52:45,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:45,626][root][INFO] - Training Epoch: 2/2, step 1707/7134 completed (loss: 0.049270786345005035, acc: 0.9915433526039124)
[2024-12-17 04:52:45,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:46,063][root][INFO] - Training Epoch: 2/2, step 1708/7134 completed (loss: 0.05541349574923515, acc: 0.9853658676147461)
[2024-12-17 04:52:46,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:46,495][root][INFO] - Training Epoch: 2/2, step 1709/7134 completed (loss: 0.0677802711725235, acc: 0.9741379022598267)
[2024-12-17 04:52:46,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:46,957][root][INFO] - Training Epoch: 2/2, step 1710/7134 completed (loss: 0.044586166739463806, acc: 0.9885057210922241)
[2024-12-17 04:52:47,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:47,355][root][INFO] - Training Epoch: 2/2, step 1711/7134 completed (loss: 0.05415308102965355, acc: 0.9861830472946167)
[2024-12-17 04:52:47,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:47,754][root][INFO] - Training Epoch: 2/2, step 1712/7134 completed (loss: 0.08010474592447281, acc: 0.9754385948181152)
[2024-12-17 04:52:47,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:48,177][root][INFO] - Training Epoch: 2/2, step 1713/7134 completed (loss: 0.046979308128356934, acc: 0.9880239367485046)
[2024-12-17 04:52:48,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:48,615][root][INFO] - Training Epoch: 2/2, step 1714/7134 completed (loss: 0.074908547103405, acc: 0.9786184430122375)
[2024-12-17 04:52:48,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:49,054][root][INFO] - Training Epoch: 2/2, step 1715/7134 completed (loss: 0.03403228893876076, acc: 0.9837728142738342)
[2024-12-17 04:52:49,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:49,457][root][INFO] - Training Epoch: 2/2, step 1716/7134 completed (loss: 0.09116270393133163, acc: 0.9700000286102295)
[2024-12-17 04:52:49,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:49,874][root][INFO] - Training Epoch: 2/2, step 1717/7134 completed (loss: 0.029526174068450928, acc: 0.9922178983688354)
[2024-12-17 04:52:49,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:50,294][root][INFO] - Training Epoch: 2/2, step 1718/7134 completed (loss: 0.052687544375658035, acc: 0.9866369962692261)
[2024-12-17 04:52:50,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:50,743][root][INFO] - Training Epoch: 2/2, step 1719/7134 completed (loss: 0.07585185021162033, acc: 0.9863013625144958)
[2024-12-17 04:52:50,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:51,146][root][INFO] - Training Epoch: 2/2, step 1720/7134 completed (loss: 0.07383706420660019, acc: 0.9751552939414978)
[2024-12-17 04:52:51,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:51,513][root][INFO] - Training Epoch: 2/2, step 1721/7134 completed (loss: 0.032863814383745193, acc: 0.9881955981254578)
[2024-12-17 04:52:51,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:51,920][root][INFO] - Training Epoch: 2/2, step 1722/7134 completed (loss: 0.02676454372704029, acc: 0.9894737005233765)
[2024-12-17 04:52:52,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:52,337][root][INFO] - Training Epoch: 2/2, step 1723/7134 completed (loss: 0.09646980464458466, acc: 0.9731743931770325)
[2024-12-17 04:52:52,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:52,769][root][INFO] - Training Epoch: 2/2, step 1724/7134 completed (loss: 0.08091891556978226, acc: 0.9733123779296875)
[2024-12-17 04:52:52,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:53,152][root][INFO] - Training Epoch: 2/2, step 1725/7134 completed (loss: 0.022780807688832283, acc: 0.9935691356658936)
[2024-12-17 04:52:53,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:53,548][root][INFO] - Training Epoch: 2/2, step 1726/7134 completed (loss: 0.04447092488408089, acc: 0.9843049049377441)
[2024-12-17 04:52:53,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:53,985][root][INFO] - Training Epoch: 2/2, step 1727/7134 completed (loss: 0.04414496198296547, acc: 0.9927007555961609)
[2024-12-17 04:52:54,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:54,431][root][INFO] - Training Epoch: 2/2, step 1728/7134 completed (loss: 0.046085964888334274, acc: 0.9900662302970886)
[2024-12-17 04:52:54,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:54,846][root][INFO] - Training Epoch: 2/2, step 1729/7134 completed (loss: 0.07939833402633667, acc: 0.9796333909034729)
[2024-12-17 04:52:54,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:55,286][root][INFO] - Training Epoch: 2/2, step 1730/7134 completed (loss: 0.02523445338010788, acc: 0.9914346933364868)
[2024-12-17 04:52:55,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:55,658][root][INFO] - Training Epoch: 2/2, step 1731/7134 completed (loss: 0.0793021023273468, acc: 0.9884393215179443)
[2024-12-17 04:52:55,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:56,062][root][INFO] - Training Epoch: 2/2, step 1732/7134 completed (loss: 0.05327001214027405, acc: 0.9815195202827454)
[2024-12-17 04:52:56,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:56,493][root][INFO] - Training Epoch: 2/2, step 1733/7134 completed (loss: 0.05453716591000557, acc: 0.9855967164039612)
[2024-12-17 04:52:56,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:56,970][root][INFO] - Training Epoch: 2/2, step 1734/7134 completed (loss: 0.06398379802703857, acc: 0.9815725088119507)
[2024-12-17 04:52:57,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:57,416][root][INFO] - Training Epoch: 2/2, step 1735/7134 completed (loss: 0.029493529349565506, acc: 0.991584837436676)
[2024-12-17 04:52:57,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:57,884][root][INFO] - Training Epoch: 2/2, step 1736/7134 completed (loss: 0.0537148080766201, acc: 0.9830303192138672)
[2024-12-17 04:52:57,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:58,334][root][INFO] - Training Epoch: 2/2, step 1737/7134 completed (loss: 0.04238435626029968, acc: 0.9915730357170105)
[2024-12-17 04:52:58,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:58,789][root][INFO] - Training Epoch: 2/2, step 1738/7134 completed (loss: 0.02598731406033039, acc: 0.993968665599823)
[2024-12-17 04:52:58,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:59,249][root][INFO] - Training Epoch: 2/2, step 1739/7134 completed (loss: 0.04009197652339935, acc: 0.9865269660949707)
[2024-12-17 04:52:59,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:52:59,712][root][INFO] - Training Epoch: 2/2, step 1740/7134 completed (loss: 0.009787912480533123, acc: 0.9970760345458984)
[2024-12-17 04:52:59,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:00,190][root][INFO] - Training Epoch: 2/2, step 1741/7134 completed (loss: 0.04224727302789688, acc: 0.988095223903656)
[2024-12-17 04:53:00,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:00,627][root][INFO] - Training Epoch: 2/2, step 1742/7134 completed (loss: 0.05872485786676407, acc: 0.9858155846595764)
[2024-12-17 04:53:00,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:01,084][root][INFO] - Training Epoch: 2/2, step 1743/7134 completed (loss: 0.06205950304865837, acc: 0.981792688369751)
[2024-12-17 04:53:01,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:01,526][root][INFO] - Training Epoch: 2/2, step 1744/7134 completed (loss: 0.03809252381324768, acc: 0.9918566942214966)
[2024-12-17 04:53:01,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:01,977][root][INFO] - Training Epoch: 2/2, step 1745/7134 completed (loss: 0.03246463090181351, acc: 0.9887217879295349)
[2024-12-17 04:53:02,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:02,430][root][INFO] - Training Epoch: 2/2, step 1746/7134 completed (loss: 0.017976898699998856, acc: 0.9941860437393188)
[2024-12-17 04:53:02,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:02,901][root][INFO] - Training Epoch: 2/2, step 1747/7134 completed (loss: 0.035718124359846115, acc: 0.9899874925613403)
[2024-12-17 04:53:02,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:03,364][root][INFO] - Training Epoch: 2/2, step 1748/7134 completed (loss: 0.03707252815365791, acc: 0.9838709831237793)
[2024-12-17 04:53:03,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:03,835][root][INFO] - Training Epoch: 2/2, step 1749/7134 completed (loss: 0.039841581135988235, acc: 0.9909194111824036)
[2024-12-17 04:53:03,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:04,303][root][INFO] - Training Epoch: 2/2, step 1750/7134 completed (loss: 0.03209817409515381, acc: 0.9940047860145569)
[2024-12-17 04:53:04,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:04,757][root][INFO] - Training Epoch: 2/2, step 1751/7134 completed (loss: 0.0406520776450634, acc: 0.9890909194946289)
[2024-12-17 04:53:04,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:05,208][root][INFO] - Training Epoch: 2/2, step 1752/7134 completed (loss: 0.06690464168787003, acc: 0.9845361113548279)
[2024-12-17 04:53:05,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:05,661][root][INFO] - Training Epoch: 2/2, step 1753/7134 completed (loss: 0.046349719166755676, acc: 0.9869961142539978)
[2024-12-17 04:53:05,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:06,096][root][INFO] - Training Epoch: 2/2, step 1754/7134 completed (loss: 0.045952025800943375, acc: 0.9870316982269287)
[2024-12-17 04:53:06,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:06,533][root][INFO] - Training Epoch: 2/2, step 1755/7134 completed (loss: 0.01601075567305088, acc: 0.9933862686157227)
[2024-12-17 04:53:06,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:06,980][root][INFO] - Training Epoch: 2/2, step 1756/7134 completed (loss: 0.04784420505166054, acc: 0.9869961142539978)
[2024-12-17 04:53:07,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:07,400][root][INFO] - Training Epoch: 2/2, step 1757/7134 completed (loss: 0.05484984442591667, acc: 0.9866888523101807)
[2024-12-17 04:53:07,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:07,875][root][INFO] - Training Epoch: 2/2, step 1758/7134 completed (loss: 0.01664653606712818, acc: 0.9949495196342468)
[2024-12-17 04:53:07,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:08,316][root][INFO] - Training Epoch: 2/2, step 1759/7134 completed (loss: 0.03945626690983772, acc: 0.9902642369270325)
[2024-12-17 04:53:08,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:08,736][root][INFO] - Training Epoch: 2/2, step 1760/7134 completed (loss: 0.038735419511795044, acc: 0.9865546226501465)
[2024-12-17 04:53:08,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:09,131][root][INFO] - Training Epoch: 2/2, step 1761/7134 completed (loss: 0.028331907466053963, acc: 0.9914772510528564)
[2024-12-17 04:53:09,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:09,553][root][INFO] - Training Epoch: 2/2, step 1762/7134 completed (loss: 0.01302361860871315, acc: 0.9979381561279297)
[2024-12-17 04:53:09,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:09,966][root][INFO] - Training Epoch: 2/2, step 1763/7134 completed (loss: 0.06438863277435303, acc: 0.9871794581413269)
[2024-12-17 04:53:10,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:10,384][root][INFO] - Training Epoch: 2/2, step 1764/7134 completed (loss: 0.026906555518507957, acc: 0.9907063245773315)
[2024-12-17 04:53:10,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:10,822][root][INFO] - Training Epoch: 2/2, step 1765/7134 completed (loss: 0.025076692923903465, acc: 0.9938271641731262)
[2024-12-17 04:53:10,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:11,240][root][INFO] - Training Epoch: 2/2, step 1766/7134 completed (loss: 0.019238922744989395, acc: 0.9941349029541016)
[2024-12-17 04:53:11,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:11,676][root][INFO] - Training Epoch: 2/2, step 1767/7134 completed (loss: 0.07640960067510605, acc: 0.9773691892623901)
[2024-12-17 04:53:11,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:12,115][root][INFO] - Training Epoch: 2/2, step 1768/7134 completed (loss: 0.031147198751568794, acc: 0.9903661012649536)
[2024-12-17 04:53:12,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:12,563][root][INFO] - Training Epoch: 2/2, step 1769/7134 completed (loss: 0.022354235872626305, acc: 0.9941176176071167)
[2024-12-17 04:53:12,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:12,992][root][INFO] - Training Epoch: 2/2, step 1770/7134 completed (loss: 0.032357968389987946, acc: 0.987860381603241)
[2024-12-17 04:53:13,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:13,422][root][INFO] - Training Epoch: 2/2, step 1771/7134 completed (loss: 0.01824672892689705, acc: 0.994413435459137)
[2024-12-17 04:53:13,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:13,821][root][INFO] - Training Epoch: 2/2, step 1772/7134 completed (loss: 0.03770606219768524, acc: 0.9916247725486755)
[2024-12-17 04:53:13,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:14,261][root][INFO] - Training Epoch: 2/2, step 1773/7134 completed (loss: 0.026620520278811455, acc: 0.9912790656089783)
[2024-12-17 04:53:14,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:14,662][root][INFO] - Training Epoch: 2/2, step 1774/7134 completed (loss: 0.023737626150250435, acc: 0.9933554530143738)
[2024-12-17 04:53:14,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:15,080][root][INFO] - Training Epoch: 2/2, step 1775/7134 completed (loss: 0.011937106028199196, acc: 0.9984375238418579)
[2024-12-17 04:53:15,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:15,492][root][INFO] - Training Epoch: 2/2, step 1776/7134 completed (loss: 0.032469771802425385, acc: 0.9910179376602173)
[2024-12-17 04:53:15,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:15,910][root][INFO] - Training Epoch: 2/2, step 1777/7134 completed (loss: 0.008651761338114738, acc: 0.9970414042472839)
[2024-12-17 04:53:16,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:16,342][root][INFO] - Training Epoch: 2/2, step 1778/7134 completed (loss: 0.05210483819246292, acc: 0.9896449446678162)
[2024-12-17 04:53:16,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:16,752][root][INFO] - Training Epoch: 2/2, step 1779/7134 completed (loss: 0.028543392196297646, acc: 0.9898989796638489)
[2024-12-17 04:53:16,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:17,237][root][INFO] - Training Epoch: 2/2, step 1780/7134 completed (loss: 0.02993810921907425, acc: 0.9957567453384399)
[2024-12-17 04:53:18,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:18,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:18,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:19,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:19,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:19,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:20,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:20,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:20,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:21,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:21,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:22,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:22,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:22,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:23,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:23,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:23,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:24,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:24,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:25,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:25,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:25,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:26,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:26,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:26,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:27,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:27,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:28,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:28,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:28,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:29,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:29,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:30,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:30,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:30,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:31,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:31,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:31,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:32,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:32,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:32,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:33,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:33,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:33,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:34,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:34,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:35,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:35,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:36,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:36,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:36,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:37,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:37,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:37,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:38,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:38,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:38,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:39,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:39,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:39,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:40,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:40,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:41,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:41,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:41,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:42,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:42,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:42,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:43,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:43,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:44,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:44,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:44,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:45,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:45,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:45,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:46,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:46,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:47,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:47,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:47,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:48,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:48,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:48,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:49,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:49,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:50,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:50,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:50,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:51,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:51,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:51,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:52,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:52,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:52,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:53,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:53,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:54,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:54,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:54,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:55,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:55,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:56,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:56,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:56,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:57,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:57,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:57,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:58,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:58,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:58,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:59,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:59,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:53:59,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:00,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:00,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:00,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:01,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:01,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:02,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:02,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:02,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:03,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:03,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:03,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:04,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:04,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:04,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:05,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:05,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:05,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:06,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:06,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:07,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:07,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:07,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:08,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:08,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:08,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:09,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:09,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:09,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:10,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:10,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:10,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:11,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:11,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:12,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:12,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:12,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:13,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:13,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:14,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:14,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:14,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:15,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:15,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:15,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:16,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:16,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:17,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:17,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:17,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:18,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:18,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:18,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:19,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:19,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:20,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:20,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:20,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:21,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:21,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:21,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:22,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:22,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:23,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:23,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:23,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:24,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:24,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:24,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:25,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:25,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:25,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:26,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:26,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:27,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:27,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:27,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:28,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:28,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:29,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:29,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:29,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:30,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:30,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:31,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:31,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:31,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:31,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:32,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:32,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:32,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:33,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:33,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:34,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:34,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:34,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:35,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:35,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:36,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:36,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:36,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:37,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:37,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:38,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:38,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:38,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:39,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:39,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:39,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:40,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:40,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:40,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:41,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:41,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:41,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:42,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:42,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:43,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:43,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:43,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:44,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:44,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:44,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:45,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:45,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:45,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:46,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:46,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:47,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:47,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:47,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:48,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:48,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:49,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:49,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:50,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:50,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:50,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:51,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:51,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:52,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:52,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:53,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:53,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:54,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:54,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:54,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:55,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:55,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:55,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:56,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:56,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:56,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:57,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:57,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:57,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:58,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:58,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:59,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:59,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:54:59,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:00,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:00,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:01,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:01,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:01,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:02,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:02,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:03,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:03,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:03,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:04,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:04,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:05,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:05,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:05,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:06,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:06,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:07,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:07,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:07,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:08,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:08,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:09,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:09,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:10,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:10,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:10,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:11,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:11,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:11,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:12,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:12,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:12,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:13,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:13,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:14,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:14,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:14,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:14,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:15,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:15,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:16,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:16,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:16,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:17,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:17,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:18,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:18,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:18,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:19,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:19,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:19,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:20,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:20,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:21,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:21,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:21,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:22,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:22,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:23,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:23,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:23,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:24,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:24,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:24,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:25,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:25,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:26,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:26,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:27,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:27,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:28,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:28,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:29,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:29,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:29,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:30,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:30,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:30,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:31,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:31,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:31,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:32,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:32,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:33,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:33,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:33,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:34,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:34,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:35,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:36,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:36,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:37,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:37,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:37,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:38,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:38,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:39,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:39,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:39,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:40,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:40,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:40,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:41,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:41,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:42,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:42,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:42,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:43,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:43,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:43,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:44,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:44,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:44,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:45,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:45,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:45,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:46,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:46,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:46,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:47,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:47,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:48,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:48,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:48,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:49,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:49,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:50,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:50,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:50,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:51,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:51,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:51,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:52,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:52,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:52,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:53,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:53,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:54,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:54,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:54,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:55,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:55,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:56,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:56,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:56,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:57,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:57,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:58,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:58,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:58,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:59,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:59,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:55:59,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:00,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:00,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:00,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:01,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:01,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:02,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:02,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:02,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:03,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:03,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:03,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:04,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:04,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:05,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:05,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:05,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:06,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:06,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:07,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:07,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:07,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:08,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:08,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:08,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:09,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:09,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:09,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:10,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:10,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:11,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:11,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:11,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:12,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:12,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:12,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:13,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:13,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:14,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:14,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:14,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:15,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:15,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:16,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:16,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:16,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:17,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:17,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:18,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:18,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:18,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:19,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:19,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:20,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:20,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:20,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:21,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:21,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:21,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:22,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:22,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:22,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:23,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:23,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:23,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:24,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:24,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:25,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:25,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:26,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:26,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:26,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:27,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:27,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:27,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:28,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:28,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:29,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:29,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:29,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:30,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:30,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:30,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:31,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:31,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:32,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:32,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:32,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:33,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:33,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:33,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:34,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:34,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:34,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:35,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:35,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:36,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:36,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:36,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:37,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:37,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:38,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:38,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:38,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:39,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:39,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:39,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:40,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:40,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:41,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:41,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:41,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:42,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:42,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:43,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:43,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:43,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:44,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:44,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:44,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:45,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:45,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:46,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:46,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:46,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:47,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:47,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:47,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:48,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:48,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:48,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:49,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:49,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:50,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:50,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:50,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:51,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:51,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:52,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:52,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:52,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:53,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:53,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:54,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:54,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:54,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:55,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:55,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:55,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:56,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:56,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:56,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:57,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:57,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:58,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:58,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:58,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:59,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:56:59,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:00,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:00,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:00,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:01,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:01,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:01,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:02,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:02,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:02,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:03,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:03,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:03,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:04,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:04,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:04,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:05,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:05,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:06,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:06,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:06,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:07,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:07,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:08,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:08,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:08,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:09,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:09,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:10,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:10,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:10,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:11,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:11,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:11,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:12,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:12,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:12,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:13,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:13,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:14,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:14,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:15,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:16,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:16,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:17,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:17,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:18,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:18,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:19,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:19,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:20,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:20,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:20,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:21,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:21,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:21,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:21,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:22,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:22,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:22,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:23,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:23,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:24,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:24,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:25,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:25,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:25,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:26,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:26,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:27,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:27,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:27,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:28,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:28,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:28,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:29,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:29,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:29,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:30,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:30,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:30,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:31,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:31,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:32,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:32,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:32,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:33,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:33,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:34,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:34,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:35,053][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.0577, device='cuda:0') eval_epoch_loss=tensor(0.0561, device='cuda:0') eval_epoch_acc=tensor(0.9848, device='cuda:0')
[2024-12-17 04:57:35,055][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-17 04:57:35,056][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 04:57:35,314][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_2_step_1781_loss_0.056080978363752365/model.pt
[2024-12-17 04:57:35,320][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-12-17 04:57:35,320][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 0.056080978363752365
[2024-12-17 04:57:35,321][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.9847776293754578
[2024-12-17 04:57:35,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:35,773][root][INFO] - Training Epoch: 2/2, step 1781/7134 completed (loss: 0.013108398765325546, acc: 0.9954198598861694)
[2024-12-17 04:57:35,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:36,179][root][INFO] - Training Epoch: 2/2, step 1782/7134 completed (loss: 0.012478642165660858, acc: 0.9954338073730469)
[2024-12-17 04:57:36,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:36,622][root][INFO] - Training Epoch: 2/2, step 1783/7134 completed (loss: 0.03649499639868736, acc: 0.9905405640602112)
[2024-12-17 04:57:36,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:37,071][root][INFO] - Training Epoch: 2/2, step 1784/7134 completed (loss: 0.01965967006981373, acc: 0.9912023544311523)
[2024-12-17 04:57:37,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:37,559][root][INFO] - Training Epoch: 2/2, step 1785/7134 completed (loss: 0.03711172565817833, acc: 0.9889958500862122)
[2024-12-17 04:57:37,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:37,980][root][INFO] - Training Epoch: 2/2, step 1786/7134 completed (loss: 0.035683076828718185, acc: 0.9921996593475342)
[2024-12-17 04:57:38,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:38,409][root][INFO] - Training Epoch: 2/2, step 1787/7134 completed (loss: 0.02621459774672985, acc: 0.9946428537368774)
[2024-12-17 04:57:38,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:38,809][root][INFO] - Training Epoch: 2/2, step 1788/7134 completed (loss: 0.03787613660097122, acc: 0.9901800155639648)
[2024-12-17 04:57:38,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:39,231][root][INFO] - Training Epoch: 2/2, step 1789/7134 completed (loss: 0.017621003091335297, acc: 0.9938555955886841)
[2024-12-17 04:57:39,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:39,664][root][INFO] - Training Epoch: 2/2, step 1790/7134 completed (loss: 0.10562890768051147, acc: 0.9838969111442566)
[2024-12-17 04:57:39,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:40,076][root][INFO] - Training Epoch: 2/2, step 1791/7134 completed (loss: 0.1004282757639885, acc: 0.9786019921302795)
[2024-12-17 04:57:40,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:40,524][root][INFO] - Training Epoch: 2/2, step 1792/7134 completed (loss: 0.1561139076948166, acc: 0.9674796462059021)
[2024-12-17 04:57:40,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:40,978][root][INFO] - Training Epoch: 2/2, step 1793/7134 completed (loss: 0.10987205803394318, acc: 0.9783783555030823)
[2024-12-17 04:57:41,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:41,435][root][INFO] - Training Epoch: 2/2, step 1794/7134 completed (loss: 0.08595917373895645, acc: 0.9827044010162354)
[2024-12-17 04:57:41,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:41,854][root][INFO] - Training Epoch: 2/2, step 1795/7134 completed (loss: 0.1442677527666092, acc: 0.966312050819397)
[2024-12-17 04:57:41,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:42,280][root][INFO] - Training Epoch: 2/2, step 1796/7134 completed (loss: 0.1111583411693573, acc: 0.9717868566513062)
[2024-12-17 04:57:42,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:42,715][root][INFO] - Training Epoch: 2/2, step 1797/7134 completed (loss: 0.06480538845062256, acc: 0.9831932783126831)
[2024-12-17 04:57:42,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:43,160][root][INFO] - Training Epoch: 2/2, step 1798/7134 completed (loss: 0.06696773320436478, acc: 0.9749034643173218)
[2024-12-17 04:57:43,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:43,617][root][INFO] - Training Epoch: 2/2, step 1799/7134 completed (loss: 0.08378931134939194, acc: 0.9786432385444641)
[2024-12-17 04:57:43,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:44,083][root][INFO] - Training Epoch: 2/2, step 1800/7134 completed (loss: 0.10359404981136322, acc: 0.9731308221817017)
[2024-12-17 04:57:44,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:44,543][root][INFO] - Training Epoch: 2/2, step 1801/7134 completed (loss: 0.07844136655330658, acc: 0.9809321761131287)
[2024-12-17 04:57:44,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:45,014][root][INFO] - Training Epoch: 2/2, step 1802/7134 completed (loss: 0.07862018048763275, acc: 0.9837296605110168)
[2024-12-17 04:57:45,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:45,448][root][INFO] - Training Epoch: 2/2, step 1803/7134 completed (loss: 0.05684123560786247, acc: 0.9830508232116699)
[2024-12-17 04:57:45,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:45,903][root][INFO] - Training Epoch: 2/2, step 1804/7134 completed (loss: 0.04456525668501854, acc: 0.9840294718742371)
[2024-12-17 04:57:46,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:46,315][root][INFO] - Training Epoch: 2/2, step 1805/7134 completed (loss: 0.0784943550825119, acc: 0.9769119620323181)
[2024-12-17 04:57:46,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:46,719][root][INFO] - Training Epoch: 2/2, step 1806/7134 completed (loss: 0.04369698092341423, acc: 0.9868420958518982)
[2024-12-17 04:57:46,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:47,130][root][INFO] - Training Epoch: 2/2, step 1807/7134 completed (loss: 0.061451151967048645, acc: 0.9816124439239502)
[2024-12-17 04:57:47,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:47,545][root][INFO] - Training Epoch: 2/2, step 1808/7134 completed (loss: 0.033766742795705795, acc: 0.9895969033241272)
[2024-12-17 04:57:47,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:47,994][root][INFO] - Training Epoch: 2/2, step 1809/7134 completed (loss: 0.029305903241038322, acc: 0.9918919205665588)
[2024-12-17 04:57:48,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:48,475][root][INFO] - Training Epoch: 2/2, step 1810/7134 completed (loss: 0.017948752269148827, acc: 0.9961340427398682)
[2024-12-17 04:57:48,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:48,901][root][INFO] - Training Epoch: 2/2, step 1811/7134 completed (loss: 0.0677255243062973, acc: 0.9837177991867065)
[2024-12-17 04:57:49,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:49,357][root][INFO] - Training Epoch: 2/2, step 1812/7134 completed (loss: 0.034407470375299454, acc: 0.9897959232330322)
[2024-12-17 04:57:49,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:49,808][root][INFO] - Training Epoch: 2/2, step 1813/7134 completed (loss: 0.07055921107530594, acc: 0.9796407222747803)
[2024-12-17 04:57:49,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:50,273][root][INFO] - Training Epoch: 2/2, step 1814/7134 completed (loss: 0.02353738434612751, acc: 0.9930070042610168)
[2024-12-17 04:57:50,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:50,710][root][INFO] - Training Epoch: 2/2, step 1815/7134 completed (loss: 0.040322303771972656, acc: 0.9870689511299133)
[2024-12-17 04:57:50,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:51,129][root][INFO] - Training Epoch: 2/2, step 1816/7134 completed (loss: 0.05252920091152191, acc: 0.9827855825424194)
[2024-12-17 04:57:51,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:51,575][root][INFO] - Training Epoch: 2/2, step 1817/7134 completed (loss: 0.04107455536723137, acc: 0.9904534816741943)
[2024-12-17 04:57:51,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:52,040][root][INFO] - Training Epoch: 2/2, step 1818/7134 completed (loss: 0.0646943524479866, acc: 0.9851301312446594)
[2024-12-17 04:57:52,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:52,491][root][INFO] - Training Epoch: 2/2, step 1819/7134 completed (loss: 0.023272238671779633, acc: 0.9912717938423157)
[2024-12-17 04:57:52,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:53,014][root][INFO] - Training Epoch: 2/2, step 1820/7134 completed (loss: 0.02585378848016262, acc: 0.9923580884933472)
[2024-12-17 04:57:53,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:53,449][root][INFO] - Training Epoch: 2/2, step 1821/7134 completed (loss: 0.03194036707282066, acc: 0.9901531934738159)
[2024-12-17 04:57:53,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:53,889][root][INFO] - Training Epoch: 2/2, step 1822/7134 completed (loss: 0.013075421564280987, acc: 0.9926900863647461)
[2024-12-17 04:57:53,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:54,333][root][INFO] - Training Epoch: 2/2, step 1823/7134 completed (loss: 0.027657441794872284, acc: 0.9904502034187317)
[2024-12-17 04:57:54,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:54,806][root][INFO] - Training Epoch: 2/2, step 1824/7134 completed (loss: 0.027835439890623093, acc: 0.9913473129272461)
[2024-12-17 04:57:54,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:55,263][root][INFO] - Training Epoch: 2/2, step 1825/7134 completed (loss: 0.02111678011715412, acc: 0.9932735562324524)
[2024-12-17 04:57:55,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:55,711][root][INFO] - Training Epoch: 2/2, step 1826/7134 completed (loss: 0.020468205213546753, acc: 0.9919246435165405)
[2024-12-17 04:57:55,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:56,161][root][INFO] - Training Epoch: 2/2, step 1827/7134 completed (loss: 0.052422620356082916, acc: 0.9889746308326721)
[2024-12-17 04:57:56,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:56,602][root][INFO] - Training Epoch: 2/2, step 1828/7134 completed (loss: 0.004088766407221556, acc: 1.0)
[2024-12-17 04:57:56,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:57,051][root][INFO] - Training Epoch: 2/2, step 1829/7134 completed (loss: 0.03123471327126026, acc: 0.9900621175765991)
[2024-12-17 04:57:57,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:57,511][root][INFO] - Training Epoch: 2/2, step 1830/7134 completed (loss: 0.03300468251109123, acc: 0.9927361011505127)
[2024-12-17 04:57:57,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:57,938][root][INFO] - Training Epoch: 2/2, step 1831/7134 completed (loss: 0.013791300356388092, acc: 0.9937499761581421)
[2024-12-17 04:57:58,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:58,350][root][INFO] - Training Epoch: 2/2, step 1832/7134 completed (loss: 0.07693148404359818, acc: 0.9858657121658325)
[2024-12-17 04:57:58,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:58,789][root][INFO] - Training Epoch: 2/2, step 1833/7134 completed (loss: 0.1889229565858841, acc: 0.9598308801651001)
[2024-12-17 04:57:58,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:59,235][root][INFO] - Training Epoch: 2/2, step 1834/7134 completed (loss: 0.05075894296169281, acc: 0.983098566532135)
[2024-12-17 04:57:59,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:57:59,660][root][INFO] - Training Epoch: 2/2, step 1835/7134 completed (loss: 0.06603556871414185, acc: 0.9854651093482971)
[2024-12-17 04:57:59,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:00,104][root][INFO] - Training Epoch: 2/2, step 1836/7134 completed (loss: 0.05329068377614021, acc: 0.9834515452384949)
[2024-12-17 04:58:00,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:00,540][root][INFO] - Training Epoch: 2/2, step 1837/7134 completed (loss: 0.03283834457397461, acc: 0.9901719689369202)
[2024-12-17 04:58:00,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:00,913][root][INFO] - Training Epoch: 2/2, step 1838/7134 completed (loss: 0.012607822194695473, acc: 0.9938775300979614)
[2024-12-17 04:58:01,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:01,380][root][INFO] - Training Epoch: 2/2, step 1839/7134 completed (loss: 0.031979721039533615, acc: 0.9896373152732849)
[2024-12-17 04:58:01,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:01,830][root][INFO] - Training Epoch: 2/2, step 1840/7134 completed (loss: 0.04136376827955246, acc: 0.9888424277305603)
[2024-12-17 04:58:01,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:02,242][root][INFO] - Training Epoch: 2/2, step 1841/7134 completed (loss: 0.03023294359445572, acc: 0.9872340559959412)
[2024-12-17 04:58:02,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:02,713][root][INFO] - Training Epoch: 2/2, step 1842/7134 completed (loss: 0.0413501039147377, acc: 0.9931972622871399)
[2024-12-17 04:58:02,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:03,130][root][INFO] - Training Epoch: 2/2, step 1843/7134 completed (loss: 0.0562785342335701, acc: 0.9862499833106995)
[2024-12-17 04:58:03,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:03,581][root][INFO] - Training Epoch: 2/2, step 1844/7134 completed (loss: 0.03779829293489456, acc: 0.9934959411621094)
[2024-12-17 04:58:03,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:04,053][root][INFO] - Training Epoch: 2/2, step 1845/7134 completed (loss: 0.056372690945863724, acc: 0.9874739050865173)
[2024-12-17 04:58:04,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:04,510][root][INFO] - Training Epoch: 2/2, step 1846/7134 completed (loss: 0.02823852002620697, acc: 0.9914529919624329)
[2024-12-17 04:58:04,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:04,984][root][INFO] - Training Epoch: 2/2, step 1847/7134 completed (loss: 0.026935270056128502, acc: 0.9892473220825195)
[2024-12-17 04:58:05,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:05,432][root][INFO] - Training Epoch: 2/2, step 1848/7134 completed (loss: 0.04831581190228462, acc: 0.9858757257461548)
[2024-12-17 04:58:05,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:05,874][root][INFO] - Training Epoch: 2/2, step 1849/7134 completed (loss: 0.06142262741923332, acc: 0.982425332069397)
[2024-12-17 04:58:05,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:06,341][root][INFO] - Training Epoch: 2/2, step 1850/7134 completed (loss: 0.025111479684710503, acc: 0.9902200698852539)
[2024-12-17 04:58:06,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:06,797][root][INFO] - Training Epoch: 2/2, step 1851/7134 completed (loss: 0.04995930567383766, acc: 0.9853479862213135)
[2024-12-17 04:58:06,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:07,227][root][INFO] - Training Epoch: 2/2, step 1852/7134 completed (loss: 0.04053375497460365, acc: 0.9844720363616943)
[2024-12-17 04:58:07,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:07,665][root][INFO] - Training Epoch: 2/2, step 1853/7134 completed (loss: 0.04098677635192871, acc: 0.9928229451179504)
[2024-12-17 04:58:07,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:08,111][root][INFO] - Training Epoch: 2/2, step 1854/7134 completed (loss: 0.05935921147465706, acc: 0.9797859787940979)
[2024-12-17 04:58:08,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:08,559][root][INFO] - Training Epoch: 2/2, step 1855/7134 completed (loss: 0.05452532321214676, acc: 0.9872832298278809)
[2024-12-17 04:58:08,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:08,978][root][INFO] - Training Epoch: 2/2, step 1856/7134 completed (loss: 0.042546000331640244, acc: 0.9889298677444458)
[2024-12-17 04:58:09,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:09,447][root][INFO] - Training Epoch: 2/2, step 1857/7134 completed (loss: 0.06468942761421204, acc: 0.9876847267150879)
[2024-12-17 04:58:09,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:09,902][root][INFO] - Training Epoch: 2/2, step 1858/7134 completed (loss: 0.02613459900021553, acc: 0.9904305934906006)
[2024-12-17 04:58:10,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:10,363][root][INFO] - Training Epoch: 2/2, step 1859/7134 completed (loss: 0.015559296123683453, acc: 0.9965870380401611)
[2024-12-17 04:58:10,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:10,814][root][INFO] - Training Epoch: 2/2, step 1860/7134 completed (loss: 0.01842755265533924, acc: 0.9949367046356201)
[2024-12-17 04:58:10,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:11,248][root][INFO] - Training Epoch: 2/2, step 1861/7134 completed (loss: 0.053282175213098526, acc: 0.9896640777587891)
[2024-12-17 04:58:11,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:11,683][root][INFO] - Training Epoch: 2/2, step 1862/7134 completed (loss: 0.020805923268198967, acc: 0.9945725798606873)
[2024-12-17 04:58:11,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:12,137][root][INFO] - Training Epoch: 2/2, step 1863/7134 completed (loss: 0.030237097293138504, acc: 0.9928057789802551)
[2024-12-17 04:58:12,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:12,573][root][INFO] - Training Epoch: 2/2, step 1864/7134 completed (loss: 0.14947032928466797, acc: 0.9646258354187012)
[2024-12-17 04:58:12,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:12,982][root][INFO] - Training Epoch: 2/2, step 1865/7134 completed (loss: 0.04386299476027489, acc: 0.9864636063575745)
[2024-12-17 04:58:13,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:13,413][root][INFO] - Training Epoch: 2/2, step 1866/7134 completed (loss: 0.01509236078709364, acc: 0.994397759437561)
[2024-12-17 04:58:13,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:13,875][root][INFO] - Training Epoch: 2/2, step 1867/7134 completed (loss: 0.01982215605676174, acc: 0.9911727905273438)
[2024-12-17 04:58:13,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:14,331][root][INFO] - Training Epoch: 2/2, step 1868/7134 completed (loss: 0.08131805807352066, acc: 0.9834983348846436)
[2024-12-17 04:58:14,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:14,761][root][INFO] - Training Epoch: 2/2, step 1869/7134 completed (loss: 0.05390503257513046, acc: 0.9869494438171387)
[2024-12-17 04:58:14,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:15,183][root][INFO] - Training Epoch: 2/2, step 1870/7134 completed (loss: 0.027995305135846138, acc: 0.99609375)
[2024-12-17 04:58:15,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:15,633][root][INFO] - Training Epoch: 2/2, step 1871/7134 completed (loss: 0.09133077412843704, acc: 0.980424165725708)
[2024-12-17 04:58:15,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:16,041][root][INFO] - Training Epoch: 2/2, step 1872/7134 completed (loss: 0.5287588834762573, acc: 0.9060773253440857)
[2024-12-17 04:58:16,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:16,484][root][INFO] - Training Epoch: 2/2, step 1873/7134 completed (loss: 0.18045230209827423, acc: 0.9524940848350525)
[2024-12-17 04:58:16,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:16,947][root][INFO] - Training Epoch: 2/2, step 1874/7134 completed (loss: 0.061013009399175644, acc: 0.9882044792175293)
[2024-12-17 04:58:17,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:17,376][root][INFO] - Training Epoch: 2/2, step 1875/7134 completed (loss: 0.03825697675347328, acc: 0.9847161769866943)
[2024-12-17 04:58:17,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:17,793][root][INFO] - Training Epoch: 2/2, step 1876/7134 completed (loss: 0.19927991926670074, acc: 0.9473684430122375)
[2024-12-17 04:58:17,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:18,261][root][INFO] - Training Epoch: 2/2, step 1877/7134 completed (loss: 0.06174810975790024, acc: 0.986146092414856)
[2024-12-17 04:58:18,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:18,708][root][INFO] - Training Epoch: 2/2, step 1878/7134 completed (loss: 0.08471427857875824, acc: 0.9768875241279602)
[2024-12-17 04:58:18,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:19,121][root][INFO] - Training Epoch: 2/2, step 1879/7134 completed (loss: 0.08565640449523926, acc: 0.980424165725708)
[2024-12-17 04:58:19,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:19,518][root][INFO] - Training Epoch: 2/2, step 1880/7134 completed (loss: 0.0837995782494545, acc: 0.9839034080505371)
[2024-12-17 04:58:19,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:19,952][root][INFO] - Training Epoch: 2/2, step 1881/7134 completed (loss: 0.08274433016777039, acc: 0.9754902124404907)
[2024-12-17 04:58:20,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:20,340][root][INFO] - Training Epoch: 2/2, step 1882/7134 completed (loss: 0.08213255554437637, acc: 0.9729064106941223)
[2024-12-17 04:58:20,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:20,767][root][INFO] - Training Epoch: 2/2, step 1883/7134 completed (loss: 0.07889395952224731, acc: 0.9763779640197754)
[2024-12-17 04:58:20,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:21,180][root][INFO] - Training Epoch: 2/2, step 1884/7134 completed (loss: 0.11515289545059204, acc: 0.9668246507644653)
[2024-12-17 04:58:21,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:21,589][root][INFO] - Training Epoch: 2/2, step 1885/7134 completed (loss: 0.08675916492938995, acc: 0.9681050777435303)
[2024-12-17 04:58:21,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:22,009][root][INFO] - Training Epoch: 2/2, step 1886/7134 completed (loss: 0.07825300842523575, acc: 0.9791231751441956)
[2024-12-17 04:58:22,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:22,418][root][INFO] - Training Epoch: 2/2, step 1887/7134 completed (loss: 0.06319130957126617, acc: 0.9867172837257385)
[2024-12-17 04:58:22,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:22,850][root][INFO] - Training Epoch: 2/2, step 1888/7134 completed (loss: 0.08812984824180603, acc: 0.9788867831230164)
[2024-12-17 04:58:22,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:23,307][root][INFO] - Training Epoch: 2/2, step 1889/7134 completed (loss: 0.04146412014961243, acc: 0.9855491518974304)
[2024-12-17 04:58:23,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:23,741][root][INFO] - Training Epoch: 2/2, step 1890/7134 completed (loss: 0.03536614775657654, acc: 0.9922600388526917)
[2024-12-17 04:58:23,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:24,155][root][INFO] - Training Epoch: 2/2, step 1891/7134 completed (loss: 0.096009761095047, acc: 0.9724025726318359)
[2024-12-17 04:58:24,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:24,573][root][INFO] - Training Epoch: 2/2, step 1892/7134 completed (loss: 0.07560309022665024, acc: 0.9768160581588745)
[2024-12-17 04:58:24,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:24,976][root][INFO] - Training Epoch: 2/2, step 1893/7134 completed (loss: 0.04073764383792877, acc: 0.9843993782997131)
[2024-12-17 04:58:25,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:25,394][root][INFO] - Training Epoch: 2/2, step 1894/7134 completed (loss: 0.11153088510036469, acc: 0.9704861044883728)
[2024-12-17 04:58:25,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:25,766][root][INFO] - Training Epoch: 2/2, step 1895/7134 completed (loss: 0.273732453584671, acc: 0.9411764740943909)
[2024-12-17 04:58:25,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:26,180][root][INFO] - Training Epoch: 2/2, step 1896/7134 completed (loss: 0.07352712005376816, acc: 0.974117636680603)
[2024-12-17 04:58:26,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:26,605][root][INFO] - Training Epoch: 2/2, step 1897/7134 completed (loss: 0.022071318700909615, acc: 0.9962962865829468)
[2024-12-17 04:58:26,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:27,056][root][INFO] - Training Epoch: 2/2, step 1898/7134 completed (loss: 0.0482763946056366, acc: 0.9800994992256165)
[2024-12-17 04:58:27,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:27,462][root][INFO] - Training Epoch: 2/2, step 1899/7134 completed (loss: 0.05936974659562111, acc: 0.9873417615890503)
[2024-12-17 04:58:27,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:27,879][root][INFO] - Training Epoch: 2/2, step 1900/7134 completed (loss: 0.02871466800570488, acc: 0.9967637658119202)
[2024-12-17 04:58:27,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:28,307][root][INFO] - Training Epoch: 2/2, step 1901/7134 completed (loss: 0.07569444924592972, acc: 0.9872029423713684)
[2024-12-17 04:58:28,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:28,707][root][INFO] - Training Epoch: 2/2, step 1902/7134 completed (loss: 0.03257271274924278, acc: 0.9894551634788513)
[2024-12-17 04:58:28,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:29,154][root][INFO] - Training Epoch: 2/2, step 1903/7134 completed (loss: 0.048274680972099304, acc: 0.9826388955116272)
[2024-12-17 04:58:29,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:29,545][root][INFO] - Training Epoch: 2/2, step 1904/7134 completed (loss: 0.036346614360809326, acc: 0.9872881174087524)
[2024-12-17 04:58:29,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:29,939][root][INFO] - Training Epoch: 2/2, step 1905/7134 completed (loss: 0.06354515999555588, acc: 0.9815950989723206)
[2024-12-17 04:58:30,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:30,373][root][INFO] - Training Epoch: 2/2, step 1906/7134 completed (loss: 0.051107101142406464, acc: 0.9863547682762146)
[2024-12-17 04:58:30,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:30,983][root][INFO] - Training Epoch: 2/2, step 1907/7134 completed (loss: 0.037895530462265015, acc: 0.9882352948188782)
[2024-12-17 04:58:31,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:31,423][root][INFO] - Training Epoch: 2/2, step 1908/7134 completed (loss: 0.030730998143553734, acc: 0.9924812316894531)
[2024-12-17 04:58:31,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:31,859][root][INFO] - Training Epoch: 2/2, step 1909/7134 completed (loss: 0.05205975100398064, acc: 0.9867549538612366)
[2024-12-17 04:58:31,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:32,303][root][INFO] - Training Epoch: 2/2, step 1910/7134 completed (loss: 0.06465353816747665, acc: 0.9835526347160339)
[2024-12-17 04:58:32,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:32,744][root][INFO] - Training Epoch: 2/2, step 1911/7134 completed (loss: 0.04308009520173073, acc: 0.9902912378311157)
[2024-12-17 04:58:32,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:33,192][root][INFO] - Training Epoch: 2/2, step 1912/7134 completed (loss: 0.02355310134589672, acc: 0.9880159497261047)
[2024-12-17 04:58:33,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:33,604][root][INFO] - Training Epoch: 2/2, step 1913/7134 completed (loss: 0.09324219822883606, acc: 0.9777365326881409)
[2024-12-17 04:58:33,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:34,056][root][INFO] - Training Epoch: 2/2, step 1914/7134 completed (loss: 0.05786249414086342, acc: 0.9878214001655579)
[2024-12-17 04:58:34,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:34,454][root][INFO] - Training Epoch: 2/2, step 1915/7134 completed (loss: 0.049062833189964294, acc: 0.9885807633399963)
[2024-12-17 04:58:34,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:34,852][root][INFO] - Training Epoch: 2/2, step 1916/7134 completed (loss: 0.04594126716256142, acc: 0.9805115461349487)
[2024-12-17 04:58:34,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:35,292][root][INFO] - Training Epoch: 2/2, step 1917/7134 completed (loss: 0.058803003281354904, acc: 0.9845938086509705)
[2024-12-17 04:58:35,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:35,721][root][INFO] - Training Epoch: 2/2, step 1918/7134 completed (loss: 0.058556776493787766, acc: 0.9890282154083252)
[2024-12-17 04:58:35,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:36,293][root][INFO] - Training Epoch: 2/2, step 1919/7134 completed (loss: 0.0541897788643837, acc: 0.9885222315788269)
[2024-12-17 04:58:36,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:36,747][root][INFO] - Training Epoch: 2/2, step 1920/7134 completed (loss: 0.03599570319056511, acc: 0.9891975522041321)
[2024-12-17 04:58:36,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:37,188][root][INFO] - Training Epoch: 2/2, step 1921/7134 completed (loss: 0.040698692202568054, acc: 0.990304708480835)
[2024-12-17 04:58:37,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:37,649][root][INFO] - Training Epoch: 2/2, step 1922/7134 completed (loss: 0.042882755398750305, acc: 0.9900596141815186)
[2024-12-17 04:58:37,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:38,072][root][INFO] - Training Epoch: 2/2, step 1923/7134 completed (loss: 0.03475653752684593, acc: 0.9899497628211975)
[2024-12-17 04:58:38,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:38,528][root][INFO] - Training Epoch: 2/2, step 1924/7134 completed (loss: 0.07200067490339279, acc: 0.9785407781600952)
[2024-12-17 04:58:38,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:39,001][root][INFO] - Training Epoch: 2/2, step 1925/7134 completed (loss: 0.06815003603696823, acc: 0.9767195582389832)
[2024-12-17 04:58:39,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:39,460][root][INFO] - Training Epoch: 2/2, step 1926/7134 completed (loss: 0.01723831705749035, acc: 0.9948927760124207)
[2024-12-17 04:58:39,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:39,922][root][INFO] - Training Epoch: 2/2, step 1927/7134 completed (loss: 0.05361032485961914, acc: 0.9911602139472961)
[2024-12-17 04:58:40,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:40,386][root][INFO] - Training Epoch: 2/2, step 1928/7134 completed (loss: 0.02916499599814415, acc: 0.9908814430236816)
[2024-12-17 04:58:40,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:40,818][root][INFO] - Training Epoch: 2/2, step 1929/7134 completed (loss: 0.024814993143081665, acc: 0.994350254535675)
[2024-12-17 04:58:40,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:41,271][root][INFO] - Training Epoch: 2/2, step 1930/7134 completed (loss: 0.07748505473136902, acc: 0.9763779640197754)
[2024-12-17 04:58:41,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:41,735][root][INFO] - Training Epoch: 2/2, step 1931/7134 completed (loss: 0.09292033314704895, acc: 0.9797724485397339)
[2024-12-17 04:58:41,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:42,134][root][INFO] - Training Epoch: 2/2, step 1932/7134 completed (loss: 0.10366543382406235, acc: 0.9761193990707397)
[2024-12-17 04:58:42,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:42,570][root][INFO] - Training Epoch: 2/2, step 1933/7134 completed (loss: 0.12302085757255554, acc: 0.9719887971878052)
[2024-12-17 04:58:42,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:42,999][root][INFO] - Training Epoch: 2/2, step 1934/7134 completed (loss: 0.036131829023361206, acc: 0.9929378628730774)
[2024-12-17 04:58:43,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:43,457][root][INFO] - Training Epoch: 2/2, step 1935/7134 completed (loss: 0.10361173003911972, acc: 0.9781659245491028)
[2024-12-17 04:58:43,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:43,918][root][INFO] - Training Epoch: 2/2, step 1936/7134 completed (loss: 0.034180451184511185, acc: 0.9889415502548218)
[2024-12-17 04:58:44,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:44,333][root][INFO] - Training Epoch: 2/2, step 1937/7134 completed (loss: 0.04775141924619675, acc: 0.9886363744735718)
[2024-12-17 04:58:44,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:44,769][root][INFO] - Training Epoch: 2/2, step 1938/7134 completed (loss: 0.08411721885204315, acc: 0.9772079586982727)
[2024-12-17 04:58:44,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:45,229][root][INFO] - Training Epoch: 2/2, step 1939/7134 completed (loss: 0.0752192810177803, acc: 0.9830508232116699)
[2024-12-17 04:58:45,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:45,672][root][INFO] - Training Epoch: 2/2, step 1940/7134 completed (loss: 0.06573391705751419, acc: 0.9809523820877075)
[2024-12-17 04:58:45,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:46,132][root][INFO] - Training Epoch: 2/2, step 1941/7134 completed (loss: 0.06723915785551071, acc: 0.9786096215248108)
[2024-12-17 04:58:46,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:46,534][root][INFO] - Training Epoch: 2/2, step 1942/7134 completed (loss: 0.04878811165690422, acc: 0.9878048896789551)
[2024-12-17 04:58:46,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:46,999][root][INFO] - Training Epoch: 2/2, step 1943/7134 completed (loss: 0.07598324865102768, acc: 0.9743902683258057)
[2024-12-17 04:58:47,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:47,441][root][INFO] - Training Epoch: 2/2, step 1944/7134 completed (loss: 0.047773804515600204, acc: 0.9835466146469116)
[2024-12-17 04:58:47,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:47,888][root][INFO] - Training Epoch: 2/2, step 1945/7134 completed (loss: 0.05439792573451996, acc: 0.9842519760131836)
[2024-12-17 04:58:48,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:48,330][root][INFO] - Training Epoch: 2/2, step 1946/7134 completed (loss: 0.05504157394170761, acc: 0.979626476764679)
[2024-12-17 04:58:48,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:48,768][root][INFO] - Training Epoch: 2/2, step 1947/7134 completed (loss: 0.07001297920942307, acc: 0.9763157963752747)
[2024-12-17 04:58:48,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:49,194][root][INFO] - Training Epoch: 2/2, step 1948/7134 completed (loss: 0.10909796506166458, acc: 0.9753320813179016)
[2024-12-17 04:58:49,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:49,590][root][INFO] - Training Epoch: 2/2, step 1949/7134 completed (loss: 0.07116448879241943, acc: 0.9832776188850403)
[2024-12-17 04:58:49,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:50,032][root][INFO] - Training Epoch: 2/2, step 1950/7134 completed (loss: 0.0701661929488182, acc: 0.9762773513793945)
[2024-12-17 04:58:50,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:50,503][root][INFO] - Training Epoch: 2/2, step 1951/7134 completed (loss: 0.061206918209791183, acc: 0.9882943034172058)
[2024-12-17 04:58:50,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:50,917][root][INFO] - Training Epoch: 2/2, step 1952/7134 completed (loss: 0.08168811351060867, acc: 0.9750415682792664)
[2024-12-17 04:58:51,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:51,341][root][INFO] - Training Epoch: 2/2, step 1953/7134 completed (loss: 0.03872888535261154, acc: 0.9845201373100281)
[2024-12-17 04:58:51,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:51,743][root][INFO] - Training Epoch: 2/2, step 1954/7134 completed (loss: 0.04183565452694893, acc: 0.9853658676147461)
[2024-12-17 04:58:51,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:52,165][root][INFO] - Training Epoch: 2/2, step 1955/7134 completed (loss: 0.04945916682481766, acc: 0.9841827750205994)
[2024-12-17 04:58:52,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:52,521][root][INFO] - Training Epoch: 2/2, step 1956/7134 completed (loss: 0.03014340251684189, acc: 0.9919354915618896)
[2024-12-17 04:58:52,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:52,918][root][INFO] - Training Epoch: 2/2, step 1957/7134 completed (loss: 0.0609717033803463, acc: 0.9851852059364319)
[2024-12-17 04:58:53,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:53,297][root][INFO] - Training Epoch: 2/2, step 1958/7134 completed (loss: 0.05007677525281906, acc: 0.9856733679771423)
[2024-12-17 04:58:53,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:53,691][root][INFO] - Training Epoch: 2/2, step 1959/7134 completed (loss: 0.05861559137701988, acc: 0.9872068166732788)
[2024-12-17 04:58:53,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:54,122][root][INFO] - Training Epoch: 2/2, step 1960/7134 completed (loss: 0.02547706477344036, acc: 0.9943609237670898)
[2024-12-17 04:58:54,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:54,504][root][INFO] - Training Epoch: 2/2, step 1961/7134 completed (loss: 0.027833782136440277, acc: 0.9966555237770081)
[2024-12-17 04:58:54,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:54,924][root][INFO] - Training Epoch: 2/2, step 1962/7134 completed (loss: 0.05554599314928055, acc: 0.9860334992408752)
[2024-12-17 04:58:55,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:55,329][root][INFO] - Training Epoch: 2/2, step 1963/7134 completed (loss: 0.03692520037293434, acc: 0.9879102110862732)
[2024-12-17 04:58:55,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:55,762][root][INFO] - Training Epoch: 2/2, step 1964/7134 completed (loss: 0.048456475138664246, acc: 0.9865689873695374)
[2024-12-17 04:58:55,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:56,195][root][INFO] - Training Epoch: 2/2, step 1965/7134 completed (loss: 0.028576357290148735, acc: 0.991631805896759)
[2024-12-17 04:58:56,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:56,619][root][INFO] - Training Epoch: 2/2, step 1966/7134 completed (loss: 0.038333021104335785, acc: 0.9862385392189026)
[2024-12-17 04:58:56,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:57,067][root][INFO] - Training Epoch: 2/2, step 1967/7134 completed (loss: 0.08010224997997284, acc: 0.9821656346321106)
[2024-12-17 04:58:57,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:57,511][root][INFO] - Training Epoch: 2/2, step 1968/7134 completed (loss: 0.030765388160943985, acc: 0.9925925731658936)
[2024-12-17 04:58:57,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:57,925][root][INFO] - Training Epoch: 2/2, step 1969/7134 completed (loss: 0.0406002439558506, acc: 0.9893333315849304)
[2024-12-17 04:58:58,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:58,360][root][INFO] - Training Epoch: 2/2, step 1970/7134 completed (loss: 0.03306075558066368, acc: 0.9923312664031982)
[2024-12-17 04:58:58,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:58,771][root][INFO] - Training Epoch: 2/2, step 1971/7134 completed (loss: 0.04667872563004494, acc: 0.988063633441925)
[2024-12-17 04:58:58,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:59,157][root][INFO] - Training Epoch: 2/2, step 1972/7134 completed (loss: 0.19068844616413116, acc: 0.9484029412269592)
[2024-12-17 04:58:59,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:58:59,581][root][INFO] - Training Epoch: 2/2, step 1973/7134 completed (loss: 0.1108110100030899, acc: 0.9638095498085022)
[2024-12-17 04:58:59,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:00,043][root][INFO] - Training Epoch: 2/2, step 1974/7134 completed (loss: 0.038755904883146286, acc: 0.9899497628211975)
[2024-12-17 04:59:00,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:00,461][root][INFO] - Training Epoch: 2/2, step 1975/7134 completed (loss: 0.037201736122369766, acc: 0.9878787994384766)
[2024-12-17 04:59:00,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:00,918][root][INFO] - Training Epoch: 2/2, step 1976/7134 completed (loss: 0.045931216329336166, acc: 0.9841449856758118)
[2024-12-17 04:59:01,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:01,363][root][INFO] - Training Epoch: 2/2, step 1977/7134 completed (loss: 0.05721689760684967, acc: 0.9855072498321533)
[2024-12-17 04:59:01,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:01,793][root][INFO] - Training Epoch: 2/2, step 1978/7134 completed (loss: 0.015673017129302025, acc: 0.9973154067993164)
[2024-12-17 04:59:01,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:02,255][root][INFO] - Training Epoch: 2/2, step 1979/7134 completed (loss: 0.02378729172050953, acc: 0.9934895634651184)
[2024-12-17 04:59:02,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:02,707][root][INFO] - Training Epoch: 2/2, step 1980/7134 completed (loss: 0.10383974015712738, acc: 0.979139506816864)
[2024-12-17 04:59:02,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:03,152][root][INFO] - Training Epoch: 2/2, step 1981/7134 completed (loss: 0.0738777294754982, acc: 0.9804195761680603)
[2024-12-17 04:59:03,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:03,585][root][INFO] - Training Epoch: 2/2, step 1982/7134 completed (loss: 0.053916919976472855, acc: 0.9832689762115479)
[2024-12-17 04:59:03,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:04,016][root][INFO] - Training Epoch: 2/2, step 1983/7134 completed (loss: 0.028337184339761734, acc: 0.991094172000885)
[2024-12-17 04:59:04,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:04,438][root][INFO] - Training Epoch: 2/2, step 1984/7134 completed (loss: 0.014317668043076992, acc: 0.9973081946372986)
[2024-12-17 04:59:04,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:04,873][root][INFO] - Training Epoch: 2/2, step 1985/7134 completed (loss: 0.0350915901362896, acc: 0.9916434288024902)
[2024-12-17 04:59:04,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:05,313][root][INFO] - Training Epoch: 2/2, step 1986/7134 completed (loss: 0.047591786831617355, acc: 0.9897040128707886)
[2024-12-17 04:59:05,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:05,761][root][INFO] - Training Epoch: 2/2, step 1987/7134 completed (loss: 0.04820267856121063, acc: 0.9886685609817505)
[2024-12-17 04:59:05,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:06,207][root][INFO] - Training Epoch: 2/2, step 1988/7134 completed (loss: 0.04566584527492523, acc: 0.9857346415519714)
[2024-12-17 04:59:06,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:06,624][root][INFO] - Training Epoch: 2/2, step 1989/7134 completed (loss: 0.06794974207878113, acc: 0.9840510487556458)
[2024-12-17 04:59:06,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:07,086][root][INFO] - Training Epoch: 2/2, step 1990/7134 completed (loss: 0.05149136111140251, acc: 0.9842233061790466)
[2024-12-17 04:59:07,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:07,534][root][INFO] - Training Epoch: 2/2, step 1991/7134 completed (loss: 0.014827755279839039, acc: 0.9950166344642639)
[2024-12-17 04:59:07,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:07,968][root][INFO] - Training Epoch: 2/2, step 1992/7134 completed (loss: 0.05688074976205826, acc: 0.9767441749572754)
[2024-12-17 04:59:08,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:08,410][root][INFO] - Training Epoch: 2/2, step 1993/7134 completed (loss: 0.020313940942287445, acc: 0.994727611541748)
[2024-12-17 04:59:08,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:08,855][root][INFO] - Training Epoch: 2/2, step 1994/7134 completed (loss: 0.017779555171728134, acc: 0.9931034445762634)
[2024-12-17 04:59:08,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:09,287][root][INFO] - Training Epoch: 2/2, step 1995/7134 completed (loss: 0.03169558197259903, acc: 0.9938176274299622)
[2024-12-17 04:59:09,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:09,711][root][INFO] - Training Epoch: 2/2, step 1996/7134 completed (loss: 0.03779975324869156, acc: 0.9900826215744019)
[2024-12-17 04:59:09,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:10,126][root][INFO] - Training Epoch: 2/2, step 1997/7134 completed (loss: 0.023810258135199547, acc: 0.9970887899398804)
[2024-12-17 04:59:10,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:10,542][root][INFO] - Training Epoch: 2/2, step 1998/7134 completed (loss: 0.02707611583173275, acc: 0.9921507239341736)
[2024-12-17 04:59:10,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:10,967][root][INFO] - Training Epoch: 2/2, step 1999/7134 completed (loss: 0.03134985640645027, acc: 0.9881154298782349)
[2024-12-17 04:59:11,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:11,379][root][INFO] - Training Epoch: 2/2, step 2000/7134 completed (loss: 0.044141314923763275, acc: 0.9905362725257874)
[2024-12-17 04:59:11,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:11,781][root][INFO] - Training Epoch: 2/2, step 2001/7134 completed (loss: 0.02450915239751339, acc: 0.9939393997192383)
[2024-12-17 04:59:11,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:12,216][root][INFO] - Training Epoch: 2/2, step 2002/7134 completed (loss: 0.03773585334420204, acc: 0.991304337978363)
[2024-12-17 04:59:12,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:12,602][root][INFO] - Training Epoch: 2/2, step 2003/7134 completed (loss: 0.036353953182697296, acc: 0.9854166507720947)
[2024-12-17 04:59:12,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:12,980][root][INFO] - Training Epoch: 2/2, step 2004/7134 completed (loss: 0.24054187536239624, acc: 0.9345991611480713)
[2024-12-17 04:59:13,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:13,441][root][INFO] - Training Epoch: 2/2, step 2005/7134 completed (loss: 0.16342416405677795, acc: 0.96712327003479)
[2024-12-17 04:59:13,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:13,844][root][INFO] - Training Epoch: 2/2, step 2006/7134 completed (loss: 0.04508260637521744, acc: 0.9913544654846191)
[2024-12-17 04:59:13,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:14,256][root][INFO] - Training Epoch: 2/2, step 2007/7134 completed (loss: 0.04198716580867767, acc: 0.9879518151283264)
[2024-12-17 04:59:14,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:14,655][root][INFO] - Training Epoch: 2/2, step 2008/7134 completed (loss: 0.04174323007464409, acc: 0.9875444769859314)
[2024-12-17 04:59:14,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:15,065][root][INFO] - Training Epoch: 2/2, step 2009/7134 completed (loss: 0.04211968928575516, acc: 0.9891696572303772)
[2024-12-17 04:59:15,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:15,469][root][INFO] - Training Epoch: 2/2, step 2010/7134 completed (loss: 0.0323062539100647, acc: 0.989708423614502)
[2024-12-17 04:59:15,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:15,895][root][INFO] - Training Epoch: 2/2, step 2011/7134 completed (loss: 0.03899893909692764, acc: 0.9863013625144958)
[2024-12-17 04:59:16,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:16,298][root][INFO] - Training Epoch: 2/2, step 2012/7134 completed (loss: 0.04328388348221779, acc: 0.985200822353363)
[2024-12-17 04:59:16,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:16,725][root][INFO] - Training Epoch: 2/2, step 2013/7134 completed (loss: 0.023287823423743248, acc: 0.9919999837875366)
[2024-12-17 04:59:16,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:17,144][root][INFO] - Training Epoch: 2/2, step 2014/7134 completed (loss: 0.023835845291614532, acc: 0.995275616645813)
[2024-12-17 04:59:17,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:17,559][root][INFO] - Training Epoch: 2/2, step 2015/7134 completed (loss: 0.03076913394033909, acc: 0.9917762875556946)
[2024-12-17 04:59:17,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:17,998][root][INFO] - Training Epoch: 2/2, step 2016/7134 completed (loss: 0.07506394386291504, acc: 0.9815384745597839)
[2024-12-17 04:59:18,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:18,420][root][INFO] - Training Epoch: 2/2, step 2017/7134 completed (loss: 0.07458389550447464, acc: 0.9810810685157776)
[2024-12-17 04:59:18,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:18,856][root][INFO] - Training Epoch: 2/2, step 2018/7134 completed (loss: 0.03713095560669899, acc: 0.9846153855323792)
[2024-12-17 04:59:18,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:19,264][root][INFO] - Training Epoch: 2/2, step 2019/7134 completed (loss: 0.047488365322351456, acc: 0.9875862002372742)
[2024-12-17 04:59:19,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:19,687][root][INFO] - Training Epoch: 2/2, step 2020/7134 completed (loss: 0.014389822259545326, acc: 0.9949238300323486)
[2024-12-17 04:59:19,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:20,141][root][INFO] - Training Epoch: 2/2, step 2021/7134 completed (loss: 0.046817075461149216, acc: 0.9857142567634583)
[2024-12-17 04:59:20,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:20,560][root][INFO] - Training Epoch: 2/2, step 2022/7134 completed (loss: 0.05431671813130379, acc: 0.9878683090209961)
[2024-12-17 04:59:20,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:21,010][root][INFO] - Training Epoch: 2/2, step 2023/7134 completed (loss: 0.034753914922475815, acc: 0.9927007555961609)
[2024-12-17 04:59:21,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:21,458][root][INFO] - Training Epoch: 2/2, step 2024/7134 completed (loss: 0.053576402366161346, acc: 0.9833333492279053)
[2024-12-17 04:59:21,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:21,901][root][INFO] - Training Epoch: 2/2, step 2025/7134 completed (loss: 0.026407135650515556, acc: 0.9959999918937683)
[2024-12-17 04:59:22,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:22,320][root][INFO] - Training Epoch: 2/2, step 2026/7134 completed (loss: 0.06002747267484665, acc: 0.9849397540092468)
[2024-12-17 04:59:22,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:22,779][root][INFO] - Training Epoch: 2/2, step 2027/7134 completed (loss: 0.031360283493995667, acc: 0.9916943311691284)
[2024-12-17 04:59:22,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:23,207][root][INFO] - Training Epoch: 2/2, step 2028/7134 completed (loss: 0.03554870933294296, acc: 0.9897660613059998)
[2024-12-17 04:59:23,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:23,637][root][INFO] - Training Epoch: 2/2, step 2029/7134 completed (loss: 0.039886217564344406, acc: 0.9872159361839294)
[2024-12-17 04:59:23,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:24,040][root][INFO] - Training Epoch: 2/2, step 2030/7134 completed (loss: 0.05699577182531357, acc: 0.9800613522529602)
[2024-12-17 04:59:24,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:24,507][root][INFO] - Training Epoch: 2/2, step 2031/7134 completed (loss: 0.048597417771816254, acc: 0.9865030646324158)
[2024-12-17 04:59:24,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:24,934][root][INFO] - Training Epoch: 2/2, step 2032/7134 completed (loss: 0.045502062886953354, acc: 0.9919354915618896)
[2024-12-17 04:59:25,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:25,373][root][INFO] - Training Epoch: 2/2, step 2033/7134 completed (loss: 0.042800839990377426, acc: 0.9879931211471558)
[2024-12-17 04:59:25,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:25,786][root][INFO] - Training Epoch: 2/2, step 2034/7134 completed (loss: 0.05833438038825989, acc: 0.9862174391746521)
[2024-12-17 04:59:25,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:26,229][root][INFO] - Training Epoch: 2/2, step 2035/7134 completed (loss: 0.0269025806337595, acc: 0.9900373816490173)
[2024-12-17 04:59:26,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:26,655][root][INFO] - Training Epoch: 2/2, step 2036/7134 completed (loss: 0.0337178111076355, acc: 0.9930796027183533)
[2024-12-17 04:59:26,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:27,101][root][INFO] - Training Epoch: 2/2, step 2037/7134 completed (loss: 0.022900795564055443, acc: 0.9910979270935059)
[2024-12-17 04:59:27,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:27,549][root][INFO] - Training Epoch: 2/2, step 2038/7134 completed (loss: 0.022942962124943733, acc: 0.9929078221321106)
[2024-12-17 04:59:27,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:27,976][root][INFO] - Training Epoch: 2/2, step 2039/7134 completed (loss: 0.02191299945116043, acc: 0.9963964223861694)
[2024-12-17 04:59:28,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:28,428][root][INFO] - Training Epoch: 2/2, step 2040/7134 completed (loss: 0.04741279035806656, acc: 0.9938271641731262)
[2024-12-17 04:59:28,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:28,877][root][INFO] - Training Epoch: 2/2, step 2041/7134 completed (loss: 0.018152914941310883, acc: 0.9931318759918213)
[2024-12-17 04:59:29,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:29,310][root][INFO] - Training Epoch: 2/2, step 2042/7134 completed (loss: 0.01586170680820942, acc: 0.9979838728904724)
[2024-12-17 04:59:29,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:29,726][root][INFO] - Training Epoch: 2/2, step 2043/7134 completed (loss: 0.03657836467027664, acc: 0.9921875)
[2024-12-17 04:59:29,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:30,157][root][INFO] - Training Epoch: 2/2, step 2044/7134 completed (loss: 0.023850254714488983, acc: 0.9946332573890686)
[2024-12-17 04:59:30,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:30,562][root][INFO] - Training Epoch: 2/2, step 2045/7134 completed (loss: 0.02142786607146263, acc: 0.9909583926200867)
[2024-12-17 04:59:30,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:30,998][root][INFO] - Training Epoch: 2/2, step 2046/7134 completed (loss: 0.025864509865641594, acc: 0.9857723712921143)
[2024-12-17 04:59:31,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:31,436][root][INFO] - Training Epoch: 2/2, step 2047/7134 completed (loss: 0.0351310633122921, acc: 0.989983320236206)
[2024-12-17 04:59:31,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:31,860][root][INFO] - Training Epoch: 2/2, step 2048/7134 completed (loss: 0.06561414152383804, acc: 0.9820627570152283)
[2024-12-17 04:59:31,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:32,268][root][INFO] - Training Epoch: 2/2, step 2049/7134 completed (loss: 0.06323462724685669, acc: 0.9858823418617249)
[2024-12-17 04:59:32,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:32,662][root][INFO] - Training Epoch: 2/2, step 2050/7134 completed (loss: 0.08363652974367142, acc: 0.9811965823173523)
[2024-12-17 04:59:32,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:33,074][root][INFO] - Training Epoch: 2/2, step 2051/7134 completed (loss: 0.05734238028526306, acc: 0.986328125)
[2024-12-17 04:59:33,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:33,492][root][INFO] - Training Epoch: 2/2, step 2052/7134 completed (loss: 0.08334767818450928, acc: 0.9812286496162415)
[2024-12-17 04:59:33,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:33,897][root][INFO] - Training Epoch: 2/2, step 2053/7134 completed (loss: 0.04743199422955513, acc: 0.984000027179718)
[2024-12-17 04:59:34,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:34,340][root][INFO] - Training Epoch: 2/2, step 2054/7134 completed (loss: 0.1306959092617035, acc: 0.9633758068084717)
[2024-12-17 04:59:34,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:34,780][root][INFO] - Training Epoch: 2/2, step 2055/7134 completed (loss: 0.07288237661123276, acc: 0.9811023473739624)
[2024-12-17 04:59:34,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:35,240][root][INFO] - Training Epoch: 2/2, step 2056/7134 completed (loss: 0.0595763735473156, acc: 0.9831387996673584)
[2024-12-17 04:59:35,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:35,661][root][INFO] - Training Epoch: 2/2, step 2057/7134 completed (loss: 0.07120919972658157, acc: 0.9796472191810608)
[2024-12-17 04:59:35,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:36,104][root][INFO] - Training Epoch: 2/2, step 2058/7134 completed (loss: 0.11253548413515091, acc: 0.9756097793579102)
[2024-12-17 04:59:36,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:36,551][root][INFO] - Training Epoch: 2/2, step 2059/7134 completed (loss: 0.10511339455842972, acc: 0.9774696826934814)
[2024-12-17 04:59:36,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:36,982][root][INFO] - Training Epoch: 2/2, step 2060/7134 completed (loss: 0.04847095161676407, acc: 0.9842632412910461)
[2024-12-17 04:59:37,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:37,414][root][INFO] - Training Epoch: 2/2, step 2061/7134 completed (loss: 0.06725284457206726, acc: 0.9787535667419434)
[2024-12-17 04:59:37,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:37,865][root][INFO] - Training Epoch: 2/2, step 2062/7134 completed (loss: 0.07628905773162842, acc: 0.9791271090507507)
[2024-12-17 04:59:38,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:38,282][root][INFO] - Training Epoch: 2/2, step 2063/7134 completed (loss: 0.0773439109325409, acc: 0.9850746393203735)
[2024-12-17 04:59:38,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:38,705][root][INFO] - Training Epoch: 2/2, step 2064/7134 completed (loss: 0.02022661454975605, acc: 0.9937499761581421)
[2024-12-17 04:59:38,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:39,112][root][INFO] - Training Epoch: 2/2, step 2065/7134 completed (loss: 0.08069999516010284, acc: 0.9763779640197754)
[2024-12-17 04:59:39,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:39,491][root][INFO] - Training Epoch: 2/2, step 2066/7134 completed (loss: 0.052744604647159576, acc: 0.9859719276428223)
[2024-12-17 04:59:39,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:39,904][root][INFO] - Training Epoch: 2/2, step 2067/7134 completed (loss: 0.040314480662345886, acc: 0.9848197102546692)
[2024-12-17 04:59:39,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:40,307][root][INFO] - Training Epoch: 2/2, step 2068/7134 completed (loss: 0.07498897612094879, acc: 0.976580798625946)
[2024-12-17 04:59:40,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:40,741][root][INFO] - Training Epoch: 2/2, step 2069/7134 completed (loss: 0.07588167488574982, acc: 0.9753845930099487)
[2024-12-17 04:59:40,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:41,149][root][INFO] - Training Epoch: 2/2, step 2070/7134 completed (loss: 0.04398556798696518, acc: 0.9885931611061096)
[2024-12-17 04:59:41,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:41,561][root][INFO] - Training Epoch: 2/2, step 2071/7134 completed (loss: 0.03172558918595314, acc: 0.9929742217063904)
[2024-12-17 04:59:41,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:41,967][root][INFO] - Training Epoch: 2/2, step 2072/7134 completed (loss: 0.027710475027561188, acc: 0.9950494766235352)
[2024-12-17 04:59:42,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:42,364][root][INFO] - Training Epoch: 2/2, step 2073/7134 completed (loss: 0.04085683077573776, acc: 0.9884615540504456)
[2024-12-17 04:59:42,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:42,823][root][INFO] - Training Epoch: 2/2, step 2074/7134 completed (loss: 0.04186704009771347, acc: 0.987089216709137)
[2024-12-17 04:59:43,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:43,277][root][INFO] - Training Epoch: 2/2, step 2075/7134 completed (loss: 0.052890077233314514, acc: 0.9816360473632812)
[2024-12-17 04:59:43,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:43,728][root][INFO] - Training Epoch: 2/2, step 2076/7134 completed (loss: 0.04591088369488716, acc: 0.9846153855323792)
[2024-12-17 04:59:43,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:44,168][root][INFO] - Training Epoch: 2/2, step 2077/7134 completed (loss: 0.028747355565428734, acc: 0.9920318722724915)
[2024-12-17 04:59:44,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:44,629][root][INFO] - Training Epoch: 2/2, step 2078/7134 completed (loss: 0.03271161764860153, acc: 0.9918604493141174)
[2024-12-17 04:59:44,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:45,072][root][INFO] - Training Epoch: 2/2, step 2079/7134 completed (loss: 0.021283194422721863, acc: 0.9920634627342224)
[2024-12-17 04:59:45,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:45,499][root][INFO] - Training Epoch: 2/2, step 2080/7134 completed (loss: 0.03418190777301788, acc: 0.9926470518112183)
[2024-12-17 04:59:45,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:45,935][root][INFO] - Training Epoch: 2/2, step 2081/7134 completed (loss: 0.0297099482268095, acc: 0.994194507598877)
[2024-12-17 04:59:46,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:46,401][root][INFO] - Training Epoch: 2/2, step 2082/7134 completed (loss: 0.10089294612407684, acc: 0.9769392013549805)
[2024-12-17 04:59:46,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:46,797][root][INFO] - Training Epoch: 2/2, step 2083/7134 completed (loss: 0.05528710409998894, acc: 0.9925925731658936)
[2024-12-17 04:59:46,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:47,210][root][INFO] - Training Epoch: 2/2, step 2084/7134 completed (loss: 0.02599550597369671, acc: 0.9968944191932678)
[2024-12-17 04:59:47,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:47,672][root][INFO] - Training Epoch: 2/2, step 2085/7134 completed (loss: 0.025192957371473312, acc: 0.9926062822341919)
[2024-12-17 04:59:47,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:48,079][root][INFO] - Training Epoch: 2/2, step 2086/7134 completed (loss: 0.025063086301088333, acc: 0.9885844588279724)
[2024-12-17 04:59:48,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:48,515][root][INFO] - Training Epoch: 2/2, step 2087/7134 completed (loss: 0.008938994258642197, acc: 0.9985775351524353)
[2024-12-17 04:59:48,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:48,951][root][INFO] - Training Epoch: 2/2, step 2088/7134 completed (loss: 0.03428776189684868, acc: 0.9884726405143738)
[2024-12-17 04:59:49,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:49,394][root][INFO] - Training Epoch: 2/2, step 2089/7134 completed (loss: 0.027738185599446297, acc: 0.9936908483505249)
[2024-12-17 04:59:49,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:49,823][root][INFO] - Training Epoch: 2/2, step 2090/7134 completed (loss: 0.0192057304084301, acc: 0.9936808943748474)
[2024-12-17 04:59:49,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:50,258][root][INFO] - Training Epoch: 2/2, step 2091/7134 completed (loss: 0.031048636883497238, acc: 0.9932432174682617)
[2024-12-17 04:59:50,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:50,709][root][INFO] - Training Epoch: 2/2, step 2092/7134 completed (loss: 0.012126678600907326, acc: 0.9968454241752625)
[2024-12-17 04:59:50,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:51,165][root][INFO] - Training Epoch: 2/2, step 2093/7134 completed (loss: 0.0311870314180851, acc: 0.9932157397270203)
[2024-12-17 04:59:51,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:51,536][root][INFO] - Training Epoch: 2/2, step 2094/7134 completed (loss: 0.05641890689730644, acc: 0.9918864369392395)
[2024-12-17 04:59:51,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:51,975][root][INFO] - Training Epoch: 2/2, step 2095/7134 completed (loss: 0.042997635900974274, acc: 0.9894459247589111)
[2024-12-17 04:59:52,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:52,374][root][INFO] - Training Epoch: 2/2, step 2096/7134 completed (loss: 0.015307845547795296, acc: 0.9948275685310364)
[2024-12-17 04:59:52,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:52,804][root][INFO] - Training Epoch: 2/2, step 2097/7134 completed (loss: 0.02185797691345215, acc: 0.9943898916244507)
[2024-12-17 04:59:52,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:53,244][root][INFO] - Training Epoch: 2/2, step 2098/7134 completed (loss: 0.023795591667294502, acc: 0.9919614195823669)
[2024-12-17 04:59:53,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:53,672][root][INFO] - Training Epoch: 2/2, step 2099/7134 completed (loss: 0.028025338426232338, acc: 0.9926605224609375)
[2024-12-17 04:59:53,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:54,144][root][INFO] - Training Epoch: 2/2, step 2100/7134 completed (loss: 0.023832041770219803, acc: 0.9893758296966553)
[2024-12-17 04:59:54,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:54,571][root][INFO] - Training Epoch: 2/2, step 2101/7134 completed (loss: 0.030987873673439026, acc: 0.989924430847168)
[2024-12-17 04:59:54,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:55,000][root][INFO] - Training Epoch: 2/2, step 2102/7134 completed (loss: 0.033520374447107315, acc: 0.9897959232330322)
[2024-12-17 04:59:55,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:55,414][root][INFO] - Training Epoch: 2/2, step 2103/7134 completed (loss: 0.03381136432290077, acc: 0.987730085849762)
[2024-12-17 04:59:55,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:55,862][root][INFO] - Training Epoch: 2/2, step 2104/7134 completed (loss: 0.01764029823243618, acc: 0.9948453903198242)
[2024-12-17 04:59:55,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:56,265][root][INFO] - Training Epoch: 2/2, step 2105/7134 completed (loss: 0.0740058496594429, acc: 0.978090763092041)
[2024-12-17 04:59:56,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:56,729][root][INFO] - Training Epoch: 2/2, step 2106/7134 completed (loss: 0.065080426633358, acc: 0.9870689511299133)
[2024-12-17 04:59:56,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:57,171][root][INFO] - Training Epoch: 2/2, step 2107/7134 completed (loss: 0.02608022838830948, acc: 0.9932523369789124)
[2024-12-17 04:59:57,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:57,623][root][INFO] - Training Epoch: 2/2, step 2108/7134 completed (loss: 0.03653619810938835, acc: 0.9820627570152283)
[2024-12-17 04:59:57,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:58,040][root][INFO] - Training Epoch: 2/2, step 2109/7134 completed (loss: 0.09321542829275131, acc: 0.9841269850730896)
[2024-12-17 04:59:58,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:58,503][root][INFO] - Training Epoch: 2/2, step 2110/7134 completed (loss: 0.07115712016820908, acc: 0.9781976938247681)
[2024-12-17 04:59:58,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:58,923][root][INFO] - Training Epoch: 2/2, step 2111/7134 completed (loss: 0.05731375515460968, acc: 0.9805447459220886)
[2024-12-17 04:59:59,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:59,319][root][INFO] - Training Epoch: 2/2, step 2112/7134 completed (loss: 0.08659709990024567, acc: 0.9729299545288086)
[2024-12-17 04:59:59,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 04:59:59,734][root][INFO] - Training Epoch: 2/2, step 2113/7134 completed (loss: 0.025436248630285263, acc: 0.992548406124115)
[2024-12-17 04:59:59,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:00,169][root][INFO] - Training Epoch: 2/2, step 2114/7134 completed (loss: 0.030820021405816078, acc: 0.9908496737480164)
[2024-12-17 05:00:00,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:00,641][root][INFO] - Training Epoch: 2/2, step 2115/7134 completed (loss: 0.030928336083889008, acc: 0.991239070892334)
[2024-12-17 05:00:00,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:01,091][root][INFO] - Training Epoch: 2/2, step 2116/7134 completed (loss: 0.0416979119181633, acc: 0.9861963391304016)
[2024-12-17 05:00:01,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:01,526][root][INFO] - Training Epoch: 2/2, step 2117/7134 completed (loss: 0.03171322122216225, acc: 0.9900497794151306)
[2024-12-17 05:00:01,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:01,947][root][INFO] - Training Epoch: 2/2, step 2118/7134 completed (loss: 0.0392330028116703, acc: 0.9918144345283508)
[2024-12-17 05:00:02,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:02,371][root][INFO] - Training Epoch: 2/2, step 2119/7134 completed (loss: 0.04429428651928902, acc: 0.9855642914772034)
[2024-12-17 05:00:02,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:02,801][root][INFO] - Training Epoch: 2/2, step 2120/7134 completed (loss: 0.03651726618409157, acc: 0.9893454909324646)
[2024-12-17 05:00:02,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:03,186][root][INFO] - Training Epoch: 2/2, step 2121/7134 completed (loss: 0.04846935719251633, acc: 0.9841269850730896)
[2024-12-17 05:00:03,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:03,614][root][INFO] - Training Epoch: 2/2, step 2122/7134 completed (loss: 0.02774876169860363, acc: 0.9895833134651184)
[2024-12-17 05:00:03,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:04,025][root][INFO] - Training Epoch: 2/2, step 2123/7134 completed (loss: 0.029930537566542625, acc: 0.9921383857727051)
[2024-12-17 05:00:04,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:04,447][root][INFO] - Training Epoch: 2/2, step 2124/7134 completed (loss: 0.01810801401734352, acc: 0.9922118186950684)
[2024-12-17 05:00:04,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:04,908][root][INFO] - Training Epoch: 2/2, step 2125/7134 completed (loss: 0.016382263973355293, acc: 0.9969696998596191)
[2024-12-17 05:00:05,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:05,348][root][INFO] - Training Epoch: 2/2, step 2126/7134 completed (loss: 0.027211885899305344, acc: 0.9932773113250732)
[2024-12-17 05:00:05,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:05,802][root][INFO] - Training Epoch: 2/2, step 2127/7134 completed (loss: 0.02307240292429924, acc: 0.99262535572052)
[2024-12-17 05:00:05,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:06,247][root][INFO] - Training Epoch: 2/2, step 2128/7134 completed (loss: 0.03604451194405556, acc: 0.9842519760131836)
[2024-12-17 05:00:06,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:06,670][root][INFO] - Training Epoch: 2/2, step 2129/7134 completed (loss: 0.02803455851972103, acc: 0.9894419312477112)
[2024-12-17 05:00:06,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:07,074][root][INFO] - Training Epoch: 2/2, step 2130/7134 completed (loss: 0.029266905039548874, acc: 0.9884488582611084)
[2024-12-17 05:00:07,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:07,489][root][INFO] - Training Epoch: 2/2, step 2131/7134 completed (loss: 0.01908123679459095, acc: 0.9969040155410767)
[2024-12-17 05:00:07,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:07,913][root][INFO] - Training Epoch: 2/2, step 2132/7134 completed (loss: 0.01648915931582451, acc: 0.9946091771125793)
[2024-12-17 05:00:08,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:08,335][root][INFO] - Training Epoch: 2/2, step 2133/7134 completed (loss: 0.03653314337134361, acc: 0.9894319772720337)
[2024-12-17 05:00:08,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:08,760][root][INFO] - Training Epoch: 2/2, step 2134/7134 completed (loss: 0.009209565818309784, acc: 0.9986613392829895)
[2024-12-17 05:00:08,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:09,166][root][INFO] - Training Epoch: 2/2, step 2135/7134 completed (loss: 0.044708386063575745, acc: 0.9849397540092468)
[2024-12-17 05:00:09,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:09,607][root][INFO] - Training Epoch: 2/2, step 2136/7134 completed (loss: 0.02014796994626522, acc: 0.9946595430374146)
[2024-12-17 05:00:09,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:10,059][root][INFO] - Training Epoch: 2/2, step 2137/7134 completed (loss: 0.016298092901706696, acc: 0.9922580718994141)
[2024-12-17 05:00:10,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:10,458][root][INFO] - Training Epoch: 2/2, step 2138/7134 completed (loss: 0.012871695682406425, acc: 0.9984756112098694)
[2024-12-17 05:00:10,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:10,886][root][INFO] - Training Epoch: 2/2, step 2139/7134 completed (loss: 0.011861762963235378, acc: 0.9958391189575195)
[2024-12-17 05:00:10,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:11,544][root][INFO] - Training Epoch: 2/2, step 2140/7134 completed (loss: 0.05219024047255516, acc: 0.9876033067703247)
[2024-12-17 05:00:11,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:11,948][root][INFO] - Training Epoch: 2/2, step 2141/7134 completed (loss: 0.033067334443330765, acc: 0.9941520690917969)
[2024-12-17 05:00:12,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:12,397][root][INFO] - Training Epoch: 2/2, step 2142/7134 completed (loss: 0.03181379288434982, acc: 0.9929178357124329)
[2024-12-17 05:00:12,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:12,838][root][INFO] - Training Epoch: 2/2, step 2143/7134 completed (loss: 0.026219934225082397, acc: 0.9929824471473694)
[2024-12-17 05:00:12,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:13,290][root][INFO] - Training Epoch: 2/2, step 2144/7134 completed (loss: 0.007002647500485182, acc: 0.9986720085144043)
[2024-12-17 05:00:13,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:13,731][root][INFO] - Training Epoch: 2/2, step 2145/7134 completed (loss: 0.0638536736369133, acc: 0.9856938719749451)
[2024-12-17 05:00:13,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:14,122][root][INFO] - Training Epoch: 2/2, step 2146/7134 completed (loss: 0.038552653044462204, acc: 0.9876760840415955)
[2024-12-17 05:00:14,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:14,585][root][INFO] - Training Epoch: 2/2, step 2147/7134 completed (loss: 0.05188008397817612, acc: 0.9887780547142029)
[2024-12-17 05:00:14,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:14,992][root][INFO] - Training Epoch: 2/2, step 2148/7134 completed (loss: 0.05324902758002281, acc: 0.9898107647895813)
[2024-12-17 05:00:15,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:15,418][root][INFO] - Training Epoch: 2/2, step 2149/7134 completed (loss: 0.022066082805395126, acc: 0.9915493130683899)
[2024-12-17 05:00:15,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:15,825][root][INFO] - Training Epoch: 2/2, step 2150/7134 completed (loss: 0.032984763383865356, acc: 0.9919999837875366)
[2024-12-17 05:00:15,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:16,240][root][INFO] - Training Epoch: 2/2, step 2151/7134 completed (loss: 0.02030983939766884, acc: 0.9928571581840515)
[2024-12-17 05:00:16,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:16,658][root][INFO] - Training Epoch: 2/2, step 2152/7134 completed (loss: 0.10131222754716873, acc: 0.966911792755127)
[2024-12-17 05:00:16,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:17,166][root][INFO] - Training Epoch: 2/2, step 2153/7134 completed (loss: 0.03891465440392494, acc: 0.9900110960006714)
[2024-12-17 05:00:17,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:17,645][root][INFO] - Training Epoch: 2/2, step 2154/7134 completed (loss: 0.06404437124729156, acc: 0.9810366630554199)
[2024-12-17 05:00:17,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:18,054][root][INFO] - Training Epoch: 2/2, step 2155/7134 completed (loss: 0.08788535743951797, acc: 0.9835164546966553)
[2024-12-17 05:00:18,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:18,455][root][INFO] - Training Epoch: 2/2, step 2156/7134 completed (loss: 0.02698216587305069, acc: 0.9895833134651184)
[2024-12-17 05:00:18,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:18,913][root][INFO] - Training Epoch: 2/2, step 2157/7134 completed (loss: 0.02628120593726635, acc: 0.9921787977218628)
[2024-12-17 05:00:19,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:19,384][root][INFO] - Training Epoch: 2/2, step 2158/7134 completed (loss: 0.05519592761993408, acc: 0.9897959232330322)
[2024-12-17 05:00:19,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:19,828][root][INFO] - Training Epoch: 2/2, step 2159/7134 completed (loss: 0.03590903803706169, acc: 0.9910600185394287)
[2024-12-17 05:00:19,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:20,278][root][INFO] - Training Epoch: 2/2, step 2160/7134 completed (loss: 0.03476572036743164, acc: 0.9876203536987305)
[2024-12-17 05:00:20,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:20,741][root][INFO] - Training Epoch: 2/2, step 2161/7134 completed (loss: 0.06855759024620056, acc: 0.980793833732605)
[2024-12-17 05:00:20,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:21,181][root][INFO] - Training Epoch: 2/2, step 2162/7134 completed (loss: 0.03694170340895653, acc: 0.9878970980644226)
[2024-12-17 05:00:21,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:21,649][root][INFO] - Training Epoch: 2/2, step 2163/7134 completed (loss: 0.04692326858639717, acc: 0.98740154504776)
[2024-12-17 05:00:21,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:22,056][root][INFO] - Training Epoch: 2/2, step 2164/7134 completed (loss: 0.02520841546356678, acc: 0.989708423614502)
[2024-12-17 05:00:22,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:22,508][root][INFO] - Training Epoch: 2/2, step 2165/7134 completed (loss: 0.027217859402298927, acc: 0.991391658782959)
[2024-12-17 05:00:22,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:22,936][root][INFO] - Training Epoch: 2/2, step 2166/7134 completed (loss: 0.034040775150060654, acc: 0.98828125)
[2024-12-17 05:00:23,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:23,348][root][INFO] - Training Epoch: 2/2, step 2167/7134 completed (loss: 0.04435241222381592, acc: 0.9888641238212585)
[2024-12-17 05:00:23,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:23,762][root][INFO] - Training Epoch: 2/2, step 2168/7134 completed (loss: 0.030840998515486717, acc: 0.9920634627342224)
[2024-12-17 05:00:23,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:24,211][root][INFO] - Training Epoch: 2/2, step 2169/7134 completed (loss: 0.043619923293590546, acc: 0.9918793439865112)
[2024-12-17 05:00:24,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:24,637][root][INFO] - Training Epoch: 2/2, step 2170/7134 completed (loss: 0.03781019523739815, acc: 0.9854439496994019)
[2024-12-17 05:00:24,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:25,093][root][INFO] - Training Epoch: 2/2, step 2171/7134 completed (loss: 0.031751204282045364, acc: 0.9932050108909607)
[2024-12-17 05:00:25,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:25,557][root][INFO] - Training Epoch: 2/2, step 2172/7134 completed (loss: 0.022507881745696068, acc: 0.9948347210884094)
[2024-12-17 05:00:25,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:25,988][root][INFO] - Training Epoch: 2/2, step 2173/7134 completed (loss: 0.05233379825949669, acc: 0.9833837151527405)
[2024-12-17 05:00:26,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:26,416][root][INFO] - Training Epoch: 2/2, step 2174/7134 completed (loss: 0.02246696874499321, acc: 0.9914893507957458)
[2024-12-17 05:00:26,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:26,845][root][INFO] - Training Epoch: 2/2, step 2175/7134 completed (loss: 0.08297961950302124, acc: 0.9847645163536072)
[2024-12-17 05:00:26,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:27,342][root][INFO] - Training Epoch: 2/2, step 2176/7134 completed (loss: 0.028620854020118713, acc: 0.9893364906311035)
[2024-12-17 05:00:27,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:27,834][root][INFO] - Training Epoch: 2/2, step 2177/7134 completed (loss: 0.044902559369802475, acc: 0.984415590763092)
[2024-12-17 05:00:27,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:28,282][root][INFO] - Training Epoch: 2/2, step 2178/7134 completed (loss: 0.01995437778532505, acc: 0.9933775067329407)
[2024-12-17 05:00:28,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:28,755][root][INFO] - Training Epoch: 2/2, step 2179/7134 completed (loss: 0.031318288296461105, acc: 0.9936708807945251)
[2024-12-17 05:00:28,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:29,221][root][INFO] - Training Epoch: 2/2, step 2180/7134 completed (loss: 0.0305593553930521, acc: 0.9929078221321106)
[2024-12-17 05:00:29,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:29,699][root][INFO] - Training Epoch: 2/2, step 2181/7134 completed (loss: 0.02055487036705017, acc: 0.9942775368690491)
[2024-12-17 05:00:29,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:30,152][root][INFO] - Training Epoch: 2/2, step 2182/7134 completed (loss: 0.05376921966671944, acc: 0.985005795955658)
[2024-12-17 05:00:30,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:30,664][root][INFO] - Training Epoch: 2/2, step 2183/7134 completed (loss: 0.02889791876077652, acc: 0.9930151104927063)
[2024-12-17 05:00:30,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:31,156][root][INFO] - Training Epoch: 2/2, step 2184/7134 completed (loss: 0.030420418828725815, acc: 0.995207667350769)
[2024-12-17 05:00:31,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:31,597][root][INFO] - Training Epoch: 2/2, step 2185/7134 completed (loss: 0.06591963022947311, acc: 0.9872521162033081)
[2024-12-17 05:00:31,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:32,083][root][INFO] - Training Epoch: 2/2, step 2186/7134 completed (loss: 0.07398714870214462, acc: 0.9773095846176147)
[2024-12-17 05:00:32,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:32,517][root][INFO] - Training Epoch: 2/2, step 2187/7134 completed (loss: 0.09840169548988342, acc: 0.9711999893188477)
[2024-12-17 05:00:32,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:32,969][root][INFO] - Training Epoch: 2/2, step 2188/7134 completed (loss: 0.021334810182452202, acc: 0.9904240965843201)
[2024-12-17 05:00:33,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:33,396][root][INFO] - Training Epoch: 2/2, step 2189/7134 completed (loss: 0.06933998316526413, acc: 0.9770641922950745)
[2024-12-17 05:00:33,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:33,847][root][INFO] - Training Epoch: 2/2, step 2190/7134 completed (loss: 0.04140806198120117, acc: 0.9881266355514526)
[2024-12-17 05:00:33,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:34,236][root][INFO] - Training Epoch: 2/2, step 2191/7134 completed (loss: 0.04261212423443794, acc: 0.989159882068634)
[2024-12-17 05:00:34,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:34,641][root][INFO] - Training Epoch: 2/2, step 2192/7134 completed (loss: 0.009669768624007702, acc: 0.9981167316436768)
[2024-12-17 05:00:34,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:35,089][root][INFO] - Training Epoch: 2/2, step 2193/7134 completed (loss: 0.03144659101963043, acc: 0.9920212626457214)
[2024-12-17 05:00:35,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:35,500][root][INFO] - Training Epoch: 2/2, step 2194/7134 completed (loss: 0.034742794930934906, acc: 0.9882746934890747)
[2024-12-17 05:00:35,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:35,930][root][INFO] - Training Epoch: 2/2, step 2195/7134 completed (loss: 0.028292477130889893, acc: 0.9919999837875366)
[2024-12-17 05:00:36,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:36,383][root][INFO] - Training Epoch: 2/2, step 2196/7134 completed (loss: 0.03810346499085426, acc: 0.9857512712478638)
[2024-12-17 05:00:36,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:36,780][root][INFO] - Training Epoch: 2/2, step 2197/7134 completed (loss: 0.03166000545024872, acc: 0.9908925294876099)
[2024-12-17 05:00:36,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:37,208][root][INFO] - Training Epoch: 2/2, step 2198/7134 completed (loss: 0.05328318476676941, acc: 0.9849170446395874)
[2024-12-17 05:00:37,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:37,639][root][INFO] - Training Epoch: 2/2, step 2199/7134 completed (loss: 0.016927622258663177, acc: 0.9939576983451843)
[2024-12-17 05:00:37,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:38,063][root][INFO] - Training Epoch: 2/2, step 2200/7134 completed (loss: 0.03270845115184784, acc: 0.9909583926200867)
[2024-12-17 05:00:38,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:38,508][root][INFO] - Training Epoch: 2/2, step 2201/7134 completed (loss: 0.01611645705997944, acc: 0.9924242496490479)
[2024-12-17 05:00:38,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:38,926][root][INFO] - Training Epoch: 2/2, step 2202/7134 completed (loss: 0.030359437689185143, acc: 0.989983320236206)
[2024-12-17 05:00:39,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:39,385][root][INFO] - Training Epoch: 2/2, step 2203/7134 completed (loss: 0.010832883417606354, acc: 0.9972602725028992)
[2024-12-17 05:00:39,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:39,804][root][INFO] - Training Epoch: 2/2, step 2204/7134 completed (loss: 0.017397671937942505, acc: 0.9912280440330505)
[2024-12-17 05:00:39,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:40,252][root][INFO] - Training Epoch: 2/2, step 2205/7134 completed (loss: 0.021084586158394814, acc: 0.9947368502616882)
[2024-12-17 05:00:40,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:40,704][root][INFO] - Training Epoch: 2/2, step 2206/7134 completed (loss: 0.06382014602422714, acc: 0.9894551634788513)
[2024-12-17 05:00:40,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:41,136][root][INFO] - Training Epoch: 2/2, step 2207/7134 completed (loss: 0.029728157445788383, acc: 0.9903069734573364)
[2024-12-17 05:00:41,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:41,552][root][INFO] - Training Epoch: 2/2, step 2208/7134 completed (loss: 0.053780823945999146, acc: 0.9884297251701355)
[2024-12-17 05:00:41,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:41,980][root][INFO] - Training Epoch: 2/2, step 2209/7134 completed (loss: 0.040951307862997055, acc: 0.9900990128517151)
[2024-12-17 05:00:42,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:42,389][root][INFO] - Training Epoch: 2/2, step 2210/7134 completed (loss: 0.051767073571681976, acc: 0.9863429665565491)
[2024-12-17 05:00:42,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:42,842][root][INFO] - Training Epoch: 2/2, step 2211/7134 completed (loss: 0.03071729838848114, acc: 0.9930747747421265)
[2024-12-17 05:00:42,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:43,271][root][INFO] - Training Epoch: 2/2, step 2212/7134 completed (loss: 0.01124073937535286, acc: 0.9972222447395325)
[2024-12-17 05:00:43,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:43,703][root][INFO] - Training Epoch: 2/2, step 2213/7134 completed (loss: 0.02897373028099537, acc: 0.9901130199432373)
[2024-12-17 05:00:43,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:44,135][root][INFO] - Training Epoch: 2/2, step 2214/7134 completed (loss: 0.033597432076931, acc: 0.9880596995353699)
[2024-12-17 05:00:44,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:44,550][root][INFO] - Training Epoch: 2/2, step 2215/7134 completed (loss: 0.02423013187944889, acc: 0.992977499961853)
[2024-12-17 05:00:44,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:44,990][root][INFO] - Training Epoch: 2/2, step 2216/7134 completed (loss: 0.01441594585776329, acc: 0.9959946870803833)
[2024-12-17 05:00:45,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:45,427][root][INFO] - Training Epoch: 2/2, step 2217/7134 completed (loss: 0.02897278033196926, acc: 0.9925280213356018)
[2024-12-17 05:00:45,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:45,827][root][INFO] - Training Epoch: 2/2, step 2218/7134 completed (loss: 0.03777828812599182, acc: 0.9928160905838013)
[2024-12-17 05:00:45,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:46,230][root][INFO] - Training Epoch: 2/2, step 2219/7134 completed (loss: 0.02043868415057659, acc: 0.9922720193862915)
[2024-12-17 05:00:46,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:46,636][root][INFO] - Training Epoch: 2/2, step 2220/7134 completed (loss: 0.014952197670936584, acc: 0.9952830076217651)
[2024-12-17 05:00:46,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:47,105][root][INFO] - Training Epoch: 2/2, step 2221/7134 completed (loss: 0.019561536610126495, acc: 0.9974026083946228)
[2024-12-17 05:00:47,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:47,532][root][INFO] - Training Epoch: 2/2, step 2222/7134 completed (loss: 0.033538296818733215, acc: 0.9884393215179443)
[2024-12-17 05:00:47,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:47,953][root][INFO] - Training Epoch: 2/2, step 2223/7134 completed (loss: 0.03318722918629646, acc: 0.991631805896759)
[2024-12-17 05:00:48,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:48,410][root][INFO] - Training Epoch: 2/2, step 2224/7134 completed (loss: 0.02825143001973629, acc: 0.9890260696411133)
[2024-12-17 05:00:48,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:48,832][root][INFO] - Training Epoch: 2/2, step 2225/7134 completed (loss: 0.019025884568691254, acc: 0.9942113161087036)
[2024-12-17 05:00:48,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:49,260][root][INFO] - Training Epoch: 2/2, step 2226/7134 completed (loss: 0.02650967240333557, acc: 0.990867555141449)
[2024-12-17 05:00:49,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:49,675][root][INFO] - Training Epoch: 2/2, step 2227/7134 completed (loss: 0.017824694514274597, acc: 0.9941434860229492)
[2024-12-17 05:00:49,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:50,091][root][INFO] - Training Epoch: 2/2, step 2228/7134 completed (loss: 0.01350559014827013, acc: 0.9983739852905273)
[2024-12-17 05:00:50,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:50,532][root][INFO] - Training Epoch: 2/2, step 2229/7134 completed (loss: 0.02736281231045723, acc: 0.9940000176429749)
[2024-12-17 05:00:50,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:50,950][root][INFO] - Training Epoch: 2/2, step 2230/7134 completed (loss: 0.01792246103286743, acc: 0.9967637658119202)
[2024-12-17 05:00:51,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:51,350][root][INFO] - Training Epoch: 2/2, step 2231/7134 completed (loss: 0.03830079734325409, acc: 0.9840637445449829)
[2024-12-17 05:00:51,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:51,801][root][INFO] - Training Epoch: 2/2, step 2232/7134 completed (loss: 0.00965949147939682, acc: 0.9973261952400208)
[2024-12-17 05:00:51,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:52,223][root][INFO] - Training Epoch: 2/2, step 2233/7134 completed (loss: 0.031292565166950226, acc: 0.9900426864624023)
[2024-12-17 05:00:52,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:52,691][root][INFO] - Training Epoch: 2/2, step 2234/7134 completed (loss: 0.010334646329283714, acc: 0.9959016442298889)
[2024-12-17 05:00:52,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:53,129][root][INFO] - Training Epoch: 2/2, step 2235/7134 completed (loss: 0.03731862083077431, acc: 0.9921630024909973)
[2024-12-17 05:00:53,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:53,548][root][INFO] - Training Epoch: 2/2, step 2236/7134 completed (loss: 0.027001773938536644, acc: 0.9910045266151428)
[2024-12-17 05:00:53,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:53,996][root][INFO] - Training Epoch: 2/2, step 2237/7134 completed (loss: 0.04129216820001602, acc: 0.987270176410675)
[2024-12-17 05:00:54,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:54,493][root][INFO] - Training Epoch: 2/2, step 2238/7134 completed (loss: 0.07565683871507645, acc: 0.9840810298919678)
[2024-12-17 05:00:54,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:54,956][root][INFO] - Training Epoch: 2/2, step 2239/7134 completed (loss: 0.09683036059141159, acc: 0.9740259647369385)
[2024-12-17 05:00:55,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:55,404][root][INFO] - Training Epoch: 2/2, step 2240/7134 completed (loss: 0.041380710899829865, acc: 0.9922077655792236)
[2024-12-17 05:00:55,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:55,836][root][INFO] - Training Epoch: 2/2, step 2241/7134 completed (loss: 0.09127845615148544, acc: 0.9763593673706055)
[2024-12-17 05:00:55,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:56,273][root][INFO] - Training Epoch: 2/2, step 2242/7134 completed (loss: 0.11849257349967957, acc: 0.9619952440261841)
[2024-12-17 05:00:56,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:56,748][root][INFO] - Training Epoch: 2/2, step 2243/7134 completed (loss: 0.11424891650676727, acc: 0.9633587598800659)
[2024-12-17 05:00:56,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:57,203][root][INFO] - Training Epoch: 2/2, step 2244/7134 completed (loss: 0.030786646530032158, acc: 0.9905660152435303)
[2024-12-17 05:00:57,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:57,627][root][INFO] - Training Epoch: 2/2, step 2245/7134 completed (loss: 0.0762629434466362, acc: 0.9724919199943542)
[2024-12-17 05:00:57,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:58,080][root][INFO] - Training Epoch: 2/2, step 2246/7134 completed (loss: 0.11552082747220993, acc: 0.9675675630569458)
[2024-12-17 05:00:58,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:58,501][root][INFO] - Training Epoch: 2/2, step 2247/7134 completed (loss: 0.09545975923538208, acc: 0.9683908224105835)
[2024-12-17 05:00:58,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:58,939][root][INFO] - Training Epoch: 2/2, step 2248/7134 completed (loss: 0.06338611245155334, acc: 0.9847856163978577)
[2024-12-17 05:00:59,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:59,394][root][INFO] - Training Epoch: 2/2, step 2249/7134 completed (loss: 0.04479953646659851, acc: 0.9888268113136292)
[2024-12-17 05:00:59,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:00:59,835][root][INFO] - Training Epoch: 2/2, step 2250/7134 completed (loss: 0.05622468888759613, acc: 0.9826202988624573)
[2024-12-17 05:00:59,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:00,250][root][INFO] - Training Epoch: 2/2, step 2251/7134 completed (loss: 0.04793258011341095, acc: 0.9863945841789246)
[2024-12-17 05:01:00,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:00,666][root][INFO] - Training Epoch: 2/2, step 2252/7134 completed (loss: 0.05995224043726921, acc: 0.9803921580314636)
[2024-12-17 05:01:00,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:01,077][root][INFO] - Training Epoch: 2/2, step 2253/7134 completed (loss: 0.03858160972595215, acc: 0.9899665713310242)
[2024-12-17 05:01:01,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:01,503][root][INFO] - Training Epoch: 2/2, step 2254/7134 completed (loss: 0.10798421502113342, acc: 0.9681274890899658)
[2024-12-17 05:01:01,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:01,948][root][INFO] - Training Epoch: 2/2, step 2255/7134 completed (loss: 0.03818535804748535, acc: 0.987860381603241)
[2024-12-17 05:01:02,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:02,324][root][INFO] - Training Epoch: 2/2, step 2256/7134 completed (loss: 0.09261959791183472, acc: 0.9690265655517578)
[2024-12-17 05:01:02,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:02,743][root][INFO] - Training Epoch: 2/2, step 2257/7134 completed (loss: 0.04078592360019684, acc: 0.9894259572029114)
[2024-12-17 05:01:02,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:03,168][root][INFO] - Training Epoch: 2/2, step 2258/7134 completed (loss: 0.029507797211408615, acc: 0.9923076629638672)
[2024-12-17 05:01:03,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:03,584][root][INFO] - Training Epoch: 2/2, step 2259/7134 completed (loss: 0.03367447480559349, acc: 0.9888888597488403)
[2024-12-17 05:01:03,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:04,006][root][INFO] - Training Epoch: 2/2, step 2260/7134 completed (loss: 0.057053547352552414, acc: 0.9863636493682861)
[2024-12-17 05:01:04,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:04,390][root][INFO] - Training Epoch: 2/2, step 2261/7134 completed (loss: 0.09747565537691116, acc: 0.970802903175354)
[2024-12-17 05:01:04,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:04,806][root][INFO] - Training Epoch: 2/2, step 2262/7134 completed (loss: 0.025272784754633904, acc: 0.9944751262664795)
[2024-12-17 05:01:04,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:05,231][root][INFO] - Training Epoch: 2/2, step 2263/7134 completed (loss: 0.06154940649867058, acc: 0.9819819927215576)
[2024-12-17 05:01:05,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:05,646][root][INFO] - Training Epoch: 2/2, step 2264/7134 completed (loss: 0.0738820880651474, acc: 0.9732770919799805)
[2024-12-17 05:01:05,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:06,080][root][INFO] - Training Epoch: 2/2, step 2265/7134 completed (loss: 0.08445912599563599, acc: 0.9742268323898315)
[2024-12-17 05:01:06,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:06,517][root][INFO] - Training Epoch: 2/2, step 2266/7134 completed (loss: 0.04480453580617905, acc: 0.989276111125946)
[2024-12-17 05:01:06,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:06,940][root][INFO] - Training Epoch: 2/2, step 2267/7134 completed (loss: 0.02039490081369877, acc: 0.9938271641731262)
[2024-12-17 05:01:07,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:07,395][root][INFO] - Training Epoch: 2/2, step 2268/7134 completed (loss: 0.02477523870766163, acc: 0.9928264021873474)
[2024-12-17 05:01:07,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:07,855][root][INFO] - Training Epoch: 2/2, step 2269/7134 completed (loss: 0.028398582711815834, acc: 0.9911949634552002)
[2024-12-17 05:01:07,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:08,289][root][INFO] - Training Epoch: 2/2, step 2270/7134 completed (loss: 0.06634506583213806, acc: 0.9800994992256165)
[2024-12-17 05:01:08,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:08,786][root][INFO] - Training Epoch: 2/2, step 2271/7134 completed (loss: 0.040415577590465546, acc: 0.9861910343170166)
[2024-12-17 05:01:08,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:09,236][root][INFO] - Training Epoch: 2/2, step 2272/7134 completed (loss: 0.034384872764348984, acc: 0.9938875436782837)
[2024-12-17 05:01:09,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:09,677][root][INFO] - Training Epoch: 2/2, step 2273/7134 completed (loss: 0.011554444208741188, acc: 0.9976047873497009)
[2024-12-17 05:01:09,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:10,126][root][INFO] - Training Epoch: 2/2, step 2274/7134 completed (loss: 0.0963052436709404, acc: 0.9808917045593262)
[2024-12-17 05:01:10,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:10,571][root][INFO] - Training Epoch: 2/2, step 2275/7134 completed (loss: 0.034673575311899185, acc: 0.9906103014945984)
[2024-12-17 05:01:10,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:11,026][root][INFO] - Training Epoch: 2/2, step 2276/7134 completed (loss: 0.04499002546072006, acc: 0.9893364906311035)
[2024-12-17 05:01:11,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:11,483][root][INFO] - Training Epoch: 2/2, step 2277/7134 completed (loss: 0.03886070102453232, acc: 0.9872978925704956)
[2024-12-17 05:01:11,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:11,922][root][INFO] - Training Epoch: 2/2, step 2278/7134 completed (loss: 0.08734174072742462, acc: 0.9792332053184509)
[2024-12-17 05:01:12,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:12,378][root][INFO] - Training Epoch: 2/2, step 2279/7134 completed (loss: 0.03787926957011223, acc: 0.990554928779602)
[2024-12-17 05:01:12,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:12,855][root][INFO] - Training Epoch: 2/2, step 2280/7134 completed (loss: 0.05468457564711571, acc: 0.9893742799758911)
[2024-12-17 05:01:12,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:13,279][root][INFO] - Training Epoch: 2/2, step 2281/7134 completed (loss: 0.08929744362831116, acc: 0.984000027179718)
[2024-12-17 05:01:13,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:13,737][root][INFO] - Training Epoch: 2/2, step 2282/7134 completed (loss: 0.018045369535684586, acc: 0.995055615901947)
[2024-12-17 05:01:13,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:14,191][root][INFO] - Training Epoch: 2/2, step 2283/7134 completed (loss: 0.03160664066672325, acc: 0.9914425611495972)
[2024-12-17 05:01:14,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:14,636][root][INFO] - Training Epoch: 2/2, step 2284/7134 completed (loss: 0.03664129599928856, acc: 0.9881831407546997)
[2024-12-17 05:01:14,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:15,122][root][INFO] - Training Epoch: 2/2, step 2285/7134 completed (loss: 0.020415976643562317, acc: 0.9966555237770081)
[2024-12-17 05:01:15,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:15,569][root][INFO] - Training Epoch: 2/2, step 2286/7134 completed (loss: 0.04902025684714317, acc: 0.9818417429924011)
[2024-12-17 05:01:15,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:16,036][root][INFO] - Training Epoch: 2/2, step 2287/7134 completed (loss: 0.02859392762184143, acc: 0.989276111125946)
[2024-12-17 05:01:16,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:16,502][root][INFO] - Training Epoch: 2/2, step 2288/7134 completed (loss: 0.04174979031085968, acc: 0.9905771613121033)
[2024-12-17 05:01:16,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:16,924][root][INFO] - Training Epoch: 2/2, step 2289/7134 completed (loss: 0.056282710283994675, acc: 0.9833119511604309)
[2024-12-17 05:01:17,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:17,358][root][INFO] - Training Epoch: 2/2, step 2290/7134 completed (loss: 0.031973544508218765, acc: 0.9910827875137329)
[2024-12-17 05:01:17,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:17,804][root][INFO] - Training Epoch: 2/2, step 2291/7134 completed (loss: 0.055471185594797134, acc: 0.9824561476707458)
[2024-12-17 05:01:17,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:18,246][root][INFO] - Training Epoch: 2/2, step 2292/7134 completed (loss: 0.05938878655433655, acc: 0.9819355010986328)
[2024-12-17 05:01:18,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:18,718][root][INFO] - Training Epoch: 2/2, step 2293/7134 completed (loss: 0.04846208915114403, acc: 0.9888641238212585)
[2024-12-17 05:01:18,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:19,171][root][INFO] - Training Epoch: 2/2, step 2294/7134 completed (loss: 0.04828944429755211, acc: 0.9853768348693848)
[2024-12-17 05:01:19,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:19,685][root][INFO] - Training Epoch: 2/2, step 2295/7134 completed (loss: 0.03996313363313675, acc: 0.9905033111572266)
[2024-12-17 05:01:19,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:20,156][root][INFO] - Training Epoch: 2/2, step 2296/7134 completed (loss: 0.02105088159441948, acc: 0.992553174495697)
[2024-12-17 05:01:20,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:20,636][root][INFO] - Training Epoch: 2/2, step 2297/7134 completed (loss: 0.025611961260437965, acc: 0.9908536672592163)
[2024-12-17 05:01:20,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:21,079][root][INFO] - Training Epoch: 2/2, step 2298/7134 completed (loss: 0.0551426038146019, acc: 0.9884332418441772)
[2024-12-17 05:01:21,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:21,574][root][INFO] - Training Epoch: 2/2, step 2299/7134 completed (loss: 0.03147305175662041, acc: 0.9931740760803223)
[2024-12-17 05:01:21,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:22,044][root][INFO] - Training Epoch: 2/2, step 2300/7134 completed (loss: 0.01396926585584879, acc: 0.9977452158927917)
[2024-12-17 05:01:22,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:22,508][root][INFO] - Training Epoch: 2/2, step 2301/7134 completed (loss: 0.03070211596786976, acc: 0.9920529723167419)
[2024-12-17 05:01:22,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:22,974][root][INFO] - Training Epoch: 2/2, step 2302/7134 completed (loss: 0.057902175933122635, acc: 0.9816176295280457)
[2024-12-17 05:01:23,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:23,405][root][INFO] - Training Epoch: 2/2, step 2303/7134 completed (loss: 0.02856980636715889, acc: 0.9886105060577393)
[2024-12-17 05:01:23,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:23,879][root][INFO] - Training Epoch: 2/2, step 2304/7134 completed (loss: 0.05256330221891403, acc: 0.9866392612457275)
[2024-12-17 05:01:24,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:24,353][root][INFO] - Training Epoch: 2/2, step 2305/7134 completed (loss: 0.022391298785805702, acc: 0.9904153347015381)
[2024-12-17 05:01:24,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:24,803][root][INFO] - Training Epoch: 2/2, step 2306/7134 completed (loss: 0.023184217512607574, acc: 0.9933481216430664)
[2024-12-17 05:01:24,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:25,276][root][INFO] - Training Epoch: 2/2, step 2307/7134 completed (loss: 0.03886277228593826, acc: 0.9917355179786682)
[2024-12-17 05:01:25,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:25,738][root][INFO] - Training Epoch: 2/2, step 2308/7134 completed (loss: 0.04255210980772972, acc: 0.9908069372177124)
[2024-12-17 05:01:25,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:26,172][root][INFO] - Training Epoch: 2/2, step 2309/7134 completed (loss: 0.02623399719595909, acc: 0.9928057789802551)
[2024-12-17 05:01:26,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:26,624][root][INFO] - Training Epoch: 2/2, step 2310/7134 completed (loss: 0.02696172706782818, acc: 0.989830493927002)
[2024-12-17 05:01:26,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:27,068][root][INFO] - Training Epoch: 2/2, step 2311/7134 completed (loss: 0.02647579461336136, acc: 0.9919725060462952)
[2024-12-17 05:01:27,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:27,558][root][INFO] - Training Epoch: 2/2, step 2312/7134 completed (loss: 0.020066319033503532, acc: 0.9956803321838379)
[2024-12-17 05:01:27,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:28,004][root][INFO] - Training Epoch: 2/2, step 2313/7134 completed (loss: 0.05202824994921684, acc: 0.9863013625144958)
[2024-12-17 05:01:28,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:28,485][root][INFO] - Training Epoch: 2/2, step 2314/7134 completed (loss: 0.03004900924861431, acc: 0.9911209940910339)
[2024-12-17 05:01:28,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:28,954][root][INFO] - Training Epoch: 2/2, step 2315/7134 completed (loss: 0.025053290650248528, acc: 0.9941176176071167)
[2024-12-17 05:01:29,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:29,402][root][INFO] - Training Epoch: 2/2, step 2316/7134 completed (loss: 0.018704799935221672, acc: 0.9965477585792542)
[2024-12-17 05:01:29,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:29,875][root][INFO] - Training Epoch: 2/2, step 2317/7134 completed (loss: 0.034545641392469406, acc: 0.9925925731658936)
[2024-12-17 05:01:30,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:30,346][root][INFO] - Training Epoch: 2/2, step 2318/7134 completed (loss: 0.018286239355802536, acc: 0.9947698712348938)
[2024-12-17 05:01:30,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:30,814][root][INFO] - Training Epoch: 2/2, step 2319/7134 completed (loss: 0.022197533398866653, acc: 0.9923413395881653)
[2024-12-17 05:01:30,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:31,293][root][INFO] - Training Epoch: 2/2, step 2320/7134 completed (loss: 0.025568032637238503, acc: 0.987500011920929)
[2024-12-17 05:01:31,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:31,718][root][INFO] - Training Epoch: 2/2, step 2321/7134 completed (loss: 0.018385324627161026, acc: 0.9916666746139526)
[2024-12-17 05:01:31,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:32,159][root][INFO] - Training Epoch: 2/2, step 2322/7134 completed (loss: 0.02481687255203724, acc: 0.9881481528282166)
[2024-12-17 05:01:32,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:32,586][root][INFO] - Training Epoch: 2/2, step 2323/7134 completed (loss: 0.035613756626844406, acc: 0.9858044385910034)
[2024-12-17 05:01:32,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:33,036][root][INFO] - Training Epoch: 2/2, step 2324/7134 completed (loss: 0.05258484557271004, acc: 0.9871794581413269)
[2024-12-17 05:01:33,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:33,490][root][INFO] - Training Epoch: 2/2, step 2325/7134 completed (loss: 0.038398124277591705, acc: 0.9897435903549194)
[2024-12-17 05:01:33,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:33,904][root][INFO] - Training Epoch: 2/2, step 2326/7134 completed (loss: 0.011659981682896614, acc: 0.9963235259056091)
[2024-12-17 05:01:34,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:34,321][root][INFO] - Training Epoch: 2/2, step 2327/7134 completed (loss: 0.010756474919617176, acc: 0.9983606338500977)
[2024-12-17 05:01:34,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:34,742][root][INFO] - Training Epoch: 2/2, step 2328/7134 completed (loss: 0.07445386052131653, acc: 0.9820788502693176)
[2024-12-17 05:01:34,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:35,164][root][INFO] - Training Epoch: 2/2, step 2329/7134 completed (loss: 0.035211626440286636, acc: 0.9968992471694946)
[2024-12-17 05:01:35,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:35,583][root][INFO] - Training Epoch: 2/2, step 2330/7134 completed (loss: 0.011855821125209332, acc: 0.9969465732574463)
[2024-12-17 05:01:35,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:36,008][root][INFO] - Training Epoch: 2/2, step 2331/7134 completed (loss: 0.013007950969040394, acc: 0.995398759841919)
[2024-12-17 05:01:36,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:36,433][root][INFO] - Training Epoch: 2/2, step 2332/7134 completed (loss: 0.034242261201143265, acc: 0.9955423474311829)
[2024-12-17 05:01:36,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:36,854][root][INFO] - Training Epoch: 2/2, step 2333/7134 completed (loss: 0.015266118571162224, acc: 0.9970238208770752)
[2024-12-17 05:01:36,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:37,275][root][INFO] - Training Epoch: 2/2, step 2334/7134 completed (loss: 0.017736034467816353, acc: 0.9910447597503662)
[2024-12-17 05:01:37,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:37,719][root][INFO] - Training Epoch: 2/2, step 2335/7134 completed (loss: 0.030559970065951347, acc: 0.9919354915618896)
[2024-12-17 05:01:37,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:38,149][root][INFO] - Training Epoch: 2/2, step 2336/7134 completed (loss: 0.010296696797013283, acc: 0.9984543919563293)
[2024-12-17 05:01:38,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:38,565][root][INFO] - Training Epoch: 2/2, step 2337/7134 completed (loss: 0.0035657717380672693, acc: 1.0)
[2024-12-17 05:01:38,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:38,991][root][INFO] - Training Epoch: 2/2, step 2338/7134 completed (loss: 0.019595885649323463, acc: 0.9953632354736328)
[2024-12-17 05:01:39,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:39,406][root][INFO] - Training Epoch: 2/2, step 2339/7134 completed (loss: 0.044193219393491745, acc: 0.9869494438171387)
[2024-12-17 05:01:39,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:39,834][root][INFO] - Training Epoch: 2/2, step 2340/7134 completed (loss: 0.01594589836895466, acc: 0.9969834089279175)
[2024-12-17 05:01:39,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:40,255][root][INFO] - Training Epoch: 2/2, step 2341/7134 completed (loss: 0.009283716790378094, acc: 0.9981203079223633)
[2024-12-17 05:01:40,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:40,663][root][INFO] - Training Epoch: 2/2, step 2342/7134 completed (loss: 0.01922522857785225, acc: 0.9911373853683472)
[2024-12-17 05:01:40,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:41,068][root][INFO] - Training Epoch: 2/2, step 2343/7134 completed (loss: 0.0158548541367054, acc: 0.995199978351593)
[2024-12-17 05:01:41,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:41,494][root][INFO] - Training Epoch: 2/2, step 2344/7134 completed (loss: 0.009610970504581928, acc: 0.9968701004981995)
[2024-12-17 05:01:41,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:41,929][root][INFO] - Training Epoch: 2/2, step 2345/7134 completed (loss: 0.013548948802053928, acc: 0.9944055676460266)
[2024-12-17 05:01:42,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:42,374][root][INFO] - Training Epoch: 2/2, step 2346/7134 completed (loss: 0.015673968940973282, acc: 0.9957507252693176)
[2024-12-17 05:01:42,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:42,805][root][INFO] - Training Epoch: 2/2, step 2347/7134 completed (loss: 0.061992913484573364, acc: 0.9901315569877625)
[2024-12-17 05:01:42,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:43,255][root][INFO] - Training Epoch: 2/2, step 2348/7134 completed (loss: 0.07284196466207504, acc: 0.9798234701156616)
[2024-12-17 05:01:43,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:43,696][root][INFO] - Training Epoch: 2/2, step 2349/7134 completed (loss: 0.04205404222011566, acc: 0.9902777671813965)
[2024-12-17 05:01:43,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:44,141][root][INFO] - Training Epoch: 2/2, step 2350/7134 completed (loss: 0.07681926339864731, acc: 0.9786585569381714)
[2024-12-17 05:01:44,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:44,613][root][INFO] - Training Epoch: 2/2, step 2351/7134 completed (loss: 0.06445987522602081, acc: 0.9822404384613037)
[2024-12-17 05:01:44,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:45,028][root][INFO] - Training Epoch: 2/2, step 2352/7134 completed (loss: 0.03381524980068207, acc: 0.9887820482254028)
[2024-12-17 05:01:45,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:45,477][root][INFO] - Training Epoch: 2/2, step 2353/7134 completed (loss: 0.05889067053794861, acc: 0.9886524677276611)
[2024-12-17 05:01:45,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:45,916][root][INFO] - Training Epoch: 2/2, step 2354/7134 completed (loss: 0.0315682478249073, acc: 0.9873417615890503)
[2024-12-17 05:01:46,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:46,354][root][INFO] - Training Epoch: 2/2, step 2355/7134 completed (loss: 0.04483552649617195, acc: 0.9864197373390198)
[2024-12-17 05:01:46,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:46,767][root][INFO] - Training Epoch: 2/2, step 2356/7134 completed (loss: 0.05597081780433655, acc: 0.9805653691291809)
[2024-12-17 05:01:46,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:47,183][root][INFO] - Training Epoch: 2/2, step 2357/7134 completed (loss: 0.055899474769830704, acc: 0.9801587462425232)
[2024-12-17 05:01:47,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:47,651][root][INFO] - Training Epoch: 2/2, step 2358/7134 completed (loss: 0.06244345381855965, acc: 0.9855421781539917)
[2024-12-17 05:01:47,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:48,069][root][INFO] - Training Epoch: 2/2, step 2359/7134 completed (loss: 0.04691125079989433, acc: 0.9838472604751587)
[2024-12-17 05:01:48,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:48,530][root][INFO] - Training Epoch: 2/2, step 2360/7134 completed (loss: 0.023766033351421356, acc: 0.9926793575286865)
[2024-12-17 05:01:48,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:48,956][root][INFO] - Training Epoch: 2/2, step 2361/7134 completed (loss: 0.03929274529218674, acc: 0.9881656765937805)
[2024-12-17 05:01:49,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:49,328][root][INFO] - Training Epoch: 2/2, step 2362/7134 completed (loss: 0.04394995793700218, acc: 0.9843049049377441)
[2024-12-17 05:01:49,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:49,810][root][INFO] - Training Epoch: 2/2, step 2363/7134 completed (loss: 0.053865909576416016, acc: 0.9849362969398499)
[2024-12-17 05:01:49,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:50,226][root][INFO] - Training Epoch: 2/2, step 2364/7134 completed (loss: 0.024570563808083534, acc: 0.9893454909324646)
[2024-12-17 05:01:50,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:50,656][root][INFO] - Training Epoch: 2/2, step 2365/7134 completed (loss: 0.023010211065411568, acc: 0.994490385055542)
[2024-12-17 05:01:50,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:51,100][root][INFO] - Training Epoch: 2/2, step 2366/7134 completed (loss: 0.018172957003116608, acc: 0.9953703880310059)
[2024-12-17 05:01:51,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:51,592][root][INFO] - Training Epoch: 2/2, step 2367/7134 completed (loss: 0.05549588054418564, acc: 0.9899497628211975)
[2024-12-17 05:01:51,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:52,056][root][INFO] - Training Epoch: 2/2, step 2368/7134 completed (loss: 0.027033774182200432, acc: 0.9927272796630859)
[2024-12-17 05:01:52,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:52,506][root][INFO] - Training Epoch: 2/2, step 2369/7134 completed (loss: 0.01429707370698452, acc: 0.9976470470428467)
[2024-12-17 05:01:52,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:52,929][root][INFO] - Training Epoch: 2/2, step 2370/7134 completed (loss: 0.027059458196163177, acc: 0.9969135522842407)
[2024-12-17 05:01:53,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:53,394][root][INFO] - Training Epoch: 2/2, step 2371/7134 completed (loss: 0.03361654281616211, acc: 0.9927954077720642)
[2024-12-17 05:01:53,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:53,845][root][INFO] - Training Epoch: 2/2, step 2372/7134 completed (loss: 0.023471809923648834, acc: 0.9931972622871399)
[2024-12-17 05:01:53,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:54,272][root][INFO] - Training Epoch: 2/2, step 2373/7134 completed (loss: 0.01296420767903328, acc: 0.996277928352356)
[2024-12-17 05:01:54,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:54,711][root][INFO] - Training Epoch: 2/2, step 2374/7134 completed (loss: 0.021477647125720978, acc: 0.9946452379226685)
[2024-12-17 05:01:54,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:55,176][root][INFO] - Training Epoch: 2/2, step 2375/7134 completed (loss: 0.041379887610673904, acc: 0.9878787994384766)
[2024-12-17 05:01:55,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:55,616][root][INFO] - Training Epoch: 2/2, step 2376/7134 completed (loss: 0.09918992966413498, acc: 0.9693356156349182)
[2024-12-17 05:01:55,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:56,063][root][INFO] - Training Epoch: 2/2, step 2377/7134 completed (loss: 0.06909458339214325, acc: 0.9832736253738403)
[2024-12-17 05:01:56,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:56,501][root][INFO] - Training Epoch: 2/2, step 2378/7134 completed (loss: 0.0538199357688427, acc: 0.98591548204422)
[2024-12-17 05:01:56,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:56,952][root][INFO] - Training Epoch: 2/2, step 2379/7134 completed (loss: 0.10340375453233719, acc: 0.9710344672203064)
[2024-12-17 05:01:57,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:57,414][root][INFO] - Training Epoch: 2/2, step 2380/7134 completed (loss: 0.04901014268398285, acc: 0.984280526638031)
[2024-12-17 05:01:57,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:57,797][root][INFO] - Training Epoch: 2/2, step 2381/7134 completed (loss: 0.10850151628255844, acc: 0.9746192693710327)
[2024-12-17 05:01:57,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:58,222][root][INFO] - Training Epoch: 2/2, step 2382/7134 completed (loss: 0.050380367785692215, acc: 0.9877675771713257)
[2024-12-17 05:01:58,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:58,653][root][INFO] - Training Epoch: 2/2, step 2383/7134 completed (loss: 0.09755367040634155, acc: 0.9758672714233398)
[2024-12-17 05:01:58,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:59,080][root][INFO] - Training Epoch: 2/2, step 2384/7134 completed (loss: 0.07813283801078796, acc: 0.9816993474960327)
[2024-12-17 05:01:59,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:59,535][root][INFO] - Training Epoch: 2/2, step 2385/7134 completed (loss: 0.03208980709314346, acc: 0.9875690340995789)
[2024-12-17 05:01:59,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:01:59,968][root][INFO] - Training Epoch: 2/2, step 2386/7134 completed (loss: 0.043214838951826096, acc: 0.9869109988212585)
[2024-12-17 05:02:00,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:00,450][root][INFO] - Training Epoch: 2/2, step 2387/7134 completed (loss: 0.055778902024030685, acc: 0.9849187731742859)
[2024-12-17 05:02:00,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:00,907][root][INFO] - Training Epoch: 2/2, step 2388/7134 completed (loss: 0.09972972422838211, acc: 0.9737783074378967)
[2024-12-17 05:02:01,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:01,444][root][INFO] - Training Epoch: 2/2, step 2389/7134 completed (loss: 0.055529527366161346, acc: 0.9793341159820557)
[2024-12-17 05:02:01,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:01,894][root][INFO] - Training Epoch: 2/2, step 2390/7134 completed (loss: 0.0677063837647438, acc: 0.979689359664917)
[2024-12-17 05:02:02,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:02,333][root][INFO] - Training Epoch: 2/2, step 2391/7134 completed (loss: 0.07332076132297516, acc: 0.9783989787101746)
[2024-12-17 05:02:02,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:02,772][root][INFO] - Training Epoch: 2/2, step 2392/7134 completed (loss: 0.03786497935652733, acc: 0.9879840016365051)
[2024-12-17 05:02:02,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:03,207][root][INFO] - Training Epoch: 2/2, step 2393/7134 completed (loss: 0.05663083866238594, acc: 0.9844357967376709)
[2024-12-17 05:02:03,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:03,664][root][INFO] - Training Epoch: 2/2, step 2394/7134 completed (loss: 0.03861941397190094, acc: 0.9878787994384766)
[2024-12-17 05:02:03,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:04,089][root][INFO] - Training Epoch: 2/2, step 2395/7134 completed (loss: 0.15999506413936615, acc: 0.965798020362854)
[2024-12-17 05:02:04,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:04,554][root][INFO] - Training Epoch: 2/2, step 2396/7134 completed (loss: 0.07878144830465317, acc: 0.9724518060684204)
[2024-12-17 05:02:04,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:04,979][root][INFO] - Training Epoch: 2/2, step 2397/7134 completed (loss: 0.08908668905496597, acc: 0.9752547144889832)
[2024-12-17 05:02:05,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:05,423][root][INFO] - Training Epoch: 2/2, step 2398/7134 completed (loss: 0.029667338356375694, acc: 0.9889958500862122)
[2024-12-17 05:02:05,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:05,864][root][INFO] - Training Epoch: 2/2, step 2399/7134 completed (loss: 0.07762325555086136, acc: 0.9771101474761963)
[2024-12-17 05:02:06,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:06,328][root][INFO] - Training Epoch: 2/2, step 2400/7134 completed (loss: 0.03216991573572159, acc: 0.9875862002372742)
[2024-12-17 05:02:06,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:06,745][root][INFO] - Training Epoch: 2/2, step 2401/7134 completed (loss: 0.10669097304344177, acc: 0.969936728477478)
[2024-12-17 05:02:06,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:07,177][root][INFO] - Training Epoch: 2/2, step 2402/7134 completed (loss: 0.06644733995199203, acc: 0.9774236679077148)
[2024-12-17 05:02:07,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:07,611][root][INFO] - Training Epoch: 2/2, step 2403/7134 completed (loss: 0.04238301143050194, acc: 0.9843971729278564)
[2024-12-17 05:02:07,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:08,029][root][INFO] - Training Epoch: 2/2, step 2404/7134 completed (loss: 0.029982013627886772, acc: 0.9918032884597778)
[2024-12-17 05:02:08,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:08,478][root][INFO] - Training Epoch: 2/2, step 2405/7134 completed (loss: 0.06553895771503448, acc: 0.9715719223022461)
[2024-12-17 05:02:08,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:08,899][root][INFO] - Training Epoch: 2/2, step 2406/7134 completed (loss: 0.019983265548944473, acc: 0.9906914830207825)
[2024-12-17 05:02:08,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:09,342][root][INFO] - Training Epoch: 2/2, step 2407/7134 completed (loss: 0.04895247891545296, acc: 0.9848024249076843)
[2024-12-17 05:02:09,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:09,784][root][INFO] - Training Epoch: 2/2, step 2408/7134 completed (loss: 0.11660773307085037, acc: 0.9697368144989014)
[2024-12-17 05:02:09,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:10,225][root][INFO] - Training Epoch: 2/2, step 2409/7134 completed (loss: 0.0495276153087616, acc: 0.9822404384613037)
[2024-12-17 05:02:10,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:10,679][root][INFO] - Training Epoch: 2/2, step 2410/7134 completed (loss: 0.0368921272456646, acc: 0.9842180609703064)
[2024-12-17 05:02:10,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:11,117][root][INFO] - Training Epoch: 2/2, step 2411/7134 completed (loss: 0.0320027731359005, acc: 0.9922380447387695)
[2024-12-17 05:02:11,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:11,549][root][INFO] - Training Epoch: 2/2, step 2412/7134 completed (loss: 0.0334930345416069, acc: 0.9897435903549194)
[2024-12-17 05:02:11,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:11,989][root][INFO] - Training Epoch: 2/2, step 2413/7134 completed (loss: 0.018992161378264427, acc: 0.9936467409133911)
[2024-12-17 05:02:12,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:12,450][root][INFO] - Training Epoch: 2/2, step 2414/7134 completed (loss: 0.03095858544111252, acc: 0.9888059496879578)
[2024-12-17 05:02:12,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:12,910][root][INFO] - Training Epoch: 2/2, step 2415/7134 completed (loss: 0.06091621518135071, acc: 0.9821673631668091)
[2024-12-17 05:02:13,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:13,339][root][INFO] - Training Epoch: 2/2, step 2416/7134 completed (loss: 0.029320986941456795, acc: 0.9847856163978577)
[2024-12-17 05:02:13,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:13,819][root][INFO] - Training Epoch: 2/2, step 2417/7134 completed (loss: 0.05548964813351631, acc: 0.9877368807792664)
[2024-12-17 05:02:13,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:14,220][root][INFO] - Training Epoch: 2/2, step 2418/7134 completed (loss: 0.04908929020166397, acc: 0.9859353303909302)
[2024-12-17 05:02:14,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:14,649][root][INFO] - Training Epoch: 2/2, step 2419/7134 completed (loss: 0.028220081701874733, acc: 0.9928469061851501)
[2024-12-17 05:02:14,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:15,072][root][INFO] - Training Epoch: 2/2, step 2420/7134 completed (loss: 0.025052107870578766, acc: 0.9933664798736572)
[2024-12-17 05:02:15,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:15,515][root][INFO] - Training Epoch: 2/2, step 2421/7134 completed (loss: 0.04268641397356987, acc: 0.9888059496879578)
[2024-12-17 05:02:15,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:15,990][root][INFO] - Training Epoch: 2/2, step 2422/7134 completed (loss: 0.019889511168003082, acc: 0.9964538812637329)
[2024-12-17 05:02:16,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:16,413][root][INFO] - Training Epoch: 2/2, step 2423/7134 completed (loss: 0.02350389026105404, acc: 0.991631805896759)
[2024-12-17 05:02:16,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:16,847][root][INFO] - Training Epoch: 2/2, step 2424/7134 completed (loss: 0.03323011472821236, acc: 0.9887640476226807)
[2024-12-17 05:02:16,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:17,284][root][INFO] - Training Epoch: 2/2, step 2425/7134 completed (loss: 0.03402993083000183, acc: 0.9879999756813049)
[2024-12-17 05:02:17,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:17,756][root][INFO] - Training Epoch: 2/2, step 2426/7134 completed (loss: 0.023862920701503754, acc: 0.9916765689849854)
[2024-12-17 05:02:17,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:18,221][root][INFO] - Training Epoch: 2/2, step 2427/7134 completed (loss: 0.01827649027109146, acc: 0.9953595995903015)
[2024-12-17 05:02:18,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:18,682][root][INFO] - Training Epoch: 2/2, step 2428/7134 completed (loss: 0.0244018342345953, acc: 0.993630588054657)
[2024-12-17 05:02:18,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:19,119][root][INFO] - Training Epoch: 2/2, step 2429/7134 completed (loss: 0.04049824923276901, acc: 0.9922118186950684)
[2024-12-17 05:02:19,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:19,531][root][INFO] - Training Epoch: 2/2, step 2430/7134 completed (loss: 0.03375660255551338, acc: 0.9895678162574768)
[2024-12-17 05:02:19,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:19,967][root][INFO] - Training Epoch: 2/2, step 2431/7134 completed (loss: 0.08448494970798492, acc: 0.9853372573852539)
[2024-12-17 05:02:20,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:20,414][root][INFO] - Training Epoch: 2/2, step 2432/7134 completed (loss: 0.14213654398918152, acc: 0.9694397449493408)
[2024-12-17 05:02:20,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:20,860][root][INFO] - Training Epoch: 2/2, step 2433/7134 completed (loss: 0.0766119658946991, acc: 0.984375)
[2024-12-17 05:02:20,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:21,267][root][INFO] - Training Epoch: 2/2, step 2434/7134 completed (loss: 0.06174652650952339, acc: 0.9844720363616943)
[2024-12-17 05:02:21,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:21,723][root][INFO] - Training Epoch: 2/2, step 2435/7134 completed (loss: 0.03687563166022301, acc: 0.9881423115730286)
[2024-12-17 05:02:21,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:22,173][root][INFO] - Training Epoch: 2/2, step 2436/7134 completed (loss: 0.030007775872945786, acc: 0.9918509721755981)
[2024-12-17 05:02:22,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:22,603][root][INFO] - Training Epoch: 2/2, step 2437/7134 completed (loss: 0.04729678854346275, acc: 0.9849170446395874)
[2024-12-17 05:02:22,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:23,058][root][INFO] - Training Epoch: 2/2, step 2438/7134 completed (loss: 0.05678827688097954, acc: 0.9868420958518982)
[2024-12-17 05:02:23,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:23,518][root][INFO] - Training Epoch: 2/2, step 2439/7134 completed (loss: 0.05333821848034859, acc: 0.9838535785675049)
[2024-12-17 05:02:23,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:23,941][root][INFO] - Training Epoch: 2/2, step 2440/7134 completed (loss: 0.0486019067466259, acc: 0.9820627570152283)
[2024-12-17 05:02:24,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:24,366][root][INFO] - Training Epoch: 2/2, step 2441/7134 completed (loss: 0.1307133138179779, acc: 0.973128616809845)
[2024-12-17 05:02:24,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:24,836][root][INFO] - Training Epoch: 2/2, step 2442/7134 completed (loss: 0.048699330538511276, acc: 0.9832167625427246)
[2024-12-17 05:02:24,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:25,305][root][INFO] - Training Epoch: 2/2, step 2443/7134 completed (loss: 0.03717925772070885, acc: 0.9833101630210876)
[2024-12-17 05:02:25,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:25,720][root][INFO] - Training Epoch: 2/2, step 2444/7134 completed (loss: 0.04729524999856949, acc: 0.9810606241226196)
[2024-12-17 05:02:25,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:26,165][root][INFO] - Training Epoch: 2/2, step 2445/7134 completed (loss: 0.06716438382863998, acc: 0.9809644818305969)
[2024-12-17 05:02:26,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:26,645][root][INFO] - Training Epoch: 2/2, step 2446/7134 completed (loss: 0.10947476327419281, acc: 0.9680555462837219)
[2024-12-17 05:02:26,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:27,117][root][INFO] - Training Epoch: 2/2, step 2447/7134 completed (loss: 0.04699414223432541, acc: 0.9822419285774231)
[2024-12-17 05:02:27,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:27,550][root][INFO] - Training Epoch: 2/2, step 2448/7134 completed (loss: 0.05030283331871033, acc: 0.9866310358047485)
[2024-12-17 05:02:27,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:27,957][root][INFO] - Training Epoch: 2/2, step 2449/7134 completed (loss: 0.05251392722129822, acc: 0.988063633441925)
[2024-12-17 05:02:28,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:28,398][root][INFO] - Training Epoch: 2/2, step 2450/7134 completed (loss: 0.05123130604624748, acc: 0.9860228896141052)
[2024-12-17 05:02:28,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:28,829][root][INFO] - Training Epoch: 2/2, step 2451/7134 completed (loss: 0.025019243359565735, acc: 0.9923567175865173)
[2024-12-17 05:02:28,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:29,300][root][INFO] - Training Epoch: 2/2, step 2452/7134 completed (loss: 0.03328799456357956, acc: 0.9908972978591919)
[2024-12-17 05:02:29,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:29,769][root][INFO] - Training Epoch: 2/2, step 2453/7134 completed (loss: 0.044420354068279266, acc: 0.9832258224487305)
[2024-12-17 05:02:29,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:30,164][root][INFO] - Training Epoch: 2/2, step 2454/7134 completed (loss: 0.030460912734270096, acc: 0.9866220951080322)
[2024-12-17 05:02:30,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:30,628][root][INFO] - Training Epoch: 2/2, step 2455/7134 completed (loss: 0.03063974529504776, acc: 0.9872521162033081)
[2024-12-17 05:02:30,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:31,056][root][INFO] - Training Epoch: 2/2, step 2456/7134 completed (loss: 0.05118317902088165, acc: 0.9805447459220886)
[2024-12-17 05:02:31,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:31,518][root][INFO] - Training Epoch: 2/2, step 2457/7134 completed (loss: 0.06195519492030144, acc: 0.9833610653877258)
[2024-12-17 05:02:31,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:31,909][root][INFO] - Training Epoch: 2/2, step 2458/7134 completed (loss: 0.08939431607723236, acc: 0.9842767119407654)
[2024-12-17 05:02:32,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:32,406][root][INFO] - Training Epoch: 2/2, step 2459/7134 completed (loss: 0.01468286756426096, acc: 0.9955621361732483)
[2024-12-17 05:02:32,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:32,851][root][INFO] - Training Epoch: 2/2, step 2460/7134 completed (loss: 0.029815007001161575, acc: 0.9930843710899353)
[2024-12-17 05:02:32,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:33,289][root][INFO] - Training Epoch: 2/2, step 2461/7134 completed (loss: 0.0190610121935606, acc: 0.9927536249160767)
[2024-12-17 05:02:33,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:33,713][root][INFO] - Training Epoch: 2/2, step 2462/7134 completed (loss: 0.03534437343478203, acc: 0.9875862002372742)
[2024-12-17 05:02:33,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:34,156][root][INFO] - Training Epoch: 2/2, step 2463/7134 completed (loss: 0.020457901060581207, acc: 0.9909228682518005)
[2024-12-17 05:02:34,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:34,547][root][INFO] - Training Epoch: 2/2, step 2464/7134 completed (loss: 0.045022524893283844, acc: 0.9850187301635742)
[2024-12-17 05:02:34,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:34,992][root][INFO] - Training Epoch: 2/2, step 2465/7134 completed (loss: 0.03709527850151062, acc: 0.9880794882774353)
[2024-12-17 05:02:35,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:35,443][root][INFO] - Training Epoch: 2/2, step 2466/7134 completed (loss: 0.018329713493585587, acc: 0.9933775067329407)
[2024-12-17 05:02:35,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:35,894][root][INFO] - Training Epoch: 2/2, step 2467/7134 completed (loss: 0.04627791792154312, acc: 0.9832904934883118)
[2024-12-17 05:02:36,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:36,346][root][INFO] - Training Epoch: 2/2, step 2468/7134 completed (loss: 0.014666153118014336, acc: 0.9958041906356812)
[2024-12-17 05:02:36,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:36,802][root][INFO] - Training Epoch: 2/2, step 2469/7134 completed (loss: 0.019763417541980743, acc: 0.9931787252426147)
[2024-12-17 05:02:36,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:37,216][root][INFO] - Training Epoch: 2/2, step 2470/7134 completed (loss: 0.03012325055897236, acc: 0.9915825128555298)
[2024-12-17 05:02:37,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:37,631][root][INFO] - Training Epoch: 2/2, step 2471/7134 completed (loss: 0.02030746452510357, acc: 0.9933110475540161)
[2024-12-17 05:02:37,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:38,043][root][INFO] - Training Epoch: 2/2, step 2472/7134 completed (loss: 0.013153835199773312, acc: 0.9984848499298096)
[2024-12-17 05:02:38,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:38,473][root][INFO] - Training Epoch: 2/2, step 2473/7134 completed (loss: 0.03649212792515755, acc: 0.9897540807723999)
[2024-12-17 05:02:38,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:38,895][root][INFO] - Training Epoch: 2/2, step 2474/7134 completed (loss: 0.013381106778979301, acc: 0.9957746267318726)
[2024-12-17 05:02:39,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:39,294][root][INFO] - Training Epoch: 2/2, step 2475/7134 completed (loss: 0.022957902401685715, acc: 0.9914236664772034)
[2024-12-17 05:02:39,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:39,719][root][INFO] - Training Epoch: 2/2, step 2476/7134 completed (loss: 0.04825587943196297, acc: 0.9888579249382019)
[2024-12-17 05:02:39,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:40,127][root][INFO] - Training Epoch: 2/2, step 2477/7134 completed (loss: 0.033073484897613525, acc: 0.9917126893997192)
[2024-12-17 05:02:40,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:40,562][root][INFO] - Training Epoch: 2/2, step 2478/7134 completed (loss: 0.014042909257113934, acc: 0.9953271150588989)
[2024-12-17 05:02:40,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:40,977][root][INFO] - Training Epoch: 2/2, step 2479/7134 completed (loss: 0.07854904234409332, acc: 0.9777424335479736)
[2024-12-17 05:02:41,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:41,389][root][INFO] - Training Epoch: 2/2, step 2480/7134 completed (loss: 0.005735460203140974, acc: 1.0)
[2024-12-17 05:02:41,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:41,820][root][INFO] - Training Epoch: 2/2, step 2481/7134 completed (loss: 0.027554722502827644, acc: 0.9875621795654297)
[2024-12-17 05:02:41,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:42,261][root][INFO] - Training Epoch: 2/2, step 2482/7134 completed (loss: 0.04233099892735481, acc: 0.9791332483291626)
[2024-12-17 05:02:42,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:42,700][root][INFO] - Training Epoch: 2/2, step 2483/7134 completed (loss: 0.02715950459241867, acc: 0.9889042973518372)
[2024-12-17 05:02:42,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:43,132][root][INFO] - Training Epoch: 2/2, step 2484/7134 completed (loss: 0.029965771362185478, acc: 0.9902777671813965)
[2024-12-17 05:02:43,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:43,558][root][INFO] - Training Epoch: 2/2, step 2485/7134 completed (loss: 0.0292457677423954, acc: 0.9952380657196045)
[2024-12-17 05:02:43,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:43,996][root][INFO] - Training Epoch: 2/2, step 2486/7134 completed (loss: 0.027675913646817207, acc: 0.9971264600753784)
[2024-12-17 05:02:44,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:44,425][root][INFO] - Training Epoch: 2/2, step 2487/7134 completed (loss: 0.10177721828222275, acc: 0.9795275330543518)
[2024-12-17 05:02:44,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:44,858][root][INFO] - Training Epoch: 2/2, step 2488/7134 completed (loss: 0.020408786833286285, acc: 0.9930939078330994)
[2024-12-17 05:02:44,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:45,269][root][INFO] - Training Epoch: 2/2, step 2489/7134 completed (loss: 0.01786985993385315, acc: 0.9944289922714233)
[2024-12-17 05:02:45,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:45,709][root][INFO] - Training Epoch: 2/2, step 2490/7134 completed (loss: 0.020039934664964676, acc: 0.9942938685417175)
[2024-12-17 05:02:45,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:46,127][root][INFO] - Training Epoch: 2/2, step 2491/7134 completed (loss: 0.1127733439207077, acc: 0.9814814925193787)
[2024-12-17 05:02:46,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:46,563][root][INFO] - Training Epoch: 2/2, step 2492/7134 completed (loss: 0.04027796909213066, acc: 0.9888337254524231)
[2024-12-17 05:02:46,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:47,016][root][INFO] - Training Epoch: 2/2, step 2493/7134 completed (loss: 0.04502961412072182, acc: 0.9847418069839478)
[2024-12-17 05:02:47,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:47,456][root][INFO] - Training Epoch: 2/2, step 2494/7134 completed (loss: 0.04029896482825279, acc: 0.9899874925613403)
[2024-12-17 05:02:47,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:47,942][root][INFO] - Training Epoch: 2/2, step 2495/7134 completed (loss: 0.04825671389698982, acc: 0.9837177991867065)
[2024-12-17 05:02:48,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:48,415][root][INFO] - Training Epoch: 2/2, step 2496/7134 completed (loss: 0.025087008252739906, acc: 0.9915730357170105)
[2024-12-17 05:02:48,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:48,858][root][INFO] - Training Epoch: 2/2, step 2497/7134 completed (loss: 0.042064517736434937, acc: 0.9866179823875427)
[2024-12-17 05:02:48,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:49,312][root][INFO] - Training Epoch: 2/2, step 2498/7134 completed (loss: 0.023260654881596565, acc: 0.9920364022254944)
[2024-12-17 05:02:49,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:49,770][root][INFO] - Training Epoch: 2/2, step 2499/7134 completed (loss: 0.021532196551561356, acc: 0.9927536249160767)
[2024-12-17 05:02:49,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:50,219][root][INFO] - Training Epoch: 2/2, step 2500/7134 completed (loss: 0.021989157423377037, acc: 0.993565022945404)
[2024-12-17 05:02:50,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:50,658][root][INFO] - Training Epoch: 2/2, step 2501/7134 completed (loss: 0.0342109389603138, acc: 0.9897025227546692)
[2024-12-17 05:02:50,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:51,098][root][INFO] - Training Epoch: 2/2, step 2502/7134 completed (loss: 0.02132965438067913, acc: 0.9946996569633484)
[2024-12-17 05:02:51,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:51,507][root][INFO] - Training Epoch: 2/2, step 2503/7134 completed (loss: 0.02701488509774208, acc: 0.994301974773407)
[2024-12-17 05:02:51,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:51,937][root][INFO] - Training Epoch: 2/2, step 2504/7134 completed (loss: 0.02750529535114765, acc: 0.9919999837875366)
[2024-12-17 05:02:52,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:52,390][root][INFO] - Training Epoch: 2/2, step 2505/7134 completed (loss: 0.02544834278523922, acc: 0.9931740760803223)
[2024-12-17 05:02:52,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:52,863][root][INFO] - Training Epoch: 2/2, step 2506/7134 completed (loss: 0.02818264439702034, acc: 0.9903846383094788)
[2024-12-17 05:02:52,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:53,306][root][INFO] - Training Epoch: 2/2, step 2507/7134 completed (loss: 0.009318490512669086, acc: 0.9988385438919067)
[2024-12-17 05:02:53,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:53,770][root][INFO] - Training Epoch: 2/2, step 2508/7134 completed (loss: 0.05022789537906647, acc: 0.9861751198768616)
[2024-12-17 05:02:53,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:54,203][root][INFO] - Training Epoch: 2/2, step 2509/7134 completed (loss: 0.015558568760752678, acc: 0.9975520372390747)
[2024-12-17 05:02:54,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:54,649][root][INFO] - Training Epoch: 2/2, step 2510/7134 completed (loss: 0.022440435364842415, acc: 0.9924127459526062)
[2024-12-17 05:02:54,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:55,097][root][INFO] - Training Epoch: 2/2, step 2511/7134 completed (loss: 0.04451363906264305, acc: 0.9887892603874207)
[2024-12-17 05:02:55,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:55,519][root][INFO] - Training Epoch: 2/2, step 2512/7134 completed (loss: 0.061211276799440384, acc: 0.9851552248001099)
[2024-12-17 05:02:55,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:55,980][root][INFO] - Training Epoch: 2/2, step 2513/7134 completed (loss: 0.021304752677679062, acc: 0.9940758347511292)
[2024-12-17 05:02:56,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:56,425][root][INFO] - Training Epoch: 2/2, step 2514/7134 completed (loss: 0.021581025794148445, acc: 0.9918319582939148)
[2024-12-17 05:02:56,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:56,881][root][INFO] - Training Epoch: 2/2, step 2515/7134 completed (loss: 0.008972679264843464, acc: 0.9960988163948059)
[2024-12-17 05:02:56,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:57,338][root][INFO] - Training Epoch: 2/2, step 2516/7134 completed (loss: 0.014012323692440987, acc: 0.9954545497894287)
[2024-12-17 05:02:57,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:57,800][root][INFO] - Training Epoch: 2/2, step 2517/7134 completed (loss: 0.044597309082746506, acc: 0.9908151626586914)
[2024-12-17 05:02:57,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:58,210][root][INFO] - Training Epoch: 2/2, step 2518/7134 completed (loss: 0.024469872936606407, acc: 0.9942775368690491)
[2024-12-17 05:02:58,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:58,659][root][INFO] - Training Epoch: 2/2, step 2519/7134 completed (loss: 0.016409898176789284, acc: 0.9958506226539612)
[2024-12-17 05:02:58,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:59,092][root][INFO] - Training Epoch: 2/2, step 2520/7134 completed (loss: 0.0130084790289402, acc: 0.995726466178894)
[2024-12-17 05:02:59,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:59,541][root][INFO] - Training Epoch: 2/2, step 2521/7134 completed (loss: 0.07060294598340988, acc: 0.9832689762115479)
[2024-12-17 05:02:59,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:02:59,953][root][INFO] - Training Epoch: 2/2, step 2522/7134 completed (loss: 0.030524691566824913, acc: 0.9914039969444275)
[2024-12-17 05:03:00,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:00,383][root][INFO] - Training Epoch: 2/2, step 2523/7134 completed (loss: 0.046933986246585846, acc: 0.9921466112136841)
[2024-12-17 05:03:00,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:00,809][root][INFO] - Training Epoch: 2/2, step 2524/7134 completed (loss: 0.00693430146202445, acc: 0.9986187815666199)
[2024-12-17 05:03:00,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:01,213][root][INFO] - Training Epoch: 2/2, step 2525/7134 completed (loss: 0.028435470536351204, acc: 0.9883138537406921)
[2024-12-17 05:03:01,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:01,607][root][INFO] - Training Epoch: 2/2, step 2526/7134 completed (loss: 0.009887638501822948, acc: 0.9976470470428467)
[2024-12-17 05:03:01,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:02,059][root][INFO] - Training Epoch: 2/2, step 2527/7134 completed (loss: 0.038701076060533524, acc: 0.9902439117431641)
[2024-12-17 05:03:02,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:02,482][root][INFO] - Training Epoch: 2/2, step 2528/7134 completed (loss: 0.01258175354450941, acc: 0.99589604139328)
[2024-12-17 05:03:02,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:02,933][root][INFO] - Training Epoch: 2/2, step 2529/7134 completed (loss: 0.014790556393563747, acc: 0.9960106611251831)
[2024-12-17 05:03:03,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:03,399][root][INFO] - Training Epoch: 2/2, step 2530/7134 completed (loss: 0.014529766514897346, acc: 0.9961038827896118)
[2024-12-17 05:03:03,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:03,815][root][INFO] - Training Epoch: 2/2, step 2531/7134 completed (loss: 0.011290496215224266, acc: 0.9958563446998596)
[2024-12-17 05:03:03,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:04,226][root][INFO] - Training Epoch: 2/2, step 2532/7134 completed (loss: 0.011139743030071259, acc: 0.9984591603279114)
[2024-12-17 05:03:04,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:04,638][root][INFO] - Training Epoch: 2/2, step 2533/7134 completed (loss: 0.030403614044189453, acc: 0.9879336357116699)
[2024-12-17 05:03:04,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:05,052][root][INFO] - Training Epoch: 2/2, step 2534/7134 completed (loss: 0.03453541174530983, acc: 0.9949044585227966)
[2024-12-17 05:03:05,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:05,488][root][INFO] - Training Epoch: 2/2, step 2535/7134 completed (loss: 0.03692950680851936, acc: 0.9903661012649536)
[2024-12-17 05:03:05,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:05,940][root][INFO] - Training Epoch: 2/2, step 2536/7134 completed (loss: 0.0441986508667469, acc: 0.9864698648452759)
[2024-12-17 05:03:06,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:06,344][root][INFO] - Training Epoch: 2/2, step 2537/7134 completed (loss: 0.06826149672269821, acc: 0.9831804037094116)
[2024-12-17 05:03:06,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:06,757][root][INFO] - Training Epoch: 2/2, step 2538/7134 completed (loss: 0.07495655119419098, acc: 0.980169951915741)
[2024-12-17 05:03:06,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:07,129][root][INFO] - Training Epoch: 2/2, step 2539/7134 completed (loss: 0.019831011071801186, acc: 0.9946428537368774)
[2024-12-17 05:03:07,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:07,544][root][INFO] - Training Epoch: 2/2, step 2540/7134 completed (loss: 0.05840793624520302, acc: 0.9862385392189026)
[2024-12-17 05:03:07,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:07,952][root][INFO] - Training Epoch: 2/2, step 2541/7134 completed (loss: 0.01790045015513897, acc: 0.9950330853462219)
[2024-12-17 05:03:08,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:08,354][root][INFO] - Training Epoch: 2/2, step 2542/7134 completed (loss: 0.06240005046129227, acc: 0.9896449446678162)
[2024-12-17 05:03:08,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:08,791][root][INFO] - Training Epoch: 2/2, step 2543/7134 completed (loss: 0.0957099124789238, acc: 0.9836065769195557)
[2024-12-17 05:03:08,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:09,233][root][INFO] - Training Epoch: 2/2, step 2544/7134 completed (loss: 0.03198665380477905, acc: 0.9896907210350037)
[2024-12-17 05:03:09,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:09,661][root][INFO] - Training Epoch: 2/2, step 2545/7134 completed (loss: 0.04442177712917328, acc: 0.9860383868217468)
[2024-12-17 05:03:09,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:10,129][root][INFO] - Training Epoch: 2/2, step 2546/7134 completed (loss: 0.1335618793964386, acc: 0.9603841304779053)
[2024-12-17 05:03:10,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:10,541][root][INFO] - Training Epoch: 2/2, step 2547/7134 completed (loss: 0.05726063251495361, acc: 0.9855072498321533)
[2024-12-17 05:03:10,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:10,964][root][INFO] - Training Epoch: 2/2, step 2548/7134 completed (loss: 0.037776172161102295, acc: 0.9940944910049438)
[2024-12-17 05:03:11,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:11,407][root][INFO] - Training Epoch: 2/2, step 2549/7134 completed (loss: 0.05659540370106697, acc: 0.9760589599609375)
[2024-12-17 05:03:11,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:11,843][root][INFO] - Training Epoch: 2/2, step 2550/7134 completed (loss: 0.0335455983877182, acc: 0.990212082862854)
[2024-12-17 05:03:11,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:12,257][root][INFO] - Training Epoch: 2/2, step 2551/7134 completed (loss: 0.05189285799860954, acc: 0.9884488582611084)
[2024-12-17 05:03:12,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:12,651][root][INFO] - Training Epoch: 2/2, step 2552/7134 completed (loss: 0.014746488071978092, acc: 0.9968454241752625)
[2024-12-17 05:03:12,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:13,023][root][INFO] - Training Epoch: 2/2, step 2553/7134 completed (loss: 0.03332680091261864, acc: 0.9879153966903687)
[2024-12-17 05:03:13,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:13,456][root][INFO] - Training Epoch: 2/2, step 2554/7134 completed (loss: 0.06094370037317276, acc: 0.9832496047019958)
[2024-12-17 05:03:13,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:13,854][root][INFO] - Training Epoch: 2/2, step 2555/7134 completed (loss: 0.03895982354879379, acc: 0.9855371713638306)
[2024-12-17 05:03:14,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:14,283][root][INFO] - Training Epoch: 2/2, step 2556/7134 completed (loss: 0.045459989458322525, acc: 0.9853249192237854)
[2024-12-17 05:03:14,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:14,718][root][INFO] - Training Epoch: 2/2, step 2557/7134 completed (loss: 0.05362089350819588, acc: 0.9836065769195557)
[2024-12-17 05:03:14,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:15,130][root][INFO] - Training Epoch: 2/2, step 2558/7134 completed (loss: 0.021125447005033493, acc: 0.9935275316238403)
[2024-12-17 05:03:15,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:15,555][root][INFO] - Training Epoch: 2/2, step 2559/7134 completed (loss: 0.029358666390180588, acc: 0.9932340979576111)
[2024-12-17 05:03:15,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:16,014][root][INFO] - Training Epoch: 2/2, step 2560/7134 completed (loss: 0.049696456640958786, acc: 0.9886178970336914)
[2024-12-17 05:03:16,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:16,439][root][INFO] - Training Epoch: 2/2, step 2561/7134 completed (loss: 0.04138105362653732, acc: 0.9869281053543091)
[2024-12-17 05:03:16,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:16,855][root][INFO] - Training Epoch: 2/2, step 2562/7134 completed (loss: 0.03819476440548897, acc: 0.9914529919624329)
[2024-12-17 05:03:16,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:17,295][root][INFO] - Training Epoch: 2/2, step 2563/7134 completed (loss: 0.03767040744423866, acc: 0.992668628692627)
[2024-12-17 05:03:17,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:17,748][root][INFO] - Training Epoch: 2/2, step 2564/7134 completed (loss: 0.1200619637966156, acc: 0.9714764952659607)
[2024-12-17 05:03:17,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:18,154][root][INFO] - Training Epoch: 2/2, step 2565/7134 completed (loss: 0.01888800971210003, acc: 0.9939576983451843)
[2024-12-17 05:03:18,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:18,605][root][INFO] - Training Epoch: 2/2, step 2566/7134 completed (loss: 0.02878871187567711, acc: 0.9915730357170105)
[2024-12-17 05:03:18,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:19,020][root][INFO] - Training Epoch: 2/2, step 2567/7134 completed (loss: 0.02696032077074051, acc: 0.9876543283462524)
[2024-12-17 05:03:19,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:19,436][root][INFO] - Training Epoch: 2/2, step 2568/7134 completed (loss: 0.04130319505929947, acc: 0.9884393215179443)
[2024-12-17 05:03:19,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:19,862][root][INFO] - Training Epoch: 2/2, step 2569/7134 completed (loss: 0.02970060333609581, acc: 0.9864457845687866)
[2024-12-17 05:03:19,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:20,293][root][INFO] - Training Epoch: 2/2, step 2570/7134 completed (loss: 0.03935149684548378, acc: 0.9925037622451782)
[2024-12-17 05:03:20,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:20,693][root][INFO] - Training Epoch: 2/2, step 2571/7134 completed (loss: 0.027011170983314514, acc: 0.994727611541748)
[2024-12-17 05:03:20,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:21,131][root][INFO] - Training Epoch: 2/2, step 2572/7134 completed (loss: 0.05274350941181183, acc: 0.9858044385910034)
[2024-12-17 05:03:21,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:21,543][root][INFO] - Training Epoch: 2/2, step 2573/7134 completed (loss: 0.04479318484663963, acc: 0.9885246157646179)
[2024-12-17 05:03:21,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:21,975][root][INFO] - Training Epoch: 2/2, step 2574/7134 completed (loss: 0.03357086330652237, acc: 0.9868995547294617)
[2024-12-17 05:03:22,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:22,373][root][INFO] - Training Epoch: 2/2, step 2575/7134 completed (loss: 0.024523746222257614, acc: 0.9925650358200073)
[2024-12-17 05:03:22,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:22,782][root][INFO] - Training Epoch: 2/2, step 2576/7134 completed (loss: 0.032092709094285965, acc: 0.9896551966667175)
[2024-12-17 05:03:22,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:23,205][root][INFO] - Training Epoch: 2/2, step 2577/7134 completed (loss: 0.06309070438146591, acc: 0.988034188747406)
[2024-12-17 05:03:23,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:23,616][root][INFO] - Training Epoch: 2/2, step 2578/7134 completed (loss: 0.05657237395644188, acc: 0.9831546545028687)
[2024-12-17 05:03:23,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:24,045][root][INFO] - Training Epoch: 2/2, step 2579/7134 completed (loss: 0.08378289639949799, acc: 0.9746835231781006)
[2024-12-17 05:03:24,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:24,496][root][INFO] - Training Epoch: 2/2, step 2580/7134 completed (loss: 0.05513030290603638, acc: 0.9856396913528442)
[2024-12-17 05:03:24,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:24,926][root][INFO] - Training Epoch: 2/2, step 2581/7134 completed (loss: 0.030477484688162804, acc: 0.9919246435165405)
[2024-12-17 05:03:25,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:25,370][root][INFO] - Training Epoch: 2/2, step 2582/7134 completed (loss: 0.03572670370340347, acc: 0.9878048896789551)
[2024-12-17 05:03:25,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:25,796][root][INFO] - Training Epoch: 2/2, step 2583/7134 completed (loss: 0.047889046370983124, acc: 0.9857752323150635)
[2024-12-17 05:03:25,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:26,189][root][INFO] - Training Epoch: 2/2, step 2584/7134 completed (loss: 0.07125329226255417, acc: 0.9773123860359192)
[2024-12-17 05:03:26,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:26,645][root][INFO] - Training Epoch: 2/2, step 2585/7134 completed (loss: 0.06543590128421783, acc: 0.9812949895858765)
[2024-12-17 05:03:26,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:27,080][root][INFO] - Training Epoch: 2/2, step 2586/7134 completed (loss: 0.08583647012710571, acc: 0.9771126508712769)
[2024-12-17 05:03:27,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:27,523][root][INFO] - Training Epoch: 2/2, step 2587/7134 completed (loss: 0.04886283352971077, acc: 0.9864864945411682)
[2024-12-17 05:03:27,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:27,969][root][INFO] - Training Epoch: 2/2, step 2588/7134 completed (loss: 0.014691025018692017, acc: 0.9945429563522339)
[2024-12-17 05:03:28,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:28,373][root][INFO] - Training Epoch: 2/2, step 2589/7134 completed (loss: 0.04966321587562561, acc: 0.9858657121658325)
[2024-12-17 05:03:28,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:28,780][root][INFO] - Training Epoch: 2/2, step 2590/7134 completed (loss: 0.03977907821536064, acc: 0.9885621070861816)
[2024-12-17 05:03:28,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:29,226][root][INFO] - Training Epoch: 2/2, step 2591/7134 completed (loss: 0.06631776690483093, acc: 0.9795396327972412)
[2024-12-17 05:03:29,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:29,696][root][INFO] - Training Epoch: 2/2, step 2592/7134 completed (loss: 0.058143988251686096, acc: 0.984009861946106)
[2024-12-17 05:03:29,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:30,141][root][INFO] - Training Epoch: 2/2, step 2593/7134 completed (loss: 0.042118463665246964, acc: 0.9921466112136841)
[2024-12-17 05:03:30,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:30,565][root][INFO] - Training Epoch: 2/2, step 2594/7134 completed (loss: 0.03648480027914047, acc: 0.9785932898521423)
[2024-12-17 05:03:30,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:31,006][root][INFO] - Training Epoch: 2/2, step 2595/7134 completed (loss: 0.022111061960458755, acc: 0.9959677457809448)
[2024-12-17 05:03:31,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:31,485][root][INFO] - Training Epoch: 2/2, step 2596/7134 completed (loss: 0.03780260682106018, acc: 0.9899749159812927)
[2024-12-17 05:03:31,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:31,934][root][INFO] - Training Epoch: 2/2, step 2597/7134 completed (loss: 0.044879551976919174, acc: 0.9864864945411682)
[2024-12-17 05:03:32,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:32,380][root][INFO] - Training Epoch: 2/2, step 2598/7134 completed (loss: 0.06128377839922905, acc: 0.9814241528511047)
[2024-12-17 05:03:32,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:32,806][root][INFO] - Training Epoch: 2/2, step 2599/7134 completed (loss: 0.014644195325672626, acc: 0.9960421919822693)
[2024-12-17 05:03:32,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:33,279][root][INFO] - Training Epoch: 2/2, step 2600/7134 completed (loss: 0.04533146321773529, acc: 0.98975670337677)
[2024-12-17 05:03:33,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:33,726][root][INFO] - Training Epoch: 2/2, step 2601/7134 completed (loss: 0.05052507296204567, acc: 0.9824086427688599)
[2024-12-17 05:03:33,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:34,173][root][INFO] - Training Epoch: 2/2, step 2602/7134 completed (loss: 0.04098261892795563, acc: 0.9878934621810913)
[2024-12-17 05:03:34,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:34,637][root][INFO] - Training Epoch: 2/2, step 2603/7134 completed (loss: 0.06026110425591469, acc: 0.9906976819038391)
[2024-12-17 05:03:34,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:35,095][root][INFO] - Training Epoch: 2/2, step 2604/7134 completed (loss: 0.03631666302680969, acc: 0.9868420958518982)
[2024-12-17 05:03:35,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:35,535][root][INFO] - Training Epoch: 2/2, step 2605/7134 completed (loss: 0.0812717154622078, acc: 0.9657039642333984)
[2024-12-17 05:03:35,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:35,981][root][INFO] - Training Epoch: 2/2, step 2606/7134 completed (loss: 0.04826715588569641, acc: 0.9856114983558655)
[2024-12-17 05:03:36,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:36,435][root][INFO] - Training Epoch: 2/2, step 2607/7134 completed (loss: 0.04268617928028107, acc: 0.9835293889045715)
[2024-12-17 05:03:36,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:36,881][root][INFO] - Training Epoch: 2/2, step 2608/7134 completed (loss: 0.0684058889746666, acc: 0.9814586043357849)
[2024-12-17 05:03:36,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:37,325][root][INFO] - Training Epoch: 2/2, step 2609/7134 completed (loss: 0.07004420459270477, acc: 0.9818941354751587)
[2024-12-17 05:03:37,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:37,690][root][INFO] - Training Epoch: 2/2, step 2610/7134 completed (loss: 0.08513616025447845, acc: 0.9847328066825867)
[2024-12-17 05:03:37,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:38,164][root][INFO] - Training Epoch: 2/2, step 2611/7134 completed (loss: 0.07516743987798691, acc: 0.9770379066467285)
[2024-12-17 05:03:38,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:38,629][root][INFO] - Training Epoch: 2/2, step 2612/7134 completed (loss: 0.0720447227358818, acc: 0.9829156994819641)
[2024-12-17 05:03:38,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:39,111][root][INFO] - Training Epoch: 2/2, step 2613/7134 completed (loss: 0.031337566673755646, acc: 0.9911392331123352)
[2024-12-17 05:03:39,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:39,578][root][INFO] - Training Epoch: 2/2, step 2614/7134 completed (loss: 0.0774497389793396, acc: 0.9783599376678467)
[2024-12-17 05:03:39,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:40,034][root][INFO] - Training Epoch: 2/2, step 2615/7134 completed (loss: 0.05176039785146713, acc: 0.9832904934883118)
[2024-12-17 05:03:40,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:40,483][root][INFO] - Training Epoch: 2/2, step 2616/7134 completed (loss: 0.07818343490362167, acc: 0.9814814925193787)
[2024-12-17 05:03:40,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:40,942][root][INFO] - Training Epoch: 2/2, step 2617/7134 completed (loss: 0.06745195388793945, acc: 0.9838056564331055)
[2024-12-17 05:03:41,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:41,325][root][INFO] - Training Epoch: 2/2, step 2618/7134 completed (loss: 0.03450428694486618, acc: 0.9856262803077698)
[2024-12-17 05:03:41,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:41,754][root][INFO] - Training Epoch: 2/2, step 2619/7134 completed (loss: 0.04865850880742073, acc: 0.9848993420600891)
[2024-12-17 05:03:41,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:42,205][root][INFO] - Training Epoch: 2/2, step 2620/7134 completed (loss: 0.0570906400680542, acc: 0.9826517701148987)
[2024-12-17 05:03:42,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:42,661][root][INFO] - Training Epoch: 2/2, step 2621/7134 completed (loss: 0.043131060898303986, acc: 0.9893364906311035)
[2024-12-17 05:03:42,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:43,129][root][INFO] - Training Epoch: 2/2, step 2622/7134 completed (loss: 0.04915737360715866, acc: 0.9869067072868347)
[2024-12-17 05:03:43,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:43,596][root][INFO] - Training Epoch: 2/2, step 2623/7134 completed (loss: 0.06878482550382614, acc: 0.9804597496986389)
[2024-12-17 05:03:43,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:44,050][root][INFO] - Training Epoch: 2/2, step 2624/7134 completed (loss: 0.0625227689743042, acc: 0.9853768348693848)
[2024-12-17 05:03:44,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:44,500][root][INFO] - Training Epoch: 2/2, step 2625/7134 completed (loss: 0.054527249187231064, acc: 0.9819444417953491)
[2024-12-17 05:03:44,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:44,949][root][INFO] - Training Epoch: 2/2, step 2626/7134 completed (loss: 0.042050398886203766, acc: 0.9863861203193665)
[2024-12-17 05:03:45,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:45,410][root][INFO] - Training Epoch: 2/2, step 2627/7134 completed (loss: 0.03452108055353165, acc: 0.9878214001655579)
[2024-12-17 05:03:45,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:45,832][root][INFO] - Training Epoch: 2/2, step 2628/7134 completed (loss: 0.05477525666356087, acc: 0.9823232293128967)
[2024-12-17 05:03:45,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:46,349][root][INFO] - Training Epoch: 2/2, step 2629/7134 completed (loss: 0.019401542842388153, acc: 0.9949430823326111)
[2024-12-17 05:03:46,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:46,815][root][INFO] - Training Epoch: 2/2, step 2630/7134 completed (loss: 0.0234993789345026, acc: 0.9888178706169128)
[2024-12-17 05:03:46,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:47,258][root][INFO] - Training Epoch: 2/2, step 2631/7134 completed (loss: 0.046783220022916794, acc: 0.9836257100105286)
[2024-12-17 05:03:47,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:47,699][root][INFO] - Training Epoch: 2/2, step 2632/7134 completed (loss: 0.0250401571393013, acc: 0.994106113910675)
[2024-12-17 05:03:47,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:48,148][root][INFO] - Training Epoch: 2/2, step 2633/7134 completed (loss: 0.03580218181014061, acc: 0.9900850057601929)
[2024-12-17 05:03:48,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:48,562][root][INFO] - Training Epoch: 2/2, step 2634/7134 completed (loss: 0.01588580571115017, acc: 0.9970015287399292)
[2024-12-17 05:03:48,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:49,014][root][INFO] - Training Epoch: 2/2, step 2635/7134 completed (loss: 0.08473244309425354, acc: 0.9847221970558167)
[2024-12-17 05:03:49,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:49,469][root][INFO] - Training Epoch: 2/2, step 2636/7134 completed (loss: 0.07071559876203537, acc: 0.9772403836250305)
[2024-12-17 05:03:49,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:49,888][root][INFO] - Training Epoch: 2/2, step 2637/7134 completed (loss: 0.17388099431991577, acc: 0.9592529535293579)
[2024-12-17 05:03:49,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:50,346][root][INFO] - Training Epoch: 2/2, step 2638/7134 completed (loss: 0.10854095965623856, acc: 0.9700130224227905)
[2024-12-17 05:03:50,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:50,774][root][INFO] - Training Epoch: 2/2, step 2639/7134 completed (loss: 0.09752947092056274, acc: 0.9709543585777283)
[2024-12-17 05:03:50,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:51,250][root][INFO] - Training Epoch: 2/2, step 2640/7134 completed (loss: 0.0815395787358284, acc: 0.9787765145301819)
[2024-12-17 05:03:51,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:51,706][root][INFO] - Training Epoch: 2/2, step 2641/7134 completed (loss: 0.06575393676757812, acc: 0.9764359593391418)
[2024-12-17 05:03:51,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:52,114][root][INFO] - Training Epoch: 2/2, step 2642/7134 completed (loss: 0.09130945056676865, acc: 0.9733096361160278)
[2024-12-17 05:03:52,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:52,553][root][INFO] - Training Epoch: 2/2, step 2643/7134 completed (loss: 0.056826088577508926, acc: 0.985049843788147)
[2024-12-17 05:03:52,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:53,044][root][INFO] - Training Epoch: 2/2, step 2644/7134 completed (loss: 0.07074684649705887, acc: 0.9793689250946045)
[2024-12-17 05:03:53,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:53,458][root][INFO] - Training Epoch: 2/2, step 2645/7134 completed (loss: 0.05501831695437431, acc: 0.9825072884559631)
[2024-12-17 05:03:53,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:53,869][root][INFO] - Training Epoch: 2/2, step 2646/7134 completed (loss: 0.12093474715948105, acc: 0.9633758068084717)
[2024-12-17 05:03:53,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:54,318][root][INFO] - Training Epoch: 2/2, step 2647/7134 completed (loss: 0.05853801220655441, acc: 0.9804941415786743)
[2024-12-17 05:03:54,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:54,745][root][INFO] - Training Epoch: 2/2, step 2648/7134 completed (loss: 0.03240766003727913, acc: 0.9870967864990234)
[2024-12-17 05:03:54,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:55,182][root][INFO] - Training Epoch: 2/2, step 2649/7134 completed (loss: 0.11300845444202423, acc: 0.9672130942344666)
[2024-12-17 05:03:55,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:55,584][root][INFO] - Training Epoch: 2/2, step 2650/7134 completed (loss: 0.1059972420334816, acc: 0.9712556600570679)
[2024-12-17 05:03:55,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:56,022][root][INFO] - Training Epoch: 2/2, step 2651/7134 completed (loss: 0.035105347633361816, acc: 0.9868891835212708)
[2024-12-17 05:03:56,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:56,447][root][INFO] - Training Epoch: 2/2, step 2652/7134 completed (loss: 0.04897646605968475, acc: 0.9848675727844238)
[2024-12-17 05:03:56,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:56,838][root][INFO] - Training Epoch: 2/2, step 2653/7134 completed (loss: 0.05146483704447746, acc: 0.9786184430122375)
[2024-12-17 05:03:56,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:57,255][root][INFO] - Training Epoch: 2/2, step 2654/7134 completed (loss: 0.04565839841961861, acc: 0.9901639223098755)
[2024-12-17 05:03:57,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:57,669][root][INFO] - Training Epoch: 2/2, step 2655/7134 completed (loss: 0.027751818299293518, acc: 0.9894099831581116)
[2024-12-17 05:03:57,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:58,124][root][INFO] - Training Epoch: 2/2, step 2656/7134 completed (loss: 0.061245303601026535, acc: 0.9847009778022766)
[2024-12-17 05:03:58,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:58,547][root][INFO] - Training Epoch: 2/2, step 2657/7134 completed (loss: 0.04830938205122948, acc: 0.9854838848114014)
[2024-12-17 05:03:58,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:58,965][root][INFO] - Training Epoch: 2/2, step 2658/7134 completed (loss: 0.10639970749616623, acc: 0.9759679436683655)
[2024-12-17 05:03:59,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:59,361][root][INFO] - Training Epoch: 2/2, step 2659/7134 completed (loss: 0.056307509541511536, acc: 0.99042147397995)
[2024-12-17 05:03:59,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:03:59,762][root][INFO] - Training Epoch: 2/2, step 2660/7134 completed (loss: 0.04403778538107872, acc: 0.9879032373428345)
[2024-12-17 05:03:59,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:00,183][root][INFO] - Training Epoch: 2/2, step 2661/7134 completed (loss: 0.04818737879395485, acc: 0.9901823401451111)
[2024-12-17 05:04:00,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:00,674][root][INFO] - Training Epoch: 2/2, step 2662/7134 completed (loss: 0.021506676450371742, acc: 0.991465151309967)
[2024-12-17 05:04:00,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:01,141][root][INFO] - Training Epoch: 2/2, step 2663/7134 completed (loss: 0.03684103116393089, acc: 0.9906432628631592)
[2024-12-17 05:04:01,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:01,591][root][INFO] - Training Epoch: 2/2, step 2664/7134 completed (loss: 0.02304040640592575, acc: 0.9922580718994141)
[2024-12-17 05:04:01,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:02,030][root][INFO] - Training Epoch: 2/2, step 2665/7134 completed (loss: 0.01930553838610649, acc: 0.99609375)
[2024-12-17 05:04:02,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:02,502][root][INFO] - Training Epoch: 2/2, step 2666/7134 completed (loss: 0.02900836057960987, acc: 0.9926560521125793)
[2024-12-17 05:04:02,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:02,924][root][INFO] - Training Epoch: 2/2, step 2667/7134 completed (loss: 0.016870060935616493, acc: 0.9957507252693176)
[2024-12-17 05:04:03,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:03,344][root][INFO] - Training Epoch: 2/2, step 2668/7134 completed (loss: 0.017335377633571625, acc: 0.9959623217582703)
[2024-12-17 05:04:03,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:03,799][root][INFO] - Training Epoch: 2/2, step 2669/7134 completed (loss: 0.009659274481236935, acc: 0.9976984858512878)
[2024-12-17 05:04:03,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:04,223][root][INFO] - Training Epoch: 2/2, step 2670/7134 completed (loss: 0.03185437619686127, acc: 0.9895150661468506)
[2024-12-17 05:04:04,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:04,663][root][INFO] - Training Epoch: 2/2, step 2671/7134 completed (loss: 0.01868392340838909, acc: 0.9933155179023743)
[2024-12-17 05:04:04,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:05,107][root][INFO] - Training Epoch: 2/2, step 2672/7134 completed (loss: 0.01542629487812519, acc: 0.9970845580101013)
[2024-12-17 05:04:05,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:05,567][root][INFO] - Training Epoch: 2/2, step 2673/7134 completed (loss: 0.017226869240403175, acc: 0.9949495196342468)
[2024-12-17 05:04:05,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:05,977][root][INFO] - Training Epoch: 2/2, step 2674/7134 completed (loss: 0.011293028481304646, acc: 0.9986053109169006)
[2024-12-17 05:04:06,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:06,426][root][INFO] - Training Epoch: 2/2, step 2675/7134 completed (loss: 0.00817655399441719, acc: 0.998630166053772)
[2024-12-17 05:04:06,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:06,856][root][INFO] - Training Epoch: 2/2, step 2676/7134 completed (loss: 0.018268799409270287, acc: 0.9935064911842346)
[2024-12-17 05:04:06,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:07,295][root][INFO] - Training Epoch: 2/2, step 2677/7134 completed (loss: 0.01566181518137455, acc: 0.9955357313156128)
[2024-12-17 05:04:07,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:07,748][root][INFO] - Training Epoch: 2/2, step 2678/7134 completed (loss: 0.0041257101111114025, acc: 1.0)
[2024-12-17 05:04:07,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:08,211][root][INFO] - Training Epoch: 2/2, step 2679/7134 completed (loss: 0.013369634747505188, acc: 0.9955106377601624)
[2024-12-17 05:04:08,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:08,660][root][INFO] - Training Epoch: 2/2, step 2680/7134 completed (loss: 0.021163688972592354, acc: 0.9938347935676575)
[2024-12-17 05:04:08,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:09,064][root][INFO] - Training Epoch: 2/2, step 2681/7134 completed (loss: 0.011098298244178295, acc: 0.9954476356506348)
[2024-12-17 05:04:09,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:09,458][root][INFO] - Training Epoch: 2/2, step 2682/7134 completed (loss: 0.011313710361719131, acc: 0.9968101978302002)
[2024-12-17 05:04:09,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:09,862][root][INFO] - Training Epoch: 2/2, step 2683/7134 completed (loss: 0.009124750271439552, acc: 0.9969651103019714)
[2024-12-17 05:04:10,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:10,289][root][INFO] - Training Epoch: 2/2, step 2684/7134 completed (loss: 0.03847936540842056, acc: 0.9910394549369812)
[2024-12-17 05:04:10,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:10,749][root][INFO] - Training Epoch: 2/2, step 2685/7134 completed (loss: 0.015541259199380875, acc: 0.9960988163948059)
[2024-12-17 05:04:10,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:11,230][root][INFO] - Training Epoch: 2/2, step 2686/7134 completed (loss: 0.04941163957118988, acc: 0.9826388955116272)
[2024-12-17 05:04:11,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:11,661][root][INFO] - Training Epoch: 2/2, step 2687/7134 completed (loss: 0.039213526993989944, acc: 0.9840989112854004)
[2024-12-17 05:04:11,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:12,112][root][INFO] - Training Epoch: 2/2, step 2688/7134 completed (loss: 0.09952982515096664, acc: 0.9842767119407654)
[2024-12-17 05:04:12,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:12,473][root][INFO] - Training Epoch: 2/2, step 2689/7134 completed (loss: 0.05227791890501976, acc: 0.9873417615890503)
[2024-12-17 05:04:12,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:12,913][root][INFO] - Training Epoch: 2/2, step 2690/7134 completed (loss: 0.07620211690664291, acc: 0.9752704501152039)
[2024-12-17 05:04:13,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:13,331][root][INFO] - Training Epoch: 2/2, step 2691/7134 completed (loss: 0.0761730819940567, acc: 0.984375)
[2024-12-17 05:04:13,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:13,759][root][INFO] - Training Epoch: 2/2, step 2692/7134 completed (loss: 0.11823615431785583, acc: 0.968342661857605)
[2024-12-17 05:04:13,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:14,202][root][INFO] - Training Epoch: 2/2, step 2693/7134 completed (loss: 0.10151590406894684, acc: 0.9750000238418579)
[2024-12-17 05:04:14,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:14,640][root][INFO] - Training Epoch: 2/2, step 2694/7134 completed (loss: 0.0940326377749443, acc: 0.979411780834198)
[2024-12-17 05:04:14,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:15,118][root][INFO] - Training Epoch: 2/2, step 2695/7134 completed (loss: 0.04954484477639198, acc: 0.9832496047019958)
[2024-12-17 05:04:15,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:15,561][root][INFO] - Training Epoch: 2/2, step 2696/7134 completed (loss: 0.08571241796016693, acc: 0.9777424335479736)
[2024-12-17 05:04:15,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:15,974][root][INFO] - Training Epoch: 2/2, step 2697/7134 completed (loss: 0.08702104538679123, acc: 0.9661017060279846)
[2024-12-17 05:04:16,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:16,426][root][INFO] - Training Epoch: 2/2, step 2698/7134 completed (loss: 0.03714071586728096, acc: 0.9846153855323792)
[2024-12-17 05:04:16,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:16,888][root][INFO] - Training Epoch: 2/2, step 2699/7134 completed (loss: 0.059667520225048065, acc: 0.9801324605941772)
[2024-12-17 05:04:17,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:17,268][root][INFO] - Training Epoch: 2/2, step 2700/7134 completed (loss: 0.05316519737243652, acc: 0.9910979270935059)
[2024-12-17 05:04:17,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:17,683][root][INFO] - Training Epoch: 2/2, step 2701/7134 completed (loss: 0.07997286319732666, acc: 0.978151261806488)
[2024-12-17 05:04:17,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:18,089][root][INFO] - Training Epoch: 2/2, step 2702/7134 completed (loss: 0.07899102568626404, acc: 0.984375)
[2024-12-17 05:04:18,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:18,459][root][INFO] - Training Epoch: 2/2, step 2703/7134 completed (loss: 0.045850466936826706, acc: 0.9904458522796631)
[2024-12-17 05:04:18,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:18,914][root][INFO] - Training Epoch: 2/2, step 2704/7134 completed (loss: 0.05835938826203346, acc: 0.9878706336021423)
[2024-12-17 05:04:19,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:19,362][root][INFO] - Training Epoch: 2/2, step 2705/7134 completed (loss: 0.10617448389530182, acc: 0.9768518805503845)
[2024-12-17 05:04:19,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:19,837][root][INFO] - Training Epoch: 2/2, step 2706/7134 completed (loss: 0.05840643122792244, acc: 0.9811320900917053)
[2024-12-17 05:04:19,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:20,304][root][INFO] - Training Epoch: 2/2, step 2707/7134 completed (loss: 0.05749238654971123, acc: 0.9775862097740173)
[2024-12-17 05:04:20,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:20,764][root][INFO] - Training Epoch: 2/2, step 2708/7134 completed (loss: 0.06909076124429703, acc: 0.9747545719146729)
[2024-12-17 05:04:20,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:21,225][root][INFO] - Training Epoch: 2/2, step 2709/7134 completed (loss: 0.026494406163692474, acc: 0.9918830990791321)
[2024-12-17 05:04:21,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:21,661][root][INFO] - Training Epoch: 2/2, step 2710/7134 completed (loss: 0.02393055334687233, acc: 0.9930070042610168)
[2024-12-17 05:04:21,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:22,098][root][INFO] - Training Epoch: 2/2, step 2711/7134 completed (loss: 0.043561216443777084, acc: 0.9858490824699402)
[2024-12-17 05:04:22,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:22,540][root][INFO] - Training Epoch: 2/2, step 2712/7134 completed (loss: 0.05154377967119217, acc: 0.984375)
[2024-12-17 05:04:22,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:22,990][root][INFO] - Training Epoch: 2/2, step 2713/7134 completed (loss: 0.06756117194890976, acc: 0.9916434288024902)
[2024-12-17 05:04:23,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:23,455][root][INFO] - Training Epoch: 2/2, step 2714/7134 completed (loss: 0.047225821763277054, acc: 0.9866888523101807)
[2024-12-17 05:04:23,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:23,895][root][INFO] - Training Epoch: 2/2, step 2715/7134 completed (loss: 0.028189990669488907, acc: 0.9924812316894531)
[2024-12-17 05:04:24,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:24,334][root][INFO] - Training Epoch: 2/2, step 2716/7134 completed (loss: 0.03616556525230408, acc: 0.9908257126808167)
[2024-12-17 05:04:24,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:24,767][root][INFO] - Training Epoch: 2/2, step 2717/7134 completed (loss: 0.09342203289270401, acc: 0.975359320640564)
[2024-12-17 05:04:24,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:25,199][root][INFO] - Training Epoch: 2/2, step 2718/7134 completed (loss: 0.14134714007377625, acc: 0.9718309640884399)
[2024-12-17 05:04:25,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:25,653][root][INFO] - Training Epoch: 2/2, step 2719/7134 completed (loss: 0.08917780965566635, acc: 0.9813874959945679)
[2024-12-17 05:04:25,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:26,093][root][INFO] - Training Epoch: 2/2, step 2720/7134 completed (loss: 0.04642704501748085, acc: 0.9873816967010498)
[2024-12-17 05:04:26,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:26,466][root][INFO] - Training Epoch: 2/2, step 2721/7134 completed (loss: 0.04134013131260872, acc: 0.9942029118537903)
[2024-12-17 05:04:26,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:26,837][root][INFO] - Training Epoch: 2/2, step 2722/7134 completed (loss: 0.12299613654613495, acc: 0.97826087474823)
[2024-12-17 05:04:26,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:27,290][root][INFO] - Training Epoch: 2/2, step 2723/7134 completed (loss: 0.09231849759817123, acc: 0.9753997325897217)
[2024-12-17 05:04:27,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:27,733][root][INFO] - Training Epoch: 2/2, step 2724/7134 completed (loss: 0.07386773079633713, acc: 0.9781287908554077)
[2024-12-17 05:04:27,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:28,176][root][INFO] - Training Epoch: 2/2, step 2725/7134 completed (loss: 0.03237912058830261, acc: 0.9901477694511414)
[2024-12-17 05:04:28,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:28,639][root][INFO] - Training Epoch: 2/2, step 2726/7134 completed (loss: 0.06013530120253563, acc: 0.9815497994422913)
[2024-12-17 05:04:28,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:29,122][root][INFO] - Training Epoch: 2/2, step 2727/7134 completed (loss: 0.02844955213367939, acc: 0.9888888597488403)
[2024-12-17 05:04:29,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:29,552][root][INFO] - Training Epoch: 2/2, step 2728/7134 completed (loss: 0.1150621548295021, acc: 0.9724770784378052)
[2024-12-17 05:04:29,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:29,953][root][INFO] - Training Epoch: 2/2, step 2729/7134 completed (loss: 0.06269117444753647, acc: 0.9756097793579102)
[2024-12-17 05:04:30,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:30,366][root][INFO] - Training Epoch: 2/2, step 2730/7134 completed (loss: 0.08258014172315598, acc: 0.9770833253860474)
[2024-12-17 05:04:30,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:30,797][root][INFO] - Training Epoch: 2/2, step 2731/7134 completed (loss: 0.11489229649305344, acc: 0.9683698415756226)
[2024-12-17 05:04:30,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:31,242][root][INFO] - Training Epoch: 2/2, step 2732/7134 completed (loss: 0.04663315787911415, acc: 0.9873096346855164)
[2024-12-17 05:04:31,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:31,684][root][INFO] - Training Epoch: 2/2, step 2733/7134 completed (loss: 0.058018505573272705, acc: 0.9837177991867065)
[2024-12-17 05:04:31,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:32,097][root][INFO] - Training Epoch: 2/2, step 2734/7134 completed (loss: 0.05719514191150665, acc: 0.9839034080505371)
[2024-12-17 05:04:32,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:32,569][root][INFO] - Training Epoch: 2/2, step 2735/7134 completed (loss: 0.047368284314870834, acc: 0.9905149340629578)
[2024-12-17 05:04:32,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:32,961][root][INFO] - Training Epoch: 2/2, step 2736/7134 completed (loss: 0.08143919706344604, acc: 0.9720149040222168)
[2024-12-17 05:04:33,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:33,381][root][INFO] - Training Epoch: 2/2, step 2737/7134 completed (loss: 0.03777999058365822, acc: 0.9917491674423218)
[2024-12-17 05:04:33,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:33,786][root][INFO] - Training Epoch: 2/2, step 2738/7134 completed (loss: 0.04312579333782196, acc: 0.9871428608894348)
[2024-12-17 05:04:33,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:34,207][root][INFO] - Training Epoch: 2/2, step 2739/7134 completed (loss: 0.05997419357299805, acc: 0.9818181991577148)
[2024-12-17 05:04:34,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:34,634][root][INFO] - Training Epoch: 2/2, step 2740/7134 completed (loss: 0.02820705994963646, acc: 0.9912917017936707)
[2024-12-17 05:04:34,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:35,091][root][INFO] - Training Epoch: 2/2, step 2741/7134 completed (loss: 0.09824388474225998, acc: 0.9602803587913513)
[2024-12-17 05:04:35,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:35,538][root][INFO] - Training Epoch: 2/2, step 2742/7134 completed (loss: 0.036084990948438644, acc: 0.9895833134651184)
[2024-12-17 05:04:35,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:35,936][root][INFO] - Training Epoch: 2/2, step 2743/7134 completed (loss: 0.016725873574614525, acc: 0.99210524559021)
[2024-12-17 05:04:36,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:36,316][root][INFO] - Training Epoch: 2/2, step 2744/7134 completed (loss: 0.02752905897796154, acc: 0.9961685538291931)
[2024-12-17 05:04:36,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:36,688][root][INFO] - Training Epoch: 2/2, step 2745/7134 completed (loss: 0.10365602374076843, acc: 0.9790940880775452)
[2024-12-17 05:04:36,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:37,056][root][INFO] - Training Epoch: 2/2, step 2746/7134 completed (loss: 0.04389747232198715, acc: 0.9871794581413269)
[2024-12-17 05:04:37,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:37,458][root][INFO] - Training Epoch: 2/2, step 2747/7134 completed (loss: 0.036434151232242584, acc: 0.9901719689369202)
[2024-12-17 05:04:37,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:37,841][root][INFO] - Training Epoch: 2/2, step 2748/7134 completed (loss: 0.012899670749902725, acc: 0.9968152642250061)
[2024-12-17 05:04:37,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:38,254][root][INFO] - Training Epoch: 2/2, step 2749/7134 completed (loss: 0.061099082231521606, acc: 0.9863387942314148)
[2024-12-17 05:04:38,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:38,681][root][INFO] - Training Epoch: 2/2, step 2750/7134 completed (loss: 0.022891109809279442, acc: 0.995488703250885)
[2024-12-17 05:04:38,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:39,087][root][INFO] - Training Epoch: 2/2, step 2751/7134 completed (loss: 0.04622702673077583, acc: 0.9848101139068604)
[2024-12-17 05:04:39,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:39,505][root][INFO] - Training Epoch: 2/2, step 2752/7134 completed (loss: 0.04415370896458626, acc: 0.9866920113563538)
[2024-12-17 05:04:39,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:39,906][root][INFO] - Training Epoch: 2/2, step 2753/7134 completed (loss: 0.06858239322900772, acc: 0.9749373197555542)
[2024-12-17 05:04:40,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:40,349][root][INFO] - Training Epoch: 2/2, step 2754/7134 completed (loss: 0.06868598610162735, acc: 0.9776875972747803)
[2024-12-17 05:04:40,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:40,776][root][INFO] - Training Epoch: 2/2, step 2755/7134 completed (loss: 0.03373824805021286, acc: 0.9961240291595459)
[2024-12-17 05:04:40,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:41,179][root][INFO] - Training Epoch: 2/2, step 2756/7134 completed (loss: 0.0654907077550888, acc: 0.9790475964546204)
[2024-12-17 05:04:41,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:41,546][root][INFO] - Training Epoch: 2/2, step 2757/7134 completed (loss: 0.05200378596782684, acc: 0.9890710115432739)
[2024-12-17 05:04:41,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:41,953][root][INFO] - Training Epoch: 2/2, step 2758/7134 completed (loss: 0.05620090663433075, acc: 0.9863013625144958)
[2024-12-17 05:04:42,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:42,358][root][INFO] - Training Epoch: 2/2, step 2759/7134 completed (loss: 0.030991747975349426, acc: 0.9899665713310242)
[2024-12-17 05:04:42,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:42,750][root][INFO] - Training Epoch: 2/2, step 2760/7134 completed (loss: 0.0424078032374382, acc: 0.9873015880584717)
[2024-12-17 05:04:42,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:43,200][root][INFO] - Training Epoch: 2/2, step 2761/7134 completed (loss: 0.08511731028556824, acc: 0.9760100841522217)
[2024-12-17 05:04:43,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:43,672][root][INFO] - Training Epoch: 2/2, step 2762/7134 completed (loss: 0.05523281916975975, acc: 0.9827387928962708)
[2024-12-17 05:04:43,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:44,108][root][INFO] - Training Epoch: 2/2, step 2763/7134 completed (loss: 0.05858317017555237, acc: 0.9849246144294739)
[2024-12-17 05:04:44,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:44,554][root][INFO] - Training Epoch: 2/2, step 2764/7134 completed (loss: 0.08917026221752167, acc: 0.9723320007324219)
[2024-12-17 05:04:44,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:45,002][root][INFO] - Training Epoch: 2/2, step 2765/7134 completed (loss: 0.03659910336136818, acc: 0.9956896305084229)
[2024-12-17 05:04:45,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:45,465][root][INFO] - Training Epoch: 2/2, step 2766/7134 completed (loss: 0.04421663284301758, acc: 0.9822294116020203)
[2024-12-17 05:04:45,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:45,910][root][INFO] - Training Epoch: 2/2, step 2767/7134 completed (loss: 0.07870813459157944, acc: 0.9814814925193787)
[2024-12-17 05:04:46,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:46,351][root][INFO] - Training Epoch: 2/2, step 2768/7134 completed (loss: 0.052008431404829025, acc: 0.9886845946311951)
[2024-12-17 05:04:46,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:46,799][root][INFO] - Training Epoch: 2/2, step 2769/7134 completed (loss: 0.051156409084796906, acc: 0.9876126050949097)
[2024-12-17 05:04:46,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:47,259][root][INFO] - Training Epoch: 2/2, step 2770/7134 completed (loss: 0.034940917044878006, acc: 0.9916550517082214)
[2024-12-17 05:04:47,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:47,765][root][INFO] - Training Epoch: 2/2, step 2771/7134 completed (loss: 0.046492453664541245, acc: 0.9839228391647339)
[2024-12-17 05:04:47,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:48,242][root][INFO] - Training Epoch: 2/2, step 2772/7134 completed (loss: 0.02498546615242958, acc: 0.9899328947067261)
[2024-12-17 05:04:48,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:48,714][root][INFO] - Training Epoch: 2/2, step 2773/7134 completed (loss: 0.034389711916446686, acc: 0.9851428866386414)
[2024-12-17 05:04:48,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:49,170][root][INFO] - Training Epoch: 2/2, step 2774/7134 completed (loss: 0.061685334891080856, acc: 0.9835526347160339)
[2024-12-17 05:04:49,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:49,613][root][INFO] - Training Epoch: 2/2, step 2775/7134 completed (loss: 0.04249254986643791, acc: 0.987730085849762)
[2024-12-17 05:04:49,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:50,110][root][INFO] - Training Epoch: 2/2, step 2776/7134 completed (loss: 0.01813507452607155, acc: 0.9918200373649597)
[2024-12-17 05:04:50,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:50,563][root][INFO] - Training Epoch: 2/2, step 2777/7134 completed (loss: 0.024640170857310295, acc: 0.9939024448394775)
[2024-12-17 05:04:50,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:51,017][root][INFO] - Training Epoch: 2/2, step 2778/7134 completed (loss: 0.04493197798728943, acc: 0.9860950112342834)
[2024-12-17 05:04:51,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:51,478][root][INFO] - Training Epoch: 2/2, step 2779/7134 completed (loss: 0.04978341981768608, acc: 0.9862869381904602)
[2024-12-17 05:04:51,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:51,950][root][INFO] - Training Epoch: 2/2, step 2780/7134 completed (loss: 0.04543052241206169, acc: 0.9894514679908752)
[2024-12-17 05:04:52,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:52,419][root][INFO] - Training Epoch: 2/2, step 2781/7134 completed (loss: 0.034119416028261185, acc: 0.9883419871330261)
[2024-12-17 05:04:52,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:52,900][root][INFO] - Training Epoch: 2/2, step 2782/7134 completed (loss: 0.03138187900185585, acc: 0.9915966391563416)
[2024-12-17 05:04:53,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:53,337][root][INFO] - Training Epoch: 2/2, step 2783/7134 completed (loss: 0.023215401917696, acc: 0.9939939975738525)
[2024-12-17 05:04:53,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:53,806][root][INFO] - Training Epoch: 2/2, step 2784/7134 completed (loss: 0.038027163594961166, acc: 0.9905362725257874)
[2024-12-17 05:04:53,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:54,285][root][INFO] - Training Epoch: 2/2, step 2785/7134 completed (loss: 0.028698934242129326, acc: 0.9934498071670532)
[2024-12-17 05:04:54,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:54,752][root][INFO] - Training Epoch: 2/2, step 2786/7134 completed (loss: 0.03812528774142265, acc: 0.9865005016326904)
[2024-12-17 05:04:54,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:55,241][root][INFO] - Training Epoch: 2/2, step 2787/7134 completed (loss: 0.0334303118288517, acc: 0.9933599233627319)
[2024-12-17 05:04:55,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:55,690][root][INFO] - Training Epoch: 2/2, step 2788/7134 completed (loss: 0.0470544770359993, acc: 0.9829843044281006)
[2024-12-17 05:04:55,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:56,079][root][INFO] - Training Epoch: 2/2, step 2789/7134 completed (loss: 0.14889754354953766, acc: 0.9567723274230957)
[2024-12-17 05:04:56,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:56,471][root][INFO] - Training Epoch: 2/2, step 2790/7134 completed (loss: 0.1285567283630371, acc: 0.9713024497032166)
[2024-12-17 05:04:56,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:56,931][root][INFO] - Training Epoch: 2/2, step 2791/7134 completed (loss: 0.03417864814400673, acc: 0.9895366430282593)
[2024-12-17 05:04:57,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:57,405][root][INFO] - Training Epoch: 2/2, step 2792/7134 completed (loss: 0.044042665511369705, acc: 0.9895226955413818)
[2024-12-17 05:04:57,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:57,859][root][INFO] - Training Epoch: 2/2, step 2793/7134 completed (loss: 0.05535583570599556, acc: 0.9824561476707458)
[2024-12-17 05:04:57,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:58,254][root][INFO] - Training Epoch: 2/2, step 2794/7134 completed (loss: 0.028271296992897987, acc: 0.9934853315353394)
[2024-12-17 05:04:58,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:58,698][root][INFO] - Training Epoch: 2/2, step 2795/7134 completed (loss: 0.12074891477823257, acc: 0.9628770351409912)
[2024-12-17 05:04:58,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:59,085][root][INFO] - Training Epoch: 2/2, step 2796/7134 completed (loss: 0.15310610830783844, acc: 0.9516128897666931)
[2024-12-17 05:04:59,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:59,509][root][INFO] - Training Epoch: 2/2, step 2797/7134 completed (loss: 0.10422249138355255, acc: 0.9683544039726257)
[2024-12-17 05:04:59,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:04:59,936][root][INFO] - Training Epoch: 2/2, step 2798/7134 completed (loss: 0.07912502437829971, acc: 0.9747899174690247)
[2024-12-17 05:05:00,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:00,353][root][INFO] - Training Epoch: 2/2, step 2799/7134 completed (loss: 0.08227984607219696, acc: 0.9754816293716431)
[2024-12-17 05:05:00,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:00,767][root][INFO] - Training Epoch: 2/2, step 2800/7134 completed (loss: 0.09940017759799957, acc: 0.9736379384994507)
[2024-12-17 05:05:00,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:01,230][root][INFO] - Training Epoch: 2/2, step 2801/7134 completed (loss: 0.04166710376739502, acc: 0.9884910583496094)
[2024-12-17 05:05:01,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:01,698][root][INFO] - Training Epoch: 2/2, step 2802/7134 completed (loss: 0.07692346721887589, acc: 0.9775280952453613)
[2024-12-17 05:05:01,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:02,135][root][INFO] - Training Epoch: 2/2, step 2803/7134 completed (loss: 0.028468091040849686, acc: 0.9929278492927551)
[2024-12-17 05:05:02,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:02,616][root][INFO] - Training Epoch: 2/2, step 2804/7134 completed (loss: 0.049989040940999985, acc: 0.9876237511634827)
[2024-12-17 05:05:02,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:03,048][root][INFO] - Training Epoch: 2/2, step 2805/7134 completed (loss: 0.02368951216340065, acc: 0.9947299361228943)
[2024-12-17 05:05:03,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:03,463][root][INFO] - Training Epoch: 2/2, step 2806/7134 completed (loss: 0.06731770187616348, acc: 0.9819672107696533)
[2024-12-17 05:05:03,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:03,881][root][INFO] - Training Epoch: 2/2, step 2807/7134 completed (loss: 0.07894296199083328, acc: 0.9771309494972229)
[2024-12-17 05:05:04,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:04,335][root][INFO] - Training Epoch: 2/2, step 2808/7134 completed (loss: 0.03807838633656502, acc: 0.9885714054107666)
[2024-12-17 05:05:04,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:04,753][root][INFO] - Training Epoch: 2/2, step 2809/7134 completed (loss: 0.06494548171758652, acc: 0.9893048405647278)
[2024-12-17 05:05:04,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:05,247][root][INFO] - Training Epoch: 2/2, step 2810/7134 completed (loss: 0.040918584913015366, acc: 0.9869358539581299)
[2024-12-17 05:05:05,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:05,703][root][INFO] - Training Epoch: 2/2, step 2811/7134 completed (loss: 0.01109206210821867, acc: 0.9976133704185486)
[2024-12-17 05:05:05,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:06,151][root][INFO] - Training Epoch: 2/2, step 2812/7134 completed (loss: 0.02805580012500286, acc: 0.9907407164573669)
[2024-12-17 05:05:06,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:06,608][root][INFO] - Training Epoch: 2/2, step 2813/7134 completed (loss: 0.01694376952946186, acc: 0.992443323135376)
[2024-12-17 05:05:06,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:07,028][root][INFO] - Training Epoch: 2/2, step 2814/7134 completed (loss: 0.0403321273624897, acc: 0.9870129823684692)
[2024-12-17 05:05:07,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:07,473][root][INFO] - Training Epoch: 2/2, step 2815/7134 completed (loss: 0.0488477386534214, acc: 0.9869513511657715)
[2024-12-17 05:05:07,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:07,952][root][INFO] - Training Epoch: 2/2, step 2816/7134 completed (loss: 0.03952335566282272, acc: 0.9868247509002686)
[2024-12-17 05:05:08,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:08,444][root][INFO] - Training Epoch: 2/2, step 2817/7134 completed (loss: 0.05460519343614578, acc: 0.9884696006774902)
[2024-12-17 05:05:08,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:08,913][root][INFO] - Training Epoch: 2/2, step 2818/7134 completed (loss: 0.037512872368097305, acc: 0.9868420958518982)
[2024-12-17 05:05:09,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:09,343][root][INFO] - Training Epoch: 2/2, step 2819/7134 completed (loss: 0.017259592190384865, acc: 0.9967690110206604)
[2024-12-17 05:05:09,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:09,777][root][INFO] - Training Epoch: 2/2, step 2820/7134 completed (loss: 0.11534202843904495, acc: 0.9675993919372559)
[2024-12-17 05:05:09,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:10,224][root][INFO] - Training Epoch: 2/2, step 2821/7134 completed (loss: 0.05679778382182121, acc: 0.979689359664917)
[2024-12-17 05:05:10,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:10,670][root][INFO] - Training Epoch: 2/2, step 2822/7134 completed (loss: 0.06593859940767288, acc: 0.982300877571106)
[2024-12-17 05:05:10,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:11,162][root][INFO] - Training Epoch: 2/2, step 2823/7134 completed (loss: 0.0876978188753128, acc: 0.9730496406555176)
[2024-12-17 05:05:11,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:11,595][root][INFO] - Training Epoch: 2/2, step 2824/7134 completed (loss: 0.08985410630702972, acc: 0.9724025726318359)
[2024-12-17 05:05:11,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:12,036][root][INFO] - Training Epoch: 2/2, step 2825/7134 completed (loss: 0.06930913031101227, acc: 0.9798657894134521)
[2024-12-17 05:05:12,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:12,478][root][INFO] - Training Epoch: 2/2, step 2826/7134 completed (loss: 0.08125994354486465, acc: 0.9759036302566528)
[2024-12-17 05:05:12,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:12,929][root][INFO] - Training Epoch: 2/2, step 2827/7134 completed (loss: 0.06700635701417923, acc: 0.9782886505126953)
[2024-12-17 05:05:13,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:13,370][root][INFO] - Training Epoch: 2/2, step 2828/7134 completed (loss: 0.04919326677918434, acc: 0.9855999946594238)
[2024-12-17 05:05:13,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:13,823][root][INFO] - Training Epoch: 2/2, step 2829/7134 completed (loss: 0.07250908762216568, acc: 0.9849931597709656)
[2024-12-17 05:05:13,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:14,263][root][INFO] - Training Epoch: 2/2, step 2830/7134 completed (loss: 0.01706799864768982, acc: 0.9927140474319458)
[2024-12-17 05:05:14,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:14,688][root][INFO] - Training Epoch: 2/2, step 2831/7134 completed (loss: 0.028573932126164436, acc: 0.9905213117599487)
[2024-12-17 05:05:14,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:15,113][root][INFO] - Training Epoch: 2/2, step 2832/7134 completed (loss: 0.04932700842618942, acc: 0.9917582273483276)
[2024-12-17 05:05:15,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:15,557][root][INFO] - Training Epoch: 2/2, step 2833/7134 completed (loss: 0.039193395525217056, acc: 0.9894737005233765)
[2024-12-17 05:05:15,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:16,016][root][INFO] - Training Epoch: 2/2, step 2834/7134 completed (loss: 0.07536620646715164, acc: 0.9835025668144226)
[2024-12-17 05:05:16,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:16,465][root][INFO] - Training Epoch: 2/2, step 2835/7134 completed (loss: 0.049736831337213516, acc: 0.987075924873352)
[2024-12-17 05:05:16,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:16,888][root][INFO] - Training Epoch: 2/2, step 2836/7134 completed (loss: 0.04810241982340813, acc: 0.9834123253822327)
[2024-12-17 05:05:17,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:17,344][root][INFO] - Training Epoch: 2/2, step 2837/7134 completed (loss: 0.026579812169075012, acc: 0.9918919205665588)
[2024-12-17 05:05:17,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:17,828][root][INFO] - Training Epoch: 2/2, step 2838/7134 completed (loss: 0.08349001407623291, acc: 0.9769874215126038)
[2024-12-17 05:05:17,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:18,277][root][INFO] - Training Epoch: 2/2, step 2839/7134 completed (loss: 0.0358642041683197, acc: 0.9924127459526062)
[2024-12-17 05:05:18,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:18,750][root][INFO] - Training Epoch: 2/2, step 2840/7134 completed (loss: 0.024779187515378, acc: 0.9930939078330994)
[2024-12-17 05:05:18,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:19,192][root][INFO] - Training Epoch: 2/2, step 2841/7134 completed (loss: 0.03366180136799812, acc: 0.9884792566299438)
[2024-12-17 05:05:19,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:19,658][root][INFO] - Training Epoch: 2/2, step 2842/7134 completed (loss: 0.04658912494778633, acc: 0.983116865158081)
[2024-12-17 05:05:19,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:20,079][root][INFO] - Training Epoch: 2/2, step 2843/7134 completed (loss: 0.031352460384368896, acc: 0.9911764860153198)
[2024-12-17 05:05:20,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:20,532][root][INFO] - Training Epoch: 2/2, step 2844/7134 completed (loss: 0.10970310866832733, acc: 0.9712722301483154)
[2024-12-17 05:05:20,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:20,943][root][INFO] - Training Epoch: 2/2, step 2845/7134 completed (loss: 0.04051200672984123, acc: 0.9913344979286194)
[2024-12-17 05:05:21,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:21,363][root][INFO] - Training Epoch: 2/2, step 2846/7134 completed (loss: 0.0792866051197052, acc: 0.9818781018257141)
[2024-12-17 05:05:21,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:21,829][root][INFO] - Training Epoch: 2/2, step 2847/7134 completed (loss: 0.062018021941185, acc: 0.9853372573852539)
[2024-12-17 05:05:21,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:22,209][root][INFO] - Training Epoch: 2/2, step 2848/7134 completed (loss: 0.06962579488754272, acc: 0.9790209531784058)
[2024-12-17 05:05:22,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:22,657][root][INFO] - Training Epoch: 2/2, step 2849/7134 completed (loss: 0.0522993728518486, acc: 0.9875518679618835)
[2024-12-17 05:05:22,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:23,067][root][INFO] - Training Epoch: 2/2, step 2850/7134 completed (loss: 0.04140137881040573, acc: 0.9870967864990234)
[2024-12-17 05:05:23,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:23,490][root][INFO] - Training Epoch: 2/2, step 2851/7134 completed (loss: 0.027609532698988914, acc: 0.990791916847229)
[2024-12-17 05:05:23,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:23,889][root][INFO] - Training Epoch: 2/2, step 2852/7134 completed (loss: 0.02160755544900894, acc: 0.9960238337516785)
[2024-12-17 05:05:24,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:24,275][root][INFO] - Training Epoch: 2/2, step 2853/7134 completed (loss: 0.038162801414728165, acc: 0.9923858046531677)
[2024-12-17 05:05:24,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:24,708][root][INFO] - Training Epoch: 2/2, step 2854/7134 completed (loss: 0.03931169584393501, acc: 0.98959881067276)
[2024-12-17 05:05:24,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:25,127][root][INFO] - Training Epoch: 2/2, step 2855/7134 completed (loss: 0.048888590186834335, acc: 0.987075924873352)
[2024-12-17 05:05:25,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:25,581][root][INFO] - Training Epoch: 2/2, step 2856/7134 completed (loss: 0.01647976040840149, acc: 0.994358241558075)
[2024-12-17 05:05:25,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:26,014][root][INFO] - Training Epoch: 2/2, step 2857/7134 completed (loss: 0.05505548417568207, acc: 0.9884393215179443)
[2024-12-17 05:05:26,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:26,408][root][INFO] - Training Epoch: 2/2, step 2858/7134 completed (loss: 0.021965211257338524, acc: 0.9936908483505249)
[2024-12-17 05:05:26,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:26,834][root][INFO] - Training Epoch: 2/2, step 2859/7134 completed (loss: 0.04948209971189499, acc: 0.9860529899597168)
[2024-12-17 05:05:26,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:27,246][root][INFO] - Training Epoch: 2/2, step 2860/7134 completed (loss: 0.03552582859992981, acc: 0.9834862351417542)
[2024-12-17 05:05:27,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:27,657][root][INFO] - Training Epoch: 2/2, step 2861/7134 completed (loss: 0.00918718334287405, acc: 0.9979715943336487)
[2024-12-17 05:05:27,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:28,069][root][INFO] - Training Epoch: 2/2, step 2862/7134 completed (loss: 0.015961650758981705, acc: 0.994854211807251)
[2024-12-17 05:05:28,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:28,519][root][INFO] - Training Epoch: 2/2, step 2863/7134 completed (loss: 0.00810276810079813, acc: 0.9974522590637207)
[2024-12-17 05:05:28,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:28,893][root][INFO] - Training Epoch: 2/2, step 2864/7134 completed (loss: 0.022747334092855453, acc: 0.9922077655792236)
[2024-12-17 05:05:29,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:29,324][root][INFO] - Training Epoch: 2/2, step 2865/7134 completed (loss: 0.019058778882026672, acc: 0.989130437374115)
[2024-12-17 05:05:29,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:29,788][root][INFO] - Training Epoch: 2/2, step 2866/7134 completed (loss: 0.03824396803975105, acc: 0.988041877746582)
[2024-12-17 05:05:29,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:30,236][root][INFO] - Training Epoch: 2/2, step 2867/7134 completed (loss: 0.02976325899362564, acc: 0.9907975196838379)
[2024-12-17 05:05:30,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:30,639][root][INFO] - Training Epoch: 2/2, step 2868/7134 completed (loss: 0.009003044106066227, acc: 1.0)
[2024-12-17 05:05:30,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:31,070][root][INFO] - Training Epoch: 2/2, step 2869/7134 completed (loss: 0.05604631453752518, acc: 0.9926793575286865)
[2024-12-17 05:05:31,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:31,502][root][INFO] - Training Epoch: 2/2, step 2870/7134 completed (loss: 0.06728751212358475, acc: 0.9853249192237854)
[2024-12-17 05:05:31,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:31,892][root][INFO] - Training Epoch: 2/2, step 2871/7134 completed (loss: 0.05064871162176132, acc: 0.9828392863273621)
[2024-12-17 05:05:32,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:32,335][root][INFO] - Training Epoch: 2/2, step 2872/7134 completed (loss: 0.012854933738708496, acc: 0.99609375)
[2024-12-17 05:05:32,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:32,753][root][INFO] - Training Epoch: 2/2, step 2873/7134 completed (loss: 0.011685920879244804, acc: 0.9963503479957581)
[2024-12-17 05:05:32,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:33,172][root][INFO] - Training Epoch: 2/2, step 2874/7134 completed (loss: 0.030641306191682816, acc: 0.9921996593475342)
[2024-12-17 05:05:33,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:33,602][root][INFO] - Training Epoch: 2/2, step 2875/7134 completed (loss: 0.04032116383314133, acc: 0.9900426864624023)
[2024-12-17 05:05:33,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:34,012][root][INFO] - Training Epoch: 2/2, step 2876/7134 completed (loss: 0.10847081989049911, acc: 0.981566846370697)
[2024-12-17 05:05:34,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:34,424][root][INFO] - Training Epoch: 2/2, step 2877/7134 completed (loss: 0.01903463341295719, acc: 0.9912663698196411)
[2024-12-17 05:05:34,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:34,836][root][INFO] - Training Epoch: 2/2, step 2878/7134 completed (loss: 0.0329616479575634, acc: 0.9978813529014587)
[2024-12-17 05:05:34,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:35,250][root][INFO] - Training Epoch: 2/2, step 2879/7134 completed (loss: 0.013746227137744427, acc: 0.9968652129173279)
[2024-12-17 05:05:35,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:35,684][root][INFO] - Training Epoch: 2/2, step 2880/7134 completed (loss: 0.013866717927157879, acc: 0.9937499761581421)
[2024-12-17 05:05:35,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:36,073][root][INFO] - Training Epoch: 2/2, step 2881/7134 completed (loss: 0.03078916296362877, acc: 0.9928443431854248)
[2024-12-17 05:05:36,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:36,511][root][INFO] - Training Epoch: 2/2, step 2882/7134 completed (loss: 0.04634788632392883, acc: 0.9839704036712646)
[2024-12-17 05:05:36,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:36,947][root][INFO] - Training Epoch: 2/2, step 2883/7134 completed (loss: 0.05657435581088066, acc: 0.9854497313499451)
[2024-12-17 05:05:37,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:37,376][root][INFO] - Training Epoch: 2/2, step 2884/7134 completed (loss: 0.079813152551651, acc: 0.9819004535675049)
[2024-12-17 05:05:37,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:37,804][root][INFO] - Training Epoch: 2/2, step 2885/7134 completed (loss: 0.03851732984185219, acc: 0.9863429665565491)
[2024-12-17 05:05:37,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:38,206][root][INFO] - Training Epoch: 2/2, step 2886/7134 completed (loss: 0.09462454169988632, acc: 0.9746268391609192)
[2024-12-17 05:05:38,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:38,680][root][INFO] - Training Epoch: 2/2, step 2887/7134 completed (loss: 0.04224943369626999, acc: 0.9893491268157959)
[2024-12-17 05:05:38,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:39,133][root][INFO] - Training Epoch: 2/2, step 2888/7134 completed (loss: 0.06563640385866165, acc: 0.9833564758300781)
[2024-12-17 05:05:39,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:39,574][root][INFO] - Training Epoch: 2/2, step 2889/7134 completed (loss: 0.021683676168322563, acc: 0.9930747747421265)
[2024-12-17 05:05:39,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:40,024][root][INFO] - Training Epoch: 2/2, step 2890/7134 completed (loss: 0.020474137738347054, acc: 0.9946737885475159)
[2024-12-17 05:05:40,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:40,468][root][INFO] - Training Epoch: 2/2, step 2891/7134 completed (loss: 0.04102645441889763, acc: 0.989230751991272)
[2024-12-17 05:05:40,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:40,914][root][INFO] - Training Epoch: 2/2, step 2892/7134 completed (loss: 0.06180843338370323, acc: 0.98740553855896)
[2024-12-17 05:05:41,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:41,360][root][INFO] - Training Epoch: 2/2, step 2893/7134 completed (loss: 0.05472709611058235, acc: 0.9848675727844238)
[2024-12-17 05:05:41,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:41,809][root][INFO] - Training Epoch: 2/2, step 2894/7134 completed (loss: 0.06862421333789825, acc: 0.9798319339752197)
[2024-12-17 05:05:41,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:42,215][root][INFO] - Training Epoch: 2/2, step 2895/7134 completed (loss: 0.02751956880092621, acc: 0.992438554763794)
[2024-12-17 05:05:42,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:42,661][root][INFO] - Training Epoch: 2/2, step 2896/7134 completed (loss: 0.027596207335591316, acc: 0.9898219108581543)
[2024-12-17 05:05:42,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:43,066][root][INFO] - Training Epoch: 2/2, step 2897/7134 completed (loss: 0.047696296125650406, acc: 0.9857904314994812)
[2024-12-17 05:05:43,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:43,495][root][INFO] - Training Epoch: 2/2, step 2898/7134 completed (loss: 0.04158754646778107, acc: 0.9921568632125854)
[2024-12-17 05:05:43,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:43,917][root][INFO] - Training Epoch: 2/2, step 2899/7134 completed (loss: 0.018496263772249222, acc: 0.9970930218696594)
[2024-12-17 05:05:44,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:44,358][root][INFO] - Training Epoch: 2/2, step 2900/7134 completed (loss: 0.045270826667547226, acc: 0.9913580417633057)
[2024-12-17 05:05:44,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:44,776][root][INFO] - Training Epoch: 2/2, step 2901/7134 completed (loss: 0.0337640754878521, acc: 0.9920381903648376)
[2024-12-17 05:05:44,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:45,149][root][INFO] - Training Epoch: 2/2, step 2902/7134 completed (loss: 0.03106267750263214, acc: 0.9906014800071716)
[2024-12-17 05:05:45,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:45,594][root][INFO] - Training Epoch: 2/2, step 2903/7134 completed (loss: 0.05076161026954651, acc: 0.9811066389083862)
[2024-12-17 05:05:45,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:46,040][root][INFO] - Training Epoch: 2/2, step 2904/7134 completed (loss: 0.016752300783991814, acc: 0.9925093650817871)
[2024-12-17 05:05:46,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:46,480][root][INFO] - Training Epoch: 2/2, step 2905/7134 completed (loss: 0.039573606103658676, acc: 0.9887359142303467)
[2024-12-17 05:05:46,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:46,926][root][INFO] - Training Epoch: 2/2, step 2906/7134 completed (loss: 0.018395720049738884, acc: 0.9940119981765747)
[2024-12-17 05:05:47,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:47,353][root][INFO] - Training Epoch: 2/2, step 2907/7134 completed (loss: 0.05679185688495636, acc: 0.983849287033081)
[2024-12-17 05:05:47,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:47,797][root][INFO] - Training Epoch: 2/2, step 2908/7134 completed (loss: 0.027507169172167778, acc: 0.9922380447387695)
[2024-12-17 05:05:47,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:48,242][root][INFO] - Training Epoch: 2/2, step 2909/7134 completed (loss: 0.03092935122549534, acc: 0.9928057789802551)
[2024-12-17 05:05:48,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:48,689][root][INFO] - Training Epoch: 2/2, step 2910/7134 completed (loss: 0.06326676160097122, acc: 0.9828693866729736)
[2024-12-17 05:05:48,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:49,157][root][INFO] - Training Epoch: 2/2, step 2911/7134 completed (loss: 0.007993022911250591, acc: 0.9986577033996582)
[2024-12-17 05:05:49,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:49,627][root][INFO] - Training Epoch: 2/2, step 2912/7134 completed (loss: 0.02426694892346859, acc: 0.9903448224067688)
[2024-12-17 05:05:49,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:50,086][root][INFO] - Training Epoch: 2/2, step 2913/7134 completed (loss: 0.04159856215119362, acc: 0.9886040091514587)
[2024-12-17 05:05:50,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:50,552][root][INFO] - Training Epoch: 2/2, step 2914/7134 completed (loss: 0.025433558970689774, acc: 0.993968665599823)
[2024-12-17 05:05:50,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:50,993][root][INFO] - Training Epoch: 2/2, step 2915/7134 completed (loss: 0.07823392003774643, acc: 0.9812679886817932)
[2024-12-17 05:05:51,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:51,395][root][INFO] - Training Epoch: 2/2, step 2916/7134 completed (loss: 0.052223268896341324, acc: 0.9845361113548279)
[2024-12-17 05:05:51,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:51,833][root][INFO] - Training Epoch: 2/2, step 2917/7134 completed (loss: 0.026487456634640694, acc: 0.9932998418807983)
[2024-12-17 05:05:51,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:52,272][root][INFO] - Training Epoch: 2/2, step 2918/7134 completed (loss: 0.02562648430466652, acc: 0.9941725134849548)
[2024-12-17 05:05:52,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:52,673][root][INFO] - Training Epoch: 2/2, step 2919/7134 completed (loss: 0.06778980046510696, acc: 0.9905992746353149)
[2024-12-17 05:05:52,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:53,155][root][INFO] - Training Epoch: 2/2, step 2920/7134 completed (loss: 0.03350010886788368, acc: 0.9894039630889893)
[2024-12-17 05:05:53,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:53,588][root][INFO] - Training Epoch: 2/2, step 2921/7134 completed (loss: 0.027160191908478737, acc: 0.9899425506591797)
[2024-12-17 05:05:53,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:53,998][root][INFO] - Training Epoch: 2/2, step 2922/7134 completed (loss: 0.0627812072634697, acc: 0.9886934757232666)
[2024-12-17 05:05:54,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:54,437][root][INFO] - Training Epoch: 2/2, step 2923/7134 completed (loss: 0.1533619463443756, acc: 0.9738863110542297)
[2024-12-17 05:05:54,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:54,849][root][INFO] - Training Epoch: 2/2, step 2924/7134 completed (loss: 0.023801438510417938, acc: 0.9941037893295288)
[2024-12-17 05:05:54,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:55,339][root][INFO] - Training Epoch: 2/2, step 2925/7134 completed (loss: 0.04401763156056404, acc: 0.9901719689369202)
[2024-12-17 05:05:55,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:55,808][root][INFO] - Training Epoch: 2/2, step 2926/7134 completed (loss: 0.15278694033622742, acc: 0.973557710647583)
[2024-12-17 05:05:55,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:56,261][root][INFO] - Training Epoch: 2/2, step 2927/7134 completed (loss: 0.01521139033138752, acc: 0.9975816011428833)
[2024-12-17 05:05:56,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:56,703][root][INFO] - Training Epoch: 2/2, step 2928/7134 completed (loss: 0.0349096916615963, acc: 0.9908536672592163)
[2024-12-17 05:05:56,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:57,175][root][INFO] - Training Epoch: 2/2, step 2929/7134 completed (loss: 0.026641959324479103, acc: 0.9921671152114868)
[2024-12-17 05:05:57,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:57,629][root][INFO] - Training Epoch: 2/2, step 2930/7134 completed (loss: 0.05058188736438751, acc: 0.988252580165863)
[2024-12-17 05:05:57,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:58,046][root][INFO] - Training Epoch: 2/2, step 2931/7134 completed (loss: 0.06136002764105797, acc: 0.9835575222969055)
[2024-12-17 05:05:58,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:58,474][root][INFO] - Training Epoch: 2/2, step 2932/7134 completed (loss: 0.026294603943824768, acc: 0.9942062497138977)
[2024-12-17 05:05:58,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:58,921][root][INFO] - Training Epoch: 2/2, step 2933/7134 completed (loss: 0.03996552154421806, acc: 0.9884560108184814)
[2024-12-17 05:05:59,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:59,377][root][INFO] - Training Epoch: 2/2, step 2934/7134 completed (loss: 0.017371242865920067, acc: 0.995768666267395)
[2024-12-17 05:05:59,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:05:59,817][root][INFO] - Training Epoch: 2/2, step 2935/7134 completed (loss: 0.027241570875048637, acc: 0.9933920502662659)
[2024-12-17 05:05:59,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:00,291][root][INFO] - Training Epoch: 2/2, step 2936/7134 completed (loss: 0.041316207498311996, acc: 0.9888097643852234)
[2024-12-17 05:06:00,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:00,704][root][INFO] - Training Epoch: 2/2, step 2937/7134 completed (loss: 0.05217820778489113, acc: 0.9842180609703064)
[2024-12-17 05:06:00,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:01,134][root][INFO] - Training Epoch: 2/2, step 2938/7134 completed (loss: 0.02747882716357708, acc: 0.9910614490509033)
[2024-12-17 05:06:01,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:01,529][root][INFO] - Training Epoch: 2/2, step 2939/7134 completed (loss: 0.02466529980301857, acc: 0.995192289352417)
[2024-12-17 05:06:01,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:01,952][root][INFO] - Training Epoch: 2/2, step 2940/7134 completed (loss: 0.060244251042604446, acc: 0.9876881241798401)
[2024-12-17 05:06:02,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:02,401][root][INFO] - Training Epoch: 2/2, step 2941/7134 completed (loss: 0.025977643206715584, acc: 0.9927431344985962)
[2024-12-17 05:06:02,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:02,804][root][INFO] - Training Epoch: 2/2, step 2942/7134 completed (loss: 0.0377025231719017, acc: 0.9925705790519714)
[2024-12-17 05:06:02,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:03,227][root][INFO] - Training Epoch: 2/2, step 2943/7134 completed (loss: 0.013279597274959087, acc: 0.9966273307800293)
[2024-12-17 05:06:03,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:03,661][root][INFO] - Training Epoch: 2/2, step 2944/7134 completed (loss: 0.036735158413648605, acc: 0.988252580165863)
[2024-12-17 05:06:03,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:04,102][root][INFO] - Training Epoch: 2/2, step 2945/7134 completed (loss: 0.020385079085826874, acc: 0.993779182434082)
[2024-12-17 05:06:04,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:04,539][root][INFO] - Training Epoch: 2/2, step 2946/7134 completed (loss: 0.048469915986061096, acc: 0.9883720874786377)
[2024-12-17 05:06:04,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:04,977][root][INFO] - Training Epoch: 2/2, step 2947/7134 completed (loss: 0.042824260890483856, acc: 0.9811320900917053)
[2024-12-17 05:06:05,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:05,395][root][INFO] - Training Epoch: 2/2, step 2948/7134 completed (loss: 0.04838775843381882, acc: 0.9884678721427917)
[2024-12-17 05:06:05,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:05,804][root][INFO] - Training Epoch: 2/2, step 2949/7134 completed (loss: 0.004329896066337824, acc: 1.0)
[2024-12-17 05:06:05,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:06,228][root][INFO] - Training Epoch: 2/2, step 2950/7134 completed (loss: 0.021225187927484512, acc: 0.9958620667457581)
[2024-12-17 05:06:06,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:06,651][root][INFO] - Training Epoch: 2/2, step 2951/7134 completed (loss: 0.010786354541778564, acc: 0.9971014261245728)
[2024-12-17 05:06:06,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:07,070][root][INFO] - Training Epoch: 2/2, step 2952/7134 completed (loss: 0.015509558841586113, acc: 0.997032642364502)
[2024-12-17 05:06:07,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:07,471][root][INFO] - Training Epoch: 2/2, step 2953/7134 completed (loss: 0.03257954493165016, acc: 0.9898648858070374)
[2024-12-17 05:06:07,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:07,902][root][INFO] - Training Epoch: 2/2, step 2954/7134 completed (loss: 0.033608030527830124, acc: 0.9897040128707886)
[2024-12-17 05:06:07,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:08,298][root][INFO] - Training Epoch: 2/2, step 2955/7134 completed (loss: 0.02327987737953663, acc: 0.9900568127632141)
[2024-12-17 05:06:08,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:08,732][root][INFO] - Training Epoch: 2/2, step 2956/7134 completed (loss: 0.017566079273819923, acc: 0.9941434860229492)
[2024-12-17 05:06:08,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:09,168][root][INFO] - Training Epoch: 2/2, step 2957/7134 completed (loss: 0.017586970701813698, acc: 0.9946523904800415)
[2024-12-17 05:06:09,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:09,576][root][INFO] - Training Epoch: 2/2, step 2958/7134 completed (loss: 0.02170000597834587, acc: 0.9931623935699463)
[2024-12-17 05:06:09,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:09,981][root][INFO] - Training Epoch: 2/2, step 2959/7134 completed (loss: 0.01613614335656166, acc: 0.9941520690917969)
[2024-12-17 05:06:10,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:10,442][root][INFO] - Training Epoch: 2/2, step 2960/7134 completed (loss: 0.015340564772486687, acc: 0.994490385055542)
[2024-12-17 05:06:10,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:10,887][root][INFO] - Training Epoch: 2/2, step 2961/7134 completed (loss: 0.015380083583295345, acc: 0.9972789287567139)
[2024-12-17 05:06:10,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:11,299][root][INFO] - Training Epoch: 2/2, step 2962/7134 completed (loss: 0.019041195511817932, acc: 0.9948253631591797)
[2024-12-17 05:06:11,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:11,753][root][INFO] - Training Epoch: 2/2, step 2963/7134 completed (loss: 0.01597241498529911, acc: 0.9947643876075745)
[2024-12-17 05:06:11,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:12,179][root][INFO] - Training Epoch: 2/2, step 2964/7134 completed (loss: 0.021214410662651062, acc: 0.9926793575286865)
[2024-12-17 05:06:12,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:12,593][root][INFO] - Training Epoch: 2/2, step 2965/7134 completed (loss: 0.05638160556554794, acc: 0.9820895791053772)
[2024-12-17 05:06:12,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:13,009][root][INFO] - Training Epoch: 2/2, step 2966/7134 completed (loss: 0.007331824395805597, acc: 1.0)
[2024-12-17 05:06:13,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:13,427][root][INFO] - Training Epoch: 2/2, step 2967/7134 completed (loss: 0.027355225756764412, acc: 0.9916201233863831)
[2024-12-17 05:06:13,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:13,892][root][INFO] - Training Epoch: 2/2, step 2968/7134 completed (loss: 0.11631186306476593, acc: 0.9742765426635742)
[2024-12-17 05:06:14,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:14,309][root][INFO] - Training Epoch: 2/2, step 2969/7134 completed (loss: 0.2699633240699768, acc: 0.9467455744743347)
[2024-12-17 05:06:14,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:14,731][root][INFO] - Training Epoch: 2/2, step 2970/7134 completed (loss: 0.27692943811416626, acc: 0.9389978051185608)
[2024-12-17 05:06:14,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:15,165][root][INFO] - Training Epoch: 2/2, step 2971/7134 completed (loss: 0.05014420673251152, acc: 0.9855453372001648)
[2024-12-17 05:06:15,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:15,583][root][INFO] - Training Epoch: 2/2, step 2972/7134 completed (loss: 0.027895290404558182, acc: 0.9955489635467529)
[2024-12-17 05:06:15,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:16,016][root][INFO] - Training Epoch: 2/2, step 2973/7134 completed (loss: 0.05271676927804947, acc: 0.9860759377479553)
[2024-12-17 05:06:16,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:16,456][root][INFO] - Training Epoch: 2/2, step 2974/7134 completed (loss: 0.04082126170396805, acc: 0.9896238446235657)
[2024-12-17 05:06:16,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:16,894][root][INFO] - Training Epoch: 2/2, step 2975/7134 completed (loss: 0.04335775598883629, acc: 0.9820442199707031)
[2024-12-17 05:06:16,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:17,360][root][INFO] - Training Epoch: 2/2, step 2976/7134 completed (loss: 0.040450431406497955, acc: 0.9882978796958923)
[2024-12-17 05:06:17,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:17,788][root][INFO] - Training Epoch: 2/2, step 2977/7134 completed (loss: 0.045738380402326584, acc: 0.986994206905365)
[2024-12-17 05:06:17,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:18,219][root][INFO] - Training Epoch: 2/2, step 2978/7134 completed (loss: 0.03473435714840889, acc: 0.9914893507957458)
[2024-12-17 05:06:18,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:18,635][root][INFO] - Training Epoch: 2/2, step 2979/7134 completed (loss: 0.014414280652999878, acc: 0.9953271150588989)
[2024-12-17 05:06:18,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:19,086][root][INFO] - Training Epoch: 2/2, step 2980/7134 completed (loss: 0.051838330924510956, acc: 0.9898089170455933)
[2024-12-17 05:06:19,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:19,527][root][INFO] - Training Epoch: 2/2, step 2981/7134 completed (loss: 0.0762433335185051, acc: 0.9837177991867065)
[2024-12-17 05:06:19,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:19,944][root][INFO] - Training Epoch: 2/2, step 2982/7134 completed (loss: 0.039389628916978836, acc: 0.9882199168205261)
[2024-12-17 05:06:20,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:20,373][root][INFO] - Training Epoch: 2/2, step 2983/7134 completed (loss: 0.07440029829740524, acc: 0.9828042387962341)
[2024-12-17 05:06:20,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:20,828][root][INFO] - Training Epoch: 2/2, step 2984/7134 completed (loss: 0.03196308761835098, acc: 0.99245285987854)
[2024-12-17 05:06:20,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:21,281][root][INFO] - Training Epoch: 2/2, step 2985/7134 completed (loss: 0.038854457437992096, acc: 0.9916567206382751)
[2024-12-17 05:06:21,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:21,757][root][INFO] - Training Epoch: 2/2, step 2986/7134 completed (loss: 0.02127501554787159, acc: 0.9940898418426514)
[2024-12-17 05:06:21,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:22,200][root][INFO] - Training Epoch: 2/2, step 2987/7134 completed (loss: 0.0344964899122715, acc: 0.9905771613121033)
[2024-12-17 05:06:22,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:22,643][root][INFO] - Training Epoch: 2/2, step 2988/7134 completed (loss: 0.026631392538547516, acc: 0.9927007555961609)
[2024-12-17 05:06:22,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:23,085][root][INFO] - Training Epoch: 2/2, step 2989/7134 completed (loss: 0.025029761716723442, acc: 0.9934640526771545)
[2024-12-17 05:06:23,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:23,474][root][INFO] - Training Epoch: 2/2, step 2990/7134 completed (loss: 0.1250804215669632, acc: 0.9667832255363464)
[2024-12-17 05:06:23,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:23,882][root][INFO] - Training Epoch: 2/2, step 2991/7134 completed (loss: 0.1296040117740631, acc: 0.9653259515762329)
[2024-12-17 05:06:23,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:24,291][root][INFO] - Training Epoch: 2/2, step 2992/7134 completed (loss: 0.07170692086219788, acc: 0.9788838624954224)
[2024-12-17 05:06:24,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:24,751][root][INFO] - Training Epoch: 2/2, step 2993/7134 completed (loss: 0.04545814171433449, acc: 0.9914425611495972)
[2024-12-17 05:06:24,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:25,174][root][INFO] - Training Epoch: 2/2, step 2994/7134 completed (loss: 0.02341783232986927, acc: 0.9928057789802551)
[2024-12-17 05:06:25,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:25,649][root][INFO] - Training Epoch: 2/2, step 2995/7134 completed (loss: 0.0257913488894701, acc: 0.994350254535675)
[2024-12-17 05:06:25,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:26,083][root][INFO] - Training Epoch: 2/2, step 2996/7134 completed (loss: 0.034436360001564026, acc: 0.9894737005233765)
[2024-12-17 05:06:26,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:26,546][root][INFO] - Training Epoch: 2/2, step 2997/7134 completed (loss: 0.01927788369357586, acc: 0.9958419799804688)
[2024-12-17 05:06:26,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:26,955][root][INFO] - Training Epoch: 2/2, step 2998/7134 completed (loss: 0.02248133346438408, acc: 0.9951515197753906)
[2024-12-17 05:06:27,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:27,439][root][INFO] - Training Epoch: 2/2, step 2999/7134 completed (loss: 0.02625017985701561, acc: 0.9927641153335571)
[2024-12-17 05:06:27,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:27,919][root][INFO] - Training Epoch: 2/2, step 3000/7134 completed (loss: 0.024994932115077972, acc: 0.9946466684341431)
[2024-12-17 05:06:28,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:28,393][root][INFO] - Training Epoch: 2/2, step 3001/7134 completed (loss: 0.022317804396152496, acc: 0.991706132888794)
[2024-12-17 05:06:28,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:28,856][root][INFO] - Training Epoch: 2/2, step 3002/7134 completed (loss: 0.0254818182438612, acc: 0.9920634627342224)
[2024-12-17 05:06:28,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:29,321][root][INFO] - Training Epoch: 2/2, step 3003/7134 completed (loss: 0.012671275064349174, acc: 0.9965197443962097)
[2024-12-17 05:06:29,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:29,779][root][INFO] - Training Epoch: 2/2, step 3004/7134 completed (loss: 0.00969991460442543, acc: 0.9977653622627258)
[2024-12-17 05:06:29,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:30,251][root][INFO] - Training Epoch: 2/2, step 3005/7134 completed (loss: 0.017452212050557137, acc: 0.9942987561225891)
[2024-12-17 05:06:30,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:30,715][root][INFO] - Training Epoch: 2/2, step 3006/7134 completed (loss: 0.014718134887516499, acc: 0.9948914647102356)
[2024-12-17 05:06:30,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:31,164][root][INFO] - Training Epoch: 2/2, step 3007/7134 completed (loss: 0.027308788150548935, acc: 0.9941452145576477)
[2024-12-17 05:06:31,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:31,586][root][INFO] - Training Epoch: 2/2, step 3008/7134 completed (loss: 0.04903947934508324, acc: 0.9874125719070435)
[2024-12-17 05:06:31,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:31,995][root][INFO] - Training Epoch: 2/2, step 3009/7134 completed (loss: 0.08098713308572769, acc: 0.9822784662246704)
[2024-12-17 05:06:32,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:32,459][root][INFO] - Training Epoch: 2/2, step 3010/7134 completed (loss: 0.0423426628112793, acc: 0.9878453016281128)
[2024-12-17 05:06:32,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:32,894][root][INFO] - Training Epoch: 2/2, step 3011/7134 completed (loss: 0.0876069888472557, acc: 0.980028510093689)
[2024-12-17 05:06:32,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:33,325][root][INFO] - Training Epoch: 2/2, step 3012/7134 completed (loss: 0.06467211246490479, acc: 0.9809825420379639)
[2024-12-17 05:06:33,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:33,821][root][INFO] - Training Epoch: 2/2, step 3013/7134 completed (loss: 0.015504203736782074, acc: 0.9953917264938354)
[2024-12-17 05:06:33,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:34,261][root][INFO] - Training Epoch: 2/2, step 3014/7134 completed (loss: 0.03161809220910072, acc: 0.9882766604423523)
[2024-12-17 05:06:34,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:34,661][root][INFO] - Training Epoch: 2/2, step 3015/7134 completed (loss: 0.025648238137364388, acc: 0.9931129217147827)
[2024-12-17 05:06:34,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:35,123][root][INFO] - Training Epoch: 2/2, step 3016/7134 completed (loss: 0.012792042456567287, acc: 0.997187077999115)
[2024-12-17 05:06:35,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:35,550][root][INFO] - Training Epoch: 2/2, step 3017/7134 completed (loss: 0.032282717525959015, acc: 0.988135576248169)
[2024-12-17 05:06:35,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:35,941][root][INFO] - Training Epoch: 2/2, step 3018/7134 completed (loss: 0.03446489945054054, acc: 0.9950413107872009)
[2024-12-17 05:06:36,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:36,380][root][INFO] - Training Epoch: 2/2, step 3019/7134 completed (loss: 0.029549116268754005, acc: 0.9950980544090271)
[2024-12-17 05:06:36,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:36,808][root][INFO] - Training Epoch: 2/2, step 3020/7134 completed (loss: 0.04684704914689064, acc: 0.9857397675514221)
[2024-12-17 05:06:36,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:37,231][root][INFO] - Training Epoch: 2/2, step 3021/7134 completed (loss: 0.021395370364189148, acc: 0.9927272796630859)
[2024-12-17 05:06:37,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:37,656][root][INFO] - Training Epoch: 2/2, step 3022/7134 completed (loss: 0.0416087806224823, acc: 0.9903537034988403)
[2024-12-17 05:06:37,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:38,066][root][INFO] - Training Epoch: 2/2, step 3023/7134 completed (loss: 0.028332389891147614, acc: 0.9860835075378418)
[2024-12-17 05:06:38,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:38,510][root][INFO] - Training Epoch: 2/2, step 3024/7134 completed (loss: 0.010108454152941704, acc: 0.998084306716919)
[2024-12-17 05:06:38,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:38,960][root][INFO] - Training Epoch: 2/2, step 3025/7134 completed (loss: 0.07096546143293381, acc: 0.982758641242981)
[2024-12-17 05:06:39,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:39,380][root][INFO] - Training Epoch: 2/2, step 3026/7134 completed (loss: 0.02600579708814621, acc: 0.9946140050888062)
[2024-12-17 05:06:39,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:39,788][root][INFO] - Training Epoch: 2/2, step 3027/7134 completed (loss: 0.055515091866254807, acc: 0.991919219493866)
[2024-12-17 05:06:39,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:40,161][root][INFO] - Training Epoch: 2/2, step 3028/7134 completed (loss: 0.017540674656629562, acc: 0.9954648613929749)
[2024-12-17 05:06:40,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:40,565][root][INFO] - Training Epoch: 2/2, step 3029/7134 completed (loss: 0.04120006039738655, acc: 0.9922720193862915)
[2024-12-17 05:06:40,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:41,019][root][INFO] - Training Epoch: 2/2, step 3030/7134 completed (loss: 0.03471531346440315, acc: 0.9923664331436157)
[2024-12-17 05:06:41,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:41,429][root][INFO] - Training Epoch: 2/2, step 3031/7134 completed (loss: 0.014147963374853134, acc: 0.9936440587043762)
[2024-12-17 05:06:41,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:41,847][root][INFO] - Training Epoch: 2/2, step 3032/7134 completed (loss: 0.04073907807469368, acc: 0.9909256100654602)
[2024-12-17 05:06:41,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:42,267][root][INFO] - Training Epoch: 2/2, step 3033/7134 completed (loss: 0.03333573415875435, acc: 0.9841269850730896)
[2024-12-17 05:06:42,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:42,675][root][INFO] - Training Epoch: 2/2, step 3034/7134 completed (loss: 0.03904290869832039, acc: 0.9872340559959412)
[2024-12-17 05:06:42,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:43,073][root][INFO] - Training Epoch: 2/2, step 3035/7134 completed (loss: 0.016912920400500298, acc: 0.995275616645813)
[2024-12-17 05:06:43,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:43,489][root][INFO] - Training Epoch: 2/2, step 3036/7134 completed (loss: 0.05993657559156418, acc: 0.9866220951080322)
[2024-12-17 05:06:43,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:43,935][root][INFO] - Training Epoch: 2/2, step 3037/7134 completed (loss: 0.029472962021827698, acc: 0.990755021572113)
[2024-12-17 05:06:44,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:44,367][root][INFO] - Training Epoch: 2/2, step 3038/7134 completed (loss: 0.01192216482013464, acc: 0.9982608556747437)
[2024-12-17 05:06:44,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:44,781][root][INFO] - Training Epoch: 2/2, step 3039/7134 completed (loss: 0.046018488705158234, acc: 0.9938744306564331)
[2024-12-17 05:06:44,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:45,192][root][INFO] - Training Epoch: 2/2, step 3040/7134 completed (loss: 0.028980964794754982, acc: 0.9925788640975952)
[2024-12-17 05:06:45,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:45,608][root][INFO] - Training Epoch: 2/2, step 3041/7134 completed (loss: 0.06225360184907913, acc: 0.9872408509254456)
[2024-12-17 05:06:45,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:46,016][root][INFO] - Training Epoch: 2/2, step 3042/7134 completed (loss: 0.02065434679389, acc: 0.9940915703773499)
[2024-12-17 05:06:46,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:46,405][root][INFO] - Training Epoch: 2/2, step 3043/7134 completed (loss: 0.018553130328655243, acc: 0.9923954606056213)
[2024-12-17 05:06:46,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:46,798][root][INFO] - Training Epoch: 2/2, step 3044/7134 completed (loss: 0.018544107675552368, acc: 0.9965457916259766)
[2024-12-17 05:06:46,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:47,193][root][INFO] - Training Epoch: 2/2, step 3045/7134 completed (loss: 0.018354998901486397, acc: 0.993220329284668)
[2024-12-17 05:06:47,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:47,643][root][INFO] - Training Epoch: 2/2, step 3046/7134 completed (loss: 0.036275941878557205, acc: 0.9918032884597778)
[2024-12-17 05:06:47,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:48,079][root][INFO] - Training Epoch: 2/2, step 3047/7134 completed (loss: 0.011661136522889137, acc: 0.9974842667579651)
[2024-12-17 05:06:48,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:48,582][root][INFO] - Training Epoch: 2/2, step 3048/7134 completed (loss: 0.017054332420229912, acc: 0.994962215423584)
[2024-12-17 05:06:48,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:48,998][root][INFO] - Training Epoch: 2/2, step 3049/7134 completed (loss: 0.017870508134365082, acc: 0.9941860437393188)
[2024-12-17 05:06:49,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:49,445][root][INFO] - Training Epoch: 2/2, step 3050/7134 completed (loss: 0.025432411581277847, acc: 0.9916864633560181)
[2024-12-17 05:06:49,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:49,862][root][INFO] - Training Epoch: 2/2, step 3051/7134 completed (loss: 0.04104756563901901, acc: 0.9879699349403381)
[2024-12-17 05:06:49,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:50,313][root][INFO] - Training Epoch: 2/2, step 3052/7134 completed (loss: 0.02122533693909645, acc: 0.9909793734550476)
[2024-12-17 05:06:50,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:50,751][root][INFO] - Training Epoch: 2/2, step 3053/7134 completed (loss: 0.021451732143759727, acc: 0.9927536249160767)
[2024-12-17 05:06:50,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:51,177][root][INFO] - Training Epoch: 2/2, step 3054/7134 completed (loss: 0.06481318175792694, acc: 0.984415590763092)
[2024-12-17 05:06:51,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:51,610][root][INFO] - Training Epoch: 2/2, step 3055/7134 completed (loss: 0.030219344422221184, acc: 0.9897435903549194)
[2024-12-17 05:06:51,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:52,053][root][INFO] - Training Epoch: 2/2, step 3056/7134 completed (loss: 0.013936719857156277, acc: 0.9935732483863831)
[2024-12-17 05:06:52,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:52,522][root][INFO] - Training Epoch: 2/2, step 3057/7134 completed (loss: 0.015335362404584885, acc: 0.9958391189575195)
[2024-12-17 05:06:52,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:52,957][root][INFO] - Training Epoch: 2/2, step 3058/7134 completed (loss: 0.04796275869011879, acc: 0.9922279715538025)
[2024-12-17 05:06:53,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:53,411][root][INFO] - Training Epoch: 2/2, step 3059/7134 completed (loss: 0.016712773591279984, acc: 0.9931507110595703)
[2024-12-17 05:06:53,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:53,857][root][INFO] - Training Epoch: 2/2, step 3060/7134 completed (loss: 0.026166578754782677, acc: 0.9928401112556458)
[2024-12-17 05:06:53,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:54,256][root][INFO] - Training Epoch: 2/2, step 3061/7134 completed (loss: 0.019606195390224457, acc: 0.9924242496490479)
[2024-12-17 05:06:54,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:54,713][root][INFO] - Training Epoch: 2/2, step 3062/7134 completed (loss: 0.01751204952597618, acc: 0.9946091771125793)
[2024-12-17 05:06:54,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:55,160][root][INFO] - Training Epoch: 2/2, step 3063/7134 completed (loss: 0.029230987653136253, acc: 0.9935815334320068)
[2024-12-17 05:06:55,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:55,578][root][INFO] - Training Epoch: 2/2, step 3064/7134 completed (loss: 0.014637349173426628, acc: 0.9957746267318726)
[2024-12-17 05:06:55,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:56,038][root][INFO] - Training Epoch: 2/2, step 3065/7134 completed (loss: 0.01580723561346531, acc: 0.9959677457809448)
[2024-12-17 05:06:56,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:56,464][root][INFO] - Training Epoch: 2/2, step 3066/7134 completed (loss: 0.009760510176420212, acc: 0.9983870983123779)
[2024-12-17 05:06:56,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:56,858][root][INFO] - Training Epoch: 2/2, step 3067/7134 completed (loss: 0.0256046075373888, acc: 0.9945454597473145)
[2024-12-17 05:06:56,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:57,308][root][INFO] - Training Epoch: 2/2, step 3068/7134 completed (loss: 0.027396533638238907, acc: 0.9891745448112488)
[2024-12-17 05:06:57,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:57,765][root][INFO] - Training Epoch: 2/2, step 3069/7134 completed (loss: 0.014040880836546421, acc: 0.9976958632469177)
[2024-12-17 05:06:57,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:58,246][root][INFO] - Training Epoch: 2/2, step 3070/7134 completed (loss: 0.014277483336627483, acc: 0.9957582354545593)
[2024-12-17 05:06:58,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:58,707][root][INFO] - Training Epoch: 2/2, step 3071/7134 completed (loss: 0.017499512061476707, acc: 0.9961389899253845)
[2024-12-17 05:06:58,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:59,156][root][INFO] - Training Epoch: 2/2, step 3072/7134 completed (loss: 0.02290395461022854, acc: 0.9953325390815735)
[2024-12-17 05:06:59,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:06:59,575][root][INFO] - Training Epoch: 2/2, step 3073/7134 completed (loss: 0.013757031410932541, acc: 0.9949109554290771)
[2024-12-17 05:06:59,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:00,006][root][INFO] - Training Epoch: 2/2, step 3074/7134 completed (loss: 0.022198017686605453, acc: 0.9950082898139954)
[2024-12-17 05:07:00,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:00,426][root][INFO] - Training Epoch: 2/2, step 3075/7134 completed (loss: 0.009685814380645752, acc: 0.9986110925674438)
[2024-12-17 05:07:00,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:00,877][root][INFO] - Training Epoch: 2/2, step 3076/7134 completed (loss: 0.023222602903842926, acc: 0.9900110960006714)
[2024-12-17 05:07:01,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:01,363][root][INFO] - Training Epoch: 2/2, step 3077/7134 completed (loss: 0.07571815699338913, acc: 0.9770491719245911)
[2024-12-17 05:07:01,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:01,816][root][INFO] - Training Epoch: 2/2, step 3078/7134 completed (loss: 0.041608165949583054, acc: 0.9879781603813171)
[2024-12-17 05:07:01,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:02,264][root][INFO] - Training Epoch: 2/2, step 3079/7134 completed (loss: 0.03107244148850441, acc: 0.9913580417633057)
[2024-12-17 05:07:02,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:02,729][root][INFO] - Training Epoch: 2/2, step 3080/7134 completed (loss: 0.05747778341174126, acc: 0.9825518131256104)
[2024-12-17 05:07:02,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:03,129][root][INFO] - Training Epoch: 2/2, step 3081/7134 completed (loss: 0.027055418118834496, acc: 0.9913793206214905)
[2024-12-17 05:07:03,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:03,589][root][INFO] - Training Epoch: 2/2, step 3082/7134 completed (loss: 0.05296400934457779, acc: 0.9831528067588806)
[2024-12-17 05:07:03,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:04,041][root][INFO] - Training Epoch: 2/2, step 3083/7134 completed (loss: 0.03847955912351608, acc: 0.985602080821991)
[2024-12-17 05:07:04,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:04,488][root][INFO] - Training Epoch: 2/2, step 3084/7134 completed (loss: 0.05425792559981346, acc: 0.9833333492279053)
[2024-12-17 05:07:04,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:04,939][root][INFO] - Training Epoch: 2/2, step 3085/7134 completed (loss: 0.06341725587844849, acc: 0.9839416146278381)
[2024-12-17 05:07:05,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:05,435][root][INFO] - Training Epoch: 2/2, step 3086/7134 completed (loss: 0.039471324533224106, acc: 0.9898989796638489)
[2024-12-17 05:07:05,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:05,904][root][INFO] - Training Epoch: 2/2, step 3087/7134 completed (loss: 0.037400681525468826, acc: 0.9870874881744385)
[2024-12-17 05:07:06,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:06,369][root][INFO] - Training Epoch: 2/2, step 3088/7134 completed (loss: 0.031053127720952034, acc: 0.9921082258224487)
[2024-12-17 05:07:06,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:06,850][root][INFO] - Training Epoch: 2/2, step 3089/7134 completed (loss: 0.026740314438939095, acc: 0.9892125129699707)
[2024-12-17 05:07:06,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:07,311][root][INFO] - Training Epoch: 2/2, step 3090/7134 completed (loss: 0.06775478273630142, acc: 0.9836956262588501)
[2024-12-17 05:07:07,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:07,785][root][INFO] - Training Epoch: 2/2, step 3091/7134 completed (loss: 0.04009716957807541, acc: 0.9873272180557251)
[2024-12-17 05:07:07,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:08,211][root][INFO] - Training Epoch: 2/2, step 3092/7134 completed (loss: 0.04183219373226166, acc: 0.9889094233512878)
[2024-12-17 05:07:08,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:08,661][root][INFO] - Training Epoch: 2/2, step 3093/7134 completed (loss: 0.054893858730793, acc: 0.9845474362373352)
[2024-12-17 05:07:08,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:09,127][root][INFO] - Training Epoch: 2/2, step 3094/7134 completed (loss: 0.018704192712903023, acc: 0.9931880235671997)
[2024-12-17 05:07:09,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:09,547][root][INFO] - Training Epoch: 2/2, step 3095/7134 completed (loss: 0.049304645508527756, acc: 0.9888888597488403)
[2024-12-17 05:07:09,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:09,993][root][INFO] - Training Epoch: 2/2, step 3096/7134 completed (loss: 0.045428548008203506, acc: 0.9871630072593689)
[2024-12-17 05:07:10,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:10,454][root][INFO] - Training Epoch: 2/2, step 3097/7134 completed (loss: 0.07609160989522934, acc: 0.9800570011138916)
[2024-12-17 05:07:10,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:10,897][root][INFO] - Training Epoch: 2/2, step 3098/7134 completed (loss: 0.02618354745209217, acc: 0.9921383857727051)
[2024-12-17 05:07:10,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:11,305][root][INFO] - Training Epoch: 2/2, step 3099/7134 completed (loss: 0.025886379182338715, acc: 0.990275502204895)
[2024-12-17 05:07:11,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:11,794][root][INFO] - Training Epoch: 2/2, step 3100/7134 completed (loss: 0.041617680341005325, acc: 0.98617023229599)
[2024-12-17 05:07:11,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:12,242][root][INFO] - Training Epoch: 2/2, step 3101/7134 completed (loss: 0.02495071105659008, acc: 0.9914841651916504)
[2024-12-17 05:07:12,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:12,708][root][INFO] - Training Epoch: 2/2, step 3102/7134 completed (loss: 0.027791757136583328, acc: 0.9911110997200012)
[2024-12-17 05:07:12,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:13,185][root][INFO] - Training Epoch: 2/2, step 3103/7134 completed (loss: 0.03268279880285263, acc: 0.9882854223251343)
[2024-12-17 05:07:13,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:13,596][root][INFO] - Training Epoch: 2/2, step 3104/7134 completed (loss: 0.024893345311284065, acc: 0.9923664331436157)
[2024-12-17 05:07:13,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:14,038][root][INFO] - Training Epoch: 2/2, step 3105/7134 completed (loss: 0.0460771881043911, acc: 0.9868131875991821)
[2024-12-17 05:07:14,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:14,473][root][INFO] - Training Epoch: 2/2, step 3106/7134 completed (loss: 0.018405847251415253, acc: 0.9949832558631897)
[2024-12-17 05:07:14,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:14,909][root][INFO] - Training Epoch: 2/2, step 3107/7134 completed (loss: 0.015474147163331509, acc: 0.9947712421417236)
[2024-12-17 05:07:15,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:15,354][root][INFO] - Training Epoch: 2/2, step 3108/7134 completed (loss: 0.04034211486577988, acc: 0.9923076629638672)
[2024-12-17 05:07:15,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:15,778][root][INFO] - Training Epoch: 2/2, step 3109/7134 completed (loss: 0.027551129460334778, acc: 0.9944649338722229)
[2024-12-17 05:07:15,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:16,203][root][INFO] - Training Epoch: 2/2, step 3110/7134 completed (loss: 0.01903030462563038, acc: 0.992682933807373)
[2024-12-17 05:07:16,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:16,646][root][INFO] - Training Epoch: 2/2, step 3111/7134 completed (loss: 0.12702052295207977, acc: 0.969072163105011)
[2024-12-17 05:07:16,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:17,051][root][INFO] - Training Epoch: 2/2, step 3112/7134 completed (loss: 0.04500982165336609, acc: 0.9947368502616882)
[2024-12-17 05:07:17,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:17,506][root][INFO] - Training Epoch: 2/2, step 3113/7134 completed (loss: 0.026303723454475403, acc: 0.9915730357170105)
[2024-12-17 05:07:17,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:17,928][root][INFO] - Training Epoch: 2/2, step 3114/7134 completed (loss: 0.02643749490380287, acc: 0.9931034445762634)
[2024-12-17 05:07:18,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:18,336][root][INFO] - Training Epoch: 2/2, step 3115/7134 completed (loss: 0.06373944878578186, acc: 0.9861111044883728)
[2024-12-17 05:07:18,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:18,783][root][INFO] - Training Epoch: 2/2, step 3116/7134 completed (loss: 0.027565613389015198, acc: 0.9910256266593933)
[2024-12-17 05:07:18,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:19,225][root][INFO] - Training Epoch: 2/2, step 3117/7134 completed (loss: 0.08576972782611847, acc: 0.9836956262588501)
[2024-12-17 05:07:19,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:19,656][root][INFO] - Training Epoch: 2/2, step 3118/7134 completed (loss: 0.04659862443804741, acc: 0.990777313709259)
[2024-12-17 05:07:19,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:20,094][root][INFO] - Training Epoch: 2/2, step 3119/7134 completed (loss: 0.05376454070210457, acc: 0.9844357967376709)
[2024-12-17 05:07:20,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:20,512][root][INFO] - Training Epoch: 2/2, step 3120/7134 completed (loss: 0.05200442299246788, acc: 0.9929478168487549)
[2024-12-17 05:07:20,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:20,939][root][INFO] - Training Epoch: 2/2, step 3121/7134 completed (loss: 0.046644099056720734, acc: 0.9897172451019287)
[2024-12-17 05:07:21,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:21,395][root][INFO] - Training Epoch: 2/2, step 3122/7134 completed (loss: 0.04331817477941513, acc: 0.9872093200683594)
[2024-12-17 05:07:21,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:21,839][root][INFO] - Training Epoch: 2/2, step 3123/7134 completed (loss: 0.050431497395038605, acc: 0.9838308691978455)
[2024-12-17 05:07:21,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:22,278][root][INFO] - Training Epoch: 2/2, step 3124/7134 completed (loss: 0.04078036546707153, acc: 0.9913366436958313)
[2024-12-17 05:07:22,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:22,694][root][INFO] - Training Epoch: 2/2, step 3125/7134 completed (loss: 0.023582004010677338, acc: 0.9909228682518005)
[2024-12-17 05:07:22,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:23,160][root][INFO] - Training Epoch: 2/2, step 3126/7134 completed (loss: 0.03947225585579872, acc: 0.9860228896141052)
[2024-12-17 05:07:23,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:23,608][root][INFO] - Training Epoch: 2/2, step 3127/7134 completed (loss: 0.02672865428030491, acc: 0.9906976819038391)
[2024-12-17 05:07:23,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:24,038][root][INFO] - Training Epoch: 2/2, step 3128/7134 completed (loss: 0.02308286540210247, acc: 0.9948387145996094)
[2024-12-17 05:07:24,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:24,494][root][INFO] - Training Epoch: 2/2, step 3129/7134 completed (loss: 0.0301126167178154, acc: 0.9925834536552429)
[2024-12-17 05:07:24,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:24,965][root][INFO] - Training Epoch: 2/2, step 3130/7134 completed (loss: 0.029437752440571785, acc: 0.9931192398071289)
[2024-12-17 05:07:25,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:25,419][root][INFO] - Training Epoch: 2/2, step 3131/7134 completed (loss: 0.0479244627058506, acc: 0.9855072498321533)
[2024-12-17 05:07:25,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:25,831][root][INFO] - Training Epoch: 2/2, step 3132/7134 completed (loss: 0.0213729590177536, acc: 0.9934924244880676)
[2024-12-17 05:07:25,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:26,290][root][INFO] - Training Epoch: 2/2, step 3133/7134 completed (loss: 0.09935195744037628, acc: 0.9821428656578064)
[2024-12-17 05:07:26,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:26,742][root][INFO] - Training Epoch: 2/2, step 3134/7134 completed (loss: 0.03414307162165642, acc: 0.9890109896659851)
[2024-12-17 05:07:26,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:27,140][root][INFO] - Training Epoch: 2/2, step 3135/7134 completed (loss: 0.03330700471997261, acc: 0.9838337302207947)
[2024-12-17 05:07:27,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:27,565][root][INFO] - Training Epoch: 2/2, step 3136/7134 completed (loss: 0.01697593554854393, acc: 0.9982608556747437)
[2024-12-17 05:07:27,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:27,980][root][INFO] - Training Epoch: 2/2, step 3137/7134 completed (loss: 0.04324321821331978, acc: 0.9861111044883728)
[2024-12-17 05:07:28,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:28,396][root][INFO] - Training Epoch: 2/2, step 3138/7134 completed (loss: 0.054069411009550095, acc: 0.9882352948188782)
[2024-12-17 05:07:28,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:28,756][root][INFO] - Training Epoch: 2/2, step 3139/7134 completed (loss: 0.06779727339744568, acc: 0.9828326106071472)
[2024-12-17 05:07:28,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:29,163][root][INFO] - Training Epoch: 2/2, step 3140/7134 completed (loss: 0.025032853707671165, acc: 0.9922178983688354)
[2024-12-17 05:07:29,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:29,579][root][INFO] - Training Epoch: 2/2, step 3141/7134 completed (loss: 0.059219181537628174, acc: 0.9842657446861267)
[2024-12-17 05:07:29,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:29,993][root][INFO] - Training Epoch: 2/2, step 3142/7134 completed (loss: 0.014309853315353394, acc: 0.9955157041549683)
[2024-12-17 05:07:30,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:30,419][root][INFO] - Training Epoch: 2/2, step 3143/7134 completed (loss: 0.018710577860474586, acc: 0.9935691356658936)
[2024-12-17 05:07:30,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:30,853][root][INFO] - Training Epoch: 2/2, step 3144/7134 completed (loss: 0.02045537158846855, acc: 0.9921383857727051)
[2024-12-17 05:07:30,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:31,268][root][INFO] - Training Epoch: 2/2, step 3145/7134 completed (loss: 0.052670806646347046, acc: 0.9868708848953247)
[2024-12-17 05:07:31,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:31,688][root][INFO] - Training Epoch: 2/2, step 3146/7134 completed (loss: 0.032813962548971176, acc: 0.9908854365348816)
[2024-12-17 05:07:31,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:32,129][root][INFO] - Training Epoch: 2/2, step 3147/7134 completed (loss: 0.04169045016169548, acc: 0.9919742941856384)
[2024-12-17 05:07:32,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:32,571][root][INFO] - Training Epoch: 2/2, step 3148/7134 completed (loss: 0.03715507686138153, acc: 0.9885203838348389)
[2024-12-17 05:07:32,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:33,007][root][INFO] - Training Epoch: 2/2, step 3149/7134 completed (loss: 0.007949705235660076, acc: 0.9985358715057373)
[2024-12-17 05:07:33,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:33,433][root][INFO] - Training Epoch: 2/2, step 3150/7134 completed (loss: 0.12723885476589203, acc: 0.9723865985870361)
[2024-12-17 05:07:33,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:33,847][root][INFO] - Training Epoch: 2/2, step 3151/7134 completed (loss: 0.10417237132787704, acc: 0.975095808506012)
[2024-12-17 05:07:33,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:34,280][root][INFO] - Training Epoch: 2/2, step 3152/7134 completed (loss: 0.0330522246658802, acc: 0.9863636493682861)
[2024-12-17 05:07:34,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:34,724][root][INFO] - Training Epoch: 2/2, step 3153/7134 completed (loss: 0.04846254363656044, acc: 0.9862155318260193)
[2024-12-17 05:07:34,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:35,153][root][INFO] - Training Epoch: 2/2, step 3154/7134 completed (loss: 0.0312521830201149, acc: 0.9928951859474182)
[2024-12-17 05:07:35,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:35,558][root][INFO] - Training Epoch: 2/2, step 3155/7134 completed (loss: 0.0864374041557312, acc: 0.9817444086074829)
[2024-12-17 05:07:35,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:35,989][root][INFO] - Training Epoch: 2/2, step 3156/7134 completed (loss: 0.08227803558111191, acc: 0.9747399687767029)
[2024-12-17 05:07:36,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:36,397][root][INFO] - Training Epoch: 2/2, step 3157/7134 completed (loss: 0.019624225795269012, acc: 0.9935483932495117)
[2024-12-17 05:07:36,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:36,805][root][INFO] - Training Epoch: 2/2, step 3158/7134 completed (loss: 0.021243643015623093, acc: 0.9934640526771545)
[2024-12-17 05:07:36,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:37,214][root][INFO] - Training Epoch: 2/2, step 3159/7134 completed (loss: 0.0793657898902893, acc: 0.9852941036224365)
[2024-12-17 05:07:37,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:37,652][root][INFO] - Training Epoch: 2/2, step 3160/7134 completed (loss: 0.012762146070599556, acc: 0.9972337484359741)
[2024-12-17 05:07:37,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:38,106][root][INFO] - Training Epoch: 2/2, step 3161/7134 completed (loss: 0.024975838139653206, acc: 0.994397759437561)
[2024-12-17 05:07:38,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:38,525][root][INFO] - Training Epoch: 2/2, step 3162/7134 completed (loss: 0.025479238480329514, acc: 0.9897959232330322)
[2024-12-17 05:07:38,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:38,931][root][INFO] - Training Epoch: 2/2, step 3163/7134 completed (loss: 0.0540727935731411, acc: 0.9866443872451782)
[2024-12-17 05:07:39,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:39,343][root][INFO] - Training Epoch: 2/2, step 3164/7134 completed (loss: 0.05671263858675957, acc: 0.9849246144294739)
[2024-12-17 05:07:39,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:39,757][root][INFO] - Training Epoch: 2/2, step 3165/7134 completed (loss: 0.026900576427578926, acc: 0.9916527271270752)
[2024-12-17 05:07:39,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:40,181][root][INFO] - Training Epoch: 2/2, step 3166/7134 completed (loss: 0.06517361849546432, acc: 0.9834586381912231)
[2024-12-17 05:07:40,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:40,615][root][INFO] - Training Epoch: 2/2, step 3167/7134 completed (loss: 0.10926234722137451, acc: 0.9671875238418579)
[2024-12-17 05:07:40,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:41,024][root][INFO] - Training Epoch: 2/2, step 3168/7134 completed (loss: 0.08609342575073242, acc: 0.9740853905677795)
[2024-12-17 05:07:41,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:41,422][root][INFO] - Training Epoch: 2/2, step 3169/7134 completed (loss: 0.07302001863718033, acc: 0.9754098653793335)
[2024-12-17 05:07:41,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:41,842][root][INFO] - Training Epoch: 2/2, step 3170/7134 completed (loss: 0.032356176525354385, acc: 0.9836363792419434)
[2024-12-17 05:07:41,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:42,264][root][INFO] - Training Epoch: 2/2, step 3171/7134 completed (loss: 0.04973292350769043, acc: 0.9868938326835632)
[2024-12-17 05:07:42,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:42,665][root][INFO] - Training Epoch: 2/2, step 3172/7134 completed (loss: 0.008811168372631073, acc: 0.9961685538291931)
[2024-12-17 05:07:42,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:43,059][root][INFO] - Training Epoch: 2/2, step 3173/7134 completed (loss: 0.04139084741473198, acc: 0.9846938848495483)
[2024-12-17 05:07:43,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:43,484][root][INFO] - Training Epoch: 2/2, step 3174/7134 completed (loss: 0.06640589982271194, acc: 0.9807692170143127)
[2024-12-17 05:07:43,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:43,907][root][INFO] - Training Epoch: 2/2, step 3175/7134 completed (loss: 0.0559408962726593, acc: 0.9873239398002625)
[2024-12-17 05:07:44,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:44,329][root][INFO] - Training Epoch: 2/2, step 3176/7134 completed (loss: 0.07257720828056335, acc: 0.9759398698806763)
[2024-12-17 05:07:44,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:44,729][root][INFO] - Training Epoch: 2/2, step 3177/7134 completed (loss: 0.07434643805027008, acc: 0.9809027910232544)
[2024-12-17 05:07:44,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:45,138][root][INFO] - Training Epoch: 2/2, step 3178/7134 completed (loss: 0.026612740010023117, acc: 0.9950739145278931)
[2024-12-17 05:07:45,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:45,573][root][INFO] - Training Epoch: 2/2, step 3179/7134 completed (loss: 0.08814822137355804, acc: 0.9784411191940308)
[2024-12-17 05:07:45,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:45,980][root][INFO] - Training Epoch: 2/2, step 3180/7134 completed (loss: 0.036229442805051804, acc: 0.9928571581840515)
[2024-12-17 05:07:46,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:46,400][root][INFO] - Training Epoch: 2/2, step 3181/7134 completed (loss: 0.04896833375096321, acc: 0.9906396269798279)
[2024-12-17 05:07:46,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:46,829][root][INFO] - Training Epoch: 2/2, step 3182/7134 completed (loss: 0.03469410166144371, acc: 0.9940387606620789)
[2024-12-17 05:07:46,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:47,225][root][INFO] - Training Epoch: 2/2, step 3183/7134 completed (loss: 0.05027873069047928, acc: 0.9847715497016907)
[2024-12-17 05:07:47,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:47,652][root][INFO] - Training Epoch: 2/2, step 3184/7134 completed (loss: 0.04873214289546013, acc: 0.9866071343421936)
[2024-12-17 05:07:47,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:48,065][root][INFO] - Training Epoch: 2/2, step 3185/7134 completed (loss: 0.007620038464665413, acc: 0.9985755085945129)
[2024-12-17 05:07:48,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:48,486][root][INFO] - Training Epoch: 2/2, step 3186/7134 completed (loss: 0.0220638494938612, acc: 0.9925925731658936)
[2024-12-17 05:07:48,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:48,889][root][INFO] - Training Epoch: 2/2, step 3187/7134 completed (loss: 0.047466959804296494, acc: 0.982594907283783)
[2024-12-17 05:07:49,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:49,323][root][INFO] - Training Epoch: 2/2, step 3188/7134 completed (loss: 0.03179733082652092, acc: 0.9935317039489746)
[2024-12-17 05:07:49,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:49,737][root][INFO] - Training Epoch: 2/2, step 3189/7134 completed (loss: 0.051662202924489975, acc: 0.9840810298919678)
[2024-12-17 05:07:49,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:50,197][root][INFO] - Training Epoch: 2/2, step 3190/7134 completed (loss: 0.046088770031929016, acc: 0.9886075854301453)
[2024-12-17 05:07:50,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:50,605][root][INFO] - Training Epoch: 2/2, step 3191/7134 completed (loss: 0.03263125941157341, acc: 0.9957143068313599)
[2024-12-17 05:07:50,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:51,037][root][INFO] - Training Epoch: 2/2, step 3192/7134 completed (loss: 0.07104496657848358, acc: 0.9867674708366394)
[2024-12-17 05:07:51,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:51,443][root][INFO] - Training Epoch: 2/2, step 3193/7134 completed (loss: 0.053044985979795456, acc: 0.9838945865631104)
[2024-12-17 05:07:51,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:51,861][root][INFO] - Training Epoch: 2/2, step 3194/7134 completed (loss: 0.045116472989320755, acc: 0.983660101890564)
[2024-12-17 05:07:51,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:52,264][root][INFO] - Training Epoch: 2/2, step 3195/7134 completed (loss: 0.041009578853845596, acc: 0.989708423614502)
[2024-12-17 05:07:52,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:52,683][root][INFO] - Training Epoch: 2/2, step 3196/7134 completed (loss: 0.01671149954199791, acc: 0.9943925142288208)
[2024-12-17 05:07:52,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:53,100][root][INFO] - Training Epoch: 2/2, step 3197/7134 completed (loss: 0.027806514874100685, acc: 0.9943661689758301)
[2024-12-17 05:07:53,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:53,527][root][INFO] - Training Epoch: 2/2, step 3198/7134 completed (loss: 0.049960050731897354, acc: 0.9863842725753784)
[2024-12-17 05:07:53,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:53,935][root][INFO] - Training Epoch: 2/2, step 3199/7134 completed (loss: 0.02182159759104252, acc: 0.9941262602806091)
[2024-12-17 05:07:54,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:54,325][root][INFO] - Training Epoch: 2/2, step 3200/7134 completed (loss: 0.03830449655652046, acc: 0.9894551634788513)
[2024-12-17 05:07:54,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:54,756][root][INFO] - Training Epoch: 2/2, step 3201/7134 completed (loss: 0.08933986723423004, acc: 0.9826464056968689)
[2024-12-17 05:07:54,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:55,179][root][INFO] - Training Epoch: 2/2, step 3202/7134 completed (loss: 0.02517601288855076, acc: 0.9930843710899353)
[2024-12-17 05:07:55,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:55,596][root][INFO] - Training Epoch: 2/2, step 3203/7134 completed (loss: 0.03964061662554741, acc: 0.9905213117599487)
[2024-12-17 05:07:55,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:55,997][root][INFO] - Training Epoch: 2/2, step 3204/7134 completed (loss: 0.07038843631744385, acc: 0.9793233275413513)
[2024-12-17 05:07:56,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:56,409][root][INFO] - Training Epoch: 2/2, step 3205/7134 completed (loss: 0.011799799278378487, acc: 0.9982331991195679)
[2024-12-17 05:07:56,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:56,858][root][INFO] - Training Epoch: 2/2, step 3206/7134 completed (loss: 0.03780024126172066, acc: 0.9927641153335571)
[2024-12-17 05:07:56,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:57,276][root][INFO] - Training Epoch: 2/2, step 3207/7134 completed (loss: 0.03835926204919815, acc: 0.9892802238464355)
[2024-12-17 05:07:57,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:57,720][root][INFO] - Training Epoch: 2/2, step 3208/7134 completed (loss: 0.07114548236131668, acc: 0.983660101890564)
[2024-12-17 05:07:57,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:58,134][root][INFO] - Training Epoch: 2/2, step 3209/7134 completed (loss: 0.021424731239676476, acc: 0.9940476417541504)
[2024-12-17 05:07:58,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:58,594][root][INFO] - Training Epoch: 2/2, step 3210/7134 completed (loss: 0.00942662637680769, acc: 0.9984939694404602)
[2024-12-17 05:07:58,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:58,999][root][INFO] - Training Epoch: 2/2, step 3211/7134 completed (loss: 0.04119192436337471, acc: 0.9916840195655823)
[2024-12-17 05:07:59,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:59,421][root][INFO] - Training Epoch: 2/2, step 3212/7134 completed (loss: 0.008329770527780056, acc: 0.9986013770103455)
[2024-12-17 05:07:59,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:07:59,841][root][INFO] - Training Epoch: 2/2, step 3213/7134 completed (loss: 0.025853004306554794, acc: 0.9928264021873474)
[2024-12-17 05:07:59,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:00,295][root][INFO] - Training Epoch: 2/2, step 3214/7134 completed (loss: 0.028224600479006767, acc: 0.993306577205658)
[2024-12-17 05:08:00,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:00,736][root][INFO] - Training Epoch: 2/2, step 3215/7134 completed (loss: 0.03367127850651741, acc: 0.9901960492134094)
[2024-12-17 05:08:00,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:01,177][root][INFO] - Training Epoch: 2/2, step 3216/7134 completed (loss: 0.015024229884147644, acc: 0.9957020282745361)
[2024-12-17 05:08:01,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:01,635][root][INFO] - Training Epoch: 2/2, step 3217/7134 completed (loss: 0.015664156526327133, acc: 0.996129035949707)
[2024-12-17 05:08:01,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:02,044][root][INFO] - Training Epoch: 2/2, step 3218/7134 completed (loss: 0.0656237080693245, acc: 0.978090763092041)
[2024-12-17 05:08:02,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:02,461][root][INFO] - Training Epoch: 2/2, step 3219/7134 completed (loss: 0.05062790587544441, acc: 0.9822747707366943)
[2024-12-17 05:08:02,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:02,897][root][INFO] - Training Epoch: 2/2, step 3220/7134 completed (loss: 0.038846760988235474, acc: 0.9906542301177979)
[2024-12-17 05:08:03,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:03,357][root][INFO] - Training Epoch: 2/2, step 3221/7134 completed (loss: 0.03031390719115734, acc: 0.9890410900115967)
[2024-12-17 05:08:03,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:03,786][root][INFO] - Training Epoch: 2/2, step 3222/7134 completed (loss: 0.055000148713588715, acc: 0.987484335899353)
[2024-12-17 05:08:03,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:04,216][root][INFO] - Training Epoch: 2/2, step 3223/7134 completed (loss: 0.05447924882173538, acc: 0.9904761910438538)
[2024-12-17 05:08:04,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:04,675][root][INFO] - Training Epoch: 2/2, step 3224/7134 completed (loss: 0.05517293140292168, acc: 0.986975371837616)
[2024-12-17 05:08:04,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:05,135][root][INFO] - Training Epoch: 2/2, step 3225/7134 completed (loss: 0.021938340738415718, acc: 0.9898862242698669)
[2024-12-17 05:08:05,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:05,537][root][INFO] - Training Epoch: 2/2, step 3226/7134 completed (loss: 0.037476181983947754, acc: 0.985637366771698)
[2024-12-17 05:08:05,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:06,013][root][INFO] - Training Epoch: 2/2, step 3227/7134 completed (loss: 0.07940293848514557, acc: 0.9813186526298523)
[2024-12-17 05:08:06,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:06,477][root][INFO] - Training Epoch: 2/2, step 3228/7134 completed (loss: 0.051820456981658936, acc: 0.9868593811988831)
[2024-12-17 05:08:06,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:06,911][root][INFO] - Training Epoch: 2/2, step 3229/7134 completed (loss: 0.038115426898002625, acc: 0.9877601265907288)
[2024-12-17 05:08:07,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:07,341][root][INFO] - Training Epoch: 2/2, step 3230/7134 completed (loss: 0.04478836432099342, acc: 0.9792899489402771)
[2024-12-17 05:08:07,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:07,740][root][INFO] - Training Epoch: 2/2, step 3231/7134 completed (loss: 0.04410374164581299, acc: 0.9863221645355225)
[2024-12-17 05:08:07,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:08,191][root][INFO] - Training Epoch: 2/2, step 3232/7134 completed (loss: 0.02294250950217247, acc: 0.9932659864425659)
[2024-12-17 05:08:08,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:08,629][root][INFO] - Training Epoch: 2/2, step 3233/7134 completed (loss: 0.046887967735528946, acc: 0.990138053894043)
[2024-12-17 05:08:08,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:09,062][root][INFO] - Training Epoch: 2/2, step 3234/7134 completed (loss: 0.028964200988411903, acc: 0.9921011328697205)
[2024-12-17 05:08:09,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:09,492][root][INFO] - Training Epoch: 2/2, step 3235/7134 completed (loss: 0.042443450540304184, acc: 0.9828571677207947)
[2024-12-17 05:08:09,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:09,911][root][INFO] - Training Epoch: 2/2, step 3236/7134 completed (loss: 0.07253921777009964, acc: 0.9808542132377625)
[2024-12-17 05:08:10,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:10,329][root][INFO] - Training Epoch: 2/2, step 3237/7134 completed (loss: 0.025082333013415337, acc: 0.9951691031455994)
[2024-12-17 05:08:10,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:10,761][root][INFO] - Training Epoch: 2/2, step 3238/7134 completed (loss: 0.05219873785972595, acc: 0.9800613522529602)
[2024-12-17 05:08:10,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:11,199][root][INFO] - Training Epoch: 2/2, step 3239/7134 completed (loss: 0.014635981060564518, acc: 0.9968454241752625)
[2024-12-17 05:08:11,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:11,630][root][INFO] - Training Epoch: 2/2, step 3240/7134 completed (loss: 0.024480270221829414, acc: 0.9925261735916138)
[2024-12-17 05:08:11,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:12,071][root][INFO] - Training Epoch: 2/2, step 3241/7134 completed (loss: 0.013821647502481937, acc: 0.9940652847290039)
[2024-12-17 05:08:12,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:12,504][root][INFO] - Training Epoch: 2/2, step 3242/7134 completed (loss: 0.021016038954257965, acc: 0.9901960492134094)
[2024-12-17 05:08:12,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:12,956][root][INFO] - Training Epoch: 2/2, step 3243/7134 completed (loss: 0.02715541608631611, acc: 0.9945504069328308)
[2024-12-17 05:08:13,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:13,373][root][INFO] - Training Epoch: 2/2, step 3244/7134 completed (loss: 0.02432337775826454, acc: 0.9942611455917358)
[2024-12-17 05:08:13,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:13,819][root][INFO] - Training Epoch: 2/2, step 3245/7134 completed (loss: 0.021208686754107475, acc: 0.9974226951599121)
[2024-12-17 05:08:13,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:14,257][root][INFO] - Training Epoch: 2/2, step 3246/7134 completed (loss: 0.039249297231435776, acc: 0.9846153855323792)
[2024-12-17 05:08:14,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:14,683][root][INFO] - Training Epoch: 2/2, step 3247/7134 completed (loss: 0.02202688157558441, acc: 0.9935170412063599)
[2024-12-17 05:08:14,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:15,091][root][INFO] - Training Epoch: 2/2, step 3248/7134 completed (loss: 0.02545325644314289, acc: 0.9950739145278931)
[2024-12-17 05:08:15,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:15,508][root][INFO] - Training Epoch: 2/2, step 3249/7134 completed (loss: 0.03795819729566574, acc: 0.9930651783943176)
[2024-12-17 05:08:15,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:15,939][root][INFO] - Training Epoch: 2/2, step 3250/7134 completed (loss: 0.0390239879488945, acc: 0.9899280667304993)
[2024-12-17 05:08:16,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:16,364][root][INFO] - Training Epoch: 2/2, step 3251/7134 completed (loss: 0.006805149372667074, acc: 0.9985734820365906)
[2024-12-17 05:08:16,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:16,797][root][INFO] - Training Epoch: 2/2, step 3252/7134 completed (loss: 0.013304980471730232, acc: 0.9957447052001953)
[2024-12-17 05:08:16,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:17,229][root][INFO] - Training Epoch: 2/2, step 3253/7134 completed (loss: 0.013712537474930286, acc: 0.995184600353241)
[2024-12-17 05:08:17,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:17,668][root][INFO] - Training Epoch: 2/2, step 3254/7134 completed (loss: 0.008408522233366966, acc: 1.0)
[2024-12-17 05:08:17,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:18,085][root][INFO] - Training Epoch: 2/2, step 3255/7134 completed (loss: 0.008898073807358742, acc: 0.9960052967071533)
[2024-12-17 05:08:18,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:18,498][root][INFO] - Training Epoch: 2/2, step 3256/7134 completed (loss: 0.013151120394468307, acc: 0.9970370531082153)
[2024-12-17 05:08:18,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:18,907][root][INFO] - Training Epoch: 2/2, step 3257/7134 completed (loss: 0.016971949487924576, acc: 0.9972260594367981)
[2024-12-17 05:08:19,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:19,338][root][INFO] - Training Epoch: 2/2, step 3258/7134 completed (loss: 0.02614067681133747, acc: 0.9903846383094788)
[2024-12-17 05:08:19,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:19,761][root][INFO] - Training Epoch: 2/2, step 3259/7134 completed (loss: 0.014805957674980164, acc: 0.9941176176071167)
[2024-12-17 05:08:19,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:20,163][root][INFO] - Training Epoch: 2/2, step 3260/7134 completed (loss: 0.07446029782295227, acc: 0.9881305694580078)
[2024-12-17 05:08:20,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:20,582][root][INFO] - Training Epoch: 2/2, step 3261/7134 completed (loss: 0.04278961569070816, acc: 0.9848993420600891)
[2024-12-17 05:08:20,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:21,005][root][INFO] - Training Epoch: 2/2, step 3262/7134 completed (loss: 0.01768362894654274, acc: 0.9927641153335571)
[2024-12-17 05:08:21,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:21,419][root][INFO] - Training Epoch: 2/2, step 3263/7134 completed (loss: 0.0661279633641243, acc: 0.98531574010849)
[2024-12-17 05:08:21,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:21,830][root][INFO] - Training Epoch: 2/2, step 3264/7134 completed (loss: 0.02713768556714058, acc: 0.9944444298744202)
[2024-12-17 05:08:21,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:22,271][root][INFO] - Training Epoch: 2/2, step 3265/7134 completed (loss: 0.0986766517162323, acc: 0.9800570011138916)
[2024-12-17 05:08:22,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:22,708][root][INFO] - Training Epoch: 2/2, step 3266/7134 completed (loss: 0.04055806249380112, acc: 0.9894894957542419)
[2024-12-17 05:08:22,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:23,133][root][INFO] - Training Epoch: 2/2, step 3267/7134 completed (loss: 0.05852776765823364, acc: 0.9856733679771423)
[2024-12-17 05:08:23,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:23,556][root][INFO] - Training Epoch: 2/2, step 3268/7134 completed (loss: 0.04051830247044563, acc: 0.9892141819000244)
[2024-12-17 05:08:23,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:23,998][root][INFO] - Training Epoch: 2/2, step 3269/7134 completed (loss: 0.04243315011262894, acc: 0.9861111044883728)
[2024-12-17 05:08:24,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:24,462][root][INFO] - Training Epoch: 2/2, step 3270/7134 completed (loss: 0.01620708778500557, acc: 0.9940191507339478)
[2024-12-17 05:08:24,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:24,841][root][INFO] - Training Epoch: 2/2, step 3271/7134 completed (loss: 0.00419600261375308, acc: 1.0)
[2024-12-17 05:08:24,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:25,273][root][INFO] - Training Epoch: 2/2, step 3272/7134 completed (loss: 0.032088082283735275, acc: 0.9954198598861694)
[2024-12-17 05:08:25,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:25,732][root][INFO] - Training Epoch: 2/2, step 3273/7134 completed (loss: 0.02444874495267868, acc: 0.9948914647102356)
[2024-12-17 05:08:25,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:26,180][root][INFO] - Training Epoch: 2/2, step 3274/7134 completed (loss: 0.03532306104898453, acc: 0.9926578402519226)
[2024-12-17 05:08:26,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:26,627][root][INFO] - Training Epoch: 2/2, step 3275/7134 completed (loss: 0.14311730861663818, acc: 0.9678362607955933)
[2024-12-17 05:08:26,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:27,052][root][INFO] - Training Epoch: 2/2, step 3276/7134 completed (loss: 0.05774097144603729, acc: 0.9820936918258667)
[2024-12-17 05:08:27,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:27,479][root][INFO] - Training Epoch: 2/2, step 3277/7134 completed (loss: 0.04570235684514046, acc: 0.9832317233085632)
[2024-12-17 05:08:27,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:27,867][root][INFO] - Training Epoch: 2/2, step 3278/7134 completed (loss: 0.042986489832401276, acc: 0.9885277152061462)
[2024-12-17 05:08:27,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:28,315][root][INFO] - Training Epoch: 2/2, step 3279/7134 completed (loss: 0.03700746223330498, acc: 0.9888198971748352)
[2024-12-17 05:08:28,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:28,734][root][INFO] - Training Epoch: 2/2, step 3280/7134 completed (loss: 0.12167734652757645, acc: 0.9668049812316895)
[2024-12-17 05:08:28,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:29,172][root][INFO] - Training Epoch: 2/2, step 3281/7134 completed (loss: 0.048883967101573944, acc: 0.9884058237075806)
[2024-12-17 05:08:29,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:29,605][root][INFO] - Training Epoch: 2/2, step 3282/7134 completed (loss: 0.024370895698666573, acc: 0.9920886158943176)
[2024-12-17 05:08:29,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:30,069][root][INFO] - Training Epoch: 2/2, step 3283/7134 completed (loss: 0.033663440495729446, acc: 0.9896907210350037)
[2024-12-17 05:08:30,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:30,492][root][INFO] - Training Epoch: 2/2, step 3284/7134 completed (loss: 0.07983226329088211, acc: 0.9817351698875427)
[2024-12-17 05:08:30,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:30,912][root][INFO] - Training Epoch: 2/2, step 3285/7134 completed (loss: 0.025125352665781975, acc: 0.9922600388526917)
[2024-12-17 05:08:31,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:31,341][root][INFO] - Training Epoch: 2/2, step 3286/7134 completed (loss: 0.03449208289384842, acc: 0.995488703250885)
[2024-12-17 05:08:31,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:31,748][root][INFO] - Training Epoch: 2/2, step 3287/7134 completed (loss: 0.08904179185628891, acc: 0.9786184430122375)
[2024-12-17 05:08:31,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:32,186][root][INFO] - Training Epoch: 2/2, step 3288/7134 completed (loss: 0.04591015726327896, acc: 0.9865269660949707)
[2024-12-17 05:08:32,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:32,582][root][INFO] - Training Epoch: 2/2, step 3289/7134 completed (loss: 0.07585509866476059, acc: 0.9789473414421082)
[2024-12-17 05:08:32,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:32,980][root][INFO] - Training Epoch: 2/2, step 3290/7134 completed (loss: 0.05275341868400574, acc: 0.984375)
[2024-12-17 05:08:33,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:33,383][root][INFO] - Training Epoch: 2/2, step 3291/7134 completed (loss: 0.05794826149940491, acc: 0.9777283072471619)
[2024-12-17 05:08:33,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:33,789][root][INFO] - Training Epoch: 2/2, step 3292/7134 completed (loss: 0.03638792410492897, acc: 0.9894179701805115)
[2024-12-17 05:08:33,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:34,243][root][INFO] - Training Epoch: 2/2, step 3293/7134 completed (loss: 0.028561094775795937, acc: 0.99262535572052)
[2024-12-17 05:08:34,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:34,670][root][INFO] - Training Epoch: 2/2, step 3294/7134 completed (loss: 0.06022651121020317, acc: 0.9785605072975159)
[2024-12-17 05:08:34,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:35,063][root][INFO] - Training Epoch: 2/2, step 3295/7134 completed (loss: 0.028321852907538414, acc: 0.9931740760803223)
[2024-12-17 05:08:35,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:35,456][root][INFO] - Training Epoch: 2/2, step 3296/7134 completed (loss: 0.04561229050159454, acc: 0.9853747487068176)
[2024-12-17 05:08:35,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:35,833][root][INFO] - Training Epoch: 2/2, step 3297/7134 completed (loss: 0.03743676841259003, acc: 0.9882628917694092)
[2024-12-17 05:08:35,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:36,254][root][INFO] - Training Epoch: 2/2, step 3298/7134 completed (loss: 0.10091367363929749, acc: 0.9824281334877014)
[2024-12-17 05:08:36,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:36,666][root][INFO] - Training Epoch: 2/2, step 3299/7134 completed (loss: 0.03086933121085167, acc: 0.9916107654571533)
[2024-12-17 05:08:36,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:37,063][root][INFO] - Training Epoch: 2/2, step 3300/7134 completed (loss: 0.06639639288187027, acc: 0.9821746945381165)
[2024-12-17 05:08:37,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:37,436][root][INFO] - Training Epoch: 2/2, step 3301/7134 completed (loss: 0.044175151735544205, acc: 0.9896265268325806)
[2024-12-17 05:08:37,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:37,856][root][INFO] - Training Epoch: 2/2, step 3302/7134 completed (loss: 0.05194651335477829, acc: 0.9865319728851318)
[2024-12-17 05:08:37,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:38,217][root][INFO] - Training Epoch: 2/2, step 3303/7134 completed (loss: 0.04329533874988556, acc: 0.9867841601371765)
[2024-12-17 05:08:38,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:38,669][root][INFO] - Training Epoch: 2/2, step 3304/7134 completed (loss: 0.02105036750435829, acc: 0.9940333962440491)
[2024-12-17 05:08:38,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:39,110][root][INFO] - Training Epoch: 2/2, step 3305/7134 completed (loss: 0.035998281091451645, acc: 0.9879336357116699)
[2024-12-17 05:08:39,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:39,585][root][INFO] - Training Epoch: 2/2, step 3306/7134 completed (loss: 0.023554624989628792, acc: 0.9922178983688354)
[2024-12-17 05:08:39,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:39,986][root][INFO] - Training Epoch: 2/2, step 3307/7134 completed (loss: 0.041344691067934036, acc: 0.9864636063575745)
[2024-12-17 05:08:40,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:40,403][root][INFO] - Training Epoch: 2/2, step 3308/7134 completed (loss: 0.04277966171503067, acc: 0.9841040372848511)
[2024-12-17 05:08:40,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:40,799][root][INFO] - Training Epoch: 2/2, step 3309/7134 completed (loss: 0.053435068577528, acc: 0.98525071144104)
[2024-12-17 05:08:40,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:41,246][root][INFO] - Training Epoch: 2/2, step 3310/7134 completed (loss: 0.035768985748291016, acc: 0.9914712309837341)
[2024-12-17 05:08:41,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:41,638][root][INFO] - Training Epoch: 2/2, step 3311/7134 completed (loss: 0.02641582489013672, acc: 0.9913978576660156)
[2024-12-17 05:08:41,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:42,097][root][INFO] - Training Epoch: 2/2, step 3312/7134 completed (loss: 0.030919022858142853, acc: 0.9927272796630859)
[2024-12-17 05:08:42,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:42,512][root][INFO] - Training Epoch: 2/2, step 3313/7134 completed (loss: 0.02052663266658783, acc: 0.9952267408370972)
[2024-12-17 05:08:42,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:42,942][root][INFO] - Training Epoch: 2/2, step 3314/7134 completed (loss: 0.04219536855816841, acc: 0.989130437374115)
[2024-12-17 05:08:43,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:43,394][root][INFO] - Training Epoch: 2/2, step 3315/7134 completed (loss: 0.06462867558002472, acc: 0.9823608994483948)
[2024-12-17 05:08:43,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:43,831][root][INFO] - Training Epoch: 2/2, step 3316/7134 completed (loss: 0.020518241450190544, acc: 0.9966386556625366)
[2024-12-17 05:08:43,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:44,265][root][INFO] - Training Epoch: 2/2, step 3317/7134 completed (loss: 0.0883331224322319, acc: 0.9769230484962463)
[2024-12-17 05:08:44,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:44,673][root][INFO] - Training Epoch: 2/2, step 3318/7134 completed (loss: 0.038175590336322784, acc: 0.9891696572303772)
[2024-12-17 05:08:44,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:45,125][root][INFO] - Training Epoch: 2/2, step 3319/7134 completed (loss: 0.047942306846380234, acc: 0.9885993599891663)
[2024-12-17 05:08:45,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:45,571][root][INFO] - Training Epoch: 2/2, step 3320/7134 completed (loss: 0.05240854248404503, acc: 0.9908376932144165)
[2024-12-17 05:08:45,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:46,005][root][INFO] - Training Epoch: 2/2, step 3321/7134 completed (loss: 0.09926919639110565, acc: 0.9779816269874573)
[2024-12-17 05:08:46,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:46,467][root][INFO] - Training Epoch: 2/2, step 3322/7134 completed (loss: 0.032379765063524246, acc: 0.9879879951477051)
[2024-12-17 05:08:46,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:46,905][root][INFO] - Training Epoch: 2/2, step 3323/7134 completed (loss: 0.027943886816501617, acc: 0.9944827556610107)
[2024-12-17 05:08:47,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:47,376][root][INFO] - Training Epoch: 2/2, step 3324/7134 completed (loss: 0.06715754419565201, acc: 0.9787985682487488)
[2024-12-17 05:08:47,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:47,827][root][INFO] - Training Epoch: 2/2, step 3325/7134 completed (loss: 0.0329686775803566, acc: 0.9919354915618896)
[2024-12-17 05:08:47,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:48,263][root][INFO] - Training Epoch: 2/2, step 3326/7134 completed (loss: 0.05893442779779434, acc: 0.9842519760131836)
[2024-12-17 05:08:48,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:48,685][root][INFO] - Training Epoch: 2/2, step 3327/7134 completed (loss: 0.031068304553627968, acc: 0.9918808937072754)
[2024-12-17 05:08:48,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:49,145][root][INFO] - Training Epoch: 2/2, step 3328/7134 completed (loss: 0.03901628404855728, acc: 0.9937343597412109)
[2024-12-17 05:08:49,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:49,588][root][INFO] - Training Epoch: 2/2, step 3329/7134 completed (loss: 0.020375754684209824, acc: 0.9987819790840149)
[2024-12-17 05:08:49,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:50,044][root][INFO] - Training Epoch: 2/2, step 3330/7134 completed (loss: 0.054593525826931, acc: 0.9884792566299438)
[2024-12-17 05:08:50,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:50,468][root][INFO] - Training Epoch: 2/2, step 3331/7134 completed (loss: 0.08559015393257141, acc: 0.9752907156944275)
[2024-12-17 05:08:50,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:50,910][root][INFO] - Training Epoch: 2/2, step 3332/7134 completed (loss: 0.11507508158683777, acc: 0.9740484356880188)
[2024-12-17 05:08:51,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:51,298][root][INFO] - Training Epoch: 2/2, step 3333/7134 completed (loss: 0.05392845720052719, acc: 0.9856557250022888)
[2024-12-17 05:08:51,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:51,720][root][INFO] - Training Epoch: 2/2, step 3334/7134 completed (loss: 0.0642576664686203, acc: 0.9837837815284729)
[2024-12-17 05:08:51,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:52,144][root][INFO] - Training Epoch: 2/2, step 3335/7134 completed (loss: 0.03973892703652382, acc: 0.9905063509941101)
[2024-12-17 05:08:52,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:52,568][root][INFO] - Training Epoch: 2/2, step 3336/7134 completed (loss: 0.02789408154785633, acc: 0.991253674030304)
[2024-12-17 05:08:52,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:52,994][root][INFO] - Training Epoch: 2/2, step 3337/7134 completed (loss: 0.011533216573297977, acc: 0.9980276226997375)
[2024-12-17 05:08:53,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:53,433][root][INFO] - Training Epoch: 2/2, step 3338/7134 completed (loss: 0.010605419054627419, acc: 0.9962732791900635)
[2024-12-17 05:08:53,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:53,883][root][INFO] - Training Epoch: 2/2, step 3339/7134 completed (loss: 0.05057376250624657, acc: 0.9856801629066467)
[2024-12-17 05:08:54,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:54,312][root][INFO] - Training Epoch: 2/2, step 3340/7134 completed (loss: 0.1112406775355339, acc: 0.9713423848152161)
[2024-12-17 05:08:54,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:54,800][root][INFO] - Training Epoch: 2/2, step 3341/7134 completed (loss: 0.07877583056688309, acc: 0.9822221994400024)
[2024-12-17 05:08:54,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:55,226][root][INFO] - Training Epoch: 2/2, step 3342/7134 completed (loss: 0.03848836198449135, acc: 0.9915540814399719)
[2024-12-17 05:08:55,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:55,666][root][INFO] - Training Epoch: 2/2, step 3343/7134 completed (loss: 0.04675125703215599, acc: 0.9879032373428345)
[2024-12-17 05:08:55,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:56,104][root][INFO] - Training Epoch: 2/2, step 3344/7134 completed (loss: 0.02775878645479679, acc: 0.989708423614502)
[2024-12-17 05:08:56,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:56,547][root][INFO] - Training Epoch: 2/2, step 3345/7134 completed (loss: 0.07490341365337372, acc: 0.987034022808075)
[2024-12-17 05:08:56,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:56,976][root][INFO] - Training Epoch: 2/2, step 3346/7134 completed (loss: 0.03217991068959236, acc: 0.9912280440330505)
[2024-12-17 05:08:57,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:57,375][root][INFO] - Training Epoch: 2/2, step 3347/7134 completed (loss: 0.07482873648405075, acc: 0.9804560542106628)
[2024-12-17 05:08:57,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:57,784][root][INFO] - Training Epoch: 2/2, step 3348/7134 completed (loss: 0.05531756952404976, acc: 0.9911110997200012)
[2024-12-17 05:08:57,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:58,173][root][INFO] - Training Epoch: 2/2, step 3349/7134 completed (loss: 0.02494126185774803, acc: 0.9911816716194153)
[2024-12-17 05:08:58,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:58,603][root][INFO] - Training Epoch: 2/2, step 3350/7134 completed (loss: 0.029864832758903503, acc: 0.9898374080657959)
[2024-12-17 05:08:58,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:59,009][root][INFO] - Training Epoch: 2/2, step 3351/7134 completed (loss: 0.05656199902296066, acc: 0.9840849041938782)
[2024-12-17 05:08:59,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:59,424][root][INFO] - Training Epoch: 2/2, step 3352/7134 completed (loss: 0.02194865606725216, acc: 0.9965217113494873)
[2024-12-17 05:08:59,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:08:59,836][root][INFO] - Training Epoch: 2/2, step 3353/7134 completed (loss: 0.057488761842250824, acc: 0.9783037304878235)
[2024-12-17 05:08:59,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:00,245][root][INFO] - Training Epoch: 2/2, step 3354/7134 completed (loss: 0.037313129752874374, acc: 0.9937984347343445)
[2024-12-17 05:09:00,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:00,662][root][INFO] - Training Epoch: 2/2, step 3355/7134 completed (loss: 0.012766014784574509, acc: 0.994358241558075)
[2024-12-17 05:09:00,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:01,087][root][INFO] - Training Epoch: 2/2, step 3356/7134 completed (loss: 0.017969531938433647, acc: 0.9947916865348816)
[2024-12-17 05:09:01,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:01,519][root][INFO] - Training Epoch: 2/2, step 3357/7134 completed (loss: 0.041049931198358536, acc: 0.9913420081138611)
[2024-12-17 05:09:01,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:01,916][root][INFO] - Training Epoch: 2/2, step 3358/7134 completed (loss: 0.04433896765112877, acc: 0.9930796027183533)
[2024-12-17 05:09:02,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:02,328][root][INFO] - Training Epoch: 2/2, step 3359/7134 completed (loss: 0.01344818715006113, acc: 0.9983818531036377)
[2024-12-17 05:09:02,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:02,740][root][INFO] - Training Epoch: 2/2, step 3360/7134 completed (loss: 0.12100201845169067, acc: 0.9785407781600952)
[2024-12-17 05:09:02,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:03,154][root][INFO] - Training Epoch: 2/2, step 3361/7134 completed (loss: 0.05591271445155144, acc: 0.9843400716781616)
[2024-12-17 05:09:03,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:03,553][root][INFO] - Training Epoch: 2/2, step 3362/7134 completed (loss: 0.0471198745071888, acc: 0.9886621236801147)
[2024-12-17 05:09:03,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:03,909][root][INFO] - Training Epoch: 2/2, step 3363/7134 completed (loss: 0.010710122995078564, acc: 1.0)
[2024-12-17 05:09:04,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:04,331][root][INFO] - Training Epoch: 2/2, step 3364/7134 completed (loss: 0.1022757813334465, acc: 0.9738863110542297)
[2024-12-17 05:09:04,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:04,747][root][INFO] - Training Epoch: 2/2, step 3365/7134 completed (loss: 0.06574493646621704, acc: 0.983132541179657)
[2024-12-17 05:09:04,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:05,154][root][INFO] - Training Epoch: 2/2, step 3366/7134 completed (loss: 0.025441588833928108, acc: 0.9932735562324524)
[2024-12-17 05:09:05,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:05,579][root][INFO] - Training Epoch: 2/2, step 3367/7134 completed (loss: 0.02791368030011654, acc: 0.9931129217147827)
[2024-12-17 05:09:05,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:06,009][root][INFO] - Training Epoch: 2/2, step 3368/7134 completed (loss: 0.03806198760867119, acc: 0.9906396269798279)
[2024-12-17 05:09:06,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:06,469][root][INFO] - Training Epoch: 2/2, step 3369/7134 completed (loss: 0.056857310235500336, acc: 0.9841726422309875)
[2024-12-17 05:09:06,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:06,915][root][INFO] - Training Epoch: 2/2, step 3370/7134 completed (loss: 0.02451249212026596, acc: 0.991416335105896)
[2024-12-17 05:09:07,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:07,319][root][INFO] - Training Epoch: 2/2, step 3371/7134 completed (loss: 0.015919115394353867, acc: 0.9917762875556946)
[2024-12-17 05:09:07,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:07,757][root][INFO] - Training Epoch: 2/2, step 3372/7134 completed (loss: 0.03400810807943344, acc: 0.9890282154083252)
[2024-12-17 05:09:07,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:08,183][root][INFO] - Training Epoch: 2/2, step 3373/7134 completed (loss: 0.019283998757600784, acc: 0.9938271641731262)
[2024-12-17 05:09:08,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:08,638][root][INFO] - Training Epoch: 2/2, step 3374/7134 completed (loss: 0.01642131619155407, acc: 0.9930362105369568)
[2024-12-17 05:09:08,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:09,097][root][INFO] - Training Epoch: 2/2, step 3375/7134 completed (loss: 0.02451678365468979, acc: 0.9956584572792053)
[2024-12-17 05:09:09,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:09,542][root][INFO] - Training Epoch: 2/2, step 3376/7134 completed (loss: 0.013104109093546867, acc: 0.9961685538291931)
[2024-12-17 05:09:09,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:10,015][root][INFO] - Training Epoch: 2/2, step 3377/7134 completed (loss: 0.013971426524221897, acc: 0.9964243173599243)
[2024-12-17 05:09:10,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:10,443][root][INFO] - Training Epoch: 2/2, step 3378/7134 completed (loss: 0.010296841152012348, acc: 0.99609375)
[2024-12-17 05:09:10,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:10,851][root][INFO] - Training Epoch: 2/2, step 3379/7134 completed (loss: 0.028350139036774635, acc: 0.9909774661064148)
[2024-12-17 05:09:10,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:11,267][root][INFO] - Training Epoch: 2/2, step 3380/7134 completed (loss: 0.02944791689515114, acc: 0.9938461780548096)
[2024-12-17 05:09:11,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:11,724][root][INFO] - Training Epoch: 2/2, step 3381/7134 completed (loss: 0.05190645903348923, acc: 0.985788106918335)
[2024-12-17 05:09:11,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:12,143][root][INFO] - Training Epoch: 2/2, step 3382/7134 completed (loss: 0.0036807043943554163, acc: 1.0)
[2024-12-17 05:09:12,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:12,600][root][INFO] - Training Epoch: 2/2, step 3383/7134 completed (loss: 0.03150501102209091, acc: 0.9928264021873474)
[2024-12-17 05:09:12,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:13,001][root][INFO] - Training Epoch: 2/2, step 3384/7134 completed (loss: 0.0440230518579483, acc: 0.9877675771713257)
[2024-12-17 05:09:13,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:13,437][root][INFO] - Training Epoch: 2/2, step 3385/7134 completed (loss: 0.042067550122737885, acc: 0.9870503544807434)
[2024-12-17 05:09:13,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:13,870][root][INFO] - Training Epoch: 2/2, step 3386/7134 completed (loss: 0.02049862965941429, acc: 0.994350254535675)
[2024-12-17 05:09:13,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:14,288][root][INFO] - Training Epoch: 2/2, step 3387/7134 completed (loss: 0.04628390818834305, acc: 0.9904761910438538)
[2024-12-17 05:09:14,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:14,712][root][INFO] - Training Epoch: 2/2, step 3388/7134 completed (loss: 0.034960001707077026, acc: 0.9873417615890503)
[2024-12-17 05:09:14,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:15,163][root][INFO] - Training Epoch: 2/2, step 3389/7134 completed (loss: 0.028585677966475487, acc: 0.9947299361228943)
[2024-12-17 05:09:15,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:15,607][root][INFO] - Training Epoch: 2/2, step 3390/7134 completed (loss: 0.02828816883265972, acc: 0.9896373152732849)
[2024-12-17 05:09:15,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:16,012][root][INFO] - Training Epoch: 2/2, step 3391/7134 completed (loss: 0.0040823654271662235, acc: 1.0)
[2024-12-17 05:09:16,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:16,414][root][INFO] - Training Epoch: 2/2, step 3392/7134 completed (loss: 0.011066139675676823, acc: 0.9952830076217651)
[2024-12-17 05:09:16,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:16,829][root][INFO] - Training Epoch: 2/2, step 3393/7134 completed (loss: 0.019090469926595688, acc: 0.9938271641731262)
[2024-12-17 05:09:16,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:17,258][root][INFO] - Training Epoch: 2/2, step 3394/7134 completed (loss: 0.03734273463487625, acc: 0.9873417615890503)
[2024-12-17 05:09:17,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:17,673][root][INFO] - Training Epoch: 2/2, step 3395/7134 completed (loss: 0.06385649740695953, acc: 0.9788960814476013)
[2024-12-17 05:09:17,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:18,123][root][INFO] - Training Epoch: 2/2, step 3396/7134 completed (loss: 0.04239818826317787, acc: 0.9928143620491028)
[2024-12-17 05:09:18,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:18,584][root][INFO] - Training Epoch: 2/2, step 3397/7134 completed (loss: 0.03151460364460945, acc: 0.9938875436782837)
[2024-12-17 05:09:18,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:19,007][root][INFO] - Training Epoch: 2/2, step 3398/7134 completed (loss: 0.03851857781410217, acc: 0.9910394549369812)
[2024-12-17 05:09:19,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:19,424][root][INFO] - Training Epoch: 2/2, step 3399/7134 completed (loss: 0.10250324010848999, acc: 0.9742646813392639)
[2024-12-17 05:09:19,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:19,847][root][INFO] - Training Epoch: 2/2, step 3400/7134 completed (loss: 0.06537185609340668, acc: 0.9817444086074829)
[2024-12-17 05:09:19,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:20,259][root][INFO] - Training Epoch: 2/2, step 3401/7134 completed (loss: 0.056123312562704086, acc: 0.9877622127532959)
[2024-12-17 05:09:20,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:20,757][root][INFO] - Training Epoch: 2/2, step 3402/7134 completed (loss: 0.04965445026755333, acc: 0.9881423115730286)
[2024-12-17 05:09:20,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:21,212][root][INFO] - Training Epoch: 2/2, step 3403/7134 completed (loss: 0.08080438524484634, acc: 0.98046875)
[2024-12-17 05:09:21,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:21,623][root][INFO] - Training Epoch: 2/2, step 3404/7134 completed (loss: 0.020434629172086716, acc: 0.9955157041549683)
[2024-12-17 05:09:21,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:22,048][root][INFO] - Training Epoch: 2/2, step 3405/7134 completed (loss: 0.07021817564964294, acc: 0.9820144176483154)
[2024-12-17 05:09:22,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:22,497][root][INFO] - Training Epoch: 2/2, step 3406/7134 completed (loss: 0.04008932411670685, acc: 0.9896907210350037)
[2024-12-17 05:09:22,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:22,875][root][INFO] - Training Epoch: 2/2, step 3407/7134 completed (loss: 0.05085545405745506, acc: 0.9859594106674194)
[2024-12-17 05:09:22,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:23,280][root][INFO] - Training Epoch: 2/2, step 3408/7134 completed (loss: 0.03551490977406502, acc: 0.9861751198768616)
[2024-12-17 05:09:23,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:23,729][root][INFO] - Training Epoch: 2/2, step 3409/7134 completed (loss: 0.03810020163655281, acc: 0.9905277490615845)
[2024-12-17 05:09:23,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:24,146][root][INFO] - Training Epoch: 2/2, step 3410/7134 completed (loss: 0.03472870588302612, acc: 0.9931129217147827)
[2024-12-17 05:09:24,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:24,589][root][INFO] - Training Epoch: 2/2, step 3411/7134 completed (loss: 0.03955530747771263, acc: 0.9896507263183594)
[2024-12-17 05:09:24,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:24,984][root][INFO] - Training Epoch: 2/2, step 3412/7134 completed (loss: 0.03888479620218277, acc: 0.9867674708366394)
[2024-12-17 05:09:25,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:25,417][root][INFO] - Training Epoch: 2/2, step 3413/7134 completed (loss: 0.04584605246782303, acc: 0.9879999756813049)
[2024-12-17 05:09:25,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:25,853][root][INFO] - Training Epoch: 2/2, step 3414/7134 completed (loss: 0.0482262559235096, acc: 0.9883138537406921)
[2024-12-17 05:09:25,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:26,299][root][INFO] - Training Epoch: 2/2, step 3415/7134 completed (loss: 0.0359283946454525, acc: 0.9903846383094788)
[2024-12-17 05:09:26,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:26,759][root][INFO] - Training Epoch: 2/2, step 3416/7134 completed (loss: 0.05214865133166313, acc: 0.9855942130088806)
[2024-12-17 05:09:26,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:27,202][root][INFO] - Training Epoch: 2/2, step 3417/7134 completed (loss: 0.025835396721959114, acc: 0.9932523369789124)
[2024-12-17 05:09:27,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:27,623][root][INFO] - Training Epoch: 2/2, step 3418/7134 completed (loss: 0.029058007523417473, acc: 0.9941089749336243)
[2024-12-17 05:09:27,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:28,037][root][INFO] - Training Epoch: 2/2, step 3419/7134 completed (loss: 0.011880247853696346, acc: 0.9942362904548645)
[2024-12-17 05:09:28,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:28,467][root][INFO] - Training Epoch: 2/2, step 3420/7134 completed (loss: 0.011477788910269737, acc: 0.9968404173851013)
[2024-12-17 05:09:28,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:28,899][root][INFO] - Training Epoch: 2/2, step 3421/7134 completed (loss: 0.027027752250432968, acc: 0.9953343868255615)
[2024-12-17 05:09:29,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:29,296][root][INFO] - Training Epoch: 2/2, step 3422/7134 completed (loss: 0.010995077900588512, acc: 0.996497392654419)
[2024-12-17 05:09:29,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:29,743][root][INFO] - Training Epoch: 2/2, step 3423/7134 completed (loss: 0.01842520944774151, acc: 0.9924242496490479)
[2024-12-17 05:09:29,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:30,170][root][INFO] - Training Epoch: 2/2, step 3424/7134 completed (loss: 0.07459250837564468, acc: 0.9819276928901672)
[2024-12-17 05:09:30,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:30,584][root][INFO] - Training Epoch: 2/2, step 3425/7134 completed (loss: 0.024555973708629608, acc: 0.9923076629638672)
[2024-12-17 05:09:30,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:31,026][root][INFO] - Training Epoch: 2/2, step 3426/7134 completed (loss: 0.039658062160015106, acc: 0.9944827556610107)
[2024-12-17 05:09:31,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:31,448][root][INFO] - Training Epoch: 2/2, step 3427/7134 completed (loss: 0.03659813851118088, acc: 0.9905213117599487)
[2024-12-17 05:09:31,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:31,890][root][INFO] - Training Epoch: 2/2, step 3428/7134 completed (loss: 0.021026866510510445, acc: 0.9942693114280701)
[2024-12-17 05:09:32,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:32,340][root][INFO] - Training Epoch: 2/2, step 3429/7134 completed (loss: 0.028893979266285896, acc: 0.9902912378311157)
[2024-12-17 05:09:32,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:32,777][root][INFO] - Training Epoch: 2/2, step 3430/7134 completed (loss: 0.0702919289469719, acc: 0.987034022808075)
[2024-12-17 05:09:32,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:33,214][root][INFO] - Training Epoch: 2/2, step 3431/7134 completed (loss: 0.039261575788259506, acc: 0.9898132681846619)
[2024-12-17 05:09:33,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:33,665][root][INFO] - Training Epoch: 2/2, step 3432/7134 completed (loss: 0.029722079634666443, acc: 0.9945130348205566)
[2024-12-17 05:09:33,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:34,118][root][INFO] - Training Epoch: 2/2, step 3433/7134 completed (loss: 0.05068572238087654, acc: 0.9820261597633362)
[2024-12-17 05:09:34,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:34,529][root][INFO] - Training Epoch: 2/2, step 3434/7134 completed (loss: 0.020428216084837914, acc: 0.9936407208442688)
[2024-12-17 05:09:34,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:34,951][root][INFO] - Training Epoch: 2/2, step 3435/7134 completed (loss: 0.05602990463376045, acc: 0.9823151230812073)
[2024-12-17 05:09:35,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:35,381][root][INFO] - Training Epoch: 2/2, step 3436/7134 completed (loss: 0.038407228887081146, acc: 0.9886178970336914)
[2024-12-17 05:09:35,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:35,765][root][INFO] - Training Epoch: 2/2, step 3437/7134 completed (loss: 0.022137576714158058, acc: 0.994140625)
[2024-12-17 05:09:35,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:36,177][root][INFO] - Training Epoch: 2/2, step 3438/7134 completed (loss: 0.03801751509308815, acc: 0.991919219493866)
[2024-12-17 05:09:36,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:36,582][root][INFO] - Training Epoch: 2/2, step 3439/7134 completed (loss: 0.03742722049355507, acc: 0.9891501069068909)
[2024-12-17 05:09:36,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:36,989][root][INFO] - Training Epoch: 2/2, step 3440/7134 completed (loss: 0.059582699090242386, acc: 0.9711934328079224)
[2024-12-17 05:09:37,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:37,404][root][INFO] - Training Epoch: 2/2, step 3441/7134 completed (loss: 0.04613234102725983, acc: 0.9855491518974304)
[2024-12-17 05:09:37,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:37,823][root][INFO] - Training Epoch: 2/2, step 3442/7134 completed (loss: 0.0176607146859169, acc: 0.9945255517959595)
[2024-12-17 05:09:37,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:38,187][root][INFO] - Training Epoch: 2/2, step 3443/7134 completed (loss: 0.06563121825456619, acc: 0.983146071434021)
[2024-12-17 05:09:38,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:38,613][root][INFO] - Training Epoch: 2/2, step 3444/7134 completed (loss: 0.059103090316057205, acc: 0.9873417615890503)
[2024-12-17 05:09:38,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:38,994][root][INFO] - Training Epoch: 2/2, step 3445/7134 completed (loss: 0.11596719920635223, acc: 0.9741935729980469)
[2024-12-17 05:09:39,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:39,420][root][INFO] - Training Epoch: 2/2, step 3446/7134 completed (loss: 0.0826122984290123, acc: 0.9799330830574036)
[2024-12-17 05:09:39,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:39,845][root][INFO] - Training Epoch: 2/2, step 3447/7134 completed (loss: 0.051178865134716034, acc: 0.9837133288383484)
[2024-12-17 05:09:39,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:40,269][root][INFO] - Training Epoch: 2/2, step 3448/7134 completed (loss: 0.023907821625471115, acc: 0.9909909963607788)
[2024-12-17 05:09:40,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:40,668][root][INFO] - Training Epoch: 2/2, step 3449/7134 completed (loss: 0.053416505455970764, acc: 0.9897959232330322)
[2024-12-17 05:09:40,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:41,085][root][INFO] - Training Epoch: 2/2, step 3450/7134 completed (loss: 0.04605000838637352, acc: 0.9898734092712402)
[2024-12-17 05:09:41,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:41,494][root][INFO] - Training Epoch: 2/2, step 3451/7134 completed (loss: 0.030252553522586823, acc: 0.9929328560829163)
[2024-12-17 05:09:41,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:41,900][root][INFO] - Training Epoch: 2/2, step 3452/7134 completed (loss: 0.039092957973480225, acc: 0.989154040813446)
[2024-12-17 05:09:42,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:42,299][root][INFO] - Training Epoch: 2/2, step 3453/7134 completed (loss: 0.04979563504457474, acc: 0.9881154298782349)
[2024-12-17 05:09:42,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:42,732][root][INFO] - Training Epoch: 2/2, step 3454/7134 completed (loss: 0.032581910490989685, acc: 0.9873060584068298)
[2024-12-17 05:09:42,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:43,174][root][INFO] - Training Epoch: 2/2, step 3455/7134 completed (loss: 0.013036034069955349, acc: 0.9942029118537903)
[2024-12-17 05:09:43,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:43,625][root][INFO] - Training Epoch: 2/2, step 3456/7134 completed (loss: 0.02847912535071373, acc: 0.9952940940856934)
[2024-12-17 05:09:43,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:44,063][root][INFO] - Training Epoch: 2/2, step 3457/7134 completed (loss: 0.018169311806559563, acc: 0.994915246963501)
[2024-12-17 05:09:44,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:44,520][root][INFO] - Training Epoch: 2/2, step 3458/7134 completed (loss: 0.047106292098760605, acc: 0.9878214001655579)
[2024-12-17 05:09:44,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:44,960][root][INFO] - Training Epoch: 2/2, step 3459/7134 completed (loss: 0.04620838165283203, acc: 0.9893454909324646)
[2024-12-17 05:09:45,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:45,416][root][INFO] - Training Epoch: 2/2, step 3460/7134 completed (loss: 0.1612783819437027, acc: 0.9615384340286255)
[2024-12-17 05:09:45,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:45,830][root][INFO] - Training Epoch: 2/2, step 3461/7134 completed (loss: 0.21478067338466644, acc: 0.9563218355178833)
[2024-12-17 05:09:45,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:46,245][root][INFO] - Training Epoch: 2/2, step 3462/7134 completed (loss: 0.09620462357997894, acc: 0.9733123779296875)
[2024-12-17 05:09:46,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:46,708][root][INFO] - Training Epoch: 2/2, step 3463/7134 completed (loss: 0.017710324376821518, acc: 0.9954751133918762)
[2024-12-17 05:09:46,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:47,141][root][INFO] - Training Epoch: 2/2, step 3464/7134 completed (loss: 0.03682195395231247, acc: 0.989276111125946)
[2024-12-17 05:09:47,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:47,538][root][INFO] - Training Epoch: 2/2, step 3465/7134 completed (loss: 0.07033572345972061, acc: 0.9857434034347534)
[2024-12-17 05:09:47,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:47,967][root][INFO] - Training Epoch: 2/2, step 3466/7134 completed (loss: 0.025950267910957336, acc: 0.9936608672142029)
[2024-12-17 05:09:48,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:48,382][root][INFO] - Training Epoch: 2/2, step 3467/7134 completed (loss: 0.032012756913900375, acc: 0.9893842935562134)
[2024-12-17 05:09:48,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:48,801][root][INFO] - Training Epoch: 2/2, step 3468/7134 completed (loss: 0.007660317234694958, acc: 1.0)
[2024-12-17 05:09:48,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:49,215][root][INFO] - Training Epoch: 2/2, step 3469/7134 completed (loss: 0.05004342272877693, acc: 0.9867924451828003)
[2024-12-17 05:09:49,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:49,613][root][INFO] - Training Epoch: 2/2, step 3470/7134 completed (loss: 0.014254060573875904, acc: 0.9953917264938354)
[2024-12-17 05:09:49,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:50,013][root][INFO] - Training Epoch: 2/2, step 3471/7134 completed (loss: 0.06894172728061676, acc: 0.9917126893997192)
[2024-12-17 05:09:50,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:50,443][root][INFO] - Training Epoch: 2/2, step 3472/7134 completed (loss: 0.013718859292566776, acc: 0.997019350528717)
[2024-12-17 05:09:50,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:50,925][root][INFO] - Training Epoch: 2/2, step 3473/7134 completed (loss: 0.021369514986872673, acc: 0.9933775067329407)
[2024-12-17 05:09:51,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:51,316][root][INFO] - Training Epoch: 2/2, step 3474/7134 completed (loss: 0.043456900864839554, acc: 0.9911660552024841)
[2024-12-17 05:09:51,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:51,737][root][INFO] - Training Epoch: 2/2, step 3475/7134 completed (loss: 0.028868122026324272, acc: 0.9911190271377563)
[2024-12-17 05:09:51,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:52,171][root][INFO] - Training Epoch: 2/2, step 3476/7134 completed (loss: 0.05093058571219444, acc: 0.9845890402793884)
[2024-12-17 05:09:52,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:52,591][root][INFO] - Training Epoch: 2/2, step 3477/7134 completed (loss: 0.04331722483038902, acc: 0.9901315569877625)
[2024-12-17 05:09:52,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:53,006][root][INFO] - Training Epoch: 2/2, step 3478/7134 completed (loss: 0.03557545691728592, acc: 0.9895209670066833)
[2024-12-17 05:09:53,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:53,427][root][INFO] - Training Epoch: 2/2, step 3479/7134 completed (loss: 0.004104844760149717, acc: 1.0)
[2024-12-17 05:09:53,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:53,869][root][INFO] - Training Epoch: 2/2, step 3480/7134 completed (loss: 0.03194544091820717, acc: 0.9918256402015686)
[2024-12-17 05:09:53,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:54,290][root][INFO] - Training Epoch: 2/2, step 3481/7134 completed (loss: 0.025585362687706947, acc: 0.9929078221321106)
[2024-12-17 05:09:54,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:54,707][root][INFO] - Training Epoch: 2/2, step 3482/7134 completed (loss: 0.011599809862673283, acc: 0.9946042895317078)
[2024-12-17 05:09:54,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:55,144][root][INFO] - Training Epoch: 2/2, step 3483/7134 completed (loss: 0.00469899782910943, acc: 1.0)
[2024-12-17 05:09:55,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:55,547][root][INFO] - Training Epoch: 2/2, step 3484/7134 completed (loss: 0.02518559992313385, acc: 0.99262535572052)
[2024-12-17 05:09:55,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:55,940][root][INFO] - Training Epoch: 2/2, step 3485/7134 completed (loss: 0.02454119361937046, acc: 0.9942280054092407)
[2024-12-17 05:09:56,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:56,358][root][INFO] - Training Epoch: 2/2, step 3486/7134 completed (loss: 0.018899647518992424, acc: 0.9964028596878052)
[2024-12-17 05:09:56,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:56,786][root][INFO] - Training Epoch: 2/2, step 3487/7134 completed (loss: 0.023007869720458984, acc: 0.9911634922027588)
[2024-12-17 05:09:56,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:57,218][root][INFO] - Training Epoch: 2/2, step 3488/7134 completed (loss: 0.03102269023656845, acc: 0.9901315569877625)
[2024-12-17 05:09:57,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:57,617][root][INFO] - Training Epoch: 2/2, step 3489/7134 completed (loss: 0.07013694941997528, acc: 0.9815837740898132)
[2024-12-17 05:09:57,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:58,073][root][INFO] - Training Epoch: 2/2, step 3490/7134 completed (loss: 0.0671229213476181, acc: 0.9867060780525208)
[2024-12-17 05:09:58,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:58,490][root][INFO] - Training Epoch: 2/2, step 3491/7134 completed (loss: 0.0395597368478775, acc: 0.9886524677276611)
[2024-12-17 05:09:58,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:58,874][root][INFO] - Training Epoch: 2/2, step 3492/7134 completed (loss: 0.040235307067632675, acc: 0.987679660320282)
[2024-12-17 05:09:59,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:59,307][root][INFO] - Training Epoch: 2/2, step 3493/7134 completed (loss: 0.014659767970442772, acc: 0.9957982897758484)
[2024-12-17 05:09:59,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:09:59,714][root][INFO] - Training Epoch: 2/2, step 3494/7134 completed (loss: 0.02854376845061779, acc: 0.9931034445762634)
[2024-12-17 05:09:59,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:00,146][root][INFO] - Training Epoch: 2/2, step 3495/7134 completed (loss: 0.01096052210777998, acc: 0.9952038526535034)
[2024-12-17 05:10:00,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:00,546][root][INFO] - Training Epoch: 2/2, step 3496/7134 completed (loss: 0.016941694542765617, acc: 0.9954954981803894)
[2024-12-17 05:10:00,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:00,961][root][INFO] - Training Epoch: 2/2, step 3497/7134 completed (loss: 0.027294186875224113, acc: 0.9940652847290039)
[2024-12-17 05:10:01,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:01,379][root][INFO] - Training Epoch: 2/2, step 3498/7134 completed (loss: 0.033516839146614075, acc: 0.9878048896789551)
[2024-12-17 05:10:01,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:01,796][root][INFO] - Training Epoch: 2/2, step 3499/7134 completed (loss: 0.0099730109795928, acc: 0.9983792304992676)
[2024-12-17 05:10:01,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:02,210][root][INFO] - Training Epoch: 2/2, step 3500/7134 completed (loss: 0.04820369556546211, acc: 0.9867841601371765)
[2024-12-17 05:10:02,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:02,651][root][INFO] - Training Epoch: 2/2, step 3501/7134 completed (loss: 0.08112216740846634, acc: 0.9698188900947571)
[2024-12-17 05:10:02,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:03,057][root][INFO] - Training Epoch: 2/2, step 3502/7134 completed (loss: 0.06935404986143112, acc: 0.9789473414421082)
[2024-12-17 05:10:03,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:03,482][root][INFO] - Training Epoch: 2/2, step 3503/7134 completed (loss: 0.05796835198998451, acc: 0.9878683090209961)
[2024-12-17 05:10:03,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:03,909][root][INFO] - Training Epoch: 2/2, step 3504/7134 completed (loss: 0.009647734463214874, acc: 0.9984917044639587)
[2024-12-17 05:10:04,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:04,342][root][INFO] - Training Epoch: 2/2, step 3505/7134 completed (loss: 0.03306029736995697, acc: 0.9856887459754944)
[2024-12-17 05:10:04,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:04,751][root][INFO] - Training Epoch: 2/2, step 3506/7134 completed (loss: 0.022529521957039833, acc: 0.9943289160728455)
[2024-12-17 05:10:04,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:05,190][root][INFO] - Training Epoch: 2/2, step 3507/7134 completed (loss: 0.009726755321025848, acc: 0.998344361782074)
[2024-12-17 05:10:05,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:05,622][root][INFO] - Training Epoch: 2/2, step 3508/7134 completed (loss: 0.032706666737794876, acc: 0.9926900863647461)
[2024-12-17 05:10:05,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:06,053][root][INFO] - Training Epoch: 2/2, step 3509/7134 completed (loss: 0.014629223383963108, acc: 0.9944751262664795)
[2024-12-17 05:10:06,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:06,466][root][INFO] - Training Epoch: 2/2, step 3510/7134 completed (loss: 0.033811699599027634, acc: 0.989708423614502)
[2024-12-17 05:10:06,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:06,901][root][INFO] - Training Epoch: 2/2, step 3511/7134 completed (loss: 0.009001044556498528, acc: 0.9963964223861694)
[2024-12-17 05:10:07,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:07,315][root][INFO] - Training Epoch: 2/2, step 3512/7134 completed (loss: 0.03564222529530525, acc: 0.9904912710189819)
[2024-12-17 05:10:07,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:07,749][root][INFO] - Training Epoch: 2/2, step 3513/7134 completed (loss: 0.017332026734948158, acc: 0.9946902394294739)
[2024-12-17 05:10:07,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:08,200][root][INFO] - Training Epoch: 2/2, step 3514/7134 completed (loss: 0.03262968361377716, acc: 0.9919354915618896)
[2024-12-17 05:10:08,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:08,624][root][INFO] - Training Epoch: 2/2, step 3515/7134 completed (loss: 0.006245358847081661, acc: 1.0)
[2024-12-17 05:10:08,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:09,092][root][INFO] - Training Epoch: 2/2, step 3516/7134 completed (loss: 0.014764669351279736, acc: 0.996749758720398)
[2024-12-17 05:10:09,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:09,538][root][INFO] - Training Epoch: 2/2, step 3517/7134 completed (loss: 0.014050483703613281, acc: 0.9940405488014221)
[2024-12-17 05:10:09,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:09,986][root][INFO] - Training Epoch: 2/2, step 3518/7134 completed (loss: 0.019757598638534546, acc: 0.9907578825950623)
[2024-12-17 05:10:10,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:10,432][root][INFO] - Training Epoch: 2/2, step 3519/7134 completed (loss: 0.018626859411597252, acc: 0.9955056309700012)
[2024-12-17 05:10:10,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:10,906][root][INFO] - Training Epoch: 2/2, step 3520/7134 completed (loss: 0.05734359845519066, acc: 0.9847058653831482)
[2024-12-17 05:10:11,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:11,357][root][INFO] - Training Epoch: 2/2, step 3521/7134 completed (loss: 0.016514010727405548, acc: 0.9971550703048706)
[2024-12-17 05:10:11,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:11,769][root][INFO] - Training Epoch: 2/2, step 3522/7134 completed (loss: 0.010365854017436504, acc: 0.9973261952400208)
[2024-12-17 05:10:11,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:12,223][root][INFO] - Training Epoch: 2/2, step 3523/7134 completed (loss: 0.008094326592981815, acc: 0.9984591603279114)
[2024-12-17 05:10:12,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:12,678][root][INFO] - Training Epoch: 2/2, step 3524/7134 completed (loss: 0.02426501363515854, acc: 0.9947916865348816)
[2024-12-17 05:10:12,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:13,131][root][INFO] - Training Epoch: 2/2, step 3525/7134 completed (loss: 0.01853594183921814, acc: 0.9950576424598694)
[2024-12-17 05:10:13,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:13,582][root][INFO] - Training Epoch: 2/2, step 3526/7134 completed (loss: 0.04062071070075035, acc: 0.9911280274391174)
[2024-12-17 05:10:13,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:14,044][root][INFO] - Training Epoch: 2/2, step 3527/7134 completed (loss: 0.022217443212866783, acc: 0.9974392056465149)
[2024-12-17 05:10:14,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:14,493][root][INFO] - Training Epoch: 2/2, step 3528/7134 completed (loss: 0.0031110274139791727, acc: 1.0)
[2024-12-17 05:10:14,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:14,926][root][INFO] - Training Epoch: 2/2, step 3529/7134 completed (loss: 0.008312010206282139, acc: 1.0)
[2024-12-17 05:10:15,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:15,399][root][INFO] - Training Epoch: 2/2, step 3530/7134 completed (loss: 0.025930888950824738, acc: 0.9919725060462952)
[2024-12-17 05:10:15,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:15,842][root][INFO] - Training Epoch: 2/2, step 3531/7134 completed (loss: 0.024289172142744064, acc: 0.9939758777618408)
[2024-12-17 05:10:15,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:16,302][root][INFO] - Training Epoch: 2/2, step 3532/7134 completed (loss: 0.0033765777479857206, acc: 1.0)
[2024-12-17 05:10:16,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:16,740][root][INFO] - Training Epoch: 2/2, step 3533/7134 completed (loss: 0.014232907444238663, acc: 0.9930151104927063)
[2024-12-17 05:10:16,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:17,170][root][INFO] - Training Epoch: 2/2, step 3534/7134 completed (loss: 0.03131062537431717, acc: 0.9930459260940552)
[2024-12-17 05:10:17,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:17,607][root][INFO] - Training Epoch: 2/2, step 3535/7134 completed (loss: 0.033708322793245316, acc: 0.9907833933830261)
[2024-12-17 05:10:17,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:18,065][root][INFO] - Training Epoch: 2/2, step 3536/7134 completed (loss: 0.04523051157593727, acc: 0.9863387942314148)
[2024-12-17 05:10:18,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:18,463][root][INFO] - Training Epoch: 2/2, step 3537/7134 completed (loss: 0.023902101442217827, acc: 0.9932885766029358)
[2024-12-17 05:10:18,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:18,869][root][INFO] - Training Epoch: 2/2, step 3538/7134 completed (loss: 0.04819202795624733, acc: 0.9923954606056213)
[2024-12-17 05:10:18,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:19,242][root][INFO] - Training Epoch: 2/2, step 3539/7134 completed (loss: 0.015767673030495644, acc: 0.9927184581756592)
[2024-12-17 05:10:19,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:19,662][root][INFO] - Training Epoch: 2/2, step 3540/7134 completed (loss: 0.0383591465651989, acc: 0.9863429665565491)
[2024-12-17 05:10:19,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:20,091][root][INFO] - Training Epoch: 2/2, step 3541/7134 completed (loss: 0.026414472609758377, acc: 0.9897210001945496)
[2024-12-17 05:10:20,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:20,527][root][INFO] - Training Epoch: 2/2, step 3542/7134 completed (loss: 0.03472520038485527, acc: 0.989230751991272)
[2024-12-17 05:10:20,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:20,931][root][INFO] - Training Epoch: 2/2, step 3543/7134 completed (loss: 0.03229369595646858, acc: 0.9823943376541138)
[2024-12-17 05:10:21,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:21,374][root][INFO] - Training Epoch: 2/2, step 3544/7134 completed (loss: 0.0392710380256176, acc: 0.9846153855323792)
[2024-12-17 05:10:21,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:21,824][root][INFO] - Training Epoch: 2/2, step 3545/7134 completed (loss: 0.010385105386376381, acc: 0.9968944191932678)
[2024-12-17 05:10:21,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:22,245][root][INFO] - Training Epoch: 2/2, step 3546/7134 completed (loss: 0.022297322750091553, acc: 0.9950494766235352)
[2024-12-17 05:10:22,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:22,697][root][INFO] - Training Epoch: 2/2, step 3547/7134 completed (loss: 0.04431086406111717, acc: 0.9860140085220337)
[2024-12-17 05:10:22,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:23,131][root][INFO] - Training Epoch: 2/2, step 3548/7134 completed (loss: 0.028957249596714973, acc: 0.991150438785553)
[2024-12-17 05:10:23,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:23,552][root][INFO] - Training Epoch: 2/2, step 3549/7134 completed (loss: 0.04380475729703903, acc: 0.9911816716194153)
[2024-12-17 05:10:23,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:23,951][root][INFO] - Training Epoch: 2/2, step 3550/7134 completed (loss: 0.011948807165026665, acc: 0.9947460889816284)
[2024-12-17 05:10:24,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:24,369][root][INFO] - Training Epoch: 2/2, step 3551/7134 completed (loss: 0.026349086314439774, acc: 0.9898989796638489)
[2024-12-17 05:10:24,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:24,807][root][INFO] - Training Epoch: 2/2, step 3552/7134 completed (loss: 0.11578341573476791, acc: 0.9719101190567017)
[2024-12-17 05:10:24,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:25,228][root][INFO] - Training Epoch: 2/2, step 3553/7134 completed (loss: 0.06639672070741653, acc: 0.9851973652839661)
[2024-12-17 05:10:25,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:25,647][root][INFO] - Training Epoch: 2/2, step 3554/7134 completed (loss: 0.045538775622844696, acc: 0.9894578456878662)
[2024-12-17 05:10:25,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:26,051][root][INFO] - Training Epoch: 2/2, step 3555/7134 completed (loss: 0.03053954429924488, acc: 0.9921507239341736)
[2024-12-17 05:10:26,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:26,459][root][INFO] - Training Epoch: 2/2, step 3556/7134 completed (loss: 0.030545692890882492, acc: 0.9942418336868286)
[2024-12-17 05:10:26,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:26,903][root][INFO] - Training Epoch: 2/2, step 3557/7134 completed (loss: 0.027810916304588318, acc: 0.9945553541183472)
[2024-12-17 05:10:26,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:27,306][root][INFO] - Training Epoch: 2/2, step 3558/7134 completed (loss: 0.046641938388347626, acc: 0.985567033290863)
[2024-12-17 05:10:27,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:27,732][root][INFO] - Training Epoch: 2/2, step 3559/7134 completed (loss: 0.021269377321004868, acc: 0.9970930218696594)
[2024-12-17 05:10:27,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:28,156][root][INFO] - Training Epoch: 2/2, step 3560/7134 completed (loss: 0.012772809714078903, acc: 0.9958904385566711)
[2024-12-17 05:10:28,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:28,592][root][INFO] - Training Epoch: 2/2, step 3561/7134 completed (loss: 0.037641361355781555, acc: 0.9859943985939026)
[2024-12-17 05:10:28,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:29,001][root][INFO] - Training Epoch: 2/2, step 3562/7134 completed (loss: 0.041075654327869415, acc: 0.987500011920929)
[2024-12-17 05:10:29,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:29,411][root][INFO] - Training Epoch: 2/2, step 3563/7134 completed (loss: 0.01648811623454094, acc: 0.995230495929718)
[2024-12-17 05:10:30,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:31,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:31,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:31,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:32,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:32,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:32,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:33,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:33,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:34,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:34,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:34,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:35,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:35,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:35,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:36,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:36,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:36,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:37,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:37,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:38,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:38,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:38,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:39,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:39,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:39,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:40,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:40,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:40,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:41,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:41,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:42,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:42,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:42,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:43,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:43,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:43,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:44,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:44,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:45,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:45,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:45,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:46,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:46,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:46,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:47,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:47,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:48,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:48,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:48,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:48,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:49,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:49,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:50,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:50,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:50,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:51,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:51,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:51,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:52,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:52,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:52,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:53,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:53,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:53,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:54,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:54,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:54,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:54,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:55,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:55,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:56,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:56,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:56,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:57,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:57,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:58,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:58,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:58,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:59,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:59,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:10:59,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:00,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:00,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:01,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:01,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:02,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:02,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:02,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:03,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:03,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:04,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:04,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:04,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:04,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:05,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:05,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:05,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:06,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:06,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:07,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:07,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:07,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:08,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:08,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:09,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:09,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:09,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:10,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:10,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:10,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:11,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:11,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:12,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:12,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:12,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:12,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:13,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:13,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:14,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:14,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:14,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:15,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:15,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:15,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:16,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:16,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:17,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:17,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:17,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:18,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:18,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:18,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:19,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:19,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:20,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:20,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:20,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:21,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:21,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:22,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:22,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:22,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:23,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:23,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:24,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:24,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:24,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:25,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:25,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:26,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:26,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:26,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:27,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:27,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:27,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:28,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:28,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:29,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:29,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:30,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:30,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:30,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:31,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:31,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:31,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:32,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:32,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:33,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:33,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:33,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:34,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:34,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:34,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:35,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:35,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:36,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:36,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:36,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:37,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:37,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:37,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:38,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:38,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:39,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:39,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:39,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:40,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:40,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:40,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:41,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:41,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:41,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:42,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:42,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:43,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:43,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:43,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:44,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:44,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:45,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:45,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:45,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:45,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:46,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:46,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:47,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:47,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:47,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:48,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:48,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:49,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:49,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:49,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:50,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:50,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:50,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:51,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:51,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:51,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:52,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:52,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:53,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:53,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:53,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:53,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:54,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:54,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:54,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:55,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:55,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:56,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:56,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:57,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:57,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:57,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:58,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:58,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:59,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:59,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:11:59,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:00,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:00,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:00,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:01,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:01,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:02,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:02,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:03,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:03,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:04,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:04,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:04,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:05,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:05,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:06,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:06,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:07,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:07,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:07,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:08,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:08,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:08,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:09,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:09,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:10,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:10,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:10,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:11,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:11,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:11,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:12,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:12,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:13,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:13,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:13,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:14,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:14,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:14,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:15,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:15,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:16,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:16,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:17,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:17,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:17,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:18,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:18,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:19,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:19,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:20,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:20,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:20,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:21,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:21,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:21,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:22,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:22,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:22,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:23,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:23,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:24,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:24,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:24,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:25,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:25,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:25,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:26,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:26,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:27,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:27,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:27,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:28,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:28,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:28,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:29,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:29,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:30,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:30,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:30,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:31,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:31,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:32,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:32,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:32,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:33,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:33,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:34,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:34,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:35,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:35,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:35,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:36,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:36,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:36,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:37,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:37,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:37,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:38,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:38,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:39,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:39,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:40,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:40,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:40,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:41,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:41,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:41,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:42,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:42,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:42,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:43,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:43,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:43,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:44,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:44,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:44,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:45,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:45,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:46,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:46,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:47,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:47,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:48,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:49,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:49,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:49,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:50,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:50,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:50,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:51,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:51,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:52,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:52,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:52,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:52,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:53,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:53,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:54,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:54,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:54,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:55,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:55,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:55,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:56,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:56,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:56,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:57,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:57,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:58,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:58,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:58,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:59,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:12:59,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:00,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:00,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:00,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:00,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:01,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:01,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:02,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:02,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:02,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:03,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:03,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:03,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:04,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:04,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:05,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:05,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:05,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:06,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:06,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:06,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:07,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:07,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:08,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:08,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:08,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:09,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:09,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:09,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:10,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:10,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:10,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:11,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:11,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:11,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:12,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:12,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:12,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:13,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:13,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:13,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:14,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:14,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:14,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:15,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:15,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:15,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:16,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:16,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:17,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:17,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:17,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:18,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:18,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:18,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:19,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:19,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:19,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:20,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:20,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:21,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:21,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:21,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:22,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:22,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:22,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:23,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:23,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:23,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:24,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:24,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:24,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:25,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:25,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:26,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:26,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:26,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:27,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:27,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:27,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:28,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:28,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:28,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:29,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:29,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:30,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:30,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:30,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:31,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:31,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:32,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:32,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:32,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:33,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:33,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:34,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:34,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:34,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:35,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:35,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:36,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:36,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:36,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:37,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:37,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:38,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:38,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:38,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:39,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:39,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:40,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:40,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:40,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:41,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:41,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:41,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:42,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:42,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:42,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:43,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:43,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:43,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:44,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:44,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:45,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:45,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:45,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:46,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:46,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:46,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:47,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:47,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:47,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:48,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:48,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:48,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:49,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:49,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:49,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:50,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:50,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:51,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:51,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:52,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:52,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:52,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:53,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:53,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:54,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:54,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:54,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:55,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:55,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:55,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:56,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:56,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:56,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:56,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:57,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:57,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:58,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:58,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:58,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:59,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:59,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:13:59,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:00,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:00,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:00,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:01,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:01,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:02,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:02,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:03,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:03,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:03,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:04,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:04,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:04,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:05,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:05,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:06,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:06,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:07,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:07,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:07,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:08,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:08,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:09,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:09,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:09,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:10,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:10,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:11,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:11,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:11,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:12,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:12,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:13,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:13,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:13,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:14,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:14,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:14,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:15,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:15,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:15,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:16,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:16,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:16,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:17,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:17,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:17,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:18,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:18,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:19,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:19,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:19,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:20,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:20,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:20,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:20,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:21,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:21,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:22,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:22,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:22,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:23,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:23,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:23,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:24,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:24,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:25,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:25,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:26,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:27,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:27,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:27,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:28,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:28,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:29,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:29,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:30,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:30,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:30,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:31,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:31,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:32,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:32,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:32,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:33,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:33,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:33,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:34,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:34,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:35,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:35,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:36,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:36,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:36,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:37,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:37,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:37,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:38,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:38,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:38,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:39,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:39,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:40,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:40,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:40,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:41,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:41,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:41,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:42,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:42,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:42,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:43,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:43,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:44,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:44,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:45,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:45,819][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.0525, device='cuda:0') eval_epoch_loss=tensor(0.0512, device='cuda:0') eval_epoch_acc=tensor(0.9858, device='cuda:0')
[2024-12-17 05:14:45,824][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-17 05:14:45,825][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 05:14:46,164][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_2_step_3564_loss_0.051154620945453644/model.pt
[2024-12-17 05:14:46,176][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-12-17 05:14:46,177][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 0.051154620945453644
[2024-12-17 05:14:46,178][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.9858471751213074
[2024-12-17 05:14:46,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:46,746][root][INFO] - Training Epoch: 2/2, step 3564/7134 completed (loss: 0.03968019038438797, acc: 0.9943609237670898)
[2024-12-17 05:14:46,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:47,179][root][INFO] - Training Epoch: 2/2, step 3565/7134 completed (loss: 0.06656046211719513, acc: 0.9755638837814331)
[2024-12-17 05:14:47,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:47,588][root][INFO] - Training Epoch: 2/2, step 3566/7134 completed (loss: 0.044610921293497086, acc: 0.9840637445449829)
[2024-12-17 05:14:47,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:47,991][root][INFO] - Training Epoch: 2/2, step 3567/7134 completed (loss: 0.07266156375408173, acc: 0.9818887710571289)
[2024-12-17 05:14:48,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:48,402][root][INFO] - Training Epoch: 2/2, step 3568/7134 completed (loss: 0.0844607800245285, acc: 0.9819967150688171)
[2024-12-17 05:14:48,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:48,785][root][INFO] - Training Epoch: 2/2, step 3569/7134 completed (loss: 0.03865538910031319, acc: 0.9874551892280579)
[2024-12-17 05:14:48,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:49,212][root][INFO] - Training Epoch: 2/2, step 3570/7134 completed (loss: 0.08901335299015045, acc: 0.9801653027534485)
[2024-12-17 05:14:49,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:49,630][root][INFO] - Training Epoch: 2/2, step 3571/7134 completed (loss: 0.07090911269187927, acc: 0.9840849041938782)
[2024-12-17 05:14:49,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:50,084][root][INFO] - Training Epoch: 2/2, step 3572/7134 completed (loss: 0.020950092002749443, acc: 0.9934123754501343)
[2024-12-17 05:14:50,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:50,516][root][INFO] - Training Epoch: 2/2, step 3573/7134 completed (loss: 0.04589758813381195, acc: 0.9866666793823242)
[2024-12-17 05:14:50,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:50,917][root][INFO] - Training Epoch: 2/2, step 3574/7134 completed (loss: 0.05448737367987633, acc: 0.982758641242981)
[2024-12-17 05:14:51,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:51,326][root][INFO] - Training Epoch: 2/2, step 3575/7134 completed (loss: 0.11268214136362076, acc: 0.9725557565689087)
[2024-12-17 05:14:51,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:51,761][root][INFO] - Training Epoch: 2/2, step 3576/7134 completed (loss: 0.06824856251478195, acc: 0.9779005646705627)
[2024-12-17 05:14:51,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:52,266][root][INFO] - Training Epoch: 2/2, step 3577/7134 completed (loss: 0.031196478754281998, acc: 0.9886220097541809)
[2024-12-17 05:14:52,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:52,708][root][INFO] - Training Epoch: 2/2, step 3578/7134 completed (loss: 0.03655363619327545, acc: 0.9868995547294617)
[2024-12-17 05:14:52,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:53,132][root][INFO] - Training Epoch: 2/2, step 3579/7134 completed (loss: 0.04820798709988594, acc: 0.9866666793823242)
[2024-12-17 05:14:53,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:53,550][root][INFO] - Training Epoch: 2/2, step 3580/7134 completed (loss: 0.09524724632501602, acc: 0.9732283353805542)
[2024-12-17 05:14:53,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:53,974][root][INFO] - Training Epoch: 2/2, step 3581/7134 completed (loss: 0.06574986129999161, acc: 0.9823269248008728)
[2024-12-17 05:14:54,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:54,323][root][INFO] - Training Epoch: 2/2, step 3582/7134 completed (loss: 0.0740252137184143, acc: 0.9834123253822327)
[2024-12-17 05:14:54,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:54,762][root][INFO] - Training Epoch: 2/2, step 3583/7134 completed (loss: 0.06963814049959183, acc: 0.9848024249076843)
[2024-12-17 05:14:54,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:55,123][root][INFO] - Training Epoch: 2/2, step 3584/7134 completed (loss: 0.06750732660293579, acc: 0.9841269850730896)
[2024-12-17 05:14:55,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:55,550][root][INFO] - Training Epoch: 2/2, step 3585/7134 completed (loss: 0.0732768103480339, acc: 0.9809027910232544)
[2024-12-17 05:14:55,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:55,958][root][INFO] - Training Epoch: 2/2, step 3586/7134 completed (loss: 0.07129815220832825, acc: 0.9791332483291626)
[2024-12-17 05:14:56,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:56,374][root][INFO] - Training Epoch: 2/2, step 3587/7134 completed (loss: 0.0505494587123394, acc: 0.9847715497016907)
[2024-12-17 05:14:56,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:56,828][root][INFO] - Training Epoch: 2/2, step 3588/7134 completed (loss: 0.0722428485751152, acc: 0.9837278127670288)
[2024-12-17 05:14:56,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:57,258][root][INFO] - Training Epoch: 2/2, step 3589/7134 completed (loss: 0.07028323411941528, acc: 0.9878970980644226)
[2024-12-17 05:14:57,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:57,699][root][INFO] - Training Epoch: 2/2, step 3590/7134 completed (loss: 0.020549891516566277, acc: 0.9957864880561829)
[2024-12-17 05:14:57,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:58,096][root][INFO] - Training Epoch: 2/2, step 3591/7134 completed (loss: 0.0324629470705986, acc: 0.9924924969673157)
[2024-12-17 05:14:58,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:58,519][root][INFO] - Training Epoch: 2/2, step 3592/7134 completed (loss: 0.022903235629200935, acc: 0.9917355179786682)
[2024-12-17 05:14:58,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:58,982][root][INFO] - Training Epoch: 2/2, step 3593/7134 completed (loss: 0.04397396743297577, acc: 0.9877408146858215)
[2024-12-17 05:14:59,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:59,396][root][INFO] - Training Epoch: 2/2, step 3594/7134 completed (loss: 0.025866055861115456, acc: 0.9935064911842346)
[2024-12-17 05:14:59,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:14:59,838][root][INFO] - Training Epoch: 2/2, step 3595/7134 completed (loss: 0.04600180312991142, acc: 0.9831546545028687)
[2024-12-17 05:14:59,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:00,258][root][INFO] - Training Epoch: 2/2, step 3596/7134 completed (loss: 0.0278948824852705, acc: 0.9958734512329102)
[2024-12-17 05:15:00,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:00,704][root][INFO] - Training Epoch: 2/2, step 3597/7134 completed (loss: 0.02668500691652298, acc: 0.9942445755004883)
[2024-12-17 05:15:00,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:01,190][root][INFO] - Training Epoch: 2/2, step 3598/7134 completed (loss: 0.04989040642976761, acc: 0.9839816689491272)
[2024-12-17 05:15:01,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:01,640][root][INFO] - Training Epoch: 2/2, step 3599/7134 completed (loss: 0.07171420007944107, acc: 0.9810844659805298)
[2024-12-17 05:15:01,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:02,106][root][INFO] - Training Epoch: 2/2, step 3600/7134 completed (loss: 0.04948919638991356, acc: 0.9898989796638489)
[2024-12-17 05:15:02,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:02,548][root][INFO] - Training Epoch: 2/2, step 3601/7134 completed (loss: 0.12886589765548706, acc: 0.9641379117965698)
[2024-12-17 05:15:02,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:03,002][root][INFO] - Training Epoch: 2/2, step 3602/7134 completed (loss: 0.08638574928045273, acc: 0.97782963514328)
[2024-12-17 05:15:03,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:03,406][root][INFO] - Training Epoch: 2/2, step 3603/7134 completed (loss: 0.031143054366111755, acc: 0.9906250238418579)
[2024-12-17 05:15:03,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:03,783][root][INFO] - Training Epoch: 2/2, step 3604/7134 completed (loss: 0.035763006657361984, acc: 0.9849905967712402)
[2024-12-17 05:15:03,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:04,246][root][INFO] - Training Epoch: 2/2, step 3605/7134 completed (loss: 0.04648057371377945, acc: 0.9875776171684265)
[2024-12-17 05:15:04,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:04,690][root][INFO] - Training Epoch: 2/2, step 3606/7134 completed (loss: 0.0556391105055809, acc: 0.9857904314994812)
[2024-12-17 05:15:04,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:05,129][root][INFO] - Training Epoch: 2/2, step 3607/7134 completed (loss: 0.037533096969127655, acc: 0.9865771532058716)
[2024-12-17 05:15:05,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:05,589][root][INFO] - Training Epoch: 2/2, step 3608/7134 completed (loss: 0.08850976824760437, acc: 0.9811946749687195)
[2024-12-17 05:15:05,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:06,052][root][INFO] - Training Epoch: 2/2, step 3609/7134 completed (loss: 0.05274048075079918, acc: 0.9873096346855164)
[2024-12-17 05:15:06,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:06,506][root][INFO] - Training Epoch: 2/2, step 3610/7134 completed (loss: 0.06738462299108505, acc: 0.9792208075523376)
[2024-12-17 05:15:06,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:06,957][root][INFO] - Training Epoch: 2/2, step 3611/7134 completed (loss: 0.03944312036037445, acc: 0.9905914068222046)
[2024-12-17 05:15:07,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:07,432][root][INFO] - Training Epoch: 2/2, step 3612/7134 completed (loss: 0.09290564060211182, acc: 0.9751037359237671)
[2024-12-17 05:15:07,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:07,894][root][INFO] - Training Epoch: 2/2, step 3613/7134 completed (loss: 0.04887542873620987, acc: 0.9809160232543945)
[2024-12-17 05:15:07,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:08,314][root][INFO] - Training Epoch: 2/2, step 3614/7134 completed (loss: 0.04116884991526604, acc: 0.9825970530509949)
[2024-12-17 05:15:08,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:08,765][root][INFO] - Training Epoch: 2/2, step 3615/7134 completed (loss: 0.027965974062681198, acc: 0.9954128265380859)
[2024-12-17 05:15:08,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:09,208][root][INFO] - Training Epoch: 2/2, step 3616/7134 completed (loss: 0.036825478076934814, acc: 0.9827315807342529)
[2024-12-17 05:15:09,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:09,684][root][INFO] - Training Epoch: 2/2, step 3617/7134 completed (loss: 0.03816818818449974, acc: 0.9900990128517151)
[2024-12-17 05:15:09,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:10,092][root][INFO] - Training Epoch: 2/2, step 3618/7134 completed (loss: 0.10055913776159286, acc: 0.9673202633857727)
[2024-12-17 05:15:10,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:10,551][root][INFO] - Training Epoch: 2/2, step 3619/7134 completed (loss: 0.07985293120145798, acc: 0.973809540271759)
[2024-12-17 05:15:10,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:11,019][root][INFO] - Training Epoch: 2/2, step 3620/7134 completed (loss: 0.04527260735630989, acc: 0.9859353303909302)
[2024-12-17 05:15:11,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:11,432][root][INFO] - Training Epoch: 2/2, step 3621/7134 completed (loss: 0.03328818082809448, acc: 0.9916782379150391)
[2024-12-17 05:15:11,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:11,896][root][INFO] - Training Epoch: 2/2, step 3622/7134 completed (loss: 0.036343030631542206, acc: 0.9879879951477051)
[2024-12-17 05:15:12,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:12,264][root][INFO] - Training Epoch: 2/2, step 3623/7134 completed (loss: 0.019125921651721, acc: 0.9925650358200073)
[2024-12-17 05:15:12,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:12,699][root][INFO] - Training Epoch: 2/2, step 3624/7134 completed (loss: 0.026402104645967484, acc: 0.9950000047683716)
[2024-12-17 05:15:12,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:13,092][root][INFO] - Training Epoch: 2/2, step 3625/7134 completed (loss: 0.062801793217659, acc: 0.9778671860694885)
[2024-12-17 05:15:13,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:13,489][root][INFO] - Training Epoch: 2/2, step 3626/7134 completed (loss: 0.16525384783744812, acc: 0.9573333263397217)
[2024-12-17 05:15:13,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:13,896][root][INFO] - Training Epoch: 2/2, step 3627/7134 completed (loss: 0.08152453601360321, acc: 0.9834515452384949)
[2024-12-17 05:15:14,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:14,285][root][INFO] - Training Epoch: 2/2, step 3628/7134 completed (loss: 0.14119920134544373, acc: 0.9659090638160706)
[2024-12-17 05:15:14,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:14,659][root][INFO] - Training Epoch: 2/2, step 3629/7134 completed (loss: 0.10003494471311569, acc: 0.9735772609710693)
[2024-12-17 05:15:14,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:15,033][root][INFO] - Training Epoch: 2/2, step 3630/7134 completed (loss: 0.07156892865896225, acc: 0.9741601943969727)
[2024-12-17 05:15:15,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:15,451][root][INFO] - Training Epoch: 2/2, step 3631/7134 completed (loss: 0.06883656233549118, acc: 0.9786885380744934)
[2024-12-17 05:15:15,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:15,865][root][INFO] - Training Epoch: 2/2, step 3632/7134 completed (loss: 0.036914318799972534, acc: 0.9899396300315857)
[2024-12-17 05:15:15,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:16,273][root][INFO] - Training Epoch: 2/2, step 3633/7134 completed (loss: 0.07907283306121826, acc: 0.9799138903617859)
[2024-12-17 05:15:16,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:16,672][root][INFO] - Training Epoch: 2/2, step 3634/7134 completed (loss: 0.09541939198970795, acc: 0.9858299493789673)
[2024-12-17 05:15:16,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:17,095][root][INFO] - Training Epoch: 2/2, step 3635/7134 completed (loss: 0.019677067175507545, acc: 0.9928315281867981)
[2024-12-17 05:15:17,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:17,520][root][INFO] - Training Epoch: 2/2, step 3636/7134 completed (loss: 0.03031150996685028, acc: 0.9901574850082397)
[2024-12-17 05:15:17,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:17,942][root][INFO] - Training Epoch: 2/2, step 3637/7134 completed (loss: 0.033505238592624664, acc: 0.9959758520126343)
[2024-12-17 05:15:18,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:18,333][root][INFO] - Training Epoch: 2/2, step 3638/7134 completed (loss: 0.01701144501566887, acc: 0.9976470470428467)
[2024-12-17 05:15:18,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:18,738][root][INFO] - Training Epoch: 2/2, step 3639/7134 completed (loss: 0.018381305038928986, acc: 0.9954954981803894)
[2024-12-17 05:15:18,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:19,163][root][INFO] - Training Epoch: 2/2, step 3640/7134 completed (loss: 0.037090469151735306, acc: 0.9904580116271973)
[2024-12-17 05:15:19,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:19,549][root][INFO] - Training Epoch: 2/2, step 3641/7134 completed (loss: 0.02929556369781494, acc: 0.9922178983688354)
[2024-12-17 05:15:19,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:19,974][root][INFO] - Training Epoch: 2/2, step 3642/7134 completed (loss: 0.027877023443579674, acc: 0.9907264113426208)
[2024-12-17 05:15:20,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:20,394][root][INFO] - Training Epoch: 2/2, step 3643/7134 completed (loss: 0.042714621871709824, acc: 0.9879724979400635)
[2024-12-17 05:15:20,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:20,822][root][INFO] - Training Epoch: 2/2, step 3644/7134 completed (loss: 0.06151987239718437, acc: 0.9853658676147461)
[2024-12-17 05:15:20,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:21,250][root][INFO] - Training Epoch: 2/2, step 3645/7134 completed (loss: 0.04314346984028816, acc: 0.9876760840415955)
[2024-12-17 05:15:21,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:21,657][root][INFO] - Training Epoch: 2/2, step 3646/7134 completed (loss: 0.11221519112586975, acc: 0.9791666865348816)
[2024-12-17 05:15:21,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:22,066][root][INFO] - Training Epoch: 2/2, step 3647/7134 completed (loss: 0.014307282865047455, acc: 0.9974160194396973)
[2024-12-17 05:15:22,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:22,521][root][INFO] - Training Epoch: 2/2, step 3648/7134 completed (loss: 0.06877714395523071, acc: 0.9807956218719482)
[2024-12-17 05:15:22,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:22,958][root][INFO] - Training Epoch: 2/2, step 3649/7134 completed (loss: 0.07662203162908554, acc: 0.9789915680885315)
[2024-12-17 05:15:23,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:23,407][root][INFO] - Training Epoch: 2/2, step 3650/7134 completed (loss: 0.04755416512489319, acc: 0.9816993474960327)
[2024-12-17 05:15:23,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:23,849][root][INFO] - Training Epoch: 2/2, step 3651/7134 completed (loss: 0.06972059607505798, acc: 0.9798927903175354)
[2024-12-17 05:15:23,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:24,268][root][INFO] - Training Epoch: 2/2, step 3652/7134 completed (loss: 0.06102917715907097, acc: 0.9849170446395874)
[2024-12-17 05:15:24,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:24,699][root][INFO] - Training Epoch: 2/2, step 3653/7134 completed (loss: 0.10434896498918533, acc: 0.9758672714233398)
[2024-12-17 05:15:24,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:25,129][root][INFO] - Training Epoch: 2/2, step 3654/7134 completed (loss: 0.02399669960141182, acc: 0.9913644194602966)
[2024-12-17 05:15:25,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:25,566][root][INFO] - Training Epoch: 2/2, step 3655/7134 completed (loss: 0.0536678247153759, acc: 0.9876373410224915)
[2024-12-17 05:15:25,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:25,936][root][INFO] - Training Epoch: 2/2, step 3656/7134 completed (loss: 0.09272071719169617, acc: 0.9781818389892578)
[2024-12-17 05:15:26,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:26,355][root][INFO] - Training Epoch: 2/2, step 3657/7134 completed (loss: 0.0198845025151968, acc: 0.995192289352417)
[2024-12-17 05:15:26,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:26,774][root][INFO] - Training Epoch: 2/2, step 3658/7134 completed (loss: 0.050553228706121445, acc: 0.985981285572052)
[2024-12-17 05:15:26,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:27,192][root][INFO] - Training Epoch: 2/2, step 3659/7134 completed (loss: 0.02596711739897728, acc: 0.9895366430282593)
[2024-12-17 05:15:27,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:27,517][root][INFO] - Training Epoch: 2/2, step 3660/7134 completed (loss: 0.05296694114804268, acc: 0.9868852496147156)
[2024-12-17 05:15:27,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:27,882][root][INFO] - Training Epoch: 2/2, step 3661/7134 completed (loss: 0.0424874871969223, acc: 0.9857142567634583)
[2024-12-17 05:15:27,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:28,330][root][INFO] - Training Epoch: 2/2, step 3662/7134 completed (loss: 0.07144023478031158, acc: 0.9847561120986938)
[2024-12-17 05:15:28,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:28,743][root][INFO] - Training Epoch: 2/2, step 3663/7134 completed (loss: 0.03624771535396576, acc: 0.9890109896659851)
[2024-12-17 05:15:28,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:29,161][root][INFO] - Training Epoch: 2/2, step 3664/7134 completed (loss: 0.05461371690034866, acc: 0.9908814430236816)
[2024-12-17 05:15:29,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:29,576][root][INFO] - Training Epoch: 2/2, step 3665/7134 completed (loss: 0.03347859904170036, acc: 0.9934318661689758)
[2024-12-17 05:15:29,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:29,984][root][INFO] - Training Epoch: 2/2, step 3666/7134 completed (loss: 0.043381333351135254, acc: 0.985401451587677)
[2024-12-17 05:15:30,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:30,361][root][INFO] - Training Epoch: 2/2, step 3667/7134 completed (loss: 0.15873202681541443, acc: 0.965831458568573)
[2024-12-17 05:15:30,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:30,763][root][INFO] - Training Epoch: 2/2, step 3668/7134 completed (loss: 0.04106258973479271, acc: 0.9947643876075745)
[2024-12-17 05:15:30,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:31,166][root][INFO] - Training Epoch: 2/2, step 3669/7134 completed (loss: 0.015338998287916183, acc: 0.9943289160728455)
[2024-12-17 05:15:31,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:31,587][root][INFO] - Training Epoch: 2/2, step 3670/7134 completed (loss: 0.03036133013665676, acc: 0.9958791136741638)
[2024-12-17 05:15:31,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:31,985][root][INFO] - Training Epoch: 2/2, step 3671/7134 completed (loss: 0.019875500351190567, acc: 0.9942196607589722)
[2024-12-17 05:15:32,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:32,437][root][INFO] - Training Epoch: 2/2, step 3672/7134 completed (loss: 0.01330183818936348, acc: 0.9962121248245239)
[2024-12-17 05:15:32,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:32,843][root][INFO] - Training Epoch: 2/2, step 3673/7134 completed (loss: 0.0465569943189621, acc: 0.9866220951080322)
[2024-12-17 05:15:32,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:33,261][root][INFO] - Training Epoch: 2/2, step 3674/7134 completed (loss: 0.018991077318787575, acc: 0.9968503713607788)
[2024-12-17 05:15:33,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:33,694][root][INFO] - Training Epoch: 2/2, step 3675/7134 completed (loss: 0.017583023756742477, acc: 0.9974489808082581)
[2024-12-17 05:15:33,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:34,113][root][INFO] - Training Epoch: 2/2, step 3676/7134 completed (loss: 0.021433066576719284, acc: 0.9927113652229309)
[2024-12-17 05:15:34,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:34,556][root][INFO] - Training Epoch: 2/2, step 3677/7134 completed (loss: 0.03343082219362259, acc: 0.9890410900115967)
[2024-12-17 05:15:34,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:34,989][root][INFO] - Training Epoch: 2/2, step 3678/7134 completed (loss: 0.028319591656327248, acc: 0.9878542423248291)
[2024-12-17 05:15:35,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:35,443][root][INFO] - Training Epoch: 2/2, step 3679/7134 completed (loss: 0.014385426416993141, acc: 0.9966942071914673)
[2024-12-17 05:15:35,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:35,876][root][INFO] - Training Epoch: 2/2, step 3680/7134 completed (loss: 0.03960810601711273, acc: 0.9870129823684692)
[2024-12-17 05:15:35,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:36,285][root][INFO] - Training Epoch: 2/2, step 3681/7134 completed (loss: 0.023551929742097855, acc: 0.9916201233863831)
[2024-12-17 05:15:36,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:36,718][root][INFO] - Training Epoch: 2/2, step 3682/7134 completed (loss: 0.021646665409207344, acc: 0.9934123754501343)
[2024-12-17 05:15:36,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:37,184][root][INFO] - Training Epoch: 2/2, step 3683/7134 completed (loss: 0.015329486690461636, acc: 0.995275616645813)
[2024-12-17 05:15:37,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:37,625][root][INFO] - Training Epoch: 2/2, step 3684/7134 completed (loss: 0.02287955768406391, acc: 0.9913420081138611)
[2024-12-17 05:15:37,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:38,049][root][INFO] - Training Epoch: 2/2, step 3685/7134 completed (loss: 0.013409299775958061, acc: 0.9942196607589722)
[2024-12-17 05:15:38,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:38,482][root][INFO] - Training Epoch: 2/2, step 3686/7134 completed (loss: 0.01704275980591774, acc: 0.9925037622451782)
[2024-12-17 05:15:38,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:38,920][root][INFO] - Training Epoch: 2/2, step 3687/7134 completed (loss: 0.008552535437047482, acc: 0.9938461780548096)
[2024-12-17 05:15:39,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:39,339][root][INFO] - Training Epoch: 2/2, step 3688/7134 completed (loss: 0.00920969806611538, acc: 0.9959431886672974)
[2024-12-17 05:15:39,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:39,758][root][INFO] - Training Epoch: 2/2, step 3689/7134 completed (loss: 0.019783534109592438, acc: 0.991830050945282)
[2024-12-17 05:15:39,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:40,205][root][INFO] - Training Epoch: 2/2, step 3690/7134 completed (loss: 0.013142869807779789, acc: 0.9971387982368469)
[2024-12-17 05:15:40,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:40,606][root][INFO] - Training Epoch: 2/2, step 3691/7134 completed (loss: 0.030679218471050262, acc: 0.9900744557380676)
[2024-12-17 05:15:40,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:41,031][root][INFO] - Training Epoch: 2/2, step 3692/7134 completed (loss: 0.0373593308031559, acc: 0.9923896789550781)
[2024-12-17 05:15:41,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:41,452][root][INFO] - Training Epoch: 2/2, step 3693/7134 completed (loss: 0.015477774664759636, acc: 0.9968454241752625)
[2024-12-17 05:15:41,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:41,876][root][INFO] - Training Epoch: 2/2, step 3694/7134 completed (loss: 0.020561207085847855, acc: 0.9957325458526611)
[2024-12-17 05:15:41,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:42,310][root][INFO] - Training Epoch: 2/2, step 3695/7134 completed (loss: 0.02909548580646515, acc: 0.9915013909339905)
[2024-12-17 05:15:42,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:42,773][root][INFO] - Training Epoch: 2/2, step 3696/7134 completed (loss: 0.016582375392317772, acc: 0.9935732483863831)
[2024-12-17 05:15:42,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:43,171][root][INFO] - Training Epoch: 2/2, step 3697/7134 completed (loss: 0.011175992898643017, acc: 0.9941691160202026)
[2024-12-17 05:15:43,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:43,567][root][INFO] - Training Epoch: 2/2, step 3698/7134 completed (loss: 0.022793900221586227, acc: 0.9919742941856384)
[2024-12-17 05:15:43,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:43,967][root][INFO] - Training Epoch: 2/2, step 3699/7134 completed (loss: 0.00812592078000307, acc: 0.9983108043670654)
[2024-12-17 05:15:44,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:44,392][root][INFO] - Training Epoch: 2/2, step 3700/7134 completed (loss: 0.01933910883963108, acc: 0.9956268072128296)
[2024-12-17 05:15:44,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:44,842][root][INFO] - Training Epoch: 2/2, step 3701/7134 completed (loss: 0.034512754529714584, acc: 0.9917218685150146)
[2024-12-17 05:15:44,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:45,252][root][INFO] - Training Epoch: 2/2, step 3702/7134 completed (loss: 0.037105903029441833, acc: 0.9903581142425537)
[2024-12-17 05:15:45,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:45,712][root][INFO] - Training Epoch: 2/2, step 3703/7134 completed (loss: 0.02953074872493744, acc: 0.9936143159866333)
[2024-12-17 05:15:45,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:46,148][root][INFO] - Training Epoch: 2/2, step 3704/7134 completed (loss: 0.004237249493598938, acc: 1.0)
[2024-12-17 05:15:46,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:46,562][root][INFO] - Training Epoch: 2/2, step 3705/7134 completed (loss: 0.05200015380978584, acc: 0.9840764403343201)
[2024-12-17 05:15:46,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:46,980][root][INFO] - Training Epoch: 2/2, step 3706/7134 completed (loss: 0.0815388485789299, acc: 0.9803197979927063)
[2024-12-17 05:15:47,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:47,415][root][INFO] - Training Epoch: 2/2, step 3707/7134 completed (loss: 0.016521764919161797, acc: 0.9957924485206604)
[2024-12-17 05:15:47,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:47,863][root][INFO] - Training Epoch: 2/2, step 3708/7134 completed (loss: 0.04975743591785431, acc: 0.9857142567634583)
[2024-12-17 05:15:47,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:48,348][root][INFO] - Training Epoch: 2/2, step 3709/7134 completed (loss: 0.025776255875825882, acc: 0.9908722043037415)
[2024-12-17 05:15:48,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:48,829][root][INFO] - Training Epoch: 2/2, step 3710/7134 completed (loss: 0.03561568632721901, acc: 0.9897540807723999)
[2024-12-17 05:15:48,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:49,246][root][INFO] - Training Epoch: 2/2, step 3711/7134 completed (loss: 0.03470410034060478, acc: 0.9925558567047119)
[2024-12-17 05:15:49,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:49,714][root][INFO] - Training Epoch: 2/2, step 3712/7134 completed (loss: 0.019868969917297363, acc: 0.9952210187911987)
[2024-12-17 05:15:49,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:50,144][root][INFO] - Training Epoch: 2/2, step 3713/7134 completed (loss: 0.03314388170838356, acc: 0.9901477694511414)
[2024-12-17 05:15:50,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:50,581][root][INFO] - Training Epoch: 2/2, step 3714/7134 completed (loss: 0.026479944586753845, acc: 0.9944751262664795)
[2024-12-17 05:15:50,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:51,032][root][INFO] - Training Epoch: 2/2, step 3715/7134 completed (loss: 0.03534476459026337, acc: 0.9927448630332947)
[2024-12-17 05:15:51,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:51,506][root][INFO] - Training Epoch: 2/2, step 3716/7134 completed (loss: 0.036507364362478256, acc: 0.9889025688171387)
[2024-12-17 05:15:51,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:51,956][root][INFO] - Training Epoch: 2/2, step 3717/7134 completed (loss: 0.022603292018175125, acc: 0.9972677826881409)
[2024-12-17 05:15:52,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:52,417][root][INFO] - Training Epoch: 2/2, step 3718/7134 completed (loss: 0.04594561457633972, acc: 0.9894490242004395)
[2024-12-17 05:15:52,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:52,868][root][INFO] - Training Epoch: 2/2, step 3719/7134 completed (loss: 0.03854767233133316, acc: 0.9897058606147766)
[2024-12-17 05:15:52,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:53,265][root][INFO] - Training Epoch: 2/2, step 3720/7134 completed (loss: 0.018920304253697395, acc: 0.992668628692627)
[2024-12-17 05:15:53,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:53,720][root][INFO] - Training Epoch: 2/2, step 3721/7134 completed (loss: 0.03464561328291893, acc: 0.9880159497261047)
[2024-12-17 05:15:53,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:54,156][root][INFO] - Training Epoch: 2/2, step 3722/7134 completed (loss: 0.022742776200175285, acc: 0.9913793206214905)
[2024-12-17 05:15:54,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:54,582][root][INFO] - Training Epoch: 2/2, step 3723/7134 completed (loss: 0.04677986353635788, acc: 0.9884892106056213)
[2024-12-17 05:15:54,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:55,018][root][INFO] - Training Epoch: 2/2, step 3724/7134 completed (loss: 0.03544839099049568, acc: 0.9870689511299133)
[2024-12-17 05:15:55,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:55,475][root][INFO] - Training Epoch: 2/2, step 3725/7134 completed (loss: 0.09269028902053833, acc: 0.9793510437011719)
[2024-12-17 05:15:55,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:55,944][root][INFO] - Training Epoch: 2/2, step 3726/7134 completed (loss: 0.020531756803393364, acc: 0.9936237931251526)
[2024-12-17 05:15:56,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:56,370][root][INFO] - Training Epoch: 2/2, step 3727/7134 completed (loss: 0.024662544950842857, acc: 0.9959946870803833)
[2024-12-17 05:15:56,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:56,811][root][INFO] - Training Epoch: 2/2, step 3728/7134 completed (loss: 0.01152855809777975, acc: 0.994363009929657)
[2024-12-17 05:15:56,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:57,258][root][INFO] - Training Epoch: 2/2, step 3729/7134 completed (loss: 0.03035128489136696, acc: 0.987500011920929)
[2024-12-17 05:15:57,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:57,704][root][INFO] - Training Epoch: 2/2, step 3730/7134 completed (loss: 0.022174786776304245, acc: 0.9918588995933533)
[2024-12-17 05:15:57,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:58,146][root][INFO] - Training Epoch: 2/2, step 3731/7134 completed (loss: 0.021008355543017387, acc: 0.993773341178894)
[2024-12-17 05:15:58,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:58,591][root][INFO] - Training Epoch: 2/2, step 3732/7134 completed (loss: 0.01786644756793976, acc: 0.9931895732879639)
[2024-12-17 05:15:58,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:59,016][root][INFO] - Training Epoch: 2/2, step 3733/7134 completed (loss: 0.04620295390486717, acc: 0.9845722317695618)
[2024-12-17 05:15:59,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:59,435][root][INFO] - Training Epoch: 2/2, step 3734/7134 completed (loss: 0.0459599494934082, acc: 0.9870550036430359)
[2024-12-17 05:15:59,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:15:59,858][root][INFO] - Training Epoch: 2/2, step 3735/7134 completed (loss: 0.03366852551698685, acc: 0.9954819083213806)
[2024-12-17 05:15:59,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:00,297][root][INFO] - Training Epoch: 2/2, step 3736/7134 completed (loss: 0.08346369862556458, acc: 0.9773913025856018)
[2024-12-17 05:16:00,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:00,722][root][INFO] - Training Epoch: 2/2, step 3737/7134 completed (loss: 0.04917727783322334, acc: 0.9879336357116699)
[2024-12-17 05:16:00,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:01,164][root][INFO] - Training Epoch: 2/2, step 3738/7134 completed (loss: 0.029033737257122993, acc: 0.9950494766235352)
[2024-12-17 05:16:01,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:01,537][root][INFO] - Training Epoch: 2/2, step 3739/7134 completed (loss: 0.0541527234017849, acc: 0.9887640476226807)
[2024-12-17 05:16:01,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:01,935][root][INFO] - Training Epoch: 2/2, step 3740/7134 completed (loss: 0.03932886943221092, acc: 0.9918830990791321)
[2024-12-17 05:16:02,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:02,349][root][INFO] - Training Epoch: 2/2, step 3741/7134 completed (loss: 0.05537845566868782, acc: 0.9885877370834351)
[2024-12-17 05:16:02,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:02,712][root][INFO] - Training Epoch: 2/2, step 3742/7134 completed (loss: 0.06502484530210495, acc: 0.9794871807098389)
[2024-12-17 05:16:02,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:03,148][root][INFO] - Training Epoch: 2/2, step 3743/7134 completed (loss: 0.04780928045511246, acc: 0.9882006049156189)
[2024-12-17 05:16:03,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:03,583][root][INFO] - Training Epoch: 2/2, step 3744/7134 completed (loss: 0.07799414545297623, acc: 0.9789196252822876)
[2024-12-17 05:16:03,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:03,995][root][INFO] - Training Epoch: 2/2, step 3745/7134 completed (loss: 0.11473871022462845, acc: 0.9767981171607971)
[2024-12-17 05:16:04,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:04,447][root][INFO] - Training Epoch: 2/2, step 3746/7134 completed (loss: 0.05639931559562683, acc: 0.9869109988212585)
[2024-12-17 05:16:04,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:04,888][root][INFO] - Training Epoch: 2/2, step 3747/7134 completed (loss: 0.037271615117788315, acc: 0.9883381724357605)
[2024-12-17 05:16:05,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:05,271][root][INFO] - Training Epoch: 2/2, step 3748/7134 completed (loss: 0.06521500647068024, acc: 0.98591548204422)
[2024-12-17 05:16:05,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:05,680][root][INFO] - Training Epoch: 2/2, step 3749/7134 completed (loss: 0.08441296964883804, acc: 0.9775112271308899)
[2024-12-17 05:16:05,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:06,107][root][INFO] - Training Epoch: 2/2, step 3750/7134 completed (loss: 0.02441018633544445, acc: 0.991631805896759)
[2024-12-17 05:16:06,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:06,534][root][INFO] - Training Epoch: 2/2, step 3751/7134 completed (loss: 0.06495432555675507, acc: 0.9772403836250305)
[2024-12-17 05:16:06,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:06,966][root][INFO] - Training Epoch: 2/2, step 3752/7134 completed (loss: 0.053464941680431366, acc: 0.983582079410553)
[2024-12-17 05:16:07,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:07,388][root][INFO] - Training Epoch: 2/2, step 3753/7134 completed (loss: 0.0666658952832222, acc: 0.980567991733551)
[2024-12-17 05:16:07,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:07,802][root][INFO] - Training Epoch: 2/2, step 3754/7134 completed (loss: 0.021346380934119225, acc: 0.9924127459526062)
[2024-12-17 05:16:07,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:08,213][root][INFO] - Training Epoch: 2/2, step 3755/7134 completed (loss: 0.047797225415706635, acc: 0.9907235503196716)
[2024-12-17 05:16:08,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:08,651][root][INFO] - Training Epoch: 2/2, step 3756/7134 completed (loss: 0.05544815585017204, acc: 0.9861496090888977)
[2024-12-17 05:16:08,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:09,084][root][INFO] - Training Epoch: 2/2, step 3757/7134 completed (loss: 0.08566334843635559, acc: 0.9737274050712585)
[2024-12-17 05:16:09,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:09,475][root][INFO] - Training Epoch: 2/2, step 3758/7134 completed (loss: 0.03824947401881218, acc: 0.9927927851676941)
[2024-12-17 05:16:09,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:09,886][root][INFO] - Training Epoch: 2/2, step 3759/7134 completed (loss: 0.05484168604016304, acc: 0.9780405163764954)
[2024-12-17 05:16:10,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:10,337][root][INFO] - Training Epoch: 2/2, step 3760/7134 completed (loss: 0.06035434082150459, acc: 0.9858757257461548)
[2024-12-17 05:16:10,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:10,761][root][INFO] - Training Epoch: 2/2, step 3761/7134 completed (loss: 0.02840098738670349, acc: 0.9922720193862915)
[2024-12-17 05:16:10,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:11,198][root][INFO] - Training Epoch: 2/2, step 3762/7134 completed (loss: 0.03290209546685219, acc: 0.9903714060783386)
[2024-12-17 05:16:11,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:11,620][root][INFO] - Training Epoch: 2/2, step 3763/7134 completed (loss: 0.017224406823515892, acc: 0.9953703880310059)
[2024-12-17 05:16:11,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:12,055][root][INFO] - Training Epoch: 2/2, step 3764/7134 completed (loss: 0.044931426644325256, acc: 0.9863201379776001)
[2024-12-17 05:16:12,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:12,536][root][INFO] - Training Epoch: 2/2, step 3765/7134 completed (loss: 0.02310805395245552, acc: 0.9915966391563416)
[2024-12-17 05:16:12,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:12,949][root][INFO] - Training Epoch: 2/2, step 3766/7134 completed (loss: 0.05954977124929428, acc: 0.9857549667358398)
[2024-12-17 05:16:13,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:13,392][root][INFO] - Training Epoch: 2/2, step 3767/7134 completed (loss: 0.019896144047379494, acc: 0.9912717938423157)
[2024-12-17 05:16:13,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:13,809][root][INFO] - Training Epoch: 2/2, step 3768/7134 completed (loss: 0.01848101057112217, acc: 0.9937759041786194)
[2024-12-17 05:16:13,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:14,260][root][INFO] - Training Epoch: 2/2, step 3769/7134 completed (loss: 0.03294776752591133, acc: 0.991183876991272)
[2024-12-17 05:16:14,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:14,691][root][INFO] - Training Epoch: 2/2, step 3770/7134 completed (loss: 0.03372187912464142, acc: 0.9929378628730774)
[2024-12-17 05:16:14,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:15,139][root][INFO] - Training Epoch: 2/2, step 3771/7134 completed (loss: 0.027564767748117447, acc: 0.9922077655792236)
[2024-12-17 05:16:15,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:15,584][root][INFO] - Training Epoch: 2/2, step 3772/7134 completed (loss: 0.04528488963842392, acc: 0.9895366430282593)
[2024-12-17 05:16:15,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:16,042][root][INFO] - Training Epoch: 2/2, step 3773/7134 completed (loss: 0.031071245670318604, acc: 0.9899553656578064)
[2024-12-17 05:16:16,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:16,510][root][INFO] - Training Epoch: 2/2, step 3774/7134 completed (loss: 0.024507006630301476, acc: 0.9930394291877747)
[2024-12-17 05:16:16,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:16,950][root][INFO] - Training Epoch: 2/2, step 3775/7134 completed (loss: 0.02739444561302662, acc: 0.9914039969444275)
[2024-12-17 05:16:17,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:17,392][root][INFO] - Training Epoch: 2/2, step 3776/7134 completed (loss: 0.04721525311470032, acc: 0.9851852059364319)
[2024-12-17 05:16:17,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:17,826][root][INFO] - Training Epoch: 2/2, step 3777/7134 completed (loss: 0.023816067725419998, acc: 0.9937343597412109)
[2024-12-17 05:16:17,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:18,251][root][INFO] - Training Epoch: 2/2, step 3778/7134 completed (loss: 0.05440912023186684, acc: 0.9843527674674988)
[2024-12-17 05:16:18,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:18,653][root][INFO] - Training Epoch: 2/2, step 3779/7134 completed (loss: 0.03777715563774109, acc: 0.9843304753303528)
[2024-12-17 05:16:18,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:19,079][root][INFO] - Training Epoch: 2/2, step 3780/7134 completed (loss: 0.02107837237417698, acc: 0.9927954077720642)
[2024-12-17 05:16:19,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:19,497][root][INFO] - Training Epoch: 2/2, step 3781/7134 completed (loss: 0.05849623307585716, acc: 0.9862825870513916)
[2024-12-17 05:16:19,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:19,891][root][INFO] - Training Epoch: 2/2, step 3782/7134 completed (loss: 0.04468333721160889, acc: 0.9814814925193787)
[2024-12-17 05:16:19,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:20,320][root][INFO] - Training Epoch: 2/2, step 3783/7134 completed (loss: 0.04150773212313652, acc: 0.9883871078491211)
[2024-12-17 05:16:20,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:20,750][root][INFO] - Training Epoch: 2/2, step 3784/7134 completed (loss: 0.057405438274145126, acc: 0.9876352548599243)
[2024-12-17 05:16:20,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:21,169][root][INFO] - Training Epoch: 2/2, step 3785/7134 completed (loss: 0.014061609283089638, acc: 0.9953197836875916)
[2024-12-17 05:16:21,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:21,583][root][INFO] - Training Epoch: 2/2, step 3786/7134 completed (loss: 0.047242987900972366, acc: 0.9844760894775391)
[2024-12-17 05:16:21,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:21,974][root][INFO] - Training Epoch: 2/2, step 3787/7134 completed (loss: 0.03170808032155037, acc: 0.9888357520103455)
[2024-12-17 05:16:22,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:22,435][root][INFO] - Training Epoch: 2/2, step 3788/7134 completed (loss: 0.032857753336429596, acc: 0.9932523369789124)
[2024-12-17 05:16:22,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:22,898][root][INFO] - Training Epoch: 2/2, step 3789/7134 completed (loss: 0.05267763137817383, acc: 0.9831223487854004)
[2024-12-17 05:16:23,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:23,371][root][INFO] - Training Epoch: 2/2, step 3790/7134 completed (loss: 0.1011412963271141, acc: 0.9784537553787231)
[2024-12-17 05:16:23,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:23,809][root][INFO] - Training Epoch: 2/2, step 3791/7134 completed (loss: 0.024218479171395302, acc: 0.9935483932495117)
[2024-12-17 05:16:23,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:24,250][root][INFO] - Training Epoch: 2/2, step 3792/7134 completed (loss: 0.019567038863897324, acc: 0.9934318661689758)
[2024-12-17 05:16:24,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:24,677][root][INFO] - Training Epoch: 2/2, step 3793/7134 completed (loss: 0.033911943435668945, acc: 0.9918919205665588)
[2024-12-17 05:16:24,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:25,105][root][INFO] - Training Epoch: 2/2, step 3794/7134 completed (loss: 0.036208704113960266, acc: 0.990920901298523)
[2024-12-17 05:16:25,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:25,564][root][INFO] - Training Epoch: 2/2, step 3795/7134 completed (loss: 0.03505320101976395, acc: 0.9891566038131714)
[2024-12-17 05:16:25,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:26,008][root][INFO] - Training Epoch: 2/2, step 3796/7134 completed (loss: 0.02634483389556408, acc: 0.9924623370170593)
[2024-12-17 05:16:26,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:26,452][root][INFO] - Training Epoch: 2/2, step 3797/7134 completed (loss: 0.015917351469397545, acc: 0.9947848916053772)
[2024-12-17 05:16:26,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:26,891][root][INFO] - Training Epoch: 2/2, step 3798/7134 completed (loss: 0.04779290035367012, acc: 0.9870689511299133)
[2024-12-17 05:16:27,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:27,324][root][INFO] - Training Epoch: 2/2, step 3799/7134 completed (loss: 0.041828542947769165, acc: 0.9858430027961731)
[2024-12-17 05:16:27,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:27,746][root][INFO] - Training Epoch: 2/2, step 3800/7134 completed (loss: 0.045282039791345596, acc: 0.9877675771713257)
[2024-12-17 05:16:27,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:28,201][root][INFO] - Training Epoch: 2/2, step 3801/7134 completed (loss: 0.027145804837346077, acc: 0.9876543283462524)
[2024-12-17 05:16:28,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:28,645][root][INFO] - Training Epoch: 2/2, step 3802/7134 completed (loss: 0.03883383795619011, acc: 0.991725742816925)
[2024-12-17 05:16:28,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:29,074][root][INFO] - Training Epoch: 2/2, step 3803/7134 completed (loss: 0.038905587047338486, acc: 0.9887955188751221)
[2024-12-17 05:16:29,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:29,529][root][INFO] - Training Epoch: 2/2, step 3804/7134 completed (loss: 0.03029499016702175, acc: 0.9875583052635193)
[2024-12-17 05:16:29,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:29,987][root][INFO] - Training Epoch: 2/2, step 3805/7134 completed (loss: 0.018566779792308807, acc: 0.9934554696083069)
[2024-12-17 05:16:30,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:30,422][root][INFO] - Training Epoch: 2/2, step 3806/7134 completed (loss: 0.04323633760213852, acc: 0.9861932992935181)
[2024-12-17 05:16:30,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:30,882][root][INFO] - Training Epoch: 2/2, step 3807/7134 completed (loss: 0.015396242029964924, acc: 0.9985380172729492)
[2024-12-17 05:16:31,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:31,357][root][INFO] - Training Epoch: 2/2, step 3808/7134 completed (loss: 0.043124452233314514, acc: 0.9873417615890503)
[2024-12-17 05:16:31,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:31,796][root][INFO] - Training Epoch: 2/2, step 3809/7134 completed (loss: 0.06364665180444717, acc: 0.9847715497016907)
[2024-12-17 05:16:31,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:32,219][root][INFO] - Training Epoch: 2/2, step 3810/7134 completed (loss: 0.030547337606549263, acc: 0.9910714030265808)
[2024-12-17 05:16:32,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:32,663][root][INFO] - Training Epoch: 2/2, step 3811/7134 completed (loss: 0.05212060734629631, acc: 0.9862068891525269)
[2024-12-17 05:16:32,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:33,103][root][INFO] - Training Epoch: 2/2, step 3812/7134 completed (loss: 0.0666101947426796, acc: 0.9777015447616577)
[2024-12-17 05:16:33,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:33,555][root][INFO] - Training Epoch: 2/2, step 3813/7134 completed (loss: 0.05658918246626854, acc: 0.9788918495178223)
[2024-12-17 05:16:33,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:34,007][root][INFO] - Training Epoch: 2/2, step 3814/7134 completed (loss: 0.01978326216340065, acc: 0.9919571280479431)
[2024-12-17 05:16:34,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:34,442][root][INFO] - Training Epoch: 2/2, step 3815/7134 completed (loss: 0.036348115652799606, acc: 0.9896296262741089)
[2024-12-17 05:16:34,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:34,954][root][INFO] - Training Epoch: 2/2, step 3816/7134 completed (loss: 0.022663062438368797, acc: 0.9936908483505249)
[2024-12-17 05:16:35,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:35,361][root][INFO] - Training Epoch: 2/2, step 3817/7134 completed (loss: 0.04570571705698967, acc: 0.9856114983558655)
[2024-12-17 05:16:35,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:35,723][root][INFO] - Training Epoch: 2/2, step 3818/7134 completed (loss: 0.05383223295211792, acc: 0.9898989796638489)
[2024-12-17 05:16:35,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:36,104][root][INFO] - Training Epoch: 2/2, step 3819/7134 completed (loss: 0.06475849449634552, acc: 0.9799196720123291)
[2024-12-17 05:16:36,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:36,514][root][INFO] - Training Epoch: 2/2, step 3820/7134 completed (loss: 0.04308153688907623, acc: 0.9881235361099243)
[2024-12-17 05:16:36,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:36,920][root][INFO] - Training Epoch: 2/2, step 3821/7134 completed (loss: 0.026106908917427063, acc: 0.989847719669342)
[2024-12-17 05:16:37,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:37,337][root][INFO] - Training Epoch: 2/2, step 3822/7134 completed (loss: 0.04362167418003082, acc: 0.9882121682167053)
[2024-12-17 05:16:37,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:37,777][root][INFO] - Training Epoch: 2/2, step 3823/7134 completed (loss: 0.0181038286536932, acc: 0.9917012453079224)
[2024-12-17 05:16:37,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:38,177][root][INFO] - Training Epoch: 2/2, step 3824/7134 completed (loss: 0.06430379301309586, acc: 0.9814502596855164)
[2024-12-17 05:16:38,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:38,613][root][INFO] - Training Epoch: 2/2, step 3825/7134 completed (loss: 0.025341719388961792, acc: 0.9900199770927429)
[2024-12-17 05:16:38,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:39,061][root][INFO] - Training Epoch: 2/2, step 3826/7134 completed (loss: 0.03493819758296013, acc: 0.9897058606147766)
[2024-12-17 05:16:39,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:39,508][root][INFO] - Training Epoch: 2/2, step 3827/7134 completed (loss: 0.025250811129808426, acc: 0.9915966391563416)
[2024-12-17 05:16:39,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:39,941][root][INFO] - Training Epoch: 2/2, step 3828/7134 completed (loss: 0.03929510340094566, acc: 0.9893898963928223)
[2024-12-17 05:16:40,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:40,403][root][INFO] - Training Epoch: 2/2, step 3829/7134 completed (loss: 0.02645612321794033, acc: 0.993966817855835)
[2024-12-17 05:16:40,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:40,834][root][INFO] - Training Epoch: 2/2, step 3830/7134 completed (loss: 0.054223038256168365, acc: 0.9865996837615967)
[2024-12-17 05:16:40,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:41,274][root][INFO] - Training Epoch: 2/2, step 3831/7134 completed (loss: 0.037042468786239624, acc: 0.9879879951477051)
[2024-12-17 05:16:41,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:41,653][root][INFO] - Training Epoch: 2/2, step 3832/7134 completed (loss: 0.04965923726558685, acc: 0.990176796913147)
[2024-12-17 05:16:41,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:42,090][root][INFO] - Training Epoch: 2/2, step 3833/7134 completed (loss: 0.010612214915454388, acc: 0.9950494766235352)
[2024-12-17 05:16:42,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:42,517][root][INFO] - Training Epoch: 2/2, step 3834/7134 completed (loss: 0.005865498445928097, acc: 0.998701274394989)
[2024-12-17 05:16:42,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:42,953][root][INFO] - Training Epoch: 2/2, step 3835/7134 completed (loss: 0.015453293919563293, acc: 0.9939320683479309)
[2024-12-17 05:16:43,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:43,370][root][INFO] - Training Epoch: 2/2, step 3836/7134 completed (loss: 0.03792194277048111, acc: 0.991304337978363)
[2024-12-17 05:16:43,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:43,800][root][INFO] - Training Epoch: 2/2, step 3837/7134 completed (loss: 0.026429200544953346, acc: 0.9956896305084229)
[2024-12-17 05:16:43,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:44,234][root][INFO] - Training Epoch: 2/2, step 3838/7134 completed (loss: 0.010191519744694233, acc: 0.9960159659385681)
[2024-12-17 05:16:44,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:44,693][root][INFO] - Training Epoch: 2/2, step 3839/7134 completed (loss: 0.03131317347288132, acc: 0.9930939078330994)
[2024-12-17 05:16:44,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:45,096][root][INFO] - Training Epoch: 2/2, step 3840/7134 completed (loss: 0.020176351070404053, acc: 0.9946452379226685)
[2024-12-17 05:16:45,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:45,559][root][INFO] - Training Epoch: 2/2, step 3841/7134 completed (loss: 0.05874055624008179, acc: 0.9866814613342285)
[2024-12-17 05:16:45,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:45,947][root][INFO] - Training Epoch: 2/2, step 3842/7134 completed (loss: 0.0056985304690897465, acc: 1.0)
[2024-12-17 05:16:46,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:46,435][root][INFO] - Training Epoch: 2/2, step 3843/7134 completed (loss: 0.04562065377831459, acc: 0.9895724654197693)
[2024-12-17 05:16:46,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:46,886][root][INFO] - Training Epoch: 2/2, step 3844/7134 completed (loss: 0.03439117223024368, acc: 0.9911054372787476)
[2024-12-17 05:16:47,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:47,305][root][INFO] - Training Epoch: 2/2, step 3845/7134 completed (loss: 0.03924579173326492, acc: 0.9898989796638489)
[2024-12-17 05:16:47,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:47,730][root][INFO] - Training Epoch: 2/2, step 3846/7134 completed (loss: 0.020331837236881256, acc: 0.9932088255882263)
[2024-12-17 05:16:47,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:48,168][root][INFO] - Training Epoch: 2/2, step 3847/7134 completed (loss: 0.023329460993409157, acc: 0.9936000108718872)
[2024-12-17 05:16:48,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:48,630][root][INFO] - Training Epoch: 2/2, step 3848/7134 completed (loss: 0.02749142237007618, acc: 0.9961832165718079)
[2024-12-17 05:16:48,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:49,076][root][INFO] - Training Epoch: 2/2, step 3849/7134 completed (loss: 0.03729994595050812, acc: 0.987522304058075)
[2024-12-17 05:16:49,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:49,510][root][INFO] - Training Epoch: 2/2, step 3850/7134 completed (loss: 0.053502339869737625, acc: 0.9889975786209106)
[2024-12-17 05:16:49,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:49,969][root][INFO] - Training Epoch: 2/2, step 3851/7134 completed (loss: 0.033664070069789886, acc: 0.9888424277305603)
[2024-12-17 05:16:50,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:50,396][root][INFO] - Training Epoch: 2/2, step 3852/7134 completed (loss: 0.02617727220058441, acc: 0.9919614195823669)
[2024-12-17 05:16:50,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:50,821][root][INFO] - Training Epoch: 2/2, step 3853/7134 completed (loss: 0.0507514514029026, acc: 0.9817159175872803)
[2024-12-17 05:16:50,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:51,247][root][INFO] - Training Epoch: 2/2, step 3854/7134 completed (loss: 0.018846876919269562, acc: 0.9943820238113403)
[2024-12-17 05:16:51,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:51,691][root][INFO] - Training Epoch: 2/2, step 3855/7134 completed (loss: 0.0461571142077446, acc: 0.9862843155860901)
[2024-12-17 05:16:51,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:52,111][root][INFO] - Training Epoch: 2/2, step 3856/7134 completed (loss: 0.046583253890275955, acc: 0.9874476790428162)
[2024-12-17 05:16:52,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:52,509][root][INFO] - Training Epoch: 2/2, step 3857/7134 completed (loss: 0.01853865385055542, acc: 0.9935691356658936)
[2024-12-17 05:16:52,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:52,968][root][INFO] - Training Epoch: 2/2, step 3858/7134 completed (loss: 0.05281553044915199, acc: 0.9844192862510681)
[2024-12-17 05:16:53,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:53,414][root][INFO] - Training Epoch: 2/2, step 3859/7134 completed (loss: 0.04369175061583519, acc: 0.9885495901107788)
[2024-12-17 05:16:53,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:53,873][root][INFO] - Training Epoch: 2/2, step 3860/7134 completed (loss: 0.034574955701828, acc: 0.9921787977218628)
[2024-12-17 05:16:53,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:54,318][root][INFO] - Training Epoch: 2/2, step 3861/7134 completed (loss: 0.03597003221511841, acc: 0.9877551198005676)
[2024-12-17 05:16:54,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:54,730][root][INFO] - Training Epoch: 2/2, step 3862/7134 completed (loss: 0.06209777668118477, acc: 0.9835796356201172)
[2024-12-17 05:16:54,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:55,204][root][INFO] - Training Epoch: 2/2, step 3863/7134 completed (loss: 0.02150888741016388, acc: 0.9950617551803589)
[2024-12-17 05:16:55,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:55,644][root][INFO] - Training Epoch: 2/2, step 3864/7134 completed (loss: 0.03183693438768387, acc: 0.9947780966758728)
[2024-12-17 05:16:55,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:56,077][root][INFO] - Training Epoch: 2/2, step 3865/7134 completed (loss: 0.03206092119216919, acc: 0.9880478382110596)
[2024-12-17 05:16:56,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:56,495][root][INFO] - Training Epoch: 2/2, step 3866/7134 completed (loss: 0.04359270632266998, acc: 0.9865689873695374)
[2024-12-17 05:16:56,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:56,950][root][INFO] - Training Epoch: 2/2, step 3867/7134 completed (loss: 0.03211984783411026, acc: 0.9886363744735718)
[2024-12-17 05:16:57,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:57,359][root][INFO] - Training Epoch: 2/2, step 3868/7134 completed (loss: 0.032564662396907806, acc: 0.9949238300323486)
[2024-12-17 05:16:57,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:57,775][root][INFO] - Training Epoch: 2/2, step 3869/7134 completed (loss: 0.024219533428549767, acc: 0.9924356937408447)
[2024-12-17 05:16:57,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:58,194][root][INFO] - Training Epoch: 2/2, step 3870/7134 completed (loss: 0.05632453411817551, acc: 0.9861111044883728)
[2024-12-17 05:16:58,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:58,608][root][INFO] - Training Epoch: 2/2, step 3871/7134 completed (loss: 0.04525359347462654, acc: 0.9837905168533325)
[2024-12-17 05:16:58,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:59,077][root][INFO] - Training Epoch: 2/2, step 3872/7134 completed (loss: 0.04382895305752754, acc: 0.9892933368682861)
[2024-12-17 05:16:59,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:59,525][root][INFO] - Training Epoch: 2/2, step 3873/7134 completed (loss: 0.030628765001893044, acc: 0.9884910583496094)
[2024-12-17 05:16:59,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:16:59,953][root][INFO] - Training Epoch: 2/2, step 3874/7134 completed (loss: 0.0608048290014267, acc: 0.9861687421798706)
[2024-12-17 05:17:00,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:00,423][root][INFO] - Training Epoch: 2/2, step 3875/7134 completed (loss: 0.058851245790719986, acc: 0.9853723645210266)
[2024-12-17 05:17:00,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:00,843][root][INFO] - Training Epoch: 2/2, step 3876/7134 completed (loss: 0.03432478755712509, acc: 0.9906191229820251)
[2024-12-17 05:17:00,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:01,261][root][INFO] - Training Epoch: 2/2, step 3877/7134 completed (loss: 0.05058662220835686, acc: 0.9895561337471008)
[2024-12-17 05:17:01,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:01,676][root][INFO] - Training Epoch: 2/2, step 3878/7134 completed (loss: 0.07119587808847427, acc: 0.9878706336021423)
[2024-12-17 05:17:01,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:02,116][root][INFO] - Training Epoch: 2/2, step 3879/7134 completed (loss: 0.018256641924381256, acc: 0.9907578825950623)
[2024-12-17 05:17:02,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:02,556][root][INFO] - Training Epoch: 2/2, step 3880/7134 completed (loss: 0.09386520832777023, acc: 0.9809104204177856)
[2024-12-17 05:17:02,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:02,980][root][INFO] - Training Epoch: 2/2, step 3881/7134 completed (loss: 0.09086967259645462, acc: 0.9800000190734863)
[2024-12-17 05:17:03,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:03,413][root][INFO] - Training Epoch: 2/2, step 3882/7134 completed (loss: 0.047905877232551575, acc: 0.9887499809265137)
[2024-12-17 05:17:03,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:03,851][root][INFO] - Training Epoch: 2/2, step 3883/7134 completed (loss: 0.020815713331103325, acc: 0.9930070042610168)
[2024-12-17 05:17:03,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:04,275][root][INFO] - Training Epoch: 2/2, step 3884/7134 completed (loss: 0.01894190162420273, acc: 0.9959183931350708)
[2024-12-17 05:17:04,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:04,683][root][INFO] - Training Epoch: 2/2, step 3885/7134 completed (loss: 0.02963707037270069, acc: 0.9908615946769714)
[2024-12-17 05:17:04,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:05,127][root][INFO] - Training Epoch: 2/2, step 3886/7134 completed (loss: 0.022373083978891373, acc: 0.9927536249160767)
[2024-12-17 05:17:05,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:05,545][root][INFO] - Training Epoch: 2/2, step 3887/7134 completed (loss: 0.03242943063378334, acc: 0.9954751133918762)
[2024-12-17 05:17:05,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:05,984][root][INFO] - Training Epoch: 2/2, step 3888/7134 completed (loss: 0.029667630791664124, acc: 0.9912499785423279)
[2024-12-17 05:17:06,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:06,449][root][INFO] - Training Epoch: 2/2, step 3889/7134 completed (loss: 0.016742082312703133, acc: 0.9961685538291931)
[2024-12-17 05:17:06,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:06,900][root][INFO] - Training Epoch: 2/2, step 3890/7134 completed (loss: 0.0218166783452034, acc: 0.9939831495285034)
[2024-12-17 05:17:07,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:07,352][root][INFO] - Training Epoch: 2/2, step 3891/7134 completed (loss: 0.015961598604917526, acc: 0.9947712421417236)
[2024-12-17 05:17:07,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:07,791][root][INFO] - Training Epoch: 2/2, step 3892/7134 completed (loss: 0.017751341685652733, acc: 0.9953846335411072)
[2024-12-17 05:17:07,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:08,219][root][INFO] - Training Epoch: 2/2, step 3893/7134 completed (loss: 0.07050296664237976, acc: 0.9793814420700073)
[2024-12-17 05:17:08,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:08,644][root][INFO] - Training Epoch: 2/2, step 3894/7134 completed (loss: 0.010729828849434853, acc: 0.9985954761505127)
[2024-12-17 05:17:08,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:09,087][root][INFO] - Training Epoch: 2/2, step 3895/7134 completed (loss: 0.028938310220837593, acc: 0.9922580718994141)
[2024-12-17 05:17:09,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:09,542][root][INFO] - Training Epoch: 2/2, step 3896/7134 completed (loss: 0.01407329086214304, acc: 0.9977426528930664)
[2024-12-17 05:17:09,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:09,996][root][INFO] - Training Epoch: 2/2, step 3897/7134 completed (loss: 0.05692834034562111, acc: 0.9873239398002625)
[2024-12-17 05:17:10,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:10,424][root][INFO] - Training Epoch: 2/2, step 3898/7134 completed (loss: 0.051211267709732056, acc: 0.9872773289680481)
[2024-12-17 05:17:10,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:10,865][root][INFO] - Training Epoch: 2/2, step 3899/7134 completed (loss: 0.02643122524023056, acc: 0.9922380447387695)
[2024-12-17 05:17:10,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:11,339][root][INFO] - Training Epoch: 2/2, step 3900/7134 completed (loss: 0.03546649217605591, acc: 0.9884124994277954)
[2024-12-17 05:17:11,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:11,761][root][INFO] - Training Epoch: 2/2, step 3901/7134 completed (loss: 0.08173933625221252, acc: 0.979784369468689)
[2024-12-17 05:17:11,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:12,194][root][INFO] - Training Epoch: 2/2, step 3902/7134 completed (loss: 0.09480690211057663, acc: 0.9774834513664246)
[2024-12-17 05:17:12,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:12,662][root][INFO] - Training Epoch: 2/2, step 3903/7134 completed (loss: 0.1023007333278656, acc: 0.9731903672218323)
[2024-12-17 05:17:12,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:13,063][root][INFO] - Training Epoch: 2/2, step 3904/7134 completed (loss: 0.03429676964879036, acc: 0.990867555141449)
[2024-12-17 05:17:13,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:13,520][root][INFO] - Training Epoch: 2/2, step 3905/7134 completed (loss: 0.027588266879320145, acc: 0.9929478168487549)
[2024-12-17 05:17:13,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:13,967][root][INFO] - Training Epoch: 2/2, step 3906/7134 completed (loss: 0.01543766912072897, acc: 0.9971264600753784)
[2024-12-17 05:17:14,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:14,382][root][INFO] - Training Epoch: 2/2, step 3907/7134 completed (loss: 0.03361201658844948, acc: 0.9922879338264465)
[2024-12-17 05:17:14,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:14,822][root][INFO] - Training Epoch: 2/2, step 3908/7134 completed (loss: 0.06633118540048599, acc: 0.9831546545028687)
[2024-12-17 05:17:14,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:15,260][root][INFO] - Training Epoch: 2/2, step 3909/7134 completed (loss: 0.036885153502225876, acc: 0.987075924873352)
[2024-12-17 05:17:15,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:15,677][root][INFO] - Training Epoch: 2/2, step 3910/7134 completed (loss: 0.045473359525203705, acc: 0.9833101630210876)
[2024-12-17 05:17:15,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:16,133][root][INFO] - Training Epoch: 2/2, step 3911/7134 completed (loss: 0.025246834382414818, acc: 0.9935275316238403)
[2024-12-17 05:17:16,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:16,565][root][INFO] - Training Epoch: 2/2, step 3912/7134 completed (loss: 0.010364169254899025, acc: 0.9985119104385376)
[2024-12-17 05:17:16,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:17,006][root][INFO] - Training Epoch: 2/2, step 3913/7134 completed (loss: 0.036959052085876465, acc: 0.9884615540504456)
[2024-12-17 05:17:17,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:17,412][root][INFO] - Training Epoch: 2/2, step 3914/7134 completed (loss: 0.027076540514826775, acc: 0.9915825128555298)
[2024-12-17 05:17:17,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:17,856][root][INFO] - Training Epoch: 2/2, step 3915/7134 completed (loss: 0.02565601095557213, acc: 0.994358241558075)
[2024-12-17 05:17:17,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:18,301][root][INFO] - Training Epoch: 2/2, step 3916/7134 completed (loss: 0.02339448221027851, acc: 0.993630588054657)
[2024-12-17 05:17:18,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:18,755][root][INFO] - Training Epoch: 2/2, step 3917/7134 completed (loss: 0.0080506457015872, acc: 1.0)
[2024-12-17 05:17:18,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:19,185][root][INFO] - Training Epoch: 2/2, step 3918/7134 completed (loss: 0.031534772366285324, acc: 0.9908854365348816)
[2024-12-17 05:17:19,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:19,636][root][INFO] - Training Epoch: 2/2, step 3919/7134 completed (loss: 0.07344004511833191, acc: 0.9853420257568359)
[2024-12-17 05:17:19,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:20,087][root][INFO] - Training Epoch: 2/2, step 3920/7134 completed (loss: 0.02502879686653614, acc: 0.9906542301177979)
[2024-12-17 05:17:20,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:20,518][root][INFO] - Training Epoch: 2/2, step 3921/7134 completed (loss: 0.02627410739660263, acc: 0.9900000095367432)
[2024-12-17 05:17:20,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:20,925][root][INFO] - Training Epoch: 2/2, step 3922/7134 completed (loss: 0.09397324174642563, acc: 0.9685534834861755)
[2024-12-17 05:17:21,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:21,362][root][INFO] - Training Epoch: 2/2, step 3923/7134 completed (loss: 0.09328149259090424, acc: 0.9777397513389587)
[2024-12-17 05:17:21,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:21,806][root][INFO] - Training Epoch: 2/2, step 3924/7134 completed (loss: 0.040375933051109314, acc: 0.9885057210922241)
[2024-12-17 05:17:21,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:22,234][root][INFO] - Training Epoch: 2/2, step 3925/7134 completed (loss: 0.0820043757557869, acc: 0.980966329574585)
[2024-12-17 05:17:22,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:22,649][root][INFO] - Training Epoch: 2/2, step 3926/7134 completed (loss: 0.048034749925136566, acc: 0.9884892106056213)
[2024-12-17 05:17:22,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:23,086][root][INFO] - Training Epoch: 2/2, step 3927/7134 completed (loss: 0.0423443503677845, acc: 0.9834938049316406)
[2024-12-17 05:17:23,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:23,548][root][INFO] - Training Epoch: 2/2, step 3928/7134 completed (loss: 0.057139791548252106, acc: 0.9870689511299133)
[2024-12-17 05:17:23,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:23,948][root][INFO] - Training Epoch: 2/2, step 3929/7134 completed (loss: 0.027660757303237915, acc: 0.9936407208442688)
[2024-12-17 05:17:24,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:24,370][root][INFO] - Training Epoch: 2/2, step 3930/7134 completed (loss: 0.03170705959200859, acc: 0.9894958138465881)
[2024-12-17 05:17:24,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:24,782][root][INFO] - Training Epoch: 2/2, step 3931/7134 completed (loss: 0.027409125119447708, acc: 0.9925261735916138)
[2024-12-17 05:17:24,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:25,255][root][INFO] - Training Epoch: 2/2, step 3932/7134 completed (loss: 0.050839442759752274, acc: 0.9822134375572205)
[2024-12-17 05:17:25,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:25,640][root][INFO] - Training Epoch: 2/2, step 3933/7134 completed (loss: 0.029829828068614006, acc: 0.9901315569877625)
[2024-12-17 05:17:25,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:26,047][root][INFO] - Training Epoch: 2/2, step 3934/7134 completed (loss: 0.016531523317098618, acc: 0.9953161478042603)
[2024-12-17 05:17:26,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:26,456][root][INFO] - Training Epoch: 2/2, step 3935/7134 completed (loss: 0.004505804739892483, acc: 1.0)
[2024-12-17 05:17:26,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:26,873][root][INFO] - Training Epoch: 2/2, step 3936/7134 completed (loss: 0.04063549265265465, acc: 0.9905660152435303)
[2024-12-17 05:17:27,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:27,292][root][INFO] - Training Epoch: 2/2, step 3937/7134 completed (loss: 0.04573587328195572, acc: 0.9836734533309937)
[2024-12-17 05:17:27,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:27,681][root][INFO] - Training Epoch: 2/2, step 3938/7134 completed (loss: 0.015914225950837135, acc: 0.9954751133918762)
[2024-12-17 05:17:27,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:28,083][root][INFO] - Training Epoch: 2/2, step 3939/7134 completed (loss: 0.06251738220453262, acc: 0.9813874959945679)
[2024-12-17 05:17:28,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:28,482][root][INFO] - Training Epoch: 2/2, step 3940/7134 completed (loss: 0.03599533066153526, acc: 0.9924623370170593)
[2024-12-17 05:17:28,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:28,880][root][INFO] - Training Epoch: 2/2, step 3941/7134 completed (loss: 0.03106086514890194, acc: 0.9908536672592163)
[2024-12-17 05:17:29,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:29,280][root][INFO] - Training Epoch: 2/2, step 3942/7134 completed (loss: 0.027013642713427544, acc: 0.993852436542511)
[2024-12-17 05:17:29,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:29,664][root][INFO] - Training Epoch: 2/2, step 3943/7134 completed (loss: 0.02375001646578312, acc: 0.9884169697761536)
[2024-12-17 05:17:29,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:30,093][root][INFO] - Training Epoch: 2/2, step 3944/7134 completed (loss: 0.02926296927034855, acc: 0.9926199316978455)
[2024-12-17 05:17:30,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:30,503][root][INFO] - Training Epoch: 2/2, step 3945/7134 completed (loss: 0.015750424936413765, acc: 0.9923780560493469)
[2024-12-17 05:17:30,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:30,893][root][INFO] - Training Epoch: 2/2, step 3946/7134 completed (loss: 0.0249642226845026, acc: 0.9937369227409363)
[2024-12-17 05:17:31,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:31,298][root][INFO] - Training Epoch: 2/2, step 3947/7134 completed (loss: 0.027112780138850212, acc: 0.9948186278343201)
[2024-12-17 05:17:31,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:31,697][root][INFO] - Training Epoch: 2/2, step 3948/7134 completed (loss: 0.018067538738250732, acc: 0.9949748516082764)
[2024-12-17 05:17:31,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:32,108][root][INFO] - Training Epoch: 2/2, step 3949/7134 completed (loss: 0.026620937511324883, acc: 0.9925373196601868)
[2024-12-17 05:17:32,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:32,502][root][INFO] - Training Epoch: 2/2, step 3950/7134 completed (loss: 0.040023572742938995, acc: 0.9888392686843872)
[2024-12-17 05:17:32,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:32,887][root][INFO] - Training Epoch: 2/2, step 3951/7134 completed (loss: 0.028910595923662186, acc: 0.9899749159812927)
[2024-12-17 05:17:33,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:33,292][root][INFO] - Training Epoch: 2/2, step 3952/7134 completed (loss: 0.021614307537674904, acc: 0.9923076629638672)
[2024-12-17 05:17:33,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:33,687][root][INFO] - Training Epoch: 2/2, step 3953/7134 completed (loss: 0.03072432428598404, acc: 0.992409884929657)
[2024-12-17 05:17:33,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:34,085][root][INFO] - Training Epoch: 2/2, step 3954/7134 completed (loss: 0.04341771453619003, acc: 0.9871134161949158)
[2024-12-17 05:17:34,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:34,486][root][INFO] - Training Epoch: 2/2, step 3955/7134 completed (loss: 0.031153423711657524, acc: 0.9932546615600586)
[2024-12-17 05:17:34,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:34,896][root][INFO] - Training Epoch: 2/2, step 3956/7134 completed (loss: 0.020621802657842636, acc: 0.995199978351593)
[2024-12-17 05:17:34,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:35,296][root][INFO] - Training Epoch: 2/2, step 3957/7134 completed (loss: 0.03411734104156494, acc: 0.9909909963607788)
[2024-12-17 05:17:35,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:35,692][root][INFO] - Training Epoch: 2/2, step 3958/7134 completed (loss: 0.051037441939115524, acc: 0.9743589758872986)
[2024-12-17 05:17:35,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:36,100][root][INFO] - Training Epoch: 2/2, step 3959/7134 completed (loss: 0.011103276163339615, acc: 1.0)
[2024-12-17 05:17:36,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:36,535][root][INFO] - Training Epoch: 2/2, step 3960/7134 completed (loss: 0.03237123787403107, acc: 0.9900285005569458)
[2024-12-17 05:17:36,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:36,980][root][INFO] - Training Epoch: 2/2, step 3961/7134 completed (loss: 0.01453294139355421, acc: 0.9940029978752136)
[2024-12-17 05:17:37,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:37,392][root][INFO] - Training Epoch: 2/2, step 3962/7134 completed (loss: 0.015288092195987701, acc: 0.991909384727478)
[2024-12-17 05:17:37,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:37,818][root][INFO] - Training Epoch: 2/2, step 3963/7134 completed (loss: 0.07834292203187943, acc: 0.9882698059082031)
[2024-12-17 05:17:37,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:38,219][root][INFO] - Training Epoch: 2/2, step 3964/7134 completed (loss: 0.06788624823093414, acc: 0.9870370626449585)
[2024-12-17 05:17:38,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:38,626][root][INFO] - Training Epoch: 2/2, step 3965/7134 completed (loss: 0.024004187434911728, acc: 0.991416335105896)
[2024-12-17 05:17:38,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:39,035][root][INFO] - Training Epoch: 2/2, step 3966/7134 completed (loss: 0.011582108214497566, acc: 0.994584858417511)
[2024-12-17 05:17:39,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:39,473][root][INFO] - Training Epoch: 2/2, step 3967/7134 completed (loss: 0.09105824679136276, acc: 0.9809358716011047)
[2024-12-17 05:17:39,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:39,919][root][INFO] - Training Epoch: 2/2, step 3968/7134 completed (loss: 0.030100034549832344, acc: 0.9934980273246765)
[2024-12-17 05:17:40,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:40,278][root][INFO] - Training Epoch: 2/2, step 3969/7134 completed (loss: 0.04794788733124733, acc: 0.9842932224273682)
[2024-12-17 05:17:40,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:40,718][root][INFO] - Training Epoch: 2/2, step 3970/7134 completed (loss: 0.06791691482067108, acc: 0.9913669228553772)
[2024-12-17 05:17:40,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:41,164][root][INFO] - Training Epoch: 2/2, step 3971/7134 completed (loss: 0.12101083993911743, acc: 0.9769821166992188)
[2024-12-17 05:17:41,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:41,586][root][INFO] - Training Epoch: 2/2, step 3972/7134 completed (loss: 0.13913695514202118, acc: 0.9742268323898315)
[2024-12-17 05:17:41,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:42,017][root][INFO] - Training Epoch: 2/2, step 3973/7134 completed (loss: 0.0654471144080162, acc: 0.9775474667549133)
[2024-12-17 05:17:42,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:42,459][root][INFO] - Training Epoch: 2/2, step 3974/7134 completed (loss: 0.09883566200733185, acc: 0.9728997349739075)
[2024-12-17 05:17:42,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:42,871][root][INFO] - Training Epoch: 2/2, step 3975/7134 completed (loss: 0.04169346019625664, acc: 0.9833837151527405)
[2024-12-17 05:17:43,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:43,338][root][INFO] - Training Epoch: 2/2, step 3976/7134 completed (loss: 0.12300141155719757, acc: 0.9705014824867249)
[2024-12-17 05:17:43,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:43,768][root][INFO] - Training Epoch: 2/2, step 3977/7134 completed (loss: 0.018826190382242203, acc: 0.9965217113494873)
[2024-12-17 05:17:43,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:44,193][root][INFO] - Training Epoch: 2/2, step 3978/7134 completed (loss: 0.016980474814772606, acc: 0.9974126815795898)
[2024-12-17 05:17:44,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:44,657][root][INFO] - Training Epoch: 2/2, step 3979/7134 completed (loss: 0.037402283400297165, acc: 0.9872495532035828)
[2024-12-17 05:17:44,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:45,074][root][INFO] - Training Epoch: 2/2, step 3980/7134 completed (loss: 0.030862927436828613, acc: 0.9923780560493469)
[2024-12-17 05:17:45,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:45,483][root][INFO] - Training Epoch: 2/2, step 3981/7134 completed (loss: 0.06948834657669067, acc: 0.9816513657569885)
[2024-12-17 05:17:45,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:45,904][root][INFO] - Training Epoch: 2/2, step 3982/7134 completed (loss: 0.08397265523672104, acc: 0.9813486337661743)
[2024-12-17 05:17:46,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:46,316][root][INFO] - Training Epoch: 2/2, step 3983/7134 completed (loss: 0.2939142882823944, acc: 0.9404255151748657)
[2024-12-17 05:17:46,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:46,744][root][INFO] - Training Epoch: 2/2, step 3984/7134 completed (loss: 0.08028071373701096, acc: 0.9779220819473267)
[2024-12-17 05:17:46,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:47,141][root][INFO] - Training Epoch: 2/2, step 3985/7134 completed (loss: 0.020040368661284447, acc: 0.9964349269866943)
[2024-12-17 05:17:47,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:47,575][root][INFO] - Training Epoch: 2/2, step 3986/7134 completed (loss: 0.15125936269760132, acc: 0.9727272987365723)
[2024-12-17 05:17:47,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:48,010][root][INFO] - Training Epoch: 2/2, step 3987/7134 completed (loss: 0.04901009052991867, acc: 0.9904030561447144)
[2024-12-17 05:17:48,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:48,456][root][INFO] - Training Epoch: 2/2, step 3988/7134 completed (loss: 0.06591958552598953, acc: 0.9797724485397339)
[2024-12-17 05:17:48,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:48,881][root][INFO] - Training Epoch: 2/2, step 3989/7134 completed (loss: 0.12764637172222137, acc: 0.968017041683197)
[2024-12-17 05:17:48,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:49,304][root][INFO] - Training Epoch: 2/2, step 3990/7134 completed (loss: 0.0458480641245842, acc: 0.9867330193519592)
[2024-12-17 05:17:49,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:49,711][root][INFO] - Training Epoch: 2/2, step 3991/7134 completed (loss: 0.030993539839982986, acc: 0.9966996908187866)
[2024-12-17 05:17:49,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:50,135][root][INFO] - Training Epoch: 2/2, step 3992/7134 completed (loss: 0.07543803751468658, acc: 0.9837837815284729)
[2024-12-17 05:17:50,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:50,538][root][INFO] - Training Epoch: 2/2, step 3993/7134 completed (loss: 0.058607492595911026, acc: 0.9839449524879456)
[2024-12-17 05:17:50,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:50,955][root][INFO] - Training Epoch: 2/2, step 3994/7134 completed (loss: 0.057066433131694794, acc: 0.9904761910438538)
[2024-12-17 05:17:51,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:51,379][root][INFO] - Training Epoch: 2/2, step 3995/7134 completed (loss: 0.09961023181676865, acc: 0.9844961166381836)
[2024-12-17 05:17:51,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:51,755][root][INFO] - Training Epoch: 2/2, step 3996/7134 completed (loss: 0.04339742660522461, acc: 0.9897330403327942)
[2024-12-17 05:17:51,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:52,181][root][INFO] - Training Epoch: 2/2, step 3997/7134 completed (loss: 0.13746868073940277, acc: 0.9758241772651672)
[2024-12-17 05:17:52,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:52,546][root][INFO] - Training Epoch: 2/2, step 3998/7134 completed (loss: 0.09708932787179947, acc: 0.9737417697906494)
[2024-12-17 05:17:52,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:52,947][root][INFO] - Training Epoch: 2/2, step 3999/7134 completed (loss: 0.05181901529431343, acc: 0.9840319156646729)
[2024-12-17 05:17:53,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:53,348][root][INFO] - Training Epoch: 2/2, step 4000/7134 completed (loss: 0.04856087267398834, acc: 0.9864864945411682)
[2024-12-17 05:17:53,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:53,743][root][INFO] - Training Epoch: 2/2, step 4001/7134 completed (loss: 0.07069990038871765, acc: 0.9801192879676819)
[2024-12-17 05:17:53,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:54,144][root][INFO] - Training Epoch: 2/2, step 4002/7134 completed (loss: 0.0909636914730072, acc: 0.9807229042053223)
[2024-12-17 05:17:54,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:54,571][root][INFO] - Training Epoch: 2/2, step 4003/7134 completed (loss: 0.09928331524133682, acc: 0.9760147333145142)
[2024-12-17 05:17:54,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:54,965][root][INFO] - Training Epoch: 2/2, step 4004/7134 completed (loss: 0.04410857707262039, acc: 0.9860140085220337)
[2024-12-17 05:17:55,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:55,370][root][INFO] - Training Epoch: 2/2, step 4005/7134 completed (loss: 0.017957905307412148, acc: 0.9937205910682678)
[2024-12-17 05:17:55,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:55,834][root][INFO] - Training Epoch: 2/2, step 4006/7134 completed (loss: 0.01719258725643158, acc: 0.9958376884460449)
[2024-12-17 05:17:55,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:56,261][root][INFO] - Training Epoch: 2/2, step 4007/7134 completed (loss: 0.02908104658126831, acc: 0.9910045266151428)
[2024-12-17 05:17:56,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:56,718][root][INFO] - Training Epoch: 2/2, step 4008/7134 completed (loss: 0.017127126455307007, acc: 0.9957716464996338)
[2024-12-17 05:17:56,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:57,157][root][INFO] - Training Epoch: 2/2, step 4009/7134 completed (loss: 0.020317144691944122, acc: 0.9933422207832336)
[2024-12-17 05:17:57,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:57,612][root][INFO] - Training Epoch: 2/2, step 4010/7134 completed (loss: 0.01494268886744976, acc: 0.9966443181037903)
[2024-12-17 05:17:57,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:58,062][root][INFO] - Training Epoch: 2/2, step 4011/7134 completed (loss: 0.0317760705947876, acc: 0.9933599233627319)
[2024-12-17 05:17:58,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:58,473][root][INFO] - Training Epoch: 2/2, step 4012/7134 completed (loss: 0.0114243533462286, acc: 0.9971751570701599)
[2024-12-17 05:17:58,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:58,912][root][INFO] - Training Epoch: 2/2, step 4013/7134 completed (loss: 0.008372174575924873, acc: 0.9983922839164734)
[2024-12-17 05:17:59,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:59,356][root][INFO] - Training Epoch: 2/2, step 4014/7134 completed (loss: 0.010762515477836132, acc: 0.9968652129173279)
[2024-12-17 05:17:59,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:17:59,791][root][INFO] - Training Epoch: 2/2, step 4015/7134 completed (loss: 0.028833819553256035, acc: 0.9907833933830261)
[2024-12-17 05:17:59,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:00,259][root][INFO] - Training Epoch: 2/2, step 4016/7134 completed (loss: 0.035140495747327805, acc: 0.9948979616165161)
[2024-12-17 05:18:00,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:00,709][root][INFO] - Training Epoch: 2/2, step 4017/7134 completed (loss: 0.03130944445729256, acc: 0.9930716156959534)
[2024-12-17 05:18:00,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:01,151][root][INFO] - Training Epoch: 2/2, step 4018/7134 completed (loss: 0.029459098353981972, acc: 0.9927272796630859)
[2024-12-17 05:18:01,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:01,578][root][INFO] - Training Epoch: 2/2, step 4019/7134 completed (loss: 0.04591198265552521, acc: 0.9911167621612549)
[2024-12-17 05:18:01,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:01,995][root][INFO] - Training Epoch: 2/2, step 4020/7134 completed (loss: 0.030077170580625534, acc: 0.9931694269180298)
[2024-12-17 05:18:02,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:02,379][root][INFO] - Training Epoch: 2/2, step 4021/7134 completed (loss: 0.021600985899567604, acc: 0.9928698539733887)
[2024-12-17 05:18:02,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:02,817][root][INFO] - Training Epoch: 2/2, step 4022/7134 completed (loss: 0.0387418232858181, acc: 0.9926380515098572)
[2024-12-17 05:18:02,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:03,276][root][INFO] - Training Epoch: 2/2, step 4023/7134 completed (loss: 0.037698496133089066, acc: 0.99245285987854)
[2024-12-17 05:18:03,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:03,719][root][INFO] - Training Epoch: 2/2, step 4024/7134 completed (loss: 0.031881604343652725, acc: 0.990813672542572)
[2024-12-17 05:18:03,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:04,155][root][INFO] - Training Epoch: 2/2, step 4025/7134 completed (loss: 0.054209887981414795, acc: 0.9864099621772766)
[2024-12-17 05:18:04,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:04,584][root][INFO] - Training Epoch: 2/2, step 4026/7134 completed (loss: 0.09417203813791275, acc: 0.983775794506073)
[2024-12-17 05:18:04,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:05,027][root][INFO] - Training Epoch: 2/2, step 4027/7134 completed (loss: 0.040549613535404205, acc: 0.9892086386680603)
[2024-12-17 05:18:05,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:05,439][root][INFO] - Training Epoch: 2/2, step 4028/7134 completed (loss: 0.04311108961701393, acc: 0.9845094680786133)
[2024-12-17 05:18:05,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:05,886][root][INFO] - Training Epoch: 2/2, step 4029/7134 completed (loss: 0.023654967546463013, acc: 0.9913899302482605)
[2024-12-17 05:18:06,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:06,338][root][INFO] - Training Epoch: 2/2, step 4030/7134 completed (loss: 0.018430955708026886, acc: 0.9938398599624634)
[2024-12-17 05:18:06,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:06,757][root][INFO] - Training Epoch: 2/2, step 4031/7134 completed (loss: 0.014908216893672943, acc: 0.9941349029541016)
[2024-12-17 05:18:06,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:07,190][root][INFO] - Training Epoch: 2/2, step 4032/7134 completed (loss: 0.06963726133108139, acc: 0.9879518151283264)
[2024-12-17 05:18:07,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:07,636][root][INFO] - Training Epoch: 2/2, step 4033/7134 completed (loss: 0.021621787920594215, acc: 0.9899371266365051)
[2024-12-17 05:18:07,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:08,072][root][INFO] - Training Epoch: 2/2, step 4034/7134 completed (loss: 0.004635229241102934, acc: 0.9987819790840149)
[2024-12-17 05:18:08,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:08,574][root][INFO] - Training Epoch: 2/2, step 4035/7134 completed (loss: 0.041969966143369675, acc: 0.9893742799758911)
[2024-12-17 05:18:08,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:08,983][root][INFO] - Training Epoch: 2/2, step 4036/7134 completed (loss: 0.037984203547239304, acc: 0.9890109896659851)
[2024-12-17 05:18:09,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:09,440][root][INFO] - Training Epoch: 2/2, step 4037/7134 completed (loss: 0.016048694029450417, acc: 0.9951865077018738)
[2024-12-17 05:18:09,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:09,856][root][INFO] - Training Epoch: 2/2, step 4038/7134 completed (loss: 0.037072423845529556, acc: 0.9889958500862122)
[2024-12-17 05:18:09,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:10,255][root][INFO] - Training Epoch: 2/2, step 4039/7134 completed (loss: 0.03754717484116554, acc: 0.9872340559959412)
[2024-12-17 05:18:10,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:10,676][root][INFO] - Training Epoch: 2/2, step 4040/7134 completed (loss: 0.016476115211844444, acc: 0.9975369572639465)
[2024-12-17 05:18:10,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:11,125][root][INFO] - Training Epoch: 2/2, step 4041/7134 completed (loss: 0.03113190084695816, acc: 0.9932795763015747)
[2024-12-17 05:18:11,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:11,541][root][INFO] - Training Epoch: 2/2, step 4042/7134 completed (loss: 0.01958385482430458, acc: 0.9941176176071167)
[2024-12-17 05:18:11,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:11,927][root][INFO] - Training Epoch: 2/2, step 4043/7134 completed (loss: 0.015974657610058784, acc: 0.9941262602806091)
[2024-12-17 05:18:12,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:12,352][root][INFO] - Training Epoch: 2/2, step 4044/7134 completed (loss: 0.013704097829759121, acc: 0.993686854839325)
[2024-12-17 05:18:12,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:12,788][root][INFO] - Training Epoch: 2/2, step 4045/7134 completed (loss: 0.04500753432512283, acc: 0.9861111044883728)
[2024-12-17 05:18:12,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:13,216][root][INFO] - Training Epoch: 2/2, step 4046/7134 completed (loss: 0.029749201610684395, acc: 0.9931318759918213)
[2024-12-17 05:18:13,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:13,663][root][INFO] - Training Epoch: 2/2, step 4047/7134 completed (loss: 0.04166780784726143, acc: 0.9928401112556458)
[2024-12-17 05:18:13,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:14,135][root][INFO] - Training Epoch: 2/2, step 4048/7134 completed (loss: 0.016413452103734016, acc: 0.9953380227088928)
[2024-12-17 05:18:14,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:14,610][root][INFO] - Training Epoch: 2/2, step 4049/7134 completed (loss: 0.02829483337700367, acc: 0.9919540286064148)
[2024-12-17 05:18:14,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:15,029][root][INFO] - Training Epoch: 2/2, step 4050/7134 completed (loss: 0.03270942345261574, acc: 0.9929078221321106)
[2024-12-17 05:18:15,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:15,473][root][INFO] - Training Epoch: 2/2, step 4051/7134 completed (loss: 0.06396119296550751, acc: 0.9880383014678955)
[2024-12-17 05:18:15,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:15,869][root][INFO] - Training Epoch: 2/2, step 4052/7134 completed (loss: 0.020960990339517593, acc: 0.9896640777587891)
[2024-12-17 05:18:15,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:16,300][root][INFO] - Training Epoch: 2/2, step 4053/7134 completed (loss: 0.03753425180912018, acc: 0.9867374300956726)
[2024-12-17 05:18:16,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:16,736][root][INFO] - Training Epoch: 2/2, step 4054/7134 completed (loss: 0.03349986672401428, acc: 0.9919999837875366)
[2024-12-17 05:18:16,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:17,199][root][INFO] - Training Epoch: 2/2, step 4055/7134 completed (loss: 0.02507966384291649, acc: 0.9902912378311157)
[2024-12-17 05:18:17,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:17,655][root][INFO] - Training Epoch: 2/2, step 4056/7134 completed (loss: 0.019329039379954338, acc: 0.9927272796630859)
[2024-12-17 05:18:17,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:18,102][root][INFO] - Training Epoch: 2/2, step 4057/7134 completed (loss: 0.050215911120176315, acc: 0.9902642369270325)
[2024-12-17 05:18:18,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:18,464][root][INFO] - Training Epoch: 2/2, step 4058/7134 completed (loss: 0.07046785950660706, acc: 0.980879545211792)
[2024-12-17 05:18:18,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:18,871][root][INFO] - Training Epoch: 2/2, step 4059/7134 completed (loss: 0.03524981066584587, acc: 0.989051103591919)
[2024-12-17 05:18:18,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:19,267][root][INFO] - Training Epoch: 2/2, step 4060/7134 completed (loss: 0.027687426656484604, acc: 0.9907264113426208)
[2024-12-17 05:18:19,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:19,707][root][INFO] - Training Epoch: 2/2, step 4061/7134 completed (loss: 0.018996648490428925, acc: 0.9928774833679199)
[2024-12-17 05:18:19,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:20,129][root][INFO] - Training Epoch: 2/2, step 4062/7134 completed (loss: 0.008656630292534828, acc: 0.9968503713607788)
[2024-12-17 05:18:20,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:20,504][root][INFO] - Training Epoch: 2/2, step 4063/7134 completed (loss: 0.013410215266048908, acc: 0.9964664578437805)
[2024-12-17 05:18:20,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:20,936][root][INFO] - Training Epoch: 2/2, step 4064/7134 completed (loss: 0.006803971249610186, acc: 0.998487114906311)
[2024-12-17 05:18:21,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:21,365][root][INFO] - Training Epoch: 2/2, step 4065/7134 completed (loss: 0.023613205179572105, acc: 0.9931034445762634)
[2024-12-17 05:18:21,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:21,805][root][INFO] - Training Epoch: 2/2, step 4066/7134 completed (loss: 0.012723898515105247, acc: 0.9958333373069763)
[2024-12-17 05:18:21,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:22,209][root][INFO] - Training Epoch: 2/2, step 4067/7134 completed (loss: 0.030559193342924118, acc: 0.9934640526771545)
[2024-12-17 05:18:22,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:22,614][root][INFO] - Training Epoch: 2/2, step 4068/7134 completed (loss: 0.03802894055843353, acc: 0.9907407164573669)
[2024-12-17 05:18:22,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:23,024][root][INFO] - Training Epoch: 2/2, step 4069/7134 completed (loss: 0.022607620805501938, acc: 0.9968701004981995)
[2024-12-17 05:18:23,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:23,436][root][INFO] - Training Epoch: 2/2, step 4070/7134 completed (loss: 0.022991903126239777, acc: 0.9954338073730469)
[2024-12-17 05:18:23,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:23,839][root][INFO] - Training Epoch: 2/2, step 4071/7134 completed (loss: 0.02940145879983902, acc: 0.9901153445243835)
[2024-12-17 05:18:23,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:24,261][root][INFO] - Training Epoch: 2/2, step 4072/7134 completed (loss: 0.011311416514217854, acc: 0.9985569715499878)
[2024-12-17 05:18:24,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:24,685][root][INFO] - Training Epoch: 2/2, step 4073/7134 completed (loss: 0.014663771726191044, acc: 0.9971264600753784)
[2024-12-17 05:18:24,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:25,108][root][INFO] - Training Epoch: 2/2, step 4074/7134 completed (loss: 0.025722255930304527, acc: 0.995708167552948)
[2024-12-17 05:18:25,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:25,541][root][INFO] - Training Epoch: 2/2, step 4075/7134 completed (loss: 0.00840072426944971, acc: 0.9970015287399292)
[2024-12-17 05:18:25,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:25,994][root][INFO] - Training Epoch: 2/2, step 4076/7134 completed (loss: 0.010683270171284676, acc: 0.9971056580543518)
[2024-12-17 05:18:26,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:26,393][root][INFO] - Training Epoch: 2/2, step 4077/7134 completed (loss: 0.042280569672584534, acc: 0.989847719669342)
[2024-12-17 05:18:26,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:26,822][root][INFO] - Training Epoch: 2/2, step 4078/7134 completed (loss: 0.015509504824876785, acc: 0.994301974773407)
[2024-12-17 05:18:26,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:27,195][root][INFO] - Training Epoch: 2/2, step 4079/7134 completed (loss: 0.020509693771600723, acc: 0.9928698539733887)
[2024-12-17 05:18:27,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:27,598][root][INFO] - Training Epoch: 2/2, step 4080/7134 completed (loss: 0.012903261929750443, acc: 0.9952531456947327)
[2024-12-17 05:18:27,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:28,000][root][INFO] - Training Epoch: 2/2, step 4081/7134 completed (loss: 0.006561816670000553, acc: 0.9966996908187866)
[2024-12-17 05:18:28,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:28,422][root][INFO] - Training Epoch: 2/2, step 4082/7134 completed (loss: 0.045753397047519684, acc: 0.9815157055854797)
[2024-12-17 05:18:28,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:28,856][root][INFO] - Training Epoch: 2/2, step 4083/7134 completed (loss: 0.050581321120262146, acc: 0.9865269660949707)
[2024-12-17 05:18:28,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:29,259][root][INFO] - Training Epoch: 2/2, step 4084/7134 completed (loss: 0.09374014288187027, acc: 0.9627450704574585)
[2024-12-17 05:18:29,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:29,677][root][INFO] - Training Epoch: 2/2, step 4085/7134 completed (loss: 0.034291718155145645, acc: 0.9892183542251587)
[2024-12-17 05:18:29,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:30,095][root][INFO] - Training Epoch: 2/2, step 4086/7134 completed (loss: 0.07729391008615494, acc: 0.978723406791687)
[2024-12-17 05:18:30,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:30,543][root][INFO] - Training Epoch: 2/2, step 4087/7134 completed (loss: 0.0215314794331789, acc: 0.9987080097198486)
[2024-12-17 05:18:30,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:30,977][root][INFO] - Training Epoch: 2/2, step 4088/7134 completed (loss: 0.06696723401546478, acc: 0.9776119589805603)
[2024-12-17 05:18:31,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:31,383][root][INFO] - Training Epoch: 2/2, step 4089/7134 completed (loss: 0.05880967527627945, acc: 0.9857904314994812)
[2024-12-17 05:18:31,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:31,797][root][INFO] - Training Epoch: 2/2, step 4090/7134 completed (loss: 0.10438388586044312, acc: 0.980211079120636)
[2024-12-17 05:18:31,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:32,206][root][INFO] - Training Epoch: 2/2, step 4091/7134 completed (loss: 0.12025918811559677, acc: 0.9713321924209595)
[2024-12-17 05:18:32,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:32,652][root][INFO] - Training Epoch: 2/2, step 4092/7134 completed (loss: 0.042503759264945984, acc: 0.9909909963607788)
[2024-12-17 05:18:32,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:33,033][root][INFO] - Training Epoch: 2/2, step 4093/7134 completed (loss: 0.027293547987937927, acc: 0.9927140474319458)
[2024-12-17 05:18:33,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:33,456][root][INFO] - Training Epoch: 2/2, step 4094/7134 completed (loss: 0.06895443052053452, acc: 0.9834834933280945)
[2024-12-17 05:18:33,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:33,910][root][INFO] - Training Epoch: 2/2, step 4095/7134 completed (loss: 0.02788306586444378, acc: 0.9927641153335571)
[2024-12-17 05:18:34,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:34,296][root][INFO] - Training Epoch: 2/2, step 4096/7134 completed (loss: 0.06296638399362564, acc: 0.9940298795700073)
[2024-12-17 05:18:34,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:34,762][root][INFO] - Training Epoch: 2/2, step 4097/7134 completed (loss: 0.056423477828502655, acc: 0.9887096881866455)
[2024-12-17 05:18:34,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:35,200][root][INFO] - Training Epoch: 2/2, step 4098/7134 completed (loss: 0.03564102202653885, acc: 0.9918699264526367)
[2024-12-17 05:18:35,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:35,638][root][INFO] - Training Epoch: 2/2, step 4099/7134 completed (loss: 0.057845886796712875, acc: 0.9823943376541138)
[2024-12-17 05:18:35,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:36,111][root][INFO] - Training Epoch: 2/2, step 4100/7134 completed (loss: 0.006760214921087027, acc: 0.9969742894172668)
[2024-12-17 05:18:36,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:36,520][root][INFO] - Training Epoch: 2/2, step 4101/7134 completed (loss: 0.01808684505522251, acc: 0.9942965507507324)
[2024-12-17 05:18:36,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:36,949][root][INFO] - Training Epoch: 2/2, step 4102/7134 completed (loss: 0.02376376837491989, acc: 0.9945155382156372)
[2024-12-17 05:18:37,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:37,378][root][INFO] - Training Epoch: 2/2, step 4103/7134 completed (loss: 0.004435381852090359, acc: 0.9985052347183228)
[2024-12-17 05:18:37,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:37,812][root][INFO] - Training Epoch: 2/2, step 4104/7134 completed (loss: 0.010989640839397907, acc: 0.9983079433441162)
[2024-12-17 05:18:37,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:38,242][root][INFO] - Training Epoch: 2/2, step 4105/7134 completed (loss: 0.030403349548578262, acc: 0.9939576983451843)
[2024-12-17 05:18:38,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:38,661][root][INFO] - Training Epoch: 2/2, step 4106/7134 completed (loss: 0.022240428254008293, acc: 0.9923312664031982)
[2024-12-17 05:18:38,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:39,059][root][INFO] - Training Epoch: 2/2, step 4107/7134 completed (loss: 0.030550673604011536, acc: 0.9966386556625366)
[2024-12-17 05:18:39,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:39,460][root][INFO] - Training Epoch: 2/2, step 4108/7134 completed (loss: 0.023633316159248352, acc: 0.9935275316238403)
[2024-12-17 05:18:39,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:39,893][root][INFO] - Training Epoch: 2/2, step 4109/7134 completed (loss: 0.010271228849887848, acc: 0.9983948469161987)
[2024-12-17 05:18:39,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:40,307][root][INFO] - Training Epoch: 2/2, step 4110/7134 completed (loss: 0.004202728159725666, acc: 0.9982993006706238)
[2024-12-17 05:18:40,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:40,759][root][INFO] - Training Epoch: 2/2, step 4111/7134 completed (loss: 0.01242581196129322, acc: 0.9936908483505249)
[2024-12-17 05:18:40,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:41,220][root][INFO] - Training Epoch: 2/2, step 4112/7134 completed (loss: 0.03215396776795387, acc: 0.9946236610412598)
[2024-12-17 05:18:41,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:41,659][root][INFO] - Training Epoch: 2/2, step 4113/7134 completed (loss: 0.02760167047381401, acc: 0.9937984347343445)
[2024-12-17 05:18:41,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:42,113][root][INFO] - Training Epoch: 2/2, step 4114/7134 completed (loss: 0.09423596411943436, acc: 0.9695122241973877)
[2024-12-17 05:18:42,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:42,530][root][INFO] - Training Epoch: 2/2, step 4115/7134 completed (loss: 0.02802141383290291, acc: 0.9925373196601868)
[2024-12-17 05:18:42,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:42,970][root][INFO] - Training Epoch: 2/2, step 4116/7134 completed (loss: 0.009988365694880486, acc: 0.9983713626861572)
[2024-12-17 05:18:43,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:43,383][root][INFO] - Training Epoch: 2/2, step 4117/7134 completed (loss: 0.018767302855849266, acc: 0.9921135902404785)
[2024-12-17 05:18:43,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:43,748][root][INFO] - Training Epoch: 2/2, step 4118/7134 completed (loss: 0.015392132103443146, acc: 0.9975429773330688)
[2024-12-17 05:18:43,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:44,209][root][INFO] - Training Epoch: 2/2, step 4119/7134 completed (loss: 0.044182781130075455, acc: 0.9886914491653442)
[2024-12-17 05:18:44,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:44,614][root][INFO] - Training Epoch: 2/2, step 4120/7134 completed (loss: 0.028666960075497627, acc: 0.9950576424598694)
[2024-12-17 05:18:44,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:45,034][root][INFO] - Training Epoch: 2/2, step 4121/7134 completed (loss: 0.0413363017141819, acc: 0.9928977489471436)
[2024-12-17 05:18:45,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:45,443][root][INFO] - Training Epoch: 2/2, step 4122/7134 completed (loss: 0.015217079780995846, acc: 0.9942747950553894)
[2024-12-17 05:18:45,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:45,857][root][INFO] - Training Epoch: 2/2, step 4123/7134 completed (loss: 0.029285643249750137, acc: 0.9894419312477112)
[2024-12-17 05:18:45,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:46,284][root][INFO] - Training Epoch: 2/2, step 4124/7134 completed (loss: 0.03278033062815666, acc: 0.9943422675132751)
[2024-12-17 05:18:46,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:46,706][root][INFO] - Training Epoch: 2/2, step 4125/7134 completed (loss: 0.02110845036804676, acc: 0.9926470518112183)
[2024-12-17 05:18:46,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:47,129][root][INFO] - Training Epoch: 2/2, step 4126/7134 completed (loss: 0.01987902820110321, acc: 0.9943342804908752)
[2024-12-17 05:18:47,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:47,532][root][INFO] - Training Epoch: 2/2, step 4127/7134 completed (loss: 0.041376449167728424, acc: 0.9906250238418579)
[2024-12-17 05:18:47,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:47,926][root][INFO] - Training Epoch: 2/2, step 4128/7134 completed (loss: 0.02687000297009945, acc: 0.9937402009963989)
[2024-12-17 05:18:48,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:48,373][root][INFO] - Training Epoch: 2/2, step 4129/7134 completed (loss: 0.015887705609202385, acc: 0.9940652847290039)
[2024-12-17 05:18:48,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:48,774][root][INFO] - Training Epoch: 2/2, step 4130/7134 completed (loss: 0.02419995702803135, acc: 0.9942196607589722)
[2024-12-17 05:18:48,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:49,175][root][INFO] - Training Epoch: 2/2, step 4131/7134 completed (loss: 0.012210301123559475, acc: 0.996303141117096)
[2024-12-17 05:18:49,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:49,584][root][INFO] - Training Epoch: 2/2, step 4132/7134 completed (loss: 0.011828690767288208, acc: 0.9955357313156128)
[2024-12-17 05:18:49,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:49,960][root][INFO] - Training Epoch: 2/2, step 4133/7134 completed (loss: 0.03506512567400932, acc: 0.9870370626449585)
[2024-12-17 05:18:50,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:50,331][root][INFO] - Training Epoch: 2/2, step 4134/7134 completed (loss: 0.07000896334648132, acc: 0.971563994884491)
[2024-12-17 05:18:50,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:50,765][root][INFO] - Training Epoch: 2/2, step 4135/7134 completed (loss: 0.015257535502314568, acc: 0.9911190271377563)
[2024-12-17 05:18:50,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:51,206][root][INFO] - Training Epoch: 2/2, step 4136/7134 completed (loss: 0.020333578810095787, acc: 0.9929203391075134)
[2024-12-17 05:18:51,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:51,620][root][INFO] - Training Epoch: 2/2, step 4137/7134 completed (loss: 0.025644401088356972, acc: 0.990234375)
[2024-12-17 05:18:51,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:52,038][root][INFO] - Training Epoch: 2/2, step 4138/7134 completed (loss: 0.03096100315451622, acc: 0.9874607920646667)
[2024-12-17 05:18:52,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:52,438][root][INFO] - Training Epoch: 2/2, step 4139/7134 completed (loss: 0.017340416088700294, acc: 0.9978540539741516)
[2024-12-17 05:18:52,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:52,866][root][INFO] - Training Epoch: 2/2, step 4140/7134 completed (loss: 0.043874941766262054, acc: 0.9889655113220215)
[2024-12-17 05:18:53,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:53,355][root][INFO] - Training Epoch: 2/2, step 4141/7134 completed (loss: 0.0717678889632225, acc: 0.9799426794052124)
[2024-12-17 05:18:53,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:53,803][root][INFO] - Training Epoch: 2/2, step 4142/7134 completed (loss: 0.07702615857124329, acc: 0.9794050455093384)
[2024-12-17 05:18:53,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:54,276][root][INFO] - Training Epoch: 2/2, step 4143/7134 completed (loss: 0.047115955501794815, acc: 0.9897959232330322)
[2024-12-17 05:18:54,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:54,751][root][INFO] - Training Epoch: 2/2, step 4144/7134 completed (loss: 0.06876800209283829, acc: 0.9783599376678467)
[2024-12-17 05:18:54,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:55,184][root][INFO] - Training Epoch: 2/2, step 4145/7134 completed (loss: 0.037980880588293076, acc: 0.9909747242927551)
[2024-12-17 05:18:55,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:55,548][root][INFO] - Training Epoch: 2/2, step 4146/7134 completed (loss: 0.09911227226257324, acc: 0.9757575988769531)
[2024-12-17 05:18:55,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:55,963][root][INFO] - Training Epoch: 2/2, step 4147/7134 completed (loss: 0.08375808596611023, acc: 0.977011501789093)
[2024-12-17 05:18:56,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:56,369][root][INFO] - Training Epoch: 2/2, step 4148/7134 completed (loss: 0.12432201206684113, acc: 0.9671814441680908)
[2024-12-17 05:18:56,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:56,735][root][INFO] - Training Epoch: 2/2, step 4149/7134 completed (loss: 0.12859858572483063, acc: 0.9679999947547913)
[2024-12-17 05:18:56,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:57,141][root][INFO] - Training Epoch: 2/2, step 4150/7134 completed (loss: 0.10901657491922379, acc: 0.9698188900947571)
[2024-12-17 05:18:57,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:57,604][root][INFO] - Training Epoch: 2/2, step 4151/7134 completed (loss: 0.12397985905408859, acc: 0.9764492511749268)
[2024-12-17 05:18:57,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:58,047][root][INFO] - Training Epoch: 2/2, step 4152/7134 completed (loss: 0.05740945413708687, acc: 0.9829984307289124)
[2024-12-17 05:18:58,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:58,493][root][INFO] - Training Epoch: 2/2, step 4153/7134 completed (loss: 0.08555519580841064, acc: 0.9815950989723206)
[2024-12-17 05:18:58,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:58,977][root][INFO] - Training Epoch: 2/2, step 4154/7134 completed (loss: 0.04409793019294739, acc: 0.9861111044883728)
[2024-12-17 05:18:59,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:59,386][root][INFO] - Training Epoch: 2/2, step 4155/7134 completed (loss: 0.07016316801309586, acc: 0.9811320900917053)
[2024-12-17 05:18:59,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:18:59,832][root][INFO] - Training Epoch: 2/2, step 4156/7134 completed (loss: 0.06928294897079468, acc: 0.976356029510498)
[2024-12-17 05:18:59,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:00,232][root][INFO] - Training Epoch: 2/2, step 4157/7134 completed (loss: 0.046226684004068375, acc: 0.9880239367485046)
[2024-12-17 05:19:00,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:00,594][root][INFO] - Training Epoch: 2/2, step 4158/7134 completed (loss: 0.16151779890060425, acc: 0.9588689208030701)
[2024-12-17 05:19:00,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:01,044][root][INFO] - Training Epoch: 2/2, step 4159/7134 completed (loss: 0.04575476422905922, acc: 0.9881154298782349)
[2024-12-17 05:19:01,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:01,495][root][INFO] - Training Epoch: 2/2, step 4160/7134 completed (loss: 0.08009407669305801, acc: 0.9754716753959656)
[2024-12-17 05:19:01,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:01,970][root][INFO] - Training Epoch: 2/2, step 4161/7134 completed (loss: 0.047257065773010254, acc: 0.9839357137680054)
[2024-12-17 05:19:02,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:02,401][root][INFO] - Training Epoch: 2/2, step 4162/7134 completed (loss: 0.06385435163974762, acc: 0.9806259274482727)
[2024-12-17 05:19:02,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:02,840][root][INFO] - Training Epoch: 2/2, step 4163/7134 completed (loss: 0.07439285516738892, acc: 0.9803328514099121)
[2024-12-17 05:19:02,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:03,302][root][INFO] - Training Epoch: 2/2, step 4164/7134 completed (loss: 0.05273793637752533, acc: 0.9854862093925476)
[2024-12-17 05:19:03,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:03,761][root][INFO] - Training Epoch: 2/2, step 4165/7134 completed (loss: 0.05918978154659271, acc: 0.9850187301635742)
[2024-12-17 05:19:03,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:04,207][root][INFO] - Training Epoch: 2/2, step 4166/7134 completed (loss: 0.05436266213655472, acc: 0.98531574010849)
[2024-12-17 05:19:04,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:04,612][root][INFO] - Training Epoch: 2/2, step 4167/7134 completed (loss: 0.014249513857066631, acc: 0.9965277910232544)
[2024-12-17 05:19:04,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:05,050][root][INFO] - Training Epoch: 2/2, step 4168/7134 completed (loss: 0.045611485838890076, acc: 0.9861111044883728)
[2024-12-17 05:19:05,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:05,525][root][INFO] - Training Epoch: 2/2, step 4169/7134 completed (loss: 0.07011157274246216, acc: 0.985216498374939)
[2024-12-17 05:19:05,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:06,012][root][INFO] - Training Epoch: 2/2, step 4170/7134 completed (loss: 0.07893604785203934, acc: 0.9808917045593262)
[2024-12-17 05:19:06,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:06,519][root][INFO] - Training Epoch: 2/2, step 4171/7134 completed (loss: 0.033454399555921555, acc: 0.9884659647941589)
[2024-12-17 05:19:06,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:06,958][root][INFO] - Training Epoch: 2/2, step 4172/7134 completed (loss: 0.05815372243523598, acc: 0.9837905168533325)
[2024-12-17 05:19:07,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:07,370][root][INFO] - Training Epoch: 2/2, step 4173/7134 completed (loss: 0.06787525117397308, acc: 0.9871244430541992)
[2024-12-17 05:19:07,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:07,775][root][INFO] - Training Epoch: 2/2, step 4174/7134 completed (loss: 0.009450435638427734, acc: 0.9961685538291931)
[2024-12-17 05:19:07,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:08,216][root][INFO] - Training Epoch: 2/2, step 4175/7134 completed (loss: 0.027229778468608856, acc: 0.993127167224884)
[2024-12-17 05:19:08,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:08,657][root][INFO] - Training Epoch: 2/2, step 4176/7134 completed (loss: 0.01842142827808857, acc: 0.995529055595398)
[2024-12-17 05:19:08,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:09,136][root][INFO] - Training Epoch: 2/2, step 4177/7134 completed (loss: 0.020311985164880753, acc: 0.9934297204017639)
[2024-12-17 05:19:09,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:09,585][root][INFO] - Training Epoch: 2/2, step 4178/7134 completed (loss: 0.027829159051179886, acc: 0.9894259572029114)
[2024-12-17 05:19:09,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:10,078][root][INFO] - Training Epoch: 2/2, step 4179/7134 completed (loss: 0.01095558237284422, acc: 0.9960629940032959)
[2024-12-17 05:19:10,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:10,530][root][INFO] - Training Epoch: 2/2, step 4180/7134 completed (loss: 0.012793123722076416, acc: 0.994350254535675)
[2024-12-17 05:19:10,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:10,955][root][INFO] - Training Epoch: 2/2, step 4181/7134 completed (loss: 0.017788562923669815, acc: 0.995106041431427)
[2024-12-17 05:19:11,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:11,384][root][INFO] - Training Epoch: 2/2, step 4182/7134 completed (loss: 0.007331706117838621, acc: 0.998609185218811)
[2024-12-17 05:19:11,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:11,851][root][INFO] - Training Epoch: 2/2, step 4183/7134 completed (loss: 0.017399830743670464, acc: 0.9944367408752441)
[2024-12-17 05:19:11,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:12,267][root][INFO] - Training Epoch: 2/2, step 4184/7134 completed (loss: 0.03630447760224342, acc: 0.9907161593437195)
[2024-12-17 05:19:12,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:12,711][root][INFO] - Training Epoch: 2/2, step 4185/7134 completed (loss: 0.010906045325100422, acc: 0.9977169036865234)
[2024-12-17 05:19:12,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:13,174][root][INFO] - Training Epoch: 2/2, step 4186/7134 completed (loss: 0.07485237717628479, acc: 0.9843562245368958)
[2024-12-17 05:19:13,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:13,579][root][INFO] - Training Epoch: 2/2, step 4187/7134 completed (loss: 0.01902872510254383, acc: 0.99609375)
[2024-12-17 05:19:13,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:14,024][root][INFO] - Training Epoch: 2/2, step 4188/7134 completed (loss: 0.016437850892543793, acc: 0.9950000047683716)
[2024-12-17 05:19:14,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:14,468][root][INFO] - Training Epoch: 2/2, step 4189/7134 completed (loss: 0.016840852797031403, acc: 0.9986013770103455)
[2024-12-17 05:19:14,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:14,916][root][INFO] - Training Epoch: 2/2, step 4190/7134 completed (loss: 0.015459660440683365, acc: 0.9943181872367859)
[2024-12-17 05:19:15,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:15,264][root][INFO] - Training Epoch: 2/2, step 4191/7134 completed (loss: 0.03014405630528927, acc: 0.9884792566299438)
[2024-12-17 05:19:15,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:15,693][root][INFO] - Training Epoch: 2/2, step 4192/7134 completed (loss: 0.011237903498113155, acc: 0.9968051314353943)
[2024-12-17 05:19:15,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:16,145][root][INFO] - Training Epoch: 2/2, step 4193/7134 completed (loss: 0.025438977405428886, acc: 0.9946523904800415)
[2024-12-17 05:19:16,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:16,606][root][INFO] - Training Epoch: 2/2, step 4194/7134 completed (loss: 0.01218588836491108, acc: 0.9954614043235779)
[2024-12-17 05:19:16,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:17,033][root][INFO] - Training Epoch: 2/2, step 4195/7134 completed (loss: 0.06026200205087662, acc: 0.9878048896789551)
[2024-12-17 05:19:17,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:17,433][root][INFO] - Training Epoch: 2/2, step 4196/7134 completed (loss: 0.012661552987992764, acc: 0.9930796027183533)
[2024-12-17 05:19:17,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:17,892][root][INFO] - Training Epoch: 2/2, step 4197/7134 completed (loss: 0.028027638792991638, acc: 0.9922380447387695)
[2024-12-17 05:19:17,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:18,336][root][INFO] - Training Epoch: 2/2, step 4198/7134 completed (loss: 0.04179653152823448, acc: 0.9888888597488403)
[2024-12-17 05:19:18,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:18,741][root][INFO] - Training Epoch: 2/2, step 4199/7134 completed (loss: 0.029724622145295143, acc: 0.9872262477874756)
[2024-12-17 05:19:18,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:19,161][root][INFO] - Training Epoch: 2/2, step 4200/7134 completed (loss: 0.029921671375632286, acc: 0.9892473220825195)
[2024-12-17 05:19:19,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:19,592][root][INFO] - Training Epoch: 2/2, step 4201/7134 completed (loss: 0.013389583677053452, acc: 0.9965753555297852)
[2024-12-17 05:19:19,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:20,046][root][INFO] - Training Epoch: 2/2, step 4202/7134 completed (loss: 0.062343236058950424, acc: 0.9883720874786377)
[2024-12-17 05:19:20,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:20,513][root][INFO] - Training Epoch: 2/2, step 4203/7134 completed (loss: 0.04311709478497505, acc: 0.9906396269798279)
[2024-12-17 05:19:20,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:20,959][root][INFO] - Training Epoch: 2/2, step 4204/7134 completed (loss: 0.06447233259677887, acc: 0.9809941649436951)
[2024-12-17 05:19:21,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:21,387][root][INFO] - Training Epoch: 2/2, step 4205/7134 completed (loss: 0.028443994000554085, acc: 0.9956834316253662)
[2024-12-17 05:19:21,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:21,842][root][INFO] - Training Epoch: 2/2, step 4206/7134 completed (loss: 0.07234427332878113, acc: 0.9802538752555847)
[2024-12-17 05:19:21,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:22,285][root][INFO] - Training Epoch: 2/2, step 4207/7134 completed (loss: 0.07487565279006958, acc: 0.9840764403343201)
[2024-12-17 05:19:22,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:22,703][root][INFO] - Training Epoch: 2/2, step 4208/7134 completed (loss: 0.0820373073220253, acc: 0.9840510487556458)
[2024-12-17 05:19:22,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:23,127][root][INFO] - Training Epoch: 2/2, step 4209/7134 completed (loss: 0.07173382490873337, acc: 0.9830028414726257)
[2024-12-17 05:19:23,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:23,566][root][INFO] - Training Epoch: 2/2, step 4210/7134 completed (loss: 0.008765487931668758, acc: 0.9979550242424011)
[2024-12-17 05:19:23,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:23,953][root][INFO] - Training Epoch: 2/2, step 4211/7134 completed (loss: 0.036495160311460495, acc: 0.9907833933830261)
[2024-12-17 05:19:24,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:24,369][root][INFO] - Training Epoch: 2/2, step 4212/7134 completed (loss: 0.02670687437057495, acc: 0.9934533834457397)
[2024-12-17 05:19:24,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:24,814][root][INFO] - Training Epoch: 2/2, step 4213/7134 completed (loss: 0.0145271560177207, acc: 0.995708167552948)
[2024-12-17 05:19:24,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:25,303][root][INFO] - Training Epoch: 2/2, step 4214/7134 completed (loss: 0.05771982669830322, acc: 0.9850746393203735)
[2024-12-17 05:19:25,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:25,690][root][INFO] - Training Epoch: 2/2, step 4215/7134 completed (loss: 0.048743266612291336, acc: 0.9890109896659851)
[2024-12-17 05:19:25,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:26,093][root][INFO] - Training Epoch: 2/2, step 4216/7134 completed (loss: 0.04262964800000191, acc: 0.9872029423713684)
[2024-12-17 05:19:26,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:26,477][root][INFO] - Training Epoch: 2/2, step 4217/7134 completed (loss: 0.02253204770386219, acc: 0.9902098178863525)
[2024-12-17 05:19:26,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:26,843][root][INFO] - Training Epoch: 2/2, step 4218/7134 completed (loss: 0.05979504436254501, acc: 0.9896907210350037)
[2024-12-17 05:19:26,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:27,166][root][INFO] - Training Epoch: 2/2, step 4219/7134 completed (loss: 0.034580063074827194, acc: 0.9879518151283264)
[2024-12-17 05:19:27,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:27,607][root][INFO] - Training Epoch: 2/2, step 4220/7134 completed (loss: 0.040471576154232025, acc: 0.9913669228553772)
[2024-12-17 05:19:27,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:28,091][root][INFO] - Training Epoch: 2/2, step 4221/7134 completed (loss: 0.02048431895673275, acc: 0.9929203391075134)
[2024-12-17 05:19:28,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:28,507][root][INFO] - Training Epoch: 2/2, step 4222/7134 completed (loss: 0.13009847700595856, acc: 0.9755555391311646)
[2024-12-17 05:19:28,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:28,924][root][INFO] - Training Epoch: 2/2, step 4223/7134 completed (loss: 0.04250633344054222, acc: 0.9894039630889893)
[2024-12-17 05:19:29,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:29,330][root][INFO] - Training Epoch: 2/2, step 4224/7134 completed (loss: 0.07274797558784485, acc: 0.9805615544319153)
[2024-12-17 05:19:29,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:29,766][root][INFO] - Training Epoch: 2/2, step 4225/7134 completed (loss: 0.08846232295036316, acc: 0.9813242554664612)
[2024-12-17 05:19:29,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:30,211][root][INFO] - Training Epoch: 2/2, step 4226/7134 completed (loss: 0.051544904708862305, acc: 0.9885057210922241)
[2024-12-17 05:19:30,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:30,581][root][INFO] - Training Epoch: 2/2, step 4227/7134 completed (loss: 0.11107278615236282, acc: 0.9852579832077026)
[2024-12-17 05:19:30,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:30,999][root][INFO] - Training Epoch: 2/2, step 4228/7134 completed (loss: 0.12716235220432281, acc: 0.9655172228813171)
[2024-12-17 05:19:31,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:31,422][root][INFO] - Training Epoch: 2/2, step 4229/7134 completed (loss: 0.08429032564163208, acc: 0.9832285046577454)
[2024-12-17 05:19:31,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:31,818][root][INFO] - Training Epoch: 2/2, step 4230/7134 completed (loss: 0.057406190782785416, acc: 0.9852941036224365)
[2024-12-17 05:19:31,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:32,244][root][INFO] - Training Epoch: 2/2, step 4231/7134 completed (loss: 0.16427959501743317, acc: 0.9650092124938965)
[2024-12-17 05:19:32,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:32,661][root][INFO] - Training Epoch: 2/2, step 4232/7134 completed (loss: 0.10365895181894302, acc: 0.970992386341095)
[2024-12-17 05:19:32,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:33,089][root][INFO] - Training Epoch: 2/2, step 4233/7134 completed (loss: 0.0666683092713356, acc: 0.9799666404724121)
[2024-12-17 05:19:33,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:33,501][root][INFO] - Training Epoch: 2/2, step 4234/7134 completed (loss: 0.04815588891506195, acc: 0.9904610514640808)
[2024-12-17 05:19:33,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:33,952][root][INFO] - Training Epoch: 2/2, step 4235/7134 completed (loss: 0.04799358546733856, acc: 0.9873617887496948)
[2024-12-17 05:19:34,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:34,352][root][INFO] - Training Epoch: 2/2, step 4236/7134 completed (loss: 0.012852360494434834, acc: 1.0)
[2024-12-17 05:19:34,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:34,771][root][INFO] - Training Epoch: 2/2, step 4237/7134 completed (loss: 0.024671802297234535, acc: 0.9979381561279297)
[2024-12-17 05:19:34,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:35,196][root][INFO] - Training Epoch: 2/2, step 4238/7134 completed (loss: 0.05479205772280693, acc: 0.9885433912277222)
[2024-12-17 05:19:35,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:35,588][root][INFO] - Training Epoch: 2/2, step 4239/7134 completed (loss: 0.024745626375079155, acc: 0.9919999837875366)
[2024-12-17 05:19:35,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:35,992][root][INFO] - Training Epoch: 2/2, step 4240/7134 completed (loss: 0.050116125494241714, acc: 0.993537962436676)
[2024-12-17 05:19:36,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:36,414][root][INFO] - Training Epoch: 2/2, step 4241/7134 completed (loss: 0.015051656402647495, acc: 0.9978308081626892)
[2024-12-17 05:19:36,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:36,850][root][INFO] - Training Epoch: 2/2, step 4242/7134 completed (loss: 0.0479300282895565, acc: 0.9910913109779358)
[2024-12-17 05:19:36,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:37,311][root][INFO] - Training Epoch: 2/2, step 4243/7134 completed (loss: 0.06789746880531311, acc: 0.9873417615890503)
[2024-12-17 05:19:37,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:37,706][root][INFO] - Training Epoch: 2/2, step 4244/7134 completed (loss: 0.037232521921396255, acc: 0.9933481216430664)
[2024-12-17 05:19:37,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:38,066][root][INFO] - Training Epoch: 2/2, step 4245/7134 completed (loss: 0.03606349602341652, acc: 0.9926650524139404)
[2024-12-17 05:19:38,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:38,482][root][INFO] - Training Epoch: 2/2, step 4246/7134 completed (loss: 0.04691321402788162, acc: 0.9920760989189148)
[2024-12-17 05:19:38,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:38,879][root][INFO] - Training Epoch: 2/2, step 4247/7134 completed (loss: 0.02334141917526722, acc: 0.9928698539733887)
[2024-12-17 05:19:38,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:39,315][root][INFO] - Training Epoch: 2/2, step 4248/7134 completed (loss: 0.06382118165493011, acc: 0.9823718070983887)
[2024-12-17 05:19:39,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:39,811][root][INFO] - Training Epoch: 2/2, step 4249/7134 completed (loss: 0.05853526294231415, acc: 0.9888888597488403)
[2024-12-17 05:19:39,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:40,182][root][INFO] - Training Epoch: 2/2, step 4250/7134 completed (loss: 0.06919220834970474, acc: 0.987261176109314)
[2024-12-17 05:19:40,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:40,590][root][INFO] - Training Epoch: 2/2, step 4251/7134 completed (loss: 0.02559320628643036, acc: 0.9934210777282715)
[2024-12-17 05:19:40,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:41,011][root][INFO] - Training Epoch: 2/2, step 4252/7134 completed (loss: 0.04657718539237976, acc: 0.9872813820838928)
[2024-12-17 05:19:41,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:41,429][root][INFO] - Training Epoch: 2/2, step 4253/7134 completed (loss: 0.05040241405367851, acc: 0.9913232326507568)
[2024-12-17 05:19:41,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:41,812][root][INFO] - Training Epoch: 2/2, step 4254/7134 completed (loss: 0.0229348111897707, acc: 0.9925187230110168)
[2024-12-17 05:19:41,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:42,258][root][INFO] - Training Epoch: 2/2, step 4255/7134 completed (loss: 0.03222274035215378, acc: 0.9914383292198181)
[2024-12-17 05:19:42,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:42,657][root][INFO] - Training Epoch: 2/2, step 4256/7134 completed (loss: 0.033351585268974304, acc: 0.9909502267837524)
[2024-12-17 05:19:42,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:43,081][root][INFO] - Training Epoch: 2/2, step 4257/7134 completed (loss: 0.020505070686340332, acc: 0.9946523904800415)
[2024-12-17 05:19:43,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:43,507][root][INFO] - Training Epoch: 2/2, step 4258/7134 completed (loss: 0.010961397551000118, acc: 0.9980915784835815)
[2024-12-17 05:19:43,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:43,951][root][INFO] - Training Epoch: 2/2, step 4259/7134 completed (loss: 0.06959021836519241, acc: 0.984240710735321)
[2024-12-17 05:19:44,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:44,389][root][INFO] - Training Epoch: 2/2, step 4260/7134 completed (loss: 0.02239377610385418, acc: 0.9937888383865356)
[2024-12-17 05:19:44,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:44,806][root][INFO] - Training Epoch: 2/2, step 4261/7134 completed (loss: 0.025077322497963905, acc: 0.990439772605896)
[2024-12-17 05:19:44,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:45,242][root][INFO] - Training Epoch: 2/2, step 4262/7134 completed (loss: 0.026868239045143127, acc: 0.9874804615974426)
[2024-12-17 05:19:45,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:45,669][root][INFO] - Training Epoch: 2/2, step 4263/7134 completed (loss: 0.06332149356603622, acc: 0.9898648858070374)
[2024-12-17 05:19:45,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:46,083][root][INFO] - Training Epoch: 2/2, step 4264/7134 completed (loss: 0.047382138669490814, acc: 0.9837296605110168)
[2024-12-17 05:19:46,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:46,518][root][INFO] - Training Epoch: 2/2, step 4265/7134 completed (loss: 0.020149126648902893, acc: 0.9949495196342468)
[2024-12-17 05:19:46,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:46,983][root][INFO] - Training Epoch: 2/2, step 4266/7134 completed (loss: 0.028414132073521614, acc: 0.9928143620491028)
[2024-12-17 05:19:47,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:47,446][root][INFO] - Training Epoch: 2/2, step 4267/7134 completed (loss: 0.027708927169442177, acc: 0.9915151596069336)
[2024-12-17 05:19:47,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:47,888][root][INFO] - Training Epoch: 2/2, step 4268/7134 completed (loss: 0.06156075745820999, acc: 0.9819639325141907)
[2024-12-17 05:19:48,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:48,354][root][INFO] - Training Epoch: 2/2, step 4269/7134 completed (loss: 0.10468454658985138, acc: 0.9669064879417419)
[2024-12-17 05:19:48,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:48,812][root][INFO] - Training Epoch: 2/2, step 4270/7134 completed (loss: 0.05316206440329552, acc: 0.9817708134651184)
[2024-12-17 05:19:48,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:49,266][root][INFO] - Training Epoch: 2/2, step 4271/7134 completed (loss: 0.029698196798563004, acc: 0.9863013625144958)
[2024-12-17 05:19:49,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:49,735][root][INFO] - Training Epoch: 2/2, step 4272/7134 completed (loss: 0.036667320877313614, acc: 0.9906103014945984)
[2024-12-17 05:19:49,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:50,184][root][INFO] - Training Epoch: 2/2, step 4273/7134 completed (loss: 0.0323905386030674, acc: 0.9849435091018677)
[2024-12-17 05:19:50,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:50,648][root][INFO] - Training Epoch: 2/2, step 4274/7134 completed (loss: 0.06516552716493607, acc: 0.9824766516685486)
[2024-12-17 05:19:50,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:51,084][root][INFO] - Training Epoch: 2/2, step 4275/7134 completed (loss: 0.02478659525513649, acc: 0.9924242496490479)
[2024-12-17 05:19:51,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:51,529][root][INFO] - Training Epoch: 2/2, step 4276/7134 completed (loss: 0.06123291701078415, acc: 0.9845361113548279)
[2024-12-17 05:19:51,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:51,945][root][INFO] - Training Epoch: 2/2, step 4277/7134 completed (loss: 0.024024248123168945, acc: 0.9904761910438538)
[2024-12-17 05:19:52,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:52,398][root][INFO] - Training Epoch: 2/2, step 4278/7134 completed (loss: 0.03637857362627983, acc: 0.990123450756073)
[2024-12-17 05:19:52,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:52,856][root][INFO] - Training Epoch: 2/2, step 4279/7134 completed (loss: 0.03649556636810303, acc: 0.992559552192688)
[2024-12-17 05:19:52,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:53,303][root][INFO] - Training Epoch: 2/2, step 4280/7134 completed (loss: 0.007093091960996389, acc: 0.9984126687049866)
[2024-12-17 05:19:53,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:53,770][root][INFO] - Training Epoch: 2/2, step 4281/7134 completed (loss: 0.05056161805987358, acc: 0.9851484894752502)
[2024-12-17 05:19:53,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:54,211][root][INFO] - Training Epoch: 2/2, step 4282/7134 completed (loss: 0.00852266140282154, acc: 0.9981481432914734)
[2024-12-17 05:19:54,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:54,670][root][INFO] - Training Epoch: 2/2, step 4283/7134 completed (loss: 0.018056880682706833, acc: 0.9919725060462952)
[2024-12-17 05:19:54,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:55,044][root][INFO] - Training Epoch: 2/2, step 4284/7134 completed (loss: 0.03740371763706207, acc: 0.9927536249160767)
[2024-12-17 05:19:55,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:55,480][root][INFO] - Training Epoch: 2/2, step 4285/7134 completed (loss: 0.02558755874633789, acc: 0.9863013625144958)
[2024-12-17 05:19:55,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:55,878][root][INFO] - Training Epoch: 2/2, step 4286/7134 completed (loss: 0.04707372933626175, acc: 0.9874100685119629)
[2024-12-17 05:19:56,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:56,319][root][INFO] - Training Epoch: 2/2, step 4287/7134 completed (loss: 0.0685131698846817, acc: 0.9806700944900513)
[2024-12-17 05:19:56,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:56,772][root][INFO] - Training Epoch: 2/2, step 4288/7134 completed (loss: 0.0409361869096756, acc: 0.9858155846595764)
[2024-12-17 05:19:56,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:57,236][root][INFO] - Training Epoch: 2/2, step 4289/7134 completed (loss: 0.04552021995186806, acc: 0.9819548726081848)
[2024-12-17 05:19:57,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:57,678][root][INFO] - Training Epoch: 2/2, step 4290/7134 completed (loss: 0.033693935722112656, acc: 0.9905277490615845)
[2024-12-17 05:19:57,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:58,119][root][INFO] - Training Epoch: 2/2, step 4291/7134 completed (loss: 0.018587086349725723, acc: 0.9940405488014221)
[2024-12-17 05:19:58,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:58,537][root][INFO] - Training Epoch: 2/2, step 4292/7134 completed (loss: 0.022141851484775543, acc: 0.9969879388809204)
[2024-12-17 05:19:58,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:58,944][root][INFO] - Training Epoch: 2/2, step 4293/7134 completed (loss: 0.012693515978753567, acc: 0.9959677457809448)
[2024-12-17 05:19:59,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:59,353][root][INFO] - Training Epoch: 2/2, step 4294/7134 completed (loss: 0.015314968302845955, acc: 0.9941775798797607)
[2024-12-17 05:19:59,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:19:59,795][root][INFO] - Training Epoch: 2/2, step 4295/7134 completed (loss: 0.030409011989831924, acc: 0.9908758997917175)
[2024-12-17 05:19:59,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:00,218][root][INFO] - Training Epoch: 2/2, step 4296/7134 completed (loss: 0.032719507813453674, acc: 0.9975669384002686)
[2024-12-17 05:20:00,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:00,637][root][INFO] - Training Epoch: 2/2, step 4297/7134 completed (loss: 0.020638594403862953, acc: 0.9953051805496216)
[2024-12-17 05:20:00,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:01,067][root][INFO] - Training Epoch: 2/2, step 4298/7134 completed (loss: 0.032744936645030975, acc: 0.993122398853302)
[2024-12-17 05:20:01,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:01,512][root][INFO] - Training Epoch: 2/2, step 4299/7134 completed (loss: 0.025593705475330353, acc: 0.9899713397026062)
[2024-12-17 05:20:01,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:01,964][root][INFO] - Training Epoch: 2/2, step 4300/7134 completed (loss: 0.012765646912157536, acc: 0.9956140518188477)
[2024-12-17 05:20:02,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:02,391][root][INFO] - Training Epoch: 2/2, step 4301/7134 completed (loss: 0.04091697931289673, acc: 0.9901639223098755)
[2024-12-17 05:20:02,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:02,819][root][INFO] - Training Epoch: 2/2, step 4302/7134 completed (loss: 0.010786431841552258, acc: 0.9970149397850037)
[2024-12-17 05:20:02,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:03,280][root][INFO] - Training Epoch: 2/2, step 4303/7134 completed (loss: 0.037279967218637466, acc: 0.9904534816741943)
[2024-12-17 05:20:03,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:03,734][root][INFO] - Training Epoch: 2/2, step 4304/7134 completed (loss: 0.021129002794623375, acc: 0.9925705790519714)
[2024-12-17 05:20:03,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:04,206][root][INFO] - Training Epoch: 2/2, step 4305/7134 completed (loss: 0.024530282244086266, acc: 0.9929577708244324)
[2024-12-17 05:20:04,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:04,656][root][INFO] - Training Epoch: 2/2, step 4306/7134 completed (loss: 0.07052560895681381, acc: 0.9842312932014465)
[2024-12-17 05:20:04,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:05,092][root][INFO] - Training Epoch: 2/2, step 4307/7134 completed (loss: 0.06338749825954437, acc: 0.9807383418083191)
[2024-12-17 05:20:05,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:05,549][root][INFO] - Training Epoch: 2/2, step 4308/7134 completed (loss: 0.04397430270910263, acc: 0.9872390031814575)
[2024-12-17 05:20:05,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:06,031][root][INFO] - Training Epoch: 2/2, step 4309/7134 completed (loss: 0.03161053732037544, acc: 0.9901356101036072)
[2024-12-17 05:20:06,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:06,481][root][INFO] - Training Epoch: 2/2, step 4310/7134 completed (loss: 0.027626480907201767, acc: 0.9941245317459106)
[2024-12-17 05:20:06,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:06,899][root][INFO] - Training Epoch: 2/2, step 4311/7134 completed (loss: 0.019169699400663376, acc: 0.9956521987915039)
[2024-12-17 05:20:06,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:07,315][root][INFO] - Training Epoch: 2/2, step 4312/7134 completed (loss: 0.019178234040737152, acc: 0.9959127902984619)
[2024-12-17 05:20:07,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:07,746][root][INFO] - Training Epoch: 2/2, step 4313/7134 completed (loss: 0.017815910279750824, acc: 0.9935064911842346)
[2024-12-17 05:20:07,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:08,243][root][INFO] - Training Epoch: 2/2, step 4314/7134 completed (loss: 0.024677477777004242, acc: 0.9924471378326416)
[2024-12-17 05:20:08,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:08,690][root][INFO] - Training Epoch: 2/2, step 4315/7134 completed (loss: 0.028528418391942978, acc: 0.9934640526771545)
[2024-12-17 05:20:08,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:09,130][root][INFO] - Training Epoch: 2/2, step 4316/7134 completed (loss: 0.037220101803541183, acc: 0.9872449040412903)
[2024-12-17 05:20:09,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:09,576][root][INFO] - Training Epoch: 2/2, step 4317/7134 completed (loss: 0.038630615919828415, acc: 0.9900867342948914)
[2024-12-17 05:20:09,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:10,032][root][INFO] - Training Epoch: 2/2, step 4318/7134 completed (loss: 0.025820251554250717, acc: 0.9921524524688721)
[2024-12-17 05:20:10,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:10,506][root][INFO] - Training Epoch: 2/2, step 4319/7134 completed (loss: 0.010371466167271137, acc: 0.997770369052887)
[2024-12-17 05:20:10,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:10,917][root][INFO] - Training Epoch: 2/2, step 4320/7134 completed (loss: 0.021016646176576614, acc: 0.995945930480957)
[2024-12-17 05:20:11,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:11,320][root][INFO] - Training Epoch: 2/2, step 4321/7134 completed (loss: 0.03409642353653908, acc: 0.9907621145248413)
[2024-12-17 05:20:11,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:11,763][root][INFO] - Training Epoch: 2/2, step 4322/7134 completed (loss: 0.03484632819890976, acc: 0.9905660152435303)
[2024-12-17 05:20:11,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:12,173][root][INFO] - Training Epoch: 2/2, step 4323/7134 completed (loss: 0.06694769114255905, acc: 0.9768785834312439)
[2024-12-17 05:20:12,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:12,562][root][INFO] - Training Epoch: 2/2, step 4324/7134 completed (loss: 0.02252095751464367, acc: 0.9922480583190918)
[2024-12-17 05:20:12,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:12,980][root][INFO] - Training Epoch: 2/2, step 4325/7134 completed (loss: 0.030538760125637054, acc: 0.9936203956604004)
[2024-12-17 05:20:13,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:13,431][root][INFO] - Training Epoch: 2/2, step 4326/7134 completed (loss: 0.030160043388605118, acc: 0.9894366264343262)
[2024-12-17 05:20:13,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:13,825][root][INFO] - Training Epoch: 2/2, step 4327/7134 completed (loss: 0.02282997965812683, acc: 0.9912587404251099)
[2024-12-17 05:20:13,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:14,242][root][INFO] - Training Epoch: 2/2, step 4328/7134 completed (loss: 0.05312023684382439, acc: 0.9849624037742615)
[2024-12-17 05:20:14,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:14,689][root][INFO] - Training Epoch: 2/2, step 4329/7134 completed (loss: 0.03902169689536095, acc: 0.9895150661468506)
[2024-12-17 05:20:14,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:15,059][root][INFO] - Training Epoch: 2/2, step 4330/7134 completed (loss: 0.046305831521749496, acc: 0.9872068166732788)
[2024-12-17 05:20:15,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:15,437][root][INFO] - Training Epoch: 2/2, step 4331/7134 completed (loss: 0.012259182520210743, acc: 0.9943342804908752)
[2024-12-17 05:20:15,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:15,901][root][INFO] - Training Epoch: 2/2, step 4332/7134 completed (loss: 0.04659932851791382, acc: 0.9847908616065979)
[2024-12-17 05:20:16,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:16,326][root][INFO] - Training Epoch: 2/2, step 4333/7134 completed (loss: 0.025985630229115486, acc: 0.9939302206039429)
[2024-12-17 05:20:16,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:16,809][root][INFO] - Training Epoch: 2/2, step 4334/7134 completed (loss: 0.03580129146575928, acc: 0.9880239367485046)
[2024-12-17 05:20:16,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:17,222][root][INFO] - Training Epoch: 2/2, step 4335/7134 completed (loss: 0.03408240154385567, acc: 0.9899193644523621)
[2024-12-17 05:20:17,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:17,648][root][INFO] - Training Epoch: 2/2, step 4336/7134 completed (loss: 0.00824925396591425, acc: 0.9967637658119202)
[2024-12-17 05:20:17,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:18,059][root][INFO] - Training Epoch: 2/2, step 4337/7134 completed (loss: 0.024190565571188927, acc: 0.9905063509941101)
[2024-12-17 05:20:18,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:18,466][root][INFO] - Training Epoch: 2/2, step 4338/7134 completed (loss: 0.012602422386407852, acc: 0.9968404173851013)
[2024-12-17 05:20:18,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:18,882][root][INFO] - Training Epoch: 2/2, step 4339/7134 completed (loss: 0.0333218052983284, acc: 0.9897959232330322)
[2024-12-17 05:20:18,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:19,338][root][INFO] - Training Epoch: 2/2, step 4340/7134 completed (loss: 0.02934292145073414, acc: 0.9898648858070374)
[2024-12-17 05:20:19,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:19,757][root][INFO] - Training Epoch: 2/2, step 4341/7134 completed (loss: 0.044811587780714035, acc: 0.98959881067276)
[2024-12-17 05:20:19,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:20,225][root][INFO] - Training Epoch: 2/2, step 4342/7134 completed (loss: 0.035241685807704926, acc: 0.9903846383094788)
[2024-12-17 05:20:20,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:20,659][root][INFO] - Training Epoch: 2/2, step 4343/7134 completed (loss: 0.030519865453243256, acc: 0.9933444261550903)
[2024-12-17 05:20:20,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:21,053][root][INFO] - Training Epoch: 2/2, step 4344/7134 completed (loss: 0.0067017050459980965, acc: 1.0)
[2024-12-17 05:20:21,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:21,423][root][INFO] - Training Epoch: 2/2, step 4345/7134 completed (loss: 0.02004864811897278, acc: 0.9917184114456177)
[2024-12-17 05:20:21,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:21,802][root][INFO] - Training Epoch: 2/2, step 4346/7134 completed (loss: 0.00837558601051569, acc: 1.0)
[2024-12-17 05:20:21,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:22,216][root][INFO] - Training Epoch: 2/2, step 4347/7134 completed (loss: 0.04728392884135246, acc: 0.9915134310722351)
[2024-12-17 05:20:22,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:22,614][root][INFO] - Training Epoch: 2/2, step 4348/7134 completed (loss: 0.014835881069302559, acc: 0.995199978351593)
[2024-12-17 05:20:22,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:23,020][root][INFO] - Training Epoch: 2/2, step 4349/7134 completed (loss: 0.009796581231057644, acc: 0.9976905584335327)
[2024-12-17 05:20:23,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:23,474][root][INFO] - Training Epoch: 2/2, step 4350/7134 completed (loss: 0.022789759561419487, acc: 0.9947643876075745)
[2024-12-17 05:20:23,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:23,907][root][INFO] - Training Epoch: 2/2, step 4351/7134 completed (loss: 0.04835103079676628, acc: 0.9862825870513916)
[2024-12-17 05:20:24,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:24,374][root][INFO] - Training Epoch: 2/2, step 4352/7134 completed (loss: 0.034859269857406616, acc: 0.9847908616065979)
[2024-12-17 05:20:24,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:24,829][root][INFO] - Training Epoch: 2/2, step 4353/7134 completed (loss: 0.033600933849811554, acc: 0.990728497505188)
[2024-12-17 05:20:24,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:25,270][root][INFO] - Training Epoch: 2/2, step 4354/7134 completed (loss: 0.03305387869477272, acc: 0.9893333315849304)
[2024-12-17 05:20:25,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:25,694][root][INFO] - Training Epoch: 2/2, step 4355/7134 completed (loss: 0.034743327647447586, acc: 0.991239070892334)
[2024-12-17 05:20:25,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:26,154][root][INFO] - Training Epoch: 2/2, step 4356/7134 completed (loss: 0.02658039890229702, acc: 0.9916368126869202)
[2024-12-17 05:20:26,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:26,612][root][INFO] - Training Epoch: 2/2, step 4357/7134 completed (loss: 0.047671861946582794, acc: 0.9889763593673706)
[2024-12-17 05:20:26,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:27,078][root][INFO] - Training Epoch: 2/2, step 4358/7134 completed (loss: 0.036508675664663315, acc: 0.9892215728759766)
[2024-12-17 05:20:27,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:27,512][root][INFO] - Training Epoch: 2/2, step 4359/7134 completed (loss: 0.040044985711574554, acc: 0.9825673699378967)
[2024-12-17 05:20:27,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:27,918][root][INFO] - Training Epoch: 2/2, step 4360/7134 completed (loss: 0.054359208792448044, acc: 0.9874301552772522)
[2024-12-17 05:20:28,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:28,349][root][INFO] - Training Epoch: 2/2, step 4361/7134 completed (loss: 0.02284049056470394, acc: 0.9942196607589722)
[2024-12-17 05:20:28,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:28,802][root][INFO] - Training Epoch: 2/2, step 4362/7134 completed (loss: 0.028201645240187645, acc: 0.9913686513900757)
[2024-12-17 05:20:28,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:29,260][root][INFO] - Training Epoch: 2/2, step 4363/7134 completed (loss: 0.032968919724226, acc: 0.9900826215744019)
[2024-12-17 05:20:29,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:29,680][root][INFO] - Training Epoch: 2/2, step 4364/7134 completed (loss: 0.0150501299649477, acc: 0.9937499761581421)
[2024-12-17 05:20:29,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:30,110][root][INFO] - Training Epoch: 2/2, step 4365/7134 completed (loss: 0.0225079208612442, acc: 0.9921383857727051)
[2024-12-17 05:20:30,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:30,559][root][INFO] - Training Epoch: 2/2, step 4366/7134 completed (loss: 0.07139836996793747, acc: 0.9793814420700073)
[2024-12-17 05:20:30,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:31,001][root][INFO] - Training Epoch: 2/2, step 4367/7134 completed (loss: 0.02163790352642536, acc: 0.9942693114280701)
[2024-12-17 05:20:31,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:31,450][root][INFO] - Training Epoch: 2/2, step 4368/7134 completed (loss: 0.014930232428014278, acc: 0.994962215423584)
[2024-12-17 05:20:31,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:31,886][root][INFO] - Training Epoch: 2/2, step 4369/7134 completed (loss: 0.01575697399675846, acc: 0.9950000047683716)
[2024-12-17 05:20:32,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:32,335][root][INFO] - Training Epoch: 2/2, step 4370/7134 completed (loss: 0.04411368444561958, acc: 0.9886506795883179)
[2024-12-17 05:20:32,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:32,781][root][INFO] - Training Epoch: 2/2, step 4371/7134 completed (loss: 0.03375198319554329, acc: 0.9868074059486389)
[2024-12-17 05:20:32,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:33,197][root][INFO] - Training Epoch: 2/2, step 4372/7134 completed (loss: 0.03321630880236626, acc: 0.9931153059005737)
[2024-12-17 05:20:33,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:33,644][root][INFO] - Training Epoch: 2/2, step 4373/7134 completed (loss: 0.009339135140180588, acc: 0.9976218938827515)
[2024-12-17 05:20:33,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:34,077][root][INFO] - Training Epoch: 2/2, step 4374/7134 completed (loss: 0.03406964987516403, acc: 0.9899280667304993)
[2024-12-17 05:20:34,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:34,521][root][INFO] - Training Epoch: 2/2, step 4375/7134 completed (loss: 0.02065158076584339, acc: 0.9884169697761536)
[2024-12-17 05:20:34,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:34,919][root][INFO] - Training Epoch: 2/2, step 4376/7134 completed (loss: 0.026840152218937874, acc: 0.9954751133918762)
[2024-12-17 05:20:35,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:35,380][root][INFO] - Training Epoch: 2/2, step 4377/7134 completed (loss: 0.05613979697227478, acc: 0.988875150680542)
[2024-12-17 05:20:35,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:35,809][root][INFO] - Training Epoch: 2/2, step 4378/7134 completed (loss: 0.03327036648988724, acc: 0.991830050945282)
[2024-12-17 05:20:35,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:36,274][root][INFO] - Training Epoch: 2/2, step 4379/7134 completed (loss: 0.06106182187795639, acc: 0.9829545617103577)
[2024-12-17 05:20:36,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:36,676][root][INFO] - Training Epoch: 2/2, step 4380/7134 completed (loss: 0.0562128908932209, acc: 0.985989511013031)
[2024-12-17 05:20:36,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:37,129][root][INFO] - Training Epoch: 2/2, step 4381/7134 completed (loss: 0.017445839941501617, acc: 0.9944827556610107)
[2024-12-17 05:20:37,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:37,522][root][INFO] - Training Epoch: 2/2, step 4382/7134 completed (loss: 0.01735217683017254, acc: 0.995230495929718)
[2024-12-17 05:20:37,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:37,958][root][INFO] - Training Epoch: 2/2, step 4383/7134 completed (loss: 0.0327305942773819, acc: 0.9862448573112488)
[2024-12-17 05:20:38,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:38,364][root][INFO] - Training Epoch: 2/2, step 4384/7134 completed (loss: 0.02145947888493538, acc: 0.9924623370170593)
[2024-12-17 05:20:38,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:38,810][root][INFO] - Training Epoch: 2/2, step 4385/7134 completed (loss: 0.06827715039253235, acc: 0.979139506816864)
[2024-12-17 05:20:38,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:39,254][root][INFO] - Training Epoch: 2/2, step 4386/7134 completed (loss: 0.03922964632511139, acc: 0.9893364906311035)
[2024-12-17 05:20:39,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:39,714][root][INFO] - Training Epoch: 2/2, step 4387/7134 completed (loss: 0.04183477163314819, acc: 0.9838969111442566)
[2024-12-17 05:20:39,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:40,145][root][INFO] - Training Epoch: 2/2, step 4388/7134 completed (loss: 0.03239361569285393, acc: 0.9906832575798035)
[2024-12-17 05:20:40,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:40,571][root][INFO] - Training Epoch: 2/2, step 4389/7134 completed (loss: 0.05589059367775917, acc: 0.985318124294281)
[2024-12-17 05:20:40,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:41,078][root][INFO] - Training Epoch: 2/2, step 4390/7134 completed (loss: 0.07188547402620316, acc: 0.9789621233940125)
[2024-12-17 05:20:41,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:41,497][root][INFO] - Training Epoch: 2/2, step 4391/7134 completed (loss: 0.061745017766952515, acc: 0.9837133288383484)
[2024-12-17 05:20:41,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:41,936][root][INFO] - Training Epoch: 2/2, step 4392/7134 completed (loss: 0.03101242333650589, acc: 0.9950980544090271)
[2024-12-17 05:20:42,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:42,383][root][INFO] - Training Epoch: 2/2, step 4393/7134 completed (loss: 0.02428101748228073, acc: 0.9915611743927002)
[2024-12-17 05:20:42,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:42,835][root][INFO] - Training Epoch: 2/2, step 4394/7134 completed (loss: 0.025433264672756195, acc: 0.9929478168487549)
[2024-12-17 05:20:42,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:43,244][root][INFO] - Training Epoch: 2/2, step 4395/7134 completed (loss: 0.041137512773275375, acc: 0.9827315807342529)
[2024-12-17 05:20:43,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:43,672][root][INFO] - Training Epoch: 2/2, step 4396/7134 completed (loss: 0.07760723680257797, acc: 0.9756097793579102)
[2024-12-17 05:20:43,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:44,075][root][INFO] - Training Epoch: 2/2, step 4397/7134 completed (loss: 0.04697151482105255, acc: 0.9858823418617249)
[2024-12-17 05:20:44,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:44,503][root][INFO] - Training Epoch: 2/2, step 4398/7134 completed (loss: 0.012523421086370945, acc: 0.9924242496490479)
[2024-12-17 05:20:44,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:44,929][root][INFO] - Training Epoch: 2/2, step 4399/7134 completed (loss: 0.04510510340332985, acc: 0.9903537034988403)
[2024-12-17 05:20:45,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:45,385][root][INFO] - Training Epoch: 2/2, step 4400/7134 completed (loss: 0.07113363593816757, acc: 0.983890950679779)
[2024-12-17 05:20:45,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:45,803][root][INFO] - Training Epoch: 2/2, step 4401/7134 completed (loss: 0.07393685728311539, acc: 0.9855072498321533)
[2024-12-17 05:20:45,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:46,232][root][INFO] - Training Epoch: 2/2, step 4402/7134 completed (loss: 0.12107334285974503, acc: 0.9680232405662537)
[2024-12-17 05:20:46,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:46,671][root][INFO] - Training Epoch: 2/2, step 4403/7134 completed (loss: 0.13989147543907166, acc: 0.9663212299346924)
[2024-12-17 05:20:46,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:47,098][root][INFO] - Training Epoch: 2/2, step 4404/7134 completed (loss: 0.1174851506948471, acc: 0.9640957713127136)
[2024-12-17 05:20:47,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:47,566][root][INFO] - Training Epoch: 2/2, step 4405/7134 completed (loss: 0.02304752916097641, acc: 0.9946004152297974)
[2024-12-17 05:20:47,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:48,057][root][INFO] - Training Epoch: 2/2, step 4406/7134 completed (loss: 0.03422994166612625, acc: 0.9899777173995972)
[2024-12-17 05:20:48,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:48,519][root][INFO] - Training Epoch: 2/2, step 4407/7134 completed (loss: 0.05396774038672447, acc: 0.981502890586853)
[2024-12-17 05:20:48,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:48,963][root][INFO] - Training Epoch: 2/2, step 4408/7134 completed (loss: 0.04860889911651611, acc: 0.9848661422729492)
[2024-12-17 05:20:49,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:49,403][root][INFO] - Training Epoch: 2/2, step 4409/7134 completed (loss: 0.060810573399066925, acc: 0.9877750873565674)
[2024-12-17 05:20:49,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:49,827][root][INFO] - Training Epoch: 2/2, step 4410/7134 completed (loss: 0.053100068122148514, acc: 0.9892473220825195)
[2024-12-17 05:20:49,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:50,253][root][INFO] - Training Epoch: 2/2, step 4411/7134 completed (loss: 0.10427094250917435, acc: 0.9683453440666199)
[2024-12-17 05:20:50,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:50,671][root][INFO] - Training Epoch: 2/2, step 4412/7134 completed (loss: 0.15447451174259186, acc: 0.955089807510376)
[2024-12-17 05:20:50,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:51,101][root][INFO] - Training Epoch: 2/2, step 4413/7134 completed (loss: 0.10646508634090424, acc: 0.9755101799964905)
[2024-12-17 05:20:51,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:51,525][root][INFO] - Training Epoch: 2/2, step 4414/7134 completed (loss: 0.04353591054677963, acc: 0.9881516695022583)
[2024-12-17 05:20:51,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:51,970][root][INFO] - Training Epoch: 2/2, step 4415/7134 completed (loss: 0.04686061665415764, acc: 0.9800747036933899)
[2024-12-17 05:20:52,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:52,429][root][INFO] - Training Epoch: 2/2, step 4416/7134 completed (loss: 0.057234104722738266, acc: 0.9871645569801331)
[2024-12-17 05:20:52,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:52,872][root][INFO] - Training Epoch: 2/2, step 4417/7134 completed (loss: 0.07351413369178772, acc: 0.9831730723381042)
[2024-12-17 05:20:53,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:53,320][root][INFO] - Training Epoch: 2/2, step 4418/7134 completed (loss: 0.05588902160525322, acc: 0.9830729365348816)
[2024-12-17 05:20:53,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:53,741][root][INFO] - Training Epoch: 2/2, step 4419/7134 completed (loss: 0.06981112062931061, acc: 0.979567289352417)
[2024-12-17 05:20:53,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:54,186][root][INFO] - Training Epoch: 2/2, step 4420/7134 completed (loss: 0.08605238050222397, acc: 0.9709543585777283)
[2024-12-17 05:20:54,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:54,642][root][INFO] - Training Epoch: 2/2, step 4421/7134 completed (loss: 0.05503387376666069, acc: 0.9865016937255859)
[2024-12-17 05:20:54,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:55,082][root][INFO] - Training Epoch: 2/2, step 4422/7134 completed (loss: 0.07830382138490677, acc: 0.9811617136001587)
[2024-12-17 05:20:55,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:55,535][root][INFO] - Training Epoch: 2/2, step 4423/7134 completed (loss: 0.050666600465774536, acc: 0.9863013625144958)
[2024-12-17 05:20:55,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:55,988][root][INFO] - Training Epoch: 2/2, step 4424/7134 completed (loss: 0.04263650253415108, acc: 0.9849849939346313)
[2024-12-17 05:20:56,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:56,441][root][INFO] - Training Epoch: 2/2, step 4425/7134 completed (loss: 0.024792911484837532, acc: 0.9894737005233765)
[2024-12-17 05:20:56,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:56,937][root][INFO] - Training Epoch: 2/2, step 4426/7134 completed (loss: 0.05164114758372307, acc: 0.9844881296157837)
[2024-12-17 05:20:57,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:57,305][root][INFO] - Training Epoch: 2/2, step 4427/7134 completed (loss: 0.09647523611783981, acc: 0.966265082359314)
[2024-12-17 05:20:57,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:57,770][root][INFO] - Training Epoch: 2/2, step 4428/7134 completed (loss: 0.02364354021847248, acc: 0.9943661689758301)
[2024-12-17 05:20:57,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:58,144][root][INFO] - Training Epoch: 2/2, step 4429/7134 completed (loss: 0.057743728160858154, acc: 0.9768041372299194)
[2024-12-17 05:20:58,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:58,582][root][INFO] - Training Epoch: 2/2, step 4430/7134 completed (loss: 0.043791212141513824, acc: 0.9862805008888245)
[2024-12-17 05:20:58,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:58,985][root][INFO] - Training Epoch: 2/2, step 4431/7134 completed (loss: 0.04627404734492302, acc: 0.9813374876976013)
[2024-12-17 05:20:59,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:59,405][root][INFO] - Training Epoch: 2/2, step 4432/7134 completed (loss: 0.014433649368584156, acc: 0.9938555955886841)
[2024-12-17 05:20:59,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:20:59,878][root][INFO] - Training Epoch: 2/2, step 4433/7134 completed (loss: 0.03941968455910683, acc: 0.9918414950370789)
[2024-12-17 05:21:00,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:00,314][root][INFO] - Training Epoch: 2/2, step 4434/7134 completed (loss: 0.030833249911665916, acc: 0.9864864945411682)
[2024-12-17 05:21:00,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:00,724][root][INFO] - Training Epoch: 2/2, step 4435/7134 completed (loss: 0.03012847900390625, acc: 0.9870610237121582)
[2024-12-17 05:21:00,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:01,199][root][INFO] - Training Epoch: 2/2, step 4436/7134 completed (loss: 0.045670438557863235, acc: 0.9818435907363892)
[2024-12-17 05:21:01,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:01,626][root][INFO] - Training Epoch: 2/2, step 4437/7134 completed (loss: 0.014821341261267662, acc: 0.9960629940032959)
[2024-12-17 05:21:01,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:02,046][root][INFO] - Training Epoch: 2/2, step 4438/7134 completed (loss: 0.03331182524561882, acc: 0.991525411605835)
[2024-12-17 05:21:02,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:02,471][root][INFO] - Training Epoch: 2/2, step 4439/7134 completed (loss: 0.02312045358121395, acc: 0.9918699264526367)
[2024-12-17 05:21:02,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:02,886][root][INFO] - Training Epoch: 2/2, step 4440/7134 completed (loss: 0.031701769679784775, acc: 0.9903314709663391)
[2024-12-17 05:21:03,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:03,372][root][INFO] - Training Epoch: 2/2, step 4441/7134 completed (loss: 0.028260406106710434, acc: 0.9892473220825195)
[2024-12-17 05:21:03,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:03,819][root][INFO] - Training Epoch: 2/2, step 4442/7134 completed (loss: 0.07470401376485825, acc: 0.9897040128707886)
[2024-12-17 05:21:03,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:04,275][root][INFO] - Training Epoch: 2/2, step 4443/7134 completed (loss: 0.03728866949677467, acc: 0.9923076629638672)
[2024-12-17 05:21:04,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:04,689][root][INFO] - Training Epoch: 2/2, step 4444/7134 completed (loss: 0.029035169631242752, acc: 0.9934747219085693)
[2024-12-17 05:21:04,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:05,107][root][INFO] - Training Epoch: 2/2, step 4445/7134 completed (loss: 0.03699556365609169, acc: 0.9832402467727661)
[2024-12-17 05:21:05,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:05,539][root][INFO] - Training Epoch: 2/2, step 4446/7134 completed (loss: 0.021294109523296356, acc: 0.988727867603302)
[2024-12-17 05:21:05,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:06,008][root][INFO] - Training Epoch: 2/2, step 4447/7134 completed (loss: 0.02843598462641239, acc: 0.9917452931404114)
[2024-12-17 05:21:06,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:06,458][root][INFO] - Training Epoch: 2/2, step 4448/7134 completed (loss: 0.03711559250950813, acc: 0.9835466146469116)
[2024-12-17 05:21:06,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:06,880][root][INFO] - Training Epoch: 2/2, step 4449/7134 completed (loss: 0.054617516696453094, acc: 0.9814126491546631)
[2024-12-17 05:21:07,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:07,316][root][INFO] - Training Epoch: 2/2, step 4450/7134 completed (loss: 0.037993695586919785, acc: 0.9851852059364319)
[2024-12-17 05:21:07,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:07,735][root][INFO] - Training Epoch: 2/2, step 4451/7134 completed (loss: 0.10255192220211029, acc: 0.9800994992256165)
[2024-12-17 05:21:07,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:08,188][root][INFO] - Training Epoch: 2/2, step 4452/7134 completed (loss: 0.015532942488789558, acc: 0.995199978351593)
[2024-12-17 05:21:08,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:08,614][root][INFO] - Training Epoch: 2/2, step 4453/7134 completed (loss: 0.047648169100284576, acc: 0.9918032884597778)
[2024-12-17 05:21:08,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:09,031][root][INFO] - Training Epoch: 2/2, step 4454/7134 completed (loss: 0.03336654230952263, acc: 0.9915013909339905)
[2024-12-17 05:21:09,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:09,402][root][INFO] - Training Epoch: 2/2, step 4455/7134 completed (loss: 0.08858782798051834, acc: 0.9861878156661987)
[2024-12-17 05:21:09,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:09,830][root][INFO] - Training Epoch: 2/2, step 4456/7134 completed (loss: 0.013649272732436657, acc: 0.9983818531036377)
[2024-12-17 05:21:09,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:10,198][root][INFO] - Training Epoch: 2/2, step 4457/7134 completed (loss: 0.021564261987805367, acc: 0.9887640476226807)
[2024-12-17 05:21:10,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:10,626][root][INFO] - Training Epoch: 2/2, step 4458/7134 completed (loss: 0.014821912162005901, acc: 0.9918166995048523)
[2024-12-17 05:21:10,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:11,062][root][INFO] - Training Epoch: 2/2, step 4459/7134 completed (loss: 0.019041983410716057, acc: 0.9931318759918213)
[2024-12-17 05:21:11,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:11,495][root][INFO] - Training Epoch: 2/2, step 4460/7134 completed (loss: 0.02087205834686756, acc: 0.9926650524139404)
[2024-12-17 05:21:11,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:11,927][root][INFO] - Training Epoch: 2/2, step 4461/7134 completed (loss: 0.053548265248537064, acc: 0.9901599287986755)
[2024-12-17 05:21:12,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:12,364][root][INFO] - Training Epoch: 2/2, step 4462/7134 completed (loss: 0.011808467097580433, acc: 0.9959127902984619)
[2024-12-17 05:21:12,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:12,809][root][INFO] - Training Epoch: 2/2, step 4463/7134 completed (loss: 0.026794886216521263, acc: 0.9937106966972351)
[2024-12-17 05:21:12,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:13,265][root][INFO] - Training Epoch: 2/2, step 4464/7134 completed (loss: 0.04658127948641777, acc: 0.9865092635154724)
[2024-12-17 05:21:13,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:13,709][root][INFO] - Training Epoch: 2/2, step 4465/7134 completed (loss: 0.014653562568128109, acc: 0.9948453903198242)
[2024-12-17 05:21:13,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:14,158][root][INFO] - Training Epoch: 2/2, step 4466/7134 completed (loss: 0.01771770790219307, acc: 0.9938271641731262)
[2024-12-17 05:21:14,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:14,613][root][INFO] - Training Epoch: 2/2, step 4467/7134 completed (loss: 0.02308497577905655, acc: 0.9937185645103455)
[2024-12-17 05:21:14,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:15,046][root][INFO] - Training Epoch: 2/2, step 4468/7134 completed (loss: 0.013245049864053726, acc: 0.9976218938827515)
[2024-12-17 05:21:15,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:15,492][root][INFO] - Training Epoch: 2/2, step 4469/7134 completed (loss: 0.028827248141169548, acc: 0.9907514452934265)
[2024-12-17 05:21:15,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:15,960][root][INFO] - Training Epoch: 2/2, step 4470/7134 completed (loss: 0.013661639764904976, acc: 0.9966850876808167)
[2024-12-17 05:21:16,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:16,392][root][INFO] - Training Epoch: 2/2, step 4471/7134 completed (loss: 0.00956753920763731, acc: 0.9987714886665344)
[2024-12-17 05:21:16,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:16,806][root][INFO] - Training Epoch: 2/2, step 4472/7134 completed (loss: 0.0315769799053669, acc: 0.990777313709259)
[2024-12-17 05:21:16,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:17,229][root][INFO] - Training Epoch: 2/2, step 4473/7134 completed (loss: 0.05808761715888977, acc: 0.9859943985939026)
[2024-12-17 05:21:17,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:17,655][root][INFO] - Training Epoch: 2/2, step 4474/7134 completed (loss: 0.06451597809791565, acc: 0.9832636117935181)
[2024-12-17 05:21:17,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:18,102][root][INFO] - Training Epoch: 2/2, step 4475/7134 completed (loss: 0.08696617186069489, acc: 0.977667510509491)
[2024-12-17 05:21:18,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:18,548][root][INFO] - Training Epoch: 2/2, step 4476/7134 completed (loss: 0.06083318591117859, acc: 0.9807956218719482)
[2024-12-17 05:21:18,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:18,986][root][INFO] - Training Epoch: 2/2, step 4477/7134 completed (loss: 0.007032489404082298, acc: 0.9963325262069702)
[2024-12-17 05:21:19,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:19,435][root][INFO] - Training Epoch: 2/2, step 4478/7134 completed (loss: 0.016285685822367668, acc: 0.9975278377532959)
[2024-12-17 05:21:19,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:19,857][root][INFO] - Training Epoch: 2/2, step 4479/7134 completed (loss: 0.014075826853513718, acc: 0.9946091771125793)
[2024-12-17 05:21:19,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:20,314][root][INFO] - Training Epoch: 2/2, step 4480/7134 completed (loss: 0.02525581791996956, acc: 0.9941588640213013)
[2024-12-17 05:21:20,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:20,767][root][INFO] - Training Epoch: 2/2, step 4481/7134 completed (loss: 0.03194426745176315, acc: 0.9929906725883484)
[2024-12-17 05:21:20,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:21,211][root][INFO] - Training Epoch: 2/2, step 4482/7134 completed (loss: 0.01332077570259571, acc: 0.9964028596878052)
[2024-12-17 05:21:21,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:21,615][root][INFO] - Training Epoch: 2/2, step 4483/7134 completed (loss: 0.021803202107548714, acc: 0.9910846948623657)
[2024-12-17 05:21:21,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:22,065][root][INFO] - Training Epoch: 2/2, step 4484/7134 completed (loss: 0.011446835473179817, acc: 0.9973545074462891)
[2024-12-17 05:21:22,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:22,505][root][INFO] - Training Epoch: 2/2, step 4485/7134 completed (loss: 0.010686674155294895, acc: 0.9954057931900024)
[2024-12-17 05:21:22,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:22,903][root][INFO] - Training Epoch: 2/2, step 4486/7134 completed (loss: 0.00730916066095233, acc: 0.9970149397850037)
[2024-12-17 05:21:23,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:23,328][root][INFO] - Training Epoch: 2/2, step 4487/7134 completed (loss: 0.00697775324806571, acc: 0.9986206889152527)
[2024-12-17 05:21:23,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:23,708][root][INFO] - Training Epoch: 2/2, step 4488/7134 completed (loss: 0.012616590596735477, acc: 0.9946042895317078)
[2024-12-17 05:21:23,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:24,156][root][INFO] - Training Epoch: 2/2, step 4489/7134 completed (loss: 0.014069824479520321, acc: 0.993127167224884)
[2024-12-17 05:21:24,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:24,584][root][INFO] - Training Epoch: 2/2, step 4490/7134 completed (loss: 0.026610666885972023, acc: 0.9907407164573669)
[2024-12-17 05:21:24,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:24,992][root][INFO] - Training Epoch: 2/2, step 4491/7134 completed (loss: 0.004397454671561718, acc: 1.0)
[2024-12-17 05:21:25,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:25,391][root][INFO] - Training Epoch: 2/2, step 4492/7134 completed (loss: 0.010038685984909534, acc: 0.9963235259056091)
[2024-12-17 05:21:25,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:25,800][root][INFO] - Training Epoch: 2/2, step 4493/7134 completed (loss: 0.005790376104414463, acc: 0.9986245036125183)
[2024-12-17 05:21:25,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:26,230][root][INFO] - Training Epoch: 2/2, step 4494/7134 completed (loss: 0.01823004148900509, acc: 0.9927641153335571)
[2024-12-17 05:21:26,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:26,667][root][INFO] - Training Epoch: 2/2, step 4495/7134 completed (loss: 0.010654513724148273, acc: 0.9974457025527954)
[2024-12-17 05:21:26,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:27,092][root][INFO] - Training Epoch: 2/2, step 4496/7134 completed (loss: 0.020886745303869247, acc: 0.9928774833679199)
[2024-12-17 05:21:27,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:27,525][root][INFO] - Training Epoch: 2/2, step 4497/7134 completed (loss: 0.013115286827087402, acc: 0.9973509907722473)
[2024-12-17 05:21:27,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:27,956][root][INFO] - Training Epoch: 2/2, step 4498/7134 completed (loss: 0.04623391106724739, acc: 0.9927431344985962)
[2024-12-17 05:21:28,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:28,353][root][INFO] - Training Epoch: 2/2, step 4499/7134 completed (loss: 0.027223890647292137, acc: 0.9930434823036194)
[2024-12-17 05:21:28,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:28,792][root][INFO] - Training Epoch: 2/2, step 4500/7134 completed (loss: 0.016876336187124252, acc: 0.9958041906356812)
[2024-12-17 05:21:28,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:29,204][root][INFO] - Training Epoch: 2/2, step 4501/7134 completed (loss: 0.014590253122150898, acc: 0.9917920827865601)
[2024-12-17 05:21:29,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:29,593][root][INFO] - Training Epoch: 2/2, step 4502/7134 completed (loss: 0.01202858705073595, acc: 0.9970015287399292)
[2024-12-17 05:21:29,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:29,969][root][INFO] - Training Epoch: 2/2, step 4503/7134 completed (loss: 0.009332156740128994, acc: 0.9983948469161987)
[2024-12-17 05:21:30,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:30,396][root][INFO] - Training Epoch: 2/2, step 4504/7134 completed (loss: 0.034005630761384964, acc: 0.988041877746582)
[2024-12-17 05:21:30,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:30,845][root][INFO] - Training Epoch: 2/2, step 4505/7134 completed (loss: 0.021791832521557808, acc: 0.9914004802703857)
[2024-12-17 05:21:30,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:31,262][root][INFO] - Training Epoch: 2/2, step 4506/7134 completed (loss: 0.02547261118888855, acc: 0.992277979850769)
[2024-12-17 05:21:31,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:31,689][root][INFO] - Training Epoch: 2/2, step 4507/7134 completed (loss: 0.02154850959777832, acc: 0.9943100810050964)
[2024-12-17 05:21:31,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:32,116][root][INFO] - Training Epoch: 2/2, step 4508/7134 completed (loss: 0.042197808623313904, acc: 0.9886040091514587)
[2024-12-17 05:21:32,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:32,572][root][INFO] - Training Epoch: 2/2, step 4509/7134 completed (loss: 0.0300968699157238, acc: 0.990604043006897)
[2024-12-17 05:21:32,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:33,016][root][INFO] - Training Epoch: 2/2, step 4510/7134 completed (loss: 0.04464465752243996, acc: 0.9901269674301147)
[2024-12-17 05:21:33,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:33,467][root][INFO] - Training Epoch: 2/2, step 4511/7134 completed (loss: 0.054778628051280975, acc: 0.9817159175872803)
[2024-12-17 05:21:33,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:33,893][root][INFO] - Training Epoch: 2/2, step 4512/7134 completed (loss: 0.029854439198970795, acc: 0.9874551892280579)
[2024-12-17 05:21:33,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:34,337][root][INFO] - Training Epoch: 2/2, step 4513/7134 completed (loss: 0.01953023672103882, acc: 0.9943820238113403)
[2024-12-17 05:21:34,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:34,783][root][INFO] - Training Epoch: 2/2, step 4514/7134 completed (loss: 0.07910361886024475, acc: 0.9868612885475159)
[2024-12-17 05:21:34,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:35,225][root][INFO] - Training Epoch: 2/2, step 4515/7134 completed (loss: 0.032963089644908905, acc: 0.9925373196601868)
[2024-12-17 05:21:35,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:35,653][root][INFO] - Training Epoch: 2/2, step 4516/7134 completed (loss: 0.026231417432427406, acc: 0.9877601265907288)
[2024-12-17 05:21:35,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:36,106][root][INFO] - Training Epoch: 2/2, step 4517/7134 completed (loss: 0.03541158139705658, acc: 0.991037130355835)
[2024-12-17 05:21:36,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:36,561][root][INFO] - Training Epoch: 2/2, step 4518/7134 completed (loss: 0.04297582432627678, acc: 0.9923469424247742)
[2024-12-17 05:21:36,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:37,004][root][INFO] - Training Epoch: 2/2, step 4519/7134 completed (loss: 0.02352643944323063, acc: 0.9927448630332947)
[2024-12-17 05:21:37,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:37,437][root][INFO] - Training Epoch: 2/2, step 4520/7134 completed (loss: 0.030491091310977936, acc: 0.9872881174087524)
[2024-12-17 05:21:37,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:37,901][root][INFO] - Training Epoch: 2/2, step 4521/7134 completed (loss: 0.03941303864121437, acc: 0.9927797913551331)
[2024-12-17 05:21:37,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:38,344][root][INFO] - Training Epoch: 2/2, step 4522/7134 completed (loss: 0.03934333100914955, acc: 0.984886646270752)
[2024-12-17 05:21:38,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:38,789][root][INFO] - Training Epoch: 2/2, step 4523/7134 completed (loss: 0.027147773653268814, acc: 0.9881656765937805)
[2024-12-17 05:21:38,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:39,254][root][INFO] - Training Epoch: 2/2, step 4524/7134 completed (loss: 0.046915680170059204, acc: 0.9892037510871887)
[2024-12-17 05:21:39,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:39,689][root][INFO] - Training Epoch: 2/2, step 4525/7134 completed (loss: 0.025475293397903442, acc: 0.9933333396911621)
[2024-12-17 05:21:39,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:40,114][root][INFO] - Training Epoch: 2/2, step 4526/7134 completed (loss: 0.037142064422369, acc: 0.9858064651489258)
[2024-12-17 05:21:40,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:40,597][root][INFO] - Training Epoch: 2/2, step 4527/7134 completed (loss: 0.015449325554072857, acc: 0.9933110475540161)
[2024-12-17 05:21:40,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:41,046][root][INFO] - Training Epoch: 2/2, step 4528/7134 completed (loss: 0.03927087038755417, acc: 0.9884318709373474)
[2024-12-17 05:21:41,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:41,465][root][INFO] - Training Epoch: 2/2, step 4529/7134 completed (loss: 0.04825616255402565, acc: 0.9870466589927673)
[2024-12-17 05:21:41,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:41,936][root][INFO] - Training Epoch: 2/2, step 4530/7134 completed (loss: 0.01530773937702179, acc: 0.9985994100570679)
[2024-12-17 05:21:42,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:42,387][root][INFO] - Training Epoch: 2/2, step 4531/7134 completed (loss: 0.018580298870801926, acc: 0.9928186535835266)
[2024-12-17 05:21:42,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:42,845][root][INFO] - Training Epoch: 2/2, step 4532/7134 completed (loss: 0.037444308400154114, acc: 0.9900398254394531)
[2024-12-17 05:21:42,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:43,279][root][INFO] - Training Epoch: 2/2, step 4533/7134 completed (loss: 0.016281239688396454, acc: 0.9964413046836853)
[2024-12-17 05:21:43,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:43,733][root][INFO] - Training Epoch: 2/2, step 4534/7134 completed (loss: 0.019569337368011475, acc: 0.9929577708244324)
[2024-12-17 05:21:43,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:44,175][root][INFO] - Training Epoch: 2/2, step 4535/7134 completed (loss: 0.01825055293738842, acc: 0.9954441785812378)
[2024-12-17 05:21:44,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:44,652][root][INFO] - Training Epoch: 2/2, step 4536/7134 completed (loss: 0.027903251349925995, acc: 0.9913793206214905)
[2024-12-17 05:21:44,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:45,112][root][INFO] - Training Epoch: 2/2, step 4537/7134 completed (loss: 0.009083551354706287, acc: 0.9955307245254517)
[2024-12-17 05:21:45,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:45,574][root][INFO] - Training Epoch: 2/2, step 4538/7134 completed (loss: 0.026544736698269844, acc: 0.9954022765159607)
[2024-12-17 05:21:45,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:46,043][root][INFO] - Training Epoch: 2/2, step 4539/7134 completed (loss: 0.023119322955608368, acc: 0.9913700222969055)
[2024-12-17 05:21:46,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:46,497][root][INFO] - Training Epoch: 2/2, step 4540/7134 completed (loss: 0.02752775326371193, acc: 0.9913294911384583)
[2024-12-17 05:21:46,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:46,867][root][INFO] - Training Epoch: 2/2, step 4541/7134 completed (loss: 0.05126553028821945, acc: 0.9815195202827454)
[2024-12-17 05:21:46,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:47,240][root][INFO] - Training Epoch: 2/2, step 4542/7134 completed (loss: 0.06513432413339615, acc: 0.9826839566230774)
[2024-12-17 05:21:47,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:47,645][root][INFO] - Training Epoch: 2/2, step 4543/7134 completed (loss: 0.07172412425279617, acc: 0.976827085018158)
[2024-12-17 05:21:47,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:48,076][root][INFO] - Training Epoch: 2/2, step 4544/7134 completed (loss: 0.039968859404325485, acc: 0.9893292784690857)
[2024-12-17 05:21:48,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:48,485][root][INFO] - Training Epoch: 2/2, step 4545/7134 completed (loss: 0.05620604008436203, acc: 0.978805422782898)
[2024-12-17 05:21:48,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:48,889][root][INFO] - Training Epoch: 2/2, step 4546/7134 completed (loss: 0.04247395694255829, acc: 0.9932773113250732)
[2024-12-17 05:21:48,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:49,289][root][INFO] - Training Epoch: 2/2, step 4547/7134 completed (loss: 0.02382722496986389, acc: 0.991349458694458)
[2024-12-17 05:21:49,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:49,723][root][INFO] - Training Epoch: 2/2, step 4548/7134 completed (loss: 0.03210460767149925, acc: 0.9867330193519592)
[2024-12-17 05:21:49,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:50,083][root][INFO] - Training Epoch: 2/2, step 4549/7134 completed (loss: 0.05564107373356819, acc: 0.9828326106071472)
[2024-12-17 05:21:50,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:50,523][root][INFO] - Training Epoch: 2/2, step 4550/7134 completed (loss: 0.0579502172768116, acc: 0.9916247725486755)
[2024-12-17 05:21:50,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:50,930][root][INFO] - Training Epoch: 2/2, step 4551/7134 completed (loss: 0.033354684710502625, acc: 0.991428554058075)
[2024-12-17 05:21:51,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:51,323][root][INFO] - Training Epoch: 2/2, step 4552/7134 completed (loss: 0.023770663887262344, acc: 0.9923809766769409)
[2024-12-17 05:21:51,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:51,723][root][INFO] - Training Epoch: 2/2, step 4553/7134 completed (loss: 0.024405166506767273, acc: 0.9932318329811096)
[2024-12-17 05:21:51,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:52,141][root][INFO] - Training Epoch: 2/2, step 4554/7134 completed (loss: 0.04893379285931587, acc: 0.9855855703353882)
[2024-12-17 05:21:52,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:52,552][root][INFO] - Training Epoch: 2/2, step 4555/7134 completed (loss: 0.05895049124956131, acc: 0.9806094169616699)
[2024-12-17 05:21:52,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:53,003][root][INFO] - Training Epoch: 2/2, step 4556/7134 completed (loss: 0.056303855031728745, acc: 0.9789473414421082)
[2024-12-17 05:21:53,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:53,366][root][INFO] - Training Epoch: 2/2, step 4557/7134 completed (loss: 0.05633154883980751, acc: 0.985401451587677)
[2024-12-17 05:21:53,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:53,777][root][INFO] - Training Epoch: 2/2, step 4558/7134 completed (loss: 0.0427558608353138, acc: 0.9865319728851318)
[2024-12-17 05:21:53,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:54,199][root][INFO] - Training Epoch: 2/2, step 4559/7134 completed (loss: 0.05060785636305809, acc: 0.9882352948188782)
[2024-12-17 05:21:54,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:54,605][root][INFO] - Training Epoch: 2/2, step 4560/7134 completed (loss: 0.023375188931822777, acc: 0.9945651888847351)
[2024-12-17 05:21:54,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:54,989][root][INFO] - Training Epoch: 2/2, step 4561/7134 completed (loss: 0.05268813669681549, acc: 0.9843137264251709)
[2024-12-17 05:21:55,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:55,387][root][INFO] - Training Epoch: 2/2, step 4562/7134 completed (loss: 0.043893881142139435, acc: 0.988950252532959)
[2024-12-17 05:21:55,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:55,827][root][INFO] - Training Epoch: 2/2, step 4563/7134 completed (loss: 0.03227245435118675, acc: 0.9908397197723389)
[2024-12-17 05:21:55,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:56,288][root][INFO] - Training Epoch: 2/2, step 4564/7134 completed (loss: 0.04372537136077881, acc: 0.9873060584068298)
[2024-12-17 05:21:56,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:56,676][root][INFO] - Training Epoch: 2/2, step 4565/7134 completed (loss: 0.03928174450993538, acc: 0.9866156578063965)
[2024-12-17 05:21:56,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:57,086][root][INFO] - Training Epoch: 2/2, step 4566/7134 completed (loss: 0.02353188395500183, acc: 0.9946236610412598)
[2024-12-17 05:21:57,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:57,509][root][INFO] - Training Epoch: 2/2, step 4567/7134 completed (loss: 0.009930686093866825, acc: 0.9963235259056091)
[2024-12-17 05:21:57,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:57,917][root][INFO] - Training Epoch: 2/2, step 4568/7134 completed (loss: 0.06639330834150314, acc: 0.9862385392189026)
[2024-12-17 05:21:58,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:58,328][root][INFO] - Training Epoch: 2/2, step 4569/7134 completed (loss: 0.012426575645804405, acc: 0.998039186000824)
[2024-12-17 05:21:58,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:58,740][root][INFO] - Training Epoch: 2/2, step 4570/7134 completed (loss: 0.023788711056113243, acc: 0.9868804812431335)
[2024-12-17 05:21:58,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:59,172][root][INFO] - Training Epoch: 2/2, step 4571/7134 completed (loss: 0.031339775770902634, acc: 0.9922978281974792)
[2024-12-17 05:21:59,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:21:59,608][root][INFO] - Training Epoch: 2/2, step 4572/7134 completed (loss: 0.03411997854709625, acc: 0.9906542301177979)
[2024-12-17 05:21:59,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:00,063][root][INFO] - Training Epoch: 2/2, step 4573/7134 completed (loss: 0.028564944863319397, acc: 0.9929971694946289)
[2024-12-17 05:22:00,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:00,491][root][INFO] - Training Epoch: 2/2, step 4574/7134 completed (loss: 0.019308200106024742, acc: 0.9893993139266968)
[2024-12-17 05:22:00,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:00,932][root][INFO] - Training Epoch: 2/2, step 4575/7134 completed (loss: 0.028018388897180557, acc: 0.9933510422706604)
[2024-12-17 05:22:01,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:01,361][root][INFO] - Training Epoch: 2/2, step 4576/7134 completed (loss: 0.01315397024154663, acc: 0.9974905848503113)
[2024-12-17 05:22:01,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:01,781][root][INFO] - Training Epoch: 2/2, step 4577/7134 completed (loss: 0.03029601462185383, acc: 0.9915730357170105)
[2024-12-17 05:22:01,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:02,220][root][INFO] - Training Epoch: 2/2, step 4578/7134 completed (loss: 0.01767200231552124, acc: 0.9956331849098206)
[2024-12-17 05:22:02,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:02,647][root][INFO] - Training Epoch: 2/2, step 4579/7134 completed (loss: 0.050054751336574554, acc: 0.9920760989189148)
[2024-12-17 05:22:02,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:03,089][root][INFO] - Training Epoch: 2/2, step 4580/7134 completed (loss: 0.01943272538483143, acc: 0.9925373196601868)
[2024-12-17 05:22:03,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:03,513][root][INFO] - Training Epoch: 2/2, step 4581/7134 completed (loss: 0.018392710015177727, acc: 0.9929453134536743)
[2024-12-17 05:22:03,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:03,943][root][INFO] - Training Epoch: 2/2, step 4582/7134 completed (loss: 0.013006829656660557, acc: 0.9967105388641357)
[2024-12-17 05:22:04,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:04,377][root][INFO] - Training Epoch: 2/2, step 4583/7134 completed (loss: 0.010294321924448013, acc: 0.9983659982681274)
[2024-12-17 05:22:04,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:04,816][root][INFO] - Training Epoch: 2/2, step 4584/7134 completed (loss: 0.013723735697567463, acc: 0.9951691031455994)
[2024-12-17 05:22:04,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:05,244][root][INFO] - Training Epoch: 2/2, step 4585/7134 completed (loss: 0.04364323243498802, acc: 0.9935275316238403)
[2024-12-17 05:22:05,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:05,695][root][INFO] - Training Epoch: 2/2, step 4586/7134 completed (loss: 0.02638866938650608, acc: 0.9895969033241272)
[2024-12-17 05:22:05,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:06,123][root][INFO] - Training Epoch: 2/2, step 4587/7134 completed (loss: 0.024608060717582703, acc: 0.9945205450057983)
[2024-12-17 05:22:06,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:06,549][root][INFO] - Training Epoch: 2/2, step 4588/7134 completed (loss: 0.04289926961064339, acc: 0.9869186282157898)
[2024-12-17 05:22:06,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:06,945][root][INFO] - Training Epoch: 2/2, step 4589/7134 completed (loss: 0.04354395717382431, acc: 0.9865269660949707)
[2024-12-17 05:22:07,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:07,406][root][INFO] - Training Epoch: 2/2, step 4590/7134 completed (loss: 0.03126741200685501, acc: 0.9917126893997192)
[2024-12-17 05:22:07,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:07,839][root][INFO] - Training Epoch: 2/2, step 4591/7134 completed (loss: 0.02571556158363819, acc: 0.9907651543617249)
[2024-12-17 05:22:07,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:08,243][root][INFO] - Training Epoch: 2/2, step 4592/7134 completed (loss: 0.037157878279685974, acc: 0.9869375824928284)
[2024-12-17 05:22:08,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:08,663][root][INFO] - Training Epoch: 2/2, step 4593/7134 completed (loss: 0.029473459348082542, acc: 0.9940740466117859)
[2024-12-17 05:22:08,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:09,117][root][INFO] - Training Epoch: 2/2, step 4594/7134 completed (loss: 0.04584038257598877, acc: 0.9879999756813049)
[2024-12-17 05:22:09,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:09,548][root][INFO] - Training Epoch: 2/2, step 4595/7134 completed (loss: 0.03050287812948227, acc: 0.9881129264831543)
[2024-12-17 05:22:09,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:09,969][root][INFO] - Training Epoch: 2/2, step 4596/7134 completed (loss: 0.045489732176065445, acc: 0.9841269850730896)
[2024-12-17 05:22:10,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:10,409][root][INFO] - Training Epoch: 2/2, step 4597/7134 completed (loss: 0.019528206437826157, acc: 0.9951397180557251)
[2024-12-17 05:22:10,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:10,858][root][INFO] - Training Epoch: 2/2, step 4598/7134 completed (loss: 0.05509784445166588, acc: 0.987730085849762)
[2024-12-17 05:22:10,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:11,254][root][INFO] - Training Epoch: 2/2, step 4599/7134 completed (loss: 0.015521460212767124, acc: 0.995230495929718)
[2024-12-17 05:22:11,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:11,681][root][INFO] - Training Epoch: 2/2, step 4600/7134 completed (loss: 0.02488885261118412, acc: 0.9878214001655579)
[2024-12-17 05:22:11,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:12,153][root][INFO] - Training Epoch: 2/2, step 4601/7134 completed (loss: 0.043157078325748444, acc: 0.9856584072113037)
[2024-12-17 05:22:12,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:12,589][root][INFO] - Training Epoch: 2/2, step 4602/7134 completed (loss: 0.03650366887450218, acc: 0.9877384305000305)
[2024-12-17 05:22:12,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:13,021][root][INFO] - Training Epoch: 2/2, step 4603/7134 completed (loss: 0.044279348105192184, acc: 0.9889655113220215)
[2024-12-17 05:22:13,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:13,436][root][INFO] - Training Epoch: 2/2, step 4604/7134 completed (loss: 0.01680316962301731, acc: 0.9919742941856384)
[2024-12-17 05:22:13,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:13,858][root][INFO] - Training Epoch: 2/2, step 4605/7134 completed (loss: 0.04817606136202812, acc: 0.9825327396392822)
[2024-12-17 05:22:13,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:14,291][root][INFO] - Training Epoch: 2/2, step 4606/7134 completed (loss: 0.016882842406630516, acc: 0.9954128265380859)
[2024-12-17 05:22:14,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:14,684][root][INFO] - Training Epoch: 2/2, step 4607/7134 completed (loss: 0.011885018087923527, acc: 0.9932659864425659)
[2024-12-17 05:22:14,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:15,108][root][INFO] - Training Epoch: 2/2, step 4608/7134 completed (loss: 0.019976459443569183, acc: 0.9925925731658936)
[2024-12-17 05:22:15,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:15,529][root][INFO] - Training Epoch: 2/2, step 4609/7134 completed (loss: 0.02567344717681408, acc: 0.9944953918457031)
[2024-12-17 05:22:15,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:15,971][root][INFO] - Training Epoch: 2/2, step 4610/7134 completed (loss: 0.022027960047125816, acc: 0.9933599233627319)
[2024-12-17 05:22:16,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:16,403][root][INFO] - Training Epoch: 2/2, step 4611/7134 completed (loss: 0.0066388375125825405, acc: 0.9984350800514221)
[2024-12-17 05:22:16,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:16,782][root][INFO] - Training Epoch: 2/2, step 4612/7134 completed (loss: 0.02372024394571781, acc: 0.9925650358200073)
[2024-12-17 05:22:16,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:17,188][root][INFO] - Training Epoch: 2/2, step 4613/7134 completed (loss: 0.018425991758704185, acc: 0.9965277910232544)
[2024-12-17 05:22:17,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:17,590][root][INFO] - Training Epoch: 2/2, step 4614/7134 completed (loss: 0.051156919449567795, acc: 0.9848484992980957)
[2024-12-17 05:22:17,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:18,040][root][INFO] - Training Epoch: 2/2, step 4615/7134 completed (loss: 0.026898527517914772, acc: 0.9877883195877075)
[2024-12-17 05:22:18,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:18,473][root][INFO] - Training Epoch: 2/2, step 4616/7134 completed (loss: 0.05583255738019943, acc: 0.9837278127670288)
[2024-12-17 05:22:18,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:18,876][root][INFO] - Training Epoch: 2/2, step 4617/7134 completed (loss: 0.025515694171190262, acc: 0.9894894957542419)
[2024-12-17 05:22:19,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:19,331][root][INFO] - Training Epoch: 2/2, step 4618/7134 completed (loss: 0.033810876309871674, acc: 0.9883494973182678)
[2024-12-17 05:22:19,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:19,786][root][INFO] - Training Epoch: 2/2, step 4619/7134 completed (loss: 0.010585636831820011, acc: 0.9954751133918762)
[2024-12-17 05:22:19,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:20,247][root][INFO] - Training Epoch: 2/2, step 4620/7134 completed (loss: 0.014820241369307041, acc: 0.9942029118537903)
[2024-12-17 05:22:20,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:20,680][root][INFO] - Training Epoch: 2/2, step 4621/7134 completed (loss: 0.01099991612136364, acc: 0.9969135522842407)
[2024-12-17 05:22:20,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:21,106][root][INFO] - Training Epoch: 2/2, step 4622/7134 completed (loss: 0.049675196409225464, acc: 0.9900124669075012)
[2024-12-17 05:22:21,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:21,525][root][INFO] - Training Epoch: 2/2, step 4623/7134 completed (loss: 0.04907216131687164, acc: 0.9882352948188782)
[2024-12-17 05:22:21,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:22,031][root][INFO] - Training Epoch: 2/2, step 4624/7134 completed (loss: 0.058278486132621765, acc: 0.9876543283462524)
[2024-12-17 05:22:22,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:22,452][root][INFO] - Training Epoch: 2/2, step 4625/7134 completed (loss: 0.07651915401220322, acc: 0.9802955389022827)
[2024-12-17 05:22:22,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:22,892][root][INFO] - Training Epoch: 2/2, step 4626/7134 completed (loss: 0.056763555854558945, acc: 0.9852349162101746)
[2024-12-17 05:22:22,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:23,318][root][INFO] - Training Epoch: 2/2, step 4627/7134 completed (loss: 0.08132157474756241, acc: 0.9787557125091553)
[2024-12-17 05:22:23,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:23,772][root][INFO] - Training Epoch: 2/2, step 4628/7134 completed (loss: 0.042680855840444565, acc: 0.9826086759567261)
[2024-12-17 05:22:23,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:24,213][root][INFO] - Training Epoch: 2/2, step 4629/7134 completed (loss: 0.0741092711687088, acc: 0.976068377494812)
[2024-12-17 05:22:24,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:24,671][root][INFO] - Training Epoch: 2/2, step 4630/7134 completed (loss: 0.05861914902925491, acc: 0.9828269481658936)
[2024-12-17 05:22:24,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:25,120][root][INFO] - Training Epoch: 2/2, step 4631/7134 completed (loss: 0.04620495066046715, acc: 0.9834070801734924)
[2024-12-17 05:22:25,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:25,597][root][INFO] - Training Epoch: 2/2, step 4632/7134 completed (loss: 0.03789051994681358, acc: 0.9926470518112183)
[2024-12-17 05:22:25,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:26,039][root][INFO] - Training Epoch: 2/2, step 4633/7134 completed (loss: 0.052946411073207855, acc: 0.981502890586853)
[2024-12-17 05:22:26,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:26,465][root][INFO] - Training Epoch: 2/2, step 4634/7134 completed (loss: 0.026142308488488197, acc: 0.9883494973182678)
[2024-12-17 05:22:26,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:26,864][root][INFO] - Training Epoch: 2/2, step 4635/7134 completed (loss: 0.06642775982618332, acc: 0.9862805008888245)
[2024-12-17 05:22:26,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:27,260][root][INFO] - Training Epoch: 2/2, step 4636/7134 completed (loss: 0.029245970770716667, acc: 0.9871134161949158)
[2024-12-17 05:22:27,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:27,692][root][INFO] - Training Epoch: 2/2, step 4637/7134 completed (loss: 0.028630541637539864, acc: 0.9919354915618896)
[2024-12-17 05:22:27,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:28,122][root][INFO] - Training Epoch: 2/2, step 4638/7134 completed (loss: 0.04841461032629013, acc: 0.9841479659080505)
[2024-12-17 05:22:28,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:28,554][root][INFO] - Training Epoch: 2/2, step 4639/7134 completed (loss: 0.04723682999610901, acc: 0.9878345727920532)
[2024-12-17 05:22:28,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:29,025][root][INFO] - Training Epoch: 2/2, step 4640/7134 completed (loss: 0.044890984892845154, acc: 0.9871794581413269)
[2024-12-17 05:22:29,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:29,456][root][INFO] - Training Epoch: 2/2, step 4641/7134 completed (loss: 0.027372807264328003, acc: 0.9928977489471436)
[2024-12-17 05:22:29,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:29,903][root][INFO] - Training Epoch: 2/2, step 4642/7134 completed (loss: 0.012152397073805332, acc: 0.9947090148925781)
[2024-12-17 05:22:30,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:30,367][root][INFO] - Training Epoch: 2/2, step 4643/7134 completed (loss: 0.025731248781085014, acc: 0.9952662587165833)
[2024-12-17 05:22:30,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:30,832][root][INFO] - Training Epoch: 2/2, step 4644/7134 completed (loss: 0.020687242969870567, acc: 0.9964497089385986)
[2024-12-17 05:22:30,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:31,285][root][INFO] - Training Epoch: 2/2, step 4645/7134 completed (loss: 0.017565380781888962, acc: 0.9958275556564331)
[2024-12-17 05:22:31,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:31,729][root][INFO] - Training Epoch: 2/2, step 4646/7134 completed (loss: 0.014716660603880882, acc: 0.9968602657318115)
[2024-12-17 05:22:31,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:32,194][root][INFO] - Training Epoch: 2/2, step 4647/7134 completed (loss: 0.08168891817331314, acc: 0.9869791865348816)
[2024-12-17 05:22:32,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:32,637][root][INFO] - Training Epoch: 2/2, step 4648/7134 completed (loss: 0.03942937031388283, acc: 0.9849108457565308)
[2024-12-17 05:22:32,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:33,083][root][INFO] - Training Epoch: 2/2, step 4649/7134 completed (loss: 0.031472884118556976, acc: 0.9912434220314026)
[2024-12-17 05:22:33,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:33,543][root][INFO] - Training Epoch: 2/2, step 4650/7134 completed (loss: 0.05320454761385918, acc: 0.9836309552192688)
[2024-12-17 05:22:33,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:33,971][root][INFO] - Training Epoch: 2/2, step 4651/7134 completed (loss: 0.06996066123247147, acc: 0.9822559952735901)
[2024-12-17 05:22:34,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:34,403][root][INFO] - Training Epoch: 2/2, step 4652/7134 completed (loss: 0.02637810818850994, acc: 0.9923780560493469)
[2024-12-17 05:22:34,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:34,868][root][INFO] - Training Epoch: 2/2, step 4653/7134 completed (loss: 0.039282526820898056, acc: 0.9892473220825195)
[2024-12-17 05:22:34,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:35,316][root][INFO] - Training Epoch: 2/2, step 4654/7134 completed (loss: 0.05741012841463089, acc: 0.9829476475715637)
[2024-12-17 05:22:35,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:35,755][root][INFO] - Training Epoch: 2/2, step 4655/7134 completed (loss: 0.04977129027247429, acc: 0.9904240965843201)
[2024-12-17 05:22:35,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:36,214][root][INFO] - Training Epoch: 2/2, step 4656/7134 completed (loss: 0.025102604180574417, acc: 0.9962121248245239)
[2024-12-17 05:22:36,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:36,635][root][INFO] - Training Epoch: 2/2, step 4657/7134 completed (loss: 0.04379362612962723, acc: 0.9858356714248657)
[2024-12-17 05:22:36,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:37,057][root][INFO] - Training Epoch: 2/2, step 4658/7134 completed (loss: 0.050785355269908905, acc: 0.9837618470191956)
[2024-12-17 05:22:37,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:37,527][root][INFO] - Training Epoch: 2/2, step 4659/7134 completed (loss: 0.0661761537194252, acc: 0.9858611822128296)
[2024-12-17 05:22:37,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:37,968][root][INFO] - Training Epoch: 2/2, step 4660/7134 completed (loss: 0.08020186424255371, acc: 0.9780564308166504)
[2024-12-17 05:22:38,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:38,374][root][INFO] - Training Epoch: 2/2, step 4661/7134 completed (loss: 0.04909302666783333, acc: 0.9878048896789551)
[2024-12-17 05:22:38,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:38,811][root][INFO] - Training Epoch: 2/2, step 4662/7134 completed (loss: 0.06647180020809174, acc: 0.9846938848495483)
[2024-12-17 05:22:38,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:39,267][root][INFO] - Training Epoch: 2/2, step 4663/7134 completed (loss: 0.06983090937137604, acc: 0.9852941036224365)
[2024-12-17 05:22:39,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:39,761][root][INFO] - Training Epoch: 2/2, step 4664/7134 completed (loss: 0.031074190512299538, acc: 0.9920739531517029)
[2024-12-17 05:22:39,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:40,186][root][INFO] - Training Epoch: 2/2, step 4665/7134 completed (loss: 0.04395713657140732, acc: 0.9849931597709656)
[2024-12-17 05:22:40,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:40,650][root][INFO] - Training Epoch: 2/2, step 4666/7134 completed (loss: 0.04044184461236, acc: 0.9882659912109375)
[2024-12-17 05:22:40,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:41,052][root][INFO] - Training Epoch: 2/2, step 4667/7134 completed (loss: 0.04253094270825386, acc: 0.9827883243560791)
[2024-12-17 05:22:41,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:41,463][root][INFO] - Training Epoch: 2/2, step 4668/7134 completed (loss: 0.023906368762254715, acc: 0.9928315281867981)
[2024-12-17 05:22:41,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:41,888][root][INFO] - Training Epoch: 2/2, step 4669/7134 completed (loss: 0.023216767236590385, acc: 0.9955621361732483)
[2024-12-17 05:22:42,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:42,311][root][INFO] - Training Epoch: 2/2, step 4670/7134 completed (loss: 0.04019602760672569, acc: 0.9922027587890625)
[2024-12-17 05:22:42,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:42,732][root][INFO] - Training Epoch: 2/2, step 4671/7134 completed (loss: 0.04939868301153183, acc: 0.9844852089881897)
[2024-12-17 05:22:42,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:43,137][root][INFO] - Training Epoch: 2/2, step 4672/7134 completed (loss: 0.0390511192381382, acc: 0.9860627055168152)
[2024-12-17 05:22:43,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:43,585][root][INFO] - Training Epoch: 2/2, step 4673/7134 completed (loss: 0.04744943976402283, acc: 0.9859594106674194)
[2024-12-17 05:22:43,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:44,022][root][INFO] - Training Epoch: 2/2, step 4674/7134 completed (loss: 0.04404474049806595, acc: 0.9904912710189819)
[2024-12-17 05:22:44,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:44,465][root][INFO] - Training Epoch: 2/2, step 4675/7134 completed (loss: 0.034495122730731964, acc: 0.9910827875137329)
[2024-12-17 05:22:44,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:44,889][root][INFO] - Training Epoch: 2/2, step 4676/7134 completed (loss: 0.02705085650086403, acc: 0.9924699068069458)
[2024-12-17 05:22:44,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:45,335][root][INFO] - Training Epoch: 2/2, step 4677/7134 completed (loss: 0.027462754398584366, acc: 0.9934210777282715)
[2024-12-17 05:22:45,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:45,767][root][INFO] - Training Epoch: 2/2, step 4678/7134 completed (loss: 0.04029763862490654, acc: 0.9910846948623657)
[2024-12-17 05:22:45,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:46,199][root][INFO] - Training Epoch: 2/2, step 4679/7134 completed (loss: 0.031419556587934494, acc: 0.9931034445762634)
[2024-12-17 05:22:46,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:46,599][root][INFO] - Training Epoch: 2/2, step 4680/7134 completed (loss: 0.0565386638045311, acc: 0.985981285572052)
[2024-12-17 05:22:46,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:47,046][root][INFO] - Training Epoch: 2/2, step 4681/7134 completed (loss: 0.035788003355264664, acc: 0.9938461780548096)
[2024-12-17 05:22:47,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:47,531][root][INFO] - Training Epoch: 2/2, step 4682/7134 completed (loss: 0.02023446001112461, acc: 0.9975669384002686)
[2024-12-17 05:22:47,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:47,937][root][INFO] - Training Epoch: 2/2, step 4683/7134 completed (loss: 0.025652237236499786, acc: 0.9942938685417175)
[2024-12-17 05:22:48,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:48,404][root][INFO] - Training Epoch: 2/2, step 4684/7134 completed (loss: 0.0614439882338047, acc: 0.9832285046577454)
[2024-12-17 05:22:48,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:48,867][root][INFO] - Training Epoch: 2/2, step 4685/7134 completed (loss: 0.031252868473529816, acc: 0.9928278923034668)
[2024-12-17 05:22:49,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:49,361][root][INFO] - Training Epoch: 2/2, step 4686/7134 completed (loss: 0.025940576568245888, acc: 0.9941792488098145)
[2024-12-17 05:22:49,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:49,718][root][INFO] - Training Epoch: 2/2, step 4687/7134 completed (loss: 0.13003015518188477, acc: 0.9693251252174377)
[2024-12-17 05:22:49,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:50,165][root][INFO] - Training Epoch: 2/2, step 4688/7134 completed (loss: 0.12965655326843262, acc: 0.9609856009483337)
[2024-12-17 05:22:50,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:50,640][root][INFO] - Training Epoch: 2/2, step 4689/7134 completed (loss: 0.11727926880121231, acc: 0.9675993919372559)
[2024-12-17 05:22:50,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:51,103][root][INFO] - Training Epoch: 2/2, step 4690/7134 completed (loss: 0.07881321758031845, acc: 0.9769392013549805)
[2024-12-17 05:22:51,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:51,533][root][INFO] - Training Epoch: 2/2, step 4691/7134 completed (loss: 0.02460128627717495, acc: 0.9897959232330322)
[2024-12-17 05:22:51,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:51,934][root][INFO] - Training Epoch: 2/2, step 4692/7134 completed (loss: 0.15523989498615265, acc: 0.9617834687232971)
[2024-12-17 05:22:52,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:52,444][root][INFO] - Training Epoch: 2/2, step 4693/7134 completed (loss: 0.14287331700325012, acc: 0.9624060392379761)
[2024-12-17 05:22:52,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:52,865][root][INFO] - Training Epoch: 2/2, step 4694/7134 completed (loss: 0.1391642689704895, acc: 0.9675456285476685)
[2024-12-17 05:22:53,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:53,333][root][INFO] - Training Epoch: 2/2, step 4695/7134 completed (loss: 0.07062559574842453, acc: 0.9786535501480103)
[2024-12-17 05:22:53,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:53,783][root][INFO] - Training Epoch: 2/2, step 4696/7134 completed (loss: 0.024177055805921555, acc: 0.9925705790519714)
[2024-12-17 05:22:53,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:54,195][root][INFO] - Training Epoch: 2/2, step 4697/7134 completed (loss: 0.029319075867533684, acc: 0.9887217879295349)
[2024-12-17 05:22:54,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:54,626][root][INFO] - Training Epoch: 2/2, step 4698/7134 completed (loss: 0.10697755962610245, acc: 0.9751908183097839)
[2024-12-17 05:22:54,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:55,098][root][INFO] - Training Epoch: 2/2, step 4699/7134 completed (loss: 0.061878979206085205, acc: 0.9872029423713684)
[2024-12-17 05:22:55,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:55,547][root][INFO] - Training Epoch: 2/2, step 4700/7134 completed (loss: 0.05273976922035217, acc: 0.9865871667861938)
[2024-12-17 05:22:55,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:55,886][root][INFO] - Training Epoch: 2/2, step 4701/7134 completed (loss: 0.049219682812690735, acc: 0.9840255379676819)
[2024-12-17 05:22:55,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:56,334][root][INFO] - Training Epoch: 2/2, step 4702/7134 completed (loss: 0.03819509595632553, acc: 0.9904458522796631)
[2024-12-17 05:22:56,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:56,789][root][INFO] - Training Epoch: 2/2, step 4703/7134 completed (loss: 0.044753238558769226, acc: 0.9864864945411682)
[2024-12-17 05:22:56,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:57,213][root][INFO] - Training Epoch: 2/2, step 4704/7134 completed (loss: 0.020733263343572617, acc: 0.9929659962654114)
[2024-12-17 05:22:57,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:57,657][root][INFO] - Training Epoch: 2/2, step 4705/7134 completed (loss: 0.024642040953040123, acc: 0.9906432628631592)
[2024-12-17 05:22:57,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:58,126][root][INFO] - Training Epoch: 2/2, step 4706/7134 completed (loss: 0.06168725714087486, acc: 0.9813084006309509)
[2024-12-17 05:22:58,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:58,555][root][INFO] - Training Epoch: 2/2, step 4707/7134 completed (loss: 0.16952389478683472, acc: 0.9659863710403442)
[2024-12-17 05:22:58,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:58,990][root][INFO] - Training Epoch: 2/2, step 4708/7134 completed (loss: 0.015444092452526093, acc: 0.9950124621391296)
[2024-12-17 05:22:59,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:59,439][root][INFO] - Training Epoch: 2/2, step 4709/7134 completed (loss: 0.01918688602745533, acc: 0.9973649382591248)
[2024-12-17 05:22:59,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:22:59,879][root][INFO] - Training Epoch: 2/2, step 4710/7134 completed (loss: 0.03951669856905937, acc: 0.9912663698196411)
[2024-12-17 05:23:00,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:00,350][root][INFO] - Training Epoch: 2/2, step 4711/7134 completed (loss: 0.07395760715007782, acc: 0.979626476764679)
[2024-12-17 05:23:00,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:00,766][root][INFO] - Training Epoch: 2/2, step 4712/7134 completed (loss: 0.07953964918851852, acc: 0.9803030490875244)
[2024-12-17 05:23:00,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:01,193][root][INFO] - Training Epoch: 2/2, step 4713/7134 completed (loss: 0.037642765790224075, acc: 0.9892857074737549)
[2024-12-17 05:23:01,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:01,578][root][INFO] - Training Epoch: 2/2, step 4714/7134 completed (loss: 0.049008917063474655, acc: 0.9869158864021301)
[2024-12-17 05:23:01,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:01,984][root][INFO] - Training Epoch: 2/2, step 4715/7134 completed (loss: 0.10862242430448532, acc: 0.9658848643302917)
[2024-12-17 05:23:02,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:02,399][root][INFO] - Training Epoch: 2/2, step 4716/7134 completed (loss: 0.02031959779560566, acc: 0.9954268336296082)
[2024-12-17 05:23:02,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:02,832][root][INFO] - Training Epoch: 2/2, step 4717/7134 completed (loss: 0.028966981917619705, acc: 0.9925925731658936)
[2024-12-17 05:23:02,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:03,263][root][INFO] - Training Epoch: 2/2, step 4718/7134 completed (loss: 0.036666400730609894, acc: 0.9867549538612366)
[2024-12-17 05:23:03,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:03,740][root][INFO] - Training Epoch: 2/2, step 4719/7134 completed (loss: 0.02562197484076023, acc: 0.9941002726554871)
[2024-12-17 05:23:03,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:04,172][root][INFO] - Training Epoch: 2/2, step 4720/7134 completed (loss: 0.01650220714509487, acc: 0.991584837436676)
[2024-12-17 05:23:04,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:04,572][root][INFO] - Training Epoch: 2/2, step 4721/7134 completed (loss: 0.004505163058638573, acc: 0.9971181750297546)
[2024-12-17 05:23:04,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:04,990][root][INFO] - Training Epoch: 2/2, step 4722/7134 completed (loss: 0.021777527406811714, acc: 0.9911242723464966)
[2024-12-17 05:23:05,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:05,396][root][INFO] - Training Epoch: 2/2, step 4723/7134 completed (loss: 0.010594869963824749, acc: 0.9969512224197388)
[2024-12-17 05:23:05,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:05,843][root][INFO] - Training Epoch: 2/2, step 4724/7134 completed (loss: 0.03097403608262539, acc: 0.9911242723464966)
[2024-12-17 05:23:05,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:06,284][root][INFO] - Training Epoch: 2/2, step 4725/7134 completed (loss: 0.012320046313107014, acc: 0.9973614811897278)
[2024-12-17 05:23:06,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:06,738][root][INFO] - Training Epoch: 2/2, step 4726/7134 completed (loss: 0.046317003667354584, acc: 0.9829787015914917)
[2024-12-17 05:23:06,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:07,163][root][INFO] - Training Epoch: 2/2, step 4727/7134 completed (loss: 0.03231635317206383, acc: 0.9905956387519836)
[2024-12-17 05:23:07,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:07,578][root][INFO] - Training Epoch: 2/2, step 4728/7134 completed (loss: 0.05597269535064697, acc: 0.9851729869842529)
[2024-12-17 05:23:07,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:07,989][root][INFO] - Training Epoch: 2/2, step 4729/7134 completed (loss: 0.011274565942585468, acc: 0.997183084487915)
[2024-12-17 05:23:08,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:08,414][root][INFO] - Training Epoch: 2/2, step 4730/7134 completed (loss: 0.024256272241473198, acc: 0.992343008518219)
[2024-12-17 05:23:08,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:08,826][root][INFO] - Training Epoch: 2/2, step 4731/7134 completed (loss: 0.03959820419549942, acc: 0.9908397197723389)
[2024-12-17 05:23:08,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:09,234][root][INFO] - Training Epoch: 2/2, step 4732/7134 completed (loss: 0.048612941056489944, acc: 0.9836660623550415)
[2024-12-17 05:23:09,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:09,648][root][INFO] - Training Epoch: 2/2, step 4733/7134 completed (loss: 0.010663384571671486, acc: 0.9951534867286682)
[2024-12-17 05:23:09,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:10,081][root][INFO] - Training Epoch: 2/2, step 4734/7134 completed (loss: 0.06533390283584595, acc: 0.9809221029281616)
[2024-12-17 05:23:10,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:10,531][root][INFO] - Training Epoch: 2/2, step 4735/7134 completed (loss: 0.02689320035278797, acc: 0.9909909963607788)
[2024-12-17 05:23:10,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:10,909][root][INFO] - Training Epoch: 2/2, step 4736/7134 completed (loss: 0.06171151623129845, acc: 0.9822485446929932)
[2024-12-17 05:23:11,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:11,325][root][INFO] - Training Epoch: 2/2, step 4737/7134 completed (loss: 0.028576074168086052, acc: 0.9921630024909973)
[2024-12-17 05:23:11,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:11,725][root][INFO] - Training Epoch: 2/2, step 4738/7134 completed (loss: 0.017521290108561516, acc: 0.9939302206039429)
[2024-12-17 05:23:11,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:12,136][root][INFO] - Training Epoch: 2/2, step 4739/7134 completed (loss: 0.07706607133150101, acc: 0.9728434681892395)
[2024-12-17 05:23:12,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:12,571][root][INFO] - Training Epoch: 2/2, step 4740/7134 completed (loss: 0.06617721915245056, acc: 0.9790419340133667)
[2024-12-17 05:23:12,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:12,959][root][INFO] - Training Epoch: 2/2, step 4741/7134 completed (loss: 0.05472990870475769, acc: 0.9870610237121582)
[2024-12-17 05:23:13,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:13,413][root][INFO] - Training Epoch: 2/2, step 4742/7134 completed (loss: 0.09216867387294769, acc: 0.9752212166786194)
[2024-12-17 05:23:13,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:13,857][root][INFO] - Training Epoch: 2/2, step 4743/7134 completed (loss: 0.03088589385151863, acc: 0.9893238544464111)
[2024-12-17 05:23:13,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:14,247][root][INFO] - Training Epoch: 2/2, step 4744/7134 completed (loss: 0.024898162111639977, acc: 0.9938016533851624)
[2024-12-17 05:23:14,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:14,591][root][INFO] - Training Epoch: 2/2, step 4745/7134 completed (loss: 0.06380824744701385, acc: 0.9832776188850403)
[2024-12-17 05:23:14,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:15,059][root][INFO] - Training Epoch: 2/2, step 4746/7134 completed (loss: 0.03829512000083923, acc: 0.9908088445663452)
[2024-12-17 05:23:15,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:15,498][root][INFO] - Training Epoch: 2/2, step 4747/7134 completed (loss: 0.028727883473038673, acc: 0.9905533194541931)
[2024-12-17 05:23:15,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:15,932][root][INFO] - Training Epoch: 2/2, step 4748/7134 completed (loss: 0.062033526599407196, acc: 0.9793510437011719)
[2024-12-17 05:23:16,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:16,377][root][INFO] - Training Epoch: 2/2, step 4749/7134 completed (loss: 0.04180249199271202, acc: 0.9933333396911621)
[2024-12-17 05:23:16,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:16,815][root][INFO] - Training Epoch: 2/2, step 4750/7134 completed (loss: 0.06885570287704468, acc: 0.9826589822769165)
[2024-12-17 05:23:16,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:17,291][root][INFO] - Training Epoch: 2/2, step 4751/7134 completed (loss: 0.00987886544317007, acc: 0.99858558177948)
[2024-12-17 05:23:17,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:17,729][root][INFO] - Training Epoch: 2/2, step 4752/7134 completed (loss: 0.04584837704896927, acc: 0.9907833933830261)
[2024-12-17 05:23:17,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:18,158][root][INFO] - Training Epoch: 2/2, step 4753/7134 completed (loss: 0.06863397359848022, acc: 0.983433723449707)
[2024-12-17 05:23:18,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:18,597][root][INFO] - Training Epoch: 2/2, step 4754/7134 completed (loss: 0.02593880146741867, acc: 0.9926578402519226)
[2024-12-17 05:23:18,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:19,040][root][INFO] - Training Epoch: 2/2, step 4755/7134 completed (loss: 0.056058961898088455, acc: 0.9861303567886353)
[2024-12-17 05:23:19,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:19,444][root][INFO] - Training Epoch: 2/2, step 4756/7134 completed (loss: 0.05975036695599556, acc: 0.9895397424697876)
[2024-12-17 05:23:19,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:19,935][root][INFO] - Training Epoch: 2/2, step 4757/7134 completed (loss: 0.03593626618385315, acc: 0.9873708486557007)
[2024-12-17 05:23:20,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:20,413][root][INFO] - Training Epoch: 2/2, step 4758/7134 completed (loss: 0.0341363325715065, acc: 0.9873949289321899)
[2024-12-17 05:23:20,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:20,861][root][INFO] - Training Epoch: 2/2, step 4759/7134 completed (loss: 0.021953007206320763, acc: 0.9948275685310364)
[2024-12-17 05:23:20,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:21,262][root][INFO] - Training Epoch: 2/2, step 4760/7134 completed (loss: 0.03456413000822067, acc: 0.9937888383865356)
[2024-12-17 05:23:21,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:21,686][root][INFO] - Training Epoch: 2/2, step 4761/7134 completed (loss: 0.04963056370615959, acc: 0.9923664331436157)
[2024-12-17 05:23:21,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:22,121][root][INFO] - Training Epoch: 2/2, step 4762/7134 completed (loss: 0.05269966647028923, acc: 0.9878378510475159)
[2024-12-17 05:23:22,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:22,545][root][INFO] - Training Epoch: 2/2, step 4763/7134 completed (loss: 0.05149954929947853, acc: 0.9863221645355225)
[2024-12-17 05:23:22,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:22,985][root][INFO] - Training Epoch: 2/2, step 4764/7134 completed (loss: 0.03652545064687729, acc: 0.9864029884338379)
[2024-12-17 05:23:23,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:23,414][root][INFO] - Training Epoch: 2/2, step 4765/7134 completed (loss: 0.0628654882311821, acc: 0.9884892106056213)
[2024-12-17 05:23:23,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:23,853][root][INFO] - Training Epoch: 2/2, step 4766/7134 completed (loss: 0.04410276189446449, acc: 0.9909909963607788)
[2024-12-17 05:23:23,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:24,233][root][INFO] - Training Epoch: 2/2, step 4767/7134 completed (loss: 0.05242498964071274, acc: 0.9821882843971252)
[2024-12-17 05:23:24,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:24,720][root][INFO] - Training Epoch: 2/2, step 4768/7134 completed (loss: 0.05352221429347992, acc: 0.9850948452949524)
[2024-12-17 05:23:24,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:25,134][root][INFO] - Training Epoch: 2/2, step 4769/7134 completed (loss: 0.04517141729593277, acc: 0.9887640476226807)
[2024-12-17 05:23:25,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:25,525][root][INFO] - Training Epoch: 2/2, step 4770/7134 completed (loss: 0.04447747394442558, acc: 0.991919219493866)
[2024-12-17 05:23:25,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:25,942][root][INFO] - Training Epoch: 2/2, step 4771/7134 completed (loss: 0.06281676888465881, acc: 0.9781976938247681)
[2024-12-17 05:23:26,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:26,348][root][INFO] - Training Epoch: 2/2, step 4772/7134 completed (loss: 0.04441436380147934, acc: 0.9920254945755005)
[2024-12-17 05:23:26,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:26,762][root][INFO] - Training Epoch: 2/2, step 4773/7134 completed (loss: 0.033792588859796524, acc: 0.9904109835624695)
[2024-12-17 05:23:26,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:27,178][root][INFO] - Training Epoch: 2/2, step 4774/7134 completed (loss: 0.03538759425282478, acc: 0.992977499961853)
[2024-12-17 05:23:27,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:27,586][root][INFO] - Training Epoch: 2/2, step 4775/7134 completed (loss: 0.051453400403261185, acc: 0.9838969111442566)
[2024-12-17 05:23:27,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:28,005][root][INFO] - Training Epoch: 2/2, step 4776/7134 completed (loss: 0.05411074683070183, acc: 0.9903692007064819)
[2024-12-17 05:23:28,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:28,444][root][INFO] - Training Epoch: 2/2, step 4777/7134 completed (loss: 0.04140980541706085, acc: 0.9866443872451782)
[2024-12-17 05:23:28,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:28,859][root][INFO] - Training Epoch: 2/2, step 4778/7134 completed (loss: 0.029112357646226883, acc: 0.9890590906143188)
[2024-12-17 05:23:28,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:29,310][root][INFO] - Training Epoch: 2/2, step 4779/7134 completed (loss: 0.02335037663578987, acc: 0.9944751262664795)
[2024-12-17 05:23:29,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:29,750][root][INFO] - Training Epoch: 2/2, step 4780/7134 completed (loss: 0.006937035359442234, acc: 0.9968847632408142)
[2024-12-17 05:23:29,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:30,180][root][INFO] - Training Epoch: 2/2, step 4781/7134 completed (loss: 0.030170660465955734, acc: 0.9941291809082031)
[2024-12-17 05:23:30,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:30,610][root][INFO] - Training Epoch: 2/2, step 4782/7134 completed (loss: 0.01898212358355522, acc: 0.9918962717056274)
[2024-12-17 05:23:30,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:31,039][root][INFO] - Training Epoch: 2/2, step 4783/7134 completed (loss: 0.06332436203956604, acc: 0.982206404209137)
[2024-12-17 05:23:31,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:31,498][root][INFO] - Training Epoch: 2/2, step 4784/7134 completed (loss: 0.023728972300887108, acc: 0.9945429563522339)
[2024-12-17 05:23:31,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:31,936][root][INFO] - Training Epoch: 2/2, step 4785/7134 completed (loss: 0.0413166806101799, acc: 0.9925093650817871)
[2024-12-17 05:23:32,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:32,364][root][INFO] - Training Epoch: 2/2, step 4786/7134 completed (loss: 0.038488056510686874, acc: 0.989130437374115)
[2024-12-17 05:23:32,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:32,812][root][INFO] - Training Epoch: 2/2, step 4787/7134 completed (loss: 0.009197114035487175, acc: 0.996835470199585)
[2024-12-17 05:23:32,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:33,239][root][INFO] - Training Epoch: 2/2, step 4788/7134 completed (loss: 0.008373661898076534, acc: 0.9964538812637329)
[2024-12-17 05:23:33,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:33,655][root][INFO] - Training Epoch: 2/2, step 4789/7134 completed (loss: 0.024106217548251152, acc: 0.9920381903648376)
[2024-12-17 05:23:33,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:34,094][root][INFO] - Training Epoch: 2/2, step 4790/7134 completed (loss: 0.02549898624420166, acc: 0.9945651888847351)
[2024-12-17 05:23:34,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:34,504][root][INFO] - Training Epoch: 2/2, step 4791/7134 completed (loss: 0.01398376002907753, acc: 0.9962756037712097)
[2024-12-17 05:23:34,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:34,925][root][INFO] - Training Epoch: 2/2, step 4792/7134 completed (loss: 0.021182959899306297, acc: 0.9899665713310242)
[2024-12-17 05:23:35,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:35,317][root][INFO] - Training Epoch: 2/2, step 4793/7134 completed (loss: 0.046153903007507324, acc: 0.983561635017395)
[2024-12-17 05:23:35,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:35,742][root][INFO] - Training Epoch: 2/2, step 4794/7134 completed (loss: 0.07241512089967728, acc: 0.977142870426178)
[2024-12-17 05:23:35,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:36,180][root][INFO] - Training Epoch: 2/2, step 4795/7134 completed (loss: 0.024557266384363174, acc: 0.9929378628730774)
[2024-12-17 05:23:36,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:36,605][root][INFO] - Training Epoch: 2/2, step 4796/7134 completed (loss: 0.028430519625544548, acc: 0.9889937043190002)
[2024-12-17 05:23:36,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:37,058][root][INFO] - Training Epoch: 2/2, step 4797/7134 completed (loss: 0.012347017414867878, acc: 0.9937888383865356)
[2024-12-17 05:23:37,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:37,488][root][INFO] - Training Epoch: 2/2, step 4798/7134 completed (loss: 0.024685770273208618, acc: 0.9906790852546692)
[2024-12-17 05:23:37,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:37,938][root][INFO] - Training Epoch: 2/2, step 4799/7134 completed (loss: 0.023096686229109764, acc: 0.9900990128517151)
[2024-12-17 05:23:38,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:38,349][root][INFO] - Training Epoch: 2/2, step 4800/7134 completed (loss: 0.022711357101798058, acc: 0.992548406124115)
[2024-12-17 05:23:38,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:38,824][root][INFO] - Training Epoch: 2/2, step 4801/7134 completed (loss: 0.024782806634902954, acc: 0.9943438768386841)
[2024-12-17 05:23:38,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:39,275][root][INFO] - Training Epoch: 2/2, step 4802/7134 completed (loss: 0.040851399302482605, acc: 0.985602080821991)
[2024-12-17 05:23:39,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:39,685][root][INFO] - Training Epoch: 2/2, step 4803/7134 completed (loss: 0.04402302950620651, acc: 0.9867647290229797)
[2024-12-17 05:23:39,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:40,146][root][INFO] - Training Epoch: 2/2, step 4804/7134 completed (loss: 0.038272686302661896, acc: 0.9876922965049744)
[2024-12-17 05:23:40,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:40,583][root][INFO] - Training Epoch: 2/2, step 4805/7134 completed (loss: 0.04138382151722908, acc: 0.991909384727478)
[2024-12-17 05:23:40,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:41,010][root][INFO] - Training Epoch: 2/2, step 4806/7134 completed (loss: 0.04430606961250305, acc: 0.9900166392326355)
[2024-12-17 05:23:41,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:41,394][root][INFO] - Training Epoch: 2/2, step 4807/7134 completed (loss: 0.04645562916994095, acc: 0.9908814430236816)
[2024-12-17 05:23:41,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:41,833][root][INFO] - Training Epoch: 2/2, step 4808/7134 completed (loss: 0.030992724001407623, acc: 0.9893617033958435)
[2024-12-17 05:23:41,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:42,266][root][INFO] - Training Epoch: 2/2, step 4809/7134 completed (loss: 0.02518877573311329, acc: 0.9920634627342224)
[2024-12-17 05:23:42,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:42,726][root][INFO] - Training Epoch: 2/2, step 4810/7134 completed (loss: 0.04841407388448715, acc: 0.9900142550468445)
[2024-12-17 05:23:42,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:43,141][root][INFO] - Training Epoch: 2/2, step 4811/7134 completed (loss: 0.03131815418601036, acc: 0.9941860437393188)
[2024-12-17 05:23:43,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:43,576][root][INFO] - Training Epoch: 2/2, step 4812/7134 completed (loss: 0.08657150715589523, acc: 0.9819193482398987)
[2024-12-17 05:23:43,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:43,978][root][INFO] - Training Epoch: 2/2, step 4813/7134 completed (loss: 0.038363393396139145, acc: 0.9896103739738464)
[2024-12-17 05:23:44,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:44,406][root][INFO] - Training Epoch: 2/2, step 4814/7134 completed (loss: 0.032369229942560196, acc: 0.9897959232330322)
[2024-12-17 05:23:44,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:44,803][root][INFO] - Training Epoch: 2/2, step 4815/7134 completed (loss: 0.0027215024456381798, acc: 1.0)
[2024-12-17 05:23:44,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:45,226][root][INFO] - Training Epoch: 2/2, step 4816/7134 completed (loss: 0.01789134554564953, acc: 0.9950494766235352)
[2024-12-17 05:23:45,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:45,669][root][INFO] - Training Epoch: 2/2, step 4817/7134 completed (loss: 0.010271845385432243, acc: 0.9951807260513306)
[2024-12-17 05:23:45,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:46,143][root][INFO] - Training Epoch: 2/2, step 4818/7134 completed (loss: 0.005920331459492445, acc: 0.9984615445137024)
[2024-12-17 05:23:46,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:46,550][root][INFO] - Training Epoch: 2/2, step 4819/7134 completed (loss: 0.019709574058651924, acc: 0.9959431886672974)
[2024-12-17 05:23:46,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:46,996][root][INFO] - Training Epoch: 2/2, step 4820/7134 completed (loss: 0.013784199953079224, acc: 0.993565022945404)
[2024-12-17 05:23:47,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:47,437][root][INFO] - Training Epoch: 2/2, step 4821/7134 completed (loss: 0.018354980275034904, acc: 0.99301677942276)
[2024-12-17 05:23:47,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:47,857][root][INFO] - Training Epoch: 2/2, step 4822/7134 completed (loss: 0.028271306306123734, acc: 0.996219277381897)
[2024-12-17 05:23:47,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:48,292][root][INFO] - Training Epoch: 2/2, step 4823/7134 completed (loss: 0.05280175060033798, acc: 0.9889415502548218)
[2024-12-17 05:23:48,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:48,675][root][INFO] - Training Epoch: 2/2, step 4824/7134 completed (loss: 0.05244462192058563, acc: 0.9840182662010193)
[2024-12-17 05:23:48,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:49,086][root][INFO] - Training Epoch: 2/2, step 4825/7134 completed (loss: 0.012241183780133724, acc: 0.9963503479957581)
[2024-12-17 05:23:49,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:49,541][root][INFO] - Training Epoch: 2/2, step 4826/7134 completed (loss: 0.021246889606118202, acc: 0.9935622215270996)
[2024-12-17 05:23:49,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:49,946][root][INFO] - Training Epoch: 2/2, step 4827/7134 completed (loss: 0.03783436119556427, acc: 0.9896193742752075)
[2024-12-17 05:23:50,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:50,383][root][INFO] - Training Epoch: 2/2, step 4828/7134 completed (loss: 0.01491683442145586, acc: 0.9975698590278625)
[2024-12-17 05:23:50,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:50,835][root][INFO] - Training Epoch: 2/2, step 4829/7134 completed (loss: 0.007932688109576702, acc: 0.9987179636955261)
[2024-12-17 05:23:50,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:51,283][root][INFO] - Training Epoch: 2/2, step 4830/7134 completed (loss: 0.014662759378552437, acc: 0.9955621361732483)
[2024-12-17 05:23:51,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:51,726][root][INFO] - Training Epoch: 2/2, step 4831/7134 completed (loss: 0.009815135039389133, acc: 0.9970760345458984)
[2024-12-17 05:23:51,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:52,149][root][INFO] - Training Epoch: 2/2, step 4832/7134 completed (loss: 0.017515279352664948, acc: 0.9983713626861572)
[2024-12-17 05:23:52,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:52,607][root][INFO] - Training Epoch: 2/2, step 4833/7134 completed (loss: 0.010424601845443249, acc: 0.9961880445480347)
[2024-12-17 05:23:52,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:53,047][root][INFO] - Training Epoch: 2/2, step 4834/7134 completed (loss: 0.027109801769256592, acc: 0.9940476417541504)
[2024-12-17 05:23:53,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:53,476][root][INFO] - Training Epoch: 2/2, step 4835/7134 completed (loss: 0.012404377572238445, acc: 0.9972972869873047)
[2024-12-17 05:23:53,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:53,938][root][INFO] - Training Epoch: 2/2, step 4836/7134 completed (loss: 0.01470219437032938, acc: 0.9954198598861694)
[2024-12-17 05:23:54,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:54,336][root][INFO] - Training Epoch: 2/2, step 4837/7134 completed (loss: 0.056217242032289505, acc: 0.9834558963775635)
[2024-12-17 05:23:54,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:54,753][root][INFO] - Training Epoch: 2/2, step 4838/7134 completed (loss: 0.02900105156004429, acc: 0.9935587644577026)
[2024-12-17 05:23:54,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:55,139][root][INFO] - Training Epoch: 2/2, step 4839/7134 completed (loss: 0.05635238066315651, acc: 0.9879518151283264)
[2024-12-17 05:23:55,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:55,562][root][INFO] - Training Epoch: 2/2, step 4840/7134 completed (loss: 0.033401068300008774, acc: 0.9898843765258789)
[2024-12-17 05:23:55,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:55,967][root][INFO] - Training Epoch: 2/2, step 4841/7134 completed (loss: 0.026901457458734512, acc: 0.9910581111907959)
[2024-12-17 05:23:56,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:56,412][root][INFO] - Training Epoch: 2/2, step 4842/7134 completed (loss: 0.038691431283950806, acc: 0.9910714030265808)
[2024-12-17 05:23:56,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:56,857][root][INFO] - Training Epoch: 2/2, step 4843/7134 completed (loss: 0.02605106122791767, acc: 0.9925705790519714)
[2024-12-17 05:23:56,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:57,233][root][INFO] - Training Epoch: 2/2, step 4844/7134 completed (loss: 0.035156603902578354, acc: 0.9886914491653442)
[2024-12-17 05:23:57,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:57,673][root][INFO] - Training Epoch: 2/2, step 4845/7134 completed (loss: 0.03461369872093201, acc: 0.9877049326896667)
[2024-12-17 05:23:57,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:58,086][root][INFO] - Training Epoch: 2/2, step 4846/7134 completed (loss: 0.031382400542497635, acc: 0.9864864945411682)
[2024-12-17 05:23:58,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:58,480][root][INFO] - Training Epoch: 2/2, step 4847/7134 completed (loss: 0.023999564349651337, acc: 0.9959568977355957)
[2024-12-17 05:23:58,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:58,883][root][INFO] - Training Epoch: 2/2, step 4848/7134 completed (loss: 0.028384029865264893, acc: 0.9944751262664795)
[2024-12-17 05:23:58,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:59,273][root][INFO] - Training Epoch: 2/2, step 4849/7134 completed (loss: 0.021427644416689873, acc: 0.9940564632415771)
[2024-12-17 05:23:59,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:23:59,710][root][INFO] - Training Epoch: 2/2, step 4850/7134 completed (loss: 0.03863120824098587, acc: 0.9889841079711914)
[2024-12-17 05:23:59,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:00,166][root][INFO] - Training Epoch: 2/2, step 4851/7134 completed (loss: 0.029225565493106842, acc: 0.9918224215507507)
[2024-12-17 05:24:00,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:00,605][root][INFO] - Training Epoch: 2/2, step 4852/7134 completed (loss: 0.03658348694443703, acc: 0.989347517490387)
[2024-12-17 05:24:00,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:01,014][root][INFO] - Training Epoch: 2/2, step 4853/7134 completed (loss: 0.06601080298423767, acc: 0.980028510093689)
[2024-12-17 05:24:01,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:01,406][root][INFO] - Training Epoch: 2/2, step 4854/7134 completed (loss: 0.022777020931243896, acc: 0.9959999918937683)
[2024-12-17 05:24:01,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:01,842][root][INFO] - Training Epoch: 2/2, step 4855/7134 completed (loss: 0.020941058173775673, acc: 0.9927448630332947)
[2024-12-17 05:24:01,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:02,305][root][INFO] - Training Epoch: 2/2, step 4856/7134 completed (loss: 0.03642594814300537, acc: 0.9872773289680481)
[2024-12-17 05:24:02,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:02,711][root][INFO] - Training Epoch: 2/2, step 4857/7134 completed (loss: 0.01911347545683384, acc: 0.9956834316253662)
[2024-12-17 05:24:02,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:03,146][root][INFO] - Training Epoch: 2/2, step 4858/7134 completed (loss: 0.026279030367732048, acc: 0.9928774833679199)
[2024-12-17 05:24:03,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:03,620][root][INFO] - Training Epoch: 2/2, step 4859/7134 completed (loss: 0.0170776154845953, acc: 0.993565022945404)
[2024-12-17 05:24:03,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:04,052][root][INFO] - Training Epoch: 2/2, step 4860/7134 completed (loss: 0.016761571168899536, acc: 0.9959127902984619)
[2024-12-17 05:24:04,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:04,470][root][INFO] - Training Epoch: 2/2, step 4861/7134 completed (loss: 0.017171058803796768, acc: 0.9919137358665466)
[2024-12-17 05:24:04,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:04,885][root][INFO] - Training Epoch: 2/2, step 4862/7134 completed (loss: 0.02123466320335865, acc: 0.995708167552948)
[2024-12-17 05:24:05,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:05,320][root][INFO] - Training Epoch: 2/2, step 4863/7134 completed (loss: 0.0302536990493536, acc: 0.989051103591919)
[2024-12-17 05:24:05,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:05,763][root][INFO] - Training Epoch: 2/2, step 4864/7134 completed (loss: 0.028047071769833565, acc: 0.989230751991272)
[2024-12-17 05:24:05,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:06,197][root][INFO] - Training Epoch: 2/2, step 4865/7134 completed (loss: 0.030379969626665115, acc: 0.9914529919624329)
[2024-12-17 05:24:06,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:06,659][root][INFO] - Training Epoch: 2/2, step 4866/7134 completed (loss: 0.021330228075385094, acc: 0.9961089491844177)
[2024-12-17 05:24:06,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:07,099][root][INFO] - Training Epoch: 2/2, step 4867/7134 completed (loss: 0.041237786412239075, acc: 0.9907407164573669)
[2024-12-17 05:24:07,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:07,517][root][INFO] - Training Epoch: 2/2, step 4868/7134 completed (loss: 0.0467333123087883, acc: 0.9864341020584106)
[2024-12-17 05:24:07,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:07,926][root][INFO] - Training Epoch: 2/2, step 4869/7134 completed (loss: 0.03886611759662628, acc: 0.9888888597488403)
[2024-12-17 05:24:08,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:08,376][root][INFO] - Training Epoch: 2/2, step 4870/7134 completed (loss: 0.010155761614441872, acc: 0.9976525902748108)
[2024-12-17 05:24:08,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:08,799][root][INFO] - Training Epoch: 2/2, step 4871/7134 completed (loss: 0.02984069287776947, acc: 0.9953703880310059)
[2024-12-17 05:24:08,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:09,218][root][INFO] - Training Epoch: 2/2, step 4872/7134 completed (loss: 0.01132149063050747, acc: 0.9972183704376221)
[2024-12-17 05:24:09,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:09,682][root][INFO] - Training Epoch: 2/2, step 4873/7134 completed (loss: 0.016749512404203415, acc: 0.9947916865348816)
[2024-12-17 05:24:09,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:10,131][root][INFO] - Training Epoch: 2/2, step 4874/7134 completed (loss: 0.017922857776284218, acc: 0.9919999837875366)
[2024-12-17 05:24:10,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:10,600][root][INFO] - Training Epoch: 2/2, step 4875/7134 completed (loss: 0.026581471785902977, acc: 0.9916782379150391)
[2024-12-17 05:24:10,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:10,961][root][INFO] - Training Epoch: 2/2, step 4876/7134 completed (loss: 0.07108255475759506, acc: 0.9830867052078247)
[2024-12-17 05:24:11,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:11,412][root][INFO] - Training Epoch: 2/2, step 4877/7134 completed (loss: 0.03156725689768791, acc: 0.9883871078491211)
[2024-12-17 05:24:11,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:11,825][root][INFO] - Training Epoch: 2/2, step 4878/7134 completed (loss: 0.029259273782372475, acc: 0.9882179498672485)
[2024-12-17 05:24:11,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:12,270][root][INFO] - Training Epoch: 2/2, step 4879/7134 completed (loss: 0.0634751096367836, acc: 0.9804216623306274)
[2024-12-17 05:24:12,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:12,698][root][INFO] - Training Epoch: 2/2, step 4880/7134 completed (loss: 0.010263705626130104, acc: 0.9961089491844177)
[2024-12-17 05:24:12,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:13,144][root][INFO] - Training Epoch: 2/2, step 4881/7134 completed (loss: 0.051220379769802094, acc: 0.9839416146278381)
[2024-12-17 05:24:13,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:13,555][root][INFO] - Training Epoch: 2/2, step 4882/7134 completed (loss: 0.031243829056620598, acc: 0.9901315569877625)
[2024-12-17 05:24:13,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:13,983][root][INFO] - Training Epoch: 2/2, step 4883/7134 completed (loss: 0.03508472815155983, acc: 0.9912408590316772)
[2024-12-17 05:24:14,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:14,416][root][INFO] - Training Epoch: 2/2, step 4884/7134 completed (loss: 0.013313943520188332, acc: 0.9938555955886841)
[2024-12-17 05:24:14,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:14,843][root][INFO] - Training Epoch: 2/2, step 4885/7134 completed (loss: 0.008751456625759602, acc: 0.9973614811897278)
[2024-12-17 05:24:14,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:15,248][root][INFO] - Training Epoch: 2/2, step 4886/7134 completed (loss: 0.022237829864025116, acc: 0.9897435903549194)
[2024-12-17 05:24:15,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:15,707][root][INFO] - Training Epoch: 2/2, step 4887/7134 completed (loss: 0.009172835387289524, acc: 0.9976105093955994)
[2024-12-17 05:24:15,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:16,180][root][INFO] - Training Epoch: 2/2, step 4888/7134 completed (loss: 0.042235590517520905, acc: 0.9917582273483276)
[2024-12-17 05:24:16,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:16,627][root][INFO] - Training Epoch: 2/2, step 4889/7134 completed (loss: 0.009552435018122196, acc: 0.9975932836532593)
[2024-12-17 05:24:16,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:17,012][root][INFO] - Training Epoch: 2/2, step 4890/7134 completed (loss: 0.042424120008945465, acc: 0.9976190328598022)
[2024-12-17 05:24:17,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:17,446][root][INFO] - Training Epoch: 2/2, step 4891/7134 completed (loss: 0.042350634932518005, acc: 0.9925373196601868)
[2024-12-17 05:24:17,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:17,854][root][INFO] - Training Epoch: 2/2, step 4892/7134 completed (loss: 0.044995855540037155, acc: 0.9899328947067261)
[2024-12-17 05:24:17,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:18,274][root][INFO] - Training Epoch: 2/2, step 4893/7134 completed (loss: 0.12850677967071533, acc: 0.9656991958618164)
[2024-12-17 05:24:18,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:18,714][root][INFO] - Training Epoch: 2/2, step 4894/7134 completed (loss: 0.01579592563211918, acc: 0.9971181750297546)
[2024-12-17 05:24:18,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:19,155][root][INFO] - Training Epoch: 2/2, step 4895/7134 completed (loss: 0.007424950134009123, acc: 0.9987499713897705)
[2024-12-17 05:24:19,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:19,553][root][INFO] - Training Epoch: 2/2, step 4896/7134 completed (loss: 0.012832165695726871, acc: 0.9971910119056702)
[2024-12-17 05:24:19,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:19,999][root][INFO] - Training Epoch: 2/2, step 4897/7134 completed (loss: 0.028359994292259216, acc: 0.988304078578949)
[2024-12-17 05:24:20,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:20,455][root][INFO] - Training Epoch: 2/2, step 4898/7134 completed (loss: 0.027319326996803284, acc: 0.9937106966972351)
[2024-12-17 05:24:20,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:20,889][root][INFO] - Training Epoch: 2/2, step 4899/7134 completed (loss: 0.030355870723724365, acc: 0.9941775798797607)
[2024-12-17 05:24:20,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:21,319][root][INFO] - Training Epoch: 2/2, step 4900/7134 completed (loss: 0.02515624463558197, acc: 0.9947368502616882)
[2024-12-17 05:24:21,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:21,754][root][INFO] - Training Epoch: 2/2, step 4901/7134 completed (loss: 0.020415889099240303, acc: 0.9939849376678467)
[2024-12-17 05:24:21,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:22,211][root][INFO] - Training Epoch: 2/2, step 4902/7134 completed (loss: 0.01660272106528282, acc: 0.9933686852455139)
[2024-12-17 05:24:22,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:22,634][root][INFO] - Training Epoch: 2/2, step 4903/7134 completed (loss: 0.013059310615062714, acc: 0.9964157938957214)
[2024-12-17 05:24:22,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:23,057][root][INFO] - Training Epoch: 2/2, step 4904/7134 completed (loss: 0.009576315991580486, acc: 0.9985074400901794)
[2024-12-17 05:24:23,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:23,474][root][INFO] - Training Epoch: 2/2, step 4905/7134 completed (loss: 0.009803531691432, acc: 0.9984076619148254)
[2024-12-17 05:24:23,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:23,879][root][INFO] - Training Epoch: 2/2, step 4906/7134 completed (loss: 0.009455679915845394, acc: 0.9983136653900146)
[2024-12-17 05:24:23,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:24,299][root][INFO] - Training Epoch: 2/2, step 4907/7134 completed (loss: 0.01797289401292801, acc: 0.9952531456947327)
[2024-12-17 05:24:24,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:24,731][root][INFO] - Training Epoch: 2/2, step 4908/7134 completed (loss: 0.016119088977575302, acc: 0.9968000054359436)
[2024-12-17 05:24:24,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:25,178][root][INFO] - Training Epoch: 2/2, step 4909/7134 completed (loss: 0.012809285894036293, acc: 0.9983792304992676)
[2024-12-17 05:24:25,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:25,606][root][INFO] - Training Epoch: 2/2, step 4910/7134 completed (loss: 0.029008740559220314, acc: 0.9890282154083252)
[2024-12-17 05:24:25,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:26,055][root][INFO] - Training Epoch: 2/2, step 4911/7134 completed (loss: 0.02890651300549507, acc: 0.9934036731719971)
[2024-12-17 05:24:26,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:26,490][root][INFO] - Training Epoch: 2/2, step 4912/7134 completed (loss: 0.02496333234012127, acc: 0.9927361011505127)
[2024-12-17 05:24:26,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:26,916][root][INFO] - Training Epoch: 2/2, step 4913/7134 completed (loss: 0.023403888568282127, acc: 0.9949324131011963)
[2024-12-17 05:24:27,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:27,339][root][INFO] - Training Epoch: 2/2, step 4914/7134 completed (loss: 0.01993626356124878, acc: 0.9938837885856628)
[2024-12-17 05:24:27,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:27,807][root][INFO] - Training Epoch: 2/2, step 4915/7134 completed (loss: 0.005720720160752535, acc: 0.998410165309906)
[2024-12-17 05:24:27,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:28,193][root][INFO] - Training Epoch: 2/2, step 4916/7134 completed (loss: 0.04977323114871979, acc: 0.987864077091217)
[2024-12-17 05:24:28,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:28,637][root][INFO] - Training Epoch: 2/2, step 4917/7134 completed (loss: 0.03554360195994377, acc: 0.9902642369270325)
[2024-12-17 05:24:28,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:29,050][root][INFO] - Training Epoch: 2/2, step 4918/7134 completed (loss: 0.005532367154955864, acc: 0.9972677826881409)
[2024-12-17 05:24:29,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:29,534][root][INFO] - Training Epoch: 2/2, step 4919/7134 completed (loss: 0.029545020312070847, acc: 0.9894737005233765)
[2024-12-17 05:24:29,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:29,997][root][INFO] - Training Epoch: 2/2, step 4920/7134 completed (loss: 0.05732748657464981, acc: 0.9870800971984863)
[2024-12-17 05:24:30,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:30,409][root][INFO] - Training Epoch: 2/2, step 4921/7134 completed (loss: 0.031053083017468452, acc: 0.9942611455917358)
[2024-12-17 05:24:30,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:30,845][root][INFO] - Training Epoch: 2/2, step 4922/7134 completed (loss: 0.019532719627022743, acc: 0.994557797908783)
[2024-12-17 05:24:30,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:31,288][root][INFO] - Training Epoch: 2/2, step 4923/7134 completed (loss: 0.017120245844125748, acc: 0.9941262602806091)
[2024-12-17 05:24:31,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:31,692][root][INFO] - Training Epoch: 2/2, step 4924/7134 completed (loss: 0.03220266476273537, acc: 0.9860000014305115)
[2024-12-17 05:24:31,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:32,100][root][INFO] - Training Epoch: 2/2, step 4925/7134 completed (loss: 0.025048697367310524, acc: 0.9899857044219971)
[2024-12-17 05:24:32,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:32,506][root][INFO] - Training Epoch: 2/2, step 4926/7134 completed (loss: 0.01339851226657629, acc: 0.9971305727958679)
[2024-12-17 05:24:32,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:32,904][root][INFO] - Training Epoch: 2/2, step 4927/7134 completed (loss: 0.018212344497442245, acc: 0.9929971694946289)
[2024-12-17 05:24:32,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:33,329][root][INFO] - Training Epoch: 2/2, step 4928/7134 completed (loss: 0.009797378443181515, acc: 0.9988412261009216)
[2024-12-17 05:24:33,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:33,730][root][INFO] - Training Epoch: 2/2, step 4929/7134 completed (loss: 0.017878876999020576, acc: 0.9937984347343445)
[2024-12-17 05:24:33,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:34,140][root][INFO] - Training Epoch: 2/2, step 4930/7134 completed (loss: 0.023861488327383995, acc: 0.9954751133918762)
[2024-12-17 05:24:34,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:34,572][root][INFO] - Training Epoch: 2/2, step 4931/7134 completed (loss: 0.06855528056621552, acc: 0.9893454909324646)
[2024-12-17 05:24:34,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:35,008][root][INFO] - Training Epoch: 2/2, step 4932/7134 completed (loss: 0.02364041469991207, acc: 0.9932523369789124)
[2024-12-17 05:24:35,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:35,440][root][INFO] - Training Epoch: 2/2, step 4933/7134 completed (loss: 0.029687240719795227, acc: 0.9925834536552429)
[2024-12-17 05:24:35,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:35,879][root][INFO] - Training Epoch: 2/2, step 4934/7134 completed (loss: 0.008191456086933613, acc: 0.9959404468536377)
[2024-12-17 05:24:35,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:36,319][root][INFO] - Training Epoch: 2/2, step 4935/7134 completed (loss: 0.014488519169390202, acc: 0.99452805519104)
[2024-12-17 05:24:36,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:36,729][root][INFO] - Training Epoch: 2/2, step 4936/7134 completed (loss: 0.026993492618203163, acc: 0.9907407164573669)
[2024-12-17 05:24:36,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:37,146][root][INFO] - Training Epoch: 2/2, step 4937/7134 completed (loss: 0.01960698328912258, acc: 0.9925261735916138)
[2024-12-17 05:24:37,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:37,565][root][INFO] - Training Epoch: 2/2, step 4938/7134 completed (loss: 0.022050242871046066, acc: 0.9905533194541931)
[2024-12-17 05:24:37,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:37,993][root][INFO] - Training Epoch: 2/2, step 4939/7134 completed (loss: 0.019843555986881256, acc: 0.9918434023857117)
[2024-12-17 05:24:38,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:38,422][root][INFO] - Training Epoch: 2/2, step 4940/7134 completed (loss: 0.034288231283426285, acc: 0.9954545497894287)
[2024-12-17 05:24:38,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:38,865][root][INFO] - Training Epoch: 2/2, step 4941/7134 completed (loss: 0.027688048779964447, acc: 0.9919246435165405)
[2024-12-17 05:24:38,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:39,298][root][INFO] - Training Epoch: 2/2, step 4942/7134 completed (loss: 0.020323410630226135, acc: 0.9946380853652954)
[2024-12-17 05:24:39,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:39,730][root][INFO] - Training Epoch: 2/2, step 4943/7134 completed (loss: 0.04366879537701607, acc: 0.9822161197662354)
[2024-12-17 05:24:39,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:40,181][root][INFO] - Training Epoch: 2/2, step 4944/7134 completed (loss: 0.019095219671726227, acc: 0.9936842322349548)
[2024-12-17 05:24:40,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:40,569][root][INFO] - Training Epoch: 2/2, step 4945/7134 completed (loss: 0.03212347626686096, acc: 0.9858871102333069)
[2024-12-17 05:24:40,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:40,977][root][INFO] - Training Epoch: 2/2, step 4946/7134 completed (loss: 0.048229508101940155, acc: 0.9802197813987732)
[2024-12-17 05:24:41,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:41,392][root][INFO] - Training Epoch: 2/2, step 4947/7134 completed (loss: 0.029935311526060104, acc: 0.9911308288574219)
[2024-12-17 05:24:41,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:41,782][root][INFO] - Training Epoch: 2/2, step 4948/7134 completed (loss: 0.03911888599395752, acc: 0.9919785857200623)
[2024-12-17 05:24:41,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:42,192][root][INFO] - Training Epoch: 2/2, step 4949/7134 completed (loss: 0.02779558300971985, acc: 0.9936507940292358)
[2024-12-17 05:24:42,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:42,604][root][INFO] - Training Epoch: 2/2, step 4950/7134 completed (loss: 0.01085971761494875, acc: 0.996497392654419)
[2024-12-17 05:24:42,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:43,027][root][INFO] - Training Epoch: 2/2, step 4951/7134 completed (loss: 0.025589222088456154, acc: 0.994301974773407)
[2024-12-17 05:24:43,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:43,488][root][INFO] - Training Epoch: 2/2, step 4952/7134 completed (loss: 0.03729553148150444, acc: 0.9933775067329407)
[2024-12-17 05:24:43,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:43,852][root][INFO] - Training Epoch: 2/2, step 4953/7134 completed (loss: 0.010850644670426846, acc: 0.9978213310241699)
[2024-12-17 05:24:43,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:44,258][root][INFO] - Training Epoch: 2/2, step 4954/7134 completed (loss: 0.011882727034389973, acc: 0.9942857027053833)
[2024-12-17 05:24:44,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:44,632][root][INFO] - Training Epoch: 2/2, step 4955/7134 completed (loss: 0.022017838433384895, acc: 0.9906322956085205)
[2024-12-17 05:24:44,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:45,045][root][INFO] - Training Epoch: 2/2, step 4956/7134 completed (loss: 0.013753270730376244, acc: 0.9957325458526611)
[2024-12-17 05:24:45,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:45,450][root][INFO] - Training Epoch: 2/2, step 4957/7134 completed (loss: 0.021865420043468475, acc: 0.9876543283462524)
[2024-12-17 05:24:45,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:45,868][root][INFO] - Training Epoch: 2/2, step 4958/7134 completed (loss: 0.01586810126900673, acc: 0.9942445755004883)
[2024-12-17 05:24:45,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:46,282][root][INFO] - Training Epoch: 2/2, step 4959/7134 completed (loss: 0.012827449478209019, acc: 0.9911764860153198)
[2024-12-17 05:24:46,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:46,700][root][INFO] - Training Epoch: 2/2, step 4960/7134 completed (loss: 0.009456116706132889, acc: 1.0)
[2024-12-17 05:24:46,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:47,152][root][INFO] - Training Epoch: 2/2, step 4961/7134 completed (loss: 0.01113098207861185, acc: 0.9963570237159729)
[2024-12-17 05:24:47,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:47,598][root][INFO] - Training Epoch: 2/2, step 4962/7134 completed (loss: 0.002656955039128661, acc: 0.9984447956085205)
[2024-12-17 05:24:47,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:48,021][root][INFO] - Training Epoch: 2/2, step 4963/7134 completed (loss: 0.0234408900141716, acc: 0.9918830990791321)
[2024-12-17 05:24:48,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:48,435][root][INFO] - Training Epoch: 2/2, step 4964/7134 completed (loss: 0.018571987748146057, acc: 0.9934959411621094)
[2024-12-17 05:24:48,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:48,855][root][INFO] - Training Epoch: 2/2, step 4965/7134 completed (loss: 0.03919657692313194, acc: 0.9894958138465881)
[2024-12-17 05:24:48,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:49,260][root][INFO] - Training Epoch: 2/2, step 4966/7134 completed (loss: 0.04042490944266319, acc: 0.9916897416114807)
[2024-12-17 05:24:49,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:49,667][root][INFO] - Training Epoch: 2/2, step 4967/7134 completed (loss: 0.023112237453460693, acc: 0.99609375)
[2024-12-17 05:24:49,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:50,108][root][INFO] - Training Epoch: 2/2, step 4968/7134 completed (loss: 0.0787828117609024, acc: 0.9804270267486572)
[2024-12-17 05:24:50,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:50,568][root][INFO] - Training Epoch: 2/2, step 4969/7134 completed (loss: 0.06120065599679947, acc: 0.9810996651649475)
[2024-12-17 05:24:50,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:50,991][root][INFO] - Training Epoch: 2/2, step 4970/7134 completed (loss: 0.01795043982565403, acc: 0.9933110475540161)
[2024-12-17 05:24:51,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:51,419][root][INFO] - Training Epoch: 2/2, step 4971/7134 completed (loss: 0.017486829310655594, acc: 0.989830493927002)
[2024-12-17 05:24:51,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:51,864][root][INFO] - Training Epoch: 2/2, step 4972/7134 completed (loss: 0.014856647700071335, acc: 0.995768666267395)
[2024-12-17 05:24:51,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:52,283][root][INFO] - Training Epoch: 2/2, step 4973/7134 completed (loss: 0.03568407893180847, acc: 0.991769552230835)
[2024-12-17 05:24:52,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:52,662][root][INFO] - Training Epoch: 2/2, step 4974/7134 completed (loss: 0.04278815910220146, acc: 0.9879759550094604)
[2024-12-17 05:24:52,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:53,096][root][INFO] - Training Epoch: 2/2, step 4975/7134 completed (loss: 0.06434813886880875, acc: 0.9872204661369324)
[2024-12-17 05:24:53,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:53,477][root][INFO] - Training Epoch: 2/2, step 4976/7134 completed (loss: 0.021076997742056847, acc: 0.9906322956085205)
[2024-12-17 05:24:53,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:53,904][root][INFO] - Training Epoch: 2/2, step 4977/7134 completed (loss: 0.06384586542844772, acc: 0.9870967864990234)
[2024-12-17 05:24:54,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:54,321][root][INFO] - Training Epoch: 2/2, step 4978/7134 completed (loss: 0.029614146798849106, acc: 0.992546558380127)
[2024-12-17 05:24:54,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:54,739][root][INFO] - Training Epoch: 2/2, step 4979/7134 completed (loss: 0.1037994846701622, acc: 0.9769357442855835)
[2024-12-17 05:24:54,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:55,190][root][INFO] - Training Epoch: 2/2, step 4980/7134 completed (loss: 0.060389742255210876, acc: 0.9838969111442566)
[2024-12-17 05:24:55,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:55,650][root][INFO] - Training Epoch: 2/2, step 4981/7134 completed (loss: 0.03982802852988243, acc: 0.9872408509254456)
[2024-12-17 05:24:55,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:56,071][root][INFO] - Training Epoch: 2/2, step 4982/7134 completed (loss: 0.06670349091291428, acc: 0.97773277759552)
[2024-12-17 05:24:56,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:56,521][root][INFO] - Training Epoch: 2/2, step 4983/7134 completed (loss: 0.045439716428518295, acc: 0.985981285572052)
[2024-12-17 05:24:56,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:56,879][root][INFO] - Training Epoch: 2/2, step 4984/7134 completed (loss: 0.0691034123301506, acc: 0.9833333492279053)
[2024-12-17 05:24:56,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:57,230][root][INFO] - Training Epoch: 2/2, step 4985/7134 completed (loss: 0.029278414323925972, acc: 0.9908257126808167)
[2024-12-17 05:24:57,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:57,665][root][INFO] - Training Epoch: 2/2, step 4986/7134 completed (loss: 0.07948032021522522, acc: 0.9851411581039429)
[2024-12-17 05:24:57,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:58,077][root][INFO] - Training Epoch: 2/2, step 4987/7134 completed (loss: 0.0298369899392128, acc: 0.9920477271080017)
[2024-12-17 05:24:58,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:58,499][root][INFO] - Training Epoch: 2/2, step 4988/7134 completed (loss: 0.016760868951678276, acc: 0.9929328560829163)
[2024-12-17 05:24:58,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:58,901][root][INFO] - Training Epoch: 2/2, step 4989/7134 completed (loss: 0.08149024099111557, acc: 0.9851484894752502)
[2024-12-17 05:24:59,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:59,313][root][INFO] - Training Epoch: 2/2, step 4990/7134 completed (loss: 0.04027627781033516, acc: 0.9881756901741028)
[2024-12-17 05:24:59,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:24:59,746][root][INFO] - Training Epoch: 2/2, step 4991/7134 completed (loss: 0.020041579380631447, acc: 0.9932998418807983)
[2024-12-17 05:24:59,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:00,189][root][INFO] - Training Epoch: 2/2, step 4992/7134 completed (loss: 0.0981781929731369, acc: 0.9759299755096436)
[2024-12-17 05:25:00,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:00,532][root][INFO] - Training Epoch: 2/2, step 4993/7134 completed (loss: 0.010909692384302616, acc: 1.0)
[2024-12-17 05:25:00,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:00,994][root][INFO] - Training Epoch: 2/2, step 4994/7134 completed (loss: 0.02739487588405609, acc: 0.9914893507957458)
[2024-12-17 05:25:01,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:01,386][root][INFO] - Training Epoch: 2/2, step 4995/7134 completed (loss: 0.04043195769190788, acc: 0.9877551198005676)
[2024-12-17 05:25:01,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:01,799][root][INFO] - Training Epoch: 2/2, step 4996/7134 completed (loss: 0.024377793073654175, acc: 0.9889298677444458)
[2024-12-17 05:25:01,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:02,269][root][INFO] - Training Epoch: 2/2, step 4997/7134 completed (loss: 0.04170437157154083, acc: 0.9880136847496033)
[2024-12-17 05:25:02,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:02,666][root][INFO] - Training Epoch: 2/2, step 4998/7134 completed (loss: 0.07765089720487595, acc: 0.9836065769195557)
[2024-12-17 05:25:02,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:03,076][root][INFO] - Training Epoch: 2/2, step 4999/7134 completed (loss: 0.020018426701426506, acc: 0.9948365092277527)
[2024-12-17 05:25:03,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:03,493][root][INFO] - Training Epoch: 2/2, step 5000/7134 completed (loss: 0.021106913685798645, acc: 0.9930232763290405)
[2024-12-17 05:25:03,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:03,938][root][INFO] - Training Epoch: 2/2, step 5001/7134 completed (loss: 0.040422841906547546, acc: 0.992732584476471)
[2024-12-17 05:25:04,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:04,354][root][INFO] - Training Epoch: 2/2, step 5002/7134 completed (loss: 0.05355392396450043, acc: 0.9925650358200073)
[2024-12-17 05:25:04,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:04,751][root][INFO] - Training Epoch: 2/2, step 5003/7134 completed (loss: 0.018485048785805702, acc: 0.9968000054359436)
[2024-12-17 05:25:04,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:05,168][root][INFO] - Training Epoch: 2/2, step 5004/7134 completed (loss: 0.009478842839598656, acc: 0.9977924823760986)
[2024-12-17 05:25:05,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:05,574][root][INFO] - Training Epoch: 2/2, step 5005/7134 completed (loss: 0.06652531772851944, acc: 0.9804878234863281)
[2024-12-17 05:25:05,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:06,013][root][INFO] - Training Epoch: 2/2, step 5006/7134 completed (loss: 0.024369793012738228, acc: 0.9926578402519226)
[2024-12-17 05:25:06,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:06,424][root][INFO] - Training Epoch: 2/2, step 5007/7134 completed (loss: 0.00964612327516079, acc: 0.9971751570701599)
[2024-12-17 05:25:06,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:06,893][root][INFO] - Training Epoch: 2/2, step 5008/7134 completed (loss: 0.054003529250621796, acc: 0.9881889820098877)
[2024-12-17 05:25:07,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:07,402][root][INFO] - Training Epoch: 2/2, step 5009/7134 completed (loss: 0.055188219994306564, acc: 0.9875930547714233)
[2024-12-17 05:25:07,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:07,804][root][INFO] - Training Epoch: 2/2, step 5010/7134 completed (loss: 0.04015135392546654, acc: 0.9939271211624146)
[2024-12-17 05:25:07,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:08,261][root][INFO] - Training Epoch: 2/2, step 5011/7134 completed (loss: 0.043626680970191956, acc: 0.9902439117431641)
[2024-12-17 05:25:08,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:08,657][root][INFO] - Training Epoch: 2/2, step 5012/7134 completed (loss: 0.05509747192263603, acc: 0.982758641242981)
[2024-12-17 05:25:08,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:09,074][root][INFO] - Training Epoch: 2/2, step 5013/7134 completed (loss: 0.00915718823671341, acc: 0.9979959726333618)
[2024-12-17 05:25:09,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:09,542][root][INFO] - Training Epoch: 2/2, step 5014/7134 completed (loss: 0.03529110550880432, acc: 0.9877049326896667)
[2024-12-17 05:25:09,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:09,981][root][INFO] - Training Epoch: 2/2, step 5015/7134 completed (loss: 0.07713731378316879, acc: 0.9848275780677795)
[2024-12-17 05:25:10,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:10,396][root][INFO] - Training Epoch: 2/2, step 5016/7134 completed (loss: 0.014958207495510578, acc: 0.994575023651123)
[2024-12-17 05:25:10,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:10,813][root][INFO] - Training Epoch: 2/2, step 5017/7134 completed (loss: 0.017068928107619286, acc: 0.9945945739746094)
[2024-12-17 05:25:10,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:11,230][root][INFO] - Training Epoch: 2/2, step 5018/7134 completed (loss: 0.022941768169403076, acc: 0.9858155846595764)
[2024-12-17 05:25:11,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:11,667][root][INFO] - Training Epoch: 2/2, step 5019/7134 completed (loss: 0.017227549105882645, acc: 0.995726466178894)
[2024-12-17 05:25:11,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:12,150][root][INFO] - Training Epoch: 2/2, step 5020/7134 completed (loss: 0.03326038271188736, acc: 0.9900000095367432)
[2024-12-17 05:25:12,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:12,565][root][INFO] - Training Epoch: 2/2, step 5021/7134 completed (loss: 0.04328111931681633, acc: 0.9885583519935608)
[2024-12-17 05:25:12,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:12,992][root][INFO] - Training Epoch: 2/2, step 5022/7134 completed (loss: 0.03290775418281555, acc: 0.9922839403152466)
[2024-12-17 05:25:13,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:13,451][root][INFO] - Training Epoch: 2/2, step 5023/7134 completed (loss: 0.030924750491976738, acc: 0.9878419637680054)
[2024-12-17 05:25:13,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:13,899][root][INFO] - Training Epoch: 2/2, step 5024/7134 completed (loss: 0.037725940346717834, acc: 0.993565022945404)
[2024-12-17 05:25:14,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:14,322][root][INFO] - Training Epoch: 2/2, step 5025/7134 completed (loss: 0.010760155506432056, acc: 0.9981883764266968)
[2024-12-17 05:25:14,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:14,753][root][INFO] - Training Epoch: 2/2, step 5026/7134 completed (loss: 0.025508025661110878, acc: 0.9912434220314026)
[2024-12-17 05:25:14,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:15,177][root][INFO] - Training Epoch: 2/2, step 5027/7134 completed (loss: 0.027984745800495148, acc: 0.9890710115432739)
[2024-12-17 05:25:15,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:15,593][root][INFO] - Training Epoch: 2/2, step 5028/7134 completed (loss: 0.018103251233696938, acc: 0.9937304258346558)
[2024-12-17 05:25:15,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:15,985][root][INFO] - Training Epoch: 2/2, step 5029/7134 completed (loss: 0.012232260778546333, acc: 0.9962121248245239)
[2024-12-17 05:25:16,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:16,420][root][INFO] - Training Epoch: 2/2, step 5030/7134 completed (loss: 0.01125937607139349, acc: 0.9972714781761169)
[2024-12-17 05:25:16,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:16,840][root][INFO] - Training Epoch: 2/2, step 5031/7134 completed (loss: 0.06588002294301987, acc: 0.9863945841789246)
[2024-12-17 05:25:16,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:17,251][root][INFO] - Training Epoch: 2/2, step 5032/7134 completed (loss: 0.017193427309393883, acc: 0.9983766078948975)
[2024-12-17 05:25:17,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:17,669][root][INFO] - Training Epoch: 2/2, step 5033/7134 completed (loss: 0.015126312151551247, acc: 0.9967948794364929)
[2024-12-17 05:25:17,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:18,093][root][INFO] - Training Epoch: 2/2, step 5034/7134 completed (loss: 0.011453530751168728, acc: 0.9946808218955994)
[2024-12-17 05:25:18,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:18,496][root][INFO] - Training Epoch: 2/2, step 5035/7134 completed (loss: 0.003427129238843918, acc: 1.0)
[2024-12-17 05:25:18,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:18,923][root][INFO] - Training Epoch: 2/2, step 5036/7134 completed (loss: 0.04859918728470802, acc: 0.9866071343421936)
[2024-12-17 05:25:19,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:19,351][root][INFO] - Training Epoch: 2/2, step 5037/7134 completed (loss: 0.04562893509864807, acc: 0.9906166195869446)
[2024-12-17 05:25:19,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:19,790][root][INFO] - Training Epoch: 2/2, step 5038/7134 completed (loss: 0.04218070209026337, acc: 0.9888641238212585)
[2024-12-17 05:25:19,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:20,194][root][INFO] - Training Epoch: 2/2, step 5039/7134 completed (loss: 0.02996968664228916, acc: 0.9905063509941101)
[2024-12-17 05:25:20,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:20,581][root][INFO] - Training Epoch: 2/2, step 5040/7134 completed (loss: 0.016861531883478165, acc: 0.9961758852005005)
[2024-12-17 05:25:20,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:21,025][root][INFO] - Training Epoch: 2/2, step 5041/7134 completed (loss: 0.007863891310989857, acc: 0.9973474740982056)
[2024-12-17 05:25:21,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:21,415][root][INFO] - Training Epoch: 2/2, step 5042/7134 completed (loss: 0.04459045082330704, acc: 0.9930070042610168)
[2024-12-17 05:25:21,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:21,791][root][INFO] - Training Epoch: 2/2, step 5043/7134 completed (loss: 0.023183787241578102, acc: 0.992094874382019)
[2024-12-17 05:25:21,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:22,234][root][INFO] - Training Epoch: 2/2, step 5044/7134 completed (loss: 0.01649586297571659, acc: 0.9970760345458984)
[2024-12-17 05:25:22,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:22,679][root][INFO] - Training Epoch: 2/2, step 5045/7134 completed (loss: 0.04317638650536537, acc: 0.983849287033081)
[2024-12-17 05:25:22,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:23,083][root][INFO] - Training Epoch: 2/2, step 5046/7134 completed (loss: 0.051389340311288834, acc: 0.9842105507850647)
[2024-12-17 05:25:23,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:23,473][root][INFO] - Training Epoch: 2/2, step 5047/7134 completed (loss: 0.05851907655596733, acc: 0.9851239919662476)
[2024-12-17 05:25:23,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:23,921][root][INFO] - Training Epoch: 2/2, step 5048/7134 completed (loss: 0.0359087698161602, acc: 0.9923896789550781)
[2024-12-17 05:25:24,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:24,326][root][INFO] - Training Epoch: 2/2, step 5049/7134 completed (loss: 0.061419714242219925, acc: 0.9836512207984924)
[2024-12-17 05:25:24,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:24,768][root][INFO] - Training Epoch: 2/2, step 5050/7134 completed (loss: 0.048357829451560974, acc: 0.9887482523918152)
[2024-12-17 05:25:24,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:25,191][root][INFO] - Training Epoch: 2/2, step 5051/7134 completed (loss: 0.049989815801382065, acc: 0.9869565367698669)
[2024-12-17 05:25:25,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:25,605][root][INFO] - Training Epoch: 2/2, step 5052/7134 completed (loss: 0.024586783722043037, acc: 0.9863636493682861)
[2024-12-17 05:25:25,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:26,040][root][INFO] - Training Epoch: 2/2, step 5053/7134 completed (loss: 0.06109901890158653, acc: 0.9867924451828003)
[2024-12-17 05:25:26,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:26,502][root][INFO] - Training Epoch: 2/2, step 5054/7134 completed (loss: 0.059854548424482346, acc: 0.9826498627662659)
[2024-12-17 05:25:26,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:26,931][root][INFO] - Training Epoch: 2/2, step 5055/7134 completed (loss: 0.013199983164668083, acc: 0.9959183931350708)
[2024-12-17 05:25:27,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:27,368][root][INFO] - Training Epoch: 2/2, step 5056/7134 completed (loss: 0.06345313787460327, acc: 0.9841269850730896)
[2024-12-17 05:25:27,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:27,809][root][INFO] - Training Epoch: 2/2, step 5057/7134 completed (loss: 0.08459903299808502, acc: 0.9815078377723694)
[2024-12-17 05:25:27,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:28,256][root][INFO] - Training Epoch: 2/2, step 5058/7134 completed (loss: 0.06687882542610168, acc: 0.9797101616859436)
[2024-12-17 05:25:28,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:28,706][root][INFO] - Training Epoch: 2/2, step 5059/7134 completed (loss: 0.04379669576883316, acc: 0.9868938326835632)
[2024-12-17 05:25:28,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:29,156][root][INFO] - Training Epoch: 2/2, step 5060/7134 completed (loss: 0.02459423430263996, acc: 0.9955423474311829)
[2024-12-17 05:25:29,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:29,561][root][INFO] - Training Epoch: 2/2, step 5061/7134 completed (loss: 0.04233919084072113, acc: 0.9848812222480774)
[2024-12-17 05:25:29,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:29,988][root][INFO] - Training Epoch: 2/2, step 5062/7134 completed (loss: 0.07172199338674545, acc: 0.9828473329544067)
[2024-12-17 05:25:30,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:30,420][root][INFO] - Training Epoch: 2/2, step 5063/7134 completed (loss: 0.038766391575336456, acc: 0.989983320236206)
[2024-12-17 05:25:30,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:30,864][root][INFO] - Training Epoch: 2/2, step 5064/7134 completed (loss: 0.02355341985821724, acc: 0.9948630332946777)
[2024-12-17 05:25:30,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:31,326][root][INFO] - Training Epoch: 2/2, step 5065/7134 completed (loss: 0.047995273023843765, acc: 0.9929478168487549)
[2024-12-17 05:25:31,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:31,759][root][INFO] - Training Epoch: 2/2, step 5066/7134 completed (loss: 0.042524728924036026, acc: 0.9833585619926453)
[2024-12-17 05:25:31,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:32,171][root][INFO] - Training Epoch: 2/2, step 5067/7134 completed (loss: 0.030067380517721176, acc: 0.9922027587890625)
[2024-12-17 05:25:32,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:32,579][root][INFO] - Training Epoch: 2/2, step 5068/7134 completed (loss: 0.030330732464790344, acc: 0.9921011328697205)
[2024-12-17 05:25:32,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:32,999][root][INFO] - Training Epoch: 2/2, step 5069/7134 completed (loss: 0.018640052527189255, acc: 0.9921875)
[2024-12-17 05:25:33,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:33,375][root][INFO] - Training Epoch: 2/2, step 5070/7134 completed (loss: 0.012554408051073551, acc: 0.9942528605461121)
[2024-12-17 05:25:33,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:33,785][root][INFO] - Training Epoch: 2/2, step 5071/7134 completed (loss: 0.04727119952440262, acc: 0.9873772859573364)
[2024-12-17 05:25:33,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:34,212][root][INFO] - Training Epoch: 2/2, step 5072/7134 completed (loss: 0.05278245732188225, acc: 0.9849435091018677)
[2024-12-17 05:25:34,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:34,622][root][INFO] - Training Epoch: 2/2, step 5073/7134 completed (loss: 0.05279730632901192, acc: 0.9864603281021118)
[2024-12-17 05:25:34,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:35,061][root][INFO] - Training Epoch: 2/2, step 5074/7134 completed (loss: 0.05213793367147446, acc: 0.9867330193519592)
[2024-12-17 05:25:35,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:35,460][root][INFO] - Training Epoch: 2/2, step 5075/7134 completed (loss: 0.03846883401274681, acc: 0.9922480583190918)
[2024-12-17 05:25:35,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:35,913][root][INFO] - Training Epoch: 2/2, step 5076/7134 completed (loss: 0.04418344050645828, acc: 0.9928229451179504)
[2024-12-17 05:25:35,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:36,354][root][INFO] - Training Epoch: 2/2, step 5077/7134 completed (loss: 0.024135209619998932, acc: 0.9952531456947327)
[2024-12-17 05:25:36,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:36,767][root][INFO] - Training Epoch: 2/2, step 5078/7134 completed (loss: 0.06421719491481781, acc: 0.9832636117935181)
[2024-12-17 05:25:36,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:37,175][root][INFO] - Training Epoch: 2/2, step 5079/7134 completed (loss: 0.019632263109087944, acc: 0.9931972622871399)
[2024-12-17 05:25:37,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:37,627][root][INFO] - Training Epoch: 2/2, step 5080/7134 completed (loss: 0.016751671209931374, acc: 0.9940898418426514)
[2024-12-17 05:25:37,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:38,074][root][INFO] - Training Epoch: 2/2, step 5081/7134 completed (loss: 0.017329763621091843, acc: 0.991847813129425)
[2024-12-17 05:25:38,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:38,524][root][INFO] - Training Epoch: 2/2, step 5082/7134 completed (loss: 0.028671206906437874, acc: 0.9897959232330322)
[2024-12-17 05:25:38,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:38,949][root][INFO] - Training Epoch: 2/2, step 5083/7134 completed (loss: 0.03292001783847809, acc: 0.9943740963935852)
[2024-12-17 05:25:39,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:39,419][root][INFO] - Training Epoch: 2/2, step 5084/7134 completed (loss: 0.014747953042387962, acc: 0.9953703880310059)
[2024-12-17 05:25:39,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:39,892][root][INFO] - Training Epoch: 2/2, step 5085/7134 completed (loss: 0.024802226573228836, acc: 0.9917159676551819)
[2024-12-17 05:25:40,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:40,311][root][INFO] - Training Epoch: 2/2, step 5086/7134 completed (loss: 0.0380902960896492, acc: 0.9911054372787476)
[2024-12-17 05:25:40,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:40,754][root][INFO] - Training Epoch: 2/2, step 5087/7134 completed (loss: 0.00946497917175293, acc: 0.9959839582443237)
[2024-12-17 05:25:40,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:41,186][root][INFO] - Training Epoch: 2/2, step 5088/7134 completed (loss: 0.00858263485133648, acc: 1.0)
[2024-12-17 05:25:41,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:41,630][root][INFO] - Training Epoch: 2/2, step 5089/7134 completed (loss: 0.03453363850712776, acc: 0.9950124621391296)
[2024-12-17 05:25:41,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:42,080][root][INFO] - Training Epoch: 2/2, step 5090/7134 completed (loss: 0.01583111472427845, acc: 0.9953325390815735)
[2024-12-17 05:25:42,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:42,527][root][INFO] - Training Epoch: 2/2, step 5091/7134 completed (loss: 0.009252732619643211, acc: 0.9973649382591248)
[2024-12-17 05:25:42,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:42,952][root][INFO] - Training Epoch: 2/2, step 5092/7134 completed (loss: 0.029176833108067513, acc: 0.9958506226539612)
[2024-12-17 05:25:43,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:43,378][root][INFO] - Training Epoch: 2/2, step 5093/7134 completed (loss: 0.020237552002072334, acc: 0.9930939078330994)
[2024-12-17 05:25:43,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:43,805][root][INFO] - Training Epoch: 2/2, step 5094/7134 completed (loss: 0.03144687041640282, acc: 0.9927272796630859)
[2024-12-17 05:25:43,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:44,223][root][INFO] - Training Epoch: 2/2, step 5095/7134 completed (loss: 0.07810283452272415, acc: 0.9828392863273621)
[2024-12-17 05:25:44,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:44,670][root][INFO] - Training Epoch: 2/2, step 5096/7134 completed (loss: 0.028060488402843475, acc: 0.99190753698349)
[2024-12-17 05:25:44,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:45,112][root][INFO] - Training Epoch: 2/2, step 5097/7134 completed (loss: 0.02598155103623867, acc: 0.990231990814209)
[2024-12-17 05:25:45,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:45,563][root][INFO] - Training Epoch: 2/2, step 5098/7134 completed (loss: 0.019356196746230125, acc: 0.993250846862793)
[2024-12-17 05:25:45,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:46,024][root][INFO] - Training Epoch: 2/2, step 5099/7134 completed (loss: 0.02117057517170906, acc: 0.9930716156959534)
[2024-12-17 05:25:46,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:46,477][root][INFO] - Training Epoch: 2/2, step 5100/7134 completed (loss: 0.04834103211760521, acc: 0.9889867901802063)
[2024-12-17 05:25:46,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:46,912][root][INFO] - Training Epoch: 2/2, step 5101/7134 completed (loss: 0.012920900247991085, acc: 0.996503472328186)
[2024-12-17 05:25:47,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:47,329][root][INFO] - Training Epoch: 2/2, step 5102/7134 completed (loss: 0.03962649405002594, acc: 0.9890859723091125)
[2024-12-17 05:25:47,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:47,800][root][INFO] - Training Epoch: 2/2, step 5103/7134 completed (loss: 0.03510152921080589, acc: 0.9885452389717102)
[2024-12-17 05:25:47,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:48,267][root][INFO] - Training Epoch: 2/2, step 5104/7134 completed (loss: 0.017990397289395332, acc: 0.9966777563095093)
[2024-12-17 05:25:48,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:48,674][root][INFO] - Training Epoch: 2/2, step 5105/7134 completed (loss: 0.023502875119447708, acc: 0.9895678162574768)
[2024-12-17 05:25:48,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:49,133][root][INFO] - Training Epoch: 2/2, step 5106/7134 completed (loss: 0.016329659149050713, acc: 0.9970370531082153)
[2024-12-17 05:25:49,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:49,560][root][INFO] - Training Epoch: 2/2, step 5107/7134 completed (loss: 0.08885239064693451, acc: 0.9841521382331848)
[2024-12-17 05:25:49,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:49,971][root][INFO] - Training Epoch: 2/2, step 5108/7134 completed (loss: 0.057026274502277374, acc: 0.9825783967971802)
[2024-12-17 05:25:50,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:50,439][root][INFO] - Training Epoch: 2/2, step 5109/7134 completed (loss: 0.04661795124411583, acc: 0.9856194853782654)
[2024-12-17 05:25:50,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:50,874][root][INFO] - Training Epoch: 2/2, step 5110/7134 completed (loss: 0.04796844720840454, acc: 0.9871794581413269)
[2024-12-17 05:25:50,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:51,290][root][INFO] - Training Epoch: 2/2, step 5111/7134 completed (loss: 0.01885390281677246, acc: 0.9917808175086975)
[2024-12-17 05:25:51,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:51,733][root][INFO] - Training Epoch: 2/2, step 5112/7134 completed (loss: 0.042430244386196136, acc: 0.9925280213356018)
[2024-12-17 05:25:51,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:52,131][root][INFO] - Training Epoch: 2/2, step 5113/7134 completed (loss: 0.045844193547964096, acc: 0.983582079410553)
[2024-12-17 05:25:52,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:52,593][root][INFO] - Training Epoch: 2/2, step 5114/7134 completed (loss: 0.03081115148961544, acc: 0.9916550517082214)
[2024-12-17 05:25:52,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:53,022][root][INFO] - Training Epoch: 2/2, step 5115/7134 completed (loss: 0.02457084320485592, acc: 0.9922580718994141)
[2024-12-17 05:25:53,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:53,480][root][INFO] - Training Epoch: 2/2, step 5116/7134 completed (loss: 0.019194239750504494, acc: 0.9935064911842346)
[2024-12-17 05:25:53,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:53,902][root][INFO] - Training Epoch: 2/2, step 5117/7134 completed (loss: 0.024949220940470695, acc: 0.9958158731460571)
[2024-12-17 05:25:54,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:54,289][root][INFO] - Training Epoch: 2/2, step 5118/7134 completed (loss: 0.04059423878788948, acc: 0.9924127459526062)
[2024-12-17 05:25:54,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:54,723][root][INFO] - Training Epoch: 2/2, step 5119/7134 completed (loss: 0.03288910537958145, acc: 0.9944979548454285)
[2024-12-17 05:25:54,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:55,140][root][INFO] - Training Epoch: 2/2, step 5120/7134 completed (loss: 0.059204209595918655, acc: 0.985602080821991)
[2024-12-17 05:25:55,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:55,563][root][INFO] - Training Epoch: 2/2, step 5121/7134 completed (loss: 0.017048237845301628, acc: 0.994452178478241)
[2024-12-17 05:25:55,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:55,982][root][INFO] - Training Epoch: 2/2, step 5122/7134 completed (loss: 0.05729253217577934, acc: 0.9845288395881653)
[2024-12-17 05:25:56,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:56,427][root][INFO] - Training Epoch: 2/2, step 5123/7134 completed (loss: 0.02219126932322979, acc: 0.9951748847961426)
[2024-12-17 05:25:56,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:56,872][root][INFO] - Training Epoch: 2/2, step 5124/7134 completed (loss: 0.031671199947595596, acc: 0.991304337978363)
[2024-12-17 05:25:57,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:57,300][root][INFO] - Training Epoch: 2/2, step 5125/7134 completed (loss: 0.025037232786417007, acc: 0.9936808943748474)
[2024-12-17 05:25:57,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:57,745][root][INFO] - Training Epoch: 2/2, step 5126/7134 completed (loss: 0.012565319426357746, acc: 0.9965811967849731)
[2024-12-17 05:25:57,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:58,160][root][INFO] - Training Epoch: 2/2, step 5127/7134 completed (loss: 0.03290834650397301, acc: 0.988811194896698)
[2024-12-17 05:25:58,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:58,599][root][INFO] - Training Epoch: 2/2, step 5128/7134 completed (loss: 0.014014092274010181, acc: 0.9967032670974731)
[2024-12-17 05:25:58,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:59,032][root][INFO] - Training Epoch: 2/2, step 5129/7134 completed (loss: 0.04590606689453125, acc: 0.9862744808197021)
[2024-12-17 05:25:59,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:59,456][root][INFO] - Training Epoch: 2/2, step 5130/7134 completed (loss: 0.017062559723854065, acc: 0.9937597513198853)
[2024-12-17 05:25:59,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:25:59,901][root][INFO] - Training Epoch: 2/2, step 5131/7134 completed (loss: 0.03796249255537987, acc: 0.9935064911842346)
[2024-12-17 05:26:00,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:00,303][root][INFO] - Training Epoch: 2/2, step 5132/7134 completed (loss: 0.008076727390289307, acc: 1.0)
[2024-12-17 05:26:00,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:00,737][root][INFO] - Training Epoch: 2/2, step 5133/7134 completed (loss: 0.0449933223426342, acc: 0.9829192757606506)
[2024-12-17 05:26:00,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:01,180][root][INFO] - Training Epoch: 2/2, step 5134/7134 completed (loss: 0.011189576238393784, acc: 0.998123824596405)
[2024-12-17 05:26:01,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:01,584][root][INFO] - Training Epoch: 2/2, step 5135/7134 completed (loss: 0.05216638371348381, acc: 0.9885714054107666)
[2024-12-17 05:26:01,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:02,025][root][INFO] - Training Epoch: 2/2, step 5136/7134 completed (loss: 0.03028944320976734, acc: 0.9877049326896667)
[2024-12-17 05:26:02,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:02,456][root][INFO] - Training Epoch: 2/2, step 5137/7134 completed (loss: 0.017783598974347115, acc: 0.9944953918457031)
[2024-12-17 05:26:02,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:02,904][root][INFO] - Training Epoch: 2/2, step 5138/7134 completed (loss: 0.019034231081604958, acc: 0.9950000047683716)
[2024-12-17 05:26:03,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:03,304][root][INFO] - Training Epoch: 2/2, step 5139/7134 completed (loss: 0.018583305180072784, acc: 0.9928469061851501)
[2024-12-17 05:26:03,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:03,750][root][INFO] - Training Epoch: 2/2, step 5140/7134 completed (loss: 0.019196858629584312, acc: 0.9957582354545593)
[2024-12-17 05:26:03,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:04,056][root][INFO] - Training Epoch: 2/2, step 5141/7134 completed (loss: 0.023617342114448547, acc: 0.9961389899253845)
[2024-12-17 05:26:04,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:04,495][root][INFO] - Training Epoch: 2/2, step 5142/7134 completed (loss: 0.02888939343392849, acc: 0.9929412007331848)
[2024-12-17 05:26:04,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:04,941][root][INFO] - Training Epoch: 2/2, step 5143/7134 completed (loss: 0.02277543395757675, acc: 0.9936548471450806)
[2024-12-17 05:26:05,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:05,382][root][INFO] - Training Epoch: 2/2, step 5144/7134 completed (loss: 0.01412408147007227, acc: 0.9976662993431091)
[2024-12-17 05:26:05,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:05,849][root][INFO] - Training Epoch: 2/2, step 5145/7134 completed (loss: 0.008865058422088623, acc: 1.0)
[2024-12-17 05:26:05,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:06,304][root][INFO] - Training Epoch: 2/2, step 5146/7134 completed (loss: 0.04244314134120941, acc: 0.9888517260551453)
[2024-12-17 05:26:06,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:06,692][root][INFO] - Training Epoch: 2/2, step 5147/7134 completed (loss: 0.03934883698821068, acc: 0.9904371500015259)
[2024-12-17 05:26:06,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:07,102][root][INFO] - Training Epoch: 2/2, step 5148/7134 completed (loss: 0.05183293670415878, acc: 0.9906790852546692)
[2024-12-17 05:26:07,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:07,567][root][INFO] - Training Epoch: 2/2, step 5149/7134 completed (loss: 0.03408532962203026, acc: 0.9900497794151306)
[2024-12-17 05:26:07,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:07,995][root][INFO] - Training Epoch: 2/2, step 5150/7134 completed (loss: 0.05440237745642662, acc: 0.9739243984222412)
[2024-12-17 05:26:08,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:08,418][root][INFO] - Training Epoch: 2/2, step 5151/7134 completed (loss: 0.040561068803071976, acc: 0.9888613820075989)
[2024-12-17 05:26:08,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:08,864][root][INFO] - Training Epoch: 2/2, step 5152/7134 completed (loss: 0.026278056204319, acc: 0.989276111125946)
[2024-12-17 05:26:08,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:09,307][root][INFO] - Training Epoch: 2/2, step 5153/7134 completed (loss: 0.018767697736620903, acc: 0.9958847761154175)
[2024-12-17 05:26:09,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:09,809][root][INFO] - Training Epoch: 2/2, step 5154/7134 completed (loss: 0.026576336473226547, acc: 0.9908987283706665)
[2024-12-17 05:26:09,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:10,300][root][INFO] - Training Epoch: 2/2, step 5155/7134 completed (loss: 0.03909407928586006, acc: 0.9939758777618408)
[2024-12-17 05:26:10,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:10,799][root][INFO] - Training Epoch: 2/2, step 5156/7134 completed (loss: 0.018462102860212326, acc: 0.9920555949211121)
[2024-12-17 05:26:10,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:11,243][root][INFO] - Training Epoch: 2/2, step 5157/7134 completed (loss: 0.054051414132118225, acc: 0.9828850626945496)
[2024-12-17 05:26:11,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:11,686][root][INFO] - Training Epoch: 2/2, step 5158/7134 completed (loss: 0.06629980355501175, acc: 0.9821958541870117)
[2024-12-17 05:26:11,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:12,121][root][INFO] - Training Epoch: 2/2, step 5159/7134 completed (loss: 0.027238672599196434, acc: 0.9921976327896118)
[2024-12-17 05:26:12,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:12,543][root][INFO] - Training Epoch: 2/2, step 5160/7134 completed (loss: 0.05458365008234978, acc: 0.9827089309692383)
[2024-12-17 05:26:12,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:12,978][root][INFO] - Training Epoch: 2/2, step 5161/7134 completed (loss: 0.07618904858827591, acc: 0.9748252034187317)
[2024-12-17 05:26:13,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:13,421][root][INFO] - Training Epoch: 2/2, step 5162/7134 completed (loss: 0.02076634019613266, acc: 0.9951377511024475)
[2024-12-17 05:26:13,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:13,838][root][INFO] - Training Epoch: 2/2, step 5163/7134 completed (loss: 0.017078019678592682, acc: 0.9943342804908752)
[2024-12-17 05:26:14,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:14,307][root][INFO] - Training Epoch: 2/2, step 5164/7134 completed (loss: 0.021730447188019753, acc: 0.9966386556625366)
[2024-12-17 05:26:14,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:14,782][root][INFO] - Training Epoch: 2/2, step 5165/7134 completed (loss: 0.031716566532850266, acc: 0.9939758777618408)
[2024-12-17 05:26:14,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:15,205][root][INFO] - Training Epoch: 2/2, step 5166/7134 completed (loss: 0.010013686493039131, acc: 0.9969558715820312)
[2024-12-17 05:26:15,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:15,625][root][INFO] - Training Epoch: 2/2, step 5167/7134 completed (loss: 0.050850898027420044, acc: 0.9791666865348816)
[2024-12-17 05:26:15,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:16,042][root][INFO] - Training Epoch: 2/2, step 5168/7134 completed (loss: 0.0338614284992218, acc: 0.989130437374115)
[2024-12-17 05:26:16,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:16,473][root][INFO] - Training Epoch: 2/2, step 5169/7134 completed (loss: 0.062438368797302246, acc: 0.9828660488128662)
[2024-12-17 05:26:16,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:16,914][root][INFO] - Training Epoch: 2/2, step 5170/7134 completed (loss: 0.029900843277573586, acc: 0.990728497505188)
[2024-12-17 05:26:17,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:17,284][root][INFO] - Training Epoch: 2/2, step 5171/7134 completed (loss: 0.028659338131546974, acc: 0.9914529919624329)
[2024-12-17 05:26:17,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:17,708][root][INFO] - Training Epoch: 2/2, step 5172/7134 completed (loss: 0.066731758415699, acc: 0.9795570969581604)
[2024-12-17 05:26:17,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:18,105][root][INFO] - Training Epoch: 2/2, step 5173/7134 completed (loss: 0.03565999120473862, acc: 0.9858267903327942)
[2024-12-17 05:26:18,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:18,543][root][INFO] - Training Epoch: 2/2, step 5174/7134 completed (loss: 0.015429495833814144, acc: 0.9961685538291931)
[2024-12-17 05:26:18,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:18,987][root][INFO] - Training Epoch: 2/2, step 5175/7134 completed (loss: 0.011626167222857475, acc: 0.9972375631332397)
[2024-12-17 05:26:19,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:19,431][root][INFO] - Training Epoch: 2/2, step 5176/7134 completed (loss: 0.018783440813422203, acc: 0.9939302206039429)
[2024-12-17 05:26:19,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:19,877][root][INFO] - Training Epoch: 2/2, step 5177/7134 completed (loss: 0.07514709234237671, acc: 0.9826086759567261)
[2024-12-17 05:26:19,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:20,292][root][INFO] - Training Epoch: 2/2, step 5178/7134 completed (loss: 0.10296240448951721, acc: 0.9790940880775452)
[2024-12-17 05:26:20,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:20,708][root][INFO] - Training Epoch: 2/2, step 5179/7134 completed (loss: 0.021305976435542107, acc: 0.9926035404205322)
[2024-12-17 05:26:20,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:21,123][root][INFO] - Training Epoch: 2/2, step 5180/7134 completed (loss: 0.0623762421309948, acc: 0.9793621301651001)
[2024-12-17 05:26:21,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:21,509][root][INFO] - Training Epoch: 2/2, step 5181/7134 completed (loss: 0.07151343673467636, acc: 0.978723406791687)
[2024-12-17 05:26:21,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:21,923][root][INFO] - Training Epoch: 2/2, step 5182/7134 completed (loss: 0.13548970222473145, acc: 0.9583333134651184)
[2024-12-17 05:26:22,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:22,341][root][INFO] - Training Epoch: 2/2, step 5183/7134 completed (loss: 0.056584179401397705, acc: 0.9851484894752502)
[2024-12-17 05:26:22,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:22,729][root][INFO] - Training Epoch: 2/2, step 5184/7134 completed (loss: 0.02884531393647194, acc: 0.9926650524139404)
[2024-12-17 05:26:22,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:23,137][root][INFO] - Training Epoch: 2/2, step 5185/7134 completed (loss: 0.03491329774260521, acc: 0.9903614521026611)
[2024-12-17 05:26:23,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:23,546][root][INFO] - Training Epoch: 2/2, step 5186/7134 completed (loss: 0.04793929681181908, acc: 0.9837067127227783)
[2024-12-17 05:26:23,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:23,949][root][INFO] - Training Epoch: 2/2, step 5187/7134 completed (loss: 0.016758153215050697, acc: 0.9961904883384705)
[2024-12-17 05:26:24,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:24,400][root][INFO] - Training Epoch: 2/2, step 5188/7134 completed (loss: 0.12857985496520996, acc: 0.9654545187950134)
[2024-12-17 05:26:24,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:24,735][root][INFO] - Training Epoch: 2/2, step 5189/7134 completed (loss: 0.10768979787826538, acc: 0.9693877696990967)
[2024-12-17 05:26:24,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:25,087][root][INFO] - Training Epoch: 2/2, step 5190/7134 completed (loss: 0.07187491655349731, acc: 0.980997622013092)
[2024-12-17 05:26:25,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:25,543][root][INFO] - Training Epoch: 2/2, step 5191/7134 completed (loss: 0.09988255798816681, acc: 0.9765739440917969)
[2024-12-17 05:26:25,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:25,985][root][INFO] - Training Epoch: 2/2, step 5192/7134 completed (loss: 0.05075286328792572, acc: 0.9869203567504883)
[2024-12-17 05:26:26,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:26,411][root][INFO] - Training Epoch: 2/2, step 5193/7134 completed (loss: 0.033743273466825485, acc: 0.9881889820098877)
[2024-12-17 05:26:26,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:26,832][root][INFO] - Training Epoch: 2/2, step 5194/7134 completed (loss: 0.07541950792074203, acc: 0.9722772240638733)
[2024-12-17 05:26:26,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:27,183][root][INFO] - Training Epoch: 2/2, step 5195/7134 completed (loss: 0.042773377150297165, acc: 0.9868420958518982)
[2024-12-17 05:26:27,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:27,558][root][INFO] - Training Epoch: 2/2, step 5196/7134 completed (loss: 0.04198168218135834, acc: 0.9880383014678955)
[2024-12-17 05:26:27,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:27,955][root][INFO] - Training Epoch: 2/2, step 5197/7134 completed (loss: 0.03443391993641853, acc: 0.9876543283462524)
[2024-12-17 05:26:28,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:28,340][root][INFO] - Training Epoch: 2/2, step 5198/7134 completed (loss: 0.03245113417506218, acc: 0.9896050095558167)
[2024-12-17 05:26:28,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:28,806][root][INFO] - Training Epoch: 2/2, step 5199/7134 completed (loss: 0.0801856592297554, acc: 0.9767441749572754)
[2024-12-17 05:26:28,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:29,224][root][INFO] - Training Epoch: 2/2, step 5200/7134 completed (loss: 0.0237282607704401, acc: 0.990176796913147)
[2024-12-17 05:26:29,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:29,668][root][INFO] - Training Epoch: 2/2, step 5201/7134 completed (loss: 0.048083968460559845, acc: 0.9891435503959656)
[2024-12-17 05:26:29,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:30,085][root][INFO] - Training Epoch: 2/2, step 5202/7134 completed (loss: 0.05705159530043602, acc: 0.9821428656578064)
[2024-12-17 05:26:30,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:30,528][root][INFO] - Training Epoch: 2/2, step 5203/7134 completed (loss: 0.05121280997991562, acc: 0.9863945841789246)
[2024-12-17 05:26:30,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:30,963][root][INFO] - Training Epoch: 2/2, step 5204/7134 completed (loss: 0.024073701351881027, acc: 0.9938144087791443)
[2024-12-17 05:26:31,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:31,354][root][INFO] - Training Epoch: 2/2, step 5205/7134 completed (loss: 0.04148570075631142, acc: 0.9850187301635742)
[2024-12-17 05:26:31,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:31,801][root][INFO] - Training Epoch: 2/2, step 5206/7134 completed (loss: 0.043384213000535965, acc: 0.9919742941856384)
[2024-12-17 05:26:31,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:32,189][root][INFO] - Training Epoch: 2/2, step 5207/7134 completed (loss: 0.06304093450307846, acc: 0.9839034080505371)
[2024-12-17 05:26:32,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:32,682][root][INFO] - Training Epoch: 2/2, step 5208/7134 completed (loss: 0.022975845262408257, acc: 0.9934036731719971)
[2024-12-17 05:26:32,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:33,100][root][INFO] - Training Epoch: 2/2, step 5209/7134 completed (loss: 0.04424430802464485, acc: 0.9859437942504883)
[2024-12-17 05:26:33,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:33,567][root][INFO] - Training Epoch: 2/2, step 5210/7134 completed (loss: 0.03166533261537552, acc: 0.9933244585990906)
[2024-12-17 05:26:33,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:34,010][root][INFO] - Training Epoch: 2/2, step 5211/7134 completed (loss: 0.04473127797245979, acc: 0.984375)
[2024-12-17 05:26:34,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:34,396][root][INFO] - Training Epoch: 2/2, step 5212/7134 completed (loss: 0.048021283000707626, acc: 0.9863481521606445)
[2024-12-17 05:26:34,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:34,820][root][INFO] - Training Epoch: 2/2, step 5213/7134 completed (loss: 0.03773197904229164, acc: 0.9946042895317078)
[2024-12-17 05:26:34,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:35,225][root][INFO] - Training Epoch: 2/2, step 5214/7134 completed (loss: 0.11305226385593414, acc: 0.9763948321342468)
[2024-12-17 05:26:35,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:35,690][root][INFO] - Training Epoch: 2/2, step 5215/7134 completed (loss: 0.05906055122613907, acc: 0.9833971858024597)
[2024-12-17 05:26:35,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:36,026][root][INFO] - Training Epoch: 2/2, step 5216/7134 completed (loss: 0.0673786848783493, acc: 0.9771863222122192)
[2024-12-17 05:26:36,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:36,407][root][INFO] - Training Epoch: 2/2, step 5217/7134 completed (loss: 0.05452371761202812, acc: 0.9786585569381714)
[2024-12-17 05:26:36,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:36,776][root][INFO] - Training Epoch: 2/2, step 5218/7134 completed (loss: 0.044716473668813705, acc: 0.9887640476226807)
[2024-12-17 05:26:36,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:37,159][root][INFO] - Training Epoch: 2/2, step 5219/7134 completed (loss: 0.04362659528851509, acc: 0.9927361011505127)
[2024-12-17 05:26:37,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:37,509][root][INFO] - Training Epoch: 2/2, step 5220/7134 completed (loss: 0.05424456670880318, acc: 0.9785330891609192)
[2024-12-17 05:26:37,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:37,934][root][INFO] - Training Epoch: 2/2, step 5221/7134 completed (loss: 0.0540771409869194, acc: 0.9844236969947815)
[2024-12-17 05:26:38,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:38,247][root][INFO] - Training Epoch: 2/2, step 5222/7134 completed (loss: 0.020096754655241966, acc: 0.9937694668769836)
[2024-12-17 05:26:38,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:38,654][root][INFO] - Training Epoch: 2/2, step 5223/7134 completed (loss: 0.020367002114653587, acc: 0.9953917264938354)
[2024-12-17 05:26:38,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:39,070][root][INFO] - Training Epoch: 2/2, step 5224/7134 completed (loss: 0.05283487215638161, acc: 0.9859402179718018)
[2024-12-17 05:26:39,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:39,503][root][INFO] - Training Epoch: 2/2, step 5225/7134 completed (loss: 0.06007092073559761, acc: 0.987075924873352)
[2024-12-17 05:26:39,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:39,933][root][INFO] - Training Epoch: 2/2, step 5226/7134 completed (loss: 0.04850742593407631, acc: 0.9901153445243835)
[2024-12-17 05:26:40,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:40,389][root][INFO] - Training Epoch: 2/2, step 5227/7134 completed (loss: 0.03245441988110542, acc: 0.9922077655792236)
[2024-12-17 05:26:40,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:40,796][root][INFO] - Training Epoch: 2/2, step 5228/7134 completed (loss: 0.02414744719862938, acc: 0.9912790656089783)
[2024-12-17 05:26:40,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:41,219][root][INFO] - Training Epoch: 2/2, step 5229/7134 completed (loss: 0.028200112283229828, acc: 0.9925705790519714)
[2024-12-17 05:26:41,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:41,656][root][INFO] - Training Epoch: 2/2, step 5230/7134 completed (loss: 0.023842759430408478, acc: 0.9919137358665466)
[2024-12-17 05:26:41,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:42,114][root][INFO] - Training Epoch: 2/2, step 5231/7134 completed (loss: 0.03308882936835289, acc: 0.9924050569534302)
[2024-12-17 05:26:42,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:42,552][root][INFO] - Training Epoch: 2/2, step 5232/7134 completed (loss: 0.022987617179751396, acc: 0.994020938873291)
[2024-12-17 05:26:42,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:43,021][root][INFO] - Training Epoch: 2/2, step 5233/7134 completed (loss: 0.02233007550239563, acc: 0.994369387626648)
[2024-12-17 05:26:43,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:43,481][root][INFO] - Training Epoch: 2/2, step 5234/7134 completed (loss: 0.031105533242225647, acc: 0.9926560521125793)
[2024-12-17 05:26:43,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:43,883][root][INFO] - Training Epoch: 2/2, step 5235/7134 completed (loss: 0.029960693791508675, acc: 0.9899159669876099)
[2024-12-17 05:26:44,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:44,306][root][INFO] - Training Epoch: 2/2, step 5236/7134 completed (loss: 0.013231147080659866, acc: 0.9965277910232544)
[2024-12-17 05:26:44,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:44,734][root][INFO] - Training Epoch: 2/2, step 5237/7134 completed (loss: 0.020124560222029686, acc: 0.9910394549369812)
[2024-12-17 05:26:44,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:45,179][root][INFO] - Training Epoch: 2/2, step 5238/7134 completed (loss: 0.014795568771660328, acc: 0.9947183132171631)
[2024-12-17 05:26:45,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:45,566][root][INFO] - Training Epoch: 2/2, step 5239/7134 completed (loss: 0.022932609543204308, acc: 0.992277979850769)
[2024-12-17 05:26:45,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:45,989][root][INFO] - Training Epoch: 2/2, step 5240/7134 completed (loss: 0.02066405862569809, acc: 0.9958506226539612)
[2024-12-17 05:26:46,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:46,418][root][INFO] - Training Epoch: 2/2, step 5241/7134 completed (loss: 0.04450614005327225, acc: 0.9921630024909973)
[2024-12-17 05:26:46,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:46,871][root][INFO] - Training Epoch: 2/2, step 5242/7134 completed (loss: 0.01211324892938137, acc: 0.9966942071914673)
[2024-12-17 05:26:46,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:47,279][root][INFO] - Training Epoch: 2/2, step 5243/7134 completed (loss: 0.02812173031270504, acc: 0.9931034445762634)
[2024-12-17 05:26:47,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:47,676][root][INFO] - Training Epoch: 2/2, step 5244/7134 completed (loss: 0.01958872564136982, acc: 0.9944827556610107)
[2024-12-17 05:26:47,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:48,182][root][INFO] - Training Epoch: 2/2, step 5245/7134 completed (loss: 0.018613141030073166, acc: 0.9930192232131958)
[2024-12-17 05:26:48,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:48,600][root][INFO] - Training Epoch: 2/2, step 5246/7134 completed (loss: 0.015096795745193958, acc: 0.9938650131225586)
[2024-12-17 05:26:48,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:49,006][root][INFO] - Training Epoch: 2/2, step 5247/7134 completed (loss: 0.011013484559953213, acc: 0.9962962865829468)
[2024-12-17 05:26:49,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:49,430][root][INFO] - Training Epoch: 2/2, step 5248/7134 completed (loss: 0.04723920300602913, acc: 0.9925093650817871)
[2024-12-17 05:26:49,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:49,854][root][INFO] - Training Epoch: 2/2, step 5249/7134 completed (loss: 0.009344165213406086, acc: 0.9968553185462952)
[2024-12-17 05:26:49,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:50,306][root][INFO] - Training Epoch: 2/2, step 5250/7134 completed (loss: 0.019161546602845192, acc: 0.9936948418617249)
[2024-12-17 05:26:50,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:50,742][root][INFO] - Training Epoch: 2/2, step 5251/7134 completed (loss: 0.028730373829603195, acc: 0.9890909194946289)
[2024-12-17 05:26:50,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:51,138][root][INFO] - Training Epoch: 2/2, step 5252/7134 completed (loss: 0.05118545517325401, acc: 0.9836448431015015)
[2024-12-17 05:26:51,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:51,568][root][INFO] - Training Epoch: 2/2, step 5253/7134 completed (loss: 0.01634959876537323, acc: 0.9950980544090271)
[2024-12-17 05:26:51,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:52,022][root][INFO] - Training Epoch: 2/2, step 5254/7134 completed (loss: 0.0535406619310379, acc: 0.9847198724746704)
[2024-12-17 05:26:52,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:52,460][root][INFO] - Training Epoch: 2/2, step 5255/7134 completed (loss: 0.04411691054701805, acc: 0.9931507110595703)
[2024-12-17 05:26:52,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:52,901][root][INFO] - Training Epoch: 2/2, step 5256/7134 completed (loss: 0.04765999689698219, acc: 0.984544038772583)
[2024-12-17 05:26:53,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:53,332][root][INFO] - Training Epoch: 2/2, step 5257/7134 completed (loss: 0.057405631989240646, acc: 0.9863013625144958)
[2024-12-17 05:26:53,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:53,773][root][INFO] - Training Epoch: 2/2, step 5258/7134 completed (loss: 0.030833175405859947, acc: 0.9923469424247742)
[2024-12-17 05:26:53,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:54,199][root][INFO] - Training Epoch: 2/2, step 5259/7134 completed (loss: 0.06766986846923828, acc: 0.9873417615890503)
[2024-12-17 05:26:54,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:54,649][root][INFO] - Training Epoch: 2/2, step 5260/7134 completed (loss: 0.028192494064569473, acc: 0.9902439117431641)
[2024-12-17 05:26:54,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:55,066][root][INFO] - Training Epoch: 2/2, step 5261/7134 completed (loss: 0.042654816061258316, acc: 0.9846153855323792)
[2024-12-17 05:26:55,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:55,529][root][INFO] - Training Epoch: 2/2, step 5262/7134 completed (loss: 0.01867154985666275, acc: 0.9944827556610107)
[2024-12-17 05:26:55,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:55,949][root][INFO] - Training Epoch: 2/2, step 5263/7134 completed (loss: 0.05261578783392906, acc: 0.9929824471473694)
[2024-12-17 05:26:56,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:56,411][root][INFO] - Training Epoch: 2/2, step 5264/7134 completed (loss: 0.02002631314098835, acc: 0.9914945363998413)
[2024-12-17 05:26:56,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:56,869][root][INFO] - Training Epoch: 2/2, step 5265/7134 completed (loss: 0.025713138282299042, acc: 0.9949173927307129)
[2024-12-17 05:26:57,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:57,303][root][INFO] - Training Epoch: 2/2, step 5266/7134 completed (loss: 0.02607676386833191, acc: 0.9931507110595703)
[2024-12-17 05:26:57,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:57,716][root][INFO] - Training Epoch: 2/2, step 5267/7134 completed (loss: 0.07857795804738998, acc: 0.9766718745231628)
[2024-12-17 05:26:57,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:58,133][root][INFO] - Training Epoch: 2/2, step 5268/7134 completed (loss: 0.039938874542713165, acc: 0.984644889831543)
[2024-12-17 05:26:58,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:58,555][root][INFO] - Training Epoch: 2/2, step 5269/7134 completed (loss: 0.08192023634910583, acc: 0.9785330891609192)
[2024-12-17 05:26:58,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:59,008][root][INFO] - Training Epoch: 2/2, step 5270/7134 completed (loss: 0.030999805778265, acc: 0.9919785857200623)
[2024-12-17 05:26:59,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:59,443][root][INFO] - Training Epoch: 2/2, step 5271/7134 completed (loss: 0.05410010740160942, acc: 0.9823633432388306)
[2024-12-17 05:26:59,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:26:59,870][root][INFO] - Training Epoch: 2/2, step 5272/7134 completed (loss: 0.03140976279973984, acc: 0.9912023544311523)
[2024-12-17 05:27:00,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:00,310][root][INFO] - Training Epoch: 2/2, step 5273/7134 completed (loss: 0.02165788970887661, acc: 0.9932088255882263)
[2024-12-17 05:27:00,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:00,755][root][INFO] - Training Epoch: 2/2, step 5274/7134 completed (loss: 0.04827030375599861, acc: 0.9865671396255493)
[2024-12-17 05:27:00,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:01,184][root][INFO] - Training Epoch: 2/2, step 5275/7134 completed (loss: 0.013245362788438797, acc: 0.9963436722755432)
[2024-12-17 05:27:01,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:01,597][root][INFO] - Training Epoch: 2/2, step 5276/7134 completed (loss: 0.03773067519068718, acc: 0.988041877746582)
[2024-12-17 05:27:01,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:02,003][root][INFO] - Training Epoch: 2/2, step 5277/7134 completed (loss: 0.02805432863533497, acc: 0.9927954077720642)
[2024-12-17 05:27:02,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:02,423][root][INFO] - Training Epoch: 2/2, step 5278/7134 completed (loss: 0.04790221527218819, acc: 0.9847095012664795)
[2024-12-17 05:27:02,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:02,852][root][INFO] - Training Epoch: 2/2, step 5279/7134 completed (loss: 0.013021085411310196, acc: 0.9961089491844177)
[2024-12-17 05:27:02,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:03,312][root][INFO] - Training Epoch: 2/2, step 5280/7134 completed (loss: 0.050946418195962906, acc: 0.9900497794151306)
[2024-12-17 05:27:03,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:03,743][root][INFO] - Training Epoch: 2/2, step 5281/7134 completed (loss: 0.025335535407066345, acc: 0.9933444261550903)
[2024-12-17 05:27:03,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:04,179][root][INFO] - Training Epoch: 2/2, step 5282/7134 completed (loss: 0.029591966420412064, acc: 0.9914407730102539)
[2024-12-17 05:27:04,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:04,620][root][INFO] - Training Epoch: 2/2, step 5283/7134 completed (loss: 0.02483290620148182, acc: 0.99452805519104)
[2024-12-17 05:27:04,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:05,044][root][INFO] - Training Epoch: 2/2, step 5284/7134 completed (loss: 0.030855799093842506, acc: 0.9930843710899353)
[2024-12-17 05:27:05,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:05,500][root][INFO] - Training Epoch: 2/2, step 5285/7134 completed (loss: 0.03410651907324791, acc: 0.9893491268157959)
[2024-12-17 05:27:05,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:05,968][root][INFO] - Training Epoch: 2/2, step 5286/7134 completed (loss: 0.028745252639055252, acc: 0.9941176176071167)
[2024-12-17 05:27:06,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:06,413][root][INFO] - Training Epoch: 2/2, step 5287/7134 completed (loss: 0.02633712813258171, acc: 0.9918699264526367)
[2024-12-17 05:27:06,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:06,846][root][INFO] - Training Epoch: 2/2, step 5288/7134 completed (loss: 0.011510726995766163, acc: 0.995398759841919)
[2024-12-17 05:27:06,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:07,289][root][INFO] - Training Epoch: 2/2, step 5289/7134 completed (loss: 0.017689647153019905, acc: 0.9943342804908752)
[2024-12-17 05:27:07,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:07,743][root][INFO] - Training Epoch: 2/2, step 5290/7134 completed (loss: 0.036412935703992844, acc: 0.9886075854301453)
[2024-12-17 05:27:07,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:08,204][root][INFO] - Training Epoch: 2/2, step 5291/7134 completed (loss: 0.030589954927563667, acc: 0.9939393997192383)
[2024-12-17 05:27:08,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:08,650][root][INFO] - Training Epoch: 2/2, step 5292/7134 completed (loss: 0.01038967352360487, acc: 0.9961832165718079)
[2024-12-17 05:27:08,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:09,098][root][INFO] - Training Epoch: 2/2, step 5293/7134 completed (loss: 0.03471909463405609, acc: 0.9941605925559998)
[2024-12-17 05:27:09,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:09,545][root][INFO] - Training Epoch: 2/2, step 5294/7134 completed (loss: 0.02384028770029545, acc: 0.9930264949798584)
[2024-12-17 05:27:09,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:09,962][root][INFO] - Training Epoch: 2/2, step 5295/7134 completed (loss: 0.011111055500805378, acc: 0.9963235259056091)
[2024-12-17 05:27:10,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:10,398][root][INFO] - Training Epoch: 2/2, step 5296/7134 completed (loss: 0.01677762158215046, acc: 0.9930459260940552)
[2024-12-17 05:27:10,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:10,821][root][INFO] - Training Epoch: 2/2, step 5297/7134 completed (loss: 0.03293108940124512, acc: 0.9899425506591797)
[2024-12-17 05:27:10,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:11,314][root][INFO] - Training Epoch: 2/2, step 5298/7134 completed (loss: 0.028777625411748886, acc: 0.9897435903549194)
[2024-12-17 05:27:11,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:11,713][root][INFO] - Training Epoch: 2/2, step 5299/7134 completed (loss: 0.016161872074007988, acc: 0.9967897534370422)
[2024-12-17 05:27:11,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:12,130][root][INFO] - Training Epoch: 2/2, step 5300/7134 completed (loss: 0.022880742326378822, acc: 0.9941262602806091)
[2024-12-17 05:27:12,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:12,535][root][INFO] - Training Epoch: 2/2, step 5301/7134 completed (loss: 0.018232760950922966, acc: 0.9941262602806091)
[2024-12-17 05:27:12,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:12,951][root][INFO] - Training Epoch: 2/2, step 5302/7134 completed (loss: 0.06788685917854309, acc: 0.9832826852798462)
[2024-12-17 05:27:13,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:13,375][root][INFO] - Training Epoch: 2/2, step 5303/7134 completed (loss: 0.056726984679698944, acc: 0.991150438785553)
[2024-12-17 05:27:13,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:13,789][root][INFO] - Training Epoch: 2/2, step 5304/7134 completed (loss: 0.06227349117398262, acc: 0.9866888523101807)
[2024-12-17 05:27:13,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:14,194][root][INFO] - Training Epoch: 2/2, step 5305/7134 completed (loss: 0.05536031723022461, acc: 0.9868612885475159)
[2024-12-17 05:27:14,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:14,621][root][INFO] - Training Epoch: 2/2, step 5306/7134 completed (loss: 0.028684822842478752, acc: 0.987500011920929)
[2024-12-17 05:27:14,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:15,053][root][INFO] - Training Epoch: 2/2, step 5307/7134 completed (loss: 0.0415600948035717, acc: 0.9907407164573669)
[2024-12-17 05:27:15,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:15,466][root][INFO] - Training Epoch: 2/2, step 5308/7134 completed (loss: 0.047540415078401566, acc: 0.9909365773200989)
[2024-12-17 05:27:15,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:15,890][root][INFO] - Training Epoch: 2/2, step 5309/7134 completed (loss: 0.08650939911603928, acc: 0.9785330891609192)
[2024-12-17 05:27:15,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:16,329][root][INFO] - Training Epoch: 2/2, step 5310/7134 completed (loss: 0.053668055683374405, acc: 0.9860529899597168)
[2024-12-17 05:27:16,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:16,763][root][INFO] - Training Epoch: 2/2, step 5311/7134 completed (loss: 0.05110037326812744, acc: 0.9887640476226807)
[2024-12-17 05:27:16,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:17,174][root][INFO] - Training Epoch: 2/2, step 5312/7134 completed (loss: 0.022424543276429176, acc: 0.9906191229820251)
[2024-12-17 05:27:17,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:17,603][root][INFO] - Training Epoch: 2/2, step 5313/7134 completed (loss: 0.03325938060879707, acc: 0.9908925294876099)
[2024-12-17 05:27:17,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:18,006][root][INFO] - Training Epoch: 2/2, step 5314/7134 completed (loss: 0.03594225272536278, acc: 0.9895470142364502)
[2024-12-17 05:27:18,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:18,426][root][INFO] - Training Epoch: 2/2, step 5315/7134 completed (loss: 0.02639516443014145, acc: 0.9918166995048523)
[2024-12-17 05:27:18,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:18,831][root][INFO] - Training Epoch: 2/2, step 5316/7134 completed (loss: 0.0435614176094532, acc: 0.9915966391563416)
[2024-12-17 05:27:18,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:19,205][root][INFO] - Training Epoch: 2/2, step 5317/7134 completed (loss: 0.020080838352441788, acc: 0.9928315281867981)
[2024-12-17 05:27:19,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:19,606][root][INFO] - Training Epoch: 2/2, step 5318/7134 completed (loss: 0.024465421214699745, acc: 0.9930915236473083)
[2024-12-17 05:27:19,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:20,029][root][INFO] - Training Epoch: 2/2, step 5319/7134 completed (loss: 0.04801193252205849, acc: 0.989051103591919)
[2024-12-17 05:27:20,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:20,455][root][INFO] - Training Epoch: 2/2, step 5320/7134 completed (loss: 0.03559236228466034, acc: 0.9922360181808472)
[2024-12-17 05:27:20,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:20,890][root][INFO] - Training Epoch: 2/2, step 5321/7134 completed (loss: 0.018095752224326134, acc: 0.9937984347343445)
[2024-12-17 05:27:20,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:21,307][root][INFO] - Training Epoch: 2/2, step 5322/7134 completed (loss: 0.011493269354104996, acc: 0.9969834089279175)
[2024-12-17 05:27:21,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:21,730][root][INFO] - Training Epoch: 2/2, step 5323/7134 completed (loss: 0.022071287035942078, acc: 0.9939393997192383)
[2024-12-17 05:27:21,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:22,153][root][INFO] - Training Epoch: 2/2, step 5324/7134 completed (loss: 0.02968541719019413, acc: 0.9907264113426208)
[2024-12-17 05:27:22,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:22,572][root][INFO] - Training Epoch: 2/2, step 5325/7134 completed (loss: 0.02471379190683365, acc: 0.9897785186767578)
[2024-12-17 05:27:22,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:22,985][root][INFO] - Training Epoch: 2/2, step 5326/7134 completed (loss: 0.03516216576099396, acc: 0.9870967864990234)
[2024-12-17 05:27:23,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:23,392][root][INFO] - Training Epoch: 2/2, step 5327/7134 completed (loss: 0.0231237281113863, acc: 0.9956458806991577)
[2024-12-17 05:27:23,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:23,784][root][INFO] - Training Epoch: 2/2, step 5328/7134 completed (loss: 0.015072152018547058, acc: 0.9963302612304688)
[2024-12-17 05:27:23,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:24,234][root][INFO] - Training Epoch: 2/2, step 5329/7134 completed (loss: 0.04452056065201759, acc: 0.9886547923088074)
[2024-12-17 05:27:24,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:24,649][root][INFO] - Training Epoch: 2/2, step 5330/7134 completed (loss: 0.03742475435137749, acc: 0.987500011920929)
[2024-12-17 05:27:24,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:25,055][root][INFO] - Training Epoch: 2/2, step 5331/7134 completed (loss: 0.04045514017343521, acc: 0.9894921183586121)
[2024-12-17 05:27:25,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:25,486][root][INFO] - Training Epoch: 2/2, step 5332/7134 completed (loss: 0.04110162332653999, acc: 0.9934959411621094)
[2024-12-17 05:27:25,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:25,891][root][INFO] - Training Epoch: 2/2, step 5333/7134 completed (loss: 0.021844735369086266, acc: 0.9937694668769836)
[2024-12-17 05:27:25,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:26,300][root][INFO] - Training Epoch: 2/2, step 5334/7134 completed (loss: 0.0560818612575531, acc: 0.992343008518219)
[2024-12-17 05:27:26,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:26,701][root][INFO] - Training Epoch: 2/2, step 5335/7134 completed (loss: 0.040364719927310944, acc: 0.9904153347015381)
[2024-12-17 05:27:26,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:27,137][root][INFO] - Training Epoch: 2/2, step 5336/7134 completed (loss: 0.03001614287495613, acc: 0.9906250238418579)
[2024-12-17 05:27:27,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:27,591][root][INFO] - Training Epoch: 2/2, step 5337/7134 completed (loss: 0.019632572308182716, acc: 0.9944320917129517)
[2024-12-17 05:27:27,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:28,081][root][INFO] - Training Epoch: 2/2, step 5338/7134 completed (loss: 0.022311687469482422, acc: 0.9942922592163086)
[2024-12-17 05:27:28,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:28,489][root][INFO] - Training Epoch: 2/2, step 5339/7134 completed (loss: 0.02606584131717682, acc: 0.9909326434135437)
[2024-12-17 05:27:28,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:28,933][root][INFO] - Training Epoch: 2/2, step 5340/7134 completed (loss: 0.057931769639253616, acc: 0.9792027473449707)
[2024-12-17 05:27:29,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:29,367][root][INFO] - Training Epoch: 2/2, step 5341/7134 completed (loss: 0.01300246361643076, acc: 0.9977400898933411)
[2024-12-17 05:27:29,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:29,824][root][INFO] - Training Epoch: 2/2, step 5342/7134 completed (loss: 0.04390140622854233, acc: 0.9826897382736206)
[2024-12-17 05:27:29,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:30,264][root][INFO] - Training Epoch: 2/2, step 5343/7134 completed (loss: 0.05781281366944313, acc: 0.9841688871383667)
[2024-12-17 05:27:30,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:30,714][root][INFO] - Training Epoch: 2/2, step 5344/7134 completed (loss: 0.028958717361092567, acc: 0.9936842322349548)
[2024-12-17 05:27:30,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:31,147][root][INFO] - Training Epoch: 2/2, step 5345/7134 completed (loss: 0.03178632631897926, acc: 0.9908046126365662)
[2024-12-17 05:27:31,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:31,592][root][INFO] - Training Epoch: 2/2, step 5346/7134 completed (loss: 0.05353754758834839, acc: 0.9863588809967041)
[2024-12-17 05:27:32,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:32,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:33,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:33,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:34,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:34,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:34,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:35,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:35,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:35,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:36,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:36,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:36,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:37,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:37,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:38,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:38,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:38,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:39,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:39,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:40,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:40,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:41,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:41,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:41,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:41,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:42,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:42,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:42,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:43,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:43,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:44,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:44,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:44,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:45,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:45,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:46,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:46,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:46,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:47,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:47,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:48,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:48,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:48,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:49,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:49,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:50,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:50,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:50,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:51,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:51,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:51,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:52,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:52,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:53,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:53,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:53,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:54,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:54,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:54,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:55,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:55,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:55,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:56,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:56,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:56,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:57,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:57,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:57,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:58,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:58,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:58,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:59,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:59,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:27:59,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:00,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:00,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:01,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:01,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:01,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:02,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:02,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:02,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:03,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:03,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:04,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:04,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:04,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:05,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:05,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:06,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:06,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:06,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:07,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:07,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:07,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:08,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:08,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:08,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:09,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:09,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:10,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:10,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:10,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:11,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:11,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:11,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:12,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:12,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:12,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:13,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:13,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:13,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:14,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:14,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:14,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:15,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:15,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:15,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:16,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:16,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:16,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:17,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:17,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:18,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:18,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:18,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:19,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:19,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:19,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:20,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:20,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:21,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:21,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:21,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:22,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:22,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:22,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:23,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:23,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:23,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:24,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:24,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:25,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:25,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:25,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:26,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:26,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:26,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:27,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:27,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:27,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:28,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:28,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:29,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:29,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:29,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:30,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:30,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:31,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:31,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:31,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:32,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:32,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:32,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:33,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:33,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:34,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:34,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:34,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:35,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:35,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:36,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:36,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:37,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:37,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:37,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:38,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:38,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:39,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:39,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:39,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:40,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:40,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:40,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:41,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:41,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:41,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:42,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:42,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:43,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:43,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:43,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:44,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:44,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:44,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:45,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:45,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:46,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:46,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:46,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:47,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:47,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:48,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:48,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:48,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:49,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:49,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:50,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:50,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:50,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:51,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:51,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:51,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:52,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:52,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:53,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:53,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:53,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:54,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:54,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:54,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:55,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:55,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:55,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:56,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:56,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:57,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:57,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:57,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:57,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:58,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:58,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:58,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:59,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:59,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:28:59,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:00,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:00,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:01,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:01,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:02,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:02,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:02,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:03,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:03,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:04,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:04,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:04,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:05,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:05,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:05,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:06,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:06,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:07,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:07,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:08,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:08,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:08,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:09,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:09,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:10,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:10,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:10,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:11,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:11,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:12,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:12,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:12,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:13,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:13,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:14,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:14,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:15,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:15,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:16,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:16,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:16,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:17,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:17,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:17,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:18,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:18,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:19,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:19,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:19,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:19,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:20,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:20,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:21,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:21,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:21,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:22,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:22,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:22,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:23,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:23,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:24,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:24,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:25,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:25,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:25,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:25,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:26,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:26,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:27,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:27,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:28,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:28,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:28,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:29,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:29,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:29,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:30,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:30,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:30,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:31,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:31,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:32,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:32,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:32,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:33,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:33,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:34,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:34,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:34,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:35,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:35,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:36,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:36,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:36,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:37,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:37,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:37,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:37,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:38,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:38,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:38,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:39,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:39,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:39,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:40,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:40,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:41,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:41,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:41,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:42,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:42,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:43,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:43,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:43,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:44,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:44,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:45,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:45,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:45,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:46,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:46,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:46,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:47,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:47,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:48,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:48,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:49,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:50,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:50,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:50,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:51,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:51,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:51,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:52,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:52,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:52,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:53,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:53,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:53,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:54,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:54,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:55,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:55,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:55,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:56,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:56,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:56,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:57,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:57,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:57,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:58,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:58,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:59,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:59,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:29:59,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:00,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:00,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:00,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:01,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:01,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:01,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:02,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:02,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:02,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:03,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:03,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:04,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:04,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:04,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:05,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:05,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:05,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:06,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:06,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:07,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:07,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:07,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:08,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:08,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:09,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:09,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:09,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:10,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:10,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:10,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:11,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:11,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:11,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:12,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:12,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:12,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:13,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:13,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:14,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:14,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:14,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:15,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:15,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:15,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:16,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:16,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:16,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:17,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:17,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:18,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:18,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:18,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:19,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:19,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:19,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:20,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:20,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:20,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:21,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:21,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:21,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:22,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:22,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:23,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:23,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:23,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:23,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:24,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:24,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:25,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:25,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:25,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:26,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:26,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:26,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:27,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:27,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:27,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:28,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:28,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:29,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:29,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:29,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:30,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:30,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:30,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:31,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:31,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:31,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:32,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:32,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:33,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:33,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:33,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:34,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:34,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:35,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:35,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:35,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:36,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:36,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:37,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:37,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:37,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:38,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:38,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:38,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:39,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:39,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:39,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:40,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:40,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:41,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:41,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:41,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:42,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:42,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:42,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:43,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:43,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:44,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:44,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:44,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:45,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:45,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:45,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:46,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:46,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:46,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:47,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:47,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:48,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:48,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:48,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:49,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:49,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:50,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:50,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:50,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:51,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:51,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:51,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:52,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:52,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:52,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:53,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:53,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:54,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:54,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:54,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:55,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:55,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:55,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:56,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:56,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:56,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:57,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:57,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:57,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:58,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:58,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:58,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:59,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:59,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:30:59,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:00,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:00,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:01,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:01,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:01,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:02,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:02,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:02,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:03,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:03,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:03,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:04,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:04,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:05,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:05,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:06,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:06,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:06,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:07,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:07,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:07,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:08,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:08,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:09,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:09,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:09,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:10,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:10,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:11,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:11,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:11,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:12,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:12,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:13,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:13,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:13,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:14,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:14,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:15,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:15,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:15,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:16,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:16,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:16,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:17,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:17,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:17,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:18,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:18,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:19,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:19,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:19,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:20,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:20,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:20,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:21,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:21,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:22,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:22,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:22,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:23,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:23,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:23,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:24,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:24,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:24,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:25,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:25,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:26,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:27,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:27,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:28,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:28,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:29,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:29,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:29,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:30,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:30,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:31,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:31,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:32,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:32,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:32,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:33,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:33,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:33,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:34,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:34,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:34,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:35,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:35,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:36,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:36,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:37,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:37,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:37,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:38,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:38,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:38,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:38,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:39,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:39,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:40,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:40,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:40,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:41,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:41,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:42,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:42,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:43,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:43,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:43,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:44,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:44,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:45,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:45,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:45,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:46,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:46,795][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.0492, device='cuda:0') eval_epoch_loss=tensor(0.0481, device='cuda:0') eval_epoch_acc=tensor(0.9868, device='cuda:0')
[2024-12-17 05:31:46,797][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-17 05:31:46,798][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 05:31:47,168][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_2_step_5347_loss_0.048072949051856995/model.pt
[2024-12-17 05:31:47,176][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-12-17 05:31:47,177][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 0.048072949051856995
[2024-12-17 05:31:47,178][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.9867501258850098
[2024-12-17 05:31:47,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:47,665][root][INFO] - Training Epoch: 2/2, step 5347/7134 completed (loss: 0.027202069759368896, acc: 0.9867374300956726)
[2024-12-17 05:31:47,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:48,122][root][INFO] - Training Epoch: 2/2, step 5348/7134 completed (loss: 0.03498879820108414, acc: 0.9889196753501892)
[2024-12-17 05:31:48,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:48,554][root][INFO] - Training Epoch: 2/2, step 5349/7134 completed (loss: 0.05005892738699913, acc: 0.9832041263580322)
[2024-12-17 05:31:48,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:48,988][root][INFO] - Training Epoch: 2/2, step 5350/7134 completed (loss: 0.03349542245268822, acc: 0.9854689836502075)
[2024-12-17 05:31:49,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:49,407][root][INFO] - Training Epoch: 2/2, step 5351/7134 completed (loss: 0.033217959105968475, acc: 0.9875930547714233)
[2024-12-17 05:31:49,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:49,813][root][INFO] - Training Epoch: 2/2, step 5352/7134 completed (loss: 0.026304328814148903, acc: 0.9896507263183594)
[2024-12-17 05:31:49,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:50,267][root][INFO] - Training Epoch: 2/2, step 5353/7134 completed (loss: 0.010372807271778584, acc: 0.9977452158927917)
[2024-12-17 05:31:50,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:50,721][root][INFO] - Training Epoch: 2/2, step 5354/7134 completed (loss: 0.0412951298058033, acc: 0.984581470489502)
[2024-12-17 05:31:50,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:51,177][root][INFO] - Training Epoch: 2/2, step 5355/7134 completed (loss: 0.06050717085599899, acc: 0.9799054265022278)
[2024-12-17 05:31:51,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:51,629][root][INFO] - Training Epoch: 2/2, step 5356/7134 completed (loss: 0.045500747859478, acc: 0.9813200235366821)
[2024-12-17 05:31:51,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:52,037][root][INFO] - Training Epoch: 2/2, step 5357/7134 completed (loss: 0.04550344869494438, acc: 0.9878048896789551)
[2024-12-17 05:31:52,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:52,479][root][INFO] - Training Epoch: 2/2, step 5358/7134 completed (loss: 0.04457265883684158, acc: 0.9903448224067688)
[2024-12-17 05:31:52,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:52,909][root][INFO] - Training Epoch: 2/2, step 5359/7134 completed (loss: 0.015651622787117958, acc: 0.996503472328186)
[2024-12-17 05:31:52,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:53,339][root][INFO] - Training Epoch: 2/2, step 5360/7134 completed (loss: 0.014336169697344303, acc: 0.9972527623176575)
[2024-12-17 05:31:53,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:53,802][root][INFO] - Training Epoch: 2/2, step 5361/7134 completed (loss: 0.022843964397907257, acc: 0.9904191493988037)
[2024-12-17 05:31:53,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:54,255][root][INFO] - Training Epoch: 2/2, step 5362/7134 completed (loss: 0.02194373868405819, acc: 0.9925373196601868)
[2024-12-17 05:31:54,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:54,674][root][INFO] - Training Epoch: 2/2, step 5363/7134 completed (loss: 0.042227741330862045, acc: 0.9811046719551086)
[2024-12-17 05:31:54,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:55,103][root][INFO] - Training Epoch: 2/2, step 5364/7134 completed (loss: 0.018427418544888496, acc: 0.9935064911842346)
[2024-12-17 05:31:55,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:55,538][root][INFO] - Training Epoch: 2/2, step 5365/7134 completed (loss: 0.0182791817933321, acc: 0.9911816716194153)
[2024-12-17 05:31:55,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:55,928][root][INFO] - Training Epoch: 2/2, step 5366/7134 completed (loss: 0.044130489230155945, acc: 0.9895833134651184)
[2024-12-17 05:31:56,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:56,370][root][INFO] - Training Epoch: 2/2, step 5367/7134 completed (loss: 0.03674733638763428, acc: 0.9886934757232666)
[2024-12-17 05:31:56,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:56,808][root][INFO] - Training Epoch: 2/2, step 5368/7134 completed (loss: 0.03200964257121086, acc: 0.9882943034172058)
[2024-12-17 05:31:56,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:57,200][root][INFO] - Training Epoch: 2/2, step 5369/7134 completed (loss: 0.019226767122745514, acc: 0.9957537055015564)
[2024-12-17 05:31:57,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:57,637][root][INFO] - Training Epoch: 2/2, step 5370/7134 completed (loss: 0.04171738028526306, acc: 0.9890109896659851)
[2024-12-17 05:31:57,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:58,076][root][INFO] - Training Epoch: 2/2, step 5371/7134 completed (loss: 0.0816434845328331, acc: 0.9767441749572754)
[2024-12-17 05:31:58,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:58,518][root][INFO] - Training Epoch: 2/2, step 5372/7134 completed (loss: 0.009149913676083088, acc: 0.9985975027084351)
[2024-12-17 05:31:58,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:58,920][root][INFO] - Training Epoch: 2/2, step 5373/7134 completed (loss: 0.0677623525261879, acc: 0.9790794849395752)
[2024-12-17 05:31:59,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:59,260][root][INFO] - Training Epoch: 2/2, step 5374/7134 completed (loss: 0.034395843744277954, acc: 0.9839228391647339)
[2024-12-17 05:31:59,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:31:59,670][root][INFO] - Training Epoch: 2/2, step 5375/7134 completed (loss: 0.03982878103852272, acc: 0.984674334526062)
[2024-12-17 05:31:59,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:00,071][root][INFO] - Training Epoch: 2/2, step 5376/7134 completed (loss: 0.02195444144308567, acc: 0.9895470142364502)
[2024-12-17 05:32:00,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:00,512][root][INFO] - Training Epoch: 2/2, step 5377/7134 completed (loss: 0.036889802664518356, acc: 0.9924127459526062)
[2024-12-17 05:32:00,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:00,952][root][INFO] - Training Epoch: 2/2, step 5378/7134 completed (loss: 0.015932580456137657, acc: 0.9963592290878296)
[2024-12-17 05:32:01,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:01,388][root][INFO] - Training Epoch: 2/2, step 5379/7134 completed (loss: 0.03127939626574516, acc: 0.9948119521141052)
[2024-12-17 05:32:01,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:01,798][root][INFO] - Training Epoch: 2/2, step 5380/7134 completed (loss: 0.03759825602173805, acc: 0.9858906269073486)
[2024-12-17 05:32:01,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:02,204][root][INFO] - Training Epoch: 2/2, step 5381/7134 completed (loss: 0.03492317348718643, acc: 0.9944211840629578)
[2024-12-17 05:32:02,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:02,609][root][INFO] - Training Epoch: 2/2, step 5382/7134 completed (loss: 0.020190853625535965, acc: 0.9914675951004028)
[2024-12-17 05:32:02,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:03,050][root][INFO] - Training Epoch: 2/2, step 5383/7134 completed (loss: 0.024188701063394547, acc: 0.9924242496490479)
[2024-12-17 05:32:03,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:03,514][root][INFO] - Training Epoch: 2/2, step 5384/7134 completed (loss: 0.010621609166264534, acc: 0.9964454770088196)
[2024-12-17 05:32:03,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:03,940][root][INFO] - Training Epoch: 2/2, step 5385/7134 completed (loss: 0.030634528025984764, acc: 0.9933949708938599)
[2024-12-17 05:32:04,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:04,390][root][INFO] - Training Epoch: 2/2, step 5386/7134 completed (loss: 0.007772423792630434, acc: 1.0)
[2024-12-17 05:32:04,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:04,837][root][INFO] - Training Epoch: 2/2, step 5387/7134 completed (loss: 0.010419790633022785, acc: 0.9961904883384705)
[2024-12-17 05:32:04,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:05,276][root][INFO] - Training Epoch: 2/2, step 5388/7134 completed (loss: 0.015063371509313583, acc: 0.997474730014801)
[2024-12-17 05:32:05,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:05,687][root][INFO] - Training Epoch: 2/2, step 5389/7134 completed (loss: 0.020141826942563057, acc: 0.9936102032661438)
[2024-12-17 05:32:05,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:06,123][root][INFO] - Training Epoch: 2/2, step 5390/7134 completed (loss: 0.03729989379644394, acc: 0.9889065027236938)
[2024-12-17 05:32:06,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:06,510][root][INFO] - Training Epoch: 2/2, step 5391/7134 completed (loss: 0.04279788210988045, acc: 0.989708423614502)
[2024-12-17 05:32:06,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:06,918][root][INFO] - Training Epoch: 2/2, step 5392/7134 completed (loss: 0.03595229610800743, acc: 0.9862805008888245)
[2024-12-17 05:32:07,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:07,345][root][INFO] - Training Epoch: 2/2, step 5393/7134 completed (loss: 0.026625115424394608, acc: 0.9921875)
[2024-12-17 05:32:07,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:07,753][root][INFO] - Training Epoch: 2/2, step 5394/7134 completed (loss: 0.0524839349091053, acc: 0.9841269850730896)
[2024-12-17 05:32:07,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:08,200][root][INFO] - Training Epoch: 2/2, step 5395/7134 completed (loss: 0.02614329755306244, acc: 0.9954751133918762)
[2024-12-17 05:32:08,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:08,625][root][INFO] - Training Epoch: 2/2, step 5396/7134 completed (loss: 0.041471436619758606, acc: 0.9894737005233765)
[2024-12-17 05:32:08,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:09,035][root][INFO] - Training Epoch: 2/2, step 5397/7134 completed (loss: 0.02241603285074234, acc: 0.9932318329811096)
[2024-12-17 05:32:09,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:09,458][root][INFO] - Training Epoch: 2/2, step 5398/7134 completed (loss: 0.029739825055003166, acc: 0.9896755218505859)
[2024-12-17 05:32:09,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:09,882][root][INFO] - Training Epoch: 2/2, step 5399/7134 completed (loss: 0.01816391758620739, acc: 0.9931600689888)
[2024-12-17 05:32:09,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:10,309][root][INFO] - Training Epoch: 2/2, step 5400/7134 completed (loss: 0.09041212499141693, acc: 0.9796238541603088)
[2024-12-17 05:32:10,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:10,730][root][INFO] - Training Epoch: 2/2, step 5401/7134 completed (loss: 0.029301408678293228, acc: 0.9935794472694397)
[2024-12-17 05:32:10,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:11,153][root][INFO] - Training Epoch: 2/2, step 5402/7134 completed (loss: 0.02220425009727478, acc: 0.9911894202232361)
[2024-12-17 05:32:11,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:11,573][root][INFO] - Training Epoch: 2/2, step 5403/7134 completed (loss: 0.05474960058927536, acc: 0.9869494438171387)
[2024-12-17 05:32:11,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:12,014][root][INFO] - Training Epoch: 2/2, step 5404/7134 completed (loss: 0.08823151141405106, acc: 0.9812080264091492)
[2024-12-17 05:32:12,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:12,466][root][INFO] - Training Epoch: 2/2, step 5405/7134 completed (loss: 0.016880519688129425, acc: 0.9930192232131958)
[2024-12-17 05:32:12,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:12,904][root][INFO] - Training Epoch: 2/2, step 5406/7134 completed (loss: 0.019901065155863762, acc: 0.9941520690917969)
[2024-12-17 05:32:13,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:13,296][root][INFO] - Training Epoch: 2/2, step 5407/7134 completed (loss: 0.03679481893777847, acc: 0.987922728061676)
[2024-12-17 05:32:13,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:13,712][root][INFO] - Training Epoch: 2/2, step 5408/7134 completed (loss: 0.07175581902265549, acc: 0.9890795350074768)
[2024-12-17 05:32:13,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:14,131][root][INFO] - Training Epoch: 2/2, step 5409/7134 completed (loss: 0.09381156414747238, acc: 0.9773070812225342)
[2024-12-17 05:32:14,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:14,553][root][INFO] - Training Epoch: 2/2, step 5410/7134 completed (loss: 0.04687568172812462, acc: 0.9881889820098877)
[2024-12-17 05:32:14,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:14,986][root][INFO] - Training Epoch: 2/2, step 5411/7134 completed (loss: 0.04219944402575493, acc: 0.9854862093925476)
[2024-12-17 05:32:15,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:15,434][root][INFO] - Training Epoch: 2/2, step 5412/7134 completed (loss: 0.08566168695688248, acc: 0.982692301273346)
[2024-12-17 05:32:15,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:15,901][root][INFO] - Training Epoch: 2/2, step 5413/7134 completed (loss: 0.06118815392255783, acc: 0.9814285635948181)
[2024-12-17 05:32:15,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:16,357][root][INFO] - Training Epoch: 2/2, step 5414/7134 completed (loss: 0.10029235482215881, acc: 0.974293053150177)
[2024-12-17 05:32:16,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:16,783][root][INFO] - Training Epoch: 2/2, step 5415/7134 completed (loss: 0.07768577337265015, acc: 0.9785100221633911)
[2024-12-17 05:32:16,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:17,251][root][INFO] - Training Epoch: 2/2, step 5416/7134 completed (loss: 0.042928069829940796, acc: 0.9872241616249084)
[2024-12-17 05:32:17,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:17,715][root][INFO] - Training Epoch: 2/2, step 5417/7134 completed (loss: 0.034157417714595795, acc: 0.995006263256073)
[2024-12-17 05:32:17,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:18,127][root][INFO] - Training Epoch: 2/2, step 5418/7134 completed (loss: 0.03939235582947731, acc: 0.9837518334388733)
[2024-12-17 05:32:18,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:18,542][root][INFO] - Training Epoch: 2/2, step 5419/7134 completed (loss: 0.09588123112916946, acc: 0.9779661297798157)
[2024-12-17 05:32:18,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:18,965][root][INFO] - Training Epoch: 2/2, step 5420/7134 completed (loss: 0.08690502494573593, acc: 0.9790209531784058)
[2024-12-17 05:32:19,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:19,404][root][INFO] - Training Epoch: 2/2, step 5421/7134 completed (loss: 0.07310371845960617, acc: 0.9843993782997131)
[2024-12-17 05:32:19,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:19,847][root][INFO] - Training Epoch: 2/2, step 5422/7134 completed (loss: 0.043630193918943405, acc: 0.9881656765937805)
[2024-12-17 05:32:19,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:20,200][root][INFO] - Training Epoch: 2/2, step 5423/7134 completed (loss: 0.04758567363023758, acc: 0.9853372573852539)
[2024-12-17 05:32:20,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:20,611][root][INFO] - Training Epoch: 2/2, step 5424/7134 completed (loss: 0.02262607403099537, acc: 0.9929577708244324)
[2024-12-17 05:32:20,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:20,988][root][INFO] - Training Epoch: 2/2, step 5425/7134 completed (loss: 0.033051300793886185, acc: 0.9922330379486084)
[2024-12-17 05:32:21,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:21,388][root][INFO] - Training Epoch: 2/2, step 5426/7134 completed (loss: 0.050469931215047836, acc: 0.9839357137680054)
[2024-12-17 05:32:21,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:21,804][root][INFO] - Training Epoch: 2/2, step 5427/7134 completed (loss: 0.022338321432471275, acc: 0.9905213117599487)
[2024-12-17 05:32:21,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:22,249][root][INFO] - Training Epoch: 2/2, step 5428/7134 completed (loss: 0.03136397525668144, acc: 0.9846677780151367)
[2024-12-17 05:32:22,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:22,648][root][INFO] - Training Epoch: 2/2, step 5429/7134 completed (loss: 0.062356606125831604, acc: 0.9855595827102661)
[2024-12-17 05:32:22,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:23,071][root][INFO] - Training Epoch: 2/2, step 5430/7134 completed (loss: 0.023103831335902214, acc: 0.9921630024909973)
[2024-12-17 05:32:23,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:23,445][root][INFO] - Training Epoch: 2/2, step 5431/7134 completed (loss: 0.028331201523542404, acc: 0.992438554763794)
[2024-12-17 05:32:23,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:23,853][root][INFO] - Training Epoch: 2/2, step 5432/7134 completed (loss: 0.018716339021921158, acc: 0.9962335228919983)
[2024-12-17 05:32:23,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:24,252][root][INFO] - Training Epoch: 2/2, step 5433/7134 completed (loss: 0.05958999693393707, acc: 0.9878787994384766)
[2024-12-17 05:32:24,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:24,662][root][INFO] - Training Epoch: 2/2, step 5434/7134 completed (loss: 0.022125782445073128, acc: 0.9959758520126343)
[2024-12-17 05:32:24,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:25,056][root][INFO] - Training Epoch: 2/2, step 5435/7134 completed (loss: 0.02225496433675289, acc: 0.9937238693237305)
[2024-12-17 05:32:25,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:25,466][root][INFO] - Training Epoch: 2/2, step 5436/7134 completed (loss: 0.03288605064153671, acc: 0.9925816059112549)
[2024-12-17 05:32:25,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:25,887][root][INFO] - Training Epoch: 2/2, step 5437/7134 completed (loss: 0.008392846211791039, acc: 1.0)
[2024-12-17 05:32:26,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:26,347][root][INFO] - Training Epoch: 2/2, step 5438/7134 completed (loss: 0.02063017152249813, acc: 0.9948320388793945)
[2024-12-17 05:32:26,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:26,781][root][INFO] - Training Epoch: 2/2, step 5439/7134 completed (loss: 0.045186180621385574, acc: 0.9825581312179565)
[2024-12-17 05:32:26,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:27,225][root][INFO] - Training Epoch: 2/2, step 5440/7134 completed (loss: 0.032834526151418686, acc: 0.9936143159866333)
[2024-12-17 05:32:27,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:27,666][root][INFO] - Training Epoch: 2/2, step 5441/7134 completed (loss: 0.024608971551060677, acc: 0.993880033493042)
[2024-12-17 05:32:27,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:28,087][root][INFO] - Training Epoch: 2/2, step 5442/7134 completed (loss: 0.01550364214926958, acc: 0.9945873022079468)
[2024-12-17 05:32:28,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:28,490][root][INFO] - Training Epoch: 2/2, step 5443/7134 completed (loss: 0.03292591869831085, acc: 0.9857954382896423)
[2024-12-17 05:32:28,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:28,912][root][INFO] - Training Epoch: 2/2, step 5444/7134 completed (loss: 0.013308852910995483, acc: 0.9927007555961609)
[2024-12-17 05:32:29,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:29,338][root][INFO] - Training Epoch: 2/2, step 5445/7134 completed (loss: 0.03862487152218819, acc: 0.9853747487068176)
[2024-12-17 05:32:29,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:29,760][root][INFO] - Training Epoch: 2/2, step 5446/7134 completed (loss: 0.019972771406173706, acc: 0.9971988797187805)
[2024-12-17 05:32:29,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:30,158][root][INFO] - Training Epoch: 2/2, step 5447/7134 completed (loss: 0.025040319189429283, acc: 0.9935587644577026)
[2024-12-17 05:32:30,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:30,616][root][INFO] - Training Epoch: 2/2, step 5448/7134 completed (loss: 0.03419924154877663, acc: 0.9846368432044983)
[2024-12-17 05:32:30,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:31,026][root][INFO] - Training Epoch: 2/2, step 5449/7134 completed (loss: 0.008686075918376446, acc: 0.9964912533760071)
[2024-12-17 05:32:31,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:31,448][root][INFO] - Training Epoch: 2/2, step 5450/7134 completed (loss: 0.024607738479971886, acc: 0.9909909963607788)
[2024-12-17 05:32:31,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:31,861][root][INFO] - Training Epoch: 2/2, step 5451/7134 completed (loss: 0.030487457290291786, acc: 0.993446946144104)
[2024-12-17 05:32:31,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:32,283][root][INFO] - Training Epoch: 2/2, step 5452/7134 completed (loss: 0.04069756716489792, acc: 0.9870800971984863)
[2024-12-17 05:32:32,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:32,725][root][INFO] - Training Epoch: 2/2, step 5453/7134 completed (loss: 0.0430438257753849, acc: 0.9889570474624634)
[2024-12-17 05:32:32,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:33,170][root][INFO] - Training Epoch: 2/2, step 5454/7134 completed (loss: 0.0203795675188303, acc: 0.9947848916053772)
[2024-12-17 05:32:33,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:33,610][root][INFO] - Training Epoch: 2/2, step 5455/7134 completed (loss: 0.08421477675437927, acc: 0.9823232293128967)
[2024-12-17 05:32:33,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:34,051][root][INFO] - Training Epoch: 2/2, step 5456/7134 completed (loss: 0.03375338762998581, acc: 0.98740553855896)
[2024-12-17 05:32:34,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:34,503][root][INFO] - Training Epoch: 2/2, step 5457/7134 completed (loss: 0.046867839992046356, acc: 0.9946308732032776)
[2024-12-17 05:32:34,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:34,941][root][INFO] - Training Epoch: 2/2, step 5458/7134 completed (loss: 0.031066685914993286, acc: 0.9910827875137329)
[2024-12-17 05:32:35,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:35,361][root][INFO] - Training Epoch: 2/2, step 5459/7134 completed (loss: 0.008273426443338394, acc: 0.9985097050666809)
[2024-12-17 05:32:35,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:35,778][root][INFO] - Training Epoch: 2/2, step 5460/7134 completed (loss: 0.031944066286087036, acc: 0.9930459260940552)
[2024-12-17 05:32:35,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:36,216][root][INFO] - Training Epoch: 2/2, step 5461/7134 completed (loss: 0.04065975919365883, acc: 0.9911699891090393)
[2024-12-17 05:32:36,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:36,662][root][INFO] - Training Epoch: 2/2, step 5462/7134 completed (loss: 0.013329500332474709, acc: 0.995708167552948)
[2024-12-17 05:32:36,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:37,116][root][INFO] - Training Epoch: 2/2, step 5463/7134 completed (loss: 0.019602492451667786, acc: 0.9938931465148926)
[2024-12-17 05:32:37,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:37,547][root][INFO] - Training Epoch: 2/2, step 5464/7134 completed (loss: 0.02805902622640133, acc: 0.9894319772720337)
[2024-12-17 05:32:37,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:37,992][root][INFO] - Training Epoch: 2/2, step 5465/7134 completed (loss: 0.04975809156894684, acc: 0.9925261735916138)
[2024-12-17 05:32:38,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:38,443][root][INFO] - Training Epoch: 2/2, step 5466/7134 completed (loss: 0.01863943226635456, acc: 0.9930955171585083)
[2024-12-17 05:32:38,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:38,912][root][INFO] - Training Epoch: 2/2, step 5467/7134 completed (loss: 0.025805849581956863, acc: 0.9953051805496216)
[2024-12-17 05:32:39,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:39,358][root][INFO] - Training Epoch: 2/2, step 5468/7134 completed (loss: 0.018169550225138664, acc: 0.9941995143890381)
[2024-12-17 05:32:39,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:39,811][root][INFO] - Training Epoch: 2/2, step 5469/7134 completed (loss: 0.02584346942603588, acc: 0.9938650131225586)
[2024-12-17 05:32:39,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:40,300][root][INFO] - Training Epoch: 2/2, step 5470/7134 completed (loss: 0.016274236142635345, acc: 0.9963855147361755)
[2024-12-17 05:32:40,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:40,759][root][INFO] - Training Epoch: 2/2, step 5471/7134 completed (loss: 0.019076954573392868, acc: 0.9932432174682617)
[2024-12-17 05:32:40,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:41,205][root][INFO] - Training Epoch: 2/2, step 5472/7134 completed (loss: 0.022169679403305054, acc: 0.9975062608718872)
[2024-12-17 05:32:41,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:41,671][root][INFO] - Training Epoch: 2/2, step 5473/7134 completed (loss: 0.016523327678442, acc: 0.9950920343399048)
[2024-12-17 05:32:41,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:42,104][root][INFO] - Training Epoch: 2/2, step 5474/7134 completed (loss: 0.019258296117186546, acc: 0.9928571581840515)
[2024-12-17 05:32:42,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:42,559][root][INFO] - Training Epoch: 2/2, step 5475/7134 completed (loss: 0.02215169183909893, acc: 0.9928876161575317)
[2024-12-17 05:32:42,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:42,981][root][INFO] - Training Epoch: 2/2, step 5476/7134 completed (loss: 0.009384301491081715, acc: 0.9956584572792053)
[2024-12-17 05:32:43,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:43,425][root][INFO] - Training Epoch: 2/2, step 5477/7134 completed (loss: 0.015328084118664265, acc: 0.9963054060935974)
[2024-12-17 05:32:43,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:43,901][root][INFO] - Training Epoch: 2/2, step 5478/7134 completed (loss: 0.0571313202381134, acc: 0.9811320900917053)
[2024-12-17 05:32:43,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:44,353][root][INFO] - Training Epoch: 2/2, step 5479/7134 completed (loss: 0.03864876180887222, acc: 0.989130437374115)
[2024-12-17 05:32:44,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:44,801][root][INFO] - Training Epoch: 2/2, step 5480/7134 completed (loss: 0.049229126423597336, acc: 0.9868420958518982)
[2024-12-17 05:32:44,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:45,210][root][INFO] - Training Epoch: 2/2, step 5481/7134 completed (loss: 0.023678679019212723, acc: 0.991919219493866)
[2024-12-17 05:32:45,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:45,954][root][INFO] - Training Epoch: 2/2, step 5482/7134 completed (loss: 0.031039249151945114, acc: 0.990326464176178)
[2024-12-17 05:32:46,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:46,448][root][INFO] - Training Epoch: 2/2, step 5483/7134 completed (loss: 0.03932078182697296, acc: 0.9888579249382019)
[2024-12-17 05:32:46,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:46,887][root][INFO] - Training Epoch: 2/2, step 5484/7134 completed (loss: 0.05199788883328438, acc: 0.9805285334587097)
[2024-12-17 05:32:46,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:47,307][root][INFO] - Training Epoch: 2/2, step 5485/7134 completed (loss: 0.05042083561420441, acc: 0.9836660623550415)
[2024-12-17 05:32:47,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:47,768][root][INFO] - Training Epoch: 2/2, step 5486/7134 completed (loss: 0.04931517690420151, acc: 0.9844290614128113)
[2024-12-17 05:32:47,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:48,201][root][INFO] - Training Epoch: 2/2, step 5487/7134 completed (loss: 0.020526016131043434, acc: 0.9918699264526367)
[2024-12-17 05:32:48,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:48,679][root][INFO] - Training Epoch: 2/2, step 5488/7134 completed (loss: 0.048792436718940735, acc: 0.9855263233184814)
[2024-12-17 05:32:48,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:49,132][root][INFO] - Training Epoch: 2/2, step 5489/7134 completed (loss: 0.038494229316711426, acc: 0.99071204662323)
[2024-12-17 05:32:49,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:49,518][root][INFO] - Training Epoch: 2/2, step 5490/7134 completed (loss: 0.014940124936401844, acc: 0.9954441785812378)
[2024-12-17 05:32:49,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:49,938][root][INFO] - Training Epoch: 2/2, step 5491/7134 completed (loss: 0.021182343363761902, acc: 0.9897360801696777)
[2024-12-17 05:32:50,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:50,361][root][INFO] - Training Epoch: 2/2, step 5492/7134 completed (loss: 0.030986212193965912, acc: 0.9932318329811096)
[2024-12-17 05:32:50,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:50,775][root][INFO] - Training Epoch: 2/2, step 5493/7134 completed (loss: 0.04028330370783806, acc: 0.9836956262588501)
[2024-12-17 05:32:50,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:51,255][root][INFO] - Training Epoch: 2/2, step 5494/7134 completed (loss: 0.01665806770324707, acc: 0.9943100810050964)
[2024-12-17 05:32:51,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:51,635][root][INFO] - Training Epoch: 2/2, step 5495/7134 completed (loss: 0.021923167631030083, acc: 0.9946236610412598)
[2024-12-17 05:32:51,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:52,042][root][INFO] - Training Epoch: 2/2, step 5496/7134 completed (loss: 0.02846749871969223, acc: 0.9922178983688354)
[2024-12-17 05:32:52,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:52,470][root][INFO] - Training Epoch: 2/2, step 5497/7134 completed (loss: 0.06542555242776871, acc: 0.9838945865631104)
[2024-12-17 05:32:52,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:52,909][root][INFO] - Training Epoch: 2/2, step 5498/7134 completed (loss: 0.029804391786456108, acc: 0.9893898963928223)
[2024-12-17 05:32:53,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:53,375][root][INFO] - Training Epoch: 2/2, step 5499/7134 completed (loss: 0.029707850888371468, acc: 0.9899497628211975)
[2024-12-17 05:32:53,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:53,805][root][INFO] - Training Epoch: 2/2, step 5500/7134 completed (loss: 0.07556914538145065, acc: 0.9863574504852295)
[2024-12-17 05:32:53,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:54,245][root][INFO] - Training Epoch: 2/2, step 5501/7134 completed (loss: 0.017170701175928116, acc: 0.9938271641731262)
[2024-12-17 05:32:54,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:54,686][root][INFO] - Training Epoch: 2/2, step 5502/7134 completed (loss: 0.030987592414021492, acc: 0.9878542423248291)
[2024-12-17 05:32:54,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:55,102][root][INFO] - Training Epoch: 2/2, step 5503/7134 completed (loss: 0.042961809784173965, acc: 0.9860835075378418)
[2024-12-17 05:32:55,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:55,550][root][INFO] - Training Epoch: 2/2, step 5504/7134 completed (loss: 0.01677931845188141, acc: 0.9927361011505127)
[2024-12-17 05:32:55,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:55,972][root][INFO] - Training Epoch: 2/2, step 5505/7134 completed (loss: 0.033020664006471634, acc: 0.9872340559959412)
[2024-12-17 05:32:56,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:56,410][root][INFO] - Training Epoch: 2/2, step 5506/7134 completed (loss: 0.026802709326148033, acc: 0.9884659647941589)
[2024-12-17 05:32:56,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:56,847][root][INFO] - Training Epoch: 2/2, step 5507/7134 completed (loss: 0.04442012310028076, acc: 0.9859943985939026)
[2024-12-17 05:32:56,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:57,298][root][INFO] - Training Epoch: 2/2, step 5508/7134 completed (loss: 0.02479671686887741, acc: 0.9906542301177979)
[2024-12-17 05:32:57,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:57,759][root][INFO] - Training Epoch: 2/2, step 5509/7134 completed (loss: 0.03161672502756119, acc: 0.9894737005233765)
[2024-12-17 05:32:57,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:58,209][root][INFO] - Training Epoch: 2/2, step 5510/7134 completed (loss: 0.04057052731513977, acc: 0.9871465563774109)
[2024-12-17 05:32:58,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:58,688][root][INFO] - Training Epoch: 2/2, step 5511/7134 completed (loss: 0.03339044377207756, acc: 0.9875565767288208)
[2024-12-17 05:32:58,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:59,125][root][INFO] - Training Epoch: 2/2, step 5512/7134 completed (loss: 0.010555717162787914, acc: 0.9973649382591248)
[2024-12-17 05:32:59,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:59,547][root][INFO] - Training Epoch: 2/2, step 5513/7134 completed (loss: 0.03863818570971489, acc: 0.98777174949646)
[2024-12-17 05:32:59,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:32:59,996][root][INFO] - Training Epoch: 2/2, step 5514/7134 completed (loss: 0.08121712505817413, acc: 0.9788557291030884)
[2024-12-17 05:33:00,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:00,416][root][INFO] - Training Epoch: 2/2, step 5515/7134 completed (loss: 0.026612645015120506, acc: 0.9914407730102539)
[2024-12-17 05:33:00,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:00,831][root][INFO] - Training Epoch: 2/2, step 5516/7134 completed (loss: 0.025465626269578934, acc: 0.9957805871963501)
[2024-12-17 05:33:00,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:01,276][root][INFO] - Training Epoch: 2/2, step 5517/7134 completed (loss: 0.0292131956666708, acc: 0.9933510422706604)
[2024-12-17 05:33:01,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:01,726][root][INFO] - Training Epoch: 2/2, step 5518/7134 completed (loss: 0.03273768723011017, acc: 0.9945651888847351)
[2024-12-17 05:33:01,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:02,170][root][INFO] - Training Epoch: 2/2, step 5519/7134 completed (loss: 0.008359231986105442, acc: 0.9972413778305054)
[2024-12-17 05:33:02,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:02,613][root][INFO] - Training Epoch: 2/2, step 5520/7134 completed (loss: 0.021037595346570015, acc: 0.9932050108909607)
[2024-12-17 05:33:02,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:03,067][root][INFO] - Training Epoch: 2/2, step 5521/7134 completed (loss: 0.03716237097978592, acc: 0.9924623370170593)
[2024-12-17 05:33:03,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:03,506][root][INFO] - Training Epoch: 2/2, step 5522/7134 completed (loss: 0.03862566128373146, acc: 0.9882352948188782)
[2024-12-17 05:33:03,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:03,911][root][INFO] - Training Epoch: 2/2, step 5523/7134 completed (loss: 0.031543049961328506, acc: 0.9915730357170105)
[2024-12-17 05:33:04,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:04,337][root][INFO] - Training Epoch: 2/2, step 5524/7134 completed (loss: 0.031053507700562477, acc: 0.9876161217689514)
[2024-12-17 05:33:04,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:04,814][root][INFO] - Training Epoch: 2/2, step 5525/7134 completed (loss: 0.025251848623156548, acc: 0.9926793575286865)
[2024-12-17 05:33:04,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:05,238][root][INFO] - Training Epoch: 2/2, step 5526/7134 completed (loss: 0.038713473826646805, acc: 0.9882179498672485)
[2024-12-17 05:33:05,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:05,662][root][INFO] - Training Epoch: 2/2, step 5527/7134 completed (loss: 0.0214151069521904, acc: 0.9932773113250732)
[2024-12-17 05:33:05,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:06,107][root][INFO] - Training Epoch: 2/2, step 5528/7134 completed (loss: 0.024799425154924393, acc: 0.9905325174331665)
[2024-12-17 05:33:06,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:06,571][root][INFO] - Training Epoch: 2/2, step 5529/7134 completed (loss: 0.04761148616671562, acc: 0.986997663974762)
[2024-12-17 05:33:06,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:07,022][root][INFO] - Training Epoch: 2/2, step 5530/7134 completed (loss: 0.024832608178257942, acc: 0.9940387606620789)
[2024-12-17 05:33:07,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:07,470][root][INFO] - Training Epoch: 2/2, step 5531/7134 completed (loss: 0.041038598865270615, acc: 0.9850560426712036)
[2024-12-17 05:33:07,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:07,932][root][INFO] - Training Epoch: 2/2, step 5532/7134 completed (loss: 0.06435063481330872, acc: 0.983930766582489)
[2024-12-17 05:33:08,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:08,400][root][INFO] - Training Epoch: 2/2, step 5533/7134 completed (loss: 0.01029685977846384, acc: 0.997732400894165)
[2024-12-17 05:33:08,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:08,862][root][INFO] - Training Epoch: 2/2, step 5534/7134 completed (loss: 0.04793241247534752, acc: 0.9836448431015015)
[2024-12-17 05:33:08,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:09,322][root][INFO] - Training Epoch: 2/2, step 5535/7134 completed (loss: 0.02733047865331173, acc: 0.9923830032348633)
[2024-12-17 05:33:09,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:09,758][root][INFO] - Training Epoch: 2/2, step 5536/7134 completed (loss: 0.019806116819381714, acc: 0.9941860437393188)
[2024-12-17 05:33:09,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:10,192][root][INFO] - Training Epoch: 2/2, step 5537/7134 completed (loss: 0.03638996183872223, acc: 0.9859976768493652)
[2024-12-17 05:33:10,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:10,665][root][INFO] - Training Epoch: 2/2, step 5538/7134 completed (loss: 0.03090624138712883, acc: 0.9920364022254944)
[2024-12-17 05:33:10,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:11,139][root][INFO] - Training Epoch: 2/2, step 5539/7134 completed (loss: 0.03266628086566925, acc: 0.9921171069145203)
[2024-12-17 05:33:11,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:11,599][root][INFO] - Training Epoch: 2/2, step 5540/7134 completed (loss: 0.03350413963198662, acc: 0.99210524559021)
[2024-12-17 05:33:11,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:12,067][root][INFO] - Training Epoch: 2/2, step 5541/7134 completed (loss: 0.025240549817681313, acc: 0.9920212626457214)
[2024-12-17 05:33:12,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:12,506][root][INFO] - Training Epoch: 2/2, step 5542/7134 completed (loss: 0.013060486875474453, acc: 0.995720386505127)
[2024-12-17 05:33:12,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:12,975][root][INFO] - Training Epoch: 2/2, step 5543/7134 completed (loss: 0.024752875789999962, acc: 0.9944567680358887)
[2024-12-17 05:33:13,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:13,454][root][INFO] - Training Epoch: 2/2, step 5544/7134 completed (loss: 0.02219313755631447, acc: 0.9935483932495117)
[2024-12-17 05:33:13,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:13,928][root][INFO] - Training Epoch: 2/2, step 5545/7134 completed (loss: 0.029339369386434555, acc: 0.991256833076477)
[2024-12-17 05:33:14,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:14,374][root][INFO] - Training Epoch: 2/2, step 5546/7134 completed (loss: 0.028402885422110558, acc: 0.9911406636238098)
[2024-12-17 05:33:14,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:14,842][root][INFO] - Training Epoch: 2/2, step 5547/7134 completed (loss: 0.03161020576953888, acc: 0.9919354915618896)
[2024-12-17 05:33:14,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:15,283][root][INFO] - Training Epoch: 2/2, step 5548/7134 completed (loss: 0.019920604303479195, acc: 0.9941860437393188)
[2024-12-17 05:33:15,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:15,692][root][INFO] - Training Epoch: 2/2, step 5549/7134 completed (loss: 0.0232933908700943, acc: 0.991428554058075)
[2024-12-17 05:33:15,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:16,139][root][INFO] - Training Epoch: 2/2, step 5550/7134 completed (loss: 0.01860293373465538, acc: 0.9952996373176575)
[2024-12-17 05:33:16,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:16,550][root][INFO] - Training Epoch: 2/2, step 5551/7134 completed (loss: 0.0655091181397438, acc: 0.9824086427688599)
[2024-12-17 05:33:16,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:17,015][root][INFO] - Training Epoch: 2/2, step 5552/7134 completed (loss: 0.009034671820700169, acc: 0.9988109469413757)
[2024-12-17 05:33:17,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:17,455][root][INFO] - Training Epoch: 2/2, step 5553/7134 completed (loss: 0.030628999695181847, acc: 0.993819534778595)
[2024-12-17 05:33:17,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:17,910][root][INFO] - Training Epoch: 2/2, step 5554/7134 completed (loss: 0.025033416226506233, acc: 0.9926650524139404)
[2024-12-17 05:33:18,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:18,340][root][INFO] - Training Epoch: 2/2, step 5555/7134 completed (loss: 0.018341397866606712, acc: 0.9959893226623535)
[2024-12-17 05:33:18,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:18,752][root][INFO] - Training Epoch: 2/2, step 5556/7134 completed (loss: 0.02852259762585163, acc: 0.9896238446235657)
[2024-12-17 05:33:18,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:19,215][root][INFO] - Training Epoch: 2/2, step 5557/7134 completed (loss: 0.02123280242085457, acc: 0.9985994100570679)
[2024-12-17 05:33:19,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:19,671][root][INFO] - Training Epoch: 2/2, step 5558/7134 completed (loss: 0.014937732368707657, acc: 0.9950310587882996)
[2024-12-17 05:33:19,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:20,131][root][INFO] - Training Epoch: 2/2, step 5559/7134 completed (loss: 0.03091663308441639, acc: 0.9962732791900635)
[2024-12-17 05:33:20,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:20,586][root][INFO] - Training Epoch: 2/2, step 5560/7134 completed (loss: 0.036245666444301605, acc: 0.9909326434135437)
[2024-12-17 05:33:20,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:20,981][root][INFO] - Training Epoch: 2/2, step 5561/7134 completed (loss: 0.03710763528943062, acc: 0.9943289160728455)
[2024-12-17 05:33:21,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:21,427][root][INFO] - Training Epoch: 2/2, step 5562/7134 completed (loss: 0.03356572613120079, acc: 0.9948805570602417)
[2024-12-17 05:33:21,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:21,881][root][INFO] - Training Epoch: 2/2, step 5563/7134 completed (loss: 0.06805097311735153, acc: 0.9894894957542419)
[2024-12-17 05:33:21,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:22,303][root][INFO] - Training Epoch: 2/2, step 5564/7134 completed (loss: 0.02955167181789875, acc: 0.9958158731460571)
[2024-12-17 05:33:22,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:22,745][root][INFO] - Training Epoch: 2/2, step 5565/7134 completed (loss: 0.008024354465305805, acc: 0.996927797794342)
[2024-12-17 05:33:22,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:23,202][root][INFO] - Training Epoch: 2/2, step 5566/7134 completed (loss: 0.010658538900315762, acc: 0.9965556859970093)
[2024-12-17 05:33:23,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:23,672][root][INFO] - Training Epoch: 2/2, step 5567/7134 completed (loss: 0.011390234343707561, acc: 0.9954338073730469)
[2024-12-17 05:33:23,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:24,087][root][INFO] - Training Epoch: 2/2, step 5568/7134 completed (loss: 0.02257666364312172, acc: 0.9935566782951355)
[2024-12-17 05:33:24,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:24,557][root][INFO] - Training Epoch: 2/2, step 5569/7134 completed (loss: 0.011015881784260273, acc: 0.9965753555297852)
[2024-12-17 05:33:24,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:24,996][root][INFO] - Training Epoch: 2/2, step 5570/7134 completed (loss: 0.017725156620144844, acc: 0.9962732791900635)
[2024-12-17 05:33:25,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:25,408][root][INFO] - Training Epoch: 2/2, step 5571/7134 completed (loss: 0.029414121061563492, acc: 0.9940564632415771)
[2024-12-17 05:33:25,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:25,833][root][INFO] - Training Epoch: 2/2, step 5572/7134 completed (loss: 0.048473991453647614, acc: 0.9890109896659851)
[2024-12-17 05:33:25,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:26,306][root][INFO] - Training Epoch: 2/2, step 5573/7134 completed (loss: 0.028131457045674324, acc: 0.9941775798797607)
[2024-12-17 05:33:26,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:26,723][root][INFO] - Training Epoch: 2/2, step 5574/7134 completed (loss: 0.005238269455730915, acc: 1.0)
[2024-12-17 05:33:26,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:27,160][root][INFO] - Training Epoch: 2/2, step 5575/7134 completed (loss: 0.01917414739727974, acc: 0.9936203956604004)
[2024-12-17 05:33:27,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:27,566][root][INFO] - Training Epoch: 2/2, step 5576/7134 completed (loss: 0.020007023587822914, acc: 0.9928366541862488)
[2024-12-17 05:33:27,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:27,988][root][INFO] - Training Epoch: 2/2, step 5577/7134 completed (loss: 0.03334485739469528, acc: 0.9912739992141724)
[2024-12-17 05:33:28,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:28,468][root][INFO] - Training Epoch: 2/2, step 5578/7134 completed (loss: 0.01075995434075594, acc: 0.9956958293914795)
[2024-12-17 05:33:28,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:28,922][root][INFO] - Training Epoch: 2/2, step 5579/7134 completed (loss: 0.024657798931002617, acc: 0.9903181195259094)
[2024-12-17 05:33:29,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:29,358][root][INFO] - Training Epoch: 2/2, step 5580/7134 completed (loss: 0.005762407090514898, acc: 0.9986357688903809)
[2024-12-17 05:33:29,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:29,818][root][INFO] - Training Epoch: 2/2, step 5581/7134 completed (loss: 0.010733270086348057, acc: 0.9960106611251831)
[2024-12-17 05:33:29,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:30,275][root][INFO] - Training Epoch: 2/2, step 5582/7134 completed (loss: 0.012641736306250095, acc: 0.9973924160003662)
[2024-12-17 05:33:30,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:30,738][root][INFO] - Training Epoch: 2/2, step 5583/7134 completed (loss: 0.018318448215723038, acc: 0.99370276927948)
[2024-12-17 05:33:30,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:31,156][root][INFO] - Training Epoch: 2/2, step 5584/7134 completed (loss: 0.008336608298122883, acc: 0.9985207319259644)
[2024-12-17 05:33:31,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:31,626][root][INFO] - Training Epoch: 2/2, step 5585/7134 completed (loss: 0.03403982147574425, acc: 0.9890909194946289)
[2024-12-17 05:33:31,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:32,018][root][INFO] - Training Epoch: 2/2, step 5586/7134 completed (loss: 0.013902484439313412, acc: 0.9982237815856934)
[2024-12-17 05:33:32,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:32,457][root][INFO] - Training Epoch: 2/2, step 5587/7134 completed (loss: 0.01767280139029026, acc: 0.9986130595207214)
[2024-12-17 05:33:32,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:32,912][root][INFO] - Training Epoch: 2/2, step 5588/7134 completed (loss: 0.007693963591009378, acc: 0.998487114906311)
[2024-12-17 05:33:33,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:33,385][root][INFO] - Training Epoch: 2/2, step 5589/7134 completed (loss: 0.024173282086849213, acc: 0.9968454241752625)
[2024-12-17 05:33:33,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:33,809][root][INFO] - Training Epoch: 2/2, step 5590/7134 completed (loss: 0.02155981957912445, acc: 0.9901408553123474)
[2024-12-17 05:33:33,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:34,228][root][INFO] - Training Epoch: 2/2, step 5591/7134 completed (loss: 0.014140399172902107, acc: 0.9934554696083069)
[2024-12-17 05:33:34,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:34,635][root][INFO] - Training Epoch: 2/2, step 5592/7134 completed (loss: 0.01551076304167509, acc: 0.9972565174102783)
[2024-12-17 05:33:34,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:35,075][root][INFO] - Training Epoch: 2/2, step 5593/7134 completed (loss: 0.01576589234173298, acc: 0.9948186278343201)
[2024-12-17 05:33:35,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:35,508][root][INFO] - Training Epoch: 2/2, step 5594/7134 completed (loss: 0.0076570650562644005, acc: 0.9973045587539673)
[2024-12-17 05:33:35,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:35,931][root][INFO] - Training Epoch: 2/2, step 5595/7134 completed (loss: 0.026790617033839226, acc: 0.9906166195869446)
[2024-12-17 05:33:36,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:36,342][root][INFO] - Training Epoch: 2/2, step 5596/7134 completed (loss: 0.008138375356793404, acc: 0.9973118305206299)
[2024-12-17 05:33:36,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:36,766][root][INFO] - Training Epoch: 2/2, step 5597/7134 completed (loss: 0.03471173346042633, acc: 0.9889807105064392)
[2024-12-17 05:33:36,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:37,181][root][INFO] - Training Epoch: 2/2, step 5598/7134 completed (loss: 0.020872704684734344, acc: 0.9958100318908691)
[2024-12-17 05:33:37,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:37,611][root][INFO] - Training Epoch: 2/2, step 5599/7134 completed (loss: 0.05752475559711456, acc: 0.9863387942314148)
[2024-12-17 05:33:37,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:38,056][root][INFO] - Training Epoch: 2/2, step 5600/7134 completed (loss: 0.015374484471976757, acc: 0.9957020282745361)
[2024-12-17 05:33:38,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:38,445][root][INFO] - Training Epoch: 2/2, step 5601/7134 completed (loss: 0.045447055250406265, acc: 0.9826086759567261)
[2024-12-17 05:33:38,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:38,856][root][INFO] - Training Epoch: 2/2, step 5602/7134 completed (loss: 0.03397579491138458, acc: 0.9871175289154053)
[2024-12-17 05:33:38,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:39,237][root][INFO] - Training Epoch: 2/2, step 5603/7134 completed (loss: 0.005289157386869192, acc: 0.9983633160591125)
[2024-12-17 05:33:39,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:39,647][root][INFO] - Training Epoch: 2/2, step 5604/7134 completed (loss: 0.03771025314927101, acc: 0.9887459874153137)
[2024-12-17 05:33:39,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:40,042][root][INFO] - Training Epoch: 2/2, step 5605/7134 completed (loss: 0.021384434774518013, acc: 0.9932088255882263)
[2024-12-17 05:33:40,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:40,443][root][INFO] - Training Epoch: 2/2, step 5606/7134 completed (loss: 0.03913787752389908, acc: 0.9850427508354187)
[2024-12-17 05:33:40,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:40,842][root][INFO] - Training Epoch: 2/2, step 5607/7134 completed (loss: 0.021968433633446693, acc: 0.9939849376678467)
[2024-12-17 05:33:40,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:41,242][root][INFO] - Training Epoch: 2/2, step 5608/7134 completed (loss: 0.023892713710665703, acc: 0.9934318661689758)
[2024-12-17 05:33:41,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:41,640][root][INFO] - Training Epoch: 2/2, step 5609/7134 completed (loss: 0.033239737153053284, acc: 0.9878261089324951)
[2024-12-17 05:33:41,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:42,020][root][INFO] - Training Epoch: 2/2, step 5610/7134 completed (loss: 0.012269492261111736, acc: 0.9959758520126343)
[2024-12-17 05:33:42,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:42,475][root][INFO] - Training Epoch: 2/2, step 5611/7134 completed (loss: 0.03771201893687248, acc: 0.9873417615890503)
[2024-12-17 05:33:42,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:42,904][root][INFO] - Training Epoch: 2/2, step 5612/7134 completed (loss: 0.03884560987353325, acc: 0.9892638325691223)
[2024-12-17 05:33:42,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:43,303][root][INFO] - Training Epoch: 2/2, step 5613/7134 completed (loss: 0.023973338305950165, acc: 0.9964221715927124)
[2024-12-17 05:33:43,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:43,718][root][INFO] - Training Epoch: 2/2, step 5614/7134 completed (loss: 0.04541093483567238, acc: 0.9885714054107666)
[2024-12-17 05:33:43,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:44,147][root][INFO] - Training Epoch: 2/2, step 5615/7134 completed (loss: 0.032546158879995346, acc: 0.9865900278091431)
[2024-12-17 05:33:44,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:44,551][root][INFO] - Training Epoch: 2/2, step 5616/7134 completed (loss: 0.011776821687817574, acc: 0.9985141158103943)
[2024-12-17 05:33:44,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:44,949][root][INFO] - Training Epoch: 2/2, step 5617/7134 completed (loss: 0.01489805057644844, acc: 0.9967532753944397)
[2024-12-17 05:33:45,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:45,380][root][INFO] - Training Epoch: 2/2, step 5618/7134 completed (loss: 0.04342380538582802, acc: 0.9804878234863281)
[2024-12-17 05:33:45,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:45,767][root][INFO] - Training Epoch: 2/2, step 5619/7134 completed (loss: 0.03335947170853615, acc: 0.9878296256065369)
[2024-12-17 05:33:45,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:46,172][root][INFO] - Training Epoch: 2/2, step 5620/7134 completed (loss: 0.033900972455739975, acc: 0.9869158864021301)
[2024-12-17 05:33:46,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:46,632][root][INFO] - Training Epoch: 2/2, step 5621/7134 completed (loss: 0.027885735034942627, acc: 0.9911054372787476)
[2024-12-17 05:33:46,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:47,075][root][INFO] - Training Epoch: 2/2, step 5622/7134 completed (loss: 0.049663763493299484, acc: 0.9918256402015686)
[2024-12-17 05:33:47,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:47,469][root][INFO] - Training Epoch: 2/2, step 5623/7134 completed (loss: 0.020381009206175804, acc: 0.9912891983985901)
[2024-12-17 05:33:47,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:47,895][root][INFO] - Training Epoch: 2/2, step 5624/7134 completed (loss: 0.026463638991117477, acc: 0.9901800155639648)
[2024-12-17 05:33:48,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:48,298][root][INFO] - Training Epoch: 2/2, step 5625/7134 completed (loss: 0.010346539318561554, acc: 0.9952940940856934)
[2024-12-17 05:33:48,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:48,705][root][INFO] - Training Epoch: 2/2, step 5626/7134 completed (loss: 0.016043229028582573, acc: 0.9949238300323486)
[2024-12-17 05:33:48,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:49,114][root][INFO] - Training Epoch: 2/2, step 5627/7134 completed (loss: 0.10049963742494583, acc: 0.9758812785148621)
[2024-12-17 05:33:49,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:49,560][root][INFO] - Training Epoch: 2/2, step 5628/7134 completed (loss: 0.034552086144685745, acc: 0.9872495532035828)
[2024-12-17 05:33:49,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:49,983][root][INFO] - Training Epoch: 2/2, step 5629/7134 completed (loss: 0.035479478538036346, acc: 0.9859402179718018)
[2024-12-17 05:33:50,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:50,391][root][INFO] - Training Epoch: 2/2, step 5630/7134 completed (loss: 0.061447035521268845, acc: 0.9794661402702332)
[2024-12-17 05:33:50,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:50,810][root][INFO] - Training Epoch: 2/2, step 5631/7134 completed (loss: 0.0702039822936058, acc: 0.9784411191940308)
[2024-12-17 05:33:50,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:51,228][root][INFO] - Training Epoch: 2/2, step 5632/7134 completed (loss: 0.033014751970767975, acc: 0.9891107082366943)
[2024-12-17 05:33:51,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:51,637][root][INFO] - Training Epoch: 2/2, step 5633/7134 completed (loss: 0.026543641462922096, acc: 0.9918566942214966)
[2024-12-17 05:33:51,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:52,046][root][INFO] - Training Epoch: 2/2, step 5634/7134 completed (loss: 0.030640264973044395, acc: 0.9930192232131958)
[2024-12-17 05:33:52,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:52,461][root][INFO] - Training Epoch: 2/2, step 5635/7134 completed (loss: 0.015458425506949425, acc: 0.9966216087341309)
[2024-12-17 05:33:52,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:52,897][root][INFO] - Training Epoch: 2/2, step 5636/7134 completed (loss: 0.036995481699705124, acc: 0.9888178706169128)
[2024-12-17 05:33:53,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:53,305][root][INFO] - Training Epoch: 2/2, step 5637/7134 completed (loss: 0.03144247084856033, acc: 0.994940996170044)
[2024-12-17 05:33:53,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:53,668][root][INFO] - Training Epoch: 2/2, step 5638/7134 completed (loss: 0.03019939363002777, acc: 0.994140625)
[2024-12-17 05:33:53,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:54,092][root][INFO] - Training Epoch: 2/2, step 5639/7134 completed (loss: 0.024631859734654427, acc: 0.9900285005569458)
[2024-12-17 05:33:54,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:54,530][root][INFO] - Training Epoch: 2/2, step 5640/7134 completed (loss: 0.03092777542769909, acc: 0.9902439117431641)
[2024-12-17 05:33:54,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:54,904][root][INFO] - Training Epoch: 2/2, step 5641/7134 completed (loss: 0.052059005945920944, acc: 0.9898989796638489)
[2024-12-17 05:33:55,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:55,305][root][INFO] - Training Epoch: 2/2, step 5642/7134 completed (loss: 0.057486847043037415, acc: 0.9848484992980957)
[2024-12-17 05:33:55,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:55,728][root][INFO] - Training Epoch: 2/2, step 5643/7134 completed (loss: 0.04862269386649132, acc: 0.9845132827758789)
[2024-12-17 05:33:55,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:56,171][root][INFO] - Training Epoch: 2/2, step 5644/7134 completed (loss: 0.02834145911037922, acc: 0.9939024448394775)
[2024-12-17 05:33:56,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:56,591][root][INFO] - Training Epoch: 2/2, step 5645/7134 completed (loss: 0.019544655457139015, acc: 0.9941089749336243)
[2024-12-17 05:33:56,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:57,015][root][INFO] - Training Epoch: 2/2, step 5646/7134 completed (loss: 0.026808829978108406, acc: 0.987261176109314)
[2024-12-17 05:33:57,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:57,443][root][INFO] - Training Epoch: 2/2, step 5647/7134 completed (loss: 0.038895245641469955, acc: 0.9891473054885864)
[2024-12-17 05:33:57,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:57,869][root][INFO] - Training Epoch: 2/2, step 5648/7134 completed (loss: 0.0650109350681305, acc: 0.9820895791053772)
[2024-12-17 05:33:57,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:58,280][root][INFO] - Training Epoch: 2/2, step 5649/7134 completed (loss: 0.05044024810194969, acc: 0.9877675771713257)
[2024-12-17 05:33:58,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:58,706][root][INFO] - Training Epoch: 2/2, step 5650/7134 completed (loss: 0.029082534834742546, acc: 0.9862778782844543)
[2024-12-17 05:33:58,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:59,128][root][INFO] - Training Epoch: 2/2, step 5651/7134 completed (loss: 0.014758465811610222, acc: 0.9970414042472839)
[2024-12-17 05:33:59,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:59,575][root][INFO] - Training Epoch: 2/2, step 5652/7134 completed (loss: 0.030526604503393173, acc: 0.9919871687889099)
[2024-12-17 05:33:59,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:33:59,932][root][INFO] - Training Epoch: 2/2, step 5653/7134 completed (loss: 0.08175302296876907, acc: 0.9791666865348816)
[2024-12-17 05:34:00,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:00,336][root][INFO] - Training Epoch: 2/2, step 5654/7134 completed (loss: 0.015992676839232445, acc: 0.9954954981803894)
[2024-12-17 05:34:00,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:00,749][root][INFO] - Training Epoch: 2/2, step 5655/7134 completed (loss: 0.05155407637357712, acc: 0.9863945841789246)
[2024-12-17 05:34:00,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:01,138][root][INFO] - Training Epoch: 2/2, step 5656/7134 completed (loss: 0.021905241534113884, acc: 0.9942857027053833)
[2024-12-17 05:34:01,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:01,541][root][INFO] - Training Epoch: 2/2, step 5657/7134 completed (loss: 0.04007033631205559, acc: 0.9926793575286865)
[2024-12-17 05:34:01,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:01,984][root][INFO] - Training Epoch: 2/2, step 5658/7134 completed (loss: 0.02769058756530285, acc: 0.9917126893997192)
[2024-12-17 05:34:02,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:02,408][root][INFO] - Training Epoch: 2/2, step 5659/7134 completed (loss: 0.020745689049363136, acc: 0.9943262338638306)
[2024-12-17 05:34:02,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:02,822][root][INFO] - Training Epoch: 2/2, step 5660/7134 completed (loss: 0.015045295469462872, acc: 0.9966942071914673)
[2024-12-17 05:34:02,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:03,262][root][INFO] - Training Epoch: 2/2, step 5661/7134 completed (loss: 0.010656957514584064, acc: 0.9945255517959595)
[2024-12-17 05:34:03,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:03,695][root][INFO] - Training Epoch: 2/2, step 5662/7134 completed (loss: 0.017870241776108742, acc: 0.9967948794364929)
[2024-12-17 05:34:03,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:04,110][root][INFO] - Training Epoch: 2/2, step 5663/7134 completed (loss: 0.01435837335884571, acc: 0.9953774809837341)
[2024-12-17 05:34:04,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:04,538][root][INFO] - Training Epoch: 2/2, step 5664/7134 completed (loss: 0.0570937804877758, acc: 0.9910846948623657)
[2024-12-17 05:34:04,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:04,959][root][INFO] - Training Epoch: 2/2, step 5665/7134 completed (loss: 0.016155943274497986, acc: 0.9942938685417175)
[2024-12-17 05:34:05,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:05,399][root][INFO] - Training Epoch: 2/2, step 5666/7134 completed (loss: 0.009091854095458984, acc: 0.9972413778305054)
[2024-12-17 05:34:05,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:05,809][root][INFO] - Training Epoch: 2/2, step 5667/7134 completed (loss: 0.02135482057929039, acc: 0.996363639831543)
[2024-12-17 05:34:05,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:06,239][root][INFO] - Training Epoch: 2/2, step 5668/7134 completed (loss: 0.024076787754893303, acc: 0.9933554530143738)
[2024-12-17 05:34:06,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:06,673][root][INFO] - Training Epoch: 2/2, step 5669/7134 completed (loss: 0.0073925405740737915, acc: 0.9985337257385254)
[2024-12-17 05:34:06,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:07,093][root][INFO] - Training Epoch: 2/2, step 5670/7134 completed (loss: 0.015503305941820145, acc: 0.9950000047683716)
[2024-12-17 05:34:07,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:07,551][root][INFO] - Training Epoch: 2/2, step 5671/7134 completed (loss: 0.010757366195321083, acc: 0.9975399971008301)
[2024-12-17 05:34:07,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:07,997][root][INFO] - Training Epoch: 2/2, step 5672/7134 completed (loss: 0.0106245381757617, acc: 0.9952681660652161)
[2024-12-17 05:34:08,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:08,399][root][INFO] - Training Epoch: 2/2, step 5673/7134 completed (loss: 0.0197439044713974, acc: 0.9955686926841736)
[2024-12-17 05:34:08,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:08,851][root][INFO] - Training Epoch: 2/2, step 5674/7134 completed (loss: 0.01568553037941456, acc: 0.9954128265380859)
[2024-12-17 05:34:08,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:09,304][root][INFO] - Training Epoch: 2/2, step 5675/7134 completed (loss: 0.02860359288752079, acc: 0.9917080998420715)
[2024-12-17 05:34:09,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:09,724][root][INFO] - Training Epoch: 2/2, step 5676/7134 completed (loss: 0.09019105136394501, acc: 0.9807692170143127)
[2024-12-17 05:34:09,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:10,147][root][INFO] - Training Epoch: 2/2, step 5677/7134 completed (loss: 0.04121316224336624, acc: 0.984375)
[2024-12-17 05:34:10,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:10,560][root][INFO] - Training Epoch: 2/2, step 5678/7134 completed (loss: 0.023679593577980995, acc: 0.9941176176071167)
[2024-12-17 05:34:10,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:11,011][root][INFO] - Training Epoch: 2/2, step 5679/7134 completed (loss: 0.06772185117006302, acc: 0.9780380725860596)
[2024-12-17 05:34:11,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:11,433][root][INFO] - Training Epoch: 2/2, step 5680/7134 completed (loss: 0.06372536718845367, acc: 0.9761549830436707)
[2024-12-17 05:34:11,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:11,864][root][INFO] - Training Epoch: 2/2, step 5681/7134 completed (loss: 0.04813198000192642, acc: 0.9879336357116699)
[2024-12-17 05:34:11,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:12,283][root][INFO] - Training Epoch: 2/2, step 5682/7134 completed (loss: 0.026755262166261673, acc: 0.9898989796638489)
[2024-12-17 05:34:12,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:12,726][root][INFO] - Training Epoch: 2/2, step 5683/7134 completed (loss: 0.049846865236759186, acc: 0.9751098155975342)
[2024-12-17 05:34:12,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:13,184][root][INFO] - Training Epoch: 2/2, step 5684/7134 completed (loss: 0.053704120218753815, acc: 0.9881955981254578)
[2024-12-17 05:34:13,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:13,593][root][INFO] - Training Epoch: 2/2, step 5685/7134 completed (loss: 0.055952705442905426, acc: 0.9834558963775635)
[2024-12-17 05:34:13,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:14,013][root][INFO] - Training Epoch: 2/2, step 5686/7134 completed (loss: 0.04432820901274681, acc: 0.9881556630134583)
[2024-12-17 05:34:14,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:14,397][root][INFO] - Training Epoch: 2/2, step 5687/7134 completed (loss: 0.06964229047298431, acc: 0.9853479862213135)
[2024-12-17 05:34:14,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:14,845][root][INFO] - Training Epoch: 2/2, step 5688/7134 completed (loss: 0.049503132700920105, acc: 0.9839786291122437)
[2024-12-17 05:34:14,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:15,295][root][INFO] - Training Epoch: 2/2, step 5689/7134 completed (loss: 0.04495128616690636, acc: 0.9893454909324646)
[2024-12-17 05:34:15,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:15,762][root][INFO] - Training Epoch: 2/2, step 5690/7134 completed (loss: 0.025279467925429344, acc: 0.9941037893295288)
[2024-12-17 05:34:15,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:16,206][root][INFO] - Training Epoch: 2/2, step 5691/7134 completed (loss: 0.04215122014284134, acc: 0.9888198971748352)
[2024-12-17 05:34:16,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:16,667][root][INFO] - Training Epoch: 2/2, step 5692/7134 completed (loss: 0.06033990532159805, acc: 0.98525470495224)
[2024-12-17 05:34:16,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:17,091][root][INFO] - Training Epoch: 2/2, step 5693/7134 completed (loss: 0.018286101520061493, acc: 0.995502233505249)
[2024-12-17 05:34:17,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:17,520][root][INFO] - Training Epoch: 2/2, step 5694/7134 completed (loss: 0.0527467355132103, acc: 0.9884225726127625)
[2024-12-17 05:34:17,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:17,970][root][INFO] - Training Epoch: 2/2, step 5695/7134 completed (loss: 0.016933664679527283, acc: 0.9957020282745361)
[2024-12-17 05:34:18,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:18,413][root][INFO] - Training Epoch: 2/2, step 5696/7134 completed (loss: 0.03230608254671097, acc: 0.9917647242546082)
[2024-12-17 05:34:18,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:18,855][root][INFO] - Training Epoch: 2/2, step 5697/7134 completed (loss: 0.030177781358361244, acc: 0.9929478168487549)
[2024-12-17 05:34:18,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:19,287][root][INFO] - Training Epoch: 2/2, step 5698/7134 completed (loss: 0.035095490515232086, acc: 0.9931972622871399)
[2024-12-17 05:34:19,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:19,737][root][INFO] - Training Epoch: 2/2, step 5699/7134 completed (loss: 0.03426405414938927, acc: 0.9885350465774536)
[2024-12-17 05:34:19,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:20,179][root][INFO] - Training Epoch: 2/2, step 5700/7134 completed (loss: 0.027690628543496132, acc: 0.9943262338638306)
[2024-12-17 05:34:20,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:20,653][root][INFO] - Training Epoch: 2/2, step 5701/7134 completed (loss: 0.034129973500967026, acc: 0.9949937462806702)
[2024-12-17 05:34:20,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:21,086][root][INFO] - Training Epoch: 2/2, step 5702/7134 completed (loss: 0.03681367263197899, acc: 0.9918808937072754)
[2024-12-17 05:34:21,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:21,510][root][INFO] - Training Epoch: 2/2, step 5703/7134 completed (loss: 0.013179188594222069, acc: 0.997187077999115)
[2024-12-17 05:34:21,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:21,923][root][INFO] - Training Epoch: 2/2, step 5704/7134 completed (loss: 0.04272818565368652, acc: 0.9885877370834351)
[2024-12-17 05:34:22,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:22,260][root][INFO] - Training Epoch: 2/2, step 5705/7134 completed (loss: 0.007240644656121731, acc: 0.9964285492897034)
[2024-12-17 05:34:22,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:22,733][root][INFO] - Training Epoch: 2/2, step 5706/7134 completed (loss: 0.013960972428321838, acc: 0.998881459236145)
[2024-12-17 05:34:22,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:23,161][root][INFO] - Training Epoch: 2/2, step 5707/7134 completed (loss: 0.03599558025598526, acc: 0.9911971688270569)
[2024-12-17 05:34:23,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:23,586][root][INFO] - Training Epoch: 2/2, step 5708/7134 completed (loss: 0.013669615611433983, acc: 0.995555579662323)
[2024-12-17 05:34:23,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:24,052][root][INFO] - Training Epoch: 2/2, step 5709/7134 completed (loss: 0.04385007172822952, acc: 0.9904240965843201)
[2024-12-17 05:34:24,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:24,497][root][INFO] - Training Epoch: 2/2, step 5710/7134 completed (loss: 0.035315196961164474, acc: 0.9923664331436157)
[2024-12-17 05:34:24,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:24,916][root][INFO] - Training Epoch: 2/2, step 5711/7134 completed (loss: 0.044493626803159714, acc: 0.9895287752151489)
[2024-12-17 05:34:25,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:25,356][root][INFO] - Training Epoch: 2/2, step 5712/7134 completed (loss: 0.028241170570254326, acc: 0.9900000095367432)
[2024-12-17 05:34:25,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:25,819][root][INFO] - Training Epoch: 2/2, step 5713/7134 completed (loss: 0.01566310040652752, acc: 0.9961880445480347)
[2024-12-17 05:34:25,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:26,267][root][INFO] - Training Epoch: 2/2, step 5714/7134 completed (loss: 0.02329813316464424, acc: 0.9950186610221863)
[2024-12-17 05:34:26,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:26,672][root][INFO] - Training Epoch: 2/2, step 5715/7134 completed (loss: 0.05600845068693161, acc: 0.9869646430015564)
[2024-12-17 05:34:26,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:27,074][root][INFO] - Training Epoch: 2/2, step 5716/7134 completed (loss: 0.09695262461900711, acc: 0.9786856174468994)
[2024-12-17 05:34:27,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:27,500][root][INFO] - Training Epoch: 2/2, step 5717/7134 completed (loss: 0.06815487891435623, acc: 0.9844478964805603)
[2024-12-17 05:34:27,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:27,904][root][INFO] - Training Epoch: 2/2, step 5718/7134 completed (loss: 0.028299562633037567, acc: 0.9905362725257874)
[2024-12-17 05:34:28,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:28,309][root][INFO] - Training Epoch: 2/2, step 5719/7134 completed (loss: 0.02335474267601967, acc: 0.9925037622451782)
[2024-12-17 05:34:28,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:28,753][root][INFO] - Training Epoch: 2/2, step 5720/7134 completed (loss: 0.027141369879245758, acc: 0.9896373152732849)
[2024-12-17 05:34:28,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:29,161][root][INFO] - Training Epoch: 2/2, step 5721/7134 completed (loss: 0.0127418739721179, acc: 0.9973683953285217)
[2024-12-17 05:34:29,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:29,527][root][INFO] - Training Epoch: 2/2, step 5722/7134 completed (loss: 0.024600669741630554, acc: 0.9933481216430664)
[2024-12-17 05:34:29,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:29,962][root][INFO] - Training Epoch: 2/2, step 5723/7134 completed (loss: 0.03213787078857422, acc: 0.9939485788345337)
[2024-12-17 05:34:30,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:30,369][root][INFO] - Training Epoch: 2/2, step 5724/7134 completed (loss: 0.025675566866993904, acc: 0.9904000163078308)
[2024-12-17 05:34:30,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:30,811][root][INFO] - Training Epoch: 2/2, step 5725/7134 completed (loss: 0.013358074240386486, acc: 0.9971428513526917)
[2024-12-17 05:34:30,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:31,219][root][INFO] - Training Epoch: 2/2, step 5726/7134 completed (loss: 0.050620391964912415, acc: 0.9877675771713257)
[2024-12-17 05:34:31,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:31,645][root][INFO] - Training Epoch: 2/2, step 5727/7134 completed (loss: 0.009247795678675175, acc: 0.9986631274223328)
[2024-12-17 05:34:31,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:32,051][root][INFO] - Training Epoch: 2/2, step 5728/7134 completed (loss: 0.007612594868987799, acc: 1.0)
[2024-12-17 05:34:32,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:32,449][root][INFO] - Training Epoch: 2/2, step 5729/7134 completed (loss: 0.02041332796216011, acc: 0.9916666746139526)
[2024-12-17 05:34:32,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:32,855][root][INFO] - Training Epoch: 2/2, step 5730/7134 completed (loss: 0.05271909013390541, acc: 0.9878787994384766)
[2024-12-17 05:34:32,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:33,297][root][INFO] - Training Epoch: 2/2, step 5731/7134 completed (loss: 0.03502601385116577, acc: 0.9883720874786377)
[2024-12-17 05:34:33,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:33,697][root][INFO] - Training Epoch: 2/2, step 5732/7134 completed (loss: 0.11325971782207489, acc: 0.9631068110466003)
[2024-12-17 05:34:33,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:34,106][root][INFO] - Training Epoch: 2/2, step 5733/7134 completed (loss: 0.029170218855142593, acc: 0.9890710115432739)
[2024-12-17 05:34:34,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:34,535][root][INFO] - Training Epoch: 2/2, step 5734/7134 completed (loss: 0.008559291251003742, acc: 1.0)
[2024-12-17 05:34:34,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:34,949][root][INFO] - Training Epoch: 2/2, step 5735/7134 completed (loss: 0.05222567170858383, acc: 0.9820788502693176)
[2024-12-17 05:34:35,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:35,414][root][INFO] - Training Epoch: 2/2, step 5736/7134 completed (loss: 0.04507671669125557, acc: 0.9819548726081848)
[2024-12-17 05:34:35,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:35,833][root][INFO] - Training Epoch: 2/2, step 5737/7134 completed (loss: 0.03473454713821411, acc: 0.9879153966903687)
[2024-12-17 05:34:35,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:36,287][root][INFO] - Training Epoch: 2/2, step 5738/7134 completed (loss: 0.02445640228688717, acc: 0.9927448630332947)
[2024-12-17 05:34:36,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:36,716][root][INFO] - Training Epoch: 2/2, step 5739/7134 completed (loss: 0.02903175912797451, acc: 0.9873684048652649)
[2024-12-17 05:34:36,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:37,132][root][INFO] - Training Epoch: 2/2, step 5740/7134 completed (loss: 0.02990892343223095, acc: 0.9897698163986206)
[2024-12-17 05:34:37,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:37,556][root][INFO] - Training Epoch: 2/2, step 5741/7134 completed (loss: 0.0390569232404232, acc: 0.9910141229629517)
[2024-12-17 05:34:37,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:37,981][root][INFO] - Training Epoch: 2/2, step 5742/7134 completed (loss: 0.036483462899923325, acc: 0.9894875288009644)
[2024-12-17 05:34:38,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:38,444][root][INFO] - Training Epoch: 2/2, step 5743/7134 completed (loss: 0.014818836934864521, acc: 0.9950980544090271)
[2024-12-17 05:34:38,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:38,865][root][INFO] - Training Epoch: 2/2, step 5744/7134 completed (loss: 0.012489109300076962, acc: 0.9979079365730286)
[2024-12-17 05:34:38,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:39,324][root][INFO] - Training Epoch: 2/2, step 5745/7134 completed (loss: 0.03238024190068245, acc: 0.9896373152732849)
[2024-12-17 05:34:39,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:39,755][root][INFO] - Training Epoch: 2/2, step 5746/7134 completed (loss: 0.049014460295438766, acc: 0.9911764860153198)
[2024-12-17 05:34:39,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:40,188][root][INFO] - Training Epoch: 2/2, step 5747/7134 completed (loss: 0.018248647451400757, acc: 0.9930747747421265)
[2024-12-17 05:34:40,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:40,632][root][INFO] - Training Epoch: 2/2, step 5748/7134 completed (loss: 0.016522062942385674, acc: 0.9945155382156372)
[2024-12-17 05:34:40,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:41,091][root][INFO] - Training Epoch: 2/2, step 5749/7134 completed (loss: 0.03726901486515999, acc: 0.9908376932144165)
[2024-12-17 05:34:41,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:41,539][root][INFO] - Training Epoch: 2/2, step 5750/7134 completed (loss: 0.04220676049590111, acc: 0.9876237511634827)
[2024-12-17 05:34:41,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:41,967][root][INFO] - Training Epoch: 2/2, step 5751/7134 completed (loss: 0.026780778542160988, acc: 0.9935815334320068)
[2024-12-17 05:34:42,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:42,393][root][INFO] - Training Epoch: 2/2, step 5752/7134 completed (loss: 0.07395792007446289, acc: 0.9837586879730225)
[2024-12-17 05:34:42,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:42,813][root][INFO] - Training Epoch: 2/2, step 5753/7134 completed (loss: 0.05983980372548103, acc: 0.981249988079071)
[2024-12-17 05:34:42,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:43,280][root][INFO] - Training Epoch: 2/2, step 5754/7134 completed (loss: 0.04349956661462784, acc: 0.9898089170455933)
[2024-12-17 05:34:43,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:43,721][root][INFO] - Training Epoch: 2/2, step 5755/7134 completed (loss: 0.03273386508226395, acc: 0.9897511005401611)
[2024-12-17 05:34:43,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:44,154][root][INFO] - Training Epoch: 2/2, step 5756/7134 completed (loss: 0.03866894543170929, acc: 0.9893617033958435)
[2024-12-17 05:34:44,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:44,605][root][INFO] - Training Epoch: 2/2, step 5757/7134 completed (loss: 0.026204336434602737, acc: 0.9936143159866333)
[2024-12-17 05:34:44,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:45,007][root][INFO] - Training Epoch: 2/2, step 5758/7134 completed (loss: 0.03482745215296745, acc: 0.9852941036224365)
[2024-12-17 05:34:45,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:45,414][root][INFO] - Training Epoch: 2/2, step 5759/7134 completed (loss: 0.028612643480300903, acc: 0.986522912979126)
[2024-12-17 05:34:45,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:45,845][root][INFO] - Training Epoch: 2/2, step 5760/7134 completed (loss: 0.03426365181803703, acc: 0.9923664331436157)
[2024-12-17 05:34:45,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:46,301][root][INFO] - Training Epoch: 2/2, step 5761/7134 completed (loss: 0.017714856192469597, acc: 0.9926739931106567)
[2024-12-17 05:34:46,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:46,721][root][INFO] - Training Epoch: 2/2, step 5762/7134 completed (loss: 0.03688952699303627, acc: 0.989051103591919)
[2024-12-17 05:34:46,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:47,181][root][INFO] - Training Epoch: 2/2, step 5763/7134 completed (loss: 0.030263252556324005, acc: 0.9924717545509338)
[2024-12-17 05:34:47,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:47,583][root][INFO] - Training Epoch: 2/2, step 5764/7134 completed (loss: 0.012701497413218021, acc: 0.9948717951774597)
[2024-12-17 05:34:47,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:48,026][root][INFO] - Training Epoch: 2/2, step 5765/7134 completed (loss: 0.01592927612364292, acc: 0.9957982897758484)
[2024-12-17 05:34:48,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:48,456][root][INFO] - Training Epoch: 2/2, step 5766/7134 completed (loss: 0.01955139823257923, acc: 0.9970104694366455)
[2024-12-17 05:34:48,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:48,878][root][INFO] - Training Epoch: 2/2, step 5767/7134 completed (loss: 0.010067266412079334, acc: 0.998609185218811)
[2024-12-17 05:34:49,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:49,311][root][INFO] - Training Epoch: 2/2, step 5768/7134 completed (loss: 0.013324367813766003, acc: 0.992514967918396)
[2024-12-17 05:34:49,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:49,761][root][INFO] - Training Epoch: 2/2, step 5769/7134 completed (loss: 0.004976149182766676, acc: 0.9983633160591125)
[2024-12-17 05:34:49,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:50,210][root][INFO] - Training Epoch: 2/2, step 5770/7134 completed (loss: 0.030957508832216263, acc: 0.9926560521125793)
[2024-12-17 05:34:50,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:50,657][root][INFO] - Training Epoch: 2/2, step 5771/7134 completed (loss: 0.03993624821305275, acc: 0.99048912525177)
[2024-12-17 05:34:50,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:51,096][root][INFO] - Training Epoch: 2/2, step 5772/7134 completed (loss: 0.01987585239112377, acc: 0.991304337978363)
[2024-12-17 05:34:51,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:51,554][root][INFO] - Training Epoch: 2/2, step 5773/7134 completed (loss: 0.010092845186591148, acc: 0.9983277320861816)
[2024-12-17 05:34:51,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:51,973][root][INFO] - Training Epoch: 2/2, step 5774/7134 completed (loss: 0.010225874371826649, acc: 0.998516321182251)
[2024-12-17 05:34:52,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:52,387][root][INFO] - Training Epoch: 2/2, step 5775/7134 completed (loss: 0.016513828188180923, acc: 0.9950576424598694)
[2024-12-17 05:34:52,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:52,804][root][INFO] - Training Epoch: 2/2, step 5776/7134 completed (loss: 0.02611716464161873, acc: 0.9915730357170105)
[2024-12-17 05:34:52,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:53,245][root][INFO] - Training Epoch: 2/2, step 5777/7134 completed (loss: 0.06238780543208122, acc: 0.9888613820075989)
[2024-12-17 05:34:53,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:53,694][root][INFO] - Training Epoch: 2/2, step 5778/7134 completed (loss: 0.06441062688827515, acc: 0.9839743375778198)
[2024-12-17 05:34:53,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:54,132][root][INFO] - Training Epoch: 2/2, step 5779/7134 completed (loss: 0.033128928393125534, acc: 0.9903714060783386)
[2024-12-17 05:34:54,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:54,584][root][INFO] - Training Epoch: 2/2, step 5780/7134 completed (loss: 0.01708405278623104, acc: 0.9940333962440491)
[2024-12-17 05:34:54,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:55,013][root][INFO] - Training Epoch: 2/2, step 5781/7134 completed (loss: 0.02980322577059269, acc: 0.9903314709663391)
[2024-12-17 05:34:55,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:55,469][root][INFO] - Training Epoch: 2/2, step 5782/7134 completed (loss: 0.014896486885845661, acc: 0.9948186278343201)
[2024-12-17 05:34:55,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:55,919][root][INFO] - Training Epoch: 2/2, step 5783/7134 completed (loss: 0.012718470767140388, acc: 0.9960159659385681)
[2024-12-17 05:34:56,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:56,341][root][INFO] - Training Epoch: 2/2, step 5784/7134 completed (loss: 0.02747189998626709, acc: 0.9932705163955688)
[2024-12-17 05:34:56,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:56,757][root][INFO] - Training Epoch: 2/2, step 5785/7134 completed (loss: 0.023402158170938492, acc: 0.986522912979126)
[2024-12-17 05:34:56,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:57,156][root][INFO] - Training Epoch: 2/2, step 5786/7134 completed (loss: 0.02526750974357128, acc: 0.9918032884597778)
[2024-12-17 05:34:57,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:57,592][root][INFO] - Training Epoch: 2/2, step 5787/7134 completed (loss: 0.016608061268925667, acc: 0.9950248599052429)
[2024-12-17 05:34:57,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:57,990][root][INFO] - Training Epoch: 2/2, step 5788/7134 completed (loss: 0.0072441487573087215, acc: 0.9984615445137024)
[2024-12-17 05:34:58,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:58,450][root][INFO] - Training Epoch: 2/2, step 5789/7134 completed (loss: 0.018918976187705994, acc: 0.9937965273857117)
[2024-12-17 05:34:58,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:58,888][root][INFO] - Training Epoch: 2/2, step 5790/7134 completed (loss: 0.02785465680062771, acc: 0.9890109896659851)
[2024-12-17 05:34:58,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:59,327][root][INFO] - Training Epoch: 2/2, step 5791/7134 completed (loss: 0.06079087033867836, acc: 0.9828178882598877)
[2024-12-17 05:34:59,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:34:59,760][root][INFO] - Training Epoch: 2/2, step 5792/7134 completed (loss: 0.05943168327212334, acc: 0.9847198724746704)
[2024-12-17 05:34:59,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:00,203][root][INFO] - Training Epoch: 2/2, step 5793/7134 completed (loss: 0.06446140259504318, acc: 0.9842767119407654)
[2024-12-17 05:35:00,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:00,630][root][INFO] - Training Epoch: 2/2, step 5794/7134 completed (loss: 0.025421058759093285, acc: 0.9939393997192383)
[2024-12-17 05:35:00,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:01,082][root][INFO] - Training Epoch: 2/2, step 5795/7134 completed (loss: 0.08356935530900955, acc: 0.9768907427787781)
[2024-12-17 05:35:01,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:01,506][root][INFO] - Training Epoch: 2/2, step 5796/7134 completed (loss: 0.021828018128871918, acc: 0.9949238300323486)
[2024-12-17 05:35:01,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:01,914][root][INFO] - Training Epoch: 2/2, step 5797/7134 completed (loss: 0.020404435694217682, acc: 0.9919999837875366)
[2024-12-17 05:35:02,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:02,315][root][INFO] - Training Epoch: 2/2, step 5798/7134 completed (loss: 0.18070735037326813, acc: 0.9669564962387085)
[2024-12-17 05:35:02,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:02,715][root][INFO] - Training Epoch: 2/2, step 5799/7134 completed (loss: 0.05256103724241257, acc: 0.9783037304878235)
[2024-12-17 05:35:02,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:03,130][root][INFO] - Training Epoch: 2/2, step 5800/7134 completed (loss: 0.049696218222379684, acc: 0.9871323704719543)
[2024-12-17 05:35:03,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:03,551][root][INFO] - Training Epoch: 2/2, step 5801/7134 completed (loss: 0.04675719514489174, acc: 0.9847561120986938)
[2024-12-17 05:35:03,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:03,962][root][INFO] - Training Epoch: 2/2, step 5802/7134 completed (loss: 0.026649165898561478, acc: 0.9926062822341919)
[2024-12-17 05:35:04,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:04,407][root][INFO] - Training Epoch: 2/2, step 5803/7134 completed (loss: 0.02282889001071453, acc: 0.9923469424247742)
[2024-12-17 05:35:04,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:04,825][root][INFO] - Training Epoch: 2/2, step 5804/7134 completed (loss: 0.0687994509935379, acc: 0.981055498123169)
[2024-12-17 05:35:04,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:05,244][root][INFO] - Training Epoch: 2/2, step 5805/7134 completed (loss: 0.041908543556928635, acc: 0.9899280667304993)
[2024-12-17 05:35:05,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:05,676][root][INFO] - Training Epoch: 2/2, step 5806/7134 completed (loss: 0.030532237142324448, acc: 0.9918032884597778)
[2024-12-17 05:35:05,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:06,098][root][INFO] - Training Epoch: 2/2, step 5807/7134 completed (loss: 0.05003451183438301, acc: 0.9894099831581116)
[2024-12-17 05:35:06,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:06,549][root][INFO] - Training Epoch: 2/2, step 5808/7134 completed (loss: 0.025560036301612854, acc: 0.9943740963935852)
[2024-12-17 05:35:06,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:06,952][root][INFO] - Training Epoch: 2/2, step 5809/7134 completed (loss: 0.03791351616382599, acc: 0.9912280440330505)
[2024-12-17 05:35:07,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:07,375][root][INFO] - Training Epoch: 2/2, step 5810/7134 completed (loss: 0.03526820242404938, acc: 0.9878296256065369)
[2024-12-17 05:35:07,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:07,742][root][INFO] - Training Epoch: 2/2, step 5811/7134 completed (loss: 0.028773505240678787, acc: 0.9927710890769958)
[2024-12-17 05:35:07,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:08,137][root][INFO] - Training Epoch: 2/2, step 5812/7134 completed (loss: 0.01151680201292038, acc: 0.9983498454093933)
[2024-12-17 05:35:08,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:08,537][root][INFO] - Training Epoch: 2/2, step 5813/7134 completed (loss: 0.021055743098258972, acc: 0.994339644908905)
[2024-12-17 05:35:08,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:09,022][root][INFO] - Training Epoch: 2/2, step 5814/7134 completed (loss: 0.014785894192755222, acc: 0.9915397763252258)
[2024-12-17 05:35:09,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:09,437][root][INFO] - Training Epoch: 2/2, step 5815/7134 completed (loss: 0.021631967276334763, acc: 0.9962335228919983)
[2024-12-17 05:35:09,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:09,881][root][INFO] - Training Epoch: 2/2, step 5816/7134 completed (loss: 0.011629701592028141, acc: 0.9975062608718872)
[2024-12-17 05:35:09,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:10,286][root][INFO] - Training Epoch: 2/2, step 5817/7134 completed (loss: 0.03946571797132492, acc: 0.989924430847168)
[2024-12-17 05:35:10,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:10,699][root][INFO] - Training Epoch: 2/2, step 5818/7134 completed (loss: 0.03414984792470932, acc: 0.9896296262741089)
[2024-12-17 05:35:10,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:11,093][root][INFO] - Training Epoch: 2/2, step 5819/7134 completed (loss: 0.0227398369461298, acc: 0.9931034445762634)
[2024-12-17 05:35:11,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:11,473][root][INFO] - Training Epoch: 2/2, step 5820/7134 completed (loss: 0.0332573764026165, acc: 0.9917355179786682)
[2024-12-17 05:35:11,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:11,874][root][INFO] - Training Epoch: 2/2, step 5821/7134 completed (loss: 0.014592587947845459, acc: 0.9938367009162903)
[2024-12-17 05:35:12,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:12,280][root][INFO] - Training Epoch: 2/2, step 5822/7134 completed (loss: 0.023577600717544556, acc: 0.9919354915618896)
[2024-12-17 05:35:12,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:12,693][root][INFO] - Training Epoch: 2/2, step 5823/7134 completed (loss: 0.020162038505077362, acc: 0.993779182434082)
[2024-12-17 05:35:12,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:13,126][root][INFO] - Training Epoch: 2/2, step 5824/7134 completed (loss: 0.01447417214512825, acc: 0.996889591217041)
[2024-12-17 05:35:13,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:13,547][root][INFO] - Training Epoch: 2/2, step 5825/7134 completed (loss: 0.031175805255770683, acc: 0.991349458694458)
[2024-12-17 05:35:13,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:13,966][root][INFO] - Training Epoch: 2/2, step 5826/7134 completed (loss: 0.005630881525576115, acc: 1.0)
[2024-12-17 05:35:14,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:14,361][root][INFO] - Training Epoch: 2/2, step 5827/7134 completed (loss: 0.01993805170059204, acc: 0.9903846383094788)
[2024-12-17 05:35:14,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:14,775][root][INFO] - Training Epoch: 2/2, step 5828/7134 completed (loss: 0.03978971391916275, acc: 0.9866270422935486)
[2024-12-17 05:35:14,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:15,202][root][INFO] - Training Epoch: 2/2, step 5829/7134 completed (loss: 0.019149985164403915, acc: 0.9947299361228943)
[2024-12-17 05:35:15,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:15,584][root][INFO] - Training Epoch: 2/2, step 5830/7134 completed (loss: 0.01646677404642105, acc: 0.9943289160728455)
[2024-12-17 05:35:15,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:15,971][root][INFO] - Training Epoch: 2/2, step 5831/7134 completed (loss: 0.009584387764334679, acc: 0.9976744055747986)
[2024-12-17 05:35:16,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:16,392][root][INFO] - Training Epoch: 2/2, step 5832/7134 completed (loss: 0.050492286682128906, acc: 0.9864864945411682)
[2024-12-17 05:35:16,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:16,785][root][INFO] - Training Epoch: 2/2, step 5833/7134 completed (loss: 0.0235176682472229, acc: 0.9946236610412598)
[2024-12-17 05:35:16,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:17,203][root][INFO] - Training Epoch: 2/2, step 5834/7134 completed (loss: 0.0245596282184124, acc: 0.9958333373069763)
[2024-12-17 05:35:17,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:17,645][root][INFO] - Training Epoch: 2/2, step 5835/7134 completed (loss: 0.011763500049710274, acc: 0.9971098303794861)
[2024-12-17 05:35:17,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:18,066][root][INFO] - Training Epoch: 2/2, step 5836/7134 completed (loss: 0.027477703988552094, acc: 0.9927954077720642)
[2024-12-17 05:35:18,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:18,476][root][INFO] - Training Epoch: 2/2, step 5837/7134 completed (loss: 0.056001462042331696, acc: 0.9915540814399719)
[2024-12-17 05:35:18,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:18,906][root][INFO] - Training Epoch: 2/2, step 5838/7134 completed (loss: 0.049570318311452866, acc: 0.9917627573013306)
[2024-12-17 05:35:19,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:19,322][root][INFO] - Training Epoch: 2/2, step 5839/7134 completed (loss: 0.022409170866012573, acc: 0.9928571581840515)
[2024-12-17 05:35:19,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:19,724][root][INFO] - Training Epoch: 2/2, step 5840/7134 completed (loss: 0.011518431827425957, acc: 0.995230495929718)
[2024-12-17 05:35:19,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:20,136][root][INFO] - Training Epoch: 2/2, step 5841/7134 completed (loss: 0.020575597882270813, acc: 0.9952152967453003)
[2024-12-17 05:35:20,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:20,538][root][INFO] - Training Epoch: 2/2, step 5842/7134 completed (loss: 0.023638281971216202, acc: 0.9945651888847351)
[2024-12-17 05:35:20,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:20,976][root][INFO] - Training Epoch: 2/2, step 5843/7134 completed (loss: 0.028462853282690048, acc: 0.9892904758453369)
[2024-12-17 05:35:21,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:21,398][root][INFO] - Training Epoch: 2/2, step 5844/7134 completed (loss: 0.013049503788352013, acc: 0.9957325458526611)
[2024-12-17 05:35:21,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:21,818][root][INFO] - Training Epoch: 2/2, step 5845/7134 completed (loss: 0.016286863014101982, acc: 0.994301974773407)
[2024-12-17 05:35:21,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:22,245][root][INFO] - Training Epoch: 2/2, step 5846/7134 completed (loss: 0.03023788332939148, acc: 0.9917920827865601)
[2024-12-17 05:35:22,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:22,681][root][INFO] - Training Epoch: 2/2, step 5847/7134 completed (loss: 0.01710185408592224, acc: 0.9972527623176575)
[2024-12-17 05:35:22,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:23,102][root][INFO] - Training Epoch: 2/2, step 5848/7134 completed (loss: 0.03631872683763504, acc: 0.9895833134651184)
[2024-12-17 05:35:23,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:23,519][root][INFO] - Training Epoch: 2/2, step 5849/7134 completed (loss: 0.03757617250084877, acc: 0.9882006049156189)
[2024-12-17 05:35:23,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:23,934][root][INFO] - Training Epoch: 2/2, step 5850/7134 completed (loss: 0.018180709332227707, acc: 0.9908397197723389)
[2024-12-17 05:35:24,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:24,378][root][INFO] - Training Epoch: 2/2, step 5851/7134 completed (loss: 0.02161937765777111, acc: 0.9917762875556946)
[2024-12-17 05:35:24,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:24,802][root][INFO] - Training Epoch: 2/2, step 5852/7134 completed (loss: 0.011666949838399887, acc: 0.9941605925559998)
[2024-12-17 05:35:24,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:25,251][root][INFO] - Training Epoch: 2/2, step 5853/7134 completed (loss: 0.05064275860786438, acc: 0.9891745448112488)
[2024-12-17 05:35:25,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:25,657][root][INFO] - Training Epoch: 2/2, step 5854/7134 completed (loss: 0.010847718454897404, acc: 0.9964601993560791)
[2024-12-17 05:35:25,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:26,062][root][INFO] - Training Epoch: 2/2, step 5855/7134 completed (loss: 0.029511312022805214, acc: 0.9913644194602966)
[2024-12-17 05:35:26,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:26,484][root][INFO] - Training Epoch: 2/2, step 5856/7134 completed (loss: 0.053637098520994186, acc: 0.9848942756652832)
[2024-12-17 05:35:26,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:26,932][root][INFO] - Training Epoch: 2/2, step 5857/7134 completed (loss: 0.03429653123021126, acc: 0.9889415502548218)
[2024-12-17 05:35:27,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:27,322][root][INFO] - Training Epoch: 2/2, step 5858/7134 completed (loss: 0.018347425386309624, acc: 0.9926062822341919)
[2024-12-17 05:35:27,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:27,732][root][INFO] - Training Epoch: 2/2, step 5859/7134 completed (loss: 0.031858641654253006, acc: 0.990234375)
[2024-12-17 05:35:27,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:28,125][root][INFO] - Training Epoch: 2/2, step 5860/7134 completed (loss: 0.02094978466629982, acc: 0.9917355179786682)
[2024-12-17 05:35:28,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:28,510][root][INFO] - Training Epoch: 2/2, step 5861/7134 completed (loss: 0.02771308831870556, acc: 0.9918864369392395)
[2024-12-17 05:35:28,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:28,921][root][INFO] - Training Epoch: 2/2, step 5862/7134 completed (loss: 0.018078036606311798, acc: 0.9935622215270996)
[2024-12-17 05:35:29,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:29,276][root][INFO] - Training Epoch: 2/2, step 5863/7134 completed (loss: 0.022486183792352676, acc: 0.9949495196342468)
[2024-12-17 05:35:29,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:29,692][root][INFO] - Training Epoch: 2/2, step 5864/7134 completed (loss: 0.04943772777915001, acc: 0.9895209670066833)
[2024-12-17 05:35:29,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:30,091][root][INFO] - Training Epoch: 2/2, step 5865/7134 completed (loss: 0.03066975064575672, acc: 0.9888888597488403)
[2024-12-17 05:35:30,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:30,546][root][INFO] - Training Epoch: 2/2, step 5866/7134 completed (loss: 0.01240772008895874, acc: 0.9960317611694336)
[2024-12-17 05:35:30,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:30,960][root][INFO] - Training Epoch: 2/2, step 5867/7134 completed (loss: 0.020546825602650642, acc: 0.9950413107872009)
[2024-12-17 05:35:31,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:31,379][root][INFO] - Training Epoch: 2/2, step 5868/7134 completed (loss: 0.029936237260699272, acc: 0.9913793206214905)
[2024-12-17 05:35:31,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:31,775][root][INFO] - Training Epoch: 2/2, step 5869/7134 completed (loss: 0.031780168414115906, acc: 0.9895522594451904)
[2024-12-17 05:35:31,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:32,194][root][INFO] - Training Epoch: 2/2, step 5870/7134 completed (loss: 0.0338263176381588, acc: 0.991631805896759)
[2024-12-17 05:35:32,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:32,591][root][INFO] - Training Epoch: 2/2, step 5871/7134 completed (loss: 0.016031447798013687, acc: 0.9915074110031128)
[2024-12-17 05:35:32,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:32,999][root][INFO] - Training Epoch: 2/2, step 5872/7134 completed (loss: 0.020652523264288902, acc: 0.9923896789550781)
[2024-12-17 05:35:33,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:33,496][root][INFO] - Training Epoch: 2/2, step 5873/7134 completed (loss: 0.01871197484433651, acc: 0.9946666955947876)
[2024-12-17 05:35:33,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:33,856][root][INFO] - Training Epoch: 2/2, step 5874/7134 completed (loss: 0.020957350730895996, acc: 0.9959839582443237)
[2024-12-17 05:35:33,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:34,237][root][INFO] - Training Epoch: 2/2, step 5875/7134 completed (loss: 0.03398441895842552, acc: 0.9858406782150269)
[2024-12-17 05:35:34,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:34,675][root][INFO] - Training Epoch: 2/2, step 5876/7134 completed (loss: 0.010513674467802048, acc: 0.9975728392601013)
[2024-12-17 05:35:34,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:35,090][root][INFO] - Training Epoch: 2/2, step 5877/7134 completed (loss: 0.044765960425138474, acc: 0.9885786771774292)
[2024-12-17 05:35:35,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:35,514][root][INFO] - Training Epoch: 2/2, step 5878/7134 completed (loss: 0.023769713938236237, acc: 0.9868420958518982)
[2024-12-17 05:35:35,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:35,911][root][INFO] - Training Epoch: 2/2, step 5879/7134 completed (loss: 0.005228945519775152, acc: 1.0)
[2024-12-17 05:35:36,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:36,252][root][INFO] - Training Epoch: 2/2, step 5880/7134 completed (loss: 0.019108500331640244, acc: 0.9911110997200012)
[2024-12-17 05:35:36,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:36,662][root][INFO] - Training Epoch: 2/2, step 5881/7134 completed (loss: 0.016996465623378754, acc: 0.9942418336868286)
[2024-12-17 05:35:36,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:37,014][root][INFO] - Training Epoch: 2/2, step 5882/7134 completed (loss: 0.017371436581015587, acc: 0.9929412007331848)
[2024-12-17 05:35:37,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:37,372][root][INFO] - Training Epoch: 2/2, step 5883/7134 completed (loss: 0.03501812368631363, acc: 0.9925093650817871)
[2024-12-17 05:35:37,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:37,794][root][INFO] - Training Epoch: 2/2, step 5884/7134 completed (loss: 0.04351610690355301, acc: 0.9872262477874756)
[2024-12-17 05:35:37,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:38,184][root][INFO] - Training Epoch: 2/2, step 5885/7134 completed (loss: 0.0739952102303505, acc: 0.9836956262588501)
[2024-12-17 05:35:38,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:38,548][root][INFO] - Training Epoch: 2/2, step 5886/7134 completed (loss: 0.017625389620661736, acc: 0.9971428513526917)
[2024-12-17 05:35:38,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:38,944][root][INFO] - Training Epoch: 2/2, step 5887/7134 completed (loss: 0.030574791133403778, acc: 0.993630588054657)
[2024-12-17 05:35:39,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:39,355][root][INFO] - Training Epoch: 2/2, step 5888/7134 completed (loss: 0.04862397164106369, acc: 0.9847972989082336)
[2024-12-17 05:35:39,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:39,605][root][INFO] - Training Epoch: 2/2, step 5889/7134 completed (loss: 0.03559381514787674, acc: 0.9910714030265808)
[2024-12-17 05:35:39,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:40,046][root][INFO] - Training Epoch: 2/2, step 5890/7134 completed (loss: 0.013392269611358643, acc: 0.9947552680969238)
[2024-12-17 05:35:40,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:40,465][root][INFO] - Training Epoch: 2/2, step 5891/7134 completed (loss: 0.02031344547867775, acc: 0.9944751262664795)
[2024-12-17 05:35:40,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:40,916][root][INFO] - Training Epoch: 2/2, step 5892/7134 completed (loss: 0.04153516888618469, acc: 0.991253674030304)
[2024-12-17 05:35:41,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:41,337][root][INFO] - Training Epoch: 2/2, step 5893/7134 completed (loss: 0.034086428582668304, acc: 0.9905511736869812)
[2024-12-17 05:35:41,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:41,709][root][INFO] - Training Epoch: 2/2, step 5894/7134 completed (loss: 0.007837707176804543, acc: 0.9967213273048401)
[2024-12-17 05:35:41,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:42,114][root][INFO] - Training Epoch: 2/2, step 5895/7134 completed (loss: 0.010744418017566204, acc: 0.9976190328598022)
[2024-12-17 05:35:42,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:42,531][root][INFO] - Training Epoch: 2/2, step 5896/7134 completed (loss: 0.04179786518216133, acc: 0.9897959232330322)
[2024-12-17 05:35:42,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:42,970][root][INFO] - Training Epoch: 2/2, step 5897/7134 completed (loss: 0.013655483722686768, acc: 0.9958677887916565)
[2024-12-17 05:35:43,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:43,380][root][INFO] - Training Epoch: 2/2, step 5898/7134 completed (loss: 0.01163020171225071, acc: 0.9978448152542114)
[2024-12-17 05:35:43,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:43,742][root][INFO] - Training Epoch: 2/2, step 5899/7134 completed (loss: 0.011430466547608376, acc: 0.9940476417541504)
[2024-12-17 05:35:43,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:44,116][root][INFO] - Training Epoch: 2/2, step 5900/7134 completed (loss: 0.019174907356500626, acc: 0.9940476417541504)
[2024-12-17 05:35:44,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:44,523][root][INFO] - Training Epoch: 2/2, step 5901/7134 completed (loss: 0.043830808252096176, acc: 0.9825000166893005)
[2024-12-17 05:35:44,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:44,956][root][INFO] - Training Epoch: 2/2, step 5902/7134 completed (loss: 0.044770315289497375, acc: 0.9793814420700073)
[2024-12-17 05:35:45,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:45,387][root][INFO] - Training Epoch: 2/2, step 5903/7134 completed (loss: 0.04196834936738014, acc: 0.989051103591919)
[2024-12-17 05:35:45,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:45,836][root][INFO] - Training Epoch: 2/2, step 5904/7134 completed (loss: 0.033574722707271576, acc: 0.9918032884597778)
[2024-12-17 05:35:45,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:46,244][root][INFO] - Training Epoch: 2/2, step 5905/7134 completed (loss: 0.029322026297450066, acc: 0.9916550517082214)
[2024-12-17 05:35:46,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:46,699][root][INFO] - Training Epoch: 2/2, step 5906/7134 completed (loss: 0.048890020698308945, acc: 0.9864864945411682)
[2024-12-17 05:35:46,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:47,178][root][INFO] - Training Epoch: 2/2, step 5907/7134 completed (loss: 0.03839638829231262, acc: 0.9896507263183594)
[2024-12-17 05:35:47,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:47,660][root][INFO] - Training Epoch: 2/2, step 5908/7134 completed (loss: 0.02531527914106846, acc: 0.9897698163986206)
[2024-12-17 05:35:47,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:48,268][root][INFO] - Training Epoch: 2/2, step 5909/7134 completed (loss: 0.04715410992503166, acc: 0.9841498732566833)
[2024-12-17 05:35:48,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:48,757][root][INFO] - Training Epoch: 2/2, step 5910/7134 completed (loss: 0.03558887168765068, acc: 0.9847434163093567)
[2024-12-17 05:35:48,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:49,175][root][INFO] - Training Epoch: 2/2, step 5911/7134 completed (loss: 0.035886846482753754, acc: 0.9917355179786682)
[2024-12-17 05:35:49,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:49,578][root][INFO] - Training Epoch: 2/2, step 5912/7134 completed (loss: 0.01705353893339634, acc: 0.9929676651954651)
[2024-12-17 05:35:49,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:50,050][root][INFO] - Training Epoch: 2/2, step 5913/7134 completed (loss: 0.07867540419101715, acc: 0.98097825050354)
[2024-12-17 05:35:50,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:50,442][root][INFO] - Training Epoch: 2/2, step 5914/7134 completed (loss: 0.03601735085248947, acc: 0.9903692007064819)
[2024-12-17 05:35:50,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:50,889][root][INFO] - Training Epoch: 2/2, step 5915/7134 completed (loss: 0.04677378013730049, acc: 0.987596869468689)
[2024-12-17 05:35:50,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:51,357][root][INFO] - Training Epoch: 2/2, step 5916/7134 completed (loss: 0.040115002542734146, acc: 0.9921362996101379)
[2024-12-17 05:35:51,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:51,739][root][INFO] - Training Epoch: 2/2, step 5917/7134 completed (loss: 0.026701465249061584, acc: 0.9930675625801086)
[2024-12-17 05:35:51,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:52,200][root][INFO] - Training Epoch: 2/2, step 5918/7134 completed (loss: 0.0628189742565155, acc: 0.9811320900917053)
[2024-12-17 05:35:52,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:52,638][root][INFO] - Training Epoch: 2/2, step 5919/7134 completed (loss: 0.03331124782562256, acc: 0.9893617033958435)
[2024-12-17 05:35:52,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:53,057][root][INFO] - Training Epoch: 2/2, step 5920/7134 completed (loss: 0.023499205708503723, acc: 0.9950082898139954)
[2024-12-17 05:35:53,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:53,477][root][INFO] - Training Epoch: 2/2, step 5921/7134 completed (loss: 0.03462868556380272, acc: 0.9874739050865173)
[2024-12-17 05:35:53,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:53,899][root][INFO] - Training Epoch: 2/2, step 5922/7134 completed (loss: 0.1578698754310608, acc: 0.9680851101875305)
[2024-12-17 05:35:53,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:54,356][root][INFO] - Training Epoch: 2/2, step 5923/7134 completed (loss: 0.06039964407682419, acc: 0.985358715057373)
[2024-12-17 05:35:54,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:54,762][root][INFO] - Training Epoch: 2/2, step 5924/7134 completed (loss: 0.04052085056900978, acc: 0.9809069037437439)
[2024-12-17 05:35:54,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:55,128][root][INFO] - Training Epoch: 2/2, step 5925/7134 completed (loss: 0.16553400456905365, acc: 0.9618768095970154)
[2024-12-17 05:35:55,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:55,530][root][INFO] - Training Epoch: 2/2, step 5926/7134 completed (loss: 0.07808056473731995, acc: 0.9733333587646484)
[2024-12-17 05:35:55,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:55,932][root][INFO] - Training Epoch: 2/2, step 5927/7134 completed (loss: 0.07521310448646545, acc: 0.9732739329338074)
[2024-12-17 05:35:56,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:56,284][root][INFO] - Training Epoch: 2/2, step 5928/7134 completed (loss: 0.17331774532794952, acc: 0.9452054500579834)
[2024-12-17 05:35:56,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:56,697][root][INFO] - Training Epoch: 2/2, step 5929/7134 completed (loss: 0.05035717785358429, acc: 0.9850746393203735)
[2024-12-17 05:35:56,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:57,064][root][INFO] - Training Epoch: 2/2, step 5930/7134 completed (loss: 0.07230524718761444, acc: 0.9821826219558716)
[2024-12-17 05:35:57,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:57,460][root][INFO] - Training Epoch: 2/2, step 5931/7134 completed (loss: 0.039459843188524246, acc: 0.9935204982757568)
[2024-12-17 05:35:57,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:57,858][root][INFO] - Training Epoch: 2/2, step 5932/7134 completed (loss: 0.06459450721740723, acc: 0.9759259223937988)
[2024-12-17 05:35:57,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:58,224][root][INFO] - Training Epoch: 2/2, step 5933/7134 completed (loss: 0.11145400255918503, acc: 0.9685534834861755)
[2024-12-17 05:35:58,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:58,659][root][INFO] - Training Epoch: 2/2, step 5934/7134 completed (loss: 0.04364025220274925, acc: 0.9875665903091431)
[2024-12-17 05:35:58,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:59,091][root][INFO] - Training Epoch: 2/2, step 5935/7134 completed (loss: 0.029858164489269257, acc: 0.9922330379486084)
[2024-12-17 05:35:59,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:59,484][root][INFO] - Training Epoch: 2/2, step 5936/7134 completed (loss: 0.06169578805565834, acc: 0.9862174391746521)
[2024-12-17 05:35:59,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:35:59,899][root][INFO] - Training Epoch: 2/2, step 5937/7134 completed (loss: 0.03179251402616501, acc: 0.9936203956604004)
[2024-12-17 05:36:00,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:00,311][root][INFO] - Training Epoch: 2/2, step 5938/7134 completed (loss: 0.06583624333143234, acc: 0.980879545211792)
[2024-12-17 05:36:00,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:00,714][root][INFO] - Training Epoch: 2/2, step 5939/7134 completed (loss: 0.1027459129691124, acc: 0.970588207244873)
[2024-12-17 05:36:00,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:01,168][root][INFO] - Training Epoch: 2/2, step 5940/7134 completed (loss: 0.05185553804039955, acc: 0.9839650392532349)
[2024-12-17 05:36:01,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:01,545][root][INFO] - Training Epoch: 2/2, step 5941/7134 completed (loss: 0.060105979442596436, acc: 0.987500011920929)
[2024-12-17 05:36:01,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:01,944][root][INFO] - Training Epoch: 2/2, step 5942/7134 completed (loss: 0.013712831772863865, acc: 0.9961758852005005)
[2024-12-17 05:36:02,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:02,361][root][INFO] - Training Epoch: 2/2, step 5943/7134 completed (loss: 0.016865810379385948, acc: 0.9928469061851501)
[2024-12-17 05:36:02,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:02,808][root][INFO] - Training Epoch: 2/2, step 5944/7134 completed (loss: 0.04387417808175087, acc: 0.985602080821991)
[2024-12-17 05:36:02,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:03,263][root][INFO] - Training Epoch: 2/2, step 5945/7134 completed (loss: 0.02756408229470253, acc: 0.9924924969673157)
[2024-12-17 05:36:03,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:03,672][root][INFO] - Training Epoch: 2/2, step 5946/7134 completed (loss: 0.02749503031373024, acc: 0.9909420013427734)
[2024-12-17 05:36:03,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:04,110][root][INFO] - Training Epoch: 2/2, step 5947/7134 completed (loss: 0.023956112563610077, acc: 0.9913259148597717)
[2024-12-17 05:36:04,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:04,535][root][INFO] - Training Epoch: 2/2, step 5948/7134 completed (loss: 0.055126652121543884, acc: 0.9819999933242798)
[2024-12-17 05:36:04,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:04,969][root][INFO] - Training Epoch: 2/2, step 5949/7134 completed (loss: 0.013314153999090195, acc: 0.9937264919281006)
[2024-12-17 05:36:05,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:05,380][root][INFO] - Training Epoch: 2/2, step 5950/7134 completed (loss: 0.08905147016048431, acc: 0.9714964628219604)
[2024-12-17 05:36:05,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:05,796][root][INFO] - Training Epoch: 2/2, step 5951/7134 completed (loss: 0.08133368194103241, acc: 0.9784792065620422)
[2024-12-17 05:36:05,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:06,245][root][INFO] - Training Epoch: 2/2, step 5952/7134 completed (loss: 0.15420833230018616, acc: 0.973437488079071)
[2024-12-17 05:36:06,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:06,681][root][INFO] - Training Epoch: 2/2, step 5953/7134 completed (loss: 0.03432464972138405, acc: 0.9862259030342102)
[2024-12-17 05:36:06,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:07,100][root][INFO] - Training Epoch: 2/2, step 5954/7134 completed (loss: 0.01766660064458847, acc: 0.9949238300323486)
[2024-12-17 05:36:07,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:07,437][root][INFO] - Training Epoch: 2/2, step 5955/7134 completed (loss: 0.03658537566661835, acc: 0.9952380657196045)
[2024-12-17 05:36:07,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:07,854][root][INFO] - Training Epoch: 2/2, step 5956/7134 completed (loss: 0.05622448772192001, acc: 0.9803921580314636)
[2024-12-17 05:36:07,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:08,241][root][INFO] - Training Epoch: 2/2, step 5957/7134 completed (loss: 0.04486416280269623, acc: 0.9895052313804626)
[2024-12-17 05:36:08,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:08,665][root][INFO] - Training Epoch: 2/2, step 5958/7134 completed (loss: 0.04079068824648857, acc: 0.9892617464065552)
[2024-12-17 05:36:08,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:09,101][root][INFO] - Training Epoch: 2/2, step 5959/7134 completed (loss: 0.034397054463624954, acc: 0.9933244585990906)
[2024-12-17 05:36:09,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:09,538][root][INFO] - Training Epoch: 2/2, step 5960/7134 completed (loss: 0.008646155707538128, acc: 0.9985954761505127)
[2024-12-17 05:36:09,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:09,918][root][INFO] - Training Epoch: 2/2, step 5961/7134 completed (loss: 0.032199710607528687, acc: 0.9877049326896667)
[2024-12-17 05:36:10,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:10,344][root][INFO] - Training Epoch: 2/2, step 5962/7134 completed (loss: 0.020613860338926315, acc: 0.995121955871582)
[2024-12-17 05:36:10,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:10,764][root][INFO] - Training Epoch: 2/2, step 5963/7134 completed (loss: 0.01162413228303194, acc: 0.9958100318908691)
[2024-12-17 05:36:10,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:11,173][root][INFO] - Training Epoch: 2/2, step 5964/7134 completed (loss: 0.02393641322851181, acc: 0.9944547414779663)
[2024-12-17 05:36:11,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:11,592][root][INFO] - Training Epoch: 2/2, step 5965/7134 completed (loss: 0.02489554136991501, acc: 0.9925037622451782)
[2024-12-17 05:36:11,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:12,020][root][INFO] - Training Epoch: 2/2, step 5966/7134 completed (loss: 0.044382140040397644, acc: 0.9833564758300781)
[2024-12-17 05:36:12,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:12,459][root][INFO] - Training Epoch: 2/2, step 5967/7134 completed (loss: 0.021151429042220116, acc: 0.9925373196601868)
[2024-12-17 05:36:12,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:12,865][root][INFO] - Training Epoch: 2/2, step 5968/7134 completed (loss: 0.030480045825242996, acc: 0.990867555141449)
[2024-12-17 05:36:12,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:13,272][root][INFO] - Training Epoch: 2/2, step 5969/7134 completed (loss: 0.03500543534755707, acc: 0.9922600388526917)
[2024-12-17 05:36:13,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:13,714][root][INFO] - Training Epoch: 2/2, step 5970/7134 completed (loss: 0.04481378197669983, acc: 0.993852436542511)
[2024-12-17 05:36:13,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:14,157][root][INFO] - Training Epoch: 2/2, step 5971/7134 completed (loss: 0.015395581722259521, acc: 0.9912280440330505)
[2024-12-17 05:36:14,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:14,620][root][INFO] - Training Epoch: 2/2, step 5972/7134 completed (loss: 0.06057963892817497, acc: 0.9897210001945496)
[2024-12-17 05:36:14,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:15,090][root][INFO] - Training Epoch: 2/2, step 5973/7134 completed (loss: 0.06034058332443237, acc: 0.9856114983558655)
[2024-12-17 05:36:15,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:15,551][root][INFO] - Training Epoch: 2/2, step 5974/7134 completed (loss: 0.017032453790307045, acc: 0.9913344979286194)
[2024-12-17 05:36:15,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:15,944][root][INFO] - Training Epoch: 2/2, step 5975/7134 completed (loss: 0.022500863298773766, acc: 0.9955752491950989)
[2024-12-17 05:36:16,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:16,394][root][INFO] - Training Epoch: 2/2, step 5976/7134 completed (loss: 0.022109881043434143, acc: 0.9938650131225586)
[2024-12-17 05:36:16,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:16,845][root][INFO] - Training Epoch: 2/2, step 5977/7134 completed (loss: 0.026341859251260757, acc: 0.9950433969497681)
[2024-12-17 05:36:16,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:17,280][root][INFO] - Training Epoch: 2/2, step 5978/7134 completed (loss: 0.030873430892825127, acc: 0.9919871687889099)
[2024-12-17 05:36:17,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:17,673][root][INFO] - Training Epoch: 2/2, step 5979/7134 completed (loss: 0.033652711659669876, acc: 0.9925925731658936)
[2024-12-17 05:36:17,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:18,127][root][INFO] - Training Epoch: 2/2, step 5980/7134 completed (loss: 0.02143576741218567, acc: 0.994878351688385)
[2024-12-17 05:36:18,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:18,606][root][INFO] - Training Epoch: 2/2, step 5981/7134 completed (loss: 0.0280761756002903, acc: 0.99190753698349)
[2024-12-17 05:36:18,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:18,998][root][INFO] - Training Epoch: 2/2, step 5982/7134 completed (loss: 0.017193149775266647, acc: 0.9940357804298401)
[2024-12-17 05:36:19,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:19,435][root][INFO] - Training Epoch: 2/2, step 5983/7134 completed (loss: 0.036657486110925674, acc: 0.9916666746139526)
[2024-12-17 05:36:19,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:19,876][root][INFO] - Training Epoch: 2/2, step 5984/7134 completed (loss: 0.018120529130101204, acc: 0.9957447052001953)
[2024-12-17 05:36:19,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:20,327][root][INFO] - Training Epoch: 2/2, step 5985/7134 completed (loss: 0.02467893250286579, acc: 0.9949937462806702)
[2024-12-17 05:36:20,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:20,791][root][INFO] - Training Epoch: 2/2, step 5986/7134 completed (loss: 0.039496518671512604, acc: 0.9910827875137329)
[2024-12-17 05:36:20,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:21,237][root][INFO] - Training Epoch: 2/2, step 5987/7134 completed (loss: 0.03670842573046684, acc: 0.9871794581413269)
[2024-12-17 05:36:21,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:21,664][root][INFO] - Training Epoch: 2/2, step 5988/7134 completed (loss: 0.008854708634316921, acc: 0.9973333477973938)
[2024-12-17 05:36:21,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:22,112][root][INFO] - Training Epoch: 2/2, step 5989/7134 completed (loss: 0.04138241335749626, acc: 0.990774929523468)
[2024-12-17 05:36:22,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:22,579][root][INFO] - Training Epoch: 2/2, step 5990/7134 completed (loss: 0.01637544110417366, acc: 0.9958904385566711)
[2024-12-17 05:36:22,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:22,888][root][INFO] - Training Epoch: 2/2, step 5991/7134 completed (loss: 0.07875680923461914, acc: 0.9888268113136292)
[2024-12-17 05:36:22,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:23,371][root][INFO] - Training Epoch: 2/2, step 5992/7134 completed (loss: 0.023934591561555862, acc: 0.99303138256073)
[2024-12-17 05:36:23,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:23,818][root][INFO] - Training Epoch: 2/2, step 5993/7134 completed (loss: 0.02058267593383789, acc: 0.9930651783943176)
[2024-12-17 05:36:23,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:24,242][root][INFO] - Training Epoch: 2/2, step 5994/7134 completed (loss: 0.015450839884579182, acc: 0.9942965507507324)
[2024-12-17 05:36:24,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:24,698][root][INFO] - Training Epoch: 2/2, step 5995/7134 completed (loss: 0.00786155741661787, acc: 0.997183084487915)
[2024-12-17 05:36:24,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:25,133][root][INFO] - Training Epoch: 2/2, step 5996/7134 completed (loss: 0.05367721989750862, acc: 0.9843505620956421)
[2024-12-17 05:36:25,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:25,568][root][INFO] - Training Epoch: 2/2, step 5997/7134 completed (loss: 0.029148386791348457, acc: 0.9933244585990906)
[2024-12-17 05:36:25,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:26,039][root][INFO] - Training Epoch: 2/2, step 5998/7134 completed (loss: 0.034830037504434586, acc: 0.9862843155860901)
[2024-12-17 05:36:26,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:26,443][root][INFO] - Training Epoch: 2/2, step 5999/7134 completed (loss: 0.022947194054722786, acc: 0.9888476133346558)
[2024-12-17 05:36:26,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:26,846][root][INFO] - Training Epoch: 2/2, step 6000/7134 completed (loss: 0.026153912767767906, acc: 0.9916805028915405)
[2024-12-17 05:36:26,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:27,290][root][INFO] - Training Epoch: 2/2, step 6001/7134 completed (loss: 0.009570639580488205, acc: 0.9974424839019775)
[2024-12-17 05:36:27,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:27,706][root][INFO] - Training Epoch: 2/2, step 6002/7134 completed (loss: 0.03420791029930115, acc: 0.9902533888816833)
[2024-12-17 05:36:27,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:28,175][root][INFO] - Training Epoch: 2/2, step 6003/7134 completed (loss: 0.02275107242166996, acc: 0.9926578402519226)
[2024-12-17 05:36:28,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:28,613][root][INFO] - Training Epoch: 2/2, step 6004/7134 completed (loss: 0.0354749821126461, acc: 0.9888734221458435)
[2024-12-17 05:36:28,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:29,034][root][INFO] - Training Epoch: 2/2, step 6005/7134 completed (loss: 0.02504841797053814, acc: 0.9923896789550781)
[2024-12-17 05:36:29,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:29,449][root][INFO] - Training Epoch: 2/2, step 6006/7134 completed (loss: 0.03615695238113403, acc: 0.9864603281021118)
[2024-12-17 05:36:29,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:29,893][root][INFO] - Training Epoch: 2/2, step 6007/7134 completed (loss: 0.016175800934433937, acc: 0.994991660118103)
[2024-12-17 05:36:30,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:30,330][root][INFO] - Training Epoch: 2/2, step 6008/7134 completed (loss: 0.029157666489481926, acc: 0.9925816059112549)
[2024-12-17 05:36:30,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:30,743][root][INFO] - Training Epoch: 2/2, step 6009/7134 completed (loss: 0.03770953044295311, acc: 0.9906832575798035)
[2024-12-17 05:36:30,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:31,182][root][INFO] - Training Epoch: 2/2, step 6010/7134 completed (loss: 0.05420248955488205, acc: 0.9864498376846313)
[2024-12-17 05:36:31,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:31,653][root][INFO] - Training Epoch: 2/2, step 6011/7134 completed (loss: 0.042977578938007355, acc: 0.9870466589927673)
[2024-12-17 05:36:31,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:32,092][root][INFO] - Training Epoch: 2/2, step 6012/7134 completed (loss: 0.02951224334537983, acc: 0.9895522594451904)
[2024-12-17 05:36:32,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:32,537][root][INFO] - Training Epoch: 2/2, step 6013/7134 completed (loss: 0.03513365983963013, acc: 0.9879679083824158)
[2024-12-17 05:36:32,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:32,934][root][INFO] - Training Epoch: 2/2, step 6014/7134 completed (loss: 0.02360142208635807, acc: 0.9854809641838074)
[2024-12-17 05:36:33,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:33,370][root][INFO] - Training Epoch: 2/2, step 6015/7134 completed (loss: 0.04770150035619736, acc: 0.9855371713638306)
[2024-12-17 05:36:33,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:33,775][root][INFO] - Training Epoch: 2/2, step 6016/7134 completed (loss: 0.012684381566941738, acc: 0.9964157938957214)
[2024-12-17 05:36:33,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:34,120][root][INFO] - Training Epoch: 2/2, step 6017/7134 completed (loss: 0.011519926600158215, acc: 0.9950494766235352)
[2024-12-17 05:36:34,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:34,521][root][INFO] - Training Epoch: 2/2, step 6018/7134 completed (loss: 0.012784897349774837, acc: 0.9947368502616882)
[2024-12-17 05:36:34,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:34,908][root][INFO] - Training Epoch: 2/2, step 6019/7134 completed (loss: 0.035192299634218216, acc: 0.9913793206214905)
[2024-12-17 05:36:35,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:35,309][root][INFO] - Training Epoch: 2/2, step 6020/7134 completed (loss: 0.005562516860663891, acc: 1.0)
[2024-12-17 05:36:35,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:35,705][root][INFO] - Training Epoch: 2/2, step 6021/7134 completed (loss: 0.004995348397642374, acc: 1.0)
[2024-12-17 05:36:35,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:36,099][root][INFO] - Training Epoch: 2/2, step 6022/7134 completed (loss: 0.023752719163894653, acc: 0.9889298677444458)
[2024-12-17 05:36:36,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:36,482][root][INFO] - Training Epoch: 2/2, step 6023/7134 completed (loss: 0.022740226238965988, acc: 0.989159882068634)
[2024-12-17 05:36:36,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:36,895][root][INFO] - Training Epoch: 2/2, step 6024/7134 completed (loss: 0.006402639672160149, acc: 1.0)
[2024-12-17 05:36:37,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:37,349][root][INFO] - Training Epoch: 2/2, step 6025/7134 completed (loss: 0.018399234861135483, acc: 0.9937238693237305)
[2024-12-17 05:36:37,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:37,742][root][INFO] - Training Epoch: 2/2, step 6026/7134 completed (loss: 0.02188682183623314, acc: 0.9885714054107666)
[2024-12-17 05:36:37,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:38,140][root][INFO] - Training Epoch: 2/2, step 6027/7134 completed (loss: 0.024387631565332413, acc: 0.9897172451019287)
[2024-12-17 05:36:38,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:38,540][root][INFO] - Training Epoch: 2/2, step 6028/7134 completed (loss: 0.0035010187420994043, acc: 1.0)
[2024-12-17 05:36:38,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:38,903][root][INFO] - Training Epoch: 2/2, step 6029/7134 completed (loss: 0.018339812755584717, acc: 0.9927797913551331)
[2024-12-17 05:36:39,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:39,295][root][INFO] - Training Epoch: 2/2, step 6030/7134 completed (loss: 0.02016979269683361, acc: 0.992337167263031)
[2024-12-17 05:36:39,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:39,694][root][INFO] - Training Epoch: 2/2, step 6031/7134 completed (loss: 0.03249138593673706, acc: 0.9941520690917969)
[2024-12-17 05:36:39,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:40,055][root][INFO] - Training Epoch: 2/2, step 6032/7134 completed (loss: 0.021010758355259895, acc: 0.9949367046356201)
[2024-12-17 05:36:40,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:40,426][root][INFO] - Training Epoch: 2/2, step 6033/7134 completed (loss: 0.07436714321374893, acc: 0.9754098653793335)
[2024-12-17 05:36:40,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:40,802][root][INFO] - Training Epoch: 2/2, step 6034/7134 completed (loss: 0.03917399421334267, acc: 0.9877049326896667)
[2024-12-17 05:36:40,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:41,282][root][INFO] - Training Epoch: 2/2, step 6035/7134 completed (loss: 0.07139953225851059, acc: 0.9777777791023254)
[2024-12-17 05:36:41,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:41,754][root][INFO] - Training Epoch: 2/2, step 6036/7134 completed (loss: 0.05157903954386711, acc: 0.9874125719070435)
[2024-12-17 05:36:41,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:42,194][root][INFO] - Training Epoch: 2/2, step 6037/7134 completed (loss: 0.027494492009282112, acc: 0.993220329284668)
[2024-12-17 05:36:42,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:42,660][root][INFO] - Training Epoch: 2/2, step 6038/7134 completed (loss: 0.037004053592681885, acc: 0.9921700358390808)
[2024-12-17 05:36:42,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:43,117][root][INFO] - Training Epoch: 2/2, step 6039/7134 completed (loss: 0.023512709885835648, acc: 0.9928825497627258)
[2024-12-17 05:36:43,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:43,578][root][INFO] - Training Epoch: 2/2, step 6040/7134 completed (loss: 0.05766858160495758, acc: 0.9844074845314026)
[2024-12-17 05:36:43,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:43,994][root][INFO] - Training Epoch: 2/2, step 6041/7134 completed (loss: 0.03446129336953163, acc: 0.9921362996101379)
[2024-12-17 05:36:44,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:44,456][root][INFO] - Training Epoch: 2/2, step 6042/7134 completed (loss: 0.017079029232263565, acc: 0.9919999837875366)
[2024-12-17 05:36:44,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:44,896][root][INFO] - Training Epoch: 2/2, step 6043/7134 completed (loss: 0.026680657640099525, acc: 0.9904076457023621)
[2024-12-17 05:36:45,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:45,368][root][INFO] - Training Epoch: 2/2, step 6044/7134 completed (loss: 0.03761954978108406, acc: 0.9864197373390198)
[2024-12-17 05:36:45,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:45,799][root][INFO] - Training Epoch: 2/2, step 6045/7134 completed (loss: 0.03413020074367523, acc: 0.9869822263717651)
[2024-12-17 05:36:45,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:46,241][root][INFO] - Training Epoch: 2/2, step 6046/7134 completed (loss: 0.044269368052482605, acc: 0.9896013736724854)
[2024-12-17 05:36:46,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:46,700][root][INFO] - Training Epoch: 2/2, step 6047/7134 completed (loss: 0.1059836894273758, acc: 0.9763912558555603)
[2024-12-17 05:36:46,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:47,132][root][INFO] - Training Epoch: 2/2, step 6048/7134 completed (loss: 0.07759573310613632, acc: 0.9739478826522827)
[2024-12-17 05:36:47,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:47,547][root][INFO] - Training Epoch: 2/2, step 6049/7134 completed (loss: 0.011895589530467987, acc: 0.9965870380401611)
[2024-12-17 05:36:47,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:47,982][root][INFO] - Training Epoch: 2/2, step 6050/7134 completed (loss: 0.07919447869062424, acc: 0.9740082025527954)
[2024-12-17 05:36:48,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:48,448][root][INFO] - Training Epoch: 2/2, step 6051/7134 completed (loss: 0.06951110064983368, acc: 0.9807976484298706)
[2024-12-17 05:36:48,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:48,912][root][INFO] - Training Epoch: 2/2, step 6052/7134 completed (loss: 0.0636325553059578, acc: 0.9827315807342529)
[2024-12-17 05:36:49,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:49,367][root][INFO] - Training Epoch: 2/2, step 6053/7134 completed (loss: 0.05548638105392456, acc: 0.9835526347160339)
[2024-12-17 05:36:49,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:49,808][root][INFO] - Training Epoch: 2/2, step 6054/7134 completed (loss: 0.03934064880013466, acc: 0.990338146686554)
[2024-12-17 05:36:49,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:50,242][root][INFO] - Training Epoch: 2/2, step 6055/7134 completed (loss: 0.030118845403194427, acc: 0.9905213117599487)
[2024-12-17 05:36:50,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:50,638][root][INFO] - Training Epoch: 2/2, step 6056/7134 completed (loss: 0.04150305315852165, acc: 0.9861751198768616)
[2024-12-17 05:36:50,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:51,052][root][INFO] - Training Epoch: 2/2, step 6057/7134 completed (loss: 0.04778308421373367, acc: 0.9835526347160339)
[2024-12-17 05:36:51,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:51,445][root][INFO] - Training Epoch: 2/2, step 6058/7134 completed (loss: 0.011424332857131958, acc: 0.9954954981803894)
[2024-12-17 05:36:51,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:51,902][root][INFO] - Training Epoch: 2/2, step 6059/7134 completed (loss: 0.0447179414331913, acc: 0.982332170009613)
[2024-12-17 05:36:52,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:52,358][root][INFO] - Training Epoch: 2/2, step 6060/7134 completed (loss: 0.02219109609723091, acc: 0.9909774661064148)
[2024-12-17 05:36:52,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:52,765][root][INFO] - Training Epoch: 2/2, step 6061/7134 completed (loss: 0.0550306998193264, acc: 0.9830508232116699)
[2024-12-17 05:36:52,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:53,218][root][INFO] - Training Epoch: 2/2, step 6062/7134 completed (loss: 0.0634043887257576, acc: 0.9780361652374268)
[2024-12-17 05:36:53,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:53,637][root][INFO] - Training Epoch: 2/2, step 6063/7134 completed (loss: 0.050048328936100006, acc: 0.9855334758758545)
[2024-12-17 05:36:53,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:54,102][root][INFO] - Training Epoch: 2/2, step 6064/7134 completed (loss: 0.027771620079874992, acc: 0.9927641153335571)
[2024-12-17 05:36:54,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:54,557][root][INFO] - Training Epoch: 2/2, step 6065/7134 completed (loss: 0.03546018898487091, acc: 0.9902794361114502)
[2024-12-17 05:36:54,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:54,965][root][INFO] - Training Epoch: 2/2, step 6066/7134 completed (loss: 0.06473254412412643, acc: 0.9752883315086365)
[2024-12-17 05:36:55,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:55,381][root][INFO] - Training Epoch: 2/2, step 6067/7134 completed (loss: 0.056439392268657684, acc: 0.9769119620323181)
[2024-12-17 05:36:55,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:55,904][root][INFO] - Training Epoch: 2/2, step 6068/7134 completed (loss: 0.09152481704950333, acc: 0.9737171530723572)
[2024-12-17 05:36:56,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:56,306][root][INFO] - Training Epoch: 2/2, step 6069/7134 completed (loss: 0.06449942290782928, acc: 0.9795620441436768)
[2024-12-17 05:36:56,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:56,769][root][INFO] - Training Epoch: 2/2, step 6070/7134 completed (loss: 0.07631516456604004, acc: 0.9786950945854187)
[2024-12-17 05:36:56,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:57,219][root][INFO] - Training Epoch: 2/2, step 6071/7134 completed (loss: 0.05550109222531319, acc: 0.9811574816703796)
[2024-12-17 05:36:57,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:57,581][root][INFO] - Training Epoch: 2/2, step 6072/7134 completed (loss: 0.09211094677448273, acc: 0.9810924530029297)
[2024-12-17 05:36:57,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:58,011][root][INFO] - Training Epoch: 2/2, step 6073/7134 completed (loss: 0.05018335208296776, acc: 0.9846153855323792)
[2024-12-17 05:36:58,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:58,421][root][INFO] - Training Epoch: 2/2, step 6074/7134 completed (loss: 0.058850932866334915, acc: 0.9897058606147766)
[2024-12-17 05:36:58,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:58,871][root][INFO] - Training Epoch: 2/2, step 6075/7134 completed (loss: 0.0459066741168499, acc: 0.9880095720291138)
[2024-12-17 05:36:58,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:59,296][root][INFO] - Training Epoch: 2/2, step 6076/7134 completed (loss: 0.06625410914421082, acc: 0.9798850417137146)
[2024-12-17 05:36:59,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:36:59,721][root][INFO] - Training Epoch: 2/2, step 6077/7134 completed (loss: 0.04776378720998764, acc: 0.9856230020523071)
[2024-12-17 05:36:59,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:00,161][root][INFO] - Training Epoch: 2/2, step 6078/7134 completed (loss: 0.059688154608011246, acc: 0.9802817106246948)
[2024-12-17 05:37:00,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:00,624][root][INFO] - Training Epoch: 2/2, step 6079/7134 completed (loss: 0.026424992829561234, acc: 0.989051103591919)
[2024-12-17 05:37:00,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:01,032][root][INFO] - Training Epoch: 2/2, step 6080/7134 completed (loss: 0.03277462720870972, acc: 0.9900990128517151)
[2024-12-17 05:37:01,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:01,461][root][INFO] - Training Epoch: 2/2, step 6081/7134 completed (loss: 0.021740516647696495, acc: 0.9923664331436157)
[2024-12-17 05:37:01,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:01,877][root][INFO] - Training Epoch: 2/2, step 6082/7134 completed (loss: 0.026484239846467972, acc: 0.9952229261398315)
[2024-12-17 05:37:01,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:02,328][root][INFO] - Training Epoch: 2/2, step 6083/7134 completed (loss: 0.011975466273725033, acc: 0.996314525604248)
[2024-12-17 05:37:02,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:02,732][root][INFO] - Training Epoch: 2/2, step 6084/7134 completed (loss: 0.025284884497523308, acc: 0.9968553185462952)
[2024-12-17 05:37:02,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:03,181][root][INFO] - Training Epoch: 2/2, step 6085/7134 completed (loss: 0.021666131913661957, acc: 0.9928443431854248)
[2024-12-17 05:37:03,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:03,660][root][INFO] - Training Epoch: 2/2, step 6086/7134 completed (loss: 0.021961037069559097, acc: 0.9957864880561829)
[2024-12-17 05:37:03,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:04,148][root][INFO] - Training Epoch: 2/2, step 6087/7134 completed (loss: 0.04848288372159004, acc: 0.9836478233337402)
[2024-12-17 05:37:04,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:04,577][root][INFO] - Training Epoch: 2/2, step 6088/7134 completed (loss: 0.020704610273241997, acc: 0.9932975769042969)
[2024-12-17 05:37:04,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:05,070][root][INFO] - Training Epoch: 2/2, step 6089/7134 completed (loss: 0.046747103333473206, acc: 0.9903448224067688)
[2024-12-17 05:37:05,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:05,501][root][INFO] - Training Epoch: 2/2, step 6090/7134 completed (loss: 0.0222153440117836, acc: 0.9931412935256958)
[2024-12-17 05:37:05,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:05,919][root][INFO] - Training Epoch: 2/2, step 6091/7134 completed (loss: 0.020152563229203224, acc: 0.993630588054657)
[2024-12-17 05:37:06,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:06,333][root][INFO] - Training Epoch: 2/2, step 6092/7134 completed (loss: 0.03599992394447327, acc: 0.9904761910438538)
[2024-12-17 05:37:06,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:06,763][root][INFO] - Training Epoch: 2/2, step 6093/7134 completed (loss: 0.046598538756370544, acc: 0.9888682961463928)
[2024-12-17 05:37:06,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:07,177][root][INFO] - Training Epoch: 2/2, step 6094/7134 completed (loss: 0.04474002122879028, acc: 0.9887955188751221)
[2024-12-17 05:37:07,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:07,620][root][INFO] - Training Epoch: 2/2, step 6095/7134 completed (loss: 0.03124714083969593, acc: 0.9942528605461121)
[2024-12-17 05:37:07,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:08,085][root][INFO] - Training Epoch: 2/2, step 6096/7134 completed (loss: 0.03795497864484787, acc: 0.9904534816741943)
[2024-12-17 05:37:08,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:08,516][root][INFO] - Training Epoch: 2/2, step 6097/7134 completed (loss: 0.04081336781382561, acc: 0.9875346422195435)
[2024-12-17 05:37:08,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:08,958][root][INFO] - Training Epoch: 2/2, step 6098/7134 completed (loss: 0.057213202118873596, acc: 0.9909909963607788)
[2024-12-17 05:37:09,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:09,397][root][INFO] - Training Epoch: 2/2, step 6099/7134 completed (loss: 0.07881268113851547, acc: 0.9831804037094116)
[2024-12-17 05:37:09,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:09,757][root][INFO] - Training Epoch: 2/2, step 6100/7134 completed (loss: 0.0671629011631012, acc: 0.9817073345184326)
[2024-12-17 05:37:09,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:10,165][root][INFO] - Training Epoch: 2/2, step 6101/7134 completed (loss: 0.02496391348540783, acc: 0.9936102032661438)
[2024-12-17 05:37:10,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:10,584][root][INFO] - Training Epoch: 2/2, step 6102/7134 completed (loss: 0.048722878098487854, acc: 0.9894366264343262)
[2024-12-17 05:37:10,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:11,021][root][INFO] - Training Epoch: 2/2, step 6103/7134 completed (loss: 0.028646089136600494, acc: 0.9888888597488403)
[2024-12-17 05:37:11,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:11,430][root][INFO] - Training Epoch: 2/2, step 6104/7134 completed (loss: 0.06395739316940308, acc: 0.9748148322105408)
[2024-12-17 05:37:11,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:11,889][root][INFO] - Training Epoch: 2/2, step 6105/7134 completed (loss: 0.07383808493614197, acc: 0.9717261791229248)
[2024-12-17 05:37:12,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:12,296][root][INFO] - Training Epoch: 2/2, step 6106/7134 completed (loss: 0.04309764504432678, acc: 0.9874776601791382)
[2024-12-17 05:37:12,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:12,711][root][INFO] - Training Epoch: 2/2, step 6107/7134 completed (loss: 0.0383046492934227, acc: 0.9873949289321899)
[2024-12-17 05:37:12,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:13,116][root][INFO] - Training Epoch: 2/2, step 6108/7134 completed (loss: 0.03888978064060211, acc: 0.9836065769195557)
[2024-12-17 05:37:13,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:13,507][root][INFO] - Training Epoch: 2/2, step 6109/7134 completed (loss: 0.015530464239418507, acc: 0.9936440587043762)
[2024-12-17 05:37:13,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:13,919][root][INFO] - Training Epoch: 2/2, step 6110/7134 completed (loss: 0.0841839537024498, acc: 0.9743589758872986)
[2024-12-17 05:37:14,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:14,305][root][INFO] - Training Epoch: 2/2, step 6111/7134 completed (loss: 0.07153443992137909, acc: 0.9839141964912415)
[2024-12-17 05:37:14,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:14,726][root][INFO] - Training Epoch: 2/2, step 6112/7134 completed (loss: 0.030820779502391815, acc: 0.9933110475540161)
[2024-12-17 05:37:14,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:15,148][root][INFO] - Training Epoch: 2/2, step 6113/7134 completed (loss: 0.016810014843940735, acc: 0.9939302206039429)
[2024-12-17 05:37:15,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:15,543][root][INFO] - Training Epoch: 2/2, step 6114/7134 completed (loss: 0.06739239394664764, acc: 0.9785124063491821)
[2024-12-17 05:37:15,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:15,914][root][INFO] - Training Epoch: 2/2, step 6115/7134 completed (loss: 0.04205580800771713, acc: 0.9885057210922241)
[2024-12-17 05:37:16,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:16,278][root][INFO] - Training Epoch: 2/2, step 6116/7134 completed (loss: 0.08066936582326889, acc: 0.9841897487640381)
[2024-12-17 05:37:16,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:16,702][root][INFO] - Training Epoch: 2/2, step 6117/7134 completed (loss: 0.06607271730899811, acc: 0.9808743000030518)
[2024-12-17 05:37:16,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:17,180][root][INFO] - Training Epoch: 2/2, step 6118/7134 completed (loss: 0.04707811772823334, acc: 0.9852941036224365)
[2024-12-17 05:37:17,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:17,623][root][INFO] - Training Epoch: 2/2, step 6119/7134 completed (loss: 0.04431022331118584, acc: 0.9831932783126831)
[2024-12-17 05:37:17,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:18,040][root][INFO] - Training Epoch: 2/2, step 6120/7134 completed (loss: 0.026612555608153343, acc: 0.9946332573890686)
[2024-12-17 05:37:18,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:18,480][root][INFO] - Training Epoch: 2/2, step 6121/7134 completed (loss: 0.055326398462057114, acc: 0.980215847492218)
[2024-12-17 05:37:18,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:18,926][root][INFO] - Training Epoch: 2/2, step 6122/7134 completed (loss: 0.023045262321829796, acc: 0.994339644908905)
[2024-12-17 05:37:19,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:19,369][root][INFO] - Training Epoch: 2/2, step 6123/7134 completed (loss: 0.07518404722213745, acc: 0.9771309494972229)
[2024-12-17 05:37:19,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:19,784][root][INFO] - Training Epoch: 2/2, step 6124/7134 completed (loss: 0.02452923357486725, acc: 0.9923076629638672)
[2024-12-17 05:37:19,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:20,242][root][INFO] - Training Epoch: 2/2, step 6125/7134 completed (loss: 0.1205759271979332, acc: 0.9783132672309875)
[2024-12-17 05:37:20,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:20,671][root][INFO] - Training Epoch: 2/2, step 6126/7134 completed (loss: 0.06653696298599243, acc: 0.9843260049819946)
[2024-12-17 05:37:20,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:21,094][root][INFO] - Training Epoch: 2/2, step 6127/7134 completed (loss: 0.02053770050406456, acc: 0.9904761910438538)
[2024-12-17 05:37:21,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:21,516][root][INFO] - Training Epoch: 2/2, step 6128/7134 completed (loss: 0.029256640002131462, acc: 0.9919028282165527)
[2024-12-17 05:37:21,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:21,945][root][INFO] - Training Epoch: 2/2, step 6129/7134 completed (loss: 0.04506005719304085, acc: 0.9845288395881653)
[2024-12-17 05:37:22,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:22,345][root][INFO] - Training Epoch: 2/2, step 6130/7134 completed (loss: 0.021244890987873077, acc: 0.9964157938957214)
[2024-12-17 05:37:22,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:22,791][root][INFO] - Training Epoch: 2/2, step 6131/7134 completed (loss: 0.04660750925540924, acc: 0.9892215728759766)
[2024-12-17 05:37:22,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:23,204][root][INFO] - Training Epoch: 2/2, step 6132/7134 completed (loss: 0.04308073967695236, acc: 0.989062488079071)
[2024-12-17 05:37:23,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:23,666][root][INFO] - Training Epoch: 2/2, step 6133/7134 completed (loss: 0.04675764590501785, acc: 0.9830096960067749)
[2024-12-17 05:37:23,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:24,074][root][INFO] - Training Epoch: 2/2, step 6134/7134 completed (loss: 0.07841203361749649, acc: 0.9739663004875183)
[2024-12-17 05:37:24,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:24,493][root][INFO] - Training Epoch: 2/2, step 6135/7134 completed (loss: 0.023997128009796143, acc: 0.9912891983985901)
[2024-12-17 05:37:24,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:24,916][root][INFO] - Training Epoch: 2/2, step 6136/7134 completed (loss: 0.049420423805713654, acc: 0.9901960492134094)
[2024-12-17 05:37:25,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:25,333][root][INFO] - Training Epoch: 2/2, step 6137/7134 completed (loss: 0.06434499472379684, acc: 0.9828392863273621)
[2024-12-17 05:37:25,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:25,748][root][INFO] - Training Epoch: 2/2, step 6138/7134 completed (loss: 0.04530119523406029, acc: 0.9877111911773682)
[2024-12-17 05:37:25,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:26,159][root][INFO] - Training Epoch: 2/2, step 6139/7134 completed (loss: 0.04580531269311905, acc: 0.9870370626449585)
[2024-12-17 05:37:26,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:26,619][root][INFO] - Training Epoch: 2/2, step 6140/7134 completed (loss: 0.03195664659142494, acc: 0.9911660552024841)
[2024-12-17 05:37:26,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:26,952][root][INFO] - Training Epoch: 2/2, step 6141/7134 completed (loss: 0.08648796379566193, acc: 0.9938837885856628)
[2024-12-17 05:37:27,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:27,370][root][INFO] - Training Epoch: 2/2, step 6142/7134 completed (loss: 0.038505058735609055, acc: 0.9856114983558655)
[2024-12-17 05:37:27,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:27,803][root][INFO] - Training Epoch: 2/2, step 6143/7134 completed (loss: 0.033963702619075775, acc: 0.9918919205665588)
[2024-12-17 05:37:27,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:28,200][root][INFO] - Training Epoch: 2/2, step 6144/7134 completed (loss: 0.02655365690588951, acc: 0.9915966391563416)
[2024-12-17 05:37:28,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:28,654][root][INFO] - Training Epoch: 2/2, step 6145/7134 completed (loss: 0.05948108434677124, acc: 0.9854689836502075)
[2024-12-17 05:37:28,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:29,089][root][INFO] - Training Epoch: 2/2, step 6146/7134 completed (loss: 0.06435833126306534, acc: 0.9819004535675049)
[2024-12-17 05:37:29,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:29,532][root][INFO] - Training Epoch: 2/2, step 6147/7134 completed (loss: 0.041083745658397675, acc: 0.9900793433189392)
[2024-12-17 05:37:29,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:29,984][root][INFO] - Training Epoch: 2/2, step 6148/7134 completed (loss: 0.043710917234420776, acc: 0.9832496047019958)
[2024-12-17 05:37:30,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:30,410][root][INFO] - Training Epoch: 2/2, step 6149/7134 completed (loss: 0.04503621160984039, acc: 0.9807074069976807)
[2024-12-17 05:37:30,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:30,863][root][INFO] - Training Epoch: 2/2, step 6150/7134 completed (loss: 0.033952247351408005, acc: 0.9894737005233765)
[2024-12-17 05:37:30,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:31,271][root][INFO] - Training Epoch: 2/2, step 6151/7134 completed (loss: 0.016005737707018852, acc: 0.9937205910682678)
[2024-12-17 05:37:31,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:31,698][root][INFO] - Training Epoch: 2/2, step 6152/7134 completed (loss: 0.03755456581711769, acc: 0.9879336357116699)
[2024-12-17 05:37:31,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:32,149][root][INFO] - Training Epoch: 2/2, step 6153/7134 completed (loss: 0.017876969650387764, acc: 0.9971056580543518)
[2024-12-17 05:37:32,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:32,602][root][INFO] - Training Epoch: 2/2, step 6154/7134 completed (loss: 0.039014678448438644, acc: 0.9902371168136597)
[2024-12-17 05:37:32,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:33,041][root][INFO] - Training Epoch: 2/2, step 6155/7134 completed (loss: 0.040275849401950836, acc: 0.9866468906402588)
[2024-12-17 05:37:33,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:33,443][root][INFO] - Training Epoch: 2/2, step 6156/7134 completed (loss: 0.014727704226970673, acc: 0.996830403804779)
[2024-12-17 05:37:33,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:33,877][root][INFO] - Training Epoch: 2/2, step 6157/7134 completed (loss: 0.024838773533701897, acc: 0.9921630024909973)
[2024-12-17 05:37:33,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:34,304][root][INFO] - Training Epoch: 2/2, step 6158/7134 completed (loss: 0.07214226573705673, acc: 0.9873417615890503)
[2024-12-17 05:37:34,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:34,747][root][INFO] - Training Epoch: 2/2, step 6159/7134 completed (loss: 0.04662958160042763, acc: 0.9843184351921082)
[2024-12-17 05:37:34,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:35,179][root][INFO] - Training Epoch: 2/2, step 6160/7134 completed (loss: 0.06614489108324051, acc: 0.9818181991577148)
[2024-12-17 05:37:35,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:35,631][root][INFO] - Training Epoch: 2/2, step 6161/7134 completed (loss: 0.06022385135293007, acc: 0.982425332069397)
[2024-12-17 05:37:35,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:36,075][root][INFO] - Training Epoch: 2/2, step 6162/7134 completed (loss: 0.04170515015721321, acc: 0.9885433912277222)
[2024-12-17 05:37:36,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:36,506][root][INFO] - Training Epoch: 2/2, step 6163/7134 completed (loss: 0.0827365443110466, acc: 0.9839285612106323)
[2024-12-17 05:37:36,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:36,961][root][INFO] - Training Epoch: 2/2, step 6164/7134 completed (loss: 0.0631227046251297, acc: 0.9787535667419434)
[2024-12-17 05:37:37,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:37,350][root][INFO] - Training Epoch: 2/2, step 6165/7134 completed (loss: 0.04216030612587929, acc: 0.9889298677444458)
[2024-12-17 05:37:37,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:37,755][root][INFO] - Training Epoch: 2/2, step 6166/7134 completed (loss: 0.04116819426417351, acc: 0.9912126660346985)
[2024-12-17 05:37:37,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:38,176][root][INFO] - Training Epoch: 2/2, step 6167/7134 completed (loss: 0.02426714077591896, acc: 0.9943422675132751)
[2024-12-17 05:37:38,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:38,631][root][INFO] - Training Epoch: 2/2, step 6168/7134 completed (loss: 0.047322019934654236, acc: 0.9845559597015381)
[2024-12-17 05:37:38,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:39,028][root][INFO] - Training Epoch: 2/2, step 6169/7134 completed (loss: 0.03763235732913017, acc: 0.9883381724357605)
[2024-12-17 05:37:39,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:39,420][root][INFO] - Training Epoch: 2/2, step 6170/7134 completed (loss: 0.0278636422008276, acc: 0.992438554763794)
[2024-12-17 05:37:39,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:39,871][root][INFO] - Training Epoch: 2/2, step 6171/7134 completed (loss: 0.01875542663037777, acc: 0.9934297204017639)
[2024-12-17 05:37:39,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:40,275][root][INFO] - Training Epoch: 2/2, step 6172/7134 completed (loss: 0.02957732230424881, acc: 0.9939879775047302)
[2024-12-17 05:37:40,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:40,671][root][INFO] - Training Epoch: 2/2, step 6173/7134 completed (loss: 0.013035763055086136, acc: 0.9970545172691345)
[2024-12-17 05:37:40,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:41,089][root][INFO] - Training Epoch: 2/2, step 6174/7134 completed (loss: 0.009973193518817425, acc: 0.9970674514770508)
[2024-12-17 05:37:41,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:41,524][root][INFO] - Training Epoch: 2/2, step 6175/7134 completed (loss: 0.028338104486465454, acc: 0.9911242723464966)
[2024-12-17 05:37:41,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:41,934][root][INFO] - Training Epoch: 2/2, step 6176/7134 completed (loss: 0.02503674104809761, acc: 0.9913169145584106)
[2024-12-17 05:37:42,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:42,362][root][INFO] - Training Epoch: 2/2, step 6177/7134 completed (loss: 0.019120151177048683, acc: 0.9923273921012878)
[2024-12-17 05:37:42,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:42,791][root][INFO] - Training Epoch: 2/2, step 6178/7134 completed (loss: 0.019734686240553856, acc: 0.991150438785553)
[2024-12-17 05:37:42,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:43,216][root][INFO] - Training Epoch: 2/2, step 6179/7134 completed (loss: 0.040580689907073975, acc: 0.989130437374115)
[2024-12-17 05:37:43,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:43,664][root][INFO] - Training Epoch: 2/2, step 6180/7134 completed (loss: 0.12615178525447845, acc: 0.9649681448936462)
[2024-12-17 05:37:43,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:44,059][root][INFO] - Training Epoch: 2/2, step 6181/7134 completed (loss: 0.209255188703537, acc: 0.9380165338516235)
[2024-12-17 05:37:44,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:44,482][root][INFO] - Training Epoch: 2/2, step 6182/7134 completed (loss: 0.03797714039683342, acc: 0.9851577281951904)
[2024-12-17 05:37:44,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:44,906][root][INFO] - Training Epoch: 2/2, step 6183/7134 completed (loss: 0.055881306529045105, acc: 0.9846860766410828)
[2024-12-17 05:37:45,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:45,307][root][INFO] - Training Epoch: 2/2, step 6184/7134 completed (loss: 0.1027156338095665, acc: 0.9737903475761414)
[2024-12-17 05:37:45,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:45,718][root][INFO] - Training Epoch: 2/2, step 6185/7134 completed (loss: 0.03532890975475311, acc: 0.9889705777168274)
[2024-12-17 05:37:45,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:46,130][root][INFO] - Training Epoch: 2/2, step 6186/7134 completed (loss: 0.03248094394803047, acc: 0.9912587404251099)
[2024-12-17 05:37:46,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:46,594][root][INFO] - Training Epoch: 2/2, step 6187/7134 completed (loss: 0.027111556380987167, acc: 0.9894179701805115)
[2024-12-17 05:37:46,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:47,024][root][INFO] - Training Epoch: 2/2, step 6188/7134 completed (loss: 0.06253194808959961, acc: 0.9844852089881897)
[2024-12-17 05:37:47,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:47,475][root][INFO] - Training Epoch: 2/2, step 6189/7134 completed (loss: 0.0754549577832222, acc: 0.9783549904823303)
[2024-12-17 05:37:47,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:47,883][root][INFO] - Training Epoch: 2/2, step 6190/7134 completed (loss: 0.04928898438811302, acc: 0.9817276000976562)
[2024-12-17 05:37:47,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:48,341][root][INFO] - Training Epoch: 2/2, step 6191/7134 completed (loss: 0.06406646966934204, acc: 0.9842657446861267)
[2024-12-17 05:37:48,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:48,808][root][INFO] - Training Epoch: 2/2, step 6192/7134 completed (loss: 0.04358551651239395, acc: 0.9871382713317871)
[2024-12-17 05:37:48,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:49,248][root][INFO] - Training Epoch: 2/2, step 6193/7134 completed (loss: 0.04672809690237045, acc: 0.9881094098091125)
[2024-12-17 05:37:49,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:49,681][root][INFO] - Training Epoch: 2/2, step 6194/7134 completed (loss: 0.03729337081313133, acc: 0.9863813519477844)
[2024-12-17 05:37:49,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:50,073][root][INFO] - Training Epoch: 2/2, step 6195/7134 completed (loss: 0.032847046852111816, acc: 0.9880383014678955)
[2024-12-17 05:37:50,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:50,504][root][INFO] - Training Epoch: 2/2, step 6196/7134 completed (loss: 0.03937438130378723, acc: 0.9820936918258667)
[2024-12-17 05:37:50,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:50,954][root][INFO] - Training Epoch: 2/2, step 6197/7134 completed (loss: 0.06789185851812363, acc: 0.9834482669830322)
[2024-12-17 05:37:51,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:51,366][root][INFO] - Training Epoch: 2/2, step 6198/7134 completed (loss: 0.045159365981817245, acc: 0.9813277721405029)
[2024-12-17 05:37:51,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:51,837][root][INFO] - Training Epoch: 2/2, step 6199/7134 completed (loss: 0.04280146211385727, acc: 0.9837586879730225)
[2024-12-17 05:37:51,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:52,282][root][INFO] - Training Epoch: 2/2, step 6200/7134 completed (loss: 0.029678843915462494, acc: 0.9914634227752686)
[2024-12-17 05:37:52,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:52,744][root][INFO] - Training Epoch: 2/2, step 6201/7134 completed (loss: 0.02616039849817753, acc: 0.9899665713310242)
[2024-12-17 05:37:52,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:53,158][root][INFO] - Training Epoch: 2/2, step 6202/7134 completed (loss: 0.02157842554152012, acc: 0.9913232326507568)
[2024-12-17 05:37:53,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:53,603][root][INFO] - Training Epoch: 2/2, step 6203/7134 completed (loss: 0.02181524597108364, acc: 0.9974489808082581)
[2024-12-17 05:37:53,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:54,056][root][INFO] - Training Epoch: 2/2, step 6204/7134 completed (loss: 0.02191631868481636, acc: 0.9921414256095886)
[2024-12-17 05:37:54,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:54,480][root][INFO] - Training Epoch: 2/2, step 6205/7134 completed (loss: 0.044925108551979065, acc: 0.9846416115760803)
[2024-12-17 05:37:54,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:54,892][root][INFO] - Training Epoch: 2/2, step 6206/7134 completed (loss: 0.020938608795404434, acc: 0.9927641153335571)
[2024-12-17 05:37:55,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:55,343][root][INFO] - Training Epoch: 2/2, step 6207/7134 completed (loss: 0.14139793813228607, acc: 0.9626168012619019)
[2024-12-17 05:37:55,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:55,775][root][INFO] - Training Epoch: 2/2, step 6208/7134 completed (loss: 0.04336216673254967, acc: 0.9872685074806213)
[2024-12-17 05:37:55,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:56,217][root][INFO] - Training Epoch: 2/2, step 6209/7134 completed (loss: 0.039684101939201355, acc: 0.9857697486877441)
[2024-12-17 05:37:56,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:56,687][root][INFO] - Training Epoch: 2/2, step 6210/7134 completed (loss: 0.02611982263624668, acc: 0.9923076629638672)
[2024-12-17 05:37:56,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:57,138][root][INFO] - Training Epoch: 2/2, step 6211/7134 completed (loss: 0.053422242403030396, acc: 0.9824086427688599)
[2024-12-17 05:37:57,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:57,544][root][INFO] - Training Epoch: 2/2, step 6212/7134 completed (loss: 0.02764812484383583, acc: 0.9912280440330505)
[2024-12-17 05:37:57,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:57,952][root][INFO] - Training Epoch: 2/2, step 6213/7134 completed (loss: 0.017231328412890434, acc: 0.9937629699707031)
[2024-12-17 05:37:58,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:58,406][root][INFO] - Training Epoch: 2/2, step 6214/7134 completed (loss: 0.01880050264298916, acc: 0.9948652386665344)
[2024-12-17 05:37:58,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:58,856][root][INFO] - Training Epoch: 2/2, step 6215/7134 completed (loss: 0.043018899857997894, acc: 0.9896313548088074)
[2024-12-17 05:37:58,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:59,255][root][INFO] - Training Epoch: 2/2, step 6216/7134 completed (loss: 0.02011803165078163, acc: 0.9936169981956482)
[2024-12-17 05:37:59,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:37:59,696][root][INFO] - Training Epoch: 2/2, step 6217/7134 completed (loss: 0.021673651412129402, acc: 0.991946280002594)
[2024-12-17 05:37:59,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:00,158][root][INFO] - Training Epoch: 2/2, step 6218/7134 completed (loss: 0.03275417909026146, acc: 0.9893292784690857)
[2024-12-17 05:38:00,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:00,605][root][INFO] - Training Epoch: 2/2, step 6219/7134 completed (loss: 0.029926661401987076, acc: 0.9915611743927002)
[2024-12-17 05:38:00,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:01,007][root][INFO] - Training Epoch: 2/2, step 6220/7134 completed (loss: 0.03145962581038475, acc: 0.9904761910438538)
[2024-12-17 05:38:01,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:01,425][root][INFO] - Training Epoch: 2/2, step 6221/7134 completed (loss: 0.01007774006575346, acc: 0.9982455968856812)
[2024-12-17 05:38:01,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:01,812][root][INFO] - Training Epoch: 2/2, step 6222/7134 completed (loss: 0.050757985562086105, acc: 0.9904371500015259)
[2024-12-17 05:38:01,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:02,252][root][INFO] - Training Epoch: 2/2, step 6223/7134 completed (loss: 0.02886970341205597, acc: 0.990231990814209)
[2024-12-17 05:38:02,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:02,675][root][INFO] - Training Epoch: 2/2, step 6224/7134 completed (loss: 0.009325236082077026, acc: 0.9956458806991577)
[2024-12-17 05:38:02,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:03,129][root][INFO] - Training Epoch: 2/2, step 6225/7134 completed (loss: 0.021371323615312576, acc: 0.9910714030265808)
[2024-12-17 05:38:03,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:03,564][root][INFO] - Training Epoch: 2/2, step 6226/7134 completed (loss: 0.039415180683135986, acc: 0.9882044792175293)
[2024-12-17 05:38:03,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:04,013][root][INFO] - Training Epoch: 2/2, step 6227/7134 completed (loss: 0.00773333664983511, acc: 0.9973226189613342)
[2024-12-17 05:38:04,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:04,450][root][INFO] - Training Epoch: 2/2, step 6228/7134 completed (loss: 0.034698206931352615, acc: 0.9877150058746338)
[2024-12-17 05:38:04,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:04,901][root][INFO] - Training Epoch: 2/2, step 6229/7134 completed (loss: 0.06995926797389984, acc: 0.9814385175704956)
[2024-12-17 05:38:05,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:05,347][root][INFO] - Training Epoch: 2/2, step 6230/7134 completed (loss: 0.03172234818339348, acc: 0.9887780547142029)
[2024-12-17 05:38:05,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:05,753][root][INFO] - Training Epoch: 2/2, step 6231/7134 completed (loss: 0.013608120381832123, acc: 0.9974160194396973)
[2024-12-17 05:38:05,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:06,206][root][INFO] - Training Epoch: 2/2, step 6232/7134 completed (loss: 0.02623525820672512, acc: 0.993686854839325)
[2024-12-17 05:38:06,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:06,646][root][INFO] - Training Epoch: 2/2, step 6233/7134 completed (loss: 0.02401379495859146, acc: 0.9919571280479431)
[2024-12-17 05:38:06,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:07,088][root][INFO] - Training Epoch: 2/2, step 6234/7134 completed (loss: 0.056591421365737915, acc: 0.9839572310447693)
[2024-12-17 05:38:07,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:07,504][root][INFO] - Training Epoch: 2/2, step 6235/7134 completed (loss: 0.01776123233139515, acc: 0.9960886836051941)
[2024-12-17 05:38:07,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:07,955][root][INFO] - Training Epoch: 2/2, step 6236/7134 completed (loss: 0.027722269296646118, acc: 0.9890859723091125)
[2024-12-17 05:38:08,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:08,390][root][INFO] - Training Epoch: 2/2, step 6237/7134 completed (loss: 0.024912679567933083, acc: 0.9877675771713257)
[2024-12-17 05:38:08,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:08,791][root][INFO] - Training Epoch: 2/2, step 6238/7134 completed (loss: 0.011003833264112473, acc: 0.9967690110206604)
[2024-12-17 05:38:08,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:09,250][root][INFO] - Training Epoch: 2/2, step 6239/7134 completed (loss: 0.031135249882936478, acc: 0.9940263032913208)
[2024-12-17 05:38:09,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:09,691][root][INFO] - Training Epoch: 2/2, step 6240/7134 completed (loss: 0.003981826826930046, acc: 1.0)
[2024-12-17 05:38:09,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:10,111][root][INFO] - Training Epoch: 2/2, step 6241/7134 completed (loss: 0.0056223440915346146, acc: 1.0)
[2024-12-17 05:38:10,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:10,533][root][INFO] - Training Epoch: 2/2, step 6242/7134 completed (loss: 0.016463590785861015, acc: 0.9948979616165161)
[2024-12-17 05:38:10,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:10,970][root][INFO] - Training Epoch: 2/2, step 6243/7134 completed (loss: 0.010230038315057755, acc: 0.9968152642250061)
[2024-12-17 05:38:11,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:11,388][root][INFO] - Training Epoch: 2/2, step 6244/7134 completed (loss: 0.016245758160948753, acc: 0.9945130348205566)
[2024-12-17 05:38:11,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:11,818][root][INFO] - Training Epoch: 2/2, step 6245/7134 completed (loss: 0.020546086132526398, acc: 0.99589604139328)
[2024-12-17 05:38:11,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:12,260][root][INFO] - Training Epoch: 2/2, step 6246/7134 completed (loss: 0.020579220727086067, acc: 0.990777313709259)
[2024-12-17 05:38:12,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:12,708][root][INFO] - Training Epoch: 2/2, step 6247/7134 completed (loss: 0.027081256732344627, acc: 0.9891566038131714)
[2024-12-17 05:38:12,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:13,151][root][INFO] - Training Epoch: 2/2, step 6248/7134 completed (loss: 0.045441027730703354, acc: 0.985981285572052)
[2024-12-17 05:38:13,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:13,585][root][INFO] - Training Epoch: 2/2, step 6249/7134 completed (loss: 0.010482405312359333, acc: 0.9952830076217651)
[2024-12-17 05:38:13,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:14,009][root][INFO] - Training Epoch: 2/2, step 6250/7134 completed (loss: 0.0031548605766147375, acc: 1.0)
[2024-12-17 05:38:14,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:14,439][root][INFO] - Training Epoch: 2/2, step 6251/7134 completed (loss: 0.019585901871323586, acc: 0.995398759841919)
[2024-12-17 05:38:14,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:14,869][root][INFO] - Training Epoch: 2/2, step 6252/7134 completed (loss: 0.009735222905874252, acc: 0.9967637658119202)
[2024-12-17 05:38:15,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:15,310][root][INFO] - Training Epoch: 2/2, step 6253/7134 completed (loss: 0.02676319144666195, acc: 0.9948275685310364)
[2024-12-17 05:38:15,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:15,730][root][INFO] - Training Epoch: 2/2, step 6254/7134 completed (loss: 0.02952634170651436, acc: 0.9930796027183533)
[2024-12-17 05:38:15,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:16,172][root][INFO] - Training Epoch: 2/2, step 6255/7134 completed (loss: 0.01815805211663246, acc: 0.9918699264526367)
[2024-12-17 05:38:16,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:16,589][root][INFO] - Training Epoch: 2/2, step 6256/7134 completed (loss: 0.013727480545639992, acc: 0.9929078221321106)
[2024-12-17 05:38:16,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:17,028][root][INFO] - Training Epoch: 2/2, step 6257/7134 completed (loss: 0.01420628558844328, acc: 0.9942445755004883)
[2024-12-17 05:38:17,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:17,433][root][INFO] - Training Epoch: 2/2, step 6258/7134 completed (loss: 0.013449737802147865, acc: 0.9968000054359436)
[2024-12-17 05:38:17,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:17,856][root][INFO] - Training Epoch: 2/2, step 6259/7134 completed (loss: 0.01584661938250065, acc: 0.9924924969673157)
[2024-12-17 05:38:17,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:18,254][root][INFO] - Training Epoch: 2/2, step 6260/7134 completed (loss: 0.01598919741809368, acc: 0.9932885766029358)
[2024-12-17 05:38:18,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:18,708][root][INFO] - Training Epoch: 2/2, step 6261/7134 completed (loss: 0.019712179899215698, acc: 0.9969512224197388)
[2024-12-17 05:38:18,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:19,122][root][INFO] - Training Epoch: 2/2, step 6262/7134 completed (loss: 0.009022303856909275, acc: 0.9942611455917358)
[2024-12-17 05:38:19,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:19,524][root][INFO] - Training Epoch: 2/2, step 6263/7134 completed (loss: 0.006418695207685232, acc: 0.9985358715057373)
[2024-12-17 05:38:19,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:19,950][root][INFO] - Training Epoch: 2/2, step 6264/7134 completed (loss: 0.010814350098371506, acc: 0.9950739145278931)
[2024-12-17 05:38:20,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:20,381][root][INFO] - Training Epoch: 2/2, step 6265/7134 completed (loss: 0.012285876087844372, acc: 0.9970414042472839)
[2024-12-17 05:38:20,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:20,778][root][INFO] - Training Epoch: 2/2, step 6266/7134 completed (loss: 0.00843768659979105, acc: 0.9947552680969238)
[2024-12-17 05:38:20,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:21,196][root][INFO] - Training Epoch: 2/2, step 6267/7134 completed (loss: 0.01790362223982811, acc: 0.9967426657676697)
[2024-12-17 05:38:21,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:21,625][root][INFO] - Training Epoch: 2/2, step 6268/7134 completed (loss: 0.012542098760604858, acc: 0.9985119104385376)
[2024-12-17 05:38:21,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:22,039][root][INFO] - Training Epoch: 2/2, step 6269/7134 completed (loss: 0.01634826511144638, acc: 0.9957355856895447)
[2024-12-17 05:38:22,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:22,455][root][INFO] - Training Epoch: 2/2, step 6270/7134 completed (loss: 0.007306688465178013, acc: 0.9984662532806396)
[2024-12-17 05:38:22,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:22,881][root][INFO] - Training Epoch: 2/2, step 6271/7134 completed (loss: 0.020756442099809647, acc: 0.9973261952400208)
[2024-12-17 05:38:23,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:23,343][root][INFO] - Training Epoch: 2/2, step 6272/7134 completed (loss: 0.0026699623558670282, acc: 1.0)
[2024-12-17 05:38:23,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:23,787][root][INFO] - Training Epoch: 2/2, step 6273/7134 completed (loss: 0.007704209070652723, acc: 0.99863201379776)
[2024-12-17 05:38:23,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:24,215][root][INFO] - Training Epoch: 2/2, step 6274/7134 completed (loss: 0.02523522637784481, acc: 0.995720386505127)
[2024-12-17 05:38:24,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:24,632][root][INFO] - Training Epoch: 2/2, step 6275/7134 completed (loss: 0.022750714793801308, acc: 0.9939117431640625)
[2024-12-17 05:38:24,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:25,015][root][INFO] - Training Epoch: 2/2, step 6276/7134 completed (loss: 0.03352438285946846, acc: 0.9894921183586121)
[2024-12-17 05:38:25,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:25,399][root][INFO] - Training Epoch: 2/2, step 6277/7134 completed (loss: 0.05680549517273903, acc: 0.9886877536773682)
[2024-12-17 05:38:25,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:25,803][root][INFO] - Training Epoch: 2/2, step 6278/7134 completed (loss: 0.0026026463601738214, acc: 1.0)
[2024-12-17 05:38:25,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:26,212][root][INFO] - Training Epoch: 2/2, step 6279/7134 completed (loss: 0.015909874811768532, acc: 0.9965753555297852)
[2024-12-17 05:38:26,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:26,615][root][INFO] - Training Epoch: 2/2, step 6280/7134 completed (loss: 0.011373098008334637, acc: 0.9947643876075745)
[2024-12-17 05:38:26,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:27,022][root][INFO] - Training Epoch: 2/2, step 6281/7134 completed (loss: 0.023316331207752228, acc: 0.9965338110923767)
[2024-12-17 05:38:27,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:27,445][root][INFO] - Training Epoch: 2/2, step 6282/7134 completed (loss: 0.015530532225966454, acc: 0.9968553185462952)
[2024-12-17 05:38:27,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:27,879][root][INFO] - Training Epoch: 2/2, step 6283/7134 completed (loss: 0.013452786020934582, acc: 0.9956331849098206)
[2024-12-17 05:38:28,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:28,310][root][INFO] - Training Epoch: 2/2, step 6284/7134 completed (loss: 0.028035983443260193, acc: 0.9846827387809753)
[2024-12-17 05:38:28,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:28,691][root][INFO] - Training Epoch: 2/2, step 6285/7134 completed (loss: 0.019245125353336334, acc: 0.9947506785392761)
[2024-12-17 05:38:28,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:29,086][root][INFO] - Training Epoch: 2/2, step 6286/7134 completed (loss: 0.009601307101547718, acc: 0.9950658082962036)
[2024-12-17 05:38:29,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:29,524][root][INFO] - Training Epoch: 2/2, step 6287/7134 completed (loss: 0.029946250841021538, acc: 0.9908088445663452)
[2024-12-17 05:38:29,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:29,932][root][INFO] - Training Epoch: 2/2, step 6288/7134 completed (loss: 0.010247528553009033, acc: 0.9967319965362549)
[2024-12-17 05:38:30,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:30,312][root][INFO] - Training Epoch: 2/2, step 6289/7134 completed (loss: 0.023945774883031845, acc: 0.9927927851676941)
[2024-12-17 05:38:30,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:30,738][root][INFO] - Training Epoch: 2/2, step 6290/7134 completed (loss: 0.018754635006189346, acc: 0.9936000108718872)
[2024-12-17 05:38:30,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:31,146][root][INFO] - Training Epoch: 2/2, step 6291/7134 completed (loss: 0.004798796493560076, acc: 0.9981818199157715)
[2024-12-17 05:38:31,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:31,546][root][INFO] - Training Epoch: 2/2, step 6292/7134 completed (loss: 0.031233521178364754, acc: 0.9886105060577393)
[2024-12-17 05:38:31,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:31,972][root][INFO] - Training Epoch: 2/2, step 6293/7134 completed (loss: 0.047584958374500275, acc: 0.988054633140564)
[2024-12-17 05:38:32,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:32,400][root][INFO] - Training Epoch: 2/2, step 6294/7134 completed (loss: 0.01902664266526699, acc: 0.9967585206031799)
[2024-12-17 05:38:32,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:32,805][root][INFO] - Training Epoch: 2/2, step 6295/7134 completed (loss: 0.01541953906416893, acc: 0.994575023651123)
[2024-12-17 05:38:32,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:33,237][root][INFO] - Training Epoch: 2/2, step 6296/7134 completed (loss: 0.051607515662908554, acc: 0.9842519760131836)
[2024-12-17 05:38:33,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:33,654][root][INFO] - Training Epoch: 2/2, step 6297/7134 completed (loss: 0.02346489578485489, acc: 0.9918032884597778)
[2024-12-17 05:38:33,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:34,070][root][INFO] - Training Epoch: 2/2, step 6298/7134 completed (loss: 0.03503722697496414, acc: 0.9879724979400635)
[2024-12-17 05:38:34,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:34,493][root][INFO] - Training Epoch: 2/2, step 6299/7134 completed (loss: 0.05983756110072136, acc: 0.9808306694030762)
[2024-12-17 05:38:34,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:34,914][root][INFO] - Training Epoch: 2/2, step 6300/7134 completed (loss: 0.04085158184170723, acc: 0.9899497628211975)
[2024-12-17 05:38:35,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:35,376][root][INFO] - Training Epoch: 2/2, step 6301/7134 completed (loss: 0.00811831932514906, acc: 0.9977011680603027)
[2024-12-17 05:38:35,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:35,808][root][INFO] - Training Epoch: 2/2, step 6302/7134 completed (loss: 0.007905750535428524, acc: 0.9972375631332397)
[2024-12-17 05:38:35,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:36,280][root][INFO] - Training Epoch: 2/2, step 6303/7134 completed (loss: 0.02598295547068119, acc: 0.9936102032661438)
[2024-12-17 05:38:36,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:36,718][root][INFO] - Training Epoch: 2/2, step 6304/7134 completed (loss: 0.012091727927327156, acc: 0.995945930480957)
[2024-12-17 05:38:36,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:37,146][root][INFO] - Training Epoch: 2/2, step 6305/7134 completed (loss: 0.008980151265859604, acc: 1.0)
[2024-12-17 05:38:37,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:37,589][root][INFO] - Training Epoch: 2/2, step 6306/7134 completed (loss: 0.031180866062641144, acc: 0.9903961420059204)
[2024-12-17 05:38:37,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:38,024][root][INFO] - Training Epoch: 2/2, step 6307/7134 completed (loss: 0.06456627696752548, acc: 0.9911816716194153)
[2024-12-17 05:38:38,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:38,459][root][INFO] - Training Epoch: 2/2, step 6308/7134 completed (loss: 0.018333736807107925, acc: 0.996314525604248)
[2024-12-17 05:38:38,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:38,877][root][INFO] - Training Epoch: 2/2, step 6309/7134 completed (loss: 0.015740089118480682, acc: 0.9919999837875366)
[2024-12-17 05:38:39,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:39,303][root][INFO] - Training Epoch: 2/2, step 6310/7134 completed (loss: 0.03212582319974899, acc: 0.9912087917327881)
[2024-12-17 05:38:39,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:39,740][root][INFO] - Training Epoch: 2/2, step 6311/7134 completed (loss: 0.019754238426685333, acc: 0.9938499331474304)
[2024-12-17 05:38:39,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:40,150][root][INFO] - Training Epoch: 2/2, step 6312/7134 completed (loss: 0.01625634916126728, acc: 0.9937106966972351)
[2024-12-17 05:38:40,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:40,587][root][INFO] - Training Epoch: 2/2, step 6313/7134 completed (loss: 0.009119371883571148, acc: 0.9950920343399048)
[2024-12-17 05:38:40,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:41,040][root][INFO] - Training Epoch: 2/2, step 6314/7134 completed (loss: 0.011134188622236252, acc: 0.9987389445304871)
[2024-12-17 05:38:41,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:41,469][root][INFO] - Training Epoch: 2/2, step 6315/7134 completed (loss: 0.039936136454343796, acc: 0.9885246157646179)
[2024-12-17 05:38:41,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:41,906][root][INFO] - Training Epoch: 2/2, step 6316/7134 completed (loss: 0.017245611175894737, acc: 0.9951377511024475)
[2024-12-17 05:38:42,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:42,335][root][INFO] - Training Epoch: 2/2, step 6317/7134 completed (loss: 0.00844217836856842, acc: 1.0)
[2024-12-17 05:38:42,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:42,750][root][INFO] - Training Epoch: 2/2, step 6318/7134 completed (loss: 0.006161081604659557, acc: 0.996820330619812)
[2024-12-17 05:38:42,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:43,221][root][INFO] - Training Epoch: 2/2, step 6319/7134 completed (loss: 0.013175229541957378, acc: 0.9958847761154175)
[2024-12-17 05:38:43,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:43,710][root][INFO] - Training Epoch: 2/2, step 6320/7134 completed (loss: 0.014051737263798714, acc: 0.9936808943748474)
[2024-12-17 05:38:43,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:44,156][root][INFO] - Training Epoch: 2/2, step 6321/7134 completed (loss: 0.007608440704643726, acc: 0.9977678656578064)
[2024-12-17 05:38:44,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:44,604][root][INFO] - Training Epoch: 2/2, step 6322/7134 completed (loss: 0.018668264150619507, acc: 0.9941860437393188)
[2024-12-17 05:38:44,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:45,053][root][INFO] - Training Epoch: 2/2, step 6323/7134 completed (loss: 0.0158571545034647, acc: 0.9939939975738525)
[2024-12-17 05:38:45,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:45,483][root][INFO] - Training Epoch: 2/2, step 6324/7134 completed (loss: 0.016751885414123535, acc: 0.9973368644714355)
[2024-12-17 05:38:45,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:45,876][root][INFO] - Training Epoch: 2/2, step 6325/7134 completed (loss: 0.026391873136162758, acc: 0.994339644908905)
[2024-12-17 05:38:45,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:46,292][root][INFO] - Training Epoch: 2/2, step 6326/7134 completed (loss: 0.040575187653303146, acc: 0.9887640476226807)
[2024-12-17 05:38:46,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:46,697][root][INFO] - Training Epoch: 2/2, step 6327/7134 completed (loss: 0.007443954702466726, acc: 0.9973614811897278)
[2024-12-17 05:38:46,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:47,119][root][INFO] - Training Epoch: 2/2, step 6328/7134 completed (loss: 0.02141851931810379, acc: 0.9936203956604004)
[2024-12-17 05:38:47,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:47,533][root][INFO] - Training Epoch: 2/2, step 6329/7134 completed (loss: 0.028635213151574135, acc: 0.9909090995788574)
[2024-12-17 05:38:47,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:47,954][root][INFO] - Training Epoch: 2/2, step 6330/7134 completed (loss: 0.01476187165826559, acc: 0.9925558567047119)
[2024-12-17 05:38:48,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:48,374][root][INFO] - Training Epoch: 2/2, step 6331/7134 completed (loss: 0.008977092802524567, acc: 0.9964664578437805)
[2024-12-17 05:38:48,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:48,806][root][INFO] - Training Epoch: 2/2, step 6332/7134 completed (loss: 0.07425575703382492, acc: 0.9814126491546631)
[2024-12-17 05:38:48,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:49,235][root][INFO] - Training Epoch: 2/2, step 6333/7134 completed (loss: 0.042317070066928864, acc: 0.9857142567634583)
[2024-12-17 05:38:49,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:49,650][root][INFO] - Training Epoch: 2/2, step 6334/7134 completed (loss: 0.019586961716413498, acc: 0.9924242496490479)
[2024-12-17 05:38:49,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:50,081][root][INFO] - Training Epoch: 2/2, step 6335/7134 completed (loss: 0.019589940086007118, acc: 0.9916107654571533)
[2024-12-17 05:38:50,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:50,500][root][INFO] - Training Epoch: 2/2, step 6336/7134 completed (loss: 0.02527536451816559, acc: 0.9908257126808167)
[2024-12-17 05:38:50,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:50,938][root][INFO] - Training Epoch: 2/2, step 6337/7134 completed (loss: 0.006291609723120928, acc: 0.9981752038002014)
[2024-12-17 05:38:51,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:51,370][root][INFO] - Training Epoch: 2/2, step 6338/7134 completed (loss: 0.031440988183021545, acc: 0.9889415502548218)
[2024-12-17 05:38:51,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:51,790][root][INFO] - Training Epoch: 2/2, step 6339/7134 completed (loss: 0.027529574930667877, acc: 0.9896193742752075)
[2024-12-17 05:38:51,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:52,215][root][INFO] - Training Epoch: 2/2, step 6340/7134 completed (loss: 0.009100138209760189, acc: 0.9970674514770508)
[2024-12-17 05:38:52,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:52,628][root][INFO] - Training Epoch: 2/2, step 6341/7134 completed (loss: 0.00877558533102274, acc: 0.9981024861335754)
[2024-12-17 05:38:52,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:53,078][root][INFO] - Training Epoch: 2/2, step 6342/7134 completed (loss: 0.01395849883556366, acc: 0.9946164488792419)
[2024-12-17 05:38:53,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:53,516][root][INFO] - Training Epoch: 2/2, step 6343/7134 completed (loss: 0.02119438163936138, acc: 0.9931153059005737)
[2024-12-17 05:38:53,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:53,972][root][INFO] - Training Epoch: 2/2, step 6344/7134 completed (loss: 0.014849512837827206, acc: 0.99589604139328)
[2024-12-17 05:38:54,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:54,404][root][INFO] - Training Epoch: 2/2, step 6345/7134 completed (loss: 0.018549218773841858, acc: 0.9931694269180298)
[2024-12-17 05:38:54,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:54,821][root][INFO] - Training Epoch: 2/2, step 6346/7134 completed (loss: 0.06267384439706802, acc: 0.9829721450805664)
[2024-12-17 05:38:54,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:55,184][root][INFO] - Training Epoch: 2/2, step 6347/7134 completed (loss: 0.0283084474503994, acc: 0.9891774654388428)
[2024-12-17 05:38:55,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:55,602][root][INFO] - Training Epoch: 2/2, step 6348/7134 completed (loss: 0.031028112396597862, acc: 0.9947916865348816)
[2024-12-17 05:38:55,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:56,012][root][INFO] - Training Epoch: 2/2, step 6349/7134 completed (loss: 0.015875643119215965, acc: 0.9963570237159729)
[2024-12-17 05:38:56,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:56,437][root][INFO] - Training Epoch: 2/2, step 6350/7134 completed (loss: 0.029457034543156624, acc: 0.9918367266654968)
[2024-12-17 05:38:56,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:56,877][root][INFO] - Training Epoch: 2/2, step 6351/7134 completed (loss: 0.03127996623516083, acc: 0.9865671396255493)
[2024-12-17 05:38:56,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:57,332][root][INFO] - Training Epoch: 2/2, step 6352/7134 completed (loss: 0.07149405777454376, acc: 0.9777117371559143)
[2024-12-17 05:38:57,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:57,798][root][INFO] - Training Epoch: 2/2, step 6353/7134 completed (loss: 0.024359095841646194, acc: 0.9882869720458984)
[2024-12-17 05:38:57,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:58,224][root][INFO] - Training Epoch: 2/2, step 6354/7134 completed (loss: 0.007768992800265551, acc: 0.9972299337387085)
[2024-12-17 05:38:58,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:58,633][root][INFO] - Training Epoch: 2/2, step 6355/7134 completed (loss: 0.006456604693084955, acc: 0.9983818531036377)
[2024-12-17 05:38:58,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:59,041][root][INFO] - Training Epoch: 2/2, step 6356/7134 completed (loss: 0.0176880843937397, acc: 0.9910314083099365)
[2024-12-17 05:38:59,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:59,468][root][INFO] - Training Epoch: 2/2, step 6357/7134 completed (loss: 0.008872837759554386, acc: 0.9944444298744202)
[2024-12-17 05:38:59,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:38:59,924][root][INFO] - Training Epoch: 2/2, step 6358/7134 completed (loss: 0.01766897924244404, acc: 0.9957746267318726)
[2024-12-17 05:39:00,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:00,331][root][INFO] - Training Epoch: 2/2, step 6359/7134 completed (loss: 0.07373282313346863, acc: 0.9859943985939026)
[2024-12-17 05:39:00,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:00,731][root][INFO] - Training Epoch: 2/2, step 6360/7134 completed (loss: 0.020587891340255737, acc: 0.9920381903648376)
[2024-12-17 05:39:00,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:01,139][root][INFO] - Training Epoch: 2/2, step 6361/7134 completed (loss: 0.03228185325860977, acc: 0.9908758997917175)
[2024-12-17 05:39:01,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:01,605][root][INFO] - Training Epoch: 2/2, step 6362/7134 completed (loss: 0.031698357313871384, acc: 0.9908536672592163)
[2024-12-17 05:39:01,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:02,066][root][INFO] - Training Epoch: 2/2, step 6363/7134 completed (loss: 0.016512718051671982, acc: 0.9956011772155762)
[2024-12-17 05:39:02,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:02,486][root][INFO] - Training Epoch: 2/2, step 6364/7134 completed (loss: 0.015107744373381138, acc: 0.9971387982368469)
[2024-12-17 05:39:02,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:02,903][root][INFO] - Training Epoch: 2/2, step 6365/7134 completed (loss: 0.012097710743546486, acc: 0.9959349632263184)
[2024-12-17 05:39:03,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:03,339][root][INFO] - Training Epoch: 2/2, step 6366/7134 completed (loss: 0.05570078268647194, acc: 0.9894319772720337)
[2024-12-17 05:39:03,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:03,741][root][INFO] - Training Epoch: 2/2, step 6367/7134 completed (loss: 0.04835045337677002, acc: 0.992438554763794)
[2024-12-17 05:39:03,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:04,162][root][INFO] - Training Epoch: 2/2, step 6368/7134 completed (loss: 0.04422391951084137, acc: 0.991525411605835)
[2024-12-17 05:39:04,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:04,606][root][INFO] - Training Epoch: 2/2, step 6369/7134 completed (loss: 0.051868267357349396, acc: 0.9829171895980835)
[2024-12-17 05:39:04,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:05,071][root][INFO] - Training Epoch: 2/2, step 6370/7134 completed (loss: 0.10514791309833527, acc: 0.9749340415000916)
[2024-12-17 05:39:05,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:05,501][root][INFO] - Training Epoch: 2/2, step 6371/7134 completed (loss: 0.037431154400110245, acc: 0.9875346422195435)
[2024-12-17 05:39:05,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:05,898][root][INFO] - Training Epoch: 2/2, step 6372/7134 completed (loss: 0.10192034393548965, acc: 0.9654510617256165)
[2024-12-17 05:39:06,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:06,292][root][INFO] - Training Epoch: 2/2, step 6373/7134 completed (loss: 0.04631323739886284, acc: 0.9817850589752197)
[2024-12-17 05:39:06,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:06,731][root][INFO] - Training Epoch: 2/2, step 6374/7134 completed (loss: 0.026046855375170708, acc: 0.9958506226539612)
[2024-12-17 05:39:06,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:07,183][root][INFO] - Training Epoch: 2/2, step 6375/7134 completed (loss: 0.06383582204580307, acc: 0.9833119511604309)
[2024-12-17 05:39:07,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:07,609][root][INFO] - Training Epoch: 2/2, step 6376/7134 completed (loss: 0.018447795882821083, acc: 0.9926199316978455)
[2024-12-17 05:39:07,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:08,036][root][INFO] - Training Epoch: 2/2, step 6377/7134 completed (loss: 0.03116990625858307, acc: 0.9908424615859985)
[2024-12-17 05:39:08,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:08,499][root][INFO] - Training Epoch: 2/2, step 6378/7134 completed (loss: 0.030613111332058907, acc: 0.9903537034988403)
[2024-12-17 05:39:08,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:08,908][root][INFO] - Training Epoch: 2/2, step 6379/7134 completed (loss: 0.024684235453605652, acc: 0.9911167621612549)
[2024-12-17 05:39:09,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:09,368][root][INFO] - Training Epoch: 2/2, step 6380/7134 completed (loss: 0.04514100030064583, acc: 0.9910179376602173)
[2024-12-17 05:39:09,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:09,795][root][INFO] - Training Epoch: 2/2, step 6381/7134 completed (loss: 0.02077091857790947, acc: 0.9923664331436157)
[2024-12-17 05:39:09,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:10,245][root][INFO] - Training Epoch: 2/2, step 6382/7134 completed (loss: 0.009826763533055782, acc: 0.9973718523979187)
[2024-12-17 05:39:10,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:10,692][root][INFO] - Training Epoch: 2/2, step 6383/7134 completed (loss: 0.0508933886885643, acc: 0.9905020594596863)
[2024-12-17 05:39:10,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:11,140][root][INFO] - Training Epoch: 2/2, step 6384/7134 completed (loss: 0.03916159272193909, acc: 0.988041877746582)
[2024-12-17 05:39:11,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:11,596][root][INFO] - Training Epoch: 2/2, step 6385/7134 completed (loss: 0.07949315756559372, acc: 0.9844311475753784)
[2024-12-17 05:39:11,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:12,101][root][INFO] - Training Epoch: 2/2, step 6386/7134 completed (loss: 0.020706670358777046, acc: 0.9963369965553284)
[2024-12-17 05:39:12,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:12,561][root][INFO] - Training Epoch: 2/2, step 6387/7134 completed (loss: 0.03775316849350929, acc: 0.9887096881866455)
[2024-12-17 05:39:12,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:13,003][root][INFO] - Training Epoch: 2/2, step 6388/7134 completed (loss: 0.04080914705991745, acc: 0.9835329055786133)
[2024-12-17 05:39:13,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:13,470][root][INFO] - Training Epoch: 2/2, step 6389/7134 completed (loss: 0.06108798831701279, acc: 0.9890109896659851)
[2024-12-17 05:39:13,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:13,961][root][INFO] - Training Epoch: 2/2, step 6390/7134 completed (loss: 0.05974708870053291, acc: 0.9868420958518982)
[2024-12-17 05:39:14,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:14,393][root][INFO] - Training Epoch: 2/2, step 6391/7134 completed (loss: 0.04219659045338631, acc: 0.98975670337677)
[2024-12-17 05:39:14,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:14,847][root][INFO] - Training Epoch: 2/2, step 6392/7134 completed (loss: 0.05433451384305954, acc: 0.9846153855323792)
[2024-12-17 05:39:14,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:15,313][root][INFO] - Training Epoch: 2/2, step 6393/7134 completed (loss: 0.03334078937768936, acc: 0.9920364022254944)
[2024-12-17 05:39:15,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:15,766][root][INFO] - Training Epoch: 2/2, step 6394/7134 completed (loss: 0.05072668194770813, acc: 0.9833101630210876)
[2024-12-17 05:39:15,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:16,233][root][INFO] - Training Epoch: 2/2, step 6395/7134 completed (loss: 0.03394760563969612, acc: 0.9926199316978455)
[2024-12-17 05:39:16,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:16,674][root][INFO] - Training Epoch: 2/2, step 6396/7134 completed (loss: 0.04054348170757294, acc: 0.9908257126808167)
[2024-12-17 05:39:16,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:17,140][root][INFO] - Training Epoch: 2/2, step 6397/7134 completed (loss: 0.02138695679605007, acc: 0.9937965273857117)
[2024-12-17 05:39:17,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:17,588][root][INFO] - Training Epoch: 2/2, step 6398/7134 completed (loss: 0.022763393819332123, acc: 0.9915611743927002)
[2024-12-17 05:39:17,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:18,041][root][INFO] - Training Epoch: 2/2, step 6399/7134 completed (loss: 0.04173535108566284, acc: 0.9887217879295349)
[2024-12-17 05:39:18,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:18,474][root][INFO] - Training Epoch: 2/2, step 6400/7134 completed (loss: 0.026533126831054688, acc: 0.995726466178894)
[2024-12-17 05:39:18,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:18,951][root][INFO] - Training Epoch: 2/2, step 6401/7134 completed (loss: 0.03943053260445595, acc: 0.9913138151168823)
[2024-12-17 05:39:19,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:19,393][root][INFO] - Training Epoch: 2/2, step 6402/7134 completed (loss: 0.042911775410175323, acc: 0.9920544624328613)
[2024-12-17 05:39:19,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:19,792][root][INFO] - Training Epoch: 2/2, step 6403/7134 completed (loss: 0.03086726740002632, acc: 0.9923469424247742)
[2024-12-17 05:39:19,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:20,223][root][INFO] - Training Epoch: 2/2, step 6404/7134 completed (loss: 0.01428475882858038, acc: 0.9958275556564331)
[2024-12-17 05:39:20,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:20,718][root][INFO] - Training Epoch: 2/2, step 6405/7134 completed (loss: 0.012645987793803215, acc: 0.9978494644165039)
[2024-12-17 05:39:20,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:21,181][root][INFO] - Training Epoch: 2/2, step 6406/7134 completed (loss: 0.030992576852440834, acc: 0.9908779859542847)
[2024-12-17 05:39:21,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:21,640][root][INFO] - Training Epoch: 2/2, step 6407/7134 completed (loss: 0.013467720709741116, acc: 0.9973718523979187)
[2024-12-17 05:39:21,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:22,053][root][INFO] - Training Epoch: 2/2, step 6408/7134 completed (loss: 0.05325327441096306, acc: 0.9896602630615234)
[2024-12-17 05:39:22,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:22,487][root][INFO] - Training Epoch: 2/2, step 6409/7134 completed (loss: 0.03379351645708084, acc: 0.996052622795105)
[2024-12-17 05:39:22,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:22,930][root][INFO] - Training Epoch: 2/2, step 6410/7134 completed (loss: 0.018471460789442062, acc: 0.9944853186607361)
[2024-12-17 05:39:23,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:23,337][root][INFO] - Training Epoch: 2/2, step 6411/7134 completed (loss: 0.03780175745487213, acc: 0.9899497628211975)
[2024-12-17 05:39:23,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:23,748][root][INFO] - Training Epoch: 2/2, step 6412/7134 completed (loss: 0.009616946801543236, acc: 0.9986666440963745)
[2024-12-17 05:39:23,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:24,210][root][INFO] - Training Epoch: 2/2, step 6413/7134 completed (loss: 0.04183196276426315, acc: 0.9897260069847107)
[2024-12-17 05:39:24,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:24,610][root][INFO] - Training Epoch: 2/2, step 6414/7134 completed (loss: 0.024129971861839294, acc: 0.9894259572029114)
[2024-12-17 05:39:24,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:25,049][root][INFO] - Training Epoch: 2/2, step 6415/7134 completed (loss: 0.02136172354221344, acc: 0.9922978281974792)
[2024-12-17 05:39:25,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:25,464][root][INFO] - Training Epoch: 2/2, step 6416/7134 completed (loss: 0.03647252172231674, acc: 0.9886147975921631)
[2024-12-17 05:39:25,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:25,897][root][INFO] - Training Epoch: 2/2, step 6417/7134 completed (loss: 0.06837322562932968, acc: 0.9859402179718018)
[2024-12-17 05:39:26,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:26,347][root][INFO] - Training Epoch: 2/2, step 6418/7134 completed (loss: 0.07839932292699814, acc: 0.9803370833396912)
[2024-12-17 05:39:26,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:26,771][root][INFO] - Training Epoch: 2/2, step 6419/7134 completed (loss: 0.040161386132240295, acc: 0.990212082862854)
[2024-12-17 05:39:26,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:27,209][root][INFO] - Training Epoch: 2/2, step 6420/7134 completed (loss: 0.034119315445423126, acc: 0.9899135231971741)
[2024-12-17 05:39:27,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:27,625][root][INFO] - Training Epoch: 2/2, step 6421/7134 completed (loss: 0.03959755599498749, acc: 0.9910846948623657)
[2024-12-17 05:39:27,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:28,062][root][INFO] - Training Epoch: 2/2, step 6422/7134 completed (loss: 0.04361524432897568, acc: 0.9876881241798401)
[2024-12-17 05:39:28,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:28,495][root][INFO] - Training Epoch: 2/2, step 6423/7134 completed (loss: 0.05370610952377319, acc: 0.9912023544311523)
[2024-12-17 05:39:28,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:28,953][root][INFO] - Training Epoch: 2/2, step 6424/7134 completed (loss: 0.03834908455610275, acc: 0.9899117350578308)
[2024-12-17 05:39:29,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:29,418][root][INFO] - Training Epoch: 2/2, step 6425/7134 completed (loss: 0.029394306242465973, acc: 0.9895697236061096)
[2024-12-17 05:39:29,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:29,881][root][INFO] - Training Epoch: 2/2, step 6426/7134 completed (loss: 0.035948555916547775, acc: 0.9868074059486389)
[2024-12-17 05:39:30,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:30,316][root][INFO] - Training Epoch: 2/2, step 6427/7134 completed (loss: 0.037193942815065384, acc: 0.9914772510528564)
[2024-12-17 05:39:30,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:30,764][root][INFO] - Training Epoch: 2/2, step 6428/7134 completed (loss: 0.016356078907847404, acc: 0.9958100318908691)
[2024-12-17 05:39:30,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:31,177][root][INFO] - Training Epoch: 2/2, step 6429/7134 completed (loss: 0.013940449804067612, acc: 0.9954545497894287)
[2024-12-17 05:39:31,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:31,642][root][INFO] - Training Epoch: 2/2, step 6430/7134 completed (loss: 0.04980585724115372, acc: 0.9841726422309875)
[2024-12-17 05:39:31,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:32,055][root][INFO] - Training Epoch: 2/2, step 6431/7134 completed (loss: 0.04839412122964859, acc: 0.9894737005233765)
[2024-12-17 05:39:32,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:32,464][root][INFO] - Training Epoch: 2/2, step 6432/7134 completed (loss: 0.1597055196762085, acc: 0.9629629850387573)
[2024-12-17 05:39:32,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:32,900][root][INFO] - Training Epoch: 2/2, step 6433/7134 completed (loss: 0.036044735461473465, acc: 0.9904371500015259)
[2024-12-17 05:39:33,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:33,309][root][INFO] - Training Epoch: 2/2, step 6434/7134 completed (loss: 0.007383907213807106, acc: 1.0)
[2024-12-17 05:39:33,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:33,727][root][INFO] - Training Epoch: 2/2, step 6435/7134 completed (loss: 0.034339193254709244, acc: 0.9913344979286194)
[2024-12-17 05:39:33,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:34,210][root][INFO] - Training Epoch: 2/2, step 6436/7134 completed (loss: 0.011753859929740429, acc: 0.9969087839126587)
[2024-12-17 05:39:34,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:34,650][root][INFO] - Training Epoch: 2/2, step 6437/7134 completed (loss: 0.03546629101037979, acc: 0.9950000047683716)
[2024-12-17 05:39:34,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:35,118][root][INFO] - Training Epoch: 2/2, step 6438/7134 completed (loss: 0.037882447242736816, acc: 0.990111231803894)
[2024-12-17 05:39:35,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:35,548][root][INFO] - Training Epoch: 2/2, step 6439/7134 completed (loss: 0.0298677459359169, acc: 0.9905511736869812)
[2024-12-17 05:39:35,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:36,022][root][INFO] - Training Epoch: 2/2, step 6440/7134 completed (loss: 0.0191314909607172, acc: 0.9952210187911987)
[2024-12-17 05:39:36,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:36,459][root][INFO] - Training Epoch: 2/2, step 6441/7134 completed (loss: 0.019076339900493622, acc: 0.9970458149909973)
[2024-12-17 05:39:36,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:36,946][root][INFO] - Training Epoch: 2/2, step 6442/7134 completed (loss: 0.02887777052819729, acc: 0.9954596757888794)
[2024-12-17 05:39:37,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:37,404][root][INFO] - Training Epoch: 2/2, step 6443/7134 completed (loss: 0.024617142975330353, acc: 0.9950494766235352)
[2024-12-17 05:39:37,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:37,867][root][INFO] - Training Epoch: 2/2, step 6444/7134 completed (loss: 0.02548021264374256, acc: 0.994413435459137)
[2024-12-17 05:39:38,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:38,318][root][INFO] - Training Epoch: 2/2, step 6445/7134 completed (loss: 0.05008064955472946, acc: 0.9889025688171387)
[2024-12-17 05:39:38,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:38,773][root][INFO] - Training Epoch: 2/2, step 6446/7134 completed (loss: 0.030116140842437744, acc: 0.9952324032783508)
[2024-12-17 05:39:38,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:39,249][root][INFO] - Training Epoch: 2/2, step 6447/7134 completed (loss: 0.034610312432050705, acc: 0.9919447898864746)
[2024-12-17 05:39:39,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:39,682][root][INFO] - Training Epoch: 2/2, step 6448/7134 completed (loss: 0.08205632120370865, acc: 0.9828660488128662)
[2024-12-17 05:39:39,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:40,135][root][INFO] - Training Epoch: 2/2, step 6449/7134 completed (loss: 0.016042232513427734, acc: 0.9971014261245728)
[2024-12-17 05:39:40,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:40,594][root][INFO] - Training Epoch: 2/2, step 6450/7134 completed (loss: 0.017850693315267563, acc: 0.9970238208770752)
[2024-12-17 05:39:40,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:41,140][root][INFO] - Training Epoch: 2/2, step 6451/7134 completed (loss: 0.04746132716536522, acc: 0.989226222038269)
[2024-12-17 05:39:41,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:41,574][root][INFO] - Training Epoch: 2/2, step 6452/7134 completed (loss: 0.014687938615679741, acc: 0.9955406785011292)
[2024-12-17 05:39:41,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:42,010][root][INFO] - Training Epoch: 2/2, step 6453/7134 completed (loss: 0.010778467170894146, acc: 0.9959677457809448)
[2024-12-17 05:39:42,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:42,494][root][INFO] - Training Epoch: 2/2, step 6454/7134 completed (loss: 0.024000098928809166, acc: 0.9964664578437805)
[2024-12-17 05:39:42,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:42,923][root][INFO] - Training Epoch: 2/2, step 6455/7134 completed (loss: 0.010014261119067669, acc: 0.9983022212982178)
[2024-12-17 05:39:43,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:43,360][root][INFO] - Training Epoch: 2/2, step 6456/7134 completed (loss: 0.01811976730823517, acc: 0.9969325065612793)
[2024-12-17 05:39:43,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:43,802][root][INFO] - Training Epoch: 2/2, step 6457/7134 completed (loss: 0.01381700113415718, acc: 0.9977973699569702)
[2024-12-17 05:39:43,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:44,221][root][INFO] - Training Epoch: 2/2, step 6458/7134 completed (loss: 0.018864847719669342, acc: 0.9899159669876099)
[2024-12-17 05:39:44,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:44,662][root][INFO] - Training Epoch: 2/2, step 6459/7134 completed (loss: 0.003749231342226267, acc: 0.9986225962638855)
[2024-12-17 05:39:44,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:45,134][root][INFO] - Training Epoch: 2/2, step 6460/7134 completed (loss: 0.005724899936467409, acc: 0.9988193511962891)
[2024-12-17 05:39:45,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:45,560][root][INFO] - Training Epoch: 2/2, step 6461/7134 completed (loss: 0.012742847204208374, acc: 0.9960578083992004)
[2024-12-17 05:39:45,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:46,006][root][INFO] - Training Epoch: 2/2, step 6462/7134 completed (loss: 0.01188674010336399, acc: 0.998769998550415)
[2024-12-17 05:39:46,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:46,482][root][INFO] - Training Epoch: 2/2, step 6463/7134 completed (loss: 0.008722526021301746, acc: 0.9965831637382507)
[2024-12-17 05:39:46,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:46,921][root][INFO] - Training Epoch: 2/2, step 6464/7134 completed (loss: 0.01873955875635147, acc: 0.9947984218597412)
[2024-12-17 05:39:47,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:47,341][root][INFO] - Training Epoch: 2/2, step 6465/7134 completed (loss: 0.015052322298288345, acc: 0.9961439371109009)
[2024-12-17 05:39:47,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:47,762][root][INFO] - Training Epoch: 2/2, step 6466/7134 completed (loss: 0.02585085853934288, acc: 0.9947159886360168)
[2024-12-17 05:39:47,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:48,207][root][INFO] - Training Epoch: 2/2, step 6467/7134 completed (loss: 0.024509919807314873, acc: 0.9923664331436157)
[2024-12-17 05:39:48,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:48,649][root][INFO] - Training Epoch: 2/2, step 6468/7134 completed (loss: 0.017591051757335663, acc: 0.9924952983856201)
[2024-12-17 05:39:48,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:49,130][root][INFO] - Training Epoch: 2/2, step 6469/7134 completed (loss: 0.0350780263543129, acc: 0.9890377521514893)
[2024-12-17 05:39:49,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:49,553][root][INFO] - Training Epoch: 2/2, step 6470/7134 completed (loss: 0.036805350333452225, acc: 0.9902200698852539)
[2024-12-17 05:39:49,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:50,002][root][INFO] - Training Epoch: 2/2, step 6471/7134 completed (loss: 0.005871945526450872, acc: 1.0)
[2024-12-17 05:39:50,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:50,483][root][INFO] - Training Epoch: 2/2, step 6472/7134 completed (loss: 0.049764975905418396, acc: 0.9905437231063843)
[2024-12-17 05:39:50,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:50,954][root][INFO] - Training Epoch: 2/2, step 6473/7134 completed (loss: 0.01262335479259491, acc: 0.9973190426826477)
[2024-12-17 05:39:51,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:51,385][root][INFO] - Training Epoch: 2/2, step 6474/7134 completed (loss: 0.016444925218820572, acc: 0.9946164488792419)
[2024-12-17 05:39:51,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:51,814][root][INFO] - Training Epoch: 2/2, step 6475/7134 completed (loss: 0.03780738264322281, acc: 0.9916666746139526)
[2024-12-17 05:39:51,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:52,220][root][INFO] - Training Epoch: 2/2, step 6476/7134 completed (loss: 0.03106486052274704, acc: 0.9950494766235352)
[2024-12-17 05:39:52,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:52,636][root][INFO] - Training Epoch: 2/2, step 6477/7134 completed (loss: 0.010363901033997536, acc: 0.9978813529014587)
[2024-12-17 05:39:52,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:53,059][root][INFO] - Training Epoch: 2/2, step 6478/7134 completed (loss: 0.02070392295718193, acc: 0.9944649338722229)
[2024-12-17 05:39:53,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:53,490][root][INFO] - Training Epoch: 2/2, step 6479/7134 completed (loss: 0.01804344542324543, acc: 0.9932998418807983)
[2024-12-17 05:39:53,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:53,896][root][INFO] - Training Epoch: 2/2, step 6480/7134 completed (loss: 0.036948490887880325, acc: 0.9879724979400635)
[2024-12-17 05:39:54,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:54,316][root][INFO] - Training Epoch: 2/2, step 6481/7134 completed (loss: 0.029542703181505203, acc: 0.9914966225624084)
[2024-12-17 05:39:54,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:54,812][root][INFO] - Training Epoch: 2/2, step 6482/7134 completed (loss: 0.014863572083413601, acc: 0.9950000047683716)
[2024-12-17 05:39:54,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:55,259][root][INFO] - Training Epoch: 2/2, step 6483/7134 completed (loss: 0.04745481163263321, acc: 0.987364649772644)
[2024-12-17 05:39:55,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:55,697][root][INFO] - Training Epoch: 2/2, step 6484/7134 completed (loss: 0.020474011078476906, acc: 0.9897360801696777)
[2024-12-17 05:39:55,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:56,158][root][INFO] - Training Epoch: 2/2, step 6485/7134 completed (loss: 0.012573176063597202, acc: 0.9980236887931824)
[2024-12-17 05:39:56,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:56,567][root][INFO] - Training Epoch: 2/2, step 6486/7134 completed (loss: 0.09280827641487122, acc: 0.9800000190734863)
[2024-12-17 05:39:56,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:56,940][root][INFO] - Training Epoch: 2/2, step 6487/7134 completed (loss: 0.14523743093013763, acc: 0.9635627269744873)
[2024-12-17 05:39:57,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:57,328][root][INFO] - Training Epoch: 2/2, step 6488/7134 completed (loss: 0.0795452743768692, acc: 0.9718309640884399)
[2024-12-17 05:39:57,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:57,739][root][INFO] - Training Epoch: 2/2, step 6489/7134 completed (loss: 0.08267512917518616, acc: 0.986940324306488)
[2024-12-17 05:39:57,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:58,141][root][INFO] - Training Epoch: 2/2, step 6490/7134 completed (loss: 0.07537412643432617, acc: 0.9862778782844543)
[2024-12-17 05:39:58,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:58,578][root][INFO] - Training Epoch: 2/2, step 6491/7134 completed (loss: 0.06692660599946976, acc: 0.9865047335624695)
[2024-12-17 05:39:58,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:59,004][root][INFO] - Training Epoch: 2/2, step 6492/7134 completed (loss: 0.020436575636267662, acc: 0.9909443855285645)
[2024-12-17 05:39:59,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:59,483][root][INFO] - Training Epoch: 2/2, step 6493/7134 completed (loss: 0.0610167533159256, acc: 0.9860050678253174)
[2024-12-17 05:39:59,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:39:59,895][root][INFO] - Training Epoch: 2/2, step 6494/7134 completed (loss: 0.04001450538635254, acc: 0.9889298677444458)
[2024-12-17 05:40:00,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:00,328][root][INFO] - Training Epoch: 2/2, step 6495/7134 completed (loss: 0.04379073530435562, acc: 0.9859747290611267)
[2024-12-17 05:40:00,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:00,779][root][INFO] - Training Epoch: 2/2, step 6496/7134 completed (loss: 0.03978284075856209, acc: 0.992443323135376)
[2024-12-17 05:40:00,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:01,231][root][INFO] - Training Epoch: 2/2, step 6497/7134 completed (loss: 0.05947225168347359, acc: 0.9813374876976013)
[2024-12-17 05:40:01,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:01,663][root][INFO] - Training Epoch: 2/2, step 6498/7134 completed (loss: 0.021641723811626434, acc: 0.992682933807373)
[2024-12-17 05:40:01,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:02,101][root][INFO] - Training Epoch: 2/2, step 6499/7134 completed (loss: 0.03508347272872925, acc: 0.9887920022010803)
[2024-12-17 05:40:02,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:02,566][root][INFO] - Training Epoch: 2/2, step 6500/7134 completed (loss: 0.06195669248700142, acc: 0.9803921580314636)
[2024-12-17 05:40:02,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:03,009][root][INFO] - Training Epoch: 2/2, step 6501/7134 completed (loss: 0.10890380293130875, acc: 0.9744245409965515)
[2024-12-17 05:40:03,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:03,541][root][INFO] - Training Epoch: 2/2, step 6502/7134 completed (loss: 0.02335147187113762, acc: 0.9940617680549622)
[2024-12-17 05:40:03,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:03,955][root][INFO] - Training Epoch: 2/2, step 6503/7134 completed (loss: 0.033146459609270096, acc: 0.9897360801696777)
[2024-12-17 05:40:04,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:04,364][root][INFO] - Training Epoch: 2/2, step 6504/7134 completed (loss: 0.03969578072428703, acc: 0.9873617887496948)
[2024-12-17 05:40:04,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:04,799][root][INFO] - Training Epoch: 2/2, step 6505/7134 completed (loss: 0.06780391931533813, acc: 0.9826086759567261)
[2024-12-17 05:40:04,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:05,272][root][INFO] - Training Epoch: 2/2, step 6506/7134 completed (loss: 0.0661076158285141, acc: 0.9826275706291199)
[2024-12-17 05:40:05,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:05,722][root][INFO] - Training Epoch: 2/2, step 6507/7134 completed (loss: 0.06693976372480392, acc: 0.9788199663162231)
[2024-12-17 05:40:05,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:06,187][root][INFO] - Training Epoch: 2/2, step 6508/7134 completed (loss: 0.06748262047767639, acc: 0.987089216709137)
[2024-12-17 05:40:06,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:06,639][root][INFO] - Training Epoch: 2/2, step 6509/7134 completed (loss: 0.030457470566034317, acc: 0.9922480583190918)
[2024-12-17 05:40:06,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:07,135][root][INFO] - Training Epoch: 2/2, step 6510/7134 completed (loss: 0.03907676413655281, acc: 0.9883720874786377)
[2024-12-17 05:40:07,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:07,573][root][INFO] - Training Epoch: 2/2, step 6511/7134 completed (loss: 0.05132299289107323, acc: 0.9849624037742615)
[2024-12-17 05:40:07,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:07,954][root][INFO] - Training Epoch: 2/2, step 6512/7134 completed (loss: 0.02170899137854576, acc: 0.9923954606056213)
[2024-12-17 05:40:08,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:08,378][root][INFO] - Training Epoch: 2/2, step 6513/7134 completed (loss: 0.033493343740701675, acc: 0.9861111044883728)
[2024-12-17 05:40:08,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:08,783][root][INFO] - Training Epoch: 2/2, step 6514/7134 completed (loss: 0.041120562702417374, acc: 0.9872159361839294)
[2024-12-17 05:40:08,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:09,254][root][INFO] - Training Epoch: 2/2, step 6515/7134 completed (loss: 0.03598883002996445, acc: 0.9873096346855164)
[2024-12-17 05:40:09,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:09,709][root][INFO] - Training Epoch: 2/2, step 6516/7134 completed (loss: 0.07501239329576492, acc: 0.9814323782920837)
[2024-12-17 05:40:09,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:10,148][root][INFO] - Training Epoch: 2/2, step 6517/7134 completed (loss: 0.02124001644551754, acc: 0.9934210777282715)
[2024-12-17 05:40:10,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:10,587][root][INFO] - Training Epoch: 2/2, step 6518/7134 completed (loss: 0.01571338064968586, acc: 0.9958620667457581)
[2024-12-17 05:40:10,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:11,008][root][INFO] - Training Epoch: 2/2, step 6519/7134 completed (loss: 0.03014560416340828, acc: 0.9929078221321106)
[2024-12-17 05:40:11,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:11,417][root][INFO] - Training Epoch: 2/2, step 6520/7134 completed (loss: 0.023552993312478065, acc: 0.9906687140464783)
[2024-12-17 05:40:11,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:11,833][root][INFO] - Training Epoch: 2/2, step 6521/7134 completed (loss: 0.012327831238508224, acc: 0.9934895634651184)
[2024-12-17 05:40:11,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:12,241][root][INFO] - Training Epoch: 2/2, step 6522/7134 completed (loss: 0.04884377494454384, acc: 0.9759863018989563)
[2024-12-17 05:40:12,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:12,673][root][INFO] - Training Epoch: 2/2, step 6523/7134 completed (loss: 0.06075937673449516, acc: 0.9836660623550415)
[2024-12-17 05:40:12,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:13,130][root][INFO] - Training Epoch: 2/2, step 6524/7134 completed (loss: 0.05424826219677925, acc: 0.9858611822128296)
[2024-12-17 05:40:13,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:13,567][root][INFO] - Training Epoch: 2/2, step 6525/7134 completed (loss: 0.029286066070199013, acc: 0.9919678568840027)
[2024-12-17 05:40:13,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:14,015][root][INFO] - Training Epoch: 2/2, step 6526/7134 completed (loss: 0.0351971760392189, acc: 0.9884763360023499)
[2024-12-17 05:40:14,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:14,432][root][INFO] - Training Epoch: 2/2, step 6527/7134 completed (loss: 0.03170941770076752, acc: 0.9940652847290039)
[2024-12-17 05:40:14,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:14,828][root][INFO] - Training Epoch: 2/2, step 6528/7134 completed (loss: 0.04940998554229736, acc: 0.987364649772644)
[2024-12-17 05:40:14,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:15,235][root][INFO] - Training Epoch: 2/2, step 6529/7134 completed (loss: 0.06311306357383728, acc: 0.9830827116966248)
[2024-12-17 05:40:15,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:15,673][root][INFO] - Training Epoch: 2/2, step 6530/7134 completed (loss: 0.024221831932663918, acc: 0.9900142550468445)
[2024-12-17 05:40:15,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:16,107][root][INFO] - Training Epoch: 2/2, step 6531/7134 completed (loss: 0.019624749198555946, acc: 0.9942196607589722)
[2024-12-17 05:40:16,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:16,569][root][INFO] - Training Epoch: 2/2, step 6532/7134 completed (loss: 0.04911696910858154, acc: 0.9862328171730042)
[2024-12-17 05:40:16,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:16,997][root][INFO] - Training Epoch: 2/2, step 6533/7134 completed (loss: 0.013302943669259548, acc: 0.9985074400901794)
[2024-12-17 05:40:17,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:17,414][root][INFO] - Training Epoch: 2/2, step 6534/7134 completed (loss: 0.04630628228187561, acc: 0.9932975769042969)
[2024-12-17 05:40:17,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:17,815][root][INFO] - Training Epoch: 2/2, step 6535/7134 completed (loss: 0.02506696991622448, acc: 0.9859485030174255)
[2024-12-17 05:40:17,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:18,262][root][INFO] - Training Epoch: 2/2, step 6536/7134 completed (loss: 0.029573878273367882, acc: 0.9900793433189392)
[2024-12-17 05:40:18,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:18,659][root][INFO] - Training Epoch: 2/2, step 6537/7134 completed (loss: 0.06844032555818558, acc: 0.971238911151886)
[2024-12-17 05:40:18,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:19,085][root][INFO] - Training Epoch: 2/2, step 6538/7134 completed (loss: 0.06010470911860466, acc: 0.9857904314994812)
[2024-12-17 05:40:19,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:19,461][root][INFO] - Training Epoch: 2/2, step 6539/7134 completed (loss: 0.003437056904658675, acc: 1.0)
[2024-12-17 05:40:19,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:19,885][root][INFO] - Training Epoch: 2/2, step 6540/7134 completed (loss: 0.17503048479557037, acc: 0.9535518884658813)
[2024-12-17 05:40:20,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:20,350][root][INFO] - Training Epoch: 2/2, step 6541/7134 completed (loss: 0.04652010276913643, acc: 0.9803921580314636)
[2024-12-17 05:40:20,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:20,801][root][INFO] - Training Epoch: 2/2, step 6542/7134 completed (loss: 0.045238200575113297, acc: 0.9864406585693359)
[2024-12-17 05:40:20,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:21,246][root][INFO] - Training Epoch: 2/2, step 6543/7134 completed (loss: 0.017489952966570854, acc: 0.9937106966972351)
[2024-12-17 05:40:21,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:21,684][root][INFO] - Training Epoch: 2/2, step 6544/7134 completed (loss: 0.04544130340218544, acc: 0.9900596141815186)
[2024-12-17 05:40:21,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:22,101][root][INFO] - Training Epoch: 2/2, step 6545/7134 completed (loss: 0.023479636758565903, acc: 0.9962825179100037)
[2024-12-17 05:40:22,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:22,492][root][INFO] - Training Epoch: 2/2, step 6546/7134 completed (loss: 0.035504624247550964, acc: 0.9934853315353394)
[2024-12-17 05:40:22,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:22,905][root][INFO] - Training Epoch: 2/2, step 6547/7134 completed (loss: 0.09210282564163208, acc: 0.9795570969581604)
[2024-12-17 05:40:23,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:23,282][root][INFO] - Training Epoch: 2/2, step 6548/7134 completed (loss: 0.00962489191442728, acc: 0.9980158805847168)
[2024-12-17 05:40:23,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:23,701][root][INFO] - Training Epoch: 2/2, step 6549/7134 completed (loss: 0.08162552863359451, acc: 0.9825242757797241)
[2024-12-17 05:40:23,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:24,112][root][INFO] - Training Epoch: 2/2, step 6550/7134 completed (loss: 0.0836130902171135, acc: 0.9830769300460815)
[2024-12-17 05:40:24,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:24,583][root][INFO] - Training Epoch: 2/2, step 6551/7134 completed (loss: 0.013036594726145267, acc: 0.9965831637382507)
[2024-12-17 05:40:24,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:25,049][root][INFO] - Training Epoch: 2/2, step 6552/7134 completed (loss: 0.02424757368862629, acc: 0.9970119595527649)
[2024-12-17 05:40:25,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:25,512][root][INFO] - Training Epoch: 2/2, step 6553/7134 completed (loss: 0.03179784119129181, acc: 0.9898219108581543)
[2024-12-17 05:40:25,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:25,975][root][INFO] - Training Epoch: 2/2, step 6554/7134 completed (loss: 0.028373098000884056, acc: 0.9956756830215454)
[2024-12-17 05:40:26,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:26,463][root][INFO] - Training Epoch: 2/2, step 6555/7134 completed (loss: 0.045195262879133224, acc: 0.9849094748497009)
[2024-12-17 05:40:26,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:26,931][root][INFO] - Training Epoch: 2/2, step 6556/7134 completed (loss: 0.0374903529882431, acc: 0.9926315546035767)
[2024-12-17 05:40:27,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:27,406][root][INFO] - Training Epoch: 2/2, step 6557/7134 completed (loss: 0.034340426325798035, acc: 0.9909273982048035)
[2024-12-17 05:40:27,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:27,888][root][INFO] - Training Epoch: 2/2, step 6558/7134 completed (loss: 0.03584807738661766, acc: 0.989130437374115)
[2024-12-17 05:40:28,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:28,326][root][INFO] - Training Epoch: 2/2, step 6559/7134 completed (loss: 0.028886601328849792, acc: 0.9916782379150391)
[2024-12-17 05:40:28,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:28,870][root][INFO] - Training Epoch: 2/2, step 6560/7134 completed (loss: 0.024025049060583115, acc: 0.9940546751022339)
[2024-12-17 05:40:28,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:29,307][root][INFO] - Training Epoch: 2/2, step 6561/7134 completed (loss: 0.02490634098649025, acc: 0.9918128848075867)
[2024-12-17 05:40:29,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:29,760][root][INFO] - Training Epoch: 2/2, step 6562/7134 completed (loss: 0.02479398064315319, acc: 0.9910314083099365)
[2024-12-17 05:40:29,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:30,232][root][INFO] - Training Epoch: 2/2, step 6563/7134 completed (loss: 0.033962901681661606, acc: 0.9895226955413818)
[2024-12-17 05:40:30,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:30,685][root][INFO] - Training Epoch: 2/2, step 6564/7134 completed (loss: 0.039334580302238464, acc: 0.9892037510871887)
[2024-12-17 05:40:30,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:31,155][root][INFO] - Training Epoch: 2/2, step 6565/7134 completed (loss: 0.03793438524007797, acc: 0.9915433526039124)
[2024-12-17 05:40:31,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:31,654][root][INFO] - Training Epoch: 2/2, step 6566/7134 completed (loss: 0.023926613852381706, acc: 0.9895536303520203)
[2024-12-17 05:40:31,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:32,155][root][INFO] - Training Epoch: 2/2, step 6567/7134 completed (loss: 0.017923973500728607, acc: 0.9929078221321106)
[2024-12-17 05:40:32,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:32,629][root][INFO] - Training Epoch: 2/2, step 6568/7134 completed (loss: 0.02531844563782215, acc: 0.9911727905273438)
[2024-12-17 05:40:32,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:33,080][root][INFO] - Training Epoch: 2/2, step 6569/7134 completed (loss: 0.010731365531682968, acc: 0.997802197933197)
[2024-12-17 05:40:33,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:33,538][root][INFO] - Training Epoch: 2/2, step 6570/7134 completed (loss: 0.014394184574484825, acc: 0.9941927790641785)
[2024-12-17 05:40:33,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:33,954][root][INFO] - Training Epoch: 2/2, step 6571/7134 completed (loss: 0.016253801062703133, acc: 0.9934554696083069)
[2024-12-17 05:40:34,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:34,407][root][INFO] - Training Epoch: 2/2, step 6572/7134 completed (loss: 0.043119877576828, acc: 0.9855875968933105)
[2024-12-17 05:40:34,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:34,873][root][INFO] - Training Epoch: 2/2, step 6573/7134 completed (loss: 0.026145104318857193, acc: 0.9909706711769104)
[2024-12-17 05:40:35,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:35,365][root][INFO] - Training Epoch: 2/2, step 6574/7134 completed (loss: 0.011434933170676231, acc: 0.9969325065612793)
[2024-12-17 05:40:35,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:35,864][root][INFO] - Training Epoch: 2/2, step 6575/7134 completed (loss: 0.03414168953895569, acc: 0.9878453016281128)
[2024-12-17 05:40:35,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:36,319][root][INFO] - Training Epoch: 2/2, step 6576/7134 completed (loss: 0.01107425894588232, acc: 0.9947478771209717)
[2024-12-17 05:40:36,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:36,772][root][INFO] - Training Epoch: 2/2, step 6577/7134 completed (loss: 0.04390261322259903, acc: 0.9873949289321899)
[2024-12-17 05:40:36,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:37,418][root][INFO] - Training Epoch: 2/2, step 6578/7134 completed (loss: 0.014613506384193897, acc: 0.9946619272232056)
[2024-12-17 05:40:37,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:37,820][root][INFO] - Training Epoch: 2/2, step 6579/7134 completed (loss: 0.02808447740972042, acc: 0.9927404522895813)
[2024-12-17 05:40:37,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:38,276][root][INFO] - Training Epoch: 2/2, step 6580/7134 completed (loss: 0.011582806706428528, acc: 0.9941176176071167)
[2024-12-17 05:40:38,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:38,714][root][INFO] - Training Epoch: 2/2, step 6581/7134 completed (loss: 0.02205037884414196, acc: 0.9950799345970154)
[2024-12-17 05:40:38,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:39,109][root][INFO] - Training Epoch: 2/2, step 6582/7134 completed (loss: 0.04610103368759155, acc: 0.9870503544807434)
[2024-12-17 05:40:39,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:39,563][root][INFO] - Training Epoch: 2/2, step 6583/7134 completed (loss: 0.011553503572940826, acc: 0.9954233169555664)
[2024-12-17 05:40:39,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:40,012][root][INFO] - Training Epoch: 2/2, step 6584/7134 completed (loss: 0.040629416704177856, acc: 0.9889841079711914)
[2024-12-17 05:40:40,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:40,453][root][INFO] - Training Epoch: 2/2, step 6585/7134 completed (loss: 0.024852627888321877, acc: 0.9901315569877625)
[2024-12-17 05:40:40,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:40,900][root][INFO] - Training Epoch: 2/2, step 6586/7134 completed (loss: 0.03253966197371483, acc: 0.9896373152732849)
[2024-12-17 05:40:41,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:41,364][root][INFO] - Training Epoch: 2/2, step 6587/7134 completed (loss: 0.07115746289491653, acc: 0.9834905862808228)
[2024-12-17 05:40:41,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:41,814][root][INFO] - Training Epoch: 2/2, step 6588/7134 completed (loss: 0.04091661050915718, acc: 0.9886792302131653)
[2024-12-17 05:40:41,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:42,265][root][INFO] - Training Epoch: 2/2, step 6589/7134 completed (loss: 0.02911827526986599, acc: 0.9917012453079224)
[2024-12-17 05:40:42,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:42,724][root][INFO] - Training Epoch: 2/2, step 6590/7134 completed (loss: 0.034836605191230774, acc: 0.9895226955413818)
[2024-12-17 05:40:42,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:43,187][root][INFO] - Training Epoch: 2/2, step 6591/7134 completed (loss: 0.039021413773298264, acc: 0.9913259148597717)
[2024-12-17 05:40:43,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:43,640][root][INFO] - Training Epoch: 2/2, step 6592/7134 completed (loss: 0.04895083233714104, acc: 0.986379086971283)
[2024-12-17 05:40:43,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:44,056][root][INFO] - Training Epoch: 2/2, step 6593/7134 completed (loss: 0.046846263110637665, acc: 0.9923896789550781)
[2024-12-17 05:40:44,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:44,498][root][INFO] - Training Epoch: 2/2, step 6594/7134 completed (loss: 0.027035938575863838, acc: 0.9929577708244324)
[2024-12-17 05:40:44,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:44,928][root][INFO] - Training Epoch: 2/2, step 6595/7134 completed (loss: 0.03793013468384743, acc: 0.9881305694580078)
[2024-12-17 05:40:45,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:45,327][root][INFO] - Training Epoch: 2/2, step 6596/7134 completed (loss: 0.03916563093662262, acc: 0.987860381603241)
[2024-12-17 05:40:45,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:45,768][root][INFO] - Training Epoch: 2/2, step 6597/7134 completed (loss: 0.028794923797249794, acc: 0.9929245114326477)
[2024-12-17 05:40:45,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:46,206][root][INFO] - Training Epoch: 2/2, step 6598/7134 completed (loss: 0.029869334772229195, acc: 0.9892617464065552)
[2024-12-17 05:40:46,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:46,674][root][INFO] - Training Epoch: 2/2, step 6599/7134 completed (loss: 0.044871795922517776, acc: 0.9855072498321533)
[2024-12-17 05:40:46,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:47,105][root][INFO] - Training Epoch: 2/2, step 6600/7134 completed (loss: 0.031169570982456207, acc: 0.9889065027236938)
[2024-12-17 05:40:47,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:47,559][root][INFO] - Training Epoch: 2/2, step 6601/7134 completed (loss: 0.04978448897600174, acc: 0.987089216709137)
[2024-12-17 05:40:47,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:48,005][root][INFO] - Training Epoch: 2/2, step 6602/7134 completed (loss: 0.02853347361087799, acc: 0.9939831495285034)
[2024-12-17 05:40:48,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:48,449][root][INFO] - Training Epoch: 2/2, step 6603/7134 completed (loss: 0.02916298247873783, acc: 0.9873772859573364)
[2024-12-17 05:40:48,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:48,826][root][INFO] - Training Epoch: 2/2, step 6604/7134 completed (loss: 0.03882307931780815, acc: 0.9885057210922241)
[2024-12-17 05:40:48,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:49,236][root][INFO] - Training Epoch: 2/2, step 6605/7134 completed (loss: 0.09318308532238007, acc: 0.9695712327957153)
[2024-12-17 05:40:49,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:49,686][root][INFO] - Training Epoch: 2/2, step 6606/7134 completed (loss: 0.04122038185596466, acc: 0.9898989796638489)
[2024-12-17 05:40:49,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:50,142][root][INFO] - Training Epoch: 2/2, step 6607/7134 completed (loss: 0.05902818590402603, acc: 0.9880319237709045)
[2024-12-17 05:40:50,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:50,595][root][INFO] - Training Epoch: 2/2, step 6608/7134 completed (loss: 0.016449036076664925, acc: 0.9973439574241638)
[2024-12-17 05:40:50,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:51,031][root][INFO] - Training Epoch: 2/2, step 6609/7134 completed (loss: 0.03167641535401344, acc: 0.9902200698852539)
[2024-12-17 05:40:51,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:51,453][root][INFO] - Training Epoch: 2/2, step 6610/7134 completed (loss: 0.058675672858953476, acc: 0.986522912979126)
[2024-12-17 05:40:51,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:51,874][root][INFO] - Training Epoch: 2/2, step 6611/7134 completed (loss: 0.07531525939702988, acc: 0.9769230484962463)
[2024-12-17 05:40:51,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:52,356][root][INFO] - Training Epoch: 2/2, step 6612/7134 completed (loss: 0.050224147737026215, acc: 0.9894982576370239)
[2024-12-17 05:40:52,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:52,829][root][INFO] - Training Epoch: 2/2, step 6613/7134 completed (loss: 0.04192684218287468, acc: 0.9866071343421936)
[2024-12-17 05:40:52,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:53,271][root][INFO] - Training Epoch: 2/2, step 6614/7134 completed (loss: 0.054575156420469284, acc: 0.9878987669944763)
[2024-12-17 05:40:53,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:53,710][root][INFO] - Training Epoch: 2/2, step 6615/7134 completed (loss: 0.035421278327703476, acc: 0.9929278492927551)
[2024-12-17 05:40:53,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:54,169][root][INFO] - Training Epoch: 2/2, step 6616/7134 completed (loss: 0.032308172434568405, acc: 0.9929577708244324)
[2024-12-17 05:40:54,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:54,581][root][INFO] - Training Epoch: 2/2, step 6617/7134 completed (loss: 0.021792879328131676, acc: 0.9956772327423096)
[2024-12-17 05:40:54,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:55,002][root][INFO] - Training Epoch: 2/2, step 6618/7134 completed (loss: 0.01318851113319397, acc: 0.9955423474311829)
[2024-12-17 05:40:55,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:55,468][root][INFO] - Training Epoch: 2/2, step 6619/7134 completed (loss: 0.024264825507998466, acc: 0.9932735562324524)
[2024-12-17 05:40:55,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:55,934][root][INFO] - Training Epoch: 2/2, step 6620/7134 completed (loss: 0.02327953465282917, acc: 0.9958734512329102)
[2024-12-17 05:40:56,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:56,376][root][INFO] - Training Epoch: 2/2, step 6621/7134 completed (loss: 0.032621532678604126, acc: 0.989595353603363)
[2024-12-17 05:40:56,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:56,844][root][INFO] - Training Epoch: 2/2, step 6622/7134 completed (loss: 0.03117671236395836, acc: 0.9918032884597778)
[2024-12-17 05:40:56,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:57,281][root][INFO] - Training Epoch: 2/2, step 6623/7134 completed (loss: 0.01680433191359043, acc: 0.9949685335159302)
[2024-12-17 05:40:57,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:57,711][root][INFO] - Training Epoch: 2/2, step 6624/7134 completed (loss: 0.03856950253248215, acc: 0.98828125)
[2024-12-17 05:40:57,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:58,143][root][INFO] - Training Epoch: 2/2, step 6625/7134 completed (loss: 0.020492805168032646, acc: 0.9944979548454285)
[2024-12-17 05:40:58,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:58,603][root][INFO] - Training Epoch: 2/2, step 6626/7134 completed (loss: 0.01500451099127531, acc: 0.9951515197753906)
[2024-12-17 05:40:58,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:59,074][root][INFO] - Training Epoch: 2/2, step 6627/7134 completed (loss: 0.022036179900169373, acc: 0.9945945739746094)
[2024-12-17 05:40:59,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:59,529][root][INFO] - Training Epoch: 2/2, step 6628/7134 completed (loss: 0.045183319598436356, acc: 0.9881656765937805)
[2024-12-17 05:40:59,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:40:59,930][root][INFO] - Training Epoch: 2/2, step 6629/7134 completed (loss: 0.06287775933742523, acc: 0.9871630072593689)
[2024-12-17 05:41:00,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:00,417][root][INFO] - Training Epoch: 2/2, step 6630/7134 completed (loss: 0.037233687937259674, acc: 0.9921962022781372)
[2024-12-17 05:41:00,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:00,858][root][INFO] - Training Epoch: 2/2, step 6631/7134 completed (loss: 0.023632364347577095, acc: 0.9921362996101379)
[2024-12-17 05:41:00,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:01,356][root][INFO] - Training Epoch: 2/2, step 6632/7134 completed (loss: 0.022919053211808205, acc: 0.9966254234313965)
[2024-12-17 05:41:01,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:01,784][root][INFO] - Training Epoch: 2/2, step 6633/7134 completed (loss: 0.037836503237485886, acc: 0.9939024448394775)
[2024-12-17 05:41:01,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:02,209][root][INFO] - Training Epoch: 2/2, step 6634/7134 completed (loss: 0.03359250724315643, acc: 0.991055428981781)
[2024-12-17 05:41:02,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:02,607][root][INFO] - Training Epoch: 2/2, step 6635/7134 completed (loss: 0.08570966869592667, acc: 0.9769821166992188)
[2024-12-17 05:41:02,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:03,064][root][INFO] - Training Epoch: 2/2, step 6636/7134 completed (loss: 0.034912317991256714, acc: 0.9885844588279724)
[2024-12-17 05:41:03,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:03,493][root][INFO] - Training Epoch: 2/2, step 6637/7134 completed (loss: 0.024656618013978004, acc: 0.9956331849098206)
[2024-12-17 05:41:03,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:03,938][root][INFO] - Training Epoch: 2/2, step 6638/7134 completed (loss: 0.013935082592070103, acc: 0.9974586963653564)
[2024-12-17 05:41:04,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:04,390][root][INFO] - Training Epoch: 2/2, step 6639/7134 completed (loss: 0.01971568912267685, acc: 0.997019350528717)
[2024-12-17 05:41:04,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:04,839][root][INFO] - Training Epoch: 2/2, step 6640/7134 completed (loss: 0.012708676978945732, acc: 0.9969372153282166)
[2024-12-17 05:41:04,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:05,295][root][INFO] - Training Epoch: 2/2, step 6641/7134 completed (loss: 0.05791836977005005, acc: 0.9847596883773804)
[2024-12-17 05:41:05,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:05,734][root][INFO] - Training Epoch: 2/2, step 6642/7134 completed (loss: 0.0330834724009037, acc: 0.9894578456878662)
[2024-12-17 05:41:05,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:06,200][root][INFO] - Training Epoch: 2/2, step 6643/7134 completed (loss: 0.026943862438201904, acc: 0.9920739531517029)
[2024-12-17 05:41:06,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:06,658][root][INFO] - Training Epoch: 2/2, step 6644/7134 completed (loss: 0.045058779418468475, acc: 0.9867751598358154)
[2024-12-17 05:41:06,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:07,100][root][INFO] - Training Epoch: 2/2, step 6645/7134 completed (loss: 0.02912069857120514, acc: 0.9889435172080994)
[2024-12-17 05:41:07,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:07,580][root][INFO] - Training Epoch: 2/2, step 6646/7134 completed (loss: 0.022233933210372925, acc: 0.9933920502662659)
[2024-12-17 05:41:07,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:08,023][root][INFO] - Training Epoch: 2/2, step 6647/7134 completed (loss: 0.01954447478055954, acc: 0.9959239363670349)
[2024-12-17 05:41:08,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:08,472][root][INFO] - Training Epoch: 2/2, step 6648/7134 completed (loss: 0.04655313491821289, acc: 0.9824000000953674)
[2024-12-17 05:41:08,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:08,943][root][INFO] - Training Epoch: 2/2, step 6649/7134 completed (loss: 0.04613083600997925, acc: 0.9858323335647583)
[2024-12-17 05:41:09,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:09,432][root][INFO] - Training Epoch: 2/2, step 6650/7134 completed (loss: 0.012197357602417469, acc: 0.9955357313156128)
[2024-12-17 05:41:09,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:09,921][root][INFO] - Training Epoch: 2/2, step 6651/7134 completed (loss: 0.022170068696141243, acc: 0.9972714781761169)
[2024-12-17 05:41:10,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:10,373][root][INFO] - Training Epoch: 2/2, step 6652/7134 completed (loss: 0.034456949681043625, acc: 0.990338146686554)
[2024-12-17 05:41:10,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:10,835][root][INFO] - Training Epoch: 2/2, step 6653/7134 completed (loss: 0.043381672352552414, acc: 0.9879518151283264)
[2024-12-17 05:41:10,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:11,267][root][INFO] - Training Epoch: 2/2, step 6654/7134 completed (loss: 0.07274090498685837, acc: 0.9860464930534363)
[2024-12-17 05:41:11,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:11,689][root][INFO] - Training Epoch: 2/2, step 6655/7134 completed (loss: 0.0232393778860569, acc: 0.9900744557380676)
[2024-12-17 05:41:11,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:12,109][root][INFO] - Training Epoch: 2/2, step 6656/7134 completed (loss: 0.04341954365372658, acc: 0.9872773289680481)
[2024-12-17 05:41:12,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:12,546][root][INFO] - Training Epoch: 2/2, step 6657/7134 completed (loss: 0.037117354571819305, acc: 0.9864498376846313)
[2024-12-17 05:41:12,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:13,002][root][INFO] - Training Epoch: 2/2, step 6658/7134 completed (loss: 0.018042758107185364, acc: 0.996129035949707)
[2024-12-17 05:41:13,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:13,477][root][INFO] - Training Epoch: 2/2, step 6659/7134 completed (loss: 0.02948414348065853, acc: 0.9908854365348816)
[2024-12-17 05:41:13,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:13,935][root][INFO] - Training Epoch: 2/2, step 6660/7134 completed (loss: 0.018922973424196243, acc: 0.995039701461792)
[2024-12-17 05:41:14,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:14,418][root][INFO] - Training Epoch: 2/2, step 6661/7134 completed (loss: 0.02394913136959076, acc: 0.9913366436958313)
[2024-12-17 05:41:14,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:14,833][root][INFO] - Training Epoch: 2/2, step 6662/7134 completed (loss: 0.048982199281454086, acc: 0.9785407781600952)
[2024-12-17 05:41:14,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:15,285][root][INFO] - Training Epoch: 2/2, step 6663/7134 completed (loss: 0.02390412427484989, acc: 0.9923497438430786)
[2024-12-17 05:41:15,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:15,682][root][INFO] - Training Epoch: 2/2, step 6664/7134 completed (loss: 0.07037340849637985, acc: 0.9686346650123596)
[2024-12-17 05:41:15,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:16,079][root][INFO] - Training Epoch: 2/2, step 6665/7134 completed (loss: 0.07444123178720474, acc: 0.9707792401313782)
[2024-12-17 05:41:16,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:16,525][root][INFO] - Training Epoch: 2/2, step 6666/7134 completed (loss: 0.020933562889695168, acc: 0.9936548471450806)
[2024-12-17 05:41:16,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:16,952][root][INFO] - Training Epoch: 2/2, step 6667/7134 completed (loss: 0.04716101288795471, acc: 0.9787985682487488)
[2024-12-17 05:41:17,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:17,362][root][INFO] - Training Epoch: 2/2, step 6668/7134 completed (loss: 0.01012466661632061, acc: 0.9965338110923767)
[2024-12-17 05:41:17,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:17,756][root][INFO] - Training Epoch: 2/2, step 6669/7134 completed (loss: 0.0216937568038702, acc: 0.9899328947067261)
[2024-12-17 05:41:17,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:18,165][root][INFO] - Training Epoch: 2/2, step 6670/7134 completed (loss: 0.011923126876354218, acc: 0.9933110475540161)
[2024-12-17 05:41:18,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:18,604][root][INFO] - Training Epoch: 2/2, step 6671/7134 completed (loss: 0.017202986404299736, acc: 0.9956011772155762)
[2024-12-17 05:41:18,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:19,044][root][INFO] - Training Epoch: 2/2, step 6672/7134 completed (loss: 0.01551502663642168, acc: 0.9962476491928101)
[2024-12-17 05:41:19,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:19,475][root][INFO] - Training Epoch: 2/2, step 6673/7134 completed (loss: 0.01992141827940941, acc: 0.9911894202232361)
[2024-12-17 05:41:19,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:19,885][root][INFO] - Training Epoch: 2/2, step 6674/7134 completed (loss: 0.012977441772818565, acc: 0.9961315393447876)
[2024-12-17 05:41:20,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:20,314][root][INFO] - Training Epoch: 2/2, step 6675/7134 completed (loss: 0.012051177211105824, acc: 0.9975308775901794)
[2024-12-17 05:41:20,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:20,750][root][INFO] - Training Epoch: 2/2, step 6676/7134 completed (loss: 0.02463487721979618, acc: 0.9880668520927429)
[2024-12-17 05:41:20,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:21,160][root][INFO] - Training Epoch: 2/2, step 6677/7134 completed (loss: 0.04716979339718819, acc: 0.9885495901107788)
[2024-12-17 05:41:21,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:21,580][root][INFO] - Training Epoch: 2/2, step 6678/7134 completed (loss: 0.012093281373381615, acc: 0.9964285492897034)
[2024-12-17 05:41:21,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:21,967][root][INFO] - Training Epoch: 2/2, step 6679/7134 completed (loss: 0.017027560621500015, acc: 0.9934498071670532)
[2024-12-17 05:41:22,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:22,387][root][INFO] - Training Epoch: 2/2, step 6680/7134 completed (loss: 0.014052193611860275, acc: 0.9972972869873047)
[2024-12-17 05:41:22,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:22,808][root][INFO] - Training Epoch: 2/2, step 6681/7134 completed (loss: 0.004607829265296459, acc: 1.0)
[2024-12-17 05:41:22,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:23,208][root][INFO] - Training Epoch: 2/2, step 6682/7134 completed (loss: 0.03789747133851051, acc: 0.9953271150588989)
[2024-12-17 05:41:23,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:23,615][root][INFO] - Training Epoch: 2/2, step 6683/7134 completed (loss: 0.02287467196583748, acc: 0.9917582273483276)
[2024-12-17 05:41:23,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:24,027][root][INFO] - Training Epoch: 2/2, step 6684/7134 completed (loss: 0.03414895385503769, acc: 0.9910714030265808)
[2024-12-17 05:41:24,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:24,420][root][INFO] - Training Epoch: 2/2, step 6685/7134 completed (loss: 0.04053864628076553, acc: 0.9904580116271973)
[2024-12-17 05:41:24,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:24,831][root][INFO] - Training Epoch: 2/2, step 6686/7134 completed (loss: 0.06886815279722214, acc: 0.9876033067703247)
[2024-12-17 05:41:24,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:25,235][root][INFO] - Training Epoch: 2/2, step 6687/7134 completed (loss: 0.03184473142027855, acc: 0.9907407164573669)
[2024-12-17 05:41:25,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:25,694][root][INFO] - Training Epoch: 2/2, step 6688/7134 completed (loss: 0.06492411345243454, acc: 0.9793814420700073)
[2024-12-17 05:41:25,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:26,114][root][INFO] - Training Epoch: 2/2, step 6689/7134 completed (loss: 0.03866194188594818, acc: 0.9881188273429871)
[2024-12-17 05:41:26,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:26,515][root][INFO] - Training Epoch: 2/2, step 6690/7134 completed (loss: 0.08411809056997299, acc: 0.9661017060279846)
[2024-12-17 05:41:26,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:26,955][root][INFO] - Training Epoch: 2/2, step 6691/7134 completed (loss: 0.01953578181564808, acc: 0.9950900077819824)
[2024-12-17 05:41:27,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:27,378][root][INFO] - Training Epoch: 2/2, step 6692/7134 completed (loss: 0.03594045341014862, acc: 0.991525411605835)
[2024-12-17 05:41:27,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:27,778][root][INFO] - Training Epoch: 2/2, step 6693/7134 completed (loss: 0.033846836537122726, acc: 0.9884488582611084)
[2024-12-17 05:41:27,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:28,206][root][INFO] - Training Epoch: 2/2, step 6694/7134 completed (loss: 0.0235567856580019, acc: 0.9938837885856628)
[2024-12-17 05:41:28,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:28,630][root][INFO] - Training Epoch: 2/2, step 6695/7134 completed (loss: 0.030096186324954033, acc: 0.9863201379776001)
[2024-12-17 05:41:28,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:29,054][root][INFO] - Training Epoch: 2/2, step 6696/7134 completed (loss: 0.07307135313749313, acc: 0.9829721450805664)
[2024-12-17 05:41:29,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:29,462][root][INFO] - Training Epoch: 2/2, step 6697/7134 completed (loss: 0.06942174583673477, acc: 0.9786885380744934)
[2024-12-17 05:41:29,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:29,889][root][INFO] - Training Epoch: 2/2, step 6698/7134 completed (loss: 0.02088109403848648, acc: 0.9940652847290039)
[2024-12-17 05:41:30,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:30,321][root][INFO] - Training Epoch: 2/2, step 6699/7134 completed (loss: 0.025472937151789665, acc: 0.9954441785812378)
[2024-12-17 05:41:30,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:30,756][root][INFO] - Training Epoch: 2/2, step 6700/7134 completed (loss: 0.06090103089809418, acc: 0.9852941036224365)
[2024-12-17 05:41:30,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:31,163][root][INFO] - Training Epoch: 2/2, step 6701/7134 completed (loss: 0.09067126363515854, acc: 0.9702380895614624)
[2024-12-17 05:41:31,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:31,555][root][INFO] - Training Epoch: 2/2, step 6702/7134 completed (loss: 0.025225507095456123, acc: 0.9921414256095886)
[2024-12-17 05:41:31,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:31,970][root][INFO] - Training Epoch: 2/2, step 6703/7134 completed (loss: 0.07100439071655273, acc: 0.9802631735801697)
[2024-12-17 05:41:32,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:32,394][root][INFO] - Training Epoch: 2/2, step 6704/7134 completed (loss: 0.10236464440822601, acc: 0.9767140746116638)
[2024-12-17 05:41:32,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:32,826][root][INFO] - Training Epoch: 2/2, step 6705/7134 completed (loss: 0.0328531414270401, acc: 0.9869961142539978)
[2024-12-17 05:41:32,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:33,234][root][INFO] - Training Epoch: 2/2, step 6706/7134 completed (loss: 0.03463774546980858, acc: 0.9896694421768188)
[2024-12-17 05:41:33,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:33,651][root][INFO] - Training Epoch: 2/2, step 6707/7134 completed (loss: 0.04326436296105385, acc: 0.9881656765937805)
[2024-12-17 05:41:33,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:34,105][root][INFO] - Training Epoch: 2/2, step 6708/7134 completed (loss: 0.046885013580322266, acc: 0.9851484894752502)
[2024-12-17 05:41:34,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:34,531][root][INFO] - Training Epoch: 2/2, step 6709/7134 completed (loss: 0.03703862428665161, acc: 0.9895209670066833)
[2024-12-17 05:41:34,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:34,944][root][INFO] - Training Epoch: 2/2, step 6710/7134 completed (loss: 0.0586298331618309, acc: 0.9835466146469116)
[2024-12-17 05:41:35,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:35,392][root][INFO] - Training Epoch: 2/2, step 6711/7134 completed (loss: 0.01648564077913761, acc: 0.9984126687049866)
[2024-12-17 05:41:35,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:35,827][root][INFO] - Training Epoch: 2/2, step 6712/7134 completed (loss: 0.04406825453042984, acc: 0.9848713874816895)
[2024-12-17 05:41:36,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:36,388][root][INFO] - Training Epoch: 2/2, step 6713/7134 completed (loss: 0.048175960779190063, acc: 0.9826338887214661)
[2024-12-17 05:41:36,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:36,832][root][INFO] - Training Epoch: 2/2, step 6714/7134 completed (loss: 0.03218933194875717, acc: 0.9881129264831543)
[2024-12-17 05:41:36,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:37,254][root][INFO] - Training Epoch: 2/2, step 6715/7134 completed (loss: 0.060641031712293625, acc: 0.976452112197876)
[2024-12-17 05:41:37,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:37,684][root][INFO] - Training Epoch: 2/2, step 6716/7134 completed (loss: 0.02014627307653427, acc: 0.9910179376602173)
[2024-12-17 05:41:37,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:38,095][root][INFO] - Training Epoch: 2/2, step 6717/7134 completed (loss: 0.01702094078063965, acc: 0.9935587644577026)
[2024-12-17 05:41:38,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:38,517][root][INFO] - Training Epoch: 2/2, step 6718/7134 completed (loss: 0.04871126264333725, acc: 0.9863636493682861)
[2024-12-17 05:41:38,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:38,928][root][INFO] - Training Epoch: 2/2, step 6719/7134 completed (loss: 0.02772272378206253, acc: 0.9885621070861816)
[2024-12-17 05:41:39,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:39,348][root][INFO] - Training Epoch: 2/2, step 6720/7134 completed (loss: 0.05102181062102318, acc: 0.9902234673500061)
[2024-12-17 05:41:39,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:39,737][root][INFO] - Training Epoch: 2/2, step 6721/7134 completed (loss: 0.05002075061202049, acc: 0.9875195026397705)
[2024-12-17 05:41:39,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:40,090][root][INFO] - Training Epoch: 2/2, step 6722/7134 completed (loss: 0.07279809564352036, acc: 0.9841827750205994)
[2024-12-17 05:41:40,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:40,522][root][INFO] - Training Epoch: 2/2, step 6723/7134 completed (loss: 0.02964508719742298, acc: 0.9902777671813965)
[2024-12-17 05:41:40,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:40,945][root][INFO] - Training Epoch: 2/2, step 6724/7134 completed (loss: 0.02935519814491272, acc: 0.9926793575286865)
[2024-12-17 05:41:41,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:41,330][root][INFO] - Training Epoch: 2/2, step 6725/7134 completed (loss: 0.025767501443624496, acc: 0.9914675951004028)
[2024-12-17 05:41:41,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:41,716][root][INFO] - Training Epoch: 2/2, step 6726/7134 completed (loss: 0.06190679222345352, acc: 0.9899598360061646)
[2024-12-17 05:41:41,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:42,133][root][INFO] - Training Epoch: 2/2, step 6727/7134 completed (loss: 0.03565189987421036, acc: 0.9894366264343262)
[2024-12-17 05:41:42,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:42,571][root][INFO] - Training Epoch: 2/2, step 6728/7134 completed (loss: 0.05357789248228073, acc: 0.9907833933830261)
[2024-12-17 05:41:42,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:43,015][root][INFO] - Training Epoch: 2/2, step 6729/7134 completed (loss: 0.019124386832118034, acc: 0.9945651888847351)
[2024-12-17 05:41:43,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:43,464][root][INFO] - Training Epoch: 2/2, step 6730/7134 completed (loss: 0.03750646859407425, acc: 0.9905808568000793)
[2024-12-17 05:41:43,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:43,955][root][INFO] - Training Epoch: 2/2, step 6731/7134 completed (loss: 0.02686651237308979, acc: 0.9924585223197937)
[2024-12-17 05:41:44,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:44,364][root][INFO] - Training Epoch: 2/2, step 6732/7134 completed (loss: 0.027105288580060005, acc: 0.9905660152435303)
[2024-12-17 05:41:44,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:44,792][root][INFO] - Training Epoch: 2/2, step 6733/7134 completed (loss: 0.033180736005306244, acc: 0.9886147975921631)
[2024-12-17 05:41:44,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:45,188][root][INFO] - Training Epoch: 2/2, step 6734/7134 completed (loss: 0.04477392137050629, acc: 0.9869158864021301)
[2024-12-17 05:41:45,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:45,596][root][INFO] - Training Epoch: 2/2, step 6735/7134 completed (loss: 0.046334415674209595, acc: 0.9877111911773682)
[2024-12-17 05:41:45,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:46,057][root][INFO] - Training Epoch: 2/2, step 6736/7134 completed (loss: 0.04792409390211105, acc: 0.9902507066726685)
[2024-12-17 05:41:46,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:46,488][root][INFO] - Training Epoch: 2/2, step 6737/7134 completed (loss: 0.04166368022561073, acc: 0.9837925434112549)
[2024-12-17 05:41:46,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:46,896][root][INFO] - Training Epoch: 2/2, step 6738/7134 completed (loss: 0.038885846734046936, acc: 0.986940324306488)
[2024-12-17 05:41:46,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:47,267][root][INFO] - Training Epoch: 2/2, step 6739/7134 completed (loss: 0.028184369206428528, acc: 0.9926470518112183)
[2024-12-17 05:41:47,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:47,691][root][INFO] - Training Epoch: 2/2, step 6740/7134 completed (loss: 0.04880988225340843, acc: 0.9881154298782349)
[2024-12-17 05:41:47,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:48,120][root][INFO] - Training Epoch: 2/2, step 6741/7134 completed (loss: 0.017402172088623047, acc: 0.994194507598877)
[2024-12-17 05:41:48,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:48,544][root][INFO] - Training Epoch: 2/2, step 6742/7134 completed (loss: 0.01924728788435459, acc: 0.9898989796638489)
[2024-12-17 05:41:48,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:49,005][root][INFO] - Training Epoch: 2/2, step 6743/7134 completed (loss: 0.0176369771361351, acc: 0.9959127902984619)
[2024-12-17 05:41:49,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:49,424][root][INFO] - Training Epoch: 2/2, step 6744/7134 completed (loss: 0.026940608397126198, acc: 0.9935897588729858)
[2024-12-17 05:41:49,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:49,842][root][INFO] - Training Epoch: 2/2, step 6745/7134 completed (loss: 0.010894503444433212, acc: 0.9972489476203918)
[2024-12-17 05:41:49,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:50,257][root][INFO] - Training Epoch: 2/2, step 6746/7134 completed (loss: 0.01070786826312542, acc: 0.998236358165741)
[2024-12-17 05:41:50,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:50,675][root][INFO] - Training Epoch: 2/2, step 6747/7134 completed (loss: 0.02596651390194893, acc: 0.9962732791900635)
[2024-12-17 05:41:50,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:51,169][root][INFO] - Training Epoch: 2/2, step 6748/7134 completed (loss: 0.015841305255889893, acc: 0.9977452158927917)
[2024-12-17 05:41:51,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:51,648][root][INFO] - Training Epoch: 2/2, step 6749/7134 completed (loss: 0.028477050364017487, acc: 0.9934640526771545)
[2024-12-17 05:41:51,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:52,117][root][INFO] - Training Epoch: 2/2, step 6750/7134 completed (loss: 0.01478326041251421, acc: 0.9976931810379028)
[2024-12-17 05:41:52,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:52,591][root][INFO] - Training Epoch: 2/2, step 6751/7134 completed (loss: 0.00863319355994463, acc: 0.9988584518432617)
[2024-12-17 05:41:52,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:53,021][root][INFO] - Training Epoch: 2/2, step 6752/7134 completed (loss: 0.006762099917978048, acc: 0.9985486268997192)
[2024-12-17 05:41:53,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:53,491][root][INFO] - Training Epoch: 2/2, step 6753/7134 completed (loss: 0.010022287257015705, acc: 0.997706413269043)
[2024-12-17 05:41:53,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:53,924][root][INFO] - Training Epoch: 2/2, step 6754/7134 completed (loss: 0.009006813168525696, acc: 0.9963855147361755)
[2024-12-17 05:41:54,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:54,379][root][INFO] - Training Epoch: 2/2, step 6755/7134 completed (loss: 0.013083579018712044, acc: 0.9963054060935974)
[2024-12-17 05:41:54,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:54,822][root][INFO] - Training Epoch: 2/2, step 6756/7134 completed (loss: 0.0037309909239411354, acc: 1.0)
[2024-12-17 05:41:54,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:55,235][root][INFO] - Training Epoch: 2/2, step 6757/7134 completed (loss: 0.017177296802401543, acc: 0.9939024448394775)
[2024-12-17 05:41:55,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:55,668][root][INFO] - Training Epoch: 2/2, step 6758/7134 completed (loss: 0.02055525779724121, acc: 0.9935317039489746)
[2024-12-17 05:41:55,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:56,151][root][INFO] - Training Epoch: 2/2, step 6759/7134 completed (loss: 0.01695520430803299, acc: 0.9944071769714355)
[2024-12-17 05:41:56,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:56,608][root][INFO] - Training Epoch: 2/2, step 6760/7134 completed (loss: 0.018859950825572014, acc: 0.9934383034706116)
[2024-12-17 05:41:56,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:57,060][root][INFO] - Training Epoch: 2/2, step 6761/7134 completed (loss: 0.025517407804727554, acc: 0.9927710890769958)
[2024-12-17 05:41:57,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:57,512][root][INFO] - Training Epoch: 2/2, step 6762/7134 completed (loss: 0.03799235075712204, acc: 0.9901960492134094)
[2024-12-17 05:41:57,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:57,966][root][INFO] - Training Epoch: 2/2, step 6763/7134 completed (loss: 0.007719208020716906, acc: 0.998745322227478)
[2024-12-17 05:41:58,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:58,374][root][INFO] - Training Epoch: 2/2, step 6764/7134 completed (loss: 0.021909693256020546, acc: 0.9913793206214905)
[2024-12-17 05:41:58,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:58,857][root][INFO] - Training Epoch: 2/2, step 6765/7134 completed (loss: 0.015961525961756706, acc: 0.9933422207832336)
[2024-12-17 05:41:58,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:59,274][root][INFO] - Training Epoch: 2/2, step 6766/7134 completed (loss: 0.010279580019414425, acc: 0.9958620667457581)
[2024-12-17 05:41:59,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:41:59,647][root][INFO] - Training Epoch: 2/2, step 6767/7134 completed (loss: 0.046338316053152084, acc: 0.9932432174682617)
[2024-12-17 05:41:59,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:00,086][root][INFO] - Training Epoch: 2/2, step 6768/7134 completed (loss: 0.008160986937582493, acc: 0.9980988502502441)
[2024-12-17 05:42:00,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:00,509][root][INFO] - Training Epoch: 2/2, step 6769/7134 completed (loss: 0.025073066353797913, acc: 0.9938271641731262)
[2024-12-17 05:42:00,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:00,945][root][INFO] - Training Epoch: 2/2, step 6770/7134 completed (loss: 0.03387867286801338, acc: 0.9865771532058716)
[2024-12-17 05:42:01,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:01,389][root][INFO] - Training Epoch: 2/2, step 6771/7134 completed (loss: 0.014234055764973164, acc: 0.9984227418899536)
[2024-12-17 05:42:01,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:01,818][root][INFO] - Training Epoch: 2/2, step 6772/7134 completed (loss: 0.07500747591257095, acc: 0.9839572310447693)
[2024-12-17 05:42:01,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:02,227][root][INFO] - Training Epoch: 2/2, step 6773/7134 completed (loss: 0.029351375997066498, acc: 0.9889240264892578)
[2024-12-17 05:42:02,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:02,655][root][INFO] - Training Epoch: 2/2, step 6774/7134 completed (loss: 0.04208623617887497, acc: 0.9920381903648376)
[2024-12-17 05:42:02,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:03,069][root][INFO] - Training Epoch: 2/2, step 6775/7134 completed (loss: 0.016386209055781364, acc: 0.992438554763794)
[2024-12-17 05:42:03,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:03,488][root][INFO] - Training Epoch: 2/2, step 6776/7134 completed (loss: 0.0454912967979908, acc: 0.9872340559959412)
[2024-12-17 05:42:03,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:03,910][root][INFO] - Training Epoch: 2/2, step 6777/7134 completed (loss: 0.024342184886336327, acc: 0.9932885766029358)
[2024-12-17 05:42:04,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:04,357][root][INFO] - Training Epoch: 2/2, step 6778/7134 completed (loss: 0.030707575380802155, acc: 0.9910846948623657)
[2024-12-17 05:42:04,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:04,782][root][INFO] - Training Epoch: 2/2, step 6779/7134 completed (loss: 0.011886771768331528, acc: 0.9970149397850037)
[2024-12-17 05:42:04,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:05,210][root][INFO] - Training Epoch: 2/2, step 6780/7134 completed (loss: 0.023311994969844818, acc: 0.9925261735916138)
[2024-12-17 05:42:05,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:05,653][root][INFO] - Training Epoch: 2/2, step 6781/7134 completed (loss: 0.01280252356082201, acc: 0.9970059990882874)
[2024-12-17 05:42:05,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:06,073][root][INFO] - Training Epoch: 2/2, step 6782/7134 completed (loss: 0.021277830004692078, acc: 0.9947916865348816)
[2024-12-17 05:42:06,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:06,449][root][INFO] - Training Epoch: 2/2, step 6783/7134 completed (loss: 0.032291293144226074, acc: 0.9865642786026001)
[2024-12-17 05:42:06,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:06,879][root][INFO] - Training Epoch: 2/2, step 6784/7134 completed (loss: 0.01107226312160492, acc: 0.9966722130775452)
[2024-12-17 05:42:06,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:07,301][root][INFO] - Training Epoch: 2/2, step 6785/7134 completed (loss: 0.01648763194680214, acc: 0.9952830076217651)
[2024-12-17 05:42:07,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:07,785][root][INFO] - Training Epoch: 2/2, step 6786/7134 completed (loss: 0.006656684447079897, acc: 0.9985611438751221)
[2024-12-17 05:42:07,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:08,234][root][INFO] - Training Epoch: 2/2, step 6787/7134 completed (loss: 0.03707719221711159, acc: 0.9894737005233765)
[2024-12-17 05:42:08,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:08,658][root][INFO] - Training Epoch: 2/2, step 6788/7134 completed (loss: 0.019984904676675797, acc: 0.9946042895317078)
[2024-12-17 05:42:08,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:09,058][root][INFO] - Training Epoch: 2/2, step 6789/7134 completed (loss: 0.013368207961320877, acc: 0.9961089491844177)
[2024-12-17 05:42:09,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:09,493][root][INFO] - Training Epoch: 2/2, step 6790/7134 completed (loss: 0.04503973200917244, acc: 0.9928160905838013)
[2024-12-17 05:42:09,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:09,902][root][INFO] - Training Epoch: 2/2, step 6791/7134 completed (loss: 0.01763191446661949, acc: 0.9931856989860535)
[2024-12-17 05:42:10,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:10,325][root][INFO] - Training Epoch: 2/2, step 6792/7134 completed (loss: 0.013071602210402489, acc: 0.9963302612304688)
[2024-12-17 05:42:10,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:10,764][root][INFO] - Training Epoch: 2/2, step 6793/7134 completed (loss: 0.006451157387346029, acc: 0.997890293598175)
[2024-12-17 05:42:10,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:11,195][root][INFO] - Training Epoch: 2/2, step 6794/7134 completed (loss: 0.014663592912256718, acc: 0.9983579516410828)
[2024-12-17 05:42:11,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:11,639][root][INFO] - Training Epoch: 2/2, step 6795/7134 completed (loss: 0.004904382396489382, acc: 0.9974026083946228)
[2024-12-17 05:42:11,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:12,071][root][INFO] - Training Epoch: 2/2, step 6796/7134 completed (loss: 0.009988740086555481, acc: 0.9956011772155762)
[2024-12-17 05:42:12,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:12,493][root][INFO] - Training Epoch: 2/2, step 6797/7134 completed (loss: 0.037069160491228104, acc: 0.9883551597595215)
[2024-12-17 05:42:12,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:12,925][root][INFO] - Training Epoch: 2/2, step 6798/7134 completed (loss: 0.020274637266993523, acc: 0.9917355179786682)
[2024-12-17 05:42:13,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:13,354][root][INFO] - Training Epoch: 2/2, step 6799/7134 completed (loss: 0.017440374940633774, acc: 0.99452805519104)
[2024-12-17 05:42:13,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:13,770][root][INFO] - Training Epoch: 2/2, step 6800/7134 completed (loss: 0.026948774233460426, acc: 0.9930939078330994)
[2024-12-17 05:42:13,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:14,227][root][INFO] - Training Epoch: 2/2, step 6801/7134 completed (loss: 0.026912575587630272, acc: 0.995275616645813)
[2024-12-17 05:42:14,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:14,642][root][INFO] - Training Epoch: 2/2, step 6802/7134 completed (loss: 0.01915776915848255, acc: 0.9970717430114746)
[2024-12-17 05:42:14,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:15,089][root][INFO] - Training Epoch: 2/2, step 6803/7134 completed (loss: 0.01118550542742014, acc: 0.99622642993927)
[2024-12-17 05:42:15,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:15,519][root][INFO] - Training Epoch: 2/2, step 6804/7134 completed (loss: 0.02017151564359665, acc: 0.996874988079071)
[2024-12-17 05:42:15,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:15,970][root][INFO] - Training Epoch: 2/2, step 6805/7134 completed (loss: 0.034288082271814346, acc: 0.9919871687889099)
[2024-12-17 05:42:16,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:16,405][root][INFO] - Training Epoch: 2/2, step 6806/7134 completed (loss: 0.03668710216879845, acc: 0.9949367046356201)
[2024-12-17 05:42:16,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:16,867][root][INFO] - Training Epoch: 2/2, step 6807/7134 completed (loss: 0.012464570812880993, acc: 0.9942528605461121)
[2024-12-17 05:42:16,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:17,303][root][INFO] - Training Epoch: 2/2, step 6808/7134 completed (loss: 0.037083011120557785, acc: 0.9904305934906006)
[2024-12-17 05:42:17,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:17,762][root][INFO] - Training Epoch: 2/2, step 6809/7134 completed (loss: 0.024822430685162544, acc: 0.9932249188423157)
[2024-12-17 05:42:17,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:18,170][root][INFO] - Training Epoch: 2/2, step 6810/7134 completed (loss: 0.007160883396863937, acc: 0.9973683953285217)
[2024-12-17 05:42:18,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:18,621][root][INFO] - Training Epoch: 2/2, step 6811/7134 completed (loss: 0.045865271240472794, acc: 0.9908257126808167)
[2024-12-17 05:42:18,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:19,035][root][INFO] - Training Epoch: 2/2, step 6812/7134 completed (loss: 0.020198054611682892, acc: 0.9886547923088074)
[2024-12-17 05:42:19,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:19,460][root][INFO] - Training Epoch: 2/2, step 6813/7134 completed (loss: 0.009678372181952, acc: 0.997183084487915)
[2024-12-17 05:42:19,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:19,887][root][INFO] - Training Epoch: 2/2, step 6814/7134 completed (loss: 0.012732472270727158, acc: 0.9973118305206299)
[2024-12-17 05:42:20,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:20,319][root][INFO] - Training Epoch: 2/2, step 6815/7134 completed (loss: 0.034873347729444504, acc: 0.9934297204017639)
[2024-12-17 05:42:20,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:20,745][root][INFO] - Training Epoch: 2/2, step 6816/7134 completed (loss: 0.015437641181051731, acc: 0.9966555237770081)
[2024-12-17 05:42:20,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:21,198][root][INFO] - Training Epoch: 2/2, step 6817/7134 completed (loss: 0.04541439563035965, acc: 0.988034188747406)
[2024-12-17 05:42:21,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:21,628][root][INFO] - Training Epoch: 2/2, step 6818/7134 completed (loss: 0.01616799086332321, acc: 0.9925037622451782)
[2024-12-17 05:42:21,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:22,063][root][INFO] - Training Epoch: 2/2, step 6819/7134 completed (loss: 0.04000005125999451, acc: 0.9856114983558655)
[2024-12-17 05:42:22,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:22,479][root][INFO] - Training Epoch: 2/2, step 6820/7134 completed (loss: 0.015449886210262775, acc: 0.9963964223861694)
[2024-12-17 05:42:22,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:22,868][root][INFO] - Training Epoch: 2/2, step 6821/7134 completed (loss: 0.015560158528387547, acc: 0.9939393997192383)
[2024-12-17 05:42:22,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:23,294][root][INFO] - Training Epoch: 2/2, step 6822/7134 completed (loss: 0.042181678116321564, acc: 0.9860383868217468)
[2024-12-17 05:42:23,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:23,719][root][INFO] - Training Epoch: 2/2, step 6823/7134 completed (loss: 0.0351218618452549, acc: 0.9899857044219971)
[2024-12-17 05:42:23,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:24,104][root][INFO] - Training Epoch: 2/2, step 6824/7134 completed (loss: 0.06877600401639938, acc: 0.9798387289047241)
[2024-12-17 05:42:24,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:24,511][root][INFO] - Training Epoch: 2/2, step 6825/7134 completed (loss: 0.021626384928822517, acc: 0.997560977935791)
[2024-12-17 05:42:24,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:24,946][root][INFO] - Training Epoch: 2/2, step 6826/7134 completed (loss: 0.042566753923892975, acc: 0.9865319728851318)
[2024-12-17 05:42:25,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:25,377][root][INFO] - Training Epoch: 2/2, step 6827/7134 completed (loss: 0.09659769386053085, acc: 0.9793814420700073)
[2024-12-17 05:42:25,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:25,804][root][INFO] - Training Epoch: 2/2, step 6828/7134 completed (loss: 0.04723735898733139, acc: 0.985401451587677)
[2024-12-17 05:42:25,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:26,248][root][INFO] - Training Epoch: 2/2, step 6829/7134 completed (loss: 0.045664940029382706, acc: 0.9896142482757568)
[2024-12-17 05:42:26,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:26,656][root][INFO] - Training Epoch: 2/2, step 6830/7134 completed (loss: 0.025509189814329147, acc: 0.9917627573013306)
[2024-12-17 05:42:26,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:27,080][root][INFO] - Training Epoch: 2/2, step 6831/7134 completed (loss: 0.03809063881635666, acc: 0.9879032373428345)
[2024-12-17 05:42:27,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:27,490][root][INFO] - Training Epoch: 2/2, step 6832/7134 completed (loss: 0.027748899534344673, acc: 0.9926062822341919)
[2024-12-17 05:42:27,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:27,916][root][INFO] - Training Epoch: 2/2, step 6833/7134 completed (loss: 0.034196674823760986, acc: 0.9919614195823669)
[2024-12-17 05:42:28,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:28,285][root][INFO] - Training Epoch: 2/2, step 6834/7134 completed (loss: 0.0487426221370697, acc: 0.9880749583244324)
[2024-12-17 05:42:28,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:28,706][root][INFO] - Training Epoch: 2/2, step 6835/7134 completed (loss: 0.03577064722776413, acc: 0.9886363744735718)
[2024-12-17 05:42:28,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:29,133][root][INFO] - Training Epoch: 2/2, step 6836/7134 completed (loss: 0.03771379962563515, acc: 0.9886934757232666)
[2024-12-17 05:42:29,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:29,585][root][INFO] - Training Epoch: 2/2, step 6837/7134 completed (loss: 0.028721436858177185, acc: 0.9926380515098572)
[2024-12-17 05:42:29,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:29,996][root][INFO] - Training Epoch: 2/2, step 6838/7134 completed (loss: 0.07610245794057846, acc: 0.9843304753303528)
[2024-12-17 05:42:30,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:30,395][root][INFO] - Training Epoch: 2/2, step 6839/7134 completed (loss: 0.08415631949901581, acc: 0.9669967293739319)
[2024-12-17 05:42:30,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:30,820][root][INFO] - Training Epoch: 2/2, step 6840/7134 completed (loss: 0.07459244877099991, acc: 0.9756447076797485)
[2024-12-17 05:42:30,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:31,234][root][INFO] - Training Epoch: 2/2, step 6841/7134 completed (loss: 0.03249969333410263, acc: 0.9913420081138611)
[2024-12-17 05:42:31,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:31,686][root][INFO] - Training Epoch: 2/2, step 6842/7134 completed (loss: 0.026443423703312874, acc: 0.9899749159812927)
[2024-12-17 05:42:31,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:32,148][root][INFO] - Training Epoch: 2/2, step 6843/7134 completed (loss: 0.039458006620407104, acc: 0.9889025688171387)
[2024-12-17 05:42:32,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:32,565][root][INFO] - Training Epoch: 2/2, step 6844/7134 completed (loss: 0.02546616457402706, acc: 0.9913644194602966)
[2024-12-17 05:42:32,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:33,015][root][INFO] - Training Epoch: 2/2, step 6845/7134 completed (loss: 0.029193151742219925, acc: 0.9914966225624084)
[2024-12-17 05:42:33,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:33,434][root][INFO] - Training Epoch: 2/2, step 6846/7134 completed (loss: 0.024663368239998817, acc: 0.9942693114280701)
[2024-12-17 05:42:33,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:33,878][root][INFO] - Training Epoch: 2/2, step 6847/7134 completed (loss: 0.03282984718680382, acc: 0.989393949508667)
[2024-12-17 05:42:33,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:34,291][root][INFO] - Training Epoch: 2/2, step 6848/7134 completed (loss: 0.031860098242759705, acc: 0.9891892075538635)
[2024-12-17 05:42:34,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:34,729][root][INFO] - Training Epoch: 2/2, step 6849/7134 completed (loss: 0.033531296998262405, acc: 0.9914089441299438)
[2024-12-17 05:42:34,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:35,130][root][INFO] - Training Epoch: 2/2, step 6850/7134 completed (loss: 0.01979365199804306, acc: 0.9931350350379944)
[2024-12-17 05:42:35,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:35,561][root][INFO] - Training Epoch: 2/2, step 6851/7134 completed (loss: 0.04723839834332466, acc: 0.9873060584068298)
[2024-12-17 05:42:35,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:35,993][root][INFO] - Training Epoch: 2/2, step 6852/7134 completed (loss: 0.018416380509734154, acc: 0.996503472328186)
[2024-12-17 05:42:36,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:36,465][root][INFO] - Training Epoch: 2/2, step 6853/7134 completed (loss: 0.022737940773367882, acc: 0.9944674968719482)
[2024-12-17 05:42:36,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:36,872][root][INFO] - Training Epoch: 2/2, step 6854/7134 completed (loss: 0.027294320985674858, acc: 0.9934924244880676)
[2024-12-17 05:42:37,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:37,280][root][INFO] - Training Epoch: 2/2, step 6855/7134 completed (loss: 0.010555935092270374, acc: 0.9976415038108826)
[2024-12-17 05:42:37,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:37,748][root][INFO] - Training Epoch: 2/2, step 6856/7134 completed (loss: 0.006028429605066776, acc: 0.9985693693161011)
[2024-12-17 05:42:37,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:38,192][root][INFO] - Training Epoch: 2/2, step 6857/7134 completed (loss: 0.01725691743195057, acc: 0.9941349029541016)
[2024-12-17 05:42:38,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:38,574][root][INFO] - Training Epoch: 2/2, step 6858/7134 completed (loss: 0.004474588204175234, acc: 1.0)
[2024-12-17 05:42:38,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:39,024][root][INFO] - Training Epoch: 2/2, step 6859/7134 completed (loss: 0.008204909041523933, acc: 0.9974392056465149)
[2024-12-17 05:42:39,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:39,463][root][INFO] - Training Epoch: 2/2, step 6860/7134 completed (loss: 0.018800631165504456, acc: 0.9946808218955994)
[2024-12-17 05:42:39,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:39,893][root][INFO] - Training Epoch: 2/2, step 6861/7134 completed (loss: 0.01427663303911686, acc: 0.9982699155807495)
[2024-12-17 05:42:40,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:40,359][root][INFO] - Training Epoch: 2/2, step 6862/7134 completed (loss: 0.020748808979988098, acc: 0.9942857027053833)
[2024-12-17 05:42:40,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:40,801][root][INFO] - Training Epoch: 2/2, step 6863/7134 completed (loss: 0.01663815975189209, acc: 0.9957627058029175)
[2024-12-17 05:42:40,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:41,255][root][INFO] - Training Epoch: 2/2, step 6864/7134 completed (loss: 0.009165284223854542, acc: 0.9966722130775452)
[2024-12-17 05:42:41,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:41,695][root][INFO] - Training Epoch: 2/2, step 6865/7134 completed (loss: 0.03251069784164429, acc: 0.985567033290863)
[2024-12-17 05:42:41,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:42,123][root][INFO] - Training Epoch: 2/2, step 6866/7134 completed (loss: 0.008449430577456951, acc: 0.9984802603721619)
[2024-12-17 05:42:42,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:42,551][root][INFO] - Training Epoch: 2/2, step 6867/7134 completed (loss: 0.002114472910761833, acc: 1.0)
[2024-12-17 05:42:42,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:42,939][root][INFO] - Training Epoch: 2/2, step 6868/7134 completed (loss: 0.005351959262043238, acc: 0.9972299337387085)
[2024-12-17 05:42:43,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:43,346][root][INFO] - Training Epoch: 2/2, step 6869/7134 completed (loss: 0.0029516955837607384, acc: 1.0)
[2024-12-17 05:42:43,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:43,793][root][INFO] - Training Epoch: 2/2, step 6870/7134 completed (loss: 0.01428381260484457, acc: 0.9967426657676697)
[2024-12-17 05:42:43,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:44,247][root][INFO] - Training Epoch: 2/2, step 6871/7134 completed (loss: 0.004261537920683622, acc: 0.9981273412704468)
[2024-12-17 05:42:44,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:44,653][root][INFO] - Training Epoch: 2/2, step 6872/7134 completed (loss: 0.007293068338185549, acc: 0.9972299337387085)
[2024-12-17 05:42:44,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:45,094][root][INFO] - Training Epoch: 2/2, step 6873/7134 completed (loss: 0.02089133858680725, acc: 0.9915966391563416)
[2024-12-17 05:42:45,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:45,522][root][INFO] - Training Epoch: 2/2, step 6874/7134 completed (loss: 0.013094662688672543, acc: 0.9946808218955994)
[2024-12-17 05:42:45,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:45,951][root][INFO] - Training Epoch: 2/2, step 6875/7134 completed (loss: 0.015310545451939106, acc: 0.9938176274299622)
[2024-12-17 05:42:46,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:46,376][root][INFO] - Training Epoch: 2/2, step 6876/7134 completed (loss: 0.01621367409825325, acc: 0.9932318329811096)
[2024-12-17 05:42:46,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:46,819][root][INFO] - Training Epoch: 2/2, step 6877/7134 completed (loss: 0.015843166038393974, acc: 0.9943820238113403)
[2024-12-17 05:42:46,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:47,241][root][INFO] - Training Epoch: 2/2, step 6878/7134 completed (loss: 0.01149706356227398, acc: 0.995502233505249)
[2024-12-17 05:42:47,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:47,629][root][INFO] - Training Epoch: 2/2, step 6879/7134 completed (loss: 0.014174671843647957, acc: 0.991631805896759)
[2024-12-17 05:42:47,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:48,105][root][INFO] - Training Epoch: 2/2, step 6880/7134 completed (loss: 0.0058658793568611145, acc: 0.9976717233657837)
[2024-12-17 05:42:48,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:48,556][root][INFO] - Training Epoch: 2/2, step 6881/7134 completed (loss: 0.04342983663082123, acc: 0.9902794361114502)
[2024-12-17 05:42:48,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:48,952][root][INFO] - Training Epoch: 2/2, step 6882/7134 completed (loss: 0.0437215119600296, acc: 0.9830827116966248)
[2024-12-17 05:42:49,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:49,369][root][INFO] - Training Epoch: 2/2, step 6883/7134 completed (loss: 0.01966959796845913, acc: 0.9950494766235352)
[2024-12-17 05:42:49,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:49,818][root][INFO] - Training Epoch: 2/2, step 6884/7134 completed (loss: 0.036237917840480804, acc: 0.994962215423584)
[2024-12-17 05:42:49,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:50,217][root][INFO] - Training Epoch: 2/2, step 6885/7134 completed (loss: 0.05098909139633179, acc: 0.9888392686843872)
[2024-12-17 05:42:50,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:50,639][root][INFO] - Training Epoch: 2/2, step 6886/7134 completed (loss: 0.022420572116971016, acc: 0.9920760989189148)
[2024-12-17 05:42:50,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:51,067][root][INFO] - Training Epoch: 2/2, step 6887/7134 completed (loss: 0.028386568650603294, acc: 0.9897330403327942)
[2024-12-17 05:42:51,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:51,512][root][INFO] - Training Epoch: 2/2, step 6888/7134 completed (loss: 0.016307324171066284, acc: 0.9933554530143738)
[2024-12-17 05:42:51,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:51,952][root][INFO] - Training Epoch: 2/2, step 6889/7134 completed (loss: 0.007500442676246166, acc: 0.9984685778617859)
[2024-12-17 05:42:52,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:52,405][root][INFO] - Training Epoch: 2/2, step 6890/7134 completed (loss: 0.030019409954547882, acc: 0.9894319772720337)
[2024-12-17 05:42:52,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:52,825][root][INFO] - Training Epoch: 2/2, step 6891/7134 completed (loss: 0.019512800499796867, acc: 0.9925925731658936)
[2024-12-17 05:42:52,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:53,268][root][INFO] - Training Epoch: 2/2, step 6892/7134 completed (loss: 0.019567787647247314, acc: 0.9921875)
[2024-12-17 05:42:53,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:53,708][root][INFO] - Training Epoch: 2/2, step 6893/7134 completed (loss: 0.04857553169131279, acc: 0.9824766516685486)
[2024-12-17 05:42:53,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:54,153][root][INFO] - Training Epoch: 2/2, step 6894/7134 completed (loss: 0.048637259751558304, acc: 0.9868420958518982)
[2024-12-17 05:42:54,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:54,604][root][INFO] - Training Epoch: 2/2, step 6895/7134 completed (loss: 0.03588679060339928, acc: 0.9832134246826172)
[2024-12-17 05:42:54,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:55,020][root][INFO] - Training Epoch: 2/2, step 6896/7134 completed (loss: 0.019325891509652138, acc: 0.9898550510406494)
[2024-12-17 05:42:55,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:55,477][root][INFO] - Training Epoch: 2/2, step 6897/7134 completed (loss: 0.01737128011882305, acc: 0.9963189959526062)
[2024-12-17 05:42:55,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:55,889][root][INFO] - Training Epoch: 2/2, step 6898/7134 completed (loss: 0.011700529605150223, acc: 0.9972527623176575)
[2024-12-17 05:42:56,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:56,331][root][INFO] - Training Epoch: 2/2, step 6899/7134 completed (loss: 0.02994098886847496, acc: 0.9912060499191284)
[2024-12-17 05:42:56,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:56,798][root][INFO] - Training Epoch: 2/2, step 6900/7134 completed (loss: 0.03578512743115425, acc: 0.9900990128517151)
[2024-12-17 05:42:56,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:57,247][root][INFO] - Training Epoch: 2/2, step 6901/7134 completed (loss: 0.021560445427894592, acc: 0.9947159886360168)
[2024-12-17 05:42:57,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:57,706][root][INFO] - Training Epoch: 2/2, step 6902/7134 completed (loss: 0.022984879091382027, acc: 0.9916782379150391)
[2024-12-17 05:42:57,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:58,148][root][INFO] - Training Epoch: 2/2, step 6903/7134 completed (loss: 0.01445277500897646, acc: 0.9961977005004883)
[2024-12-17 05:42:58,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:58,606][root][INFO] - Training Epoch: 2/2, step 6904/7134 completed (loss: 0.014058268629014492, acc: 0.9950248599052429)
[2024-12-17 05:42:58,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:59,063][root][INFO] - Training Epoch: 2/2, step 6905/7134 completed (loss: 0.02045649290084839, acc: 0.9948849081993103)
[2024-12-17 05:42:59,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:59,535][root][INFO] - Training Epoch: 2/2, step 6906/7134 completed (loss: 0.03572792932391167, acc: 0.9928143620491028)
[2024-12-17 05:42:59,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:42:59,989][root][INFO] - Training Epoch: 2/2, step 6907/7134 completed (loss: 0.028116784989833832, acc: 0.9925558567047119)
[2024-12-17 05:43:00,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:00,447][root][INFO] - Training Epoch: 2/2, step 6908/7134 completed (loss: 0.01712939515709877, acc: 0.9935232996940613)
[2024-12-17 05:43:00,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:00,894][root][INFO] - Training Epoch: 2/2, step 6909/7134 completed (loss: 0.016722630709409714, acc: 0.9973683953285217)
[2024-12-17 05:43:01,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:01,332][root][INFO] - Training Epoch: 2/2, step 6910/7134 completed (loss: 0.01340271532535553, acc: 0.9949044585227966)
[2024-12-17 05:43:01,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:01,719][root][INFO] - Training Epoch: 2/2, step 6911/7134 completed (loss: 0.0430387407541275, acc: 0.9912790656089783)
[2024-12-17 05:43:01,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:02,163][root][INFO] - Training Epoch: 2/2, step 6912/7134 completed (loss: 0.024411626160144806, acc: 0.9962546825408936)
[2024-12-17 05:43:02,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:02,658][root][INFO] - Training Epoch: 2/2, step 6913/7134 completed (loss: 0.029544305056333542, acc: 0.9951279163360596)
[2024-12-17 05:43:02,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:03,084][root][INFO] - Training Epoch: 2/2, step 6914/7134 completed (loss: 0.07404429465532303, acc: 0.9865319728851318)
[2024-12-17 05:43:03,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:03,530][root][INFO] - Training Epoch: 2/2, step 6915/7134 completed (loss: 0.01172662153840065, acc: 0.9961140155792236)
[2024-12-17 05:43:03,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:03,997][root][INFO] - Training Epoch: 2/2, step 6916/7134 completed (loss: 0.02628730796277523, acc: 0.9950920343399048)
[2024-12-17 05:43:04,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:04,464][root][INFO] - Training Epoch: 2/2, step 6917/7134 completed (loss: 0.04500400274991989, acc: 0.9924242496490479)
[2024-12-17 05:43:04,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:04,894][root][INFO] - Training Epoch: 2/2, step 6918/7134 completed (loss: 0.026311371475458145, acc: 0.9871194362640381)
[2024-12-17 05:43:05,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:05,337][root][INFO] - Training Epoch: 2/2, step 6919/7134 completed (loss: 0.03024025820195675, acc: 0.9942330121994019)
[2024-12-17 05:43:05,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:05,745][root][INFO] - Training Epoch: 2/2, step 6920/7134 completed (loss: 0.010815802030265331, acc: 0.995726466178894)
[2024-12-17 05:43:05,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:06,205][root][INFO] - Training Epoch: 2/2, step 6921/7134 completed (loss: 0.04609939083456993, acc: 0.9896073937416077)
[2024-12-17 05:43:06,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:06,601][root][INFO] - Training Epoch: 2/2, step 6922/7134 completed (loss: 0.05006249621510506, acc: 0.9875195026397705)
[2024-12-17 05:43:06,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:07,049][root][INFO] - Training Epoch: 2/2, step 6923/7134 completed (loss: 0.04575946927070618, acc: 0.9883268475532532)
[2024-12-17 05:43:07,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:07,498][root][INFO] - Training Epoch: 2/2, step 6924/7134 completed (loss: 0.019344354048371315, acc: 0.9918256402015686)
[2024-12-17 05:43:07,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:07,927][root][INFO] - Training Epoch: 2/2, step 6925/7134 completed (loss: 0.018278108909726143, acc: 0.9973958134651184)
[2024-12-17 05:43:08,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:08,346][root][INFO] - Training Epoch: 2/2, step 6926/7134 completed (loss: 0.04035229608416557, acc: 0.9837251305580139)
[2024-12-17 05:43:08,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:08,798][root][INFO] - Training Epoch: 2/2, step 6927/7134 completed (loss: 0.03674191236495972, acc: 0.9904076457023621)
[2024-12-17 05:43:08,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:09,206][root][INFO] - Training Epoch: 2/2, step 6928/7134 completed (loss: 0.05471586063504219, acc: 0.9882583022117615)
[2024-12-17 05:43:09,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:09,703][root][INFO] - Training Epoch: 2/2, step 6929/7134 completed (loss: 0.05236523970961571, acc: 0.9872881174087524)
[2024-12-17 05:43:09,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:10,217][root][INFO] - Training Epoch: 2/2, step 6930/7134 completed (loss: 0.03065291792154312, acc: 0.9900744557380676)
[2024-12-17 05:43:10,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:10,690][root][INFO] - Training Epoch: 2/2, step 6931/7134 completed (loss: 0.028042005375027657, acc: 0.9890244007110596)
[2024-12-17 05:43:10,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:11,100][root][INFO] - Training Epoch: 2/2, step 6932/7134 completed (loss: 0.04812014475464821, acc: 0.9882352948188782)
[2024-12-17 05:43:11,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:11,533][root][INFO] - Training Epoch: 2/2, step 6933/7134 completed (loss: 0.06633296608924866, acc: 0.9883570671081543)
[2024-12-17 05:43:11,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:11,966][root][INFO] - Training Epoch: 2/2, step 6934/7134 completed (loss: 0.047970566898584366, acc: 0.9871588945388794)
[2024-12-17 05:43:12,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:12,430][root][INFO] - Training Epoch: 2/2, step 6935/7134 completed (loss: 0.04076775535941124, acc: 0.9934554696083069)
[2024-12-17 05:43:12,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:12,887][root][INFO] - Training Epoch: 2/2, step 6936/7134 completed (loss: 0.022138765081763268, acc: 0.9919999837875366)
[2024-12-17 05:43:13,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:13,312][root][INFO] - Training Epoch: 2/2, step 6937/7134 completed (loss: 0.08382362127304077, acc: 0.9789842367172241)
[2024-12-17 05:43:13,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:13,773][root][INFO] - Training Epoch: 2/2, step 6938/7134 completed (loss: 0.07499444484710693, acc: 0.981249988079071)
[2024-12-17 05:43:13,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:14,244][root][INFO] - Training Epoch: 2/2, step 6939/7134 completed (loss: 0.0770910233259201, acc: 0.9819193482398987)
[2024-12-17 05:43:14,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:14,649][root][INFO] - Training Epoch: 2/2, step 6940/7134 completed (loss: 0.071451336145401, acc: 0.9811643958091736)
[2024-12-17 05:43:14,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:15,050][root][INFO] - Training Epoch: 2/2, step 6941/7134 completed (loss: 0.024082239717245102, acc: 0.9965277910232544)
[2024-12-17 05:43:15,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:15,465][root][INFO] - Training Epoch: 2/2, step 6942/7134 completed (loss: 0.03878643736243248, acc: 0.9917808175086975)
[2024-12-17 05:43:15,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:15,861][root][INFO] - Training Epoch: 2/2, step 6943/7134 completed (loss: 0.04979695379734039, acc: 0.9874476790428162)
[2024-12-17 05:43:16,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:16,282][root][INFO] - Training Epoch: 2/2, step 6944/7134 completed (loss: 0.03157549723982811, acc: 0.9920381903648376)
[2024-12-17 05:43:16,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:16,673][root][INFO] - Training Epoch: 2/2, step 6945/7134 completed (loss: 0.06147332862019539, acc: 0.9860383868217468)
[2024-12-17 05:43:16,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:17,072][root][INFO] - Training Epoch: 2/2, step 6946/7134 completed (loss: 0.021504666656255722, acc: 0.9942693114280701)
[2024-12-17 05:43:17,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:17,496][root][INFO] - Training Epoch: 2/2, step 6947/7134 completed (loss: 0.025339340791106224, acc: 0.991304337978363)
[2024-12-17 05:43:17,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:17,955][root][INFO] - Training Epoch: 2/2, step 6948/7134 completed (loss: 0.03333231061697006, acc: 0.9882746934890747)
[2024-12-17 05:43:18,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:18,362][root][INFO] - Training Epoch: 2/2, step 6949/7134 completed (loss: 0.034236788749694824, acc: 0.9893162250518799)
[2024-12-17 05:43:18,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:18,801][root][INFO] - Training Epoch: 2/2, step 6950/7134 completed (loss: 0.027324730530381203, acc: 0.9948979616165161)
[2024-12-17 05:43:18,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:19,230][root][INFO] - Training Epoch: 2/2, step 6951/7134 completed (loss: 0.020616302266716957, acc: 0.993220329284668)
[2024-12-17 05:43:19,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:19,621][root][INFO] - Training Epoch: 2/2, step 6952/7134 completed (loss: 0.018807468935847282, acc: 0.9929906725883484)
[2024-12-17 05:43:19,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:20,035][root][INFO] - Training Epoch: 2/2, step 6953/7134 completed (loss: 0.011610710062086582, acc: 1.0)
[2024-12-17 05:43:20,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:20,453][root][INFO] - Training Epoch: 2/2, step 6954/7134 completed (loss: 0.05423906445503235, acc: 0.9850746393203735)
[2024-12-17 05:43:20,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:20,839][root][INFO] - Training Epoch: 2/2, step 6955/7134 completed (loss: 0.02804812230169773, acc: 0.9939024448394775)
[2024-12-17 05:43:20,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:21,256][root][INFO] - Training Epoch: 2/2, step 6956/7134 completed (loss: 0.030338304117321968, acc: 0.9928951859474182)
[2024-12-17 05:43:21,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:21,660][root][INFO] - Training Epoch: 2/2, step 6957/7134 completed (loss: 0.012617705389857292, acc: 0.9960861206054688)
[2024-12-17 05:43:21,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:22,058][root][INFO] - Training Epoch: 2/2, step 6958/7134 completed (loss: 0.055380068719387054, acc: 0.9863547682762146)
[2024-12-17 05:43:22,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:22,458][root][INFO] - Training Epoch: 2/2, step 6959/7134 completed (loss: 0.037955719977617264, acc: 0.9866962432861328)
[2024-12-17 05:43:22,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:22,868][root][INFO] - Training Epoch: 2/2, step 6960/7134 completed (loss: 0.03223663195967674, acc: 0.9886178970336914)
[2024-12-17 05:43:22,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:23,270][root][INFO] - Training Epoch: 2/2, step 6961/7134 completed (loss: 0.02751251682639122, acc: 0.9959595799446106)
[2024-12-17 05:43:23,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:23,679][root][INFO] - Training Epoch: 2/2, step 6962/7134 completed (loss: 0.024892844259738922, acc: 0.9947826266288757)
[2024-12-17 05:43:23,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:24,096][root][INFO] - Training Epoch: 2/2, step 6963/7134 completed (loss: 0.022913923487067223, acc: 0.9949495196342468)
[2024-12-17 05:43:24,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:24,516][root][INFO] - Training Epoch: 2/2, step 6964/7134 completed (loss: 0.01516397763043642, acc: 0.994584858417511)
[2024-12-17 05:43:24,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:24,938][root][INFO] - Training Epoch: 2/2, step 6965/7134 completed (loss: 0.01581457443535328, acc: 0.9963369965553284)
[2024-12-17 05:43:25,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:25,315][root][INFO] - Training Epoch: 2/2, step 6966/7134 completed (loss: 0.046724509447813034, acc: 0.9825436472892761)
[2024-12-17 05:43:25,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:25,740][root][INFO] - Training Epoch: 2/2, step 6967/7134 completed (loss: 0.01565479300916195, acc: 0.9909502267837524)
[2024-12-17 05:43:25,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:26,139][root][INFO] - Training Epoch: 2/2, step 6968/7134 completed (loss: 0.03335104510188103, acc: 0.9913793206214905)
[2024-12-17 05:43:26,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:26,547][root][INFO] - Training Epoch: 2/2, step 6969/7134 completed (loss: 0.07554484158754349, acc: 0.9792099595069885)
[2024-12-17 05:43:26,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:26,958][root][INFO] - Training Epoch: 2/2, step 6970/7134 completed (loss: 0.06587480008602142, acc: 0.9831578731536865)
[2024-12-17 05:43:27,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:27,385][root][INFO] - Training Epoch: 2/2, step 6971/7134 completed (loss: 0.05199876427650452, acc: 0.9861830472946167)
[2024-12-17 05:43:27,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:27,827][root][INFO] - Training Epoch: 2/2, step 6972/7134 completed (loss: 0.01264419686049223, acc: 0.9964349269866943)
[2024-12-17 05:43:27,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:28,253][root][INFO] - Training Epoch: 2/2, step 6973/7134 completed (loss: 0.03759664669632912, acc: 0.9911894202232361)
[2024-12-17 05:43:28,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:28,676][root][INFO] - Training Epoch: 2/2, step 6974/7134 completed (loss: 0.036237116903066635, acc: 0.9896551966667175)
[2024-12-17 05:43:28,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:29,095][root][INFO] - Training Epoch: 2/2, step 6975/7134 completed (loss: 0.031453125178813934, acc: 0.9956616163253784)
[2024-12-17 05:43:29,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:29,530][root][INFO] - Training Epoch: 2/2, step 6976/7134 completed (loss: 0.036382921040058136, acc: 0.9861351847648621)
[2024-12-17 05:43:29,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:29,939][root][INFO] - Training Epoch: 2/2, step 6977/7134 completed (loss: 0.02879944071173668, acc: 0.9906014800071716)
[2024-12-17 05:43:30,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:30,359][root][INFO] - Training Epoch: 2/2, step 6978/7134 completed (loss: 0.02290193736553192, acc: 0.9918699264526367)
[2024-12-17 05:43:30,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:30,806][root][INFO] - Training Epoch: 2/2, step 6979/7134 completed (loss: 0.03950375318527222, acc: 0.9817073345184326)
[2024-12-17 05:43:30,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:31,269][root][INFO] - Training Epoch: 2/2, step 6980/7134 completed (loss: 0.09526658803224564, acc: 0.9710691571235657)
[2024-12-17 05:43:31,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:31,730][root][INFO] - Training Epoch: 2/2, step 6981/7134 completed (loss: 0.08561159670352936, acc: 0.9757343530654907)
[2024-12-17 05:43:31,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:32,205][root][INFO] - Training Epoch: 2/2, step 6982/7134 completed (loss: 0.07330137491226196, acc: 0.9792935252189636)
[2024-12-17 05:43:32,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:32,665][root][INFO] - Training Epoch: 2/2, step 6983/7134 completed (loss: 0.08965575695037842, acc: 0.9792284965515137)
[2024-12-17 05:43:32,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:33,124][root][INFO] - Training Epoch: 2/2, step 6984/7134 completed (loss: 0.03436484560370445, acc: 0.9935691356658936)
[2024-12-17 05:43:33,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:33,606][root][INFO] - Training Epoch: 2/2, step 6985/7134 completed (loss: 0.09584807604551315, acc: 0.9774358868598938)
[2024-12-17 05:43:33,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:34,039][root][INFO] - Training Epoch: 2/2, step 6986/7134 completed (loss: 0.03276711702346802, acc: 0.9881129264831543)
[2024-12-17 05:43:34,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:34,524][root][INFO] - Training Epoch: 2/2, step 6987/7134 completed (loss: 0.055638283491134644, acc: 0.9828282594680786)
[2024-12-17 05:43:34,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:34,863][root][INFO] - Training Epoch: 2/2, step 6988/7134 completed (loss: 0.025475988164544106, acc: 0.9960238337516785)
[2024-12-17 05:43:34,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:35,270][root][INFO] - Training Epoch: 2/2, step 6989/7134 completed (loss: 0.034996096044778824, acc: 0.9854545593261719)
[2024-12-17 05:43:35,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:35,663][root][INFO] - Training Epoch: 2/2, step 6990/7134 completed (loss: 0.010641795583069324, acc: 1.0)
[2024-12-17 05:43:35,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:36,029][root][INFO] - Training Epoch: 2/2, step 6991/7134 completed (loss: 0.0672912672162056, acc: 0.9874686598777771)
[2024-12-17 05:43:36,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:36,418][root][INFO] - Training Epoch: 2/2, step 6992/7134 completed (loss: 0.04921707510948181, acc: 0.9873684048652649)
[2024-12-17 05:43:36,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:36,849][root][INFO] - Training Epoch: 2/2, step 6993/7134 completed (loss: 0.09055409580469131, acc: 0.9819004535675049)
[2024-12-17 05:43:36,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:37,323][root][INFO] - Training Epoch: 2/2, step 6994/7134 completed (loss: 0.10864225775003433, acc: 0.9743177890777588)
[2024-12-17 05:43:37,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:37,767][root][INFO] - Training Epoch: 2/2, step 6995/7134 completed (loss: 0.035195812582969666, acc: 0.9908376932144165)
[2024-12-17 05:43:37,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:38,187][root][INFO] - Training Epoch: 2/2, step 6996/7134 completed (loss: 0.028177905827760696, acc: 0.9918830990791321)
[2024-12-17 05:43:38,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:38,623][root][INFO] - Training Epoch: 2/2, step 6997/7134 completed (loss: 0.04243951290845871, acc: 0.9844236969947815)
[2024-12-17 05:43:38,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:38,974][root][INFO] - Training Epoch: 2/2, step 6998/7134 completed (loss: 0.06373252719640732, acc: 0.9828431606292725)
[2024-12-17 05:43:39,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:39,444][root][INFO] - Training Epoch: 2/2, step 6999/7134 completed (loss: 0.02137698233127594, acc: 0.9921568632125854)
[2024-12-17 05:43:39,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:39,801][root][INFO] - Training Epoch: 2/2, step 7000/7134 completed (loss: 0.023602088913321495, acc: 0.9936440587043762)
[2024-12-17 05:43:39,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:40,270][root][INFO] - Training Epoch: 2/2, step 7001/7134 completed (loss: 0.07401417195796967, acc: 0.9864457845687866)
[2024-12-17 05:43:40,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:40,719][root][INFO] - Training Epoch: 2/2, step 7002/7134 completed (loss: 0.014583253301680088, acc: 0.9979715943336487)
[2024-12-17 05:43:40,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:41,164][root][INFO] - Training Epoch: 2/2, step 7003/7134 completed (loss: 0.011640161275863647, acc: 0.9956188201904297)
[2024-12-17 05:43:41,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:41,625][root][INFO] - Training Epoch: 2/2, step 7004/7134 completed (loss: 0.07011191546916962, acc: 0.9829396605491638)
[2024-12-17 05:43:41,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:42,088][root][INFO] - Training Epoch: 2/2, step 7005/7134 completed (loss: 0.03728882968425751, acc: 0.9892037510871887)
[2024-12-17 05:43:42,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:42,556][root][INFO] - Training Epoch: 2/2, step 7006/7134 completed (loss: 0.0395563468337059, acc: 0.9904240965843201)
[2024-12-17 05:43:42,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:43,014][root][INFO] - Training Epoch: 2/2, step 7007/7134 completed (loss: 0.03140174597501755, acc: 0.9895209670066833)
[2024-12-17 05:43:43,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:43,448][root][INFO] - Training Epoch: 2/2, step 7008/7134 completed (loss: 0.033147022128105164, acc: 0.9901356101036072)
[2024-12-17 05:43:43,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:43,902][root][INFO] - Training Epoch: 2/2, step 7009/7134 completed (loss: 0.028100285679101944, acc: 0.9918981194496155)
[2024-12-17 05:43:44,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:44,320][root][INFO] - Training Epoch: 2/2, step 7010/7134 completed (loss: 0.015181226655840874, acc: 0.9953774809837341)
[2024-12-17 05:43:44,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:44,782][root][INFO] - Training Epoch: 2/2, step 7011/7134 completed (loss: 0.017564553767442703, acc: 0.9915865659713745)
[2024-12-17 05:43:44,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:45,212][root][INFO] - Training Epoch: 2/2, step 7012/7134 completed (loss: 0.02289826236665249, acc: 0.9941691160202026)
[2024-12-17 05:43:45,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:45,658][root][INFO] - Training Epoch: 2/2, step 7013/7134 completed (loss: 0.00993794109672308, acc: 0.9985590577125549)
[2024-12-17 05:43:45,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:46,097][root][INFO] - Training Epoch: 2/2, step 7014/7134 completed (loss: 0.029120957478880882, acc: 0.9935587644577026)
[2024-12-17 05:43:46,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:46,510][root][INFO] - Training Epoch: 2/2, step 7015/7134 completed (loss: 0.02626391500234604, acc: 0.9874776601791382)
[2024-12-17 05:43:46,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:46,969][root][INFO] - Training Epoch: 2/2, step 7016/7134 completed (loss: 0.04403530806303024, acc: 0.9812138676643372)
[2024-12-17 05:43:47,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:47,360][root][INFO] - Training Epoch: 2/2, step 7017/7134 completed (loss: 0.04953267425298691, acc: 0.9834024906158447)
[2024-12-17 05:43:47,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:47,795][root][INFO] - Training Epoch: 2/2, step 7018/7134 completed (loss: 0.045203063637018204, acc: 0.9937984347343445)
[2024-12-17 05:43:47,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:48,207][root][INFO] - Training Epoch: 2/2, step 7019/7134 completed (loss: 0.1134793683886528, acc: 0.9722222089767456)
[2024-12-17 05:43:48,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:48,624][root][INFO] - Training Epoch: 2/2, step 7020/7134 completed (loss: 0.020137183368206024, acc: 0.995768666267395)
[2024-12-17 05:43:48,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:49,101][root][INFO] - Training Epoch: 2/2, step 7021/7134 completed (loss: 0.03521234169602394, acc: 0.991482138633728)
[2024-12-17 05:43:49,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:49,498][root][INFO] - Training Epoch: 2/2, step 7022/7134 completed (loss: 0.07756282389163971, acc: 0.9845678806304932)
[2024-12-17 05:43:49,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:49,886][root][INFO] - Training Epoch: 2/2, step 7023/7134 completed (loss: 0.07658662647008896, acc: 0.9809069037437439)
[2024-12-17 05:43:49,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:50,247][root][INFO] - Training Epoch: 2/2, step 7024/7134 completed (loss: 0.030951187014579773, acc: 0.9904458522796631)
[2024-12-17 05:43:50,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:50,631][root][INFO] - Training Epoch: 2/2, step 7025/7134 completed (loss: 0.12272529304027557, acc: 0.9655172228813171)
[2024-12-17 05:43:50,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:51,018][root][INFO] - Training Epoch: 2/2, step 7026/7134 completed (loss: 0.07458053529262543, acc: 0.9729729890823364)
[2024-12-17 05:43:51,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:51,392][root][INFO] - Training Epoch: 2/2, step 7027/7134 completed (loss: 0.050185464322566986, acc: 0.9847561120986938)
[2024-12-17 05:43:51,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:51,786][root][INFO] - Training Epoch: 2/2, step 7028/7134 completed (loss: 0.0315396711230278, acc: 0.9878934621810913)
[2024-12-17 05:43:51,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:52,158][root][INFO] - Training Epoch: 2/2, step 7029/7134 completed (loss: 0.024170156568288803, acc: 0.9953595995903015)
[2024-12-17 05:43:52,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:52,551][root][INFO] - Training Epoch: 2/2, step 7030/7134 completed (loss: 0.08829642087221146, acc: 0.971563994884491)
[2024-12-17 05:43:52,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:52,931][root][INFO] - Training Epoch: 2/2, step 7031/7134 completed (loss: 0.07028257101774216, acc: 0.9720812439918518)
[2024-12-17 05:43:53,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:53,334][root][INFO] - Training Epoch: 2/2, step 7032/7134 completed (loss: 0.03817133232951164, acc: 0.9918699264526367)
[2024-12-17 05:43:53,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:53,745][root][INFO] - Training Epoch: 2/2, step 7033/7134 completed (loss: 0.04077260196208954, acc: 0.9853372573852539)
[2024-12-17 05:43:53,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:54,139][root][INFO] - Training Epoch: 2/2, step 7034/7134 completed (loss: 0.06272171437740326, acc: 0.9858657121658325)
[2024-12-17 05:43:54,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:54,534][root][INFO] - Training Epoch: 2/2, step 7035/7134 completed (loss: 0.09616461396217346, acc: 0.9801587462425232)
[2024-12-17 05:43:54,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:54,901][root][INFO] - Training Epoch: 2/2, step 7036/7134 completed (loss: 0.02830718830227852, acc: 0.991769552230835)
[2024-12-17 05:43:55,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:55,231][root][INFO] - Training Epoch: 2/2, step 7037/7134 completed (loss: 0.027099043130874634, acc: 0.9921875)
[2024-12-17 05:43:55,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:55,596][root][INFO] - Training Epoch: 2/2, step 7038/7134 completed (loss: 0.09668458998203278, acc: 0.9788918495178223)
[2024-12-17 05:43:55,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:55,975][root][INFO] - Training Epoch: 2/2, step 7039/7134 completed (loss: 0.03752276673913002, acc: 0.9855072498321533)
[2024-12-17 05:43:56,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:56,346][root][INFO] - Training Epoch: 2/2, step 7040/7134 completed (loss: 0.07945006340742111, acc: 0.977011501789093)
[2024-12-17 05:43:56,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:56,752][root][INFO] - Training Epoch: 2/2, step 7041/7134 completed (loss: 0.09791532903909683, acc: 0.9685534834861755)
[2024-12-17 05:43:56,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:57,154][root][INFO] - Training Epoch: 2/2, step 7042/7134 completed (loss: 0.04912740737199783, acc: 0.9784615635871887)
[2024-12-17 05:43:57,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:57,528][root][INFO] - Training Epoch: 2/2, step 7043/7134 completed (loss: 0.07433943450450897, acc: 0.984000027179718)
[2024-12-17 05:43:57,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:57,907][root][INFO] - Training Epoch: 2/2, step 7044/7134 completed (loss: 0.07649046927690506, acc: 0.9755351543426514)
[2024-12-17 05:43:58,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:58,347][root][INFO] - Training Epoch: 2/2, step 7045/7134 completed (loss: 0.03175400570034981, acc: 0.9863945841789246)
[2024-12-17 05:43:58,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:58,798][root][INFO] - Training Epoch: 2/2, step 7046/7134 completed (loss: 0.0646776631474495, acc: 0.9822404384613037)
[2024-12-17 05:43:58,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:59,236][root][INFO] - Training Epoch: 2/2, step 7047/7134 completed (loss: 0.05898723006248474, acc: 0.9809523820877075)
[2024-12-17 05:43:59,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:43:59,676][root][INFO] - Training Epoch: 2/2, step 7048/7134 completed (loss: 0.0051691667176783085, acc: 0.9988248944282532)
[2024-12-17 05:43:59,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:00,088][root][INFO] - Training Epoch: 2/2, step 7049/7134 completed (loss: 0.027561746537685394, acc: 0.9933155179023743)
[2024-12-17 05:44:00,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:00,522][root][INFO] - Training Epoch: 2/2, step 7050/7134 completed (loss: 0.02746737003326416, acc: 0.9961140155792236)
[2024-12-17 05:44:00,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:00,977][root][INFO] - Training Epoch: 2/2, step 7051/7134 completed (loss: 0.038324952125549316, acc: 0.9898862242698669)
[2024-12-17 05:44:01,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:01,429][root][INFO] - Training Epoch: 2/2, step 7052/7134 completed (loss: 0.033107906579971313, acc: 0.9880159497261047)
[2024-12-17 05:44:01,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:01,884][root][INFO] - Training Epoch: 2/2, step 7053/7134 completed (loss: 0.02786298096179962, acc: 0.9926918148994446)
[2024-12-17 05:44:02,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:02,341][root][INFO] - Training Epoch: 2/2, step 7054/7134 completed (loss: 0.06653153151273727, acc: 0.9841772317886353)
[2024-12-17 05:44:02,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:02,771][root][INFO] - Training Epoch: 2/2, step 7055/7134 completed (loss: 0.031121866777539253, acc: 0.9885203838348389)
[2024-12-17 05:44:02,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:03,245][root][INFO] - Training Epoch: 2/2, step 7056/7134 completed (loss: 0.03840550035238266, acc: 0.989195704460144)
[2024-12-17 05:44:03,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:03,715][root][INFO] - Training Epoch: 2/2, step 7057/7134 completed (loss: 0.11582130193710327, acc: 0.9767123460769653)
[2024-12-17 05:44:03,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:04,143][root][INFO] - Training Epoch: 2/2, step 7058/7134 completed (loss: 0.05425988510251045, acc: 0.9842519760131836)
[2024-12-17 05:44:04,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:04,577][root][INFO] - Training Epoch: 2/2, step 7059/7134 completed (loss: 0.01190311647951603, acc: 0.9958100318908691)
[2024-12-17 05:44:04,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:04,994][root][INFO] - Training Epoch: 2/2, step 7060/7134 completed (loss: 0.04809572175145149, acc: 0.9854838848114014)
[2024-12-17 05:44:05,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:05,433][root][INFO] - Training Epoch: 2/2, step 7061/7134 completed (loss: 0.04429691657423973, acc: 0.9895833134651184)
[2024-12-17 05:44:05,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:05,844][root][INFO] - Training Epoch: 2/2, step 7062/7134 completed (loss: 0.07361172884702682, acc: 0.9822221994400024)
[2024-12-17 05:44:05,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:06,295][root][INFO] - Training Epoch: 2/2, step 7063/7134 completed (loss: 0.06919892132282257, acc: 0.9882352948188782)
[2024-12-17 05:44:06,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:06,759][root][INFO] - Training Epoch: 2/2, step 7064/7134 completed (loss: 0.027076469734311104, acc: 0.9925816059112549)
[2024-12-17 05:44:06,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:07,209][root][INFO] - Training Epoch: 2/2, step 7065/7134 completed (loss: 0.016496850177645683, acc: 0.9942062497138977)
[2024-12-17 05:44:07,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:07,671][root][INFO] - Training Epoch: 2/2, step 7066/7134 completed (loss: 0.02607351914048195, acc: 0.9940546751022339)
[2024-12-17 05:44:07,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:08,113][root][INFO] - Training Epoch: 2/2, step 7067/7134 completed (loss: 0.03567712754011154, acc: 0.9847133755683899)
[2024-12-17 05:44:08,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:08,577][root][INFO] - Training Epoch: 2/2, step 7068/7134 completed (loss: 0.023911628872156143, acc: 0.9915561079978943)
[2024-12-17 05:44:08,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:09,057][root][INFO] - Training Epoch: 2/2, step 7069/7134 completed (loss: 0.02031715400516987, acc: 0.9960552453994751)
[2024-12-17 05:44:09,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:09,503][root][INFO] - Training Epoch: 2/2, step 7070/7134 completed (loss: 0.027670934796333313, acc: 0.9931412935256958)
[2024-12-17 05:44:09,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:09,953][root][INFO] - Training Epoch: 2/2, step 7071/7134 completed (loss: 0.05155178904533386, acc: 0.9906014800071716)
[2024-12-17 05:44:10,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:10,397][root][INFO] - Training Epoch: 2/2, step 7072/7134 completed (loss: 0.01837153173983097, acc: 0.9951515197753906)
[2024-12-17 05:44:10,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:10,888][root][INFO] - Training Epoch: 2/2, step 7073/7134 completed (loss: 0.02793564274907112, acc: 0.9920364022254944)
[2024-12-17 05:44:11,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:11,283][root][INFO] - Training Epoch: 2/2, step 7074/7134 completed (loss: 0.033283814787864685, acc: 0.990439772605896)
[2024-12-17 05:44:11,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:11,716][root][INFO] - Training Epoch: 2/2, step 7075/7134 completed (loss: 0.023182593286037445, acc: 0.9895366430282593)
[2024-12-17 05:44:11,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:12,125][root][INFO] - Training Epoch: 2/2, step 7076/7134 completed (loss: 0.037640754133462906, acc: 0.9914529919624329)
[2024-12-17 05:44:12,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:12,533][root][INFO] - Training Epoch: 2/2, step 7077/7134 completed (loss: 0.03910389542579651, acc: 0.9852458834648132)
[2024-12-17 05:44:12,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:12,957][root][INFO] - Training Epoch: 2/2, step 7078/7134 completed (loss: 0.02258438616991043, acc: 0.9935897588729858)
[2024-12-17 05:44:13,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:13,354][root][INFO] - Training Epoch: 2/2, step 7079/7134 completed (loss: 0.024190176278352737, acc: 0.9917898178100586)
[2024-12-17 05:44:13,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:13,751][root][INFO] - Training Epoch: 2/2, step 7080/7134 completed (loss: 0.030044754967093468, acc: 0.9900332093238831)
[2024-12-17 05:44:13,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:14,196][root][INFO] - Training Epoch: 2/2, step 7081/7134 completed (loss: 0.029014794155955315, acc: 0.9901823401451111)
[2024-12-17 05:44:14,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:14,626][root][INFO] - Training Epoch: 2/2, step 7082/7134 completed (loss: 0.06404030323028564, acc: 0.9838449358940125)
[2024-12-17 05:44:14,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:15,050][root][INFO] - Training Epoch: 2/2, step 7083/7134 completed (loss: 0.019046425819396973, acc: 0.9933110475540161)
[2024-12-17 05:44:15,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:15,486][root][INFO] - Training Epoch: 2/2, step 7084/7134 completed (loss: 0.0363028310239315, acc: 0.9883889555931091)
[2024-12-17 05:44:15,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:15,905][root][INFO] - Training Epoch: 2/2, step 7085/7134 completed (loss: 0.03522774204611778, acc: 0.9922839403152466)
[2024-12-17 05:44:16,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:16,351][root][INFO] - Training Epoch: 2/2, step 7086/7134 completed (loss: 0.02264193259179592, acc: 0.99589604139328)
[2024-12-17 05:44:16,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:16,754][root][INFO] - Training Epoch: 2/2, step 7087/7134 completed (loss: 0.045992493629455566, acc: 0.9944547414779663)
[2024-12-17 05:44:16,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:17,177][root][INFO] - Training Epoch: 2/2, step 7088/7134 completed (loss: 0.039386503398418427, acc: 0.9917218685150146)
[2024-12-17 05:44:17,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:17,592][root][INFO] - Training Epoch: 2/2, step 7089/7134 completed (loss: 0.09464652836322784, acc: 0.9808917045593262)
[2024-12-17 05:44:17,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:18,032][root][INFO] - Training Epoch: 2/2, step 7090/7134 completed (loss: 0.026604872196912766, acc: 0.9959349632263184)
[2024-12-17 05:44:18,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:18,454][root][INFO] - Training Epoch: 2/2, step 7091/7134 completed (loss: 0.007524401880800724, acc: 0.9986072182655334)
[2024-12-17 05:44:18,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:18,897][root][INFO] - Training Epoch: 2/2, step 7092/7134 completed (loss: 0.029190754517912865, acc: 0.989708423614502)
[2024-12-17 05:44:19,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:19,313][root][INFO] - Training Epoch: 2/2, step 7093/7134 completed (loss: 0.03407115116715431, acc: 0.9861111044883728)
[2024-12-17 05:44:19,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:19,741][root][INFO] - Training Epoch: 2/2, step 7094/7134 completed (loss: 0.01259039156138897, acc: 0.9953917264938354)
[2024-12-17 05:44:19,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:20,182][root][INFO] - Training Epoch: 2/2, step 7095/7134 completed (loss: 0.03456030786037445, acc: 0.9958677887916565)
[2024-12-17 05:44:20,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:20,613][root][INFO] - Training Epoch: 2/2, step 7096/7134 completed (loss: 0.05059118568897247, acc: 0.9882352948188782)
[2024-12-17 05:44:20,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:21,052][root][INFO] - Training Epoch: 2/2, step 7097/7134 completed (loss: 0.04292650520801544, acc: 0.9855907559394836)
[2024-12-17 05:44:21,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:21,482][root][INFO] - Training Epoch: 2/2, step 7098/7134 completed (loss: 0.02013786882162094, acc: 0.9919742941856384)
[2024-12-17 05:44:21,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:21,867][root][INFO] - Training Epoch: 2/2, step 7099/7134 completed (loss: 0.04297913983464241, acc: 0.988034188747406)
[2024-12-17 05:44:21,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:22,291][root][INFO] - Training Epoch: 2/2, step 7100/7134 completed (loss: 0.060544829815626144, acc: 0.9813953638076782)
[2024-12-17 05:44:22,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:22,677][root][INFO] - Training Epoch: 2/2, step 7101/7134 completed (loss: 0.06456809490919113, acc: 0.9856887459754944)
[2024-12-17 05:44:22,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:23,107][root][INFO] - Training Epoch: 2/2, step 7102/7134 completed (loss: 0.01284580398350954, acc: 0.9961240291595459)
[2024-12-17 05:44:23,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:23,464][root][INFO] - Training Epoch: 2/2, step 7103/7134 completed (loss: 0.028342144563794136, acc: 0.9959677457809448)
[2024-12-17 05:44:23,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:23,894][root][INFO] - Training Epoch: 2/2, step 7104/7134 completed (loss: 0.039510007947683334, acc: 0.9938271641731262)
[2024-12-17 05:44:24,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:24,303][root][INFO] - Training Epoch: 2/2, step 7105/7134 completed (loss: 0.02641366608440876, acc: 0.9900000095367432)
[2024-12-17 05:44:24,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:24,691][root][INFO] - Training Epoch: 2/2, step 7106/7134 completed (loss: 0.012937705032527447, acc: 0.9983305335044861)
[2024-12-17 05:44:24,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:25,103][root][INFO] - Training Epoch: 2/2, step 7107/7134 completed (loss: 0.02008327841758728, acc: 0.9937888383865356)
[2024-12-17 05:44:25,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:25,515][root][INFO] - Training Epoch: 2/2, step 7108/7134 completed (loss: 0.03498024120926857, acc: 0.9950000047683716)
[2024-12-17 05:44:25,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:25,902][root][INFO] - Training Epoch: 2/2, step 7109/7134 completed (loss: 0.04683918505907059, acc: 0.9887429475784302)
[2024-12-17 05:44:26,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:26,325][root][INFO] - Training Epoch: 2/2, step 7110/7134 completed (loss: 0.03005659393966198, acc: 0.991525411605835)
[2024-12-17 05:44:26,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:26,682][root][INFO] - Training Epoch: 2/2, step 7111/7134 completed (loss: 0.03825095668435097, acc: 0.9911308288574219)
[2024-12-17 05:44:26,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:27,123][root][INFO] - Training Epoch: 2/2, step 7112/7134 completed (loss: 0.029340770095586777, acc: 0.9876543283462524)
[2024-12-17 05:44:27,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:27,574][root][INFO] - Training Epoch: 2/2, step 7113/7134 completed (loss: 0.06607666611671448, acc: 0.9763407111167908)
[2024-12-17 05:44:27,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:28,000][root][INFO] - Training Epoch: 2/2, step 7114/7134 completed (loss: 0.03825175762176514, acc: 0.9866156578063965)
[2024-12-17 05:44:28,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:28,423][root][INFO] - Training Epoch: 2/2, step 7115/7134 completed (loss: 0.027068281546235085, acc: 0.9876543283462524)
[2024-12-17 05:44:28,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:28,838][root][INFO] - Training Epoch: 2/2, step 7116/7134 completed (loss: 0.024164732545614243, acc: 0.9929701089859009)
[2024-12-17 05:44:28,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:29,235][root][INFO] - Training Epoch: 2/2, step 7117/7134 completed (loss: 0.022233646363019943, acc: 0.9950000047683716)
[2024-12-17 05:44:29,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:29,661][root][INFO] - Training Epoch: 2/2, step 7118/7134 completed (loss: 0.04511133208870888, acc: 0.9898256063461304)
[2024-12-17 05:44:29,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:30,066][root][INFO] - Training Epoch: 2/2, step 7119/7134 completed (loss: 0.013375691138207912, acc: 0.9934533834457397)
[2024-12-17 05:44:30,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:30,436][root][INFO] - Training Epoch: 2/2, step 7120/7134 completed (loss: 0.032429538667201996, acc: 0.9883177280426025)
[2024-12-17 05:44:30,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:30,849][root][INFO] - Training Epoch: 2/2, step 7121/7134 completed (loss: 0.012321538291871548, acc: 0.9929577708244324)
[2024-12-17 05:44:30,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:31,215][root][INFO] - Training Epoch: 2/2, step 7122/7134 completed (loss: 0.027788851410150528, acc: 0.9893048405647278)
[2024-12-17 05:44:31,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:31,579][root][INFO] - Training Epoch: 2/2, step 7123/7134 completed (loss: 0.02593984641134739, acc: 0.9853658676147461)
[2024-12-17 05:44:31,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:32,018][root][INFO] - Training Epoch: 2/2, step 7124/7134 completed (loss: 0.023062778636813164, acc: 0.9924952983856201)
[2024-12-17 05:44:32,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:32,377][root][INFO] - Training Epoch: 2/2, step 7125/7134 completed (loss: 0.020837638527154922, acc: 0.9933664798736572)
[2024-12-17 05:44:32,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:32,785][root][INFO] - Training Epoch: 2/2, step 7126/7134 completed (loss: 0.06368587166070938, acc: 0.979763925075531)
[2024-12-17 05:44:32,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:33,200][root][INFO] - Training Epoch: 2/2, step 7127/7134 completed (loss: 0.019404904916882515, acc: 0.993630588054657)
[2024-12-17 05:44:33,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:33,615][root][INFO] - Training Epoch: 2/2, step 7128/7134 completed (loss: 0.02753564529120922, acc: 0.9918699264526367)
[2024-12-17 05:44:33,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:34,025][root][INFO] - Training Epoch: 2/2, step 7129/7134 completed (loss: 0.056475646793842316, acc: 0.9731543660163879)
[2024-12-17 05:44:34,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:35,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:35,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:35,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:36,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:36,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:36,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:37,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:37,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:38,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:38,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:38,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:39,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:39,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:39,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:40,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:40,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:41,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:41,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:41,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:42,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:42,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:42,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:43,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:43,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:43,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:44,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:44,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:45,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:45,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:46,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:46,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:46,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:47,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:47,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:48,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:48,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:48,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:49,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:49,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:49,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:50,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:50,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:50,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:51,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:51,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:52,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:52,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:52,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:53,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:53,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:53,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:54,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:54,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:55,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:55,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:55,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:55,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:56,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:56,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:57,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:57,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:57,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:58,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:58,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:58,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:59,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:59,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:44:59,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:00,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:00,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:01,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:01,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:01,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:02,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:02,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:02,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:03,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:03,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:04,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:04,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:04,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:05,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:05,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:05,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:06,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:06,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:07,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:07,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:07,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:07,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:08,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:08,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:09,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:09,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:09,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:10,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:10,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:10,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:11,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:11,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:11,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:12,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:12,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:12,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:13,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:13,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:13,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:14,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:14,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:14,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:15,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:15,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:15,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:16,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:16,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:16,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:17,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:17,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:17,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:18,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:18,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:18,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:19,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:19,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:20,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:20,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:20,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:21,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:21,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:21,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:22,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:22,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:23,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:23,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:23,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:24,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:24,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:24,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:25,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:25,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:26,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:26,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:26,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:27,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:27,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:27,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:28,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:28,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:29,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:29,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:29,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:30,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:30,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:30,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:31,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:31,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:31,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:32,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:32,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:33,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:33,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:33,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:34,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:34,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:35,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:35,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:35,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:36,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:36,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:37,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:37,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:37,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:38,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:38,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:39,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:39,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:39,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:40,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:40,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:40,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:41,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:41,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:41,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:42,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:42,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:43,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:43,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:43,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:44,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:44,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:44,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:45,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:45,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:45,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:46,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:46,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:47,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:47,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:47,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:48,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:48,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:48,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:49,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:49,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:49,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:50,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:50,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:50,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:51,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:51,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:51,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:52,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:52,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:52,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:53,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:53,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:54,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:54,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:54,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:55,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:55,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:55,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:56,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:56,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:56,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:57,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:57,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:57,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:58,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:58,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:59,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:59,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:45:59,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:00,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:00,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:00,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:00,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:01,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:01,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:02,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:02,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:02,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:03,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:03,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:03,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:04,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:04,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:05,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:05,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:06,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:06,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:06,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:07,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:07,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:07,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:08,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:08,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:08,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:09,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:09,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:10,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:10,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:11,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:11,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:11,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:12,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:12,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:13,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:13,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:13,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:14,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:14,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:15,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:15,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:16,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:16,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:16,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:17,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:17,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:17,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:18,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:18,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:19,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:19,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:20,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:20,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:21,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:21,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:21,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:22,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:22,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:23,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:23,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:23,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:24,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:24,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:25,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:25,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:26,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:26,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:26,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:27,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:27,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:27,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:28,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:28,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:28,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:28,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:29,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:29,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:29,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:30,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:30,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:30,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:31,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:31,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:31,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:32,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:32,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:33,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:33,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:33,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:34,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:34,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:35,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:35,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:35,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:36,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:36,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:37,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:37,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:37,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:38,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:38,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:39,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:39,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:39,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:40,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:40,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:41,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:41,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:42,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:42,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:43,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:43,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:44,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:44,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:44,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:45,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:45,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:45,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:46,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:46,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:46,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:47,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:47,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:48,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:48,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:48,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:49,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:49,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:50,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:50,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:51,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:52,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:52,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:52,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:53,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:53,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:53,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:54,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:54,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:54,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:55,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:55,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:55,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:56,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:56,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:56,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:57,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:57,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:58,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:58,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:59,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:59,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:46:59,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:00,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:00,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:00,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:01,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:01,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:01,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:02,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:02,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:02,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:03,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:03,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:04,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:04,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:04,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:05,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:05,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:05,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:06,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:06,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:06,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:07,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:07,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:07,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:08,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:08,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:09,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:09,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:09,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:10,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:10,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:10,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:11,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:11,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:11,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:12,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:12,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:12,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:13,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:13,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:13,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:14,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:14,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:15,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:15,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:15,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:16,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:16,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:16,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:17,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:17,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:18,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:18,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:18,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:19,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:19,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:20,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:20,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:20,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:21,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:21,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:21,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:22,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:22,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:22,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:23,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:23,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:24,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:24,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:24,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:25,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:25,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:25,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:26,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:26,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:26,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:27,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:27,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:28,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:28,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:28,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:29,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:29,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:29,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:30,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:30,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:31,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:31,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:31,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:32,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:32,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:32,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:33,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:33,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:34,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:34,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:34,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:35,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:35,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:35,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:36,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:36,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:36,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:37,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:37,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:38,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:38,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:39,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:39,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:39,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:40,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:40,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:40,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:41,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:41,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:42,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:42,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:43,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:43,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:43,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:44,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:44,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:44,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:45,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:45,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:45,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:46,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:46,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:46,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:47,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:47,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:47,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:48,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:48,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:48,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:49,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:49,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:49,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:50,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:50,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:50,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:51,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:51,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:51,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:52,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:52,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:52,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:52,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:53,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:53,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:53,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:54,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:54,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:54,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:55,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:55,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:55,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:56,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:56,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:56,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:57,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:57,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:57,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:58,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:58,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:58,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:59,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:47:59,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:00,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:00,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:00,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:01,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:01,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:02,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:02,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:02,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:03,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:03,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:03,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:04,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:04,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:04,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:05,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:05,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:06,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:06,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:06,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:07,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:07,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:07,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:08,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:08,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:08,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:09,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:09,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:10,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:10,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:11,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:11,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:12,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:12,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:12,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:12,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:13,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:13,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:14,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:14,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:14,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:15,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:15,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:15,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:16,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:16,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:17,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:17,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:17,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:18,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:18,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:18,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:19,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:19,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:20,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:20,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:20,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:21,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:21,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:21,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:22,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:22,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:22,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:23,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:23,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:23,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:24,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:24,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:24,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:25,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:25,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:26,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:26,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:27,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:28,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:28,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:28,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:29,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:29,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:30,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:30,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:31,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:31,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:32,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:32,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:32,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:33,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:33,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:33,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:34,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:34,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:34,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:35,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:35,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:35,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:36,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:36,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:37,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:37,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:37,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:38,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:38,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:38,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:39,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:39,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:40,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:40,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:40,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:41,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:41,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:41,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:42,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:42,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:43,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:43,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:43,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:44,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:44,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:44,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:45,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:45,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:46,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:46,912][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.0523, device='cuda:0') eval_epoch_loss=tensor(0.0510, device='cuda:0') eval_epoch_acc=tensor(0.9864, device='cuda:0')
[2024-12-17 05:48:46,914][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-17 05:48:46,914][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 05:48:47,188][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_2_step_7130_loss_0.050975121557712555/model.pt
[2024-12-17 05:48:47,199][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-12-17 05:48:47,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:47,664][root][INFO] - Training Epoch: 2/2, step 7130/7134 completed (loss: 0.12147699296474457, acc: 0.9678571224212646)
[2024-12-17 05:48:47,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:48,077][root][INFO] - Training Epoch: 2/2, step 7131/7134 completed (loss: 0.012519966810941696, acc: 0.9976798295974731)
[2024-12-17 05:48:48,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:48,433][root][INFO] - Training Epoch: 2/2, step 7132/7134 completed (loss: 0.02192590944468975, acc: 0.9932659864425659)
[2024-12-17 05:48:48,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 05:48:48,811][root][INFO] - Training Epoch: 2/2, step 7133/7134 completed (loss: 0.00907830148935318, acc: 0.996303141117096)
[2024-12-17 05:48:49,279][slam_llm.utils.train_utils][INFO] - Epoch 2: train_perplexity=1.0430, train_epoch_loss=0.0421, epoch time 4123.759506840259s
[2024-12-17 05:48:49,279][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 14 GB
[2024-12-17 05:48:49,279][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 30 GB
[2024-12-17 05:48:49,279][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 14 GB
[2024-12-17 05:48:49,279][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 12
[2024-12-17 05:48:49,279][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-12-17 05:48:49,283][root][INFO] - Key: avg_train_prep, Value: 1.501934289932251
[2024-12-17 05:48:49,285][root][INFO] - Key: avg_train_loss, Value: 0.35774123668670654
[2024-12-17 05:48:49,285][root][INFO] - Key: avg_train_acc, Value: 0.8994532823562622
[2024-12-17 05:48:49,285][root][INFO] - Key: avg_eval_prep, Value: 1.5194339752197266
[2024-12-17 05:48:49,286][root][INFO] - Key: avg_eval_loss, Value: 0.24802447855472565
[2024-12-17 05:48:49,286][root][INFO] - Key: avg_eval_acc, Value: 0.9295713305473328
[2024-12-17 05:48:49,286][root][INFO] - Key: avg_epoch_time, Value: 4126.152053847909
[2024-12-17 05:48:49,286][root][INFO] - Key: avg_checkpoint_time, Value: 0.3027796489186585
