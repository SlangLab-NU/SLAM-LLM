[2024-11-29 02:52:50,681][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 10, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': False, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': True}
[2024-11-29 02:52:50,681][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': 'NO_SHARD', 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-11-29 02:52:50,681][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'dual', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': 'w2v2', 'encoder2_dim': 1024, 'encoder2_path': 'vitouphy/wav2vec2-xls-r-300m-timit-phoneme'}
[2024-11-29 02:52:50,681][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'psst_phoneme_wavlm_llama32_1b_dual_freeze_llm', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-11-29_02-52-50.txt', 'log_interval': 5}
[2024-11-29 02:53:10,742][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-11-29 02:53:16,052][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-11-29 02:53:16,053][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-11-29 02:53:16,056][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-11-29 02:53:16,057][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-11-29 02:53:16,549][slam_llm.utils.train_utils][INFO] - --> Module w2v2
[2024-11-29 02:53:16,550][slam_llm.utils.train_utils][INFO] - --> w2v2 has 315.43872 Million params

[2024-11-29 02:53:16,552][slam_llm.utils.train_utils][INFO] - --> Module w2v2
[2024-11-29 02:53:16,553][slam_llm.utils.train_utils][INFO] - --> w2v2 has 0.0 Million params

[2024-11-29 02:53:20,847][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-11-29 02:53:20,848][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-11-29 02:53:20,849][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-11-29 02:53:20,850][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 0.0 Million params

[2024-11-29 02:53:21,023][slam_llm.utils.train_utils][INFO] - --> Module dual
[2024-11-29 02:53:21,023][slam_llm.utils.train_utils][INFO] - --> dual has 25.16992 Million params

[2024-11-29 02:53:21,024][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-11-29 02:53:21,029][slam_llm.utils.train_utils][INFO] - --> asr has 25.16992 Million params

[2024-11-29 02:53:25,154][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-11-29 02:53:25,610][root][INFO] - --> Training Set Length = 2298
[2024-11-29 02:53:25,613][root][INFO] - --> Validation Set Length = 341
[2024-11-29 02:53:25,613][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-11-29 02:53:25,614][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-11-29 02:53:27,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:28,666][numexpr.utils][INFO] - Note: NumExpr detected 28 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2024-11-29 02:53:29,818][root][INFO] - Training Epoch: 1/10, step 0/574 completed (loss: 8.501876831054688, acc: 0.0)
[2024-11-29 02:53:30,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:30,187][root][INFO] - Training Epoch: 1/10, step 1/574 completed (loss: 8.201207160949707, acc: 0.0)
[2024-11-29 02:53:30,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:30,732][root][INFO] - Training Epoch: 1/10, step 2/574 completed (loss: 7.697605609893799, acc: 0.027027027681469917)
[2024-11-29 02:53:30,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:31,099][root][INFO] - Training Epoch: 1/10, step 3/574 completed (loss: 7.011045932769775, acc: 0.1315789520740509)
[2024-11-29 02:53:31,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:31,447][root][INFO] - Training Epoch: 1/10, step 4/574 completed (loss: 6.577576637268066, acc: 0.054054055362939835)
[2024-11-29 02:53:31,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:31,767][root][INFO] - Training Epoch: 1/10, step 5/574 completed (loss: 7.682891845703125, acc: 0.0357142873108387)
[2024-11-29 02:53:31,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:32,087][root][INFO] - Training Epoch: 1/10, step 6/574 completed (loss: 6.952243328094482, acc: 0.020408162847161293)
[2024-11-29 02:53:32,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:32,399][root][INFO] - Training Epoch: 1/10, step 7/574 completed (loss: 7.389335632324219, acc: 0.0)
[2024-11-29 02:53:32,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:32,757][root][INFO] - Training Epoch: 1/10, step 8/574 completed (loss: 9.337874412536621, acc: 0.0)
[2024-11-29 02:53:32,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:33,060][root][INFO] - Training Epoch: 1/10, step 9/574 completed (loss: 7.36037540435791, acc: 0.0)
[2024-11-29 02:53:33,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:33,366][root][INFO] - Training Epoch: 1/10, step 10/574 completed (loss: 8.00537109375, acc: 0.0)
[2024-11-29 02:53:33,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:33,674][root][INFO] - Training Epoch: 1/10, step 11/574 completed (loss: 6.728862285614014, acc: 0.025641025975346565)
[2024-11-29 02:53:33,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:34,019][root][INFO] - Training Epoch: 1/10, step 12/574 completed (loss: 7.754847526550293, acc: 0.0)
[2024-11-29 02:53:34,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:34,368][root][INFO] - Training Epoch: 1/10, step 13/574 completed (loss: 6.913917064666748, acc: 0.021739130839705467)
[2024-11-29 02:53:34,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:34,706][root][INFO] - Training Epoch: 1/10, step 14/574 completed (loss: 7.297780513763428, acc: 0.019607843831181526)
[2024-11-29 02:53:34,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:35,007][root][INFO] - Training Epoch: 1/10, step 15/574 completed (loss: 5.868282318115234, acc: 0.12244898080825806)
[2024-11-29 02:53:35,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:35,330][root][INFO] - Training Epoch: 1/10, step 16/574 completed (loss: 9.313178062438965, acc: 0.0)
[2024-11-29 02:53:35,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:35,623][root][INFO] - Training Epoch: 1/10, step 17/574 completed (loss: 7.674264907836914, acc: 0.0)
[2024-11-29 02:53:35,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:35,909][root][INFO] - Training Epoch: 1/10, step 18/574 completed (loss: 6.535487651824951, acc: 0.1111111119389534)
[2024-11-29 02:53:36,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:36,200][root][INFO] - Training Epoch: 1/10, step 19/574 completed (loss: 8.279202461242676, acc: 0.05263157933950424)
[2024-11-29 02:53:36,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:36,498][root][INFO] - Training Epoch: 1/10, step 20/574 completed (loss: 7.711014270782471, acc: 0.03846153989434242)
[2024-11-29 02:53:36,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:36,823][root][INFO] - Training Epoch: 1/10, step 21/574 completed (loss: 7.195520401000977, acc: 0.0)
[2024-11-29 02:53:37,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:37,183][root][INFO] - Training Epoch: 1/10, step 22/574 completed (loss: 7.232435703277588, acc: 0.03999999910593033)
[2024-11-29 02:53:37,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:37,516][root][INFO] - Training Epoch: 1/10, step 23/574 completed (loss: 8.34996223449707, acc: 0.0476190485060215)
[2024-11-29 02:53:37,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:37,868][root][INFO] - Training Epoch: 1/10, step 24/574 completed (loss: 8.400161743164062, acc: 0.0)
[2024-11-29 02:53:38,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:38,251][root][INFO] - Training Epoch: 1/10, step 25/574 completed (loss: 5.840703964233398, acc: 0.03773584961891174)
[2024-11-29 02:53:38,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:38,578][root][INFO] - Training Epoch: 1/10, step 26/574 completed (loss: 5.407018184661865, acc: 0.12328767031431198)
[2024-11-29 02:53:39,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:40,338][root][INFO] - Training Epoch: 1/10, step 27/574 completed (loss: 3.876769781112671, acc: 0.2648221254348755)
[2024-11-29 02:53:40,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:40,643][root][INFO] - Training Epoch: 1/10, step 28/574 completed (loss: 6.236451625823975, acc: 0.06976744532585144)
[2024-11-29 02:53:40,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:41,029][root][INFO] - Training Epoch: 1/10, step 29/574 completed (loss: 5.304547309875488, acc: 0.16867469251155853)
[2024-11-29 02:53:41,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:41,391][root][INFO] - Training Epoch: 1/10, step 30/574 completed (loss: 5.2892985343933105, acc: 0.1111111119389534)
[2024-11-29 02:53:41,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:41,672][root][INFO] - Training Epoch: 1/10, step 31/574 completed (loss: 7.178910732269287, acc: 0.0)
[2024-11-29 02:53:41,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:41,940][root][INFO] - Training Epoch: 1/10, step 32/574 completed (loss: 7.241802215576172, acc: 0.0)
[2024-11-29 02:53:42,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:42,291][root][INFO] - Training Epoch: 1/10, step 33/574 completed (loss: 7.865841388702393, acc: 0.0)
[2024-11-29 02:53:42,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:42,659][root][INFO] - Training Epoch: 1/10, step 34/574 completed (loss: 4.827787399291992, acc: 0.18487395346164703)
[2024-11-29 02:53:42,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:42,948][root][INFO] - Training Epoch: 1/10, step 35/574 completed (loss: 5.279321670532227, acc: 0.16393442451953888)
[2024-11-29 02:53:43,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:43,253][root][INFO] - Training Epoch: 1/10, step 36/574 completed (loss: 5.118494033813477, acc: 0.190476194024086)
[2024-11-29 02:53:43,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:43,564][root][INFO] - Training Epoch: 1/10, step 37/574 completed (loss: 5.975245475769043, acc: 0.033898305147886276)
[2024-11-29 02:53:43,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:43,934][root][INFO] - Training Epoch: 1/10, step 38/574 completed (loss: 4.8745646476745605, acc: 0.2068965584039688)
[2024-11-29 02:53:44,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:44,279][root][INFO] - Training Epoch: 1/10, step 39/574 completed (loss: 7.7421393394470215, acc: 0.0)
[2024-11-29 02:53:44,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:44,582][root][INFO] - Training Epoch: 1/10, step 40/574 completed (loss: 6.870364189147949, acc: 0.07692307978868484)
[2024-11-29 02:53:44,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:45,011][root][INFO] - Training Epoch: 1/10, step 41/574 completed (loss: 4.946310043334961, acc: 0.21621622145175934)
[2024-11-29 02:53:45,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:45,360][root][INFO] - Training Epoch: 1/10, step 42/574 completed (loss: 5.096561431884766, acc: 0.20000000298023224)
[2024-11-29 02:53:45,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:45,889][root][INFO] - Training Epoch: 1/10, step 43/574 completed (loss: 4.923220634460449, acc: 0.2222222238779068)
[2024-11-29 02:53:46,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:46,364][root][INFO] - Training Epoch: 1/10, step 44/574 completed (loss: 4.482266902923584, acc: 0.2680412232875824)
[2024-11-29 02:53:46,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:46,856][root][INFO] - Training Epoch: 1/10, step 45/574 completed (loss: 4.772560119628906, acc: 0.1764705926179886)
[2024-11-29 02:53:47,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:47,144][root][INFO] - Training Epoch: 1/10, step 46/574 completed (loss: 7.64112663269043, acc: 0.0)
[2024-11-29 02:53:47,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:47,423][root][INFO] - Training Epoch: 1/10, step 47/574 completed (loss: 6.808865070343018, acc: 0.03703703731298447)
[2024-11-29 02:53:47,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:47,728][root][INFO] - Training Epoch: 1/10, step 48/574 completed (loss: 7.1192402839660645, acc: 0.0357142873108387)
[2024-11-29 02:53:47,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:48,012][root][INFO] - Training Epoch: 1/10, step 49/574 completed (loss: 6.169985771179199, acc: 0.0555555559694767)
[2024-11-29 02:53:48,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:48,358][root][INFO] - Training Epoch: 1/10, step 50/574 completed (loss: 5.393301486968994, acc: 0.19298245012760162)
[2024-11-29 02:53:48,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:48,750][root][INFO] - Training Epoch: 1/10, step 51/574 completed (loss: 5.414387226104736, acc: 0.1428571492433548)
[2024-11-29 02:53:48,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:49,106][root][INFO] - Training Epoch: 1/10, step 52/574 completed (loss: 5.499246120452881, acc: 0.1267605572938919)
[2024-11-29 02:53:49,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:49,757][root][INFO] - Training Epoch: 1/10, step 53/574 completed (loss: 4.620254993438721, acc: 0.25333333015441895)
[2024-11-29 02:53:49,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:50,158][root][INFO] - Training Epoch: 1/10, step 54/574 completed (loss: 6.552175998687744, acc: 0.027027027681469917)
[2024-11-29 02:53:50,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:50,539][root][INFO] - Training Epoch: 1/10, step 55/574 completed (loss: 6.956694602966309, acc: 0.0)
[2024-11-29 02:53:53,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:54,876][root][INFO] - Training Epoch: 1/10, step 56/574 completed (loss: 3.088810443878174, acc: 0.42320817708969116)
[2024-11-29 02:53:55,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:56,588][root][INFO] - Training Epoch: 1/10, step 57/574 completed (loss: 3.522806406021118, acc: 0.3180827796459198)
[2024-11-29 02:53:57,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:57,446][root][INFO] - Training Epoch: 1/10, step 58/574 completed (loss: 3.938110589981079, acc: 0.27840909361839294)
[2024-11-29 02:53:57,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:58,220][root][INFO] - Training Epoch: 1/10, step 59/574 completed (loss: 4.3689374923706055, acc: 0.20588235557079315)
[2024-11-29 02:53:58,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:58,975][root][INFO] - Training Epoch: 1/10, step 60/574 completed (loss: 4.011266708374023, acc: 0.26811593770980835)
[2024-11-29 02:53:59,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:59,488][root][INFO] - Training Epoch: 1/10, step 61/574 completed (loss: 4.296280860900879, acc: 0.3125)
[2024-11-29 02:53:59,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:53:59,833][root][INFO] - Training Epoch: 1/10, step 62/574 completed (loss: 5.855834007263184, acc: 0.0882352963089943)
[2024-11-29 02:54:00,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:00,223][root][INFO] - Training Epoch: 1/10, step 63/574 completed (loss: 6.22965145111084, acc: 0.0555555559694767)
[2024-11-29 02:54:00,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:00,594][root][INFO] - Training Epoch: 1/10, step 64/574 completed (loss: 4.0722975730896, acc: 0.28125)
[2024-11-29 02:54:00,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:00,940][root][INFO] - Training Epoch: 1/10, step 65/574 completed (loss: 5.159491062164307, acc: 0.24137930572032928)
[2024-11-29 02:54:01,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:01,292][root][INFO] - Training Epoch: 1/10, step 66/574 completed (loss: 4.748965263366699, acc: 0.25)
[2024-11-29 02:54:01,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:01,616][root][INFO] - Training Epoch: 1/10, step 67/574 completed (loss: 5.0076680183410645, acc: 0.06666667014360428)
[2024-11-29 02:54:01,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:01,903][root][INFO] - Training Epoch: 1/10, step 68/574 completed (loss: 6.474668979644775, acc: 0.03999999910593033)
[2024-11-29 02:54:02,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:02,276][root][INFO] - Training Epoch: 1/10, step 69/574 completed (loss: 5.615364074707031, acc: 0.0833333358168602)
[2024-11-29 02:54:02,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:02,656][root][INFO] - Training Epoch: 1/10, step 70/574 completed (loss: 6.180715560913086, acc: 0.06060606241226196)
[2024-11-29 02:54:02,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:03,023][root][INFO] - Training Epoch: 1/10, step 71/574 completed (loss: 4.188441753387451, acc: 0.24264705181121826)
[2024-11-29 02:54:03,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:03,344][root][INFO] - Training Epoch: 1/10, step 72/574 completed (loss: 4.037862300872803, acc: 0.2142857164144516)
[2024-11-29 02:54:03,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:03,701][root][INFO] - Training Epoch: 1/10, step 73/574 completed (loss: 4.238846778869629, acc: 0.22564102709293365)
[2024-11-29 02:54:03,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:03,978][root][INFO] - Training Epoch: 1/10, step 74/574 completed (loss: 5.187804698944092, acc: 0.09183673560619354)
[2024-11-29 02:54:04,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:04,277][root][INFO] - Training Epoch: 1/10, step 75/574 completed (loss: 4.630629062652588, acc: 0.11940298229455948)
[2024-11-29 02:54:04,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:04,713][root][INFO] - Training Epoch: 1/10, step 76/574 completed (loss: 3.915574550628662, acc: 0.25182482600212097)
[2024-11-29 02:54:04,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:05,060][root][INFO] - Training Epoch: 1/10, step 77/574 completed (loss: 6.494364261627197, acc: 0.0)
[2024-11-29 02:54:05,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:05,363][root][INFO] - Training Epoch: 1/10, step 78/574 completed (loss: 5.9759039878845215, acc: 0.0416666679084301)
[2024-11-29 02:54:05,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:05,695][root][INFO] - Training Epoch: 1/10, step 79/574 completed (loss: 5.552190780639648, acc: 0.0)
[2024-11-29 02:54:05,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:05,999][root][INFO] - Training Epoch: 1/10, step 80/574 completed (loss: 5.60198450088501, acc: 0.07692307978868484)
[2024-11-29 02:54:06,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:06,354][root][INFO] - Training Epoch: 1/10, step 81/574 completed (loss: 5.130353927612305, acc: 0.03846153989434242)
[2024-11-29 02:54:06,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:06,681][root][INFO] - Training Epoch: 1/10, step 82/574 completed (loss: 5.294084548950195, acc: 0.13461539149284363)
[2024-11-29 02:54:06,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:06,989][root][INFO] - Training Epoch: 1/10, step 83/574 completed (loss: 4.677156448364258, acc: 0.09375)
[2024-11-29 02:54:07,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:07,318][root][INFO] - Training Epoch: 1/10, step 84/574 completed (loss: 4.970648288726807, acc: 0.1304347813129425)
[2024-11-29 02:54:07,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:07,686][root][INFO] - Training Epoch: 1/10, step 85/574 completed (loss: 4.759707450866699, acc: 0.11999999731779099)
[2024-11-29 02:54:07,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:08,033][root][INFO] - Training Epoch: 1/10, step 86/574 completed (loss: 6.1644816398620605, acc: 0.0)
[2024-11-29 02:54:08,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:08,664][root][INFO] - Training Epoch: 1/10, step 87/574 completed (loss: 4.679254055023193, acc: 0.18000000715255737)
[2024-11-29 02:54:08,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:09,121][root][INFO] - Training Epoch: 1/10, step 88/574 completed (loss: 3.889417886734009, acc: 0.3009708821773529)
[2024-11-29 02:54:10,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:10,838][root][INFO] - Training Epoch: 1/10, step 89/574 completed (loss: 3.7753713130950928, acc: 0.34951457381248474)
[2024-11-29 02:54:11,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:12,027][root][INFO] - Training Epoch: 1/10, step 90/574 completed (loss: 4.004138946533203, acc: 0.25806450843811035)
[2024-11-29 02:54:12,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:13,180][root][INFO] - Training Epoch: 1/10, step 91/574 completed (loss: 3.58329176902771, acc: 0.37931033968925476)
[2024-11-29 02:54:13,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:14,250][root][INFO] - Training Epoch: 1/10, step 92/574 completed (loss: 4.0123372077941895, acc: 0.28421053290367126)
[2024-11-29 02:54:15,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:15,744][root][INFO] - Training Epoch: 1/10, step 93/574 completed (loss: 4.139443874359131, acc: 0.23762376606464386)
[2024-11-29 02:54:15,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:16,046][root][INFO] - Training Epoch: 1/10, step 94/574 completed (loss: 4.497164249420166, acc: 0.12903225421905518)
[2024-11-29 02:54:16,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:16,400][root][INFO] - Training Epoch: 1/10, step 95/574 completed (loss: 4.563368320465088, acc: 0.17391304671764374)
[2024-11-29 02:54:16,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:16,756][root][INFO] - Training Epoch: 1/10, step 96/574 completed (loss: 4.483130931854248, acc: 0.10924369841814041)
[2024-11-29 02:54:16,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:17,102][root][INFO] - Training Epoch: 1/10, step 97/574 completed (loss: 4.2711710929870605, acc: 0.1538461595773697)
[2024-11-29 02:54:17,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:17,557][root][INFO] - Training Epoch: 1/10, step 98/574 completed (loss: 4.236907958984375, acc: 0.18978102505207062)
[2024-11-29 02:54:17,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:17,900][root][INFO] - Training Epoch: 1/10, step 99/574 completed (loss: 4.9231438636779785, acc: 0.08955223858356476)
[2024-11-29 02:54:18,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:18,192][root][INFO] - Training Epoch: 1/10, step 100/574 completed (loss: 5.813052177429199, acc: 0.05000000074505806)
[2024-11-29 02:54:18,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:18,474][root][INFO] - Training Epoch: 1/10, step 101/574 completed (loss: 5.062192916870117, acc: 0.13636364042758942)
[2024-11-29 02:54:18,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:18,775][root][INFO] - Training Epoch: 1/10, step 102/574 completed (loss: 4.552845001220703, acc: 0.08695652335882187)
[2024-11-29 02:54:19,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:19,132][root][INFO] - Training Epoch: 1/10, step 103/574 completed (loss: 4.205975532531738, acc: 0.13636364042758942)
[2024-11-29 02:54:19,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:19,506][root][INFO] - Training Epoch: 1/10, step 104/574 completed (loss: 4.564425468444824, acc: 0.12068965286016464)
[2024-11-29 02:54:19,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:19,800][root][INFO] - Training Epoch: 1/10, step 105/574 completed (loss: 4.558326244354248, acc: 0.13953489065170288)
[2024-11-29 02:54:20,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:20,138][root][INFO] - Training Epoch: 1/10, step 106/574 completed (loss: 4.700465202331543, acc: 0.03999999910593033)
[2024-11-29 02:54:20,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:20,520][root][INFO] - Training Epoch: 1/10, step 107/574 completed (loss: 5.043015003204346, acc: 0.11764705926179886)
[2024-11-29 02:54:20,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:20,862][root][INFO] - Training Epoch: 1/10, step 108/574 completed (loss: 4.2636332511901855, acc: 0.07692307978868484)
[2024-11-29 02:54:21,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:21,225][root][INFO] - Training Epoch: 1/10, step 109/574 completed (loss: 4.836908340454102, acc: 0.1190476194024086)
[2024-11-29 02:54:21,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:21,622][root][INFO] - Training Epoch: 1/10, step 110/574 completed (loss: 4.813313961029053, acc: 0.1230769231915474)
[2024-11-29 02:54:21,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:22,123][root][INFO] - Training Epoch: 1/10, step 111/574 completed (loss: 4.448199272155762, acc: 0.19298245012760162)
[2024-11-29 02:54:22,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:22,495][root][INFO] - Training Epoch: 1/10, step 112/574 completed (loss: 4.316458225250244, acc: 0.14035087823867798)
[2024-11-29 02:54:22,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:22,847][root][INFO] - Training Epoch: 1/10, step 113/574 completed (loss: 4.9432830810546875, acc: 0.10256410390138626)
[2024-11-29 02:54:23,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:23,267][root][INFO] - Training Epoch: 1/10, step 114/574 completed (loss: 4.55835485458374, acc: 0.06122449040412903)
[2024-11-29 02:54:23,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:23,598][root][INFO] - Training Epoch: 1/10, step 115/574 completed (loss: 4.580161094665527, acc: 0.04545454680919647)
[2024-11-29 02:54:23,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:23,979][root][INFO] - Training Epoch: 1/10, step 116/574 completed (loss: 3.836374521255493, acc: 0.190476194024086)
[2024-11-29 02:54:24,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:24,294][root][INFO] - Training Epoch: 1/10, step 117/574 completed (loss: 3.8701930046081543, acc: 0.24390244483947754)
[2024-11-29 02:54:24,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:24,638][root][INFO] - Training Epoch: 1/10, step 118/574 completed (loss: 4.179581165313721, acc: 0.27419355511665344)
[2024-11-29 02:54:25,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:25,876][root][INFO] - Training Epoch: 1/10, step 119/574 completed (loss: 3.6090199947357178, acc: 0.2775665521621704)
[2024-11-29 02:54:26,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:26,242][root][INFO] - Training Epoch: 1/10, step 120/574 completed (loss: 4.268956661224365, acc: 0.2133333384990692)
[2024-11-29 02:54:26,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:26,739][root][INFO] - Training Epoch: 1/10, step 121/574 completed (loss: 4.842368125915527, acc: 0.17307692766189575)
[2024-11-29 02:54:26,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:27,065][root][INFO] - Training Epoch: 1/10, step 122/574 completed (loss: 5.197227478027344, acc: 0.0833333358168602)
[2024-11-29 02:54:27,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:27,441][root][INFO] - Training Epoch: 1/10, step 123/574 completed (loss: 4.294511795043945, acc: 0.15789473056793213)
[2024-11-29 02:54:27,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:27,855][root][INFO] - Training Epoch: 1/10, step 124/574 completed (loss: 3.928069591522217, acc: 0.21472392976284027)
[2024-11-29 02:54:28,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:28,269][root][INFO] - Training Epoch: 1/10, step 125/574 completed (loss: 3.1277623176574707, acc: 0.3194444477558136)
[2024-11-29 02:54:28,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:28,576][root][INFO] - Training Epoch: 1/10, step 126/574 completed (loss: 3.9361112117767334, acc: 0.1666666716337204)
[2024-11-29 02:54:28,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:28,926][root][INFO] - Training Epoch: 1/10, step 127/574 completed (loss: 3.6941325664520264, acc: 0.2083333283662796)
[2024-11-29 02:54:29,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:29,267][root][INFO] - Training Epoch: 1/10, step 128/574 completed (loss: 3.875835418701172, acc: 0.1846153885126114)
[2024-11-29 02:54:29,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:29,723][root][INFO] - Training Epoch: 1/10, step 129/574 completed (loss: 3.3430309295654297, acc: 0.3382352888584137)
[2024-11-29 02:54:29,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:30,104][root][INFO] - Training Epoch: 1/10, step 130/574 completed (loss: 4.70578145980835, acc: 0.07692307978868484)
[2024-11-29 02:54:30,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:30,439][root][INFO] - Training Epoch: 1/10, step 131/574 completed (loss: 4.005950927734375, acc: 0.1304347813129425)
[2024-11-29 02:54:30,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:30,778][root][INFO] - Training Epoch: 1/10, step 132/574 completed (loss: 4.422970771789551, acc: 0.09375)
[2024-11-29 02:54:30,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:31,101][root][INFO] - Training Epoch: 1/10, step 133/574 completed (loss: 3.3563055992126465, acc: 0.21739129722118378)
[2024-11-29 02:54:31,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:31,408][root][INFO] - Training Epoch: 1/10, step 134/574 completed (loss: 3.9702212810516357, acc: 0.17142857611179352)
[2024-11-29 02:54:31,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:31,678][root][INFO] - Training Epoch: 1/10, step 135/574 completed (loss: 3.722006320953369, acc: 0.23076923191547394)
[2024-11-29 02:54:31,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:32,015][root][INFO] - Training Epoch: 1/10, step 136/574 completed (loss: 4.452317237854004, acc: 0.0714285746216774)
[2024-11-29 02:54:32,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:32,349][root][INFO] - Training Epoch: 1/10, step 137/574 completed (loss: 3.5217764377593994, acc: 0.30000001192092896)
[2024-11-29 02:54:32,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:32,715][root][INFO] - Training Epoch: 1/10, step 138/574 completed (loss: 3.9360997676849365, acc: 0.08695652335882187)
[2024-11-29 02:54:32,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:32,990][root][INFO] - Training Epoch: 1/10, step 139/574 completed (loss: 4.376734256744385, acc: 0.2380952388048172)
[2024-11-29 02:54:33,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:33,301][root][INFO] - Training Epoch: 1/10, step 140/574 completed (loss: 4.618596076965332, acc: 0.1538461595773697)
[2024-11-29 02:54:33,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:33,658][root][INFO] - Training Epoch: 1/10, step 141/574 completed (loss: 4.2539777755737305, acc: 0.12903225421905518)
[2024-11-29 02:54:33,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:34,050][root][INFO] - Training Epoch: 1/10, step 142/574 completed (loss: 3.6220438480377197, acc: 0.29729729890823364)
[2024-11-29 02:54:35,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:35,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:36,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:36,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:37,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:37,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:37,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:38,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:38,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:39,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:39,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:40,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:40,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:41,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:41,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:42,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:42,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:43,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:43,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:44,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:44,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:45,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:45,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:45,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:46,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:46,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:47,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:47,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:48,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:48,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:48,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:49,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:50,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:50,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:51,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:51,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:52,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:52,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:53,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:53,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:53,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:54,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:54,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:55,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:55,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:56,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:56,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:57,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:57,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:58,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:58,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:59,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:54:59,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:00,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:00,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:00,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:01,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:01,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:02,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:02,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:03,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:03,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:04,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:04,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:05,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:05,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:06,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:06,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:07,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:08,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:08,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:08,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:09,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:09,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:10,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:10,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:11,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:11,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:11,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:12,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:12,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:13,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:13,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:14,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:14,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:15,572][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(59.6688, device='cuda:0') eval_epoch_loss=tensor(4.0888, device='cuda:0') eval_epoch_acc=tensor(0.1911, device='cuda:0')
[2024-11-29 02:55:15,573][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 02:55:15,574][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 02:55:15,940][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_1_step_143_loss_4.088809013366699/model.pt
[2024-11-29 02:55:15,944][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 4.088809013366699
[2024-11-29 02:55:15,944][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.19110283255577087
[2024-11-29 02:55:16,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:16,677][root][INFO] - Training Epoch: 1/10, step 143/574 completed (loss: 3.3393657207489014, acc: 0.3333333432674408)
[2024-11-29 02:55:16,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:17,029][root][INFO] - Training Epoch: 1/10, step 144/574 completed (loss: 3.1081035137176514, acc: 0.4029850661754608)
[2024-11-29 02:55:17,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:17,390][root][INFO] - Training Epoch: 1/10, step 145/574 completed (loss: 3.7808454036712646, acc: 0.23469388484954834)
[2024-11-29 02:55:17,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:17,984][root][INFO] - Training Epoch: 1/10, step 146/574 completed (loss: 3.440500020980835, acc: 0.3191489279270172)
[2024-11-29 02:55:18,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:18,290][root][INFO] - Training Epoch: 1/10, step 147/574 completed (loss: 3.554964542388916, acc: 0.3571428656578064)
[2024-11-29 02:55:18,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:18,639][root][INFO] - Training Epoch: 1/10, step 148/574 completed (loss: 4.545073986053467, acc: 0.1071428582072258)
[2024-11-29 02:55:18,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:18,924][root][INFO] - Training Epoch: 1/10, step 149/574 completed (loss: 4.01284646987915, acc: 0.1304347813129425)
[2024-11-29 02:55:19,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:19,199][root][INFO] - Training Epoch: 1/10, step 150/574 completed (loss: 4.337783336639404, acc: 0.06896551698446274)
[2024-11-29 02:55:19,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:19,487][root][INFO] - Training Epoch: 1/10, step 151/574 completed (loss: 3.85957932472229, acc: 0.30434781312942505)
[2024-11-29 02:55:19,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:19,809][root][INFO] - Training Epoch: 1/10, step 152/574 completed (loss: 3.4370079040527344, acc: 0.20338982343673706)
[2024-11-29 02:55:19,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:20,092][root][INFO] - Training Epoch: 1/10, step 153/574 completed (loss: 4.2574920654296875, acc: 0.12280701845884323)
[2024-11-29 02:55:20,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:20,413][root][INFO] - Training Epoch: 1/10, step 154/574 completed (loss: 3.9315507411956787, acc: 0.2567567527294159)
[2024-11-29 02:55:20,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:20,697][root][INFO] - Training Epoch: 1/10, step 155/574 completed (loss: 3.962944507598877, acc: 0.2142857164144516)
[2024-11-29 02:55:20,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:20,952][root][INFO] - Training Epoch: 1/10, step 156/574 completed (loss: 3.1035735607147217, acc: 0.3478260934352875)
[2024-11-29 02:55:21,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:21,214][root][INFO] - Training Epoch: 1/10, step 157/574 completed (loss: 4.251716613769531, acc: 0.05263157933950424)
[2024-11-29 02:55:22,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:23,877][root][INFO] - Training Epoch: 1/10, step 158/574 completed (loss: 4.6228485107421875, acc: 0.21621622145175934)
[2024-11-29 02:55:24,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:24,247][root][INFO] - Training Epoch: 1/10, step 159/574 completed (loss: 3.9171247482299805, acc: 0.14814814925193787)
[2024-11-29 02:55:24,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:24,803][root][INFO] - Training Epoch: 1/10, step 160/574 completed (loss: 4.501888751983643, acc: 0.19767442345619202)
[2024-11-29 02:55:25,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:25,691][root][INFO] - Training Epoch: 1/10, step 161/574 completed (loss: 4.123592376708984, acc: 0.23529411852359772)
[2024-11-29 02:55:26,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:26,468][root][INFO] - Training Epoch: 1/10, step 162/574 completed (loss: 4.226840019226074, acc: 0.23595505952835083)
[2024-11-29 02:55:26,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:26,812][root][INFO] - Training Epoch: 1/10, step 163/574 completed (loss: 3.8728177547454834, acc: 0.27272728085517883)
[2024-11-29 02:55:26,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:27,105][root][INFO] - Training Epoch: 1/10, step 164/574 completed (loss: 4.1528096199035645, acc: 0.2857142984867096)
[2024-11-29 02:55:27,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:27,455][root][INFO] - Training Epoch: 1/10, step 165/574 completed (loss: 4.477027416229248, acc: 0.17241379618644714)
[2024-11-29 02:55:27,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:27,779][root][INFO] - Training Epoch: 1/10, step 166/574 completed (loss: 2.826235771179199, acc: 0.40816327929496765)
[2024-11-29 02:55:27,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:28,121][root][INFO] - Training Epoch: 1/10, step 167/574 completed (loss: 3.5329363346099854, acc: 0.30000001192092896)
[2024-11-29 02:55:28,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:28,689][root][INFO] - Training Epoch: 1/10, step 168/574 completed (loss: 3.3548264503479004, acc: 0.3472222089767456)
[2024-11-29 02:55:28,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:29,077][root][INFO] - Training Epoch: 1/10, step 169/574 completed (loss: 3.522275686264038, acc: 0.27450981736183167)
[2024-11-29 02:55:30,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:30,744][root][INFO] - Training Epoch: 1/10, step 170/574 completed (loss: 3.8672678470611572, acc: 0.25342464447021484)
[2024-11-29 02:55:30,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:31,076][root][INFO] - Training Epoch: 1/10, step 171/574 completed (loss: 3.542130470275879, acc: 0.25)
[2024-11-29 02:55:31,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:31,362][root][INFO] - Training Epoch: 1/10, step 172/574 completed (loss: 3.994906425476074, acc: 0.18518517911434174)
[2024-11-29 02:55:31,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:31,754][root][INFO] - Training Epoch: 1/10, step 173/574 completed (loss: 3.6252200603485107, acc: 0.2857142984867096)
[2024-11-29 02:55:32,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:32,520][root][INFO] - Training Epoch: 1/10, step 174/574 completed (loss: 3.0061495304107666, acc: 0.4159291982650757)
[2024-11-29 02:55:32,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:32,895][root][INFO] - Training Epoch: 1/10, step 175/574 completed (loss: 3.930860996246338, acc: 0.21739129722118378)
[2024-11-29 02:55:33,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:33,241][root][INFO] - Training Epoch: 1/10, step 176/574 completed (loss: 3.7653024196624756, acc: 0.17045454680919647)
[2024-11-29 02:55:34,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:34,631][root][INFO] - Training Epoch: 1/10, step 177/574 completed (loss: 3.863480806350708, acc: 0.23664122819900513)
[2024-11-29 02:55:35,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:35,600][root][INFO] - Training Epoch: 1/10, step 178/574 completed (loss: 3.9588677883148193, acc: 0.2074074000120163)
[2024-11-29 02:55:35,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:35,928][root][INFO] - Training Epoch: 1/10, step 179/574 completed (loss: 3.8620622158050537, acc: 0.2295081913471222)
[2024-11-29 02:55:36,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:36,222][root][INFO] - Training Epoch: 1/10, step 180/574 completed (loss: 3.6693999767303467, acc: 0.2083333283662796)
[2024-11-29 02:55:36,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:36,554][root][INFO] - Training Epoch: 1/10, step 181/574 completed (loss: 3.641918420791626, acc: 0.23999999463558197)
[2024-11-29 02:55:36,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:36,847][root][INFO] - Training Epoch: 1/10, step 182/574 completed (loss: 4.577727317810059, acc: 0.1428571492433548)
[2024-11-29 02:55:37,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:37,163][root][INFO] - Training Epoch: 1/10, step 183/574 completed (loss: 3.91188645362854, acc: 0.1463414579629898)
[2024-11-29 02:55:37,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:37,511][root][INFO] - Training Epoch: 1/10, step 184/574 completed (loss: 3.6412272453308105, acc: 0.24773414433002472)
[2024-11-29 02:55:37,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:37,869][root][INFO] - Training Epoch: 1/10, step 185/574 completed (loss: 3.6726932525634766, acc: 0.20749279856681824)
[2024-11-29 02:55:38,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:38,557][root][INFO] - Training Epoch: 1/10, step 186/574 completed (loss: 3.78766131401062, acc: 0.20937499403953552)
[2024-11-29 02:55:38,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:39,234][root][INFO] - Training Epoch: 1/10, step 187/574 completed (loss: 3.4070627689361572, acc: 0.24953095614910126)
[2024-11-29 02:55:39,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:39,706][root][INFO] - Training Epoch: 1/10, step 188/574 completed (loss: 3.4582934379577637, acc: 0.23843416571617126)
[2024-11-29 02:55:39,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:40,077][root][INFO] - Training Epoch: 1/10, step 189/574 completed (loss: 3.78974986076355, acc: 0.23999999463558197)
[2024-11-29 02:55:40,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:40,907][root][INFO] - Training Epoch: 1/10, step 190/574 completed (loss: 3.933980941772461, acc: 0.19767442345619202)
[2024-11-29 02:55:41,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:42,188][root][INFO] - Training Epoch: 1/10, step 191/574 completed (loss: 3.8503572940826416, acc: 0.2698412835597992)
[2024-11-29 02:55:43,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:43,574][root][INFO] - Training Epoch: 1/10, step 192/574 completed (loss: 3.641691207885742, acc: 0.28787878155708313)
[2024-11-29 02:55:44,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:44,718][root][INFO] - Training Epoch: 1/10, step 193/574 completed (loss: 3.30405855178833, acc: 0.3764705955982208)
[2024-11-29 02:55:45,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:46,441][root][INFO] - Training Epoch: 1/10, step 194/574 completed (loss: 3.213181972503662, acc: 0.3333333432674408)
[2024-11-29 02:55:47,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:48,008][root][INFO] - Training Epoch: 1/10, step 195/574 completed (loss: 3.622115135192871, acc: 0.32258063554763794)
[2024-11-29 02:55:48,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:48,391][root][INFO] - Training Epoch: 1/10, step 196/574 completed (loss: 3.1492698192596436, acc: 0.2857142984867096)
[2024-11-29 02:55:48,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:48,757][root][INFO] - Training Epoch: 1/10, step 197/574 completed (loss: 4.140777587890625, acc: 0.15000000596046448)
[2024-11-29 02:55:49,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:49,136][root][INFO] - Training Epoch: 1/10, step 198/574 completed (loss: 4.149125576019287, acc: 0.19117647409439087)
[2024-11-29 02:55:49,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:49,492][root][INFO] - Training Epoch: 1/10, step 199/574 completed (loss: 3.659702777862549, acc: 0.30882352590560913)
[2024-11-29 02:55:49,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:49,914][root][INFO] - Training Epoch: 1/10, step 200/574 completed (loss: 3.3635997772216797, acc: 0.2711864411830902)
[2024-11-29 02:55:50,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:50,261][root][INFO] - Training Epoch: 1/10, step 201/574 completed (loss: 3.75834584236145, acc: 0.28358209133148193)
[2024-11-29 02:55:50,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:50,643][root][INFO] - Training Epoch: 1/10, step 202/574 completed (loss: 4.211946487426758, acc: 0.20388349890708923)
[2024-11-29 02:55:50,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:50,939][root][INFO] - Training Epoch: 1/10, step 203/574 completed (loss: 3.3346316814422607, acc: 0.380952388048172)
[2024-11-29 02:55:51,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:51,203][root][INFO] - Training Epoch: 1/10, step 204/574 completed (loss: 3.467075824737549, acc: 0.2747252881526947)
[2024-11-29 02:55:51,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:51,551][root][INFO] - Training Epoch: 1/10, step 205/574 completed (loss: 3.5188658237457275, acc: 0.22421523928642273)
[2024-11-29 02:55:51,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:52,011][root][INFO] - Training Epoch: 1/10, step 206/574 completed (loss: 3.3915164470672607, acc: 0.30708661675453186)
[2024-11-29 02:55:52,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:52,314][root][INFO] - Training Epoch: 1/10, step 207/574 completed (loss: 3.5084338188171387, acc: 0.2801724076271057)
[2024-11-29 02:55:52,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:52,661][root][INFO] - Training Epoch: 1/10, step 208/574 completed (loss: 3.1462080478668213, acc: 0.3333333432674408)
[2024-11-29 02:55:52,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:53,061][root][INFO] - Training Epoch: 1/10, step 209/574 completed (loss: 3.5828709602355957, acc: 0.26070037484169006)
[2024-11-29 02:55:53,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:53,420][root][INFO] - Training Epoch: 1/10, step 210/574 completed (loss: 3.829336166381836, acc: 0.18478260934352875)
[2024-11-29 02:55:53,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:53,752][root][INFO] - Training Epoch: 1/10, step 211/574 completed (loss: 3.096041202545166, acc: 0.260869562625885)
[2024-11-29 02:55:53,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:54,101][root][INFO] - Training Epoch: 1/10, step 212/574 completed (loss: 3.4712073802948, acc: 0.2142857164144516)
[2024-11-29 02:55:54,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:54,467][root][INFO] - Training Epoch: 1/10, step 213/574 completed (loss: 3.9879651069641113, acc: 0.21276596188545227)
[2024-11-29 02:55:55,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:55,485][root][INFO] - Training Epoch: 1/10, step 214/574 completed (loss: 3.8105666637420654, acc: 0.23076923191547394)
[2024-11-29 02:55:55,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:55,844][root][INFO] - Training Epoch: 1/10, step 215/574 completed (loss: 3.734752655029297, acc: 0.20270270109176636)
[2024-11-29 02:55:56,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:56,175][root][INFO] - Training Epoch: 1/10, step 216/574 completed (loss: 3.6522419452667236, acc: 0.24418604373931885)
[2024-11-29 02:55:56,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:56,939][root][INFO] - Training Epoch: 1/10, step 217/574 completed (loss: 3.9099576473236084, acc: 0.23423422873020172)
[2024-11-29 02:55:57,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:57,413][root][INFO] - Training Epoch: 1/10, step 218/574 completed (loss: 3.6729729175567627, acc: 0.23333333432674408)
[2024-11-29 02:55:57,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:57,707][root][INFO] - Training Epoch: 1/10, step 219/574 completed (loss: 3.304598331451416, acc: 0.3030303120613098)
[2024-11-29 02:55:57,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:57,953][root][INFO] - Training Epoch: 1/10, step 220/574 completed (loss: 2.8599374294281006, acc: 0.3333333432674408)
[2024-11-29 02:55:58,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:58,231][root][INFO] - Training Epoch: 1/10, step 221/574 completed (loss: 3.0892226696014404, acc: 0.3199999928474426)
[2024-11-29 02:55:58,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:58,503][root][INFO] - Training Epoch: 1/10, step 222/574 completed (loss: 3.4657671451568604, acc: 0.25)
[2024-11-29 02:55:59,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:55:59,700][root][INFO] - Training Epoch: 1/10, step 223/574 completed (loss: 3.1972522735595703, acc: 0.3695652186870575)
[2024-11-29 02:56:00,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:00,458][root][INFO] - Training Epoch: 1/10, step 224/574 completed (loss: 3.454367160797119, acc: 0.3125)
[2024-11-29 02:56:00,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:01,015][root][INFO] - Training Epoch: 1/10, step 225/574 completed (loss: 3.5072503089904785, acc: 0.26595744490623474)
[2024-11-29 02:56:01,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:01,424][root][INFO] - Training Epoch: 1/10, step 226/574 completed (loss: 4.2514848709106445, acc: 0.2075471729040146)
[2024-11-29 02:56:01,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:01,809][root][INFO] - Training Epoch: 1/10, step 227/574 completed (loss: 3.5654780864715576, acc: 0.1666666716337204)
[2024-11-29 02:56:02,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:02,145][root][INFO] - Training Epoch: 1/10, step 228/574 completed (loss: 3.1328134536743164, acc: 0.3488371968269348)
[2024-11-29 02:56:02,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:02,485][root][INFO] - Training Epoch: 1/10, step 229/574 completed (loss: 3.5171751976013184, acc: 0.23333333432674408)
[2024-11-29 02:56:02,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:02,880][root][INFO] - Training Epoch: 1/10, step 230/574 completed (loss: 3.9569599628448486, acc: 0.20000000298023224)
[2024-11-29 02:56:03,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:03,155][root][INFO] - Training Epoch: 1/10, step 231/574 completed (loss: 3.7672884464263916, acc: 0.24444444477558136)
[2024-11-29 02:56:03,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:03,684][root][INFO] - Training Epoch: 1/10, step 232/574 completed (loss: 3.0829107761383057, acc: 0.3722222149372101)
[2024-11-29 02:56:04,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:04,353][root][INFO] - Training Epoch: 1/10, step 233/574 completed (loss: 3.3492352962493896, acc: 0.35779815912246704)
[2024-11-29 02:56:04,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:04,971][root][INFO] - Training Epoch: 1/10, step 234/574 completed (loss: 3.3811492919921875, acc: 0.32307693362236023)
[2024-11-29 02:56:05,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:05,240][root][INFO] - Training Epoch: 1/10, step 235/574 completed (loss: 3.0444507598876953, acc: 0.31578946113586426)
[2024-11-29 02:56:05,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:05,511][root][INFO] - Training Epoch: 1/10, step 236/574 completed (loss: 3.5367650985717773, acc: 0.25)
[2024-11-29 02:56:05,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:05,801][root][INFO] - Training Epoch: 1/10, step 237/574 completed (loss: 3.5014398097991943, acc: 0.3181818127632141)
[2024-11-29 02:56:05,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:06,088][root][INFO] - Training Epoch: 1/10, step 238/574 completed (loss: 3.2423715591430664, acc: 0.37037035822868347)
[2024-11-29 02:56:06,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:06,375][root][INFO] - Training Epoch: 1/10, step 239/574 completed (loss: 3.201599597930908, acc: 0.37142857909202576)
[2024-11-29 02:56:06,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:06,716][root][INFO] - Training Epoch: 1/10, step 240/574 completed (loss: 3.2669026851654053, acc: 0.3181818127632141)
[2024-11-29 02:56:06,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:07,106][root][INFO] - Training Epoch: 1/10, step 241/574 completed (loss: 3.324965715408325, acc: 0.22727273404598236)
[2024-11-29 02:56:07,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:08,008][root][INFO] - Training Epoch: 1/10, step 242/574 completed (loss: 3.6116857528686523, acc: 0.30645161867141724)
[2024-11-29 02:56:08,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:08,740][root][INFO] - Training Epoch: 1/10, step 243/574 completed (loss: 3.28969669342041, acc: 0.3181818127632141)
[2024-11-29 02:56:08,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:09,011][root][INFO] - Training Epoch: 1/10, step 244/574 completed (loss: 3.4711101055145264, acc: 0.2857142984867096)
[2024-11-29 02:56:09,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:09,289][root][INFO] - Training Epoch: 1/10, step 245/574 completed (loss: 3.4777116775512695, acc: 0.26923078298568726)
[2024-11-29 02:56:09,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:09,574][root][INFO] - Training Epoch: 1/10, step 246/574 completed (loss: 4.019870758056641, acc: 0.32258063554763794)
[2024-11-29 02:56:09,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:09,836][root][INFO] - Training Epoch: 1/10, step 247/574 completed (loss: 2.872628927230835, acc: 0.20000000298023224)
[2024-11-29 02:56:10,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:10,234][root][INFO] - Training Epoch: 1/10, step 248/574 completed (loss: 3.8282978534698486, acc: 0.2432432472705841)
[2024-11-29 02:56:10,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:10,587][root][INFO] - Training Epoch: 1/10, step 249/574 completed (loss: 3.870420217514038, acc: 0.1621621549129486)
[2024-11-29 02:56:10,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:10,952][root][INFO] - Training Epoch: 1/10, step 250/574 completed (loss: 4.035511493682861, acc: 0.1621621549129486)
[2024-11-29 02:56:11,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:11,298][root][INFO] - Training Epoch: 1/10, step 251/574 completed (loss: 4.034666061401367, acc: 0.1764705926179886)
[2024-11-29 02:56:11,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:11,598][root][INFO] - Training Epoch: 1/10, step 252/574 completed (loss: 2.961449384689331, acc: 0.4390243887901306)
[2024-11-29 02:56:11,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:11,868][root][INFO] - Training Epoch: 1/10, step 253/574 completed (loss: 3.654229164123535, acc: 0.23999999463558197)
[2024-11-29 02:56:12,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:12,136][root][INFO] - Training Epoch: 1/10, step 254/574 completed (loss: 2.5077431201934814, acc: 0.36000001430511475)
[2024-11-29 02:56:12,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:12,410][root][INFO] - Training Epoch: 1/10, step 255/574 completed (loss: 3.667104959487915, acc: 0.29032257199287415)
[2024-11-29 02:56:12,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:12,737][root][INFO] - Training Epoch: 1/10, step 256/574 completed (loss: 3.6990528106689453, acc: 0.21052631735801697)
[2024-11-29 02:56:12,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:13,115][root][INFO] - Training Epoch: 1/10, step 257/574 completed (loss: 3.5314245223999023, acc: 0.2571428716182709)
[2024-11-29 02:56:13,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:13,463][root][INFO] - Training Epoch: 1/10, step 258/574 completed (loss: 3.662541389465332, acc: 0.25)
[2024-11-29 02:56:13,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:14,269][root][INFO] - Training Epoch: 1/10, step 259/574 completed (loss: 3.4478166103363037, acc: 0.2924528419971466)
[2024-11-29 02:56:14,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:15,083][root][INFO] - Training Epoch: 1/10, step 260/574 completed (loss: 3.6575212478637695, acc: 0.2750000059604645)
[2024-11-29 02:56:15,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:15,422][root][INFO] - Training Epoch: 1/10, step 261/574 completed (loss: 3.4702234268188477, acc: 0.2777777910232544)
[2024-11-29 02:56:15,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:15,739][root][INFO] - Training Epoch: 1/10, step 262/574 completed (loss: 3.9191842079162598, acc: 0.25806450843811035)
[2024-11-29 02:56:16,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:16,148][root][INFO] - Training Epoch: 1/10, step 263/574 completed (loss: 3.2977399826049805, acc: 0.25333333015441895)
[2024-11-29 02:56:16,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:16,490][root][INFO] - Training Epoch: 1/10, step 264/574 completed (loss: 3.495363235473633, acc: 0.25)
[2024-11-29 02:56:17,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:17,822][root][INFO] - Training Epoch: 1/10, step 265/574 completed (loss: 3.57647442817688, acc: 0.2720000147819519)
[2024-11-29 02:56:18,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:18,193][root][INFO] - Training Epoch: 1/10, step 266/574 completed (loss: 3.1023905277252197, acc: 0.33707866072654724)
[2024-11-29 02:56:18,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:18,605][root][INFO] - Training Epoch: 1/10, step 267/574 completed (loss: 3.683515787124634, acc: 0.18918919563293457)
[2024-11-29 02:56:18,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:19,197][root][INFO] - Training Epoch: 1/10, step 268/574 completed (loss: 3.164795398712158, acc: 0.37931033968925476)
[2024-11-29 02:56:19,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:19,534][root][INFO] - Training Epoch: 1/10, step 269/574 completed (loss: 3.0610978603363037, acc: 0.27272728085517883)
[2024-11-29 02:56:19,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:19,827][root][INFO] - Training Epoch: 1/10, step 270/574 completed (loss: 2.0086796283721924, acc: 0.5454545617103577)
[2024-11-29 02:56:19,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:20,101][root][INFO] - Training Epoch: 1/10, step 271/574 completed (loss: 2.303513288497925, acc: 0.5625)
[2024-11-29 02:56:20,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:20,439][root][INFO] - Training Epoch: 1/10, step 272/574 completed (loss: 3.0545334815979004, acc: 0.4333333373069763)
[2024-11-29 02:56:20,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:20,896][root][INFO] - Training Epoch: 1/10, step 273/574 completed (loss: 3.04374361038208, acc: 0.4166666567325592)
[2024-11-29 02:56:21,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:21,232][root][INFO] - Training Epoch: 1/10, step 274/574 completed (loss: 2.987393379211426, acc: 0.46875)
[2024-11-29 02:56:21,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:21,548][root][INFO] - Training Epoch: 1/10, step 275/574 completed (loss: 3.1405558586120605, acc: 0.4000000059604645)
[2024-11-29 02:56:21,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:21,837][root][INFO] - Training Epoch: 1/10, step 276/574 completed (loss: 3.128253221511841, acc: 0.37931033968925476)
[2024-11-29 02:56:22,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:22,193][root][INFO] - Training Epoch: 1/10, step 277/574 completed (loss: 2.4304914474487305, acc: 0.4399999976158142)
[2024-11-29 02:56:22,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:22,537][root][INFO] - Training Epoch: 1/10, step 278/574 completed (loss: 3.428553819656372, acc: 0.2978723347187042)
[2024-11-29 02:56:22,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:22,880][root][INFO] - Training Epoch: 1/10, step 279/574 completed (loss: 3.294771432876587, acc: 0.3125)
[2024-11-29 02:56:23,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:23,172][root][INFO] - Training Epoch: 1/10, step 280/574 completed (loss: 2.6049997806549072, acc: 0.40909090638160706)
[2024-11-29 02:56:23,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:23,736][root][INFO] - Training Epoch: 1/10, step 281/574 completed (loss: 3.6054441928863525, acc: 0.1927710771560669)
[2024-11-29 02:56:23,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:24,155][root][INFO] - Training Epoch: 1/10, step 282/574 completed (loss: 3.2582943439483643, acc: 0.26851850748062134)
[2024-11-29 02:56:24,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:24,429][root][INFO] - Training Epoch: 1/10, step 283/574 completed (loss: 3.449195384979248, acc: 0.2368421107530594)
[2024-11-29 02:56:24,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:24,702][root][INFO] - Training Epoch: 1/10, step 284/574 completed (loss: 2.961578845977783, acc: 0.38235294818878174)
[2024-11-29 02:56:24,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:25,018][root][INFO] - Training Epoch: 1/10, step 285/574 completed (loss: 3.207411289215088, acc: 0.25)
[2024-11-29 02:56:26,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:26,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:26,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:27,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:27,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:28,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:28,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:29,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:29,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:30,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:30,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:30,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:31,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:31,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:32,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:32,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:33,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:33,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:34,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:34,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:34,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:35,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:35,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:35,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:36,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:36,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:37,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:37,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:38,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:38,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:39,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:39,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:40,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:40,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:41,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:41,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:41,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:42,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:42,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:43,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:43,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:44,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:44,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:44,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:45,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:45,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:45,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:46,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:46,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:47,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:47,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:47,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:48,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:48,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:49,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:49,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:49,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:50,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:50,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:51,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:51,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:52,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:52,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:53,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:53,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:54,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:54,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:55,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:56,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:56,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:57,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:57,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:58,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:58,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:58,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:59,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:56:59,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:00,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:00,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:01,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:01,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:02,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:02,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:03,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:03,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:04,221][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(22.9141, device='cuda:0') eval_epoch_loss=tensor(3.1318, device='cuda:0') eval_epoch_acc=tensor(0.3237, device='cuda:0')
[2024-11-29 02:57:04,223][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 02:57:04,223][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 02:57:04,676][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_1_step_286_loss_3.1317505836486816/model.pt
[2024-11-29 02:57:04,687][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 3.1317505836486816
[2024-11-29 02:57:04,688][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.32368412613868713
[2024-11-29 02:57:04,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:05,025][root][INFO] - Training Epoch: 1/10, step 286/574 completed (loss: 3.119016647338867, acc: 0.2734375)
[2024-11-29 02:57:05,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:05,347][root][INFO] - Training Epoch: 1/10, step 287/574 completed (loss: 3.6341280937194824, acc: 0.20000000298023224)
[2024-11-29 02:57:05,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:05,613][root][INFO] - Training Epoch: 1/10, step 288/574 completed (loss: 3.139892339706421, acc: 0.35164836049079895)
[2024-11-29 02:57:05,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:05,901][root][INFO] - Training Epoch: 1/10, step 289/574 completed (loss: 3.347043514251709, acc: 0.27950310707092285)
[2024-11-29 02:57:06,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:06,259][root][INFO] - Training Epoch: 1/10, step 290/574 completed (loss: 3.5601253509521484, acc: 0.2319587618112564)
[2024-11-29 02:57:06,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:06,588][root][INFO] - Training Epoch: 1/10, step 291/574 completed (loss: 2.644350290298462, acc: 0.3181818127632141)
[2024-11-29 02:57:06,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:06,852][root][INFO] - Training Epoch: 1/10, step 292/574 completed (loss: 2.9401378631591797, acc: 0.4285714328289032)
[2024-11-29 02:57:07,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:07,151][root][INFO] - Training Epoch: 1/10, step 293/574 completed (loss: 3.4432525634765625, acc: 0.24137930572032928)
[2024-11-29 02:57:07,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:07,810][root][INFO] - Training Epoch: 1/10, step 294/574 completed (loss: 2.573652505874634, acc: 0.4727272689342499)
[2024-11-29 02:57:08,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:08,632][root][INFO] - Training Epoch: 1/10, step 295/574 completed (loss: 2.9093048572540283, acc: 0.40721648931503296)
[2024-11-29 02:57:08,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:08,929][root][INFO] - Training Epoch: 1/10, step 296/574 completed (loss: 3.0158791542053223, acc: 0.24137930572032928)
[2024-11-29 02:57:09,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:09,258][root][INFO] - Training Epoch: 1/10, step 297/574 completed (loss: 2.8918256759643555, acc: 0.4444444477558136)
[2024-11-29 02:57:09,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:09,550][root][INFO] - Training Epoch: 1/10, step 298/574 completed (loss: 3.369671106338501, acc: 0.28947368264198303)
[2024-11-29 02:57:09,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:09,840][root][INFO] - Training Epoch: 1/10, step 299/574 completed (loss: 3.21338152885437, acc: 0.3214285671710968)
[2024-11-29 02:57:10,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:10,119][root][INFO] - Training Epoch: 1/10, step 300/574 completed (loss: 2.5246262550354004, acc: 0.40625)
[2024-11-29 02:57:10,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:10,416][root][INFO] - Training Epoch: 1/10, step 301/574 completed (loss: 3.2593257427215576, acc: 0.2830188572406769)
[2024-11-29 02:57:10,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:10,708][root][INFO] - Training Epoch: 1/10, step 302/574 completed (loss: 2.7154455184936523, acc: 0.5471698045730591)
[2024-11-29 02:57:10,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:10,948][root][INFO] - Training Epoch: 1/10, step 303/574 completed (loss: 2.649176597595215, acc: 0.4117647111415863)
[2024-11-29 02:57:11,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:11,226][root][INFO] - Training Epoch: 1/10, step 304/574 completed (loss: 2.888983964920044, acc: 0.3125)
[2024-11-29 02:57:11,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:11,582][root][INFO] - Training Epoch: 1/10, step 305/574 completed (loss: 2.9789845943450928, acc: 0.49180328845977783)
[2024-11-29 02:57:11,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:11,875][root][INFO] - Training Epoch: 1/10, step 306/574 completed (loss: 2.685363531112671, acc: 0.4000000059604645)
[2024-11-29 02:57:12,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:12,141][root][INFO] - Training Epoch: 1/10, step 307/574 completed (loss: 2.771879196166992, acc: 0.42105263471603394)
[2024-11-29 02:57:12,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:12,407][root][INFO] - Training Epoch: 1/10, step 308/574 completed (loss: 3.4063572883605957, acc: 0.24637681245803833)
[2024-11-29 02:57:12,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:12,918][root][INFO] - Training Epoch: 1/10, step 309/574 completed (loss: 3.2758450508117676, acc: 0.3611111044883728)
[2024-11-29 02:57:13,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:13,222][root][INFO] - Training Epoch: 1/10, step 310/574 completed (loss: 3.1275501251220703, acc: 0.3012048304080963)
[2024-11-29 02:57:13,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:13,522][root][INFO] - Training Epoch: 1/10, step 311/574 completed (loss: 3.2088234424591064, acc: 0.28205129504203796)
[2024-11-29 02:57:13,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:13,906][root][INFO] - Training Epoch: 1/10, step 312/574 completed (loss: 3.3818368911743164, acc: 0.2551020383834839)
[2024-11-29 02:57:14,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:14,168][root][INFO] - Training Epoch: 1/10, step 313/574 completed (loss: 2.680492401123047, acc: 0.4166666567325592)
[2024-11-29 02:57:14,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:14,445][root][INFO] - Training Epoch: 1/10, step 314/574 completed (loss: 2.642705202102661, acc: 0.3333333432674408)
[2024-11-29 02:57:14,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:14,727][root][INFO] - Training Epoch: 1/10, step 315/574 completed (loss: 2.9168074131011963, acc: 0.25806450843811035)
[2024-11-29 02:57:14,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:14,991][root][INFO] - Training Epoch: 1/10, step 316/574 completed (loss: 3.581146001815796, acc: 0.29032257199287415)
[2024-11-29 02:57:15,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:15,358][root][INFO] - Training Epoch: 1/10, step 317/574 completed (loss: 3.182288408279419, acc: 0.31343284249305725)
[2024-11-29 02:57:15,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:15,691][root][INFO] - Training Epoch: 1/10, step 318/574 completed (loss: 2.7604103088378906, acc: 0.3365384638309479)
[2024-11-29 02:57:15,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:15,967][root][INFO] - Training Epoch: 1/10, step 319/574 completed (loss: 3.2279717922210693, acc: 0.2666666805744171)
[2024-11-29 02:57:16,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:16,247][root][INFO] - Training Epoch: 1/10, step 320/574 completed (loss: 3.207756757736206, acc: 0.29032257199287415)
[2024-11-29 02:57:16,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:16,527][root][INFO] - Training Epoch: 1/10, step 321/574 completed (loss: 2.675797700881958, acc: 0.47999998927116394)
[2024-11-29 02:57:16,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:16,811][root][INFO] - Training Epoch: 1/10, step 322/574 completed (loss: 4.161144733428955, acc: 0.07407407462596893)
[2024-11-29 02:57:16,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:17,067][root][INFO] - Training Epoch: 1/10, step 323/574 completed (loss: 4.0562920570373535, acc: 0.11428571492433548)
[2024-11-29 02:57:17,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:17,342][root][INFO] - Training Epoch: 1/10, step 324/574 completed (loss: 3.829155921936035, acc: 0.20512820780277252)
[2024-11-29 02:57:17,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:17,664][root][INFO] - Training Epoch: 1/10, step 325/574 completed (loss: 3.673133611679077, acc: 0.24390244483947754)
[2024-11-29 02:57:17,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:18,000][root][INFO] - Training Epoch: 1/10, step 326/574 completed (loss: 3.254469394683838, acc: 0.2368421107530594)
[2024-11-29 02:57:18,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:18,286][root][INFO] - Training Epoch: 1/10, step 327/574 completed (loss: 3.3745341300964355, acc: 0.21052631735801697)
[2024-11-29 02:57:18,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:18,550][root][INFO] - Training Epoch: 1/10, step 328/574 completed (loss: 3.093687057495117, acc: 0.3571428656578064)
[2024-11-29 02:57:18,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:18,831][root][INFO] - Training Epoch: 1/10, step 329/574 completed (loss: 3.188652276992798, acc: 0.37037035822868347)
[2024-11-29 02:57:18,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:19,113][root][INFO] - Training Epoch: 1/10, step 330/574 completed (loss: 2.148111581802368, acc: 0.625)
[2024-11-29 02:57:19,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:19,440][root][INFO] - Training Epoch: 1/10, step 331/574 completed (loss: 3.2764246463775635, acc: 0.3870967626571655)
[2024-11-29 02:57:19,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:19,878][root][INFO] - Training Epoch: 1/10, step 332/574 completed (loss: 2.4936933517456055, acc: 0.5263158082962036)
[2024-11-29 02:57:20,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:20,211][root][INFO] - Training Epoch: 1/10, step 333/574 completed (loss: 3.16623592376709, acc: 0.25)
[2024-11-29 02:57:20,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:20,524][root][INFO] - Training Epoch: 1/10, step 334/574 completed (loss: 2.509007453918457, acc: 0.46666666865348816)
[2024-11-29 02:57:20,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:20,799][root][INFO] - Training Epoch: 1/10, step 335/574 completed (loss: 2.026386022567749, acc: 0.3684210479259491)
[2024-11-29 02:57:20,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:21,092][root][INFO] - Training Epoch: 1/10, step 336/574 completed (loss: 3.036137342453003, acc: 0.2800000011920929)
[2024-11-29 02:57:21,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:21,483][root][INFO] - Training Epoch: 1/10, step 337/574 completed (loss: 3.4442951679229736, acc: 0.25287356972694397)
[2024-11-29 02:57:21,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:21,871][root][INFO] - Training Epoch: 1/10, step 338/574 completed (loss: 3.4963057041168213, acc: 0.23404255509376526)
[2024-11-29 02:57:22,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:22,219][root][INFO] - Training Epoch: 1/10, step 339/574 completed (loss: 3.2977280616760254, acc: 0.28915661573410034)
[2024-11-29 02:57:22,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:22,481][root][INFO] - Training Epoch: 1/10, step 340/574 completed (loss: 1.8520563840866089, acc: 0.5652173757553101)
[2024-11-29 02:57:22,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:22,729][root][INFO] - Training Epoch: 1/10, step 341/574 completed (loss: 3.0729899406433105, acc: 0.38461539149284363)
[2024-11-29 02:57:22,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:23,023][root][INFO] - Training Epoch: 1/10, step 342/574 completed (loss: 3.782470703125, acc: 0.2409638613462448)
[2024-11-29 02:57:23,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:23,365][root][INFO] - Training Epoch: 1/10, step 343/574 completed (loss: 3.431077718734741, acc: 0.2830188572406769)
[2024-11-29 02:57:23,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:23,658][root][INFO] - Training Epoch: 1/10, step 344/574 completed (loss: 3.4225165843963623, acc: 0.2151898741722107)
[2024-11-29 02:57:23,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:23,940][root][INFO] - Training Epoch: 1/10, step 345/574 completed (loss: 2.9112300872802734, acc: 0.3921568691730499)
[2024-11-29 02:57:24,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:24,261][root][INFO] - Training Epoch: 1/10, step 346/574 completed (loss: 3.501953125, acc: 0.2537313401699066)
[2024-11-29 02:57:24,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:24,543][root][INFO] - Training Epoch: 1/10, step 347/574 completed (loss: 2.067823886871338, acc: 0.6000000238418579)
[2024-11-29 02:57:24,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:24,878][root][INFO] - Training Epoch: 1/10, step 348/574 completed (loss: 2.636584758758545, acc: 0.4000000059604645)
[2024-11-29 02:57:25,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:25,375][root][INFO] - Training Epoch: 1/10, step 349/574 completed (loss: 2.8645272254943848, acc: 0.4444444477558136)
[2024-11-29 02:57:25,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:25,670][root][INFO] - Training Epoch: 1/10, step 350/574 completed (loss: 2.826173782348633, acc: 0.44186046719551086)
[2024-11-29 02:57:25,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:25,978][root][INFO] - Training Epoch: 1/10, step 351/574 completed (loss: 3.11395001411438, acc: 0.3076923191547394)
[2024-11-29 02:57:26,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:26,415][root][INFO] - Training Epoch: 1/10, step 352/574 completed (loss: 3.651059627532959, acc: 0.17777778208255768)
[2024-11-29 02:57:26,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:26,690][root][INFO] - Training Epoch: 1/10, step 353/574 completed (loss: 1.6678194999694824, acc: 0.6086956262588501)
[2024-11-29 02:57:26,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:26,960][root][INFO] - Training Epoch: 1/10, step 354/574 completed (loss: 3.462033748626709, acc: 0.3076923191547394)
[2024-11-29 02:57:27,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:27,318][root][INFO] - Training Epoch: 1/10, step 355/574 completed (loss: 3.335318088531494, acc: 0.3076923191547394)
[2024-11-29 02:57:27,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:28,002][root][INFO] - Training Epoch: 1/10, step 356/574 completed (loss: 2.9563393592834473, acc: 0.321739137172699)
[2024-11-29 02:57:28,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:28,399][root][INFO] - Training Epoch: 1/10, step 357/574 completed (loss: 3.232607364654541, acc: 0.28260868787765503)
[2024-11-29 02:57:28,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:28,729][root][INFO] - Training Epoch: 1/10, step 358/574 completed (loss: 2.926544189453125, acc: 0.3877550959587097)
[2024-11-29 02:57:28,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:29,012][root][INFO] - Training Epoch: 1/10, step 359/574 completed (loss: 2.3914036750793457, acc: 0.5)
[2024-11-29 02:57:29,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:29,286][root][INFO] - Training Epoch: 1/10, step 360/574 completed (loss: 2.497166633605957, acc: 0.3076923191547394)
[2024-11-29 02:57:29,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:29,546][root][INFO] - Training Epoch: 1/10, step 361/574 completed (loss: 3.116483449935913, acc: 0.2926829159259796)
[2024-11-29 02:57:29,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:29,831][root][INFO] - Training Epoch: 1/10, step 362/574 completed (loss: 2.4322118759155273, acc: 0.42222222685813904)
[2024-11-29 02:57:30,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:30,125][root][INFO] - Training Epoch: 1/10, step 363/574 completed (loss: 3.2241106033325195, acc: 0.3552631437778473)
[2024-11-29 02:57:30,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:30,400][root][INFO] - Training Epoch: 1/10, step 364/574 completed (loss: 3.0694093704223633, acc: 0.3658536672592163)
[2024-11-29 02:57:30,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:30,653][root][INFO] - Training Epoch: 1/10, step 365/574 completed (loss: 2.7789196968078613, acc: 0.3636363744735718)
[2024-11-29 02:57:30,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:30,919][root][INFO] - Training Epoch: 1/10, step 366/574 completed (loss: 1.543382167816162, acc: 0.5416666865348816)
[2024-11-29 02:57:31,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:31,197][root][INFO] - Training Epoch: 1/10, step 367/574 completed (loss: 2.0356976985931396, acc: 0.5652173757553101)
[2024-11-29 02:57:31,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:31,529][root][INFO] - Training Epoch: 1/10, step 368/574 completed (loss: 2.469700574874878, acc: 0.3928571343421936)
[2024-11-29 02:57:31,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:31,794][root][INFO] - Training Epoch: 1/10, step 369/574 completed (loss: 2.700279951095581, acc: 0.53125)
[2024-11-29 02:57:32,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:32,660][root][INFO] - Training Epoch: 1/10, step 370/574 completed (loss: 3.3890321254730225, acc: 0.32121211290359497)
[2024-11-29 02:57:33,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:34,045][root][INFO] - Training Epoch: 1/10, step 371/574 completed (loss: 2.563128709793091, acc: 0.49056604504585266)
[2024-11-29 02:57:34,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:34,381][root][INFO] - Training Epoch: 1/10, step 372/574 completed (loss: 2.8594510555267334, acc: 0.35555556416511536)
[2024-11-29 02:57:34,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:34,737][root][INFO] - Training Epoch: 1/10, step 373/574 completed (loss: 2.891774892807007, acc: 0.375)
[2024-11-29 02:57:34,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:35,095][root][INFO] - Training Epoch: 1/10, step 374/574 completed (loss: 1.8283888101577759, acc: 0.5428571701049805)
[2024-11-29 02:57:35,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:35,357][root][INFO] - Training Epoch: 1/10, step 375/574 completed (loss: 1.8100759983062744, acc: 0.6000000238418579)
[2024-11-29 02:57:35,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:35,601][root][INFO] - Training Epoch: 1/10, step 376/574 completed (loss: 1.290299654006958, acc: 0.6521739363670349)
[2024-11-29 02:57:35,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:35,879][root][INFO] - Training Epoch: 1/10, step 377/574 completed (loss: 2.9638423919677734, acc: 0.4166666567325592)
[2024-11-29 02:57:36,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:36,255][root][INFO] - Training Epoch: 1/10, step 378/574 completed (loss: 2.210592031478882, acc: 0.5157894492149353)
[2024-11-29 02:57:36,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:37,103][root][INFO] - Training Epoch: 1/10, step 379/574 completed (loss: 2.570974826812744, acc: 0.42514970898628235)
[2024-11-29 02:57:37,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:37,602][root][INFO] - Training Epoch: 1/10, step 380/574 completed (loss: 2.335885524749756, acc: 0.4887218177318573)
[2024-11-29 02:57:38,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:39,523][root][INFO] - Training Epoch: 1/10, step 381/574 completed (loss: 2.7217156887054443, acc: 0.427807480096817)
[2024-11-29 02:57:39,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:40,313][root][INFO] - Training Epoch: 1/10, step 382/574 completed (loss: 2.0533010959625244, acc: 0.522522509098053)
[2024-11-29 02:57:40,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:40,637][root][INFO] - Training Epoch: 1/10, step 383/574 completed (loss: 2.9264469146728516, acc: 0.4285714328289032)
[2024-11-29 02:57:40,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:40,934][root][INFO] - Training Epoch: 1/10, step 384/574 completed (loss: 1.4909871816635132, acc: 0.6071428656578064)
[2024-11-29 02:57:41,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:41,187][root][INFO] - Training Epoch: 1/10, step 385/574 completed (loss: 2.152096748352051, acc: 0.53125)
[2024-11-29 02:57:41,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:41,469][root][INFO] - Training Epoch: 1/10, step 386/574 completed (loss: 2.2470061779022217, acc: 0.5277777910232544)
[2024-11-29 02:57:41,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:41,784][root][INFO] - Training Epoch: 1/10, step 387/574 completed (loss: 1.9741355180740356, acc: 0.5)
[2024-11-29 02:57:41,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:42,106][root][INFO] - Training Epoch: 1/10, step 388/574 completed (loss: 1.3923685550689697, acc: 0.6363636255264282)
[2024-11-29 02:57:42,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:42,378][root][INFO] - Training Epoch: 1/10, step 389/574 completed (loss: 1.4640828371047974, acc: 0.6000000238418579)
[2024-11-29 02:57:42,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:42,637][root][INFO] - Training Epoch: 1/10, step 390/574 completed (loss: 2.4286818504333496, acc: 0.4761904776096344)
[2024-11-29 02:57:42,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:42,912][root][INFO] - Training Epoch: 1/10, step 391/574 completed (loss: 2.5564677715301514, acc: 0.35185185074806213)
[2024-11-29 02:57:43,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:43,254][root][INFO] - Training Epoch: 1/10, step 392/574 completed (loss: 3.2217891216278076, acc: 0.25242719054222107)
[2024-11-29 02:57:43,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:43,998][root][INFO] - Training Epoch: 1/10, step 393/574 completed (loss: 2.8994674682617188, acc: 0.3529411852359772)
[2024-11-29 02:57:44,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:44,421][root][INFO] - Training Epoch: 1/10, step 394/574 completed (loss: 3.2408053874969482, acc: 0.25999999046325684)
[2024-11-29 02:57:44,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:44,886][root][INFO] - Training Epoch: 1/10, step 395/574 completed (loss: 2.9612200260162354, acc: 0.2777777910232544)
[2024-11-29 02:57:45,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:45,178][root][INFO] - Training Epoch: 1/10, step 396/574 completed (loss: 3.1355843544006348, acc: 0.3720930218696594)
[2024-11-29 02:57:45,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:45,458][root][INFO] - Training Epoch: 1/10, step 397/574 completed (loss: 2.0155913829803467, acc: 0.375)
[2024-11-29 02:57:45,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:45,791][root][INFO] - Training Epoch: 1/10, step 398/574 completed (loss: 2.496288299560547, acc: 0.3720930218696594)
[2024-11-29 02:57:45,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:46,105][root][INFO] - Training Epoch: 1/10, step 399/574 completed (loss: 1.8192908763885498, acc: 0.6000000238418579)
[2024-11-29 02:57:46,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:46,850][root][INFO] - Training Epoch: 1/10, step 400/574 completed (loss: 2.613466739654541, acc: 0.44117647409439087)
[2024-11-29 02:57:47,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:47,158][root][INFO] - Training Epoch: 1/10, step 401/574 completed (loss: 2.350184917449951, acc: 0.4533333480358124)
[2024-11-29 02:57:47,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:47,451][root][INFO] - Training Epoch: 1/10, step 402/574 completed (loss: 2.6315855979919434, acc: 0.4545454680919647)
[2024-11-29 02:57:47,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:47,719][root][INFO] - Training Epoch: 1/10, step 403/574 completed (loss: 1.8481348752975464, acc: 0.5151515007019043)
[2024-11-29 02:57:47,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:47,989][root][INFO] - Training Epoch: 1/10, step 404/574 completed (loss: 2.2257800102233887, acc: 0.3870967626571655)
[2024-11-29 02:57:48,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:48,280][root][INFO] - Training Epoch: 1/10, step 405/574 completed (loss: 1.7844293117523193, acc: 0.6666666865348816)
[2024-11-29 02:57:48,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:48,558][root][INFO] - Training Epoch: 1/10, step 406/574 completed (loss: 1.4984054565429688, acc: 0.6399999856948853)
[2024-11-29 02:57:48,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:48,853][root][INFO] - Training Epoch: 1/10, step 407/574 completed (loss: 1.442936897277832, acc: 0.6388888955116272)
[2024-11-29 02:57:49,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:49,153][root][INFO] - Training Epoch: 1/10, step 408/574 completed (loss: 1.2768471240997314, acc: 0.7037037014961243)
[2024-11-29 02:57:49,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:49,506][root][INFO] - Training Epoch: 1/10, step 409/574 completed (loss: 1.114532470703125, acc: 0.7307692170143127)
[2024-11-29 02:57:49,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:49,936][root][INFO] - Training Epoch: 1/10, step 410/574 completed (loss: 2.3667984008789062, acc: 0.48275861144065857)
[2024-11-29 02:57:50,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:50,275][root][INFO] - Training Epoch: 1/10, step 411/574 completed (loss: 2.467024564743042, acc: 0.4285714328289032)
[2024-11-29 02:57:50,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:50,599][root][INFO] - Training Epoch: 1/10, step 412/574 completed (loss: 1.796247959136963, acc: 0.46666666865348816)
[2024-11-29 02:57:50,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:50,961][root][INFO] - Training Epoch: 1/10, step 413/574 completed (loss: 1.4448826313018799, acc: 0.6666666865348816)
[2024-11-29 02:57:51,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:51,227][root][INFO] - Training Epoch: 1/10, step 414/574 completed (loss: 1.8484748601913452, acc: 0.6818181872367859)
[2024-11-29 02:57:51,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:51,517][root][INFO] - Training Epoch: 1/10, step 415/574 completed (loss: 2.366431951522827, acc: 0.4901960790157318)
[2024-11-29 02:57:51,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:51,803][root][INFO] - Training Epoch: 1/10, step 416/574 completed (loss: 1.8302674293518066, acc: 0.5384615659713745)
[2024-11-29 02:57:51,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:52,074][root][INFO] - Training Epoch: 1/10, step 417/574 completed (loss: 1.4270079135894775, acc: 0.7777777910232544)
[2024-11-29 02:57:52,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:52,395][root][INFO] - Training Epoch: 1/10, step 418/574 completed (loss: 2.692185640335083, acc: 0.4749999940395355)
[2024-11-29 02:57:52,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:52,792][root][INFO] - Training Epoch: 1/10, step 419/574 completed (loss: 2.07438325881958, acc: 0.44999998807907104)
[2024-11-29 02:57:53,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:53,124][root][INFO] - Training Epoch: 1/10, step 420/574 completed (loss: 2.1528913974761963, acc: 0.523809552192688)
[2024-11-29 02:57:53,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:53,403][root][INFO] - Training Epoch: 1/10, step 421/574 completed (loss: 1.8491517305374146, acc: 0.4333333373069763)
[2024-11-29 02:57:53,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:53,668][root][INFO] - Training Epoch: 1/10, step 422/574 completed (loss: 2.1707510948181152, acc: 0.40625)
[2024-11-29 02:57:53,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:53,955][root][INFO] - Training Epoch: 1/10, step 423/574 completed (loss: 2.665739059448242, acc: 0.2777777910232544)
[2024-11-29 02:57:54,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:54,249][root][INFO] - Training Epoch: 1/10, step 424/574 completed (loss: 3.142404079437256, acc: 0.4444444477558136)
[2024-11-29 02:57:54,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:54,528][root][INFO] - Training Epoch: 1/10, step 425/574 completed (loss: 1.6026678085327148, acc: 0.6363636255264282)
[2024-11-29 02:57:54,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:54,800][root][INFO] - Training Epoch: 1/10, step 426/574 completed (loss: 1.7113983631134033, acc: 0.5652173757553101)
[2024-11-29 02:57:54,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:55,094][root][INFO] - Training Epoch: 1/10, step 427/574 completed (loss: 1.9805927276611328, acc: 0.5405405163764954)
[2024-11-29 02:57:55,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:55,383][root][INFO] - Training Epoch: 1/10, step 428/574 completed (loss: 1.711591362953186, acc: 0.5185185074806213)
[2024-11-29 02:57:56,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:56,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:56,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:57,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:57,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:58,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:58,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:58,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:59,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:57:59,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:00,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:00,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:01,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:01,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:02,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:02,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:02,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:03,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:03,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:04,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:04,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:05,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:05,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:05,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:06,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:06,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:07,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:07,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:07,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:08,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:08,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:09,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:09,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:10,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:10,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:10,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:11,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:11,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:12,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:12,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:12,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:13,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:13,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:14,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:14,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:15,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:15,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:15,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:16,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:16,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:17,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:17,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:18,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:18,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:19,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:19,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:19,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:20,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:20,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:21,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:21,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:22,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:22,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:23,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:23,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:23,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:24,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:25,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:25,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:26,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:26,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:27,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:27,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:27,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:28,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:28,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:28,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:29,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:29,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:30,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:30,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:30,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:31,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:32,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:32,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:33,117][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(13.0778, device='cuda:0') eval_epoch_loss=tensor(2.5709, device='cuda:0') eval_epoch_acc=tensor(0.4334, device='cuda:0')
[2024-11-29 02:58:33,118][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 02:58:33,119][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 02:58:33,455][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_1_step_429_loss_2.5709147453308105/model.pt
[2024-11-29 02:58:33,465][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 2.5709147453308105
[2024-11-29 02:58:33,466][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.4333871006965637
[2024-11-29 02:58:33,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:33,761][root][INFO] - Training Epoch: 1/10, step 429/574 completed (loss: 1.7907434701919556, acc: 0.6086956262588501)
[2024-11-29 02:58:33,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:34,014][root][INFO] - Training Epoch: 1/10, step 430/574 completed (loss: 1.8107256889343262, acc: 0.6296296119689941)
[2024-11-29 02:58:34,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:34,400][root][INFO] - Training Epoch: 1/10, step 431/574 completed (loss: 1.3294241428375244, acc: 0.6666666865348816)
[2024-11-29 02:58:34,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:34,703][root][INFO] - Training Epoch: 1/10, step 432/574 completed (loss: 2.093433141708374, acc: 0.5652173757553101)
[2024-11-29 02:58:34,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:35,090][root][INFO] - Training Epoch: 1/10, step 433/574 completed (loss: 2.2556676864624023, acc: 0.5833333134651184)
[2024-11-29 02:58:35,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:35,360][root][INFO] - Training Epoch: 1/10, step 434/574 completed (loss: 0.6905229091644287, acc: 0.8799999952316284)
[2024-11-29 02:58:35,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:35,630][root][INFO] - Training Epoch: 1/10, step 435/574 completed (loss: 1.1804683208465576, acc: 0.8181818127632141)
[2024-11-29 02:58:35,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:35,926][root][INFO] - Training Epoch: 1/10, step 436/574 completed (loss: 2.1646597385406494, acc: 0.5277777910232544)
[2024-11-29 02:58:36,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:36,240][root][INFO] - Training Epoch: 1/10, step 437/574 completed (loss: 1.442117691040039, acc: 0.6590909361839294)
[2024-11-29 02:58:36,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:36,514][root][INFO] - Training Epoch: 1/10, step 438/574 completed (loss: 0.88623046875, acc: 0.6666666865348816)
[2024-11-29 02:58:36,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:36,853][root][INFO] - Training Epoch: 1/10, step 439/574 completed (loss: 1.927351713180542, acc: 0.5384615659713745)
[2024-11-29 02:58:37,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:37,526][root][INFO] - Training Epoch: 1/10, step 440/574 completed (loss: 2.7557294368743896, acc: 0.39393940567970276)
[2024-11-29 02:58:38,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:38,588][root][INFO] - Training Epoch: 1/10, step 441/574 completed (loss: 3.142245292663574, acc: 0.3199999928474426)
[2024-11-29 02:58:38,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:39,073][root][INFO] - Training Epoch: 1/10, step 442/574 completed (loss: 3.125701665878296, acc: 0.32258063554763794)
[2024-11-29 02:58:39,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:40,024][root][INFO] - Training Epoch: 1/10, step 443/574 completed (loss: 2.9877355098724365, acc: 0.2935323417186737)
[2024-11-29 02:58:40,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:40,296][root][INFO] - Training Epoch: 1/10, step 444/574 completed (loss: 2.358783006668091, acc: 0.49056604504585266)
[2024-11-29 02:58:40,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:40,828][root][INFO] - Training Epoch: 1/10, step 445/574 completed (loss: 2.107346773147583, acc: 0.5454545617103577)
[2024-11-29 02:58:40,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:41,101][root][INFO] - Training Epoch: 1/10, step 446/574 completed (loss: 1.2776782512664795, acc: 0.782608687877655)
[2024-11-29 02:58:41,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:41,372][root][INFO] - Training Epoch: 1/10, step 447/574 completed (loss: 1.6662272214889526, acc: 0.5769230723381042)
[2024-11-29 02:58:41,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:41,637][root][INFO] - Training Epoch: 1/10, step 448/574 completed (loss: 1.3253659009933472, acc: 0.7142857313156128)
[2024-11-29 02:58:41,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:41,999][root][INFO] - Training Epoch: 1/10, step 449/574 completed (loss: 2.737548351287842, acc: 0.4776119291782379)
[2024-11-29 02:58:42,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:42,325][root][INFO] - Training Epoch: 1/10, step 450/574 completed (loss: 2.0345239639282227, acc: 0.5277777910232544)
[2024-11-29 02:58:42,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:42,637][root][INFO] - Training Epoch: 1/10, step 451/574 completed (loss: 2.6270177364349365, acc: 0.4021739065647125)
[2024-11-29 02:58:42,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:42,924][root][INFO] - Training Epoch: 1/10, step 452/574 completed (loss: 2.322537422180176, acc: 0.4743589758872986)
[2024-11-29 02:58:43,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:43,217][root][INFO] - Training Epoch: 1/10, step 453/574 completed (loss: 2.5655181407928467, acc: 0.46052631735801697)
[2024-11-29 02:58:43,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:43,493][root][INFO] - Training Epoch: 1/10, step 454/574 completed (loss: 2.0314078330993652, acc: 0.5714285969734192)
[2024-11-29 02:58:43,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:43,825][root][INFO] - Training Epoch: 1/10, step 455/574 completed (loss: 1.3577966690063477, acc: 0.5454545617103577)
[2024-11-29 02:58:43,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:44,088][root][INFO] - Training Epoch: 1/10, step 456/574 completed (loss: 2.2130625247955322, acc: 0.4329896867275238)
[2024-11-29 02:58:44,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:44,369][root][INFO] - Training Epoch: 1/10, step 457/574 completed (loss: 2.1651740074157715, acc: 0.4571428596973419)
[2024-11-29 02:58:44,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:44,822][root][INFO] - Training Epoch: 1/10, step 458/574 completed (loss: 2.6886343955993652, acc: 0.35465115308761597)
[2024-11-29 02:58:44,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:45,122][root][INFO] - Training Epoch: 1/10, step 459/574 completed (loss: 2.6175544261932373, acc: 0.4107142984867096)
[2024-11-29 02:58:45,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:45,449][root][INFO] - Training Epoch: 1/10, step 460/574 completed (loss: 2.4347283840179443, acc: 0.4444444477558136)
[2024-11-29 02:58:45,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:45,754][root][INFO] - Training Epoch: 1/10, step 461/574 completed (loss: 1.7123920917510986, acc: 0.5833333134651184)
[2024-11-29 02:58:45,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:46,023][root][INFO] - Training Epoch: 1/10, step 462/574 completed (loss: 1.961918592453003, acc: 0.53125)
[2024-11-29 02:58:46,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:46,296][root][INFO] - Training Epoch: 1/10, step 463/574 completed (loss: 1.0636858940124512, acc: 0.692307710647583)
[2024-11-29 02:58:46,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:46,609][root][INFO] - Training Epoch: 1/10, step 464/574 completed (loss: 1.7065750360488892, acc: 0.5)
[2024-11-29 02:58:46,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:46,896][root][INFO] - Training Epoch: 1/10, step 465/574 completed (loss: 2.3401801586151123, acc: 0.488095223903656)
[2024-11-29 02:58:47,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:47,156][root][INFO] - Training Epoch: 1/10, step 466/574 completed (loss: 2.5042521953582764, acc: 0.4337349534034729)
[2024-11-29 02:58:47,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:47,537][root][INFO] - Training Epoch: 1/10, step 467/574 completed (loss: 2.3349311351776123, acc: 0.4864864945411682)
[2024-11-29 02:58:47,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:47,846][root][INFO] - Training Epoch: 1/10, step 468/574 completed (loss: 2.5545763969421387, acc: 0.41747573018074036)
[2024-11-29 02:58:48,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:48,167][root][INFO] - Training Epoch: 1/10, step 469/574 completed (loss: 2.5277087688446045, acc: 0.3739837408065796)
[2024-11-29 02:58:48,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:48,437][root][INFO] - Training Epoch: 1/10, step 470/574 completed (loss: 1.7094489336013794, acc: 0.625)
[2024-11-29 02:58:48,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:48,704][root][INFO] - Training Epoch: 1/10, step 471/574 completed (loss: 2.098161220550537, acc: 0.4285714328289032)
[2024-11-29 02:58:48,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:49,212][root][INFO] - Training Epoch: 1/10, step 472/574 completed (loss: 2.4447104930877686, acc: 0.44117647409439087)
[2024-11-29 02:58:49,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:49,596][root][INFO] - Training Epoch: 1/10, step 473/574 completed (loss: 2.8243393898010254, acc: 0.3056768476963043)
[2024-11-29 02:58:49,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:49,948][root][INFO] - Training Epoch: 1/10, step 474/574 completed (loss: 2.297351598739624, acc: 0.46875)
[2024-11-29 02:58:50,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:50,260][root][INFO] - Training Epoch: 1/10, step 475/574 completed (loss: 2.423292636871338, acc: 0.43558281660079956)
[2024-11-29 02:58:50,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:50,596][root][INFO] - Training Epoch: 1/10, step 476/574 completed (loss: 2.3474209308624268, acc: 0.4532374143600464)
[2024-11-29 02:58:50,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:50,975][root][INFO] - Training Epoch: 1/10, step 477/574 completed (loss: 2.6994049549102783, acc: 0.3668341636657715)
[2024-11-29 02:58:51,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:51,287][root][INFO] - Training Epoch: 1/10, step 478/574 completed (loss: 2.141228675842285, acc: 0.5277777910232544)
[2024-11-29 02:58:51,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:51,608][root][INFO] - Training Epoch: 1/10, step 479/574 completed (loss: 1.7850139141082764, acc: 0.6363636255264282)
[2024-11-29 02:58:51,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:51,906][root][INFO] - Training Epoch: 1/10, step 480/574 completed (loss: 1.6954355239868164, acc: 0.6296296119689941)
[2024-11-29 02:58:52,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:52,140][root][INFO] - Training Epoch: 1/10, step 481/574 completed (loss: 2.4879097938537598, acc: 0.44999998807907104)
[2024-11-29 02:58:52,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:52,453][root][INFO] - Training Epoch: 1/10, step 482/574 completed (loss: 2.572713851928711, acc: 0.44999998807907104)
[2024-11-29 02:58:52,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:52,934][root][INFO] - Training Epoch: 1/10, step 483/574 completed (loss: 2.5475893020629883, acc: 0.37931033968925476)
[2024-11-29 02:58:53,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:53,198][root][INFO] - Training Epoch: 1/10, step 484/574 completed (loss: 1.6664947271347046, acc: 0.6129032373428345)
[2024-11-29 02:58:53,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:53,475][root][INFO] - Training Epoch: 1/10, step 485/574 completed (loss: 1.4778587818145752, acc: 0.6842105388641357)
[2024-11-29 02:58:53,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:53,767][root][INFO] - Training Epoch: 1/10, step 486/574 completed (loss: 2.864588737487793, acc: 0.40740740299224854)
[2024-11-29 02:58:53,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:54,019][root][INFO] - Training Epoch: 1/10, step 487/574 completed (loss: 1.9226139783859253, acc: 0.523809552192688)
[2024-11-29 02:58:54,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:54,272][root][INFO] - Training Epoch: 1/10, step 488/574 completed (loss: 2.7832298278808594, acc: 0.4545454680919647)
[2024-11-29 02:58:54,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:54,705][root][INFO] - Training Epoch: 1/10, step 489/574 completed (loss: 2.354835271835327, acc: 0.446153849363327)
[2024-11-29 02:58:54,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:54,969][root][INFO] - Training Epoch: 1/10, step 490/574 completed (loss: 1.4290419816970825, acc: 0.6000000238418579)
[2024-11-29 02:58:55,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:55,295][root][INFO] - Training Epoch: 1/10, step 491/574 completed (loss: 1.4419102668762207, acc: 0.6551724076271057)
[2024-11-29 02:58:55,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:55,593][root][INFO] - Training Epoch: 1/10, step 492/574 completed (loss: 2.241208791732788, acc: 0.4313725531101227)
[2024-11-29 02:58:55,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:55,879][root][INFO] - Training Epoch: 1/10, step 493/574 completed (loss: 1.3860422372817993, acc: 0.6551724076271057)
[2024-11-29 02:58:56,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:56,152][root][INFO] - Training Epoch: 1/10, step 494/574 completed (loss: 1.929290533065796, acc: 0.6315789222717285)
[2024-11-29 02:58:56,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:56,425][root][INFO] - Training Epoch: 1/10, step 495/574 completed (loss: 2.7065844535827637, acc: 0.31578946113586426)
[2024-11-29 02:58:56,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:56,785][root][INFO] - Training Epoch: 1/10, step 496/574 completed (loss: 2.3817713260650635, acc: 0.4553571343421936)
[2024-11-29 02:58:57,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:57,213][root][INFO] - Training Epoch: 1/10, step 497/574 completed (loss: 1.9051376581192017, acc: 0.483146071434021)
[2024-11-29 02:58:57,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:57,535][root][INFO] - Training Epoch: 1/10, step 498/574 completed (loss: 2.3196537494659424, acc: 0.40449437499046326)
[2024-11-29 02:58:57,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:57,860][root][INFO] - Training Epoch: 1/10, step 499/574 completed (loss: 2.7652645111083984, acc: 0.3333333432674408)
[2024-11-29 02:58:58,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:58,171][root][INFO] - Training Epoch: 1/10, step 500/574 completed (loss: 2.419235944747925, acc: 0.52173912525177)
[2024-11-29 02:58:58,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:58,420][root][INFO] - Training Epoch: 1/10, step 501/574 completed (loss: 0.9966699481010437, acc: 0.7200000286102295)
[2024-11-29 02:58:58,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:58,688][root][INFO] - Training Epoch: 1/10, step 502/574 completed (loss: 0.7579842209815979, acc: 0.807692289352417)
[2024-11-29 02:58:58,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:59,015][root][INFO] - Training Epoch: 1/10, step 503/574 completed (loss: 1.6734517812728882, acc: 0.5185185074806213)
[2024-11-29 02:58:59,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:59,285][root][INFO] - Training Epoch: 1/10, step 504/574 completed (loss: 1.6898614168167114, acc: 0.5185185074806213)
[2024-11-29 02:58:59,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:59,591][root][INFO] - Training Epoch: 1/10, step 505/574 completed (loss: 1.8723137378692627, acc: 0.6415094137191772)
[2024-11-29 02:58:59,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:58:59,945][root][INFO] - Training Epoch: 1/10, step 506/574 completed (loss: 2.2450618743896484, acc: 0.37931033968925476)
[2024-11-29 02:59:00,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:00,830][root][INFO] - Training Epoch: 1/10, step 507/574 completed (loss: 2.6964454650878906, acc: 0.4864864945411682)
[2024-11-29 02:59:01,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:01,399][root][INFO] - Training Epoch: 1/10, step 508/574 completed (loss: 2.7863848209381104, acc: 0.4084506928920746)
[2024-11-29 02:59:01,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:01,658][root][INFO] - Training Epoch: 1/10, step 509/574 completed (loss: 0.8943134546279907, acc: 0.800000011920929)
[2024-11-29 02:59:01,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:01,969][root][INFO] - Training Epoch: 1/10, step 510/574 completed (loss: 1.4794763326644897, acc: 0.6666666865348816)
[2024-11-29 02:59:02,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:02,221][root][INFO] - Training Epoch: 1/10, step 511/574 completed (loss: 1.082719087600708, acc: 0.7692307829856873)
[2024-11-29 02:59:05,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:06,373][root][INFO] - Training Epoch: 1/10, step 512/574 completed (loss: 3.0389761924743652, acc: 0.3214285671710968)
[2024-11-29 02:59:07,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:07,475][root][INFO] - Training Epoch: 1/10, step 513/574 completed (loss: 2.3768270015716553, acc: 0.460317462682724)
[2024-11-29 02:59:07,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:07,785][root][INFO] - Training Epoch: 1/10, step 514/574 completed (loss: 1.8626080751419067, acc: 0.6428571343421936)
[2024-11-29 02:59:08,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:08,130][root][INFO] - Training Epoch: 1/10, step 515/574 completed (loss: 1.0512492656707764, acc: 0.75)
[2024-11-29 02:59:08,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:09,116][root][INFO] - Training Epoch: 1/10, step 516/574 completed (loss: 2.171191930770874, acc: 0.5416666865348816)
[2024-11-29 02:59:09,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:09,398][root][INFO] - Training Epoch: 1/10, step 517/574 completed (loss: 0.6834695339202881, acc: 0.8846153616905212)
[2024-11-29 02:59:09,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:09,685][root][INFO] - Training Epoch: 1/10, step 518/574 completed (loss: 2.043596029281616, acc: 0.5161290168762207)
[2024-11-29 02:59:09,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:10,002][root][INFO] - Training Epoch: 1/10, step 519/574 completed (loss: 1.2979247570037842, acc: 0.6499999761581421)
[2024-11-29 02:59:10,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:10,283][root][INFO] - Training Epoch: 1/10, step 520/574 completed (loss: 1.7764356136322021, acc: 0.5555555820465088)
[2024-11-29 02:59:11,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:11,808][root][INFO] - Training Epoch: 1/10, step 521/574 completed (loss: 2.5626232624053955, acc: 0.3813559412956238)
[2024-11-29 02:59:12,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:12,201][root][INFO] - Training Epoch: 1/10, step 522/574 completed (loss: 2.0878188610076904, acc: 0.5223880410194397)
[2024-11-29 02:59:12,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:12,610][root][INFO] - Training Epoch: 1/10, step 523/574 completed (loss: 2.2366812229156494, acc: 0.45985400676727295)
[2024-11-29 02:59:13,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:13,386][root][INFO] - Training Epoch: 1/10, step 524/574 completed (loss: 2.4158568382263184, acc: 0.4399999976158142)
[2024-11-29 02:59:13,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:13,664][root][INFO] - Training Epoch: 1/10, step 525/574 completed (loss: 1.1242363452911377, acc: 0.6666666865348816)
[2024-11-29 02:59:13,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:13,951][root][INFO] - Training Epoch: 1/10, step 526/574 completed (loss: 1.5323957204818726, acc: 0.5961538553237915)
[2024-11-29 02:59:14,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:14,212][root][INFO] - Training Epoch: 1/10, step 527/574 completed (loss: 1.4084975719451904, acc: 0.6666666865348816)
[2024-11-29 02:59:14,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:14,492][root][INFO] - Training Epoch: 1/10, step 528/574 completed (loss: 3.0442895889282227, acc: 0.26229506731033325)
[2024-11-29 02:59:14,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:14,770][root][INFO] - Training Epoch: 1/10, step 529/574 completed (loss: 1.9747728109359741, acc: 0.5423728823661804)
[2024-11-29 02:59:14,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:15,075][root][INFO] - Training Epoch: 1/10, step 530/574 completed (loss: 3.339466094970703, acc: 0.302325576543808)
[2024-11-29 02:59:15,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:15,400][root][INFO] - Training Epoch: 1/10, step 531/574 completed (loss: 2.464345693588257, acc: 0.4318181872367859)
[2024-11-29 02:59:15,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:15,683][root][INFO] - Training Epoch: 1/10, step 532/574 completed (loss: 2.9514100551605225, acc: 0.37735849618911743)
[2024-11-29 02:59:15,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:16,039][root][INFO] - Training Epoch: 1/10, step 533/574 completed (loss: 2.2978038787841797, acc: 0.47727271914482117)
[2024-11-29 02:59:16,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:16,338][root][INFO] - Training Epoch: 1/10, step 534/574 completed (loss: 2.270808458328247, acc: 0.5199999809265137)
[2024-11-29 02:59:16,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:16,619][root][INFO] - Training Epoch: 1/10, step 535/574 completed (loss: 1.2714629173278809, acc: 0.800000011920929)
[2024-11-29 02:59:16,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:16,878][root][INFO] - Training Epoch: 1/10, step 536/574 completed (loss: 1.0103294849395752, acc: 0.7727272510528564)
[2024-11-29 02:59:17,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:17,376][root][INFO] - Training Epoch: 1/10, step 537/574 completed (loss: 1.9722621440887451, acc: 0.5384615659713745)
[2024-11-29 02:59:17,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:17,744][root][INFO] - Training Epoch: 1/10, step 538/574 completed (loss: 1.8373446464538574, acc: 0.546875)
[2024-11-29 02:59:17,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:18,195][root][INFO] - Training Epoch: 1/10, step 539/574 completed (loss: 1.7291955947875977, acc: 0.6875)
[2024-11-29 02:59:18,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:18,473][root][INFO] - Training Epoch: 1/10, step 540/574 completed (loss: 1.92534601688385, acc: 0.6060606241226196)
[2024-11-29 02:59:18,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:18,787][root][INFO] - Training Epoch: 1/10, step 541/574 completed (loss: 1.7097010612487793, acc: 0.5625)
[2024-11-29 02:59:18,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:19,044][root][INFO] - Training Epoch: 1/10, step 542/574 completed (loss: 1.2129745483398438, acc: 0.6451612710952759)
[2024-11-29 02:59:19,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:19,297][root][INFO] - Training Epoch: 1/10, step 543/574 completed (loss: 0.6810822486877441, acc: 0.8260869383811951)
[2024-11-29 02:59:19,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:19,553][root][INFO] - Training Epoch: 1/10, step 544/574 completed (loss: 1.363153338432312, acc: 0.6333333253860474)
[2024-11-29 02:59:19,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:19,857][root][INFO] - Training Epoch: 1/10, step 545/574 completed (loss: 1.3578650951385498, acc: 0.6585366129875183)
[2024-11-29 02:59:20,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:20,126][root][INFO] - Training Epoch: 1/10, step 546/574 completed (loss: 0.578208863735199, acc: 0.8857142925262451)
[2024-11-29 02:59:20,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:20,407][root][INFO] - Training Epoch: 1/10, step 547/574 completed (loss: 1.5151211023330688, acc: 0.7105262875556946)
[2024-11-29 02:59:20,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:20,688][root][INFO] - Training Epoch: 1/10, step 548/574 completed (loss: 1.5298329591751099, acc: 0.6774193644523621)
[2024-11-29 02:59:20,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:20,943][root][INFO] - Training Epoch: 1/10, step 549/574 completed (loss: 0.9857882857322693, acc: 0.7200000286102295)
[2024-11-29 02:59:21,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:21,233][root][INFO] - Training Epoch: 1/10, step 550/574 completed (loss: 1.4592920541763306, acc: 0.7575757503509521)
[2024-11-29 02:59:21,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:21,501][root][INFO] - Training Epoch: 1/10, step 551/574 completed (loss: 1.1285215616226196, acc: 0.699999988079071)
[2024-11-29 02:59:21,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:21,742][root][INFO] - Training Epoch: 1/10, step 552/574 completed (loss: 1.3015238046646118, acc: 0.6571428775787354)
[2024-11-29 02:59:21,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:22,034][root][INFO] - Training Epoch: 1/10, step 553/574 completed (loss: 2.2113254070281982, acc: 0.43795621395111084)
[2024-11-29 02:59:22,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:22,315][root][INFO] - Training Epoch: 1/10, step 554/574 completed (loss: 1.8311645984649658, acc: 0.565517246723175)
[2024-11-29 02:59:22,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:22,651][root][INFO] - Training Epoch: 1/10, step 555/574 completed (loss: 2.199362277984619, acc: 0.48571428656578064)
[2024-11-29 02:59:22,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:22,965][root][INFO] - Training Epoch: 1/10, step 556/574 completed (loss: 2.186222791671753, acc: 0.49668875336647034)
[2024-11-29 02:59:23,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:23,265][root][INFO] - Training Epoch: 1/10, step 557/574 completed (loss: 1.9306516647338867, acc: 0.5213675498962402)
[2024-11-29 02:59:23,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:23,509][root][INFO] - Training Epoch: 1/10, step 558/574 completed (loss: 1.1481093168258667, acc: 0.6800000071525574)
[2024-11-29 02:59:23,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:23,801][root][INFO] - Training Epoch: 1/10, step 559/574 completed (loss: 1.7468689680099487, acc: 0.6153846383094788)
[2024-11-29 02:59:23,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:24,066][root][INFO] - Training Epoch: 1/10, step 560/574 completed (loss: 0.8704966306686401, acc: 0.8461538553237915)
[2024-11-29 02:59:24,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:24,408][root][INFO] - Training Epoch: 1/10, step 561/574 completed (loss: 2.0346412658691406, acc: 0.5641025900840759)
[2024-11-29 02:59:24,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:24,747][root][INFO] - Training Epoch: 1/10, step 562/574 completed (loss: 1.7472670078277588, acc: 0.5555555820465088)
[2024-11-29 02:59:24,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:25,006][root][INFO] - Training Epoch: 1/10, step 563/574 completed (loss: 2.0665011405944824, acc: 0.4935064911842346)
[2024-11-29 02:59:25,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:25,275][root][INFO] - Training Epoch: 1/10, step 564/574 completed (loss: 1.6610201597213745, acc: 0.5625)
[2024-11-29 02:59:25,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:25,557][root][INFO] - Training Epoch: 1/10, step 565/574 completed (loss: 1.6528483629226685, acc: 0.6206896305084229)
[2024-11-29 02:59:25,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:25,842][root][INFO] - Training Epoch: 1/10, step 566/574 completed (loss: 1.6659255027770996, acc: 0.6428571343421936)
[2024-11-29 02:59:25,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:26,095][root][INFO] - Training Epoch: 1/10, step 567/574 completed (loss: 1.0291311740875244, acc: 0.6578947305679321)
[2024-11-29 02:59:26,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:26,363][root][INFO] - Training Epoch: 1/10, step 568/574 completed (loss: 0.44927147030830383, acc: 0.9259259104728699)
[2024-11-29 02:59:26,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:26,798][root][INFO] - Training Epoch: 1/10, step 569/574 completed (loss: 2.283064126968384, acc: 0.48128342628479004)
[2024-11-29 02:59:26,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:27,061][root][INFO] - Training Epoch: 1/10, step 570/574 completed (loss: 0.9643309116363525, acc: 0.774193525314331)
[2024-11-29 02:59:27,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:27,386][root][INFO] - Training Epoch: 1/10, step 571/574 completed (loss: 2.0940730571746826, acc: 0.5641025900840759)
[2024-11-29 02:59:28,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:28,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:29,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:29,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:30,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:30,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:31,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:31,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:31,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:32,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:32,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:33,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:33,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:34,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:34,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:35,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:35,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:36,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:36,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:37,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:37,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:38,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:38,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:38,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:39,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:39,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:40,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:40,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:40,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:41,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:41,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:42,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:42,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:43,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:43,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:44,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:44,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:44,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:45,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:45,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:46,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:46,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:47,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:47,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:48,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:48,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:48,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:49,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:49,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:50,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:50,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:50,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:51,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:51,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:52,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:52,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:53,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:53,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:54,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:54,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:55,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:55,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:56,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:56,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:57,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:57,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:58,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:58,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:59,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 02:59:59,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:00,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:00,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:01,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:01,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:02,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:02,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:02,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:03,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:03,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:04,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:04,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:05,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:05,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:06,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:06,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:07,092][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(5.3806, device='cuda:0') eval_epoch_loss=tensor(1.6828, device='cuda:0') eval_epoch_acc=tensor(0.5986, device='cuda:0')
[2024-11-29 03:00:07,094][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:00:07,094][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:00:07,503][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_1_step_572_loss_1.6828027963638306/model.pt
[2024-11-29 03:00:07,508][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 1.6828027963638306
[2024-11-29 03:00:07,508][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.5986418128013611
[2024-11-29 03:00:07,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:07,802][root][INFO] - Training Epoch: 1/10, step 572/574 completed (loss: 2.439267158508301, acc: 0.40816327929496765)
[2024-11-29 03:00:07,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:08,153][root][INFO] - Training Epoch: 1/10, step 573/574 completed (loss: 2.426513910293579, acc: 0.402515709400177)
[2024-11-29 03:00:08,742][slam_llm.utils.train_utils][INFO] - Epoch 1: train_perplexity=29.0810, train_epoch_loss=3.3701, epoch time 403.12254108302295s
[2024-11-29 03:00:08,742][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 12 GB
[2024-11-29 03:00:08,743][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 16 GB
[2024-11-29 03:00:08,743][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 12 GB
[2024-11-29 03:00:08,743][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 3
[2024-11-29 03:00:08,743][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-29 03:00:09,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:09,513][root][INFO] - Training Epoch: 2/10, step 0/574 completed (loss: 1.623363971710205, acc: 0.6296296119689941)
[2024-11-29 03:00:09,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:09,818][root][INFO] - Training Epoch: 2/10, step 1/574 completed (loss: 1.4109501838684082, acc: 0.7599999904632568)
[2024-11-29 03:00:10,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:10,132][root][INFO] - Training Epoch: 2/10, step 2/574 completed (loss: 1.8865729570388794, acc: 0.5945945978164673)
[2024-11-29 03:00:10,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:10,494][root][INFO] - Training Epoch: 2/10, step 3/574 completed (loss: 1.6687631607055664, acc: 0.6315789222717285)
[2024-11-29 03:00:10,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:10,806][root][INFO] - Training Epoch: 2/10, step 4/574 completed (loss: 1.4203022718429565, acc: 0.6486486196517944)
[2024-11-29 03:00:10,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:11,083][root][INFO] - Training Epoch: 2/10, step 5/574 completed (loss: 1.1968975067138672, acc: 0.6785714030265808)
[2024-11-29 03:00:11,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:11,437][root][INFO] - Training Epoch: 2/10, step 6/574 completed (loss: 1.7071783542633057, acc: 0.5510203838348389)
[2024-11-29 03:00:11,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:11,751][root][INFO] - Training Epoch: 2/10, step 7/574 completed (loss: 1.1248691082000732, acc: 0.7333333492279053)
[2024-11-29 03:00:11,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:12,096][root][INFO] - Training Epoch: 2/10, step 8/574 completed (loss: 1.0545085668563843, acc: 0.7272727489471436)
[2024-11-29 03:00:12,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:12,417][root][INFO] - Training Epoch: 2/10, step 9/574 completed (loss: 0.6286543607711792, acc: 0.8846153616905212)
[2024-11-29 03:00:12,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:12,722][root][INFO] - Training Epoch: 2/10, step 10/574 completed (loss: 0.9119277000427246, acc: 0.7037037014961243)
[2024-11-29 03:00:12,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:13,030][root][INFO] - Training Epoch: 2/10, step 11/574 completed (loss: 1.7042046785354614, acc: 0.6153846383094788)
[2024-11-29 03:00:13,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:13,337][root][INFO] - Training Epoch: 2/10, step 12/574 completed (loss: 1.3903318643569946, acc: 0.6363636255264282)
[2024-11-29 03:00:13,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:13,652][root][INFO] - Training Epoch: 2/10, step 13/574 completed (loss: 1.1504075527191162, acc: 0.717391312122345)
[2024-11-29 03:00:13,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:13,949][root][INFO] - Training Epoch: 2/10, step 14/574 completed (loss: 1.574316143989563, acc: 0.5882353186607361)
[2024-11-29 03:00:14,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:14,207][root][INFO] - Training Epoch: 2/10, step 15/574 completed (loss: 1.6944621801376343, acc: 0.6530612111091614)
[2024-11-29 03:00:14,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:14,500][root][INFO] - Training Epoch: 2/10, step 16/574 completed (loss: 1.2404441833496094, acc: 0.7368420958518982)
[2024-11-29 03:00:14,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:14,825][root][INFO] - Training Epoch: 2/10, step 17/574 completed (loss: 1.8338251113891602, acc: 0.6666666865348816)
[2024-11-29 03:00:15,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:15,134][root][INFO] - Training Epoch: 2/10, step 18/574 completed (loss: 2.4199304580688477, acc: 0.4444444477558136)
[2024-11-29 03:00:15,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:15,426][root][INFO] - Training Epoch: 2/10, step 19/574 completed (loss: 0.8594351410865784, acc: 0.6842105388641357)
[2024-11-29 03:00:15,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:15,747][root][INFO] - Training Epoch: 2/10, step 20/574 completed (loss: 2.0204763412475586, acc: 0.5)
[2024-11-29 03:00:15,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:16,081][root][INFO] - Training Epoch: 2/10, step 21/574 completed (loss: 1.6425583362579346, acc: 0.5862069129943848)
[2024-11-29 03:00:16,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:16,386][root][INFO] - Training Epoch: 2/10, step 22/574 completed (loss: 1.4517592191696167, acc: 0.6399999856948853)
[2024-11-29 03:00:16,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:16,712][root][INFO] - Training Epoch: 2/10, step 23/574 completed (loss: 0.9756027460098267, acc: 0.8095238208770752)
[2024-11-29 03:00:16,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:17,091][root][INFO] - Training Epoch: 2/10, step 24/574 completed (loss: 0.9633165597915649, acc: 0.875)
[2024-11-29 03:00:17,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:17,408][root][INFO] - Training Epoch: 2/10, step 25/574 completed (loss: 1.9738584756851196, acc: 0.49056604504585266)
[2024-11-29 03:00:17,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:17,698][root][INFO] - Training Epoch: 2/10, step 26/574 completed (loss: 1.9260345697402954, acc: 0.5753424763679504)
[2024-11-29 03:00:18,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:19,390][root][INFO] - Training Epoch: 2/10, step 27/574 completed (loss: 2.699323892593384, acc: 0.38735178112983704)
[2024-11-29 03:00:19,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:19,643][root][INFO] - Training Epoch: 2/10, step 28/574 completed (loss: 2.2372379302978516, acc: 0.44186046719551086)
[2024-11-29 03:00:19,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:19,897][root][INFO] - Training Epoch: 2/10, step 29/574 completed (loss: 1.8697848320007324, acc: 0.5180723071098328)
[2024-11-29 03:00:20,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:20,162][root][INFO] - Training Epoch: 2/10, step 30/574 completed (loss: 2.128450870513916, acc: 0.4938271641731262)
[2024-11-29 03:00:20,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:20,418][root][INFO] - Training Epoch: 2/10, step 31/574 completed (loss: 1.7909756898880005, acc: 0.6071428656578064)
[2024-11-29 03:00:20,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:20,656][root][INFO] - Training Epoch: 2/10, step 32/574 completed (loss: 0.9286519289016724, acc: 0.8888888955116272)
[2024-11-29 03:00:20,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:20,903][root][INFO] - Training Epoch: 2/10, step 33/574 completed (loss: 1.1009776592254639, acc: 0.6521739363670349)
[2024-11-29 03:00:21,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:21,205][root][INFO] - Training Epoch: 2/10, step 34/574 completed (loss: 1.5948450565338135, acc: 0.6134454011917114)
[2024-11-29 03:00:21,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:21,467][root][INFO] - Training Epoch: 2/10, step 35/574 completed (loss: 1.3772807121276855, acc: 0.6557376980781555)
[2024-11-29 03:00:21,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:21,761][root][INFO] - Training Epoch: 2/10, step 36/574 completed (loss: 1.4149664640426636, acc: 0.6507936716079712)
[2024-11-29 03:00:21,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:22,030][root][INFO] - Training Epoch: 2/10, step 37/574 completed (loss: 1.7028576135635376, acc: 0.694915235042572)
[2024-11-29 03:00:22,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:22,343][root][INFO] - Training Epoch: 2/10, step 38/574 completed (loss: 1.2971680164337158, acc: 0.6896551847457886)
[2024-11-29 03:00:22,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:22,657][root][INFO] - Training Epoch: 2/10, step 39/574 completed (loss: 1.5206787586212158, acc: 0.523809552192688)
[2024-11-29 03:00:22,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:22,912][root][INFO] - Training Epoch: 2/10, step 40/574 completed (loss: 1.3450201749801636, acc: 0.6538461446762085)
[2024-11-29 03:00:23,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:23,293][root][INFO] - Training Epoch: 2/10, step 41/574 completed (loss: 2.24251127243042, acc: 0.5270270109176636)
[2024-11-29 03:00:23,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:23,639][root][INFO] - Training Epoch: 2/10, step 42/574 completed (loss: 2.4847283363342285, acc: 0.4615384638309479)
[2024-11-29 03:00:23,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:24,103][root][INFO] - Training Epoch: 2/10, step 43/574 completed (loss: 2.023178815841675, acc: 0.49494948983192444)
[2024-11-29 03:00:24,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:24,569][root][INFO] - Training Epoch: 2/10, step 44/574 completed (loss: 1.9232783317565918, acc: 0.5773195624351501)
[2024-11-29 03:00:24,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:25,007][root][INFO] - Training Epoch: 2/10, step 45/574 completed (loss: 2.01011061668396, acc: 0.5441176295280457)
[2024-11-29 03:00:25,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:25,255][root][INFO] - Training Epoch: 2/10, step 46/574 completed (loss: 1.2462916374206543, acc: 0.7692307829856873)
[2024-11-29 03:00:25,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:25,516][root][INFO] - Training Epoch: 2/10, step 47/574 completed (loss: 0.7407347559928894, acc: 0.8148148059844971)
[2024-11-29 03:00:25,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:25,819][root][INFO] - Training Epoch: 2/10, step 48/574 completed (loss: 0.9647836685180664, acc: 0.75)
[2024-11-29 03:00:25,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:26,094][root][INFO] - Training Epoch: 2/10, step 49/574 completed (loss: 1.3710130453109741, acc: 0.6666666865348816)
[2024-11-29 03:00:26,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:26,446][root][INFO] - Training Epoch: 2/10, step 50/574 completed (loss: 1.8093700408935547, acc: 0.6140350699424744)
[2024-11-29 03:00:26,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:26,735][root][INFO] - Training Epoch: 2/10, step 51/574 completed (loss: 2.2707321643829346, acc: 0.5079365372657776)
[2024-11-29 03:00:26,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:26,999][root][INFO] - Training Epoch: 2/10, step 52/574 completed (loss: 2.890442371368408, acc: 0.3802816867828369)
[2024-11-29 03:00:27,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:27,543][root][INFO] - Training Epoch: 2/10, step 53/574 completed (loss: 3.0029215812683105, acc: 0.35333332419395447)
[2024-11-29 03:00:27,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:27,797][root][INFO] - Training Epoch: 2/10, step 54/574 completed (loss: 2.281473398208618, acc: 0.5135135054588318)
[2024-11-29 03:00:27,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:28,094][root][INFO] - Training Epoch: 2/10, step 55/574 completed (loss: 0.5114083886146545, acc: 0.807692289352417)
[2024-11-29 03:00:31,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:32,432][root][INFO] - Training Epoch: 2/10, step 56/574 completed (loss: 2.3049354553222656, acc: 0.48122867941856384)
[2024-11-29 03:00:33,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:34,188][root][INFO] - Training Epoch: 2/10, step 57/574 completed (loss: 2.76456880569458, acc: 0.3965141475200653)
[2024-11-29 03:00:34,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:35,140][root][INFO] - Training Epoch: 2/10, step 58/574 completed (loss: 2.216237783432007, acc: 0.4943181872367859)
[2024-11-29 03:00:35,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:35,911][root][INFO] - Training Epoch: 2/10, step 59/574 completed (loss: 1.9219658374786377, acc: 0.5588235259056091)
[2024-11-29 03:00:36,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:36,658][root][INFO] - Training Epoch: 2/10, step 60/574 completed (loss: 1.9634923934936523, acc: 0.52173912525177)
[2024-11-29 03:00:36,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:37,140][root][INFO] - Training Epoch: 2/10, step 61/574 completed (loss: 1.9261138439178467, acc: 0.5625)
[2024-11-29 03:00:37,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:37,416][root][INFO] - Training Epoch: 2/10, step 62/574 completed (loss: 1.171208381652832, acc: 0.7058823704719543)
[2024-11-29 03:00:37,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:37,711][root][INFO] - Training Epoch: 2/10, step 63/574 completed (loss: 1.0327872037887573, acc: 0.6666666865348816)
[2024-11-29 03:00:37,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:38,112][root][INFO] - Training Epoch: 2/10, step 64/574 completed (loss: 0.9908207654953003, acc: 0.8125)
[2024-11-29 03:00:38,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:38,461][root][INFO] - Training Epoch: 2/10, step 65/574 completed (loss: 0.58485347032547, acc: 0.8620689511299133)
[2024-11-29 03:00:38,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:38,789][root][INFO] - Training Epoch: 2/10, step 66/574 completed (loss: 1.9894784688949585, acc: 0.5357142686843872)
[2024-11-29 03:00:38,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:39,111][root][INFO] - Training Epoch: 2/10, step 67/574 completed (loss: 1.7049182653427124, acc: 0.6333333253860474)
[2024-11-29 03:00:39,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:39,401][root][INFO] - Training Epoch: 2/10, step 68/574 completed (loss: 0.7407757639884949, acc: 0.9200000166893005)
[2024-11-29 03:00:39,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:39,651][root][INFO] - Training Epoch: 2/10, step 69/574 completed (loss: 1.7252377271652222, acc: 0.5833333134651184)
[2024-11-29 03:00:39,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:39,880][root][INFO] - Training Epoch: 2/10, step 70/574 completed (loss: 2.482595443725586, acc: 0.39393940567970276)
[2024-11-29 03:00:40,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:40,207][root][INFO] - Training Epoch: 2/10, step 71/574 completed (loss: 2.5147619247436523, acc: 0.4117647111415863)
[2024-11-29 03:00:40,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:40,492][root][INFO] - Training Epoch: 2/10, step 72/574 completed (loss: 1.892309546470642, acc: 0.4761904776096344)
[2024-11-29 03:00:40,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:40,790][root][INFO] - Training Epoch: 2/10, step 73/574 completed (loss: 2.72440242767334, acc: 0.40512821078300476)
[2024-11-29 03:00:40,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:41,039][root][INFO] - Training Epoch: 2/10, step 74/574 completed (loss: 2.4655449390411377, acc: 0.4183673560619354)
[2024-11-29 03:00:41,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:41,325][root][INFO] - Training Epoch: 2/10, step 75/574 completed (loss: 2.3332505226135254, acc: 0.44029849767684937)
[2024-11-29 03:00:41,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:41,737][root][INFO] - Training Epoch: 2/10, step 76/574 completed (loss: 2.538421392440796, acc: 0.4416058361530304)
[2024-11-29 03:00:41,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:42,031][root][INFO] - Training Epoch: 2/10, step 77/574 completed (loss: 0.4398999810218811, acc: 0.9523809552192688)
[2024-11-29 03:00:42,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:42,353][root][INFO] - Training Epoch: 2/10, step 78/574 completed (loss: 0.9246872067451477, acc: 0.75)
[2024-11-29 03:00:42,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:42,655][root][INFO] - Training Epoch: 2/10, step 79/574 completed (loss: 1.232446312904358, acc: 0.6666666865348816)
[2024-11-29 03:00:42,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:42,949][root][INFO] - Training Epoch: 2/10, step 80/574 completed (loss: 1.106002926826477, acc: 0.7692307829856873)
[2024-11-29 03:00:43,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:43,252][root][INFO] - Training Epoch: 2/10, step 81/574 completed (loss: 1.7800943851470947, acc: 0.6538461446762085)
[2024-11-29 03:00:43,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:43,571][root][INFO] - Training Epoch: 2/10, step 82/574 completed (loss: 2.1423842906951904, acc: 0.5384615659713745)
[2024-11-29 03:00:43,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:43,916][root][INFO] - Training Epoch: 2/10, step 83/574 completed (loss: 0.7019431591033936, acc: 0.84375)
[2024-11-29 03:00:44,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:44,272][root][INFO] - Training Epoch: 2/10, step 84/574 completed (loss: 1.5551151037216187, acc: 0.6376811861991882)
[2024-11-29 03:00:44,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:44,631][root][INFO] - Training Epoch: 2/10, step 85/574 completed (loss: 1.677968144416809, acc: 0.5799999833106995)
[2024-11-29 03:00:44,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:44,982][root][INFO] - Training Epoch: 2/10, step 86/574 completed (loss: 0.8998957276344299, acc: 0.8695651888847351)
[2024-11-29 03:00:45,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:45,578][root][INFO] - Training Epoch: 2/10, step 87/574 completed (loss: 2.138603925704956, acc: 0.5)
[2024-11-29 03:00:45,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:45,885][root][INFO] - Training Epoch: 2/10, step 88/574 completed (loss: 1.9710273742675781, acc: 0.5145630836486816)
[2024-11-29 03:00:46,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:47,596][root][INFO] - Training Epoch: 2/10, step 89/574 completed (loss: 1.9232555627822876, acc: 0.5776699185371399)
[2024-11-29 03:00:48,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:48,780][root][INFO] - Training Epoch: 2/10, step 90/574 completed (loss: 2.383971929550171, acc: 0.40860214829444885)
[2024-11-29 03:00:49,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:49,909][root][INFO] - Training Epoch: 2/10, step 91/574 completed (loss: 1.9849803447723389, acc: 0.5215517282485962)
[2024-11-29 03:00:50,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:50,956][root][INFO] - Training Epoch: 2/10, step 92/574 completed (loss: 1.762030005455017, acc: 0.5368421077728271)
[2024-11-29 03:00:51,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:52,449][root][INFO] - Training Epoch: 2/10, step 93/574 completed (loss: 2.8317930698394775, acc: 0.3366336524486542)
[2024-11-29 03:00:52,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:52,772][root][INFO] - Training Epoch: 2/10, step 94/574 completed (loss: 2.167764186859131, acc: 0.4516128897666931)
[2024-11-29 03:00:52,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:53,125][root][INFO] - Training Epoch: 2/10, step 95/574 completed (loss: 2.0859224796295166, acc: 0.4492753744125366)
[2024-11-29 03:00:53,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:53,483][root][INFO] - Training Epoch: 2/10, step 96/574 completed (loss: 2.8318119049072266, acc: 0.3025210201740265)
[2024-11-29 03:00:53,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:53,836][root][INFO] - Training Epoch: 2/10, step 97/574 completed (loss: 2.631948232650757, acc: 0.36538460850715637)
[2024-11-29 03:00:54,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:54,230][root][INFO] - Training Epoch: 2/10, step 98/574 completed (loss: 2.6345722675323486, acc: 0.34306567907333374)
[2024-11-29 03:00:54,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:54,622][root][INFO] - Training Epoch: 2/10, step 99/574 completed (loss: 3.042503595352173, acc: 0.28358209133148193)
[2024-11-29 03:00:54,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:54,924][root][INFO] - Training Epoch: 2/10, step 100/574 completed (loss: 1.9243509769439697, acc: 0.5)
[2024-11-29 03:00:55,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:55,188][root][INFO] - Training Epoch: 2/10, step 101/574 completed (loss: 0.5019786357879639, acc: 0.9090909361839294)
[2024-11-29 03:00:55,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:55,455][root][INFO] - Training Epoch: 2/10, step 102/574 completed (loss: 0.626554012298584, acc: 0.782608687877655)
[2024-11-29 03:00:55,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:55,773][root][INFO] - Training Epoch: 2/10, step 103/574 completed (loss: 0.7814905047416687, acc: 0.7727272510528564)
[2024-11-29 03:00:55,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:56,102][root][INFO] - Training Epoch: 2/10, step 104/574 completed (loss: 1.594323992729187, acc: 0.6724137663841248)
[2024-11-29 03:00:56,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:56,440][root][INFO] - Training Epoch: 2/10, step 105/574 completed (loss: 1.1580582857131958, acc: 0.6744186282157898)
[2024-11-29 03:00:56,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:56,760][root][INFO] - Training Epoch: 2/10, step 106/574 completed (loss: 1.0491257905960083, acc: 0.6800000071525574)
[2024-11-29 03:00:56,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:57,102][root][INFO] - Training Epoch: 2/10, step 107/574 completed (loss: 0.49657994508743286, acc: 0.8823529481887817)
[2024-11-29 03:00:57,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:57,408][root][INFO] - Training Epoch: 2/10, step 108/574 completed (loss: 0.5056055784225464, acc: 0.8846153616905212)
[2024-11-29 03:00:57,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:57,704][root][INFO] - Training Epoch: 2/10, step 109/574 completed (loss: 1.1690478324890137, acc: 0.738095223903656)
[2024-11-29 03:00:57,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:58,002][root][INFO] - Training Epoch: 2/10, step 110/574 completed (loss: 1.4588220119476318, acc: 0.6000000238418579)
[2024-11-29 03:00:58,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:58,454][root][INFO] - Training Epoch: 2/10, step 111/574 completed (loss: 1.9851558208465576, acc: 0.5263158082962036)
[2024-11-29 03:00:58,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:58,833][root][INFO] - Training Epoch: 2/10, step 112/574 completed (loss: 1.7145551443099976, acc: 0.5438596606254578)
[2024-11-29 03:00:59,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:59,121][root][INFO] - Training Epoch: 2/10, step 113/574 completed (loss: 1.4613198041915894, acc: 0.5897436141967773)
[2024-11-29 03:00:59,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:59,509][root][INFO] - Training Epoch: 2/10, step 114/574 completed (loss: 0.7862915992736816, acc: 0.795918345451355)
[2024-11-29 03:00:59,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:00:59,801][root][INFO] - Training Epoch: 2/10, step 115/574 completed (loss: 1.3758816719055176, acc: 0.7272727489471436)
[2024-11-29 03:00:59,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:00,102][root][INFO] - Training Epoch: 2/10, step 116/574 completed (loss: 1.8589632511138916, acc: 0.5396825671195984)
[2024-11-29 03:01:00,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:00,389][root][INFO] - Training Epoch: 2/10, step 117/574 completed (loss: 2.009612798690796, acc: 0.5609756112098694)
[2024-11-29 03:01:00,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:00,728][root][INFO] - Training Epoch: 2/10, step 118/574 completed (loss: 1.6695224046707153, acc: 0.6451612710952759)
[2024-11-29 03:01:01,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:01,932][root][INFO] - Training Epoch: 2/10, step 119/574 completed (loss: 2.180858850479126, acc: 0.47148290276527405)
[2024-11-29 03:01:02,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:02,221][root][INFO] - Training Epoch: 2/10, step 120/574 completed (loss: 1.6898443698883057, acc: 0.6000000238418579)
[2024-11-29 03:01:02,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:02,674][root][INFO] - Training Epoch: 2/10, step 121/574 completed (loss: 1.537764310836792, acc: 0.692307710647583)
[2024-11-29 03:01:02,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:02,993][root][INFO] - Training Epoch: 2/10, step 122/574 completed (loss: 1.1893256902694702, acc: 0.6666666865348816)
[2024-11-29 03:01:03,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:03,286][root][INFO] - Training Epoch: 2/10, step 123/574 completed (loss: 1.374638557434082, acc: 0.6315789222717285)
[2024-11-29 03:01:03,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:03,591][root][INFO] - Training Epoch: 2/10, step 124/574 completed (loss: 2.6130332946777344, acc: 0.3680981695652008)
[2024-11-29 03:01:03,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:03,927][root][INFO] - Training Epoch: 2/10, step 125/574 completed (loss: 2.2614293098449707, acc: 0.4791666567325592)
[2024-11-29 03:01:04,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:04,243][root][INFO] - Training Epoch: 2/10, step 126/574 completed (loss: 2.3412654399871826, acc: 0.3916666805744171)
[2024-11-29 03:01:04,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:04,614][root][INFO] - Training Epoch: 2/10, step 127/574 completed (loss: 2.4525668621063232, acc: 0.3928571343421936)
[2024-11-29 03:01:04,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:04,965][root][INFO] - Training Epoch: 2/10, step 128/574 completed (loss: 2.2786941528320312, acc: 0.4307692348957062)
[2024-11-29 03:01:05,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:05,406][root][INFO] - Training Epoch: 2/10, step 129/574 completed (loss: 2.3839449882507324, acc: 0.45588234066963196)
[2024-11-29 03:01:05,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:05,689][root][INFO] - Training Epoch: 2/10, step 130/574 completed (loss: 2.111755847930908, acc: 0.5)
[2024-11-29 03:01:05,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:06,014][root][INFO] - Training Epoch: 2/10, step 131/574 completed (loss: 1.6551636457443237, acc: 0.47826087474823)
[2024-11-29 03:01:06,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:06,332][root][INFO] - Training Epoch: 2/10, step 132/574 completed (loss: 2.6602611541748047, acc: 0.375)
[2024-11-29 03:01:06,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:06,629][root][INFO] - Training Epoch: 2/10, step 133/574 completed (loss: 1.8057090044021606, acc: 0.52173912525177)
[2024-11-29 03:01:06,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:06,953][root][INFO] - Training Epoch: 2/10, step 134/574 completed (loss: 1.9323464632034302, acc: 0.5142857432365417)
[2024-11-29 03:01:07,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:07,260][root][INFO] - Training Epoch: 2/10, step 135/574 completed (loss: 1.953075885772705, acc: 0.42307692766189575)
[2024-11-29 03:01:07,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:07,543][root][INFO] - Training Epoch: 2/10, step 136/574 completed (loss: 1.933919072151184, acc: 0.5)
[2024-11-29 03:01:07,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:07,809][root][INFO] - Training Epoch: 2/10, step 137/574 completed (loss: 2.0575735569000244, acc: 0.4333333373069763)
[2024-11-29 03:01:07,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:08,081][root][INFO] - Training Epoch: 2/10, step 138/574 completed (loss: 1.5883928537368774, acc: 0.47826087474823)
[2024-11-29 03:01:08,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:08,338][root][INFO] - Training Epoch: 2/10, step 139/574 completed (loss: 1.9098482131958008, acc: 0.523809552192688)
[2024-11-29 03:01:08,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:08,631][root][INFO] - Training Epoch: 2/10, step 140/574 completed (loss: 1.987709641456604, acc: 0.5)
[2024-11-29 03:01:09,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:10,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:10,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:10,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:11,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:11,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:12,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:12,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:13,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:13,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:14,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:14,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:15,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:15,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:16,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:16,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:17,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:17,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:17,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:18,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:18,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:19,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:19,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:20,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:20,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:20,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:21,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:21,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:22,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:22,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:23,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:23,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:23,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:24,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:24,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:25,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:25,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:26,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:26,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:26,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:27,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:27,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:28,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:28,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:29,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:29,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:30,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:30,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:30,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:31,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:31,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:31,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:32,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:32,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:33,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:33,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:34,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:34,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:35,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:35,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:35,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:36,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:37,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:37,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:38,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:38,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:39,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:39,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:40,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:40,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:41,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:41,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:41,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:42,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:42,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:43,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:43,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:43,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:44,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:44,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:45,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:45,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:46,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:46,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:46,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:47,665][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(5.3081, device='cuda:0') eval_epoch_loss=tensor(1.6692, device='cuda:0') eval_epoch_acc=tensor(0.5902, device='cuda:0')
[2024-11-29 03:01:47,668][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:01:47,669][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:01:48,137][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_2_step_141_loss_1.6692408323287964/model.pt
[2024-11-29 03:01:48,143][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 1.6692408323287964
[2024-11-29 03:01:48,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:48,511][root][INFO] - Training Epoch: 2/10, step 141/574 completed (loss: 2.3549704551696777, acc: 0.29032257199287415)
[2024-11-29 03:01:48,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:48,797][root][INFO] - Training Epoch: 2/10, step 142/574 completed (loss: 1.4503552913665771, acc: 0.5945945978164673)
[2024-11-29 03:01:49,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:49,494][root][INFO] - Training Epoch: 2/10, step 143/574 completed (loss: 1.7575923204421997, acc: 0.5614035129547119)
[2024-11-29 03:01:49,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:49,857][root][INFO] - Training Epoch: 2/10, step 144/574 completed (loss: 1.7358604669570923, acc: 0.5895522236824036)
[2024-11-29 03:01:50,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:50,192][root][INFO] - Training Epoch: 2/10, step 145/574 completed (loss: 1.8161423206329346, acc: 0.47959184646606445)
[2024-11-29 03:01:50,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:50,748][root][INFO] - Training Epoch: 2/10, step 146/574 completed (loss: 2.0388247966766357, acc: 0.43617022037506104)
[2024-11-29 03:01:50,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:51,033][root][INFO] - Training Epoch: 2/10, step 147/574 completed (loss: 1.6751477718353271, acc: 0.6000000238418579)
[2024-11-29 03:01:51,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:51,311][root][INFO] - Training Epoch: 2/10, step 148/574 completed (loss: 1.890583872795105, acc: 0.4642857015132904)
[2024-11-29 03:01:51,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:51,655][root][INFO] - Training Epoch: 2/10, step 149/574 completed (loss: 1.9678115844726562, acc: 0.52173912525177)
[2024-11-29 03:01:51,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:51,946][root][INFO] - Training Epoch: 2/10, step 150/574 completed (loss: 2.0875120162963867, acc: 0.48275861144065857)
[2024-11-29 03:01:52,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:52,236][root][INFO] - Training Epoch: 2/10, step 151/574 completed (loss: 1.615430474281311, acc: 0.6086956262588501)
[2024-11-29 03:01:52,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:52,590][root][INFO] - Training Epoch: 2/10, step 152/574 completed (loss: 1.3257927894592285, acc: 0.694915235042572)
[2024-11-29 03:01:52,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:52,878][root][INFO] - Training Epoch: 2/10, step 153/574 completed (loss: 2.3576691150665283, acc: 0.42105263471603394)
[2024-11-29 03:01:53,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:53,202][root][INFO] - Training Epoch: 2/10, step 154/574 completed (loss: 1.483447790145874, acc: 0.6351351141929626)
[2024-11-29 03:01:53,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:53,495][root][INFO] - Training Epoch: 2/10, step 155/574 completed (loss: 1.0107285976409912, acc: 0.8214285969734192)
[2024-11-29 03:01:53,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:53,735][root][INFO] - Training Epoch: 2/10, step 156/574 completed (loss: 1.5727195739746094, acc: 0.5652173757553101)
[2024-11-29 03:01:53,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:54,056][root][INFO] - Training Epoch: 2/10, step 157/574 completed (loss: 3.6886708736419678, acc: 0.31578946113586426)
[2024-11-29 03:01:55,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:56,621][root][INFO] - Training Epoch: 2/10, step 158/574 completed (loss: 3.1796863079071045, acc: 0.3513513505458832)
[2024-11-29 03:01:56,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:56,944][root][INFO] - Training Epoch: 2/10, step 159/574 completed (loss: 2.835272789001465, acc: 0.3888888955116272)
[2024-11-29 03:01:57,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:57,410][root][INFO] - Training Epoch: 2/10, step 160/574 completed (loss: 2.995358467102051, acc: 0.3604651093482971)
[2024-11-29 03:01:57,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:58,230][root][INFO] - Training Epoch: 2/10, step 161/574 completed (loss: 2.920799970626831, acc: 0.3764705955982208)
[2024-11-29 03:01:58,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:58,986][root][INFO] - Training Epoch: 2/10, step 162/574 completed (loss: 2.895510673522949, acc: 0.3483146131038666)
[2024-11-29 03:01:59,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:59,262][root][INFO] - Training Epoch: 2/10, step 163/574 completed (loss: 1.8297556638717651, acc: 0.5454545617103577)
[2024-11-29 03:01:59,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:59,566][root][INFO] - Training Epoch: 2/10, step 164/574 completed (loss: 2.3564701080322266, acc: 0.523809552192688)
[2024-11-29 03:01:59,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:01:59,922][root][INFO] - Training Epoch: 2/10, step 165/574 completed (loss: 2.228524684906006, acc: 0.517241358757019)
[2024-11-29 03:02:00,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:00,259][root][INFO] - Training Epoch: 2/10, step 166/574 completed (loss: 0.8986612558364868, acc: 0.6938775777816772)
[2024-11-29 03:02:00,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:00,550][root][INFO] - Training Epoch: 2/10, step 167/574 completed (loss: 0.9534385800361633, acc: 0.7799999713897705)
[2024-11-29 03:02:00,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:00,998][root][INFO] - Training Epoch: 2/10, step 168/574 completed (loss: 1.3072185516357422, acc: 0.6805555820465088)
[2024-11-29 03:02:01,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:01,297][root][INFO] - Training Epoch: 2/10, step 169/574 completed (loss: 1.901039481163025, acc: 0.5392156839370728)
[2024-11-29 03:02:02,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:02,873][root][INFO] - Training Epoch: 2/10, step 170/574 completed (loss: 2.683852434158325, acc: 0.4383561611175537)
[2024-11-29 03:02:03,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:03,149][root][INFO] - Training Epoch: 2/10, step 171/574 completed (loss: 1.3374876976013184, acc: 0.6666666865348816)
[2024-11-29 03:02:03,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:03,497][root][INFO] - Training Epoch: 2/10, step 172/574 completed (loss: 2.123706579208374, acc: 0.5185185074806213)
[2024-11-29 03:02:03,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:03,792][root][INFO] - Training Epoch: 2/10, step 173/574 completed (loss: 1.990630865097046, acc: 0.6071428656578064)
[2024-11-29 03:02:04,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:04,511][root][INFO] - Training Epoch: 2/10, step 174/574 completed (loss: 2.126779317855835, acc: 0.4601770043373108)
[2024-11-29 03:02:04,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:04,760][root][INFO] - Training Epoch: 2/10, step 175/574 completed (loss: 1.9818350076675415, acc: 0.5797101259231567)
[2024-11-29 03:02:04,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:05,045][root][INFO] - Training Epoch: 2/10, step 176/574 completed (loss: 1.624891996383667, acc: 0.5454545617103577)
[2024-11-29 03:02:05,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:06,423][root][INFO] - Training Epoch: 2/10, step 177/574 completed (loss: 2.4103806018829346, acc: 0.4198473393917084)
[2024-11-29 03:02:06,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:07,365][root][INFO] - Training Epoch: 2/10, step 178/574 completed (loss: 2.3080408573150635, acc: 0.45185184478759766)
[2024-11-29 03:02:07,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:07,660][root][INFO] - Training Epoch: 2/10, step 179/574 completed (loss: 1.6358473300933838, acc: 0.6229507923126221)
[2024-11-29 03:02:07,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:07,962][root][INFO] - Training Epoch: 2/10, step 180/574 completed (loss: 0.29507195949554443, acc: 1.0)
[2024-11-29 03:02:08,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:08,246][root][INFO] - Training Epoch: 2/10, step 181/574 completed (loss: 0.36061355471611023, acc: 0.9599999785423279)
[2024-11-29 03:02:08,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:08,549][root][INFO] - Training Epoch: 2/10, step 182/574 completed (loss: 1.0383857488632202, acc: 0.75)
[2024-11-29 03:02:08,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:08,857][root][INFO] - Training Epoch: 2/10, step 183/574 completed (loss: 1.1831204891204834, acc: 0.6341463327407837)
[2024-11-29 03:02:09,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:09,203][root][INFO] - Training Epoch: 2/10, step 184/574 completed (loss: 1.7743661403656006, acc: 0.6012084484100342)
[2024-11-29 03:02:09,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:09,551][root][INFO] - Training Epoch: 2/10, step 185/574 completed (loss: 1.887128233909607, acc: 0.5158501267433167)
[2024-11-29 03:02:09,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:10,157][root][INFO] - Training Epoch: 2/10, step 186/574 completed (loss: 2.2086687088012695, acc: 0.41874998807907104)
[2024-11-29 03:02:10,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:10,795][root][INFO] - Training Epoch: 2/10, step 187/574 completed (loss: 2.2353243827819824, acc: 0.4784240126609802)
[2024-11-29 03:02:11,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:11,242][root][INFO] - Training Epoch: 2/10, step 188/574 completed (loss: 1.8042000532150269, acc: 0.5480427145957947)
[2024-11-29 03:02:11,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:11,528][root][INFO] - Training Epoch: 2/10, step 189/574 completed (loss: 1.9426758289337158, acc: 0.47999998927116394)
[2024-11-29 03:02:11,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:12,286][root][INFO] - Training Epoch: 2/10, step 190/574 completed (loss: 2.19771146774292, acc: 0.4651162922382355)
[2024-11-29 03:02:12,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:13,462][root][INFO] - Training Epoch: 2/10, step 191/574 completed (loss: 2.6309828758239746, acc: 0.4126984179019928)
[2024-11-29 03:02:14,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:14,851][root][INFO] - Training Epoch: 2/10, step 192/574 completed (loss: 2.411520481109619, acc: 0.40909090638160706)
[2024-11-29 03:02:15,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:15,933][root][INFO] - Training Epoch: 2/10, step 193/574 completed (loss: 2.0172181129455566, acc: 0.4588235318660736)
[2024-11-29 03:02:16,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:17,572][root][INFO] - Training Epoch: 2/10, step 194/574 completed (loss: 2.0245001316070557, acc: 0.4753086566925049)
[2024-11-29 03:02:18,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:19,008][root][INFO] - Training Epoch: 2/10, step 195/574 completed (loss: 1.607974886894226, acc: 0.5967742204666138)
[2024-11-29 03:02:19,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:19,322][root][INFO] - Training Epoch: 2/10, step 196/574 completed (loss: 0.5786314010620117, acc: 0.8214285969734192)
[2024-11-29 03:02:19,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:19,585][root][INFO] - Training Epoch: 2/10, step 197/574 completed (loss: 2.4571032524108887, acc: 0.550000011920929)
[2024-11-29 03:02:19,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:19,872][root][INFO] - Training Epoch: 2/10, step 198/574 completed (loss: 1.6322540044784546, acc: 0.5588235259056091)
[2024-11-29 03:02:20,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:20,191][root][INFO] - Training Epoch: 2/10, step 199/574 completed (loss: 1.9845722913742065, acc: 0.595588207244873)
[2024-11-29 03:02:20,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:20,479][root][INFO] - Training Epoch: 2/10, step 200/574 completed (loss: 1.790407657623291, acc: 0.5423728823661804)
[2024-11-29 03:02:20,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:20,766][root][INFO] - Training Epoch: 2/10, step 201/574 completed (loss: 1.9602423906326294, acc: 0.5298507213592529)
[2024-11-29 03:02:20,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:21,089][root][INFO] - Training Epoch: 2/10, step 202/574 completed (loss: 2.053144693374634, acc: 0.5339806079864502)
[2024-11-29 03:02:21,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:21,384][root][INFO] - Training Epoch: 2/10, step 203/574 completed (loss: 1.8617109060287476, acc: 0.5714285969734192)
[2024-11-29 03:02:21,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:21,663][root][INFO] - Training Epoch: 2/10, step 204/574 completed (loss: 1.1814610958099365, acc: 0.7032967209815979)
[2024-11-29 03:02:21,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:21,984][root][INFO] - Training Epoch: 2/10, step 205/574 completed (loss: 1.5361526012420654, acc: 0.5829596519470215)
[2024-11-29 03:02:22,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:22,420][root][INFO] - Training Epoch: 2/10, step 206/574 completed (loss: 1.7463191747665405, acc: 0.5905511975288391)
[2024-11-29 03:02:22,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:22,753][root][INFO] - Training Epoch: 2/10, step 207/574 completed (loss: 1.416658878326416, acc: 0.6637930870056152)
[2024-11-29 03:02:22,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:23,095][root][INFO] - Training Epoch: 2/10, step 208/574 completed (loss: 1.2633445262908936, acc: 0.6884058117866516)
[2024-11-29 03:02:23,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:23,465][root][INFO] - Training Epoch: 2/10, step 209/574 completed (loss: 1.5124609470367432, acc: 0.5992217659950256)
[2024-11-29 03:02:23,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:23,765][root][INFO] - Training Epoch: 2/10, step 210/574 completed (loss: 1.7827264070510864, acc: 0.6195651888847351)
[2024-11-29 03:02:23,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:24,083][root][INFO] - Training Epoch: 2/10, step 211/574 completed (loss: 0.922889769077301, acc: 0.782608687877655)
[2024-11-29 03:02:24,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:24,418][root][INFO] - Training Epoch: 2/10, step 212/574 completed (loss: 1.2195378541946411, acc: 0.6071428656578064)
[2024-11-29 03:02:24,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:24,717][root][INFO] - Training Epoch: 2/10, step 213/574 completed (loss: 1.4938651323318481, acc: 0.6382978558540344)
[2024-11-29 03:02:25,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:25,690][root][INFO] - Training Epoch: 2/10, step 214/574 completed (loss: 1.049102544784546, acc: 0.7538461685180664)
[2024-11-29 03:02:25,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:26,009][root][INFO] - Training Epoch: 2/10, step 215/574 completed (loss: 0.8714573979377747, acc: 0.8243243098258972)
[2024-11-29 03:02:26,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:26,337][root][INFO] - Training Epoch: 2/10, step 216/574 completed (loss: 0.7599153518676758, acc: 0.8604651093482971)
[2024-11-29 03:02:26,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:27,053][root][INFO] - Training Epoch: 2/10, step 217/574 completed (loss: 0.9882127046585083, acc: 0.7477477192878723)
[2024-11-29 03:02:27,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:27,500][root][INFO] - Training Epoch: 2/10, step 218/574 completed (loss: 0.9059088826179504, acc: 0.7777777910232544)
[2024-11-29 03:02:27,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:27,786][root][INFO] - Training Epoch: 2/10, step 219/574 completed (loss: 0.735417902469635, acc: 0.8181818127632141)
[2024-11-29 03:02:27,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:28,090][root][INFO] - Training Epoch: 2/10, step 220/574 completed (loss: 0.6014999151229858, acc: 0.8148148059844971)
[2024-11-29 03:02:28,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:28,386][root][INFO] - Training Epoch: 2/10, step 221/574 completed (loss: 0.5417877435684204, acc: 0.800000011920929)
[2024-11-29 03:02:28,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:28,698][root][INFO] - Training Epoch: 2/10, step 222/574 completed (loss: 1.3809367418289185, acc: 0.6153846383094788)
[2024-11-29 03:02:29,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:29,780][root][INFO] - Training Epoch: 2/10, step 223/574 completed (loss: 1.5327967405319214, acc: 0.592391312122345)
[2024-11-29 03:02:30,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:30,499][root][INFO] - Training Epoch: 2/10, step 224/574 completed (loss: 1.5930030345916748, acc: 0.6193181872367859)
[2024-11-29 03:02:30,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:31,038][root][INFO] - Training Epoch: 2/10, step 225/574 completed (loss: 1.8518991470336914, acc: 0.521276593208313)
[2024-11-29 03:02:31,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:31,383][root][INFO] - Training Epoch: 2/10, step 226/574 completed (loss: 1.2696844339370728, acc: 0.6603773832321167)
[2024-11-29 03:02:31,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:31,705][root][INFO] - Training Epoch: 2/10, step 227/574 completed (loss: 0.848477303981781, acc: 0.7666666507720947)
[2024-11-29 03:02:31,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:31,986][root][INFO] - Training Epoch: 2/10, step 228/574 completed (loss: 1.3709625005722046, acc: 0.7441860437393188)
[2024-11-29 03:02:32,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:32,309][root][INFO] - Training Epoch: 2/10, step 229/574 completed (loss: 3.0879318714141846, acc: 0.36666667461395264)
[2024-11-29 03:02:32,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:32,691][root][INFO] - Training Epoch: 2/10, step 230/574 completed (loss: 3.5727667808532715, acc: 0.23157894611358643)
[2024-11-29 03:02:32,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:32,990][root][INFO] - Training Epoch: 2/10, step 231/574 completed (loss: 2.866396188735962, acc: 0.3333333432674408)
[2024-11-29 03:02:33,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:33,492][root][INFO] - Training Epoch: 2/10, step 232/574 completed (loss: 2.6678595542907715, acc: 0.3888888955116272)
[2024-11-29 03:02:33,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:34,117][root][INFO] - Training Epoch: 2/10, step 233/574 completed (loss: 2.885876178741455, acc: 0.35321101546287537)
[2024-11-29 03:02:34,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:34,715][root][INFO] - Training Epoch: 2/10, step 234/574 completed (loss: 2.785356283187866, acc: 0.36153846979141235)
[2024-11-29 03:02:34,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:35,012][root][INFO] - Training Epoch: 2/10, step 235/574 completed (loss: 0.7712576389312744, acc: 0.7894737124443054)
[2024-11-29 03:02:35,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:35,307][root][INFO] - Training Epoch: 2/10, step 236/574 completed (loss: 1.1727298498153687, acc: 0.625)
[2024-11-29 03:02:35,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:35,612][root][INFO] - Training Epoch: 2/10, step 237/574 completed (loss: 2.468783378601074, acc: 0.40909090638160706)
[2024-11-29 03:02:35,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:35,928][root][INFO] - Training Epoch: 2/10, step 238/574 completed (loss: 1.844290852546692, acc: 0.6296296119689941)
[2024-11-29 03:02:36,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:36,253][root][INFO] - Training Epoch: 2/10, step 239/574 completed (loss: 1.3601574897766113, acc: 0.6857143044471741)
[2024-11-29 03:02:36,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:36,578][root][INFO] - Training Epoch: 2/10, step 240/574 completed (loss: 1.8561630249023438, acc: 0.5681818127632141)
[2024-11-29 03:02:36,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:36,887][root][INFO] - Training Epoch: 2/10, step 241/574 completed (loss: 1.4289507865905762, acc: 0.6363636255264282)
[2024-11-29 03:02:37,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:37,692][root][INFO] - Training Epoch: 2/10, step 242/574 completed (loss: 2.293727397918701, acc: 0.3870967626571655)
[2024-11-29 03:02:38,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:38,409][root][INFO] - Training Epoch: 2/10, step 243/574 completed (loss: 2.1489241123199463, acc: 0.40909090638160706)
[2024-11-29 03:02:38,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:38,707][root][INFO] - Training Epoch: 2/10, step 244/574 completed (loss: 1.2370185852050781, acc: 0.7142857313156128)
[2024-11-29 03:02:38,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:39,025][root][INFO] - Training Epoch: 2/10, step 245/574 completed (loss: 2.139819383621216, acc: 0.5384615659713745)
[2024-11-29 03:02:39,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:39,276][root][INFO] - Training Epoch: 2/10, step 246/574 completed (loss: 1.7554188966751099, acc: 0.5806451439857483)
[2024-11-29 03:02:39,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:39,567][root][INFO] - Training Epoch: 2/10, step 247/574 completed (loss: 1.2818962335586548, acc: 0.6499999761581421)
[2024-11-29 03:02:39,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:39,929][root][INFO] - Training Epoch: 2/10, step 248/574 completed (loss: 1.6368675231933594, acc: 0.6486486196517944)
[2024-11-29 03:02:40,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:40,219][root][INFO] - Training Epoch: 2/10, step 249/574 completed (loss: 1.7702105045318604, acc: 0.5945945978164673)
[2024-11-29 03:02:40,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:40,524][root][INFO] - Training Epoch: 2/10, step 250/574 completed (loss: 1.315487265586853, acc: 0.7027027010917664)
[2024-11-29 03:02:40,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:40,890][root][INFO] - Training Epoch: 2/10, step 251/574 completed (loss: 1.4887456893920898, acc: 0.6029411554336548)
[2024-11-29 03:02:41,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:41,185][root][INFO] - Training Epoch: 2/10, step 252/574 completed (loss: 0.4399222433567047, acc: 0.8048780560493469)
[2024-11-29 03:02:41,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:41,457][root][INFO] - Training Epoch: 2/10, step 253/574 completed (loss: 1.212463617324829, acc: 0.6800000071525574)
[2024-11-29 03:02:41,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:41,780][root][INFO] - Training Epoch: 2/10, step 254/574 completed (loss: 0.28856322169303894, acc: 0.9200000166893005)
[2024-11-29 03:02:41,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:42,075][root][INFO] - Training Epoch: 2/10, step 255/574 completed (loss: 1.4265904426574707, acc: 0.6774193644523621)
[2024-11-29 03:02:42,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:42,421][root][INFO] - Training Epoch: 2/10, step 256/574 completed (loss: 1.0032427310943604, acc: 0.7543859481811523)
[2024-11-29 03:02:42,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:42,709][root][INFO] - Training Epoch: 2/10, step 257/574 completed (loss: 1.2855415344238281, acc: 0.699999988079071)
[2024-11-29 03:02:42,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:43,017][root][INFO] - Training Epoch: 2/10, step 258/574 completed (loss: 1.0243545770645142, acc: 0.75)
[2024-11-29 03:02:43,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:43,774][root][INFO] - Training Epoch: 2/10, step 259/574 completed (loss: 1.7364826202392578, acc: 0.5377358198165894)
[2024-11-29 03:02:44,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:44,561][root][INFO] - Training Epoch: 2/10, step 260/574 completed (loss: 1.702942132949829, acc: 0.6000000238418579)
[2024-11-29 03:02:44,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:44,898][root][INFO] - Training Epoch: 2/10, step 261/574 completed (loss: 0.9350812435150146, acc: 0.75)
[2024-11-29 03:02:45,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:45,232][root][INFO] - Training Epoch: 2/10, step 262/574 completed (loss: 1.5376696586608887, acc: 0.5806451439857483)
[2024-11-29 03:02:45,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:45,642][root][INFO] - Training Epoch: 2/10, step 263/574 completed (loss: 2.267981767654419, acc: 0.5733333230018616)
[2024-11-29 03:02:45,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:46,048][root][INFO] - Training Epoch: 2/10, step 264/574 completed (loss: 1.9827312231063843, acc: 0.4791666567325592)
[2024-11-29 03:02:46,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:47,264][root][INFO] - Training Epoch: 2/10, step 265/574 completed (loss: 2.486485004425049, acc: 0.3919999897480011)
[2024-11-29 03:02:47,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:47,623][root][INFO] - Training Epoch: 2/10, step 266/574 completed (loss: 1.8232154846191406, acc: 0.550561785697937)
[2024-11-29 03:02:47,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:47,993][root][INFO] - Training Epoch: 2/10, step 267/574 completed (loss: 2.3465566635131836, acc: 0.45945945382118225)
[2024-11-29 03:02:48,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:48,559][root][INFO] - Training Epoch: 2/10, step 268/574 completed (loss: 1.6271497011184692, acc: 0.5517241358757019)
[2024-11-29 03:02:48,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:48,848][root][INFO] - Training Epoch: 2/10, step 269/574 completed (loss: 0.5829223990440369, acc: 0.8636363744735718)
[2024-11-29 03:02:49,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:49,155][root][INFO] - Training Epoch: 2/10, step 270/574 completed (loss: 0.6492138504981995, acc: 0.9090909361839294)
[2024-11-29 03:02:49,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:49,490][root][INFO] - Training Epoch: 2/10, step 271/574 completed (loss: 0.48891469836235046, acc: 0.875)
[2024-11-29 03:02:49,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:49,826][root][INFO] - Training Epoch: 2/10, step 272/574 completed (loss: 0.5792957544326782, acc: 0.8333333134651184)
[2024-11-29 03:02:50,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:50,237][root][INFO] - Training Epoch: 2/10, step 273/574 completed (loss: 1.467395305633545, acc: 0.5833333134651184)
[2024-11-29 03:02:50,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:50,484][root][INFO] - Training Epoch: 2/10, step 274/574 completed (loss: 0.6151254773139954, acc: 0.8125)
[2024-11-29 03:02:50,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:50,801][root][INFO] - Training Epoch: 2/10, step 275/574 completed (loss: 1.0747343301773071, acc: 0.7666666507720947)
[2024-11-29 03:02:50,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:51,105][root][INFO] - Training Epoch: 2/10, step 276/574 completed (loss: 0.6936154961585999, acc: 0.8620689511299133)
[2024-11-29 03:02:51,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:51,386][root][INFO] - Training Epoch: 2/10, step 277/574 completed (loss: 0.6932898163795471, acc: 0.7599999904632568)
[2024-11-29 03:02:51,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:51,698][root][INFO] - Training Epoch: 2/10, step 278/574 completed (loss: 1.6367483139038086, acc: 0.6170212626457214)
[2024-11-29 03:02:51,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:52,068][root][INFO] - Training Epoch: 2/10, step 279/574 completed (loss: 1.0360525846481323, acc: 0.75)
[2024-11-29 03:02:52,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:52,412][root][INFO] - Training Epoch: 2/10, step 280/574 completed (loss: 0.7585560083389282, acc: 0.7954545617103577)
[2024-11-29 03:02:52,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:52,902][root][INFO] - Training Epoch: 2/10, step 281/574 completed (loss: 2.019505739212036, acc: 0.6024096608161926)
[2024-11-29 03:02:53,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:53,267][root][INFO] - Training Epoch: 2/10, step 282/574 completed (loss: 1.82986319065094, acc: 0.5092592835426331)
[2024-11-29 03:02:53,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:53,537][root][INFO] - Training Epoch: 2/10, step 283/574 completed (loss: 1.1596025228500366, acc: 0.6578947305679321)
[2024-11-29 03:02:54,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:54,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:55,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:55,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:56,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:56,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:57,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:57,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:57,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:58,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:58,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:59,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:02:59,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:00,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:00,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:01,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:01,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:01,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:02,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:02,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:02,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:03,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:03,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:04,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:04,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:05,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:05,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:05,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:06,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:06,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:07,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:07,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:08,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:08,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:08,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:09,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:09,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:10,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:10,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:10,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:11,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:11,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:12,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:12,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:13,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:13,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:13,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:14,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:14,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:15,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:15,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:16,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:16,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:17,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:17,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:17,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:18,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:18,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:19,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:19,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:20,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:20,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:21,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:21,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:22,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:22,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:22,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:23,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:24,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:24,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:24,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:25,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:25,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:25,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:26,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:26,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:27,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:27,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:27,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:28,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:28,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:28,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:29,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:29,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:30,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:30,996][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.8128, device='cuda:0') eval_epoch_loss=tensor(1.3384, device='cuda:0') eval_epoch_acc=tensor(0.6556, device='cuda:0')
[2024-11-29 03:03:30,997][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:03:30,998][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:03:31,286][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_2_step_284_loss_1.3383697271347046/model.pt
[2024-11-29 03:03:31,297][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 1.3383697271347046
[2024-11-29 03:03:31,298][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.6556352376937866
[2024-11-29 03:03:31,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:31,684][root][INFO] - Training Epoch: 2/10, step 284/574 completed (loss: 1.2459925413131714, acc: 0.6764705777168274)
[2024-11-29 03:03:31,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:32,003][root][INFO] - Training Epoch: 2/10, step 285/574 completed (loss: 1.3296345472335815, acc: 0.675000011920929)
[2024-11-29 03:03:32,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:32,348][root][INFO] - Training Epoch: 2/10, step 286/574 completed (loss: 1.2201762199401855, acc: 0.671875)
[2024-11-29 03:03:32,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:32,675][root][INFO] - Training Epoch: 2/10, step 287/574 completed (loss: 1.5637197494506836, acc: 0.5440000295639038)
[2024-11-29 03:03:32,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:32,933][root][INFO] - Training Epoch: 2/10, step 288/574 completed (loss: 1.2300697565078735, acc: 0.7362637519836426)
[2024-11-29 03:03:33,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:33,205][root][INFO] - Training Epoch: 2/10, step 289/574 completed (loss: 1.3331114053726196, acc: 0.6397515535354614)
[2024-11-29 03:03:33,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:33,555][root][INFO] - Training Epoch: 2/10, step 290/574 completed (loss: 1.6683098077774048, acc: 0.5670102834701538)
[2024-11-29 03:03:33,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:33,844][root][INFO] - Training Epoch: 2/10, step 291/574 completed (loss: 1.199729323387146, acc: 0.6818181872367859)
[2024-11-29 03:03:34,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:34,180][root][INFO] - Training Epoch: 2/10, step 292/574 completed (loss: 1.4592554569244385, acc: 0.6666666865348816)
[2024-11-29 03:03:34,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:34,502][root][INFO] - Training Epoch: 2/10, step 293/574 completed (loss: 1.2990732192993164, acc: 0.6896551847457886)
[2024-11-29 03:03:34,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:35,094][root][INFO] - Training Epoch: 2/10, step 294/574 completed (loss: 1.0755966901779175, acc: 0.7090908885002136)
[2024-11-29 03:03:35,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:35,811][root][INFO] - Training Epoch: 2/10, step 295/574 completed (loss: 1.6854268312454224, acc: 0.5670102834701538)
[2024-11-29 03:03:35,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:36,098][root][INFO] - Training Epoch: 2/10, step 296/574 completed (loss: 1.7462650537490845, acc: 0.5862069129943848)
[2024-11-29 03:03:36,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:36,404][root][INFO] - Training Epoch: 2/10, step 297/574 completed (loss: 0.6574482917785645, acc: 0.8148148059844971)
[2024-11-29 03:03:36,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:36,727][root][INFO] - Training Epoch: 2/10, step 298/574 completed (loss: 1.6021699905395508, acc: 0.5526315569877625)
[2024-11-29 03:03:36,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:37,022][root][INFO] - Training Epoch: 2/10, step 299/574 completed (loss: 0.8994775414466858, acc: 0.7678571343421936)
[2024-11-29 03:03:37,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:37,362][root][INFO] - Training Epoch: 2/10, step 300/574 completed (loss: 0.20453386008739471, acc: 0.9375)
[2024-11-29 03:03:37,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:37,671][root][INFO] - Training Epoch: 2/10, step 301/574 completed (loss: 1.0902925729751587, acc: 0.7547169923782349)
[2024-11-29 03:03:37,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:38,010][root][INFO] - Training Epoch: 2/10, step 302/574 completed (loss: 0.5967116355895996, acc: 0.8679245114326477)
[2024-11-29 03:03:38,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:38,307][root][INFO] - Training Epoch: 2/10, step 303/574 completed (loss: 0.6799615621566772, acc: 0.7647058963775635)
[2024-11-29 03:03:38,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:38,670][root][INFO] - Training Epoch: 2/10, step 304/574 completed (loss: 0.8957151174545288, acc: 0.75)
[2024-11-29 03:03:38,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:39,014][root][INFO] - Training Epoch: 2/10, step 305/574 completed (loss: 1.4775476455688477, acc: 0.688524603843689)
[2024-11-29 03:03:39,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:39,345][root][INFO] - Training Epoch: 2/10, step 306/574 completed (loss: 0.42333945631980896, acc: 0.8333333134651184)
[2024-11-29 03:03:39,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:39,675][root][INFO] - Training Epoch: 2/10, step 307/574 completed (loss: 0.13295328617095947, acc: 0.9473684430122375)
[2024-11-29 03:03:39,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:39,977][root][INFO] - Training Epoch: 2/10, step 308/574 completed (loss: 1.1675872802734375, acc: 0.7101449370384216)
[2024-11-29 03:03:40,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:40,461][root][INFO] - Training Epoch: 2/10, step 309/574 completed (loss: 1.5616196393966675, acc: 0.6111111044883728)
[2024-11-29 03:03:40,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:40,795][root][INFO] - Training Epoch: 2/10, step 310/574 completed (loss: 1.2436003684997559, acc: 0.650602400302887)
[2024-11-29 03:03:40,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:41,118][root][INFO] - Training Epoch: 2/10, step 311/574 completed (loss: 1.3976082801818848, acc: 0.6666666865348816)
[2024-11-29 03:03:41,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:41,473][root][INFO] - Training Epoch: 2/10, step 312/574 completed (loss: 1.0454537868499756, acc: 0.7448979616165161)
[2024-11-29 03:03:41,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:41,775][root][INFO] - Training Epoch: 2/10, step 313/574 completed (loss: 0.5039190649986267, acc: 0.7916666865348816)
[2024-11-29 03:03:41,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:42,083][root][INFO] - Training Epoch: 2/10, step 314/574 completed (loss: 0.7810986042022705, acc: 0.75)
[2024-11-29 03:03:42,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:42,366][root][INFO] - Training Epoch: 2/10, step 315/574 completed (loss: 1.083118200302124, acc: 0.7419354915618896)
[2024-11-29 03:03:42,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:42,692][root][INFO] - Training Epoch: 2/10, step 316/574 completed (loss: 2.2977967262268066, acc: 0.5161290168762207)
[2024-11-29 03:03:42,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:43,039][root][INFO] - Training Epoch: 2/10, step 317/574 completed (loss: 0.9960602521896362, acc: 0.7014925479888916)
[2024-11-29 03:03:43,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:43,357][root][INFO] - Training Epoch: 2/10, step 318/574 completed (loss: 0.8272620439529419, acc: 0.8269230723381042)
[2024-11-29 03:03:43,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:43,675][root][INFO] - Training Epoch: 2/10, step 319/574 completed (loss: 0.7242184281349182, acc: 0.7555555701255798)
[2024-11-29 03:03:43,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:43,990][root][INFO] - Training Epoch: 2/10, step 320/574 completed (loss: 0.4712914526462555, acc: 0.9032257795333862)
[2024-11-29 03:03:44,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:44,268][root][INFO] - Training Epoch: 2/10, step 321/574 completed (loss: 0.2952881157398224, acc: 0.9399999976158142)
[2024-11-29 03:03:44,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:44,539][root][INFO] - Training Epoch: 2/10, step 322/574 completed (loss: 2.447187662124634, acc: 0.37037035822868347)
[2024-11-29 03:03:44,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:44,810][root][INFO] - Training Epoch: 2/10, step 323/574 completed (loss: 3.180363893508911, acc: 0.2857142984867096)
[2024-11-29 03:03:45,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:45,128][root][INFO] - Training Epoch: 2/10, step 324/574 completed (loss: 3.084054470062256, acc: 0.41025641560554504)
[2024-11-29 03:03:45,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:45,421][root][INFO] - Training Epoch: 2/10, step 325/574 completed (loss: 3.0139718055725098, acc: 0.39024388790130615)
[2024-11-29 03:03:45,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:45,687][root][INFO] - Training Epoch: 2/10, step 326/574 completed (loss: 2.5873844623565674, acc: 0.3947368562221527)
[2024-11-29 03:03:45,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:45,954][root][INFO] - Training Epoch: 2/10, step 327/574 completed (loss: 1.503885269165039, acc: 0.5263158082962036)
[2024-11-29 03:03:46,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:46,246][root][INFO] - Training Epoch: 2/10, step 328/574 completed (loss: 0.41935333609580994, acc: 0.9285714030265808)
[2024-11-29 03:03:46,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:46,606][root][INFO] - Training Epoch: 2/10, step 329/574 completed (loss: 0.7861527800559998, acc: 0.7407407164573669)
[2024-11-29 03:03:46,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:46,940][root][INFO] - Training Epoch: 2/10, step 330/574 completed (loss: 0.258609414100647, acc: 0.9375)
[2024-11-29 03:03:47,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:47,269][root][INFO] - Training Epoch: 2/10, step 331/574 completed (loss: 1.2891064882278442, acc: 0.6612903475761414)
[2024-11-29 03:03:47,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:47,664][root][INFO] - Training Epoch: 2/10, step 332/574 completed (loss: 0.8268346190452576, acc: 0.7543859481811523)
[2024-11-29 03:03:47,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:47,941][root][INFO] - Training Epoch: 2/10, step 333/574 completed (loss: 1.3025180101394653, acc: 0.65625)
[2024-11-29 03:03:48,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:48,264][root][INFO] - Training Epoch: 2/10, step 334/574 completed (loss: 0.5563929677009583, acc: 0.8999999761581421)
[2024-11-29 03:03:48,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:48,553][root][INFO] - Training Epoch: 2/10, step 335/574 completed (loss: 1.2016593217849731, acc: 0.6315789222717285)
[2024-11-29 03:03:48,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:48,876][root][INFO] - Training Epoch: 2/10, step 336/574 completed (loss: 1.894779920578003, acc: 0.5400000214576721)
[2024-11-29 03:03:49,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:49,240][root][INFO] - Training Epoch: 2/10, step 337/574 completed (loss: 2.2661659717559814, acc: 0.4712643623352051)
[2024-11-29 03:03:49,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:49,580][root][INFO] - Training Epoch: 2/10, step 338/574 completed (loss: 2.500229597091675, acc: 0.40425533056259155)
[2024-11-29 03:03:49,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:49,872][root][INFO] - Training Epoch: 2/10, step 339/574 completed (loss: 2.143690824508667, acc: 0.5060241222381592)
[2024-11-29 03:03:50,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:50,162][root][INFO] - Training Epoch: 2/10, step 340/574 completed (loss: 0.4982233941555023, acc: 0.8260869383811951)
[2024-11-29 03:03:50,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:50,450][root][INFO] - Training Epoch: 2/10, step 341/574 completed (loss: 1.2682514190673828, acc: 0.7692307829856873)
[2024-11-29 03:03:50,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:50,771][root][INFO] - Training Epoch: 2/10, step 342/574 completed (loss: 1.3293964862823486, acc: 0.6746987700462341)
[2024-11-29 03:03:50,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:51,107][root][INFO] - Training Epoch: 2/10, step 343/574 completed (loss: 1.9063609838485718, acc: 0.5660377144813538)
[2024-11-29 03:03:51,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:51,419][root][INFO] - Training Epoch: 2/10, step 344/574 completed (loss: 1.0323108434677124, acc: 0.7848101258277893)
[2024-11-29 03:03:51,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:51,704][root][INFO] - Training Epoch: 2/10, step 345/574 completed (loss: 0.9031431674957275, acc: 0.8235294222831726)
[2024-11-29 03:03:51,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:51,981][root][INFO] - Training Epoch: 2/10, step 346/574 completed (loss: 1.6175682544708252, acc: 0.5970149040222168)
[2024-11-29 03:03:52,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:52,287][root][INFO] - Training Epoch: 2/10, step 347/574 completed (loss: 0.49667221307754517, acc: 0.8500000238418579)
[2024-11-29 03:03:52,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:52,606][root][INFO] - Training Epoch: 2/10, step 348/574 completed (loss: 0.6723758578300476, acc: 0.8799999952316284)
[2024-11-29 03:03:52,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:53,045][root][INFO] - Training Epoch: 2/10, step 349/574 completed (loss: 1.6951731443405151, acc: 0.6666666865348816)
[2024-11-29 03:03:53,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:53,362][root][INFO] - Training Epoch: 2/10, step 350/574 completed (loss: 1.7534912824630737, acc: 0.5348837375640869)
[2024-11-29 03:03:53,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:53,660][root][INFO] - Training Epoch: 2/10, step 351/574 completed (loss: 1.08183753490448, acc: 0.7692307829856873)
[2024-11-29 03:03:53,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:54,057][root][INFO] - Training Epoch: 2/10, step 352/574 completed (loss: 2.655299663543701, acc: 0.4000000059604645)
[2024-11-29 03:03:54,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:54,365][root][INFO] - Training Epoch: 2/10, step 353/574 completed (loss: 0.41565319895744324, acc: 0.9130434989929199)
[2024-11-29 03:03:54,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:54,719][root][INFO] - Training Epoch: 2/10, step 354/574 completed (loss: 1.5841615200042725, acc: 0.6153846383094788)
[2024-11-29 03:03:54,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:55,055][root][INFO] - Training Epoch: 2/10, step 355/574 completed (loss: 2.238497257232666, acc: 0.4175824224948883)
[2024-11-29 03:03:55,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:55,704][root][INFO] - Training Epoch: 2/10, step 356/574 completed (loss: 1.7263554334640503, acc: 0.52173912525177)
[2024-11-29 03:03:55,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:56,021][root][INFO] - Training Epoch: 2/10, step 357/574 completed (loss: 1.407802939414978, acc: 0.5978260636329651)
[2024-11-29 03:03:56,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:56,357][root][INFO] - Training Epoch: 2/10, step 358/574 completed (loss: 1.335414171218872, acc: 0.5918367505073547)
[2024-11-29 03:03:56,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:56,670][root][INFO] - Training Epoch: 2/10, step 359/574 completed (loss: 0.1189863309264183, acc: 0.9583333134651184)
[2024-11-29 03:03:56,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:56,978][root][INFO] - Training Epoch: 2/10, step 360/574 completed (loss: 0.9766591191291809, acc: 0.7692307829856873)
[2024-11-29 03:03:57,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:57,290][root][INFO] - Training Epoch: 2/10, step 361/574 completed (loss: 1.7262647151947021, acc: 0.5853658318519592)
[2024-11-29 03:03:57,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:57,577][root][INFO] - Training Epoch: 2/10, step 362/574 completed (loss: 0.95479416847229, acc: 0.7333333492279053)
[2024-11-29 03:03:57,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:57,908][root][INFO] - Training Epoch: 2/10, step 363/574 completed (loss: 1.1607650518417358, acc: 0.7105262875556946)
[2024-11-29 03:03:58,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:58,207][root][INFO] - Training Epoch: 2/10, step 364/574 completed (loss: 1.0617600679397583, acc: 0.6585366129875183)
[2024-11-29 03:03:58,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:58,523][root][INFO] - Training Epoch: 2/10, step 365/574 completed (loss: 0.6513110399246216, acc: 0.7878788113594055)
[2024-11-29 03:03:58,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:58,823][root][INFO] - Training Epoch: 2/10, step 366/574 completed (loss: 0.23036402463912964, acc: 0.9166666865348816)
[2024-11-29 03:03:59,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:59,119][root][INFO] - Training Epoch: 2/10, step 367/574 completed (loss: 0.5787591338157654, acc: 0.8260869383811951)
[2024-11-29 03:03:59,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:59,443][root][INFO] - Training Epoch: 2/10, step 368/574 completed (loss: 0.7402359247207642, acc: 0.7857142686843872)
[2024-11-29 03:03:59,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:03:59,829][root][INFO] - Training Epoch: 2/10, step 369/574 completed (loss: 1.672527551651001, acc: 0.65625)
[2024-11-29 03:04:00,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:00,656][root][INFO] - Training Epoch: 2/10, step 370/574 completed (loss: 1.9555034637451172, acc: 0.5696969628334045)
[2024-11-29 03:04:01,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:01,870][root][INFO] - Training Epoch: 2/10, step 371/574 completed (loss: 1.2412981986999512, acc: 0.7358490824699402)
[2024-11-29 03:04:02,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:02,215][root][INFO] - Training Epoch: 2/10, step 372/574 completed (loss: 1.2071274518966675, acc: 0.699999988079071)
[2024-11-29 03:04:02,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:02,516][root][INFO] - Training Epoch: 2/10, step 373/574 completed (loss: 0.5493183732032776, acc: 0.8392857313156128)
[2024-11-29 03:04:02,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:02,826][root][INFO] - Training Epoch: 2/10, step 374/574 completed (loss: 0.89035564661026, acc: 0.8285714387893677)
[2024-11-29 03:04:03,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:03,143][root][INFO] - Training Epoch: 2/10, step 375/574 completed (loss: 0.2957645654678345, acc: 0.9599999785423279)
[2024-11-29 03:04:03,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:03,484][root][INFO] - Training Epoch: 2/10, step 376/574 completed (loss: 0.6639215350151062, acc: 0.782608687877655)
[2024-11-29 03:04:03,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:03,757][root][INFO] - Training Epoch: 2/10, step 377/574 completed (loss: 0.6339936852455139, acc: 0.8541666865348816)
[2024-11-29 03:04:03,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:04,089][root][INFO] - Training Epoch: 2/10, step 378/574 completed (loss: 0.33841845393180847, acc: 0.9473684430122375)
[2024-11-29 03:04:04,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:04,868][root][INFO] - Training Epoch: 2/10, step 379/574 completed (loss: 0.9106870889663696, acc: 0.7904191613197327)
[2024-11-29 03:04:05,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:05,332][root][INFO] - Training Epoch: 2/10, step 380/574 completed (loss: 1.0197640657424927, acc: 0.7669172883033752)
[2024-11-29 03:04:06,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:07,094][root][INFO] - Training Epoch: 2/10, step 381/574 completed (loss: 1.3388986587524414, acc: 0.7005347609519958)
[2024-11-29 03:04:07,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:07,857][root][INFO] - Training Epoch: 2/10, step 382/574 completed (loss: 0.5978909730911255, acc: 0.8108108043670654)
[2024-11-29 03:04:08,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:08,136][root][INFO] - Training Epoch: 2/10, step 383/574 completed (loss: 1.006226658821106, acc: 0.6785714030265808)
[2024-11-29 03:04:08,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:08,396][root][INFO] - Training Epoch: 2/10, step 384/574 completed (loss: 0.364167183637619, acc: 0.9285714030265808)
[2024-11-29 03:04:08,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:08,667][root][INFO] - Training Epoch: 2/10, step 385/574 completed (loss: 0.5046682953834534, acc: 0.875)
[2024-11-29 03:04:08,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:08,935][root][INFO] - Training Epoch: 2/10, step 386/574 completed (loss: 0.46260198950767517, acc: 0.9166666865348816)
[2024-11-29 03:04:09,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:09,220][root][INFO] - Training Epoch: 2/10, step 387/574 completed (loss: 0.25721505284309387, acc: 0.9210526347160339)
[2024-11-29 03:04:09,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:09,553][root][INFO] - Training Epoch: 2/10, step 388/574 completed (loss: 0.17484654486179352, acc: 0.9545454382896423)
[2024-11-29 03:04:09,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:09,901][root][INFO] - Training Epoch: 2/10, step 389/574 completed (loss: 0.15793593227863312, acc: 0.949999988079071)
[2024-11-29 03:04:10,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:10,252][root][INFO] - Training Epoch: 2/10, step 390/574 completed (loss: 1.1565719842910767, acc: 0.761904776096344)
[2024-11-29 03:04:10,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:10,618][root][INFO] - Training Epoch: 2/10, step 391/574 completed (loss: 1.6399503946304321, acc: 0.6111111044883728)
[2024-11-29 03:04:10,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:10,987][root][INFO] - Training Epoch: 2/10, step 392/574 completed (loss: 1.9302960634231567, acc: 0.49514561891555786)
[2024-11-29 03:04:11,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:11,665][root][INFO] - Training Epoch: 2/10, step 393/574 completed (loss: 1.8391226530075073, acc: 0.6102941036224365)
[2024-11-29 03:04:11,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:12,060][root][INFO] - Training Epoch: 2/10, step 394/574 completed (loss: 2.069817066192627, acc: 0.5066666603088379)
[2024-11-29 03:04:12,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:12,494][root][INFO] - Training Epoch: 2/10, step 395/574 completed (loss: 1.482156753540039, acc: 0.6180555820465088)
[2024-11-29 03:04:12,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:12,783][root][INFO] - Training Epoch: 2/10, step 396/574 completed (loss: 1.2113327980041504, acc: 0.7209302186965942)
[2024-11-29 03:04:12,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:13,033][root][INFO] - Training Epoch: 2/10, step 397/574 completed (loss: 0.4537811279296875, acc: 0.8333333134651184)
[2024-11-29 03:04:13,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:13,366][root][INFO] - Training Epoch: 2/10, step 398/574 completed (loss: 1.1423923969268799, acc: 0.7209302186965942)
[2024-11-29 03:04:13,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:13,683][root][INFO] - Training Epoch: 2/10, step 399/574 completed (loss: 0.3054337203502655, acc: 0.9200000166893005)
[2024-11-29 03:04:14,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:14,397][root][INFO] - Training Epoch: 2/10, step 400/574 completed (loss: 1.2734792232513428, acc: 0.779411792755127)
[2024-11-29 03:04:14,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:14,694][root][INFO] - Training Epoch: 2/10, step 401/574 completed (loss: 1.158992052078247, acc: 0.7733333110809326)
[2024-11-29 03:04:14,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:14,990][root][INFO] - Training Epoch: 2/10, step 402/574 completed (loss: 1.4719796180725098, acc: 0.6363636255264282)
[2024-11-29 03:04:15,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:15,301][root][INFO] - Training Epoch: 2/10, step 403/574 completed (loss: 0.9213462471961975, acc: 0.6666666865348816)
[2024-11-29 03:04:15,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:15,606][root][INFO] - Training Epoch: 2/10, step 404/574 completed (loss: 1.3293046951293945, acc: 0.5806451439857483)
[2024-11-29 03:04:15,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:15,912][root][INFO] - Training Epoch: 2/10, step 405/574 completed (loss: 0.6957007646560669, acc: 0.8148148059844971)
[2024-11-29 03:04:16,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:16,190][root][INFO] - Training Epoch: 2/10, step 406/574 completed (loss: 0.667184054851532, acc: 0.8399999737739563)
[2024-11-29 03:04:16,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:16,509][root][INFO] - Training Epoch: 2/10, step 407/574 completed (loss: 0.6966507434844971, acc: 0.7777777910232544)
[2024-11-29 03:04:16,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:16,825][root][INFO] - Training Epoch: 2/10, step 408/574 completed (loss: 0.5054144859313965, acc: 0.9259259104728699)
[2024-11-29 03:04:17,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:17,123][root][INFO] - Training Epoch: 2/10, step 409/574 completed (loss: 0.26640015840530396, acc: 0.8846153616905212)
[2024-11-29 03:04:17,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:17,403][root][INFO] - Training Epoch: 2/10, step 410/574 completed (loss: 0.8540492057800293, acc: 0.8103448152542114)
[2024-11-29 03:04:17,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:17,664][root][INFO] - Training Epoch: 2/10, step 411/574 completed (loss: 0.8594903349876404, acc: 0.8214285969734192)
[2024-11-29 03:04:17,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:17,959][root][INFO] - Training Epoch: 2/10, step 412/574 completed (loss: 0.6607386469841003, acc: 0.800000011920929)
[2024-11-29 03:04:18,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:18,268][root][INFO] - Training Epoch: 2/10, step 413/574 completed (loss: 0.5789933800697327, acc: 0.8484848737716675)
[2024-11-29 03:04:18,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:18,604][root][INFO] - Training Epoch: 2/10, step 414/574 completed (loss: 0.6160526871681213, acc: 0.8636363744735718)
[2024-11-29 03:04:18,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:18,902][root][INFO] - Training Epoch: 2/10, step 415/574 completed (loss: 0.9329361915588379, acc: 0.7450980544090271)
[2024-11-29 03:04:19,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:19,191][root][INFO] - Training Epoch: 2/10, step 416/574 completed (loss: 0.28502190113067627, acc: 0.9615384340286255)
[2024-11-29 03:04:19,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:19,473][root][INFO] - Training Epoch: 2/10, step 417/574 completed (loss: 0.4668445587158203, acc: 0.8888888955116272)
[2024-11-29 03:04:19,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:19,798][root][INFO] - Training Epoch: 2/10, step 418/574 completed (loss: 0.7853314280509949, acc: 0.800000011920929)
[2024-11-29 03:04:19,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:20,094][root][INFO] - Training Epoch: 2/10, step 419/574 completed (loss: 0.6912030577659607, acc: 0.75)
[2024-11-29 03:04:20,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:20,359][root][INFO] - Training Epoch: 2/10, step 420/574 completed (loss: 0.42827972769737244, acc: 0.8571428656578064)
[2024-11-29 03:04:20,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:20,615][root][INFO] - Training Epoch: 2/10, step 421/574 completed (loss: 0.66170734167099, acc: 0.7666666507720947)
[2024-11-29 03:04:20,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:20,859][root][INFO] - Training Epoch: 2/10, step 422/574 completed (loss: 1.4925767183303833, acc: 0.65625)
[2024-11-29 03:04:21,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:21,127][root][INFO] - Training Epoch: 2/10, step 423/574 completed (loss: 1.9575366973876953, acc: 0.4722222089767456)
[2024-11-29 03:04:21,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:21,393][root][INFO] - Training Epoch: 2/10, step 424/574 completed (loss: 1.3527482748031616, acc: 0.7037037014961243)
[2024-11-29 03:04:21,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:21,662][root][INFO] - Training Epoch: 2/10, step 425/574 completed (loss: 0.5512380003929138, acc: 0.8484848737716675)
[2024-11-29 03:04:21,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:21,926][root][INFO] - Training Epoch: 2/10, step 426/574 completed (loss: 0.4563436210155487, acc: 0.8695651888847351)
[2024-11-29 03:04:22,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:23,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:23,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:24,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:24,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:24,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:25,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:25,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:26,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:26,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:27,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:27,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:28,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:28,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:29,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:29,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:29,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:30,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:30,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:31,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:31,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:32,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:32,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:32,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:33,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:33,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:34,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:34,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:34,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:35,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:35,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:36,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:36,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:36,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:37,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:37,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:38,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:38,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:39,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:39,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:40,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:40,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:40,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:41,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:41,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:42,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:42,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:43,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:43,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:43,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:44,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:44,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:45,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:45,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:46,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:46,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:47,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:47,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:47,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:48,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:48,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:49,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:49,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:50,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:50,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:51,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:51,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:52,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:52,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:53,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:53,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:53,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:54,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:54,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:55,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:55,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:56,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:56,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:57,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:57,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:57,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:58,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:58,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:59,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:04:59,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:00,302][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(4.4030, device='cuda:0') eval_epoch_loss=tensor(1.4823, device='cuda:0') eval_epoch_acc=tensor(0.6299, device='cuda:0')
[2024-11-29 03:05:00,303][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:05:00,304][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:05:00,604][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_2_step_427_loss_1.4822970628738403/model.pt
[2024-11-29 03:05:00,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:00,881][root][INFO] - Training Epoch: 2/10, step 427/574 completed (loss: 1.078804850578308, acc: 0.7297297120094299)
[2024-11-29 03:05:01,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:01,135][root][INFO] - Training Epoch: 2/10, step 428/574 completed (loss: 1.0822542905807495, acc: 0.7777777910232544)
[2024-11-29 03:05:01,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:01,381][root][INFO] - Training Epoch: 2/10, step 429/574 completed (loss: 0.40285566449165344, acc: 0.8695651888847351)
[2024-11-29 03:05:01,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:01,634][root][INFO] - Training Epoch: 2/10, step 430/574 completed (loss: 0.3114340305328369, acc: 0.9629629850387573)
[2024-11-29 03:05:01,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:01,880][root][INFO] - Training Epoch: 2/10, step 431/574 completed (loss: 0.6205249428749084, acc: 0.8148148059844971)
[2024-11-29 03:05:02,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:02,129][root][INFO] - Training Epoch: 2/10, step 432/574 completed (loss: 0.47309643030166626, acc: 0.9130434989929199)
[2024-11-29 03:05:02,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:02,479][root][INFO] - Training Epoch: 2/10, step 433/574 completed (loss: 0.6889216899871826, acc: 0.8055555820465088)
[2024-11-29 03:05:02,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:02,740][root][INFO] - Training Epoch: 2/10, step 434/574 completed (loss: 0.087897390127182, acc: 1.0)
[2024-11-29 03:05:02,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:03,004][root][INFO] - Training Epoch: 2/10, step 435/574 completed (loss: 0.0908256396651268, acc: 1.0)
[2024-11-29 03:05:03,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:03,257][root][INFO] - Training Epoch: 2/10, step 436/574 completed (loss: 0.8012562990188599, acc: 0.8055555820465088)
[2024-11-29 03:05:03,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:03,523][root][INFO] - Training Epoch: 2/10, step 437/574 completed (loss: 0.736514687538147, acc: 0.8181818127632141)
[2024-11-29 03:05:03,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:03,772][root][INFO] - Training Epoch: 2/10, step 438/574 completed (loss: 0.3695816397666931, acc: 0.9523809552192688)
[2024-11-29 03:05:03,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:04,041][root][INFO] - Training Epoch: 2/10, step 439/574 completed (loss: 0.7589641809463501, acc: 0.7948718070983887)
[2024-11-29 03:05:04,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:04,623][root][INFO] - Training Epoch: 2/10, step 440/574 completed (loss: 1.0711841583251953, acc: 0.6969696879386902)
[2024-11-29 03:05:05,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:05,597][root][INFO] - Training Epoch: 2/10, step 441/574 completed (loss: 2.0294015407562256, acc: 0.5199999809265137)
[2024-11-29 03:05:05,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:06,061][root][INFO] - Training Epoch: 2/10, step 442/574 completed (loss: 1.6816515922546387, acc: 0.5887096524238586)
[2024-11-29 03:05:06,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:06,963][root][INFO] - Training Epoch: 2/10, step 443/574 completed (loss: 1.4479674100875854, acc: 0.641791045665741)
[2024-11-29 03:05:07,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:07,211][root][INFO] - Training Epoch: 2/10, step 444/574 completed (loss: 1.2747946977615356, acc: 0.7169811129570007)
[2024-11-29 03:05:07,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:07,709][root][INFO] - Training Epoch: 2/10, step 445/574 completed (loss: 0.7810860276222229, acc: 0.8409090638160706)
[2024-11-29 03:05:07,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:07,972][root][INFO] - Training Epoch: 2/10, step 446/574 completed (loss: 0.8285166025161743, acc: 0.782608687877655)
[2024-11-29 03:05:08,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:08,225][root][INFO] - Training Epoch: 2/10, step 447/574 completed (loss: 1.200738787651062, acc: 0.7692307829856873)
[2024-11-29 03:05:08,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:08,450][root][INFO] - Training Epoch: 2/10, step 448/574 completed (loss: 0.9340201616287231, acc: 0.8214285969734192)
[2024-11-29 03:05:08,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:08,713][root][INFO] - Training Epoch: 2/10, step 449/574 completed (loss: 0.7368916273117065, acc: 0.8507462739944458)
[2024-11-29 03:05:08,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:09,018][root][INFO] - Training Epoch: 2/10, step 450/574 completed (loss: 0.6330137252807617, acc: 0.8472222089767456)
[2024-11-29 03:05:09,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:09,283][root][INFO] - Training Epoch: 2/10, step 451/574 completed (loss: 0.6273286938667297, acc: 0.8260869383811951)
[2024-11-29 03:05:09,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:09,548][root][INFO] - Training Epoch: 2/10, step 452/574 completed (loss: 0.6899946928024292, acc: 0.8333333134651184)
[2024-11-29 03:05:09,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:09,856][root][INFO] - Training Epoch: 2/10, step 453/574 completed (loss: 0.9729213714599609, acc: 0.7631579041481018)
[2024-11-29 03:05:10,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:10,229][root][INFO] - Training Epoch: 2/10, step 454/574 completed (loss: 0.9662267565727234, acc: 0.7142857313156128)
[2024-11-29 03:05:10,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:10,612][root][INFO] - Training Epoch: 2/10, step 455/574 completed (loss: 1.1640256643295288, acc: 0.6666666865348816)
[2024-11-29 03:05:10,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:10,937][root][INFO] - Training Epoch: 2/10, step 456/574 completed (loss: 1.4672237634658813, acc: 0.6288659572601318)
[2024-11-29 03:05:11,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:11,213][root][INFO] - Training Epoch: 2/10, step 457/574 completed (loss: 0.7470173835754395, acc: 0.7428571581840515)
[2024-11-29 03:05:11,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:11,631][root][INFO] - Training Epoch: 2/10, step 458/574 completed (loss: 1.802689790725708, acc: 0.569767415523529)
[2024-11-29 03:05:11,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:11,954][root][INFO] - Training Epoch: 2/10, step 459/574 completed (loss: 0.9123039841651917, acc: 0.7321428656578064)
[2024-11-29 03:05:12,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:12,273][root][INFO] - Training Epoch: 2/10, step 460/574 completed (loss: 1.2825767993927002, acc: 0.6666666865348816)
[2024-11-29 03:05:12,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:12,569][root][INFO] - Training Epoch: 2/10, step 461/574 completed (loss: 1.137433648109436, acc: 0.6944444179534912)
[2024-11-29 03:05:12,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:12,832][root][INFO] - Training Epoch: 2/10, step 462/574 completed (loss: 0.9985463619232178, acc: 0.71875)
[2024-11-29 03:05:12,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:13,087][root][INFO] - Training Epoch: 2/10, step 463/574 completed (loss: 0.5836641192436218, acc: 0.8846153616905212)
[2024-11-29 03:05:13,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:13,355][root][INFO] - Training Epoch: 2/10, step 464/574 completed (loss: 0.7920686602592468, acc: 0.782608687877655)
[2024-11-29 03:05:13,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:13,608][root][INFO] - Training Epoch: 2/10, step 465/574 completed (loss: 1.2088992595672607, acc: 0.7142857313156128)
[2024-11-29 03:05:13,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:13,855][root][INFO] - Training Epoch: 2/10, step 466/574 completed (loss: 1.693233609199524, acc: 0.5542168617248535)
[2024-11-29 03:05:14,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:14,153][root][INFO] - Training Epoch: 2/10, step 467/574 completed (loss: 1.2978472709655762, acc: 0.684684693813324)
[2024-11-29 03:05:14,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:14,418][root][INFO] - Training Epoch: 2/10, step 468/574 completed (loss: 1.6440281867980957, acc: 0.6310679316520691)
[2024-11-29 03:05:14,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:14,732][root][INFO] - Training Epoch: 2/10, step 469/574 completed (loss: 1.8592702150344849, acc: 0.5691056847572327)
[2024-11-29 03:05:14,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:14,975][root][INFO] - Training Epoch: 2/10, step 470/574 completed (loss: 0.9644959568977356, acc: 0.75)
[2024-11-29 03:05:15,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:15,230][root][INFO] - Training Epoch: 2/10, step 471/574 completed (loss: 1.093746304512024, acc: 0.6428571343421936)
[2024-11-29 03:05:15,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:15,704][root][INFO] - Training Epoch: 2/10, step 472/574 completed (loss: 1.5500811338424683, acc: 0.5196078419685364)
[2024-11-29 03:05:15,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:16,084][root][INFO] - Training Epoch: 2/10, step 473/574 completed (loss: 1.7514735460281372, acc: 0.5502183437347412)
[2024-11-29 03:05:16,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:16,416][root][INFO] - Training Epoch: 2/10, step 474/574 completed (loss: 1.422149658203125, acc: 0.6458333134651184)
[2024-11-29 03:05:16,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:16,784][root][INFO] - Training Epoch: 2/10, step 475/574 completed (loss: 1.002168893814087, acc: 0.7239263653755188)
[2024-11-29 03:05:16,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:17,099][root][INFO] - Training Epoch: 2/10, step 476/574 completed (loss: 1.0619547367095947, acc: 0.7194244861602783)
[2024-11-29 03:05:17,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:17,445][root][INFO] - Training Epoch: 2/10, step 477/574 completed (loss: 1.428937315940857, acc: 0.623115599155426)
[2024-11-29 03:05:17,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:17,728][root][INFO] - Training Epoch: 2/10, step 478/574 completed (loss: 1.3785513639450073, acc: 0.6666666865348816)
[2024-11-29 03:05:17,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:17,995][root][INFO] - Training Epoch: 2/10, step 479/574 completed (loss: 1.0652751922607422, acc: 0.7272727489471436)
[2024-11-29 03:05:18,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:18,251][root][INFO] - Training Epoch: 2/10, step 480/574 completed (loss: 1.0139539241790771, acc: 0.6666666865348816)
[2024-11-29 03:05:18,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:18,523][root][INFO] - Training Epoch: 2/10, step 481/574 completed (loss: 1.3987746238708496, acc: 0.550000011920929)
[2024-11-29 03:05:18,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:18,799][root][INFO] - Training Epoch: 2/10, step 482/574 completed (loss: 1.9963960647583008, acc: 0.6499999761581421)
[2024-11-29 03:05:19,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:19,210][root][INFO] - Training Epoch: 2/10, step 483/574 completed (loss: 1.8221451044082642, acc: 0.5517241358757019)
[2024-11-29 03:05:19,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:19,467][root][INFO] - Training Epoch: 2/10, step 484/574 completed (loss: 0.3342856168746948, acc: 0.9354838728904724)
[2024-11-29 03:05:19,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:19,730][root][INFO] - Training Epoch: 2/10, step 485/574 completed (loss: 1.0098092555999756, acc: 0.7368420958518982)
[2024-11-29 03:05:19,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:19,966][root][INFO] - Training Epoch: 2/10, step 486/574 completed (loss: 1.9356507062911987, acc: 0.4444444477558136)
[2024-11-29 03:05:20,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:20,213][root][INFO] - Training Epoch: 2/10, step 487/574 completed (loss: 1.0323898792266846, acc: 0.7142857313156128)
[2024-11-29 03:05:20,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:20,502][root][INFO] - Training Epoch: 2/10, step 488/574 completed (loss: 1.907482624053955, acc: 0.5909090638160706)
[2024-11-29 03:05:20,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:20,863][root][INFO] - Training Epoch: 2/10, step 489/574 completed (loss: 1.8584684133529663, acc: 0.4769230782985687)
[2024-11-29 03:05:21,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:21,161][root][INFO] - Training Epoch: 2/10, step 490/574 completed (loss: 0.6624389290809631, acc: 0.8333333134651184)
[2024-11-29 03:05:21,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:21,467][root][INFO] - Training Epoch: 2/10, step 491/574 completed (loss: 1.090451717376709, acc: 0.7241379022598267)
[2024-11-29 03:05:21,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:21,775][root][INFO] - Training Epoch: 2/10, step 492/574 completed (loss: 1.1356921195983887, acc: 0.686274528503418)
[2024-11-29 03:05:21,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:22,082][root][INFO] - Training Epoch: 2/10, step 493/574 completed (loss: 1.2571717500686646, acc: 0.7586206793785095)
[2024-11-29 03:05:22,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:22,435][root][INFO] - Training Epoch: 2/10, step 494/574 completed (loss: 0.9904953837394714, acc: 0.8421052694320679)
[2024-11-29 03:05:22,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:22,753][root][INFO] - Training Epoch: 2/10, step 495/574 completed (loss: 1.4110978841781616, acc: 0.6842105388641357)
[2024-11-29 03:05:22,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:23,077][root][INFO] - Training Epoch: 2/10, step 496/574 completed (loss: 1.7038246393203735, acc: 0.5892857313156128)
[2024-11-29 03:05:23,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:23,471][root][INFO] - Training Epoch: 2/10, step 497/574 completed (loss: 1.0608584880828857, acc: 0.7528089880943298)
[2024-11-29 03:05:23,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:23,797][root][INFO] - Training Epoch: 2/10, step 498/574 completed (loss: 1.527401328086853, acc: 0.5393258333206177)
[2024-11-29 03:05:23,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:24,115][root][INFO] - Training Epoch: 2/10, step 499/574 completed (loss: 2.0887579917907715, acc: 0.5106382966041565)
[2024-11-29 03:05:24,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:24,455][root][INFO] - Training Epoch: 2/10, step 500/574 completed (loss: 1.66279137134552, acc: 0.6195651888847351)
[2024-11-29 03:05:24,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:24,787][root][INFO] - Training Epoch: 2/10, step 501/574 completed (loss: 0.3425997495651245, acc: 0.9200000166893005)
[2024-11-29 03:05:24,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:25,054][root][INFO] - Training Epoch: 2/10, step 502/574 completed (loss: 0.24779118597507477, acc: 0.9230769276618958)
[2024-11-29 03:05:25,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:25,347][root][INFO] - Training Epoch: 2/10, step 503/574 completed (loss: 0.9624922871589661, acc: 0.7777777910232544)
[2024-11-29 03:05:25,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:25,660][root][INFO] - Training Epoch: 2/10, step 504/574 completed (loss: 0.7407657504081726, acc: 0.7777777910232544)
[2024-11-29 03:05:25,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:25,970][root][INFO] - Training Epoch: 2/10, step 505/574 completed (loss: 1.368754267692566, acc: 0.6603773832321167)
[2024-11-29 03:05:26,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:26,287][root][INFO] - Training Epoch: 2/10, step 506/574 completed (loss: 1.6237149238586426, acc: 0.5517241358757019)
[2024-11-29 03:05:26,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:27,104][root][INFO] - Training Epoch: 2/10, step 507/574 completed (loss: 1.9969054460525513, acc: 0.5495495200157166)
[2024-11-29 03:05:27,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:27,643][root][INFO] - Training Epoch: 2/10, step 508/574 completed (loss: 1.5785952806472778, acc: 0.6197183132171631)
[2024-11-29 03:05:27,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:27,905][root][INFO] - Training Epoch: 2/10, step 509/574 completed (loss: 0.4025881290435791, acc: 0.8500000238418579)
[2024-11-29 03:05:28,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:28,199][root][INFO] - Training Epoch: 2/10, step 510/574 completed (loss: 0.8255387544631958, acc: 0.800000011920929)
[2024-11-29 03:05:28,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:28,490][root][INFO] - Training Epoch: 2/10, step 511/574 completed (loss: 0.732346773147583, acc: 0.807692289352417)
[2024-11-29 03:05:30,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:31,969][root][INFO] - Training Epoch: 2/10, step 512/574 completed (loss: 2.2484958171844482, acc: 0.4642857015132904)
[2024-11-29 03:05:32,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:33,071][root][INFO] - Training Epoch: 2/10, step 513/574 completed (loss: 1.3049592971801758, acc: 0.6904761791229248)
[2024-11-29 03:05:33,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:33,392][root][INFO] - Training Epoch: 2/10, step 514/574 completed (loss: 1.342409372329712, acc: 0.7142857313156128)
[2024-11-29 03:05:33,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:33,728][root][INFO] - Training Epoch: 2/10, step 515/574 completed (loss: 0.4887927174568176, acc: 0.8666666746139526)
[2024-11-29 03:05:34,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:34,699][root][INFO] - Training Epoch: 2/10, step 516/574 completed (loss: 1.2775781154632568, acc: 0.7777777910232544)
[2024-11-29 03:05:34,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:34,953][root][INFO] - Training Epoch: 2/10, step 517/574 completed (loss: 0.23998267948627472, acc: 0.9615384340286255)
[2024-11-29 03:05:35,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:35,265][root][INFO] - Training Epoch: 2/10, step 518/574 completed (loss: 0.9767593741416931, acc: 0.8064516186714172)
[2024-11-29 03:05:35,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:35,587][root][INFO] - Training Epoch: 2/10, step 519/574 completed (loss: 0.8453941345214844, acc: 0.800000011920929)
[2024-11-29 03:05:35,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:35,907][root][INFO] - Training Epoch: 2/10, step 520/574 completed (loss: 0.9341246485710144, acc: 0.7407407164573669)
[2024-11-29 03:05:36,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:37,309][root][INFO] - Training Epoch: 2/10, step 521/574 completed (loss: 1.5538519620895386, acc: 0.5720338821411133)
[2024-11-29 03:05:37,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:37,706][root][INFO] - Training Epoch: 2/10, step 522/574 completed (loss: 0.9336972832679749, acc: 0.7835820913314819)
[2024-11-29 03:05:37,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:38,089][root][INFO] - Training Epoch: 2/10, step 523/574 completed (loss: 0.9314001798629761, acc: 0.7080292105674744)
[2024-11-29 03:05:38,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:38,835][root][INFO] - Training Epoch: 2/10, step 524/574 completed (loss: 1.4180729389190674, acc: 0.625)
[2024-11-29 03:05:39,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:39,142][root][INFO] - Training Epoch: 2/10, step 525/574 completed (loss: 0.3655029535293579, acc: 0.8518518805503845)
[2024-11-29 03:05:39,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:39,472][root][INFO] - Training Epoch: 2/10, step 526/574 completed (loss: 0.5931649804115295, acc: 0.8653846383094788)
[2024-11-29 03:05:39,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:39,791][root][INFO] - Training Epoch: 2/10, step 527/574 completed (loss: 0.4815615713596344, acc: 0.9047619104385376)
[2024-11-29 03:05:39,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:40,108][root][INFO] - Training Epoch: 2/10, step 528/574 completed (loss: 2.5679471492767334, acc: 0.3442623019218445)
[2024-11-29 03:05:40,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:40,422][root][INFO] - Training Epoch: 2/10, step 529/574 completed (loss: 0.9581431746482849, acc: 0.7457627058029175)
[2024-11-29 03:05:40,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:40,691][root][INFO] - Training Epoch: 2/10, step 530/574 completed (loss: 2.9258639812469482, acc: 0.3720930218696594)
[2024-11-29 03:05:40,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:40,962][root][INFO] - Training Epoch: 2/10, step 531/574 completed (loss: 1.9752894639968872, acc: 0.6363636255264282)
[2024-11-29 03:05:41,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:41,256][root][INFO] - Training Epoch: 2/10, step 532/574 completed (loss: 2.3909800052642822, acc: 0.43396225571632385)
[2024-11-29 03:05:41,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:41,508][root][INFO] - Training Epoch: 2/10, step 533/574 completed (loss: 1.4013290405273438, acc: 0.6136363744735718)
[2024-11-29 03:05:41,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:41,775][root][INFO] - Training Epoch: 2/10, step 534/574 completed (loss: 1.2417951822280884, acc: 0.7599999904632568)
[2024-11-29 03:05:41,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:42,080][root][INFO] - Training Epoch: 2/10, step 535/574 completed (loss: 0.8064945340156555, acc: 0.8999999761581421)
[2024-11-29 03:05:42,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:42,382][root][INFO] - Training Epoch: 2/10, step 536/574 completed (loss: 0.6598406434059143, acc: 0.8181818127632141)
[2024-11-29 03:05:42,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:42,834][root][INFO] - Training Epoch: 2/10, step 537/574 completed (loss: 1.4659003019332886, acc: 0.6461538672447205)
[2024-11-29 03:05:43,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:43,150][root][INFO] - Training Epoch: 2/10, step 538/574 completed (loss: 1.2738755941390991, acc: 0.640625)
[2024-11-29 03:05:43,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:43,590][root][INFO] - Training Epoch: 2/10, step 539/574 completed (loss: 0.8492361307144165, acc: 0.78125)
[2024-11-29 03:05:43,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:43,873][root][INFO] - Training Epoch: 2/10, step 540/574 completed (loss: 1.7000733613967896, acc: 0.5454545617103577)
[2024-11-29 03:05:44,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:44,165][root][INFO] - Training Epoch: 2/10, step 541/574 completed (loss: 0.661140501499176, acc: 0.875)
[2024-11-29 03:05:44,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:44,448][root][INFO] - Training Epoch: 2/10, step 542/574 completed (loss: 0.8244789838790894, acc: 0.7096773982048035)
[2024-11-29 03:05:44,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:44,779][root][INFO] - Training Epoch: 2/10, step 543/574 completed (loss: 0.30271297693252563, acc: 0.9130434989929199)
[2024-11-29 03:05:44,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:45,098][root][INFO] - Training Epoch: 2/10, step 544/574 completed (loss: 0.5889164805412292, acc: 0.8999999761581421)
[2024-11-29 03:05:45,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:45,421][root][INFO] - Training Epoch: 2/10, step 545/574 completed (loss: 0.2599329650402069, acc: 0.9756097793579102)
[2024-11-29 03:05:45,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:45,722][root][INFO] - Training Epoch: 2/10, step 546/574 completed (loss: 0.21126125752925873, acc: 0.9428571462631226)
[2024-11-29 03:05:45,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:45,985][root][INFO] - Training Epoch: 2/10, step 547/574 completed (loss: 0.45759180188179016, acc: 0.8684210777282715)
[2024-11-29 03:05:46,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:46,261][root][INFO] - Training Epoch: 2/10, step 548/574 completed (loss: 0.9230408072471619, acc: 0.7096773982048035)
[2024-11-29 03:05:46,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:46,574][root][INFO] - Training Epoch: 2/10, step 549/574 completed (loss: 0.24858780205249786, acc: 0.9200000166893005)
[2024-11-29 03:05:46,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:46,907][root][INFO] - Training Epoch: 2/10, step 550/574 completed (loss: 0.5697098970413208, acc: 0.8484848737716675)
[2024-11-29 03:05:47,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:47,246][root][INFO] - Training Epoch: 2/10, step 551/574 completed (loss: 0.6441389918327332, acc: 0.8500000238418579)
[2024-11-29 03:05:47,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:47,546][root][INFO] - Training Epoch: 2/10, step 552/574 completed (loss: 0.7878811359405518, acc: 0.7571428418159485)
[2024-11-29 03:05:47,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:47,884][root][INFO] - Training Epoch: 2/10, step 553/574 completed (loss: 1.2255804538726807, acc: 0.6934306621551514)
[2024-11-29 03:05:48,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:48,225][root][INFO] - Training Epoch: 2/10, step 554/574 completed (loss: 1.1110318899154663, acc: 0.7310344576835632)
[2024-11-29 03:05:48,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:48,569][root][INFO] - Training Epoch: 2/10, step 555/574 completed (loss: 1.2365392446517944, acc: 0.7071428298950195)
[2024-11-29 03:05:48,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:48,883][root][INFO] - Training Epoch: 2/10, step 556/574 completed (loss: 1.078582525253296, acc: 0.695364236831665)
[2024-11-29 03:05:49,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:49,153][root][INFO] - Training Epoch: 2/10, step 557/574 completed (loss: 0.8693880438804626, acc: 0.7350427508354187)
[2024-11-29 03:05:49,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:49,456][root][INFO] - Training Epoch: 2/10, step 558/574 completed (loss: 0.31106993556022644, acc: 0.9200000166893005)
[2024-11-29 03:05:49,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:49,776][root][INFO] - Training Epoch: 2/10, step 559/574 completed (loss: 0.5210310816764832, acc: 0.8461538553237915)
[2024-11-29 03:05:49,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:50,048][root][INFO] - Training Epoch: 2/10, step 560/574 completed (loss: 0.2062564492225647, acc: 0.9230769276618958)
[2024-11-29 03:05:50,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:50,368][root][INFO] - Training Epoch: 2/10, step 561/574 completed (loss: 0.947704017162323, acc: 0.7692307829856873)
[2024-11-29 03:05:50,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:50,708][root][INFO] - Training Epoch: 2/10, step 562/574 completed (loss: 1.2139530181884766, acc: 0.6777777671813965)
[2024-11-29 03:05:50,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:50,993][root][INFO] - Training Epoch: 2/10, step 563/574 completed (loss: 1.2446972131729126, acc: 0.7402597665786743)
[2024-11-29 03:05:51,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:51,270][root][INFO] - Training Epoch: 2/10, step 564/574 completed (loss: 0.954744279384613, acc: 0.6666666865348816)
[2024-11-29 03:05:51,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:51,529][root][INFO] - Training Epoch: 2/10, step 565/574 completed (loss: 0.8639969229698181, acc: 0.7758620977401733)
[2024-11-29 03:05:51,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:51,842][root][INFO] - Training Epoch: 2/10, step 566/574 completed (loss: 0.9427340626716614, acc: 0.8333333134651184)
[2024-11-29 03:05:52,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:52,154][root][INFO] - Training Epoch: 2/10, step 567/574 completed (loss: 0.40006470680236816, acc: 0.8684210777282715)
[2024-11-29 03:05:52,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:52,482][root][INFO] - Training Epoch: 2/10, step 568/574 completed (loss: 0.30939191579818726, acc: 0.8518518805503845)
[2024-11-29 03:05:52,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:52,881][root][INFO] - Training Epoch: 2/10, step 569/574 completed (loss: 1.2820795774459839, acc: 0.6898396015167236)
[2024-11-29 03:05:53,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:54,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:54,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:54,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:55,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:55,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:56,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:56,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:57,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:57,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:57,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:58,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:58,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:59,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:05:59,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:00,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:00,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:01,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:01,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:02,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:02,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:02,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:03,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:03,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:04,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:04,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:05,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:05,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:06,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:06,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:06,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:07,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:07,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:08,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:08,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:09,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:09,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:09,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:10,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:10,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:11,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:11,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:12,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:12,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:13,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:13,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:13,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:14,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:14,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:15,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:15,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:16,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:16,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:16,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:17,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:17,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:18,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:18,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:18,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:19,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:19,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:20,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:20,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:21,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:21,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:22,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:22,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:22,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:23,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:24,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:24,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:24,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:25,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:25,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:25,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:26,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:26,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:27,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:27,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:27,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:28,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:28,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:29,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:29,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:29,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:30,567][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.5636, device='cuda:0') eval_epoch_loss=tensor(1.2708, device='cuda:0') eval_epoch_acc=tensor(0.6874, device='cuda:0')
[2024-11-29 03:06:30,569][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:06:30,569][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:06:30,894][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_2_step_570_loss_1.2707593441009521/model.pt
[2024-11-29 03:06:30,898][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 1.2707593441009521
[2024-11-29 03:06:30,898][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.6874474287033081
[2024-11-29 03:06:31,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:31,268][root][INFO] - Training Epoch: 2/10, step 570/574 completed (loss: 0.4040561020374298, acc: 0.8870967626571655)
[2024-11-29 03:06:31,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:31,586][root][INFO] - Training Epoch: 2/10, step 571/574 completed (loss: 1.2106930017471313, acc: 0.7264957427978516)
[2024-11-29 03:06:31,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:31,864][root][INFO] - Training Epoch: 2/10, step 572/574 completed (loss: 1.4213883876800537, acc: 0.6224489808082581)
[2024-11-29 03:06:32,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:32,191][root][INFO] - Training Epoch: 2/10, step 573/574 completed (loss: 1.5188663005828857, acc: 0.5911949872970581)
[2024-11-29 03:06:32,604][slam_llm.utils.train_utils][INFO] - Epoch 2: train_perplexity=3.9784, train_epoch_loss=1.3809, epoch time 383.86020143702626s
[2024-11-29 03:06:32,605][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 12 GB
[2024-11-29 03:06:32,605][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 17 GB
[2024-11-29 03:06:32,605][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 12 GB
[2024-11-29 03:06:32,605][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 5
[2024-11-29 03:06:32,605][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-29 03:06:33,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:33,368][root][INFO] - Training Epoch: 3/10, step 0/574 completed (loss: 0.7443404197692871, acc: 0.7777777910232544)
[2024-11-29 03:06:33,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:33,678][root][INFO] - Training Epoch: 3/10, step 1/574 completed (loss: 0.8207857012748718, acc: 0.800000011920929)
[2024-11-29 03:06:33,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:33,933][root][INFO] - Training Epoch: 3/10, step 2/574 completed (loss: 0.9846315979957581, acc: 0.7297297120094299)
[2024-11-29 03:06:34,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:34,236][root][INFO] - Training Epoch: 3/10, step 3/574 completed (loss: 0.9589146971702576, acc: 0.8157894611358643)
[2024-11-29 03:06:34,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:34,587][root][INFO] - Training Epoch: 3/10, step 4/574 completed (loss: 0.9712057113647461, acc: 0.7297297120094299)
[2024-11-29 03:06:34,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:34,868][root][INFO] - Training Epoch: 3/10, step 5/574 completed (loss: 0.4669308364391327, acc: 0.7857142686843872)
[2024-11-29 03:06:35,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:35,164][root][INFO] - Training Epoch: 3/10, step 6/574 completed (loss: 1.2266857624053955, acc: 0.6734693646430969)
[2024-11-29 03:06:35,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:35,473][root][INFO] - Training Epoch: 3/10, step 7/574 completed (loss: 0.8072612285614014, acc: 0.8666666746139526)
[2024-11-29 03:06:35,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:35,813][root][INFO] - Training Epoch: 3/10, step 8/574 completed (loss: 0.620877742767334, acc: 0.8181818127632141)
[2024-11-29 03:06:36,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:36,150][root][INFO] - Training Epoch: 3/10, step 9/574 completed (loss: 0.25283247232437134, acc: 0.9615384340286255)
[2024-11-29 03:06:36,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:36,470][root][INFO] - Training Epoch: 3/10, step 10/574 completed (loss: 0.5259847044944763, acc: 0.8518518805503845)
[2024-11-29 03:06:36,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:36,790][root][INFO] - Training Epoch: 3/10, step 11/574 completed (loss: 0.9826353192329407, acc: 0.6410256624221802)
[2024-11-29 03:06:37,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:37,153][root][INFO] - Training Epoch: 3/10, step 12/574 completed (loss: 0.5167526602745056, acc: 0.8484848737716675)
[2024-11-29 03:06:37,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:37,515][root][INFO] - Training Epoch: 3/10, step 13/574 completed (loss: 0.7969987392425537, acc: 0.804347813129425)
[2024-11-29 03:06:37,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:37,774][root][INFO] - Training Epoch: 3/10, step 14/574 completed (loss: 0.5555239915847778, acc: 0.8627451062202454)
[2024-11-29 03:06:37,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:38,069][root][INFO] - Training Epoch: 3/10, step 15/574 completed (loss: 0.9275919198989868, acc: 0.7551020383834839)
[2024-11-29 03:06:38,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:38,361][root][INFO] - Training Epoch: 3/10, step 16/574 completed (loss: 0.25908395648002625, acc: 0.9473684430122375)
[2024-11-29 03:06:38,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:38,625][root][INFO] - Training Epoch: 3/10, step 17/574 completed (loss: 1.0001575946807861, acc: 0.75)
[2024-11-29 03:06:38,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:38,897][root][INFO] - Training Epoch: 3/10, step 18/574 completed (loss: 1.6964949369430542, acc: 0.5833333134651184)
[2024-11-29 03:06:39,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:39,185][root][INFO] - Training Epoch: 3/10, step 19/574 completed (loss: 0.5115712285041809, acc: 0.8421052694320679)
[2024-11-29 03:06:39,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:39,490][root][INFO] - Training Epoch: 3/10, step 20/574 completed (loss: 0.9810397028923035, acc: 0.8461538553237915)
[2024-11-29 03:06:39,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:39,783][root][INFO] - Training Epoch: 3/10, step 21/574 completed (loss: 1.1574736833572388, acc: 0.8275862336158752)
[2024-11-29 03:06:39,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:40,060][root][INFO] - Training Epoch: 3/10, step 22/574 completed (loss: 1.1178796291351318, acc: 0.7200000286102295)
[2024-11-29 03:06:40,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:40,309][root][INFO] - Training Epoch: 3/10, step 23/574 completed (loss: 0.70512855052948, acc: 0.8095238208770752)
[2024-11-29 03:06:40,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:40,575][root][INFO] - Training Epoch: 3/10, step 24/574 completed (loss: 0.18461579084396362, acc: 1.0)
[2024-11-29 03:06:40,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:40,942][root][INFO] - Training Epoch: 3/10, step 25/574 completed (loss: 1.2720552682876587, acc: 0.6603773832321167)
[2024-11-29 03:06:41,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:41,206][root][INFO] - Training Epoch: 3/10, step 26/574 completed (loss: 1.3319536447525024, acc: 0.6164383292198181)
[2024-11-29 03:06:42,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:42,793][root][INFO] - Training Epoch: 3/10, step 27/574 completed (loss: 2.0515291690826416, acc: 0.4901185631752014)
[2024-11-29 03:06:42,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:43,039][root][INFO] - Training Epoch: 3/10, step 28/574 completed (loss: 1.013077735900879, acc: 0.6976743936538696)
[2024-11-29 03:06:43,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:43,331][root][INFO] - Training Epoch: 3/10, step 29/574 completed (loss: 1.3993251323699951, acc: 0.650602400302887)
[2024-11-29 03:06:43,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:43,627][root][INFO] - Training Epoch: 3/10, step 30/574 completed (loss: 1.5446165800094604, acc: 0.6296296119689941)
[2024-11-29 03:06:43,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:43,915][root][INFO] - Training Epoch: 3/10, step 31/574 completed (loss: 1.014504075050354, acc: 0.75)
[2024-11-29 03:06:44,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:44,262][root][INFO] - Training Epoch: 3/10, step 32/574 completed (loss: 0.7069244980812073, acc: 0.8518518805503845)
[2024-11-29 03:06:44,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:44,584][root][INFO] - Training Epoch: 3/10, step 33/574 completed (loss: 0.35844019055366516, acc: 0.8260869383811951)
[2024-11-29 03:06:44,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:44,897][root][INFO] - Training Epoch: 3/10, step 34/574 completed (loss: 1.0135245323181152, acc: 0.7478991746902466)
[2024-11-29 03:06:45,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:45,198][root][INFO] - Training Epoch: 3/10, step 35/574 completed (loss: 0.9343845844268799, acc: 0.7704917788505554)
[2024-11-29 03:06:45,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:45,489][root][INFO] - Training Epoch: 3/10, step 36/574 completed (loss: 0.9420945048332214, acc: 0.761904776096344)
[2024-11-29 03:06:45,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:45,764][root][INFO] - Training Epoch: 3/10, step 37/574 completed (loss: 1.0410407781600952, acc: 0.7288135886192322)
[2024-11-29 03:06:45,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:46,100][root][INFO] - Training Epoch: 3/10, step 38/574 completed (loss: 0.6827361583709717, acc: 0.8160919547080994)
[2024-11-29 03:06:46,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:46,384][root][INFO] - Training Epoch: 3/10, step 39/574 completed (loss: 0.8611925840377808, acc: 0.8095238208770752)
[2024-11-29 03:06:46,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:46,721][root][INFO] - Training Epoch: 3/10, step 40/574 completed (loss: 0.9879283308982849, acc: 0.7307692170143127)
[2024-11-29 03:06:46,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:47,142][root][INFO] - Training Epoch: 3/10, step 41/574 completed (loss: 0.9395127296447754, acc: 0.7432432174682617)
[2024-11-29 03:06:47,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:47,474][root][INFO] - Training Epoch: 3/10, step 42/574 completed (loss: 1.3477604389190674, acc: 0.692307710647583)
[2024-11-29 03:06:47,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:47,946][root][INFO] - Training Epoch: 3/10, step 43/574 completed (loss: 1.308523178100586, acc: 0.6464646458625793)
[2024-11-29 03:06:48,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:48,413][root][INFO] - Training Epoch: 3/10, step 44/574 completed (loss: 1.1319435834884644, acc: 0.7525773048400879)
[2024-11-29 03:06:48,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:48,850][root][INFO] - Training Epoch: 3/10, step 45/574 completed (loss: 1.32949960231781, acc: 0.6617646813392639)
[2024-11-29 03:06:48,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:49,101][root][INFO] - Training Epoch: 3/10, step 46/574 completed (loss: 0.623225748538971, acc: 0.807692289352417)
[2024-11-29 03:06:49,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:49,405][root][INFO] - Training Epoch: 3/10, step 47/574 completed (loss: 0.29781481623649597, acc: 0.8888888955116272)
[2024-11-29 03:06:49,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:49,698][root][INFO] - Training Epoch: 3/10, step 48/574 completed (loss: 0.3691260516643524, acc: 0.8928571343421936)
[2024-11-29 03:06:49,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:50,001][root][INFO] - Training Epoch: 3/10, step 49/574 completed (loss: 0.8338807821273804, acc: 0.75)
[2024-11-29 03:06:50,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:50,346][root][INFO] - Training Epoch: 3/10, step 50/574 completed (loss: 1.4234589338302612, acc: 0.6666666865348816)
[2024-11-29 03:06:50,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:50,670][root][INFO] - Training Epoch: 3/10, step 51/574 completed (loss: 1.7314860820770264, acc: 0.5555555820465088)
[2024-11-29 03:06:50,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:50,951][root][INFO] - Training Epoch: 3/10, step 52/574 completed (loss: 1.915644645690918, acc: 0.577464759349823)
[2024-11-29 03:06:51,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:51,485][root][INFO] - Training Epoch: 3/10, step 53/574 completed (loss: 2.321974277496338, acc: 0.4266666769981384)
[2024-11-29 03:06:51,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:51,782][root][INFO] - Training Epoch: 3/10, step 54/574 completed (loss: 1.5304224491119385, acc: 0.7027027010917664)
[2024-11-29 03:06:51,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:52,064][root][INFO] - Training Epoch: 3/10, step 55/574 completed (loss: 0.1939450204372406, acc: 0.9615384340286255)
[2024-11-29 03:06:54,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:55,999][root][INFO] - Training Epoch: 3/10, step 56/574 completed (loss: 1.8317397832870483, acc: 0.5426621437072754)
[2024-11-29 03:06:56,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:57,700][root][INFO] - Training Epoch: 3/10, step 57/574 completed (loss: 2.090054750442505, acc: 0.5076252818107605)
[2024-11-29 03:06:58,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:58,525][root][INFO] - Training Epoch: 3/10, step 58/574 completed (loss: 1.4085882902145386, acc: 0.6306818127632141)
[2024-11-29 03:06:58,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:06:59,289][root][INFO] - Training Epoch: 3/10, step 59/574 completed (loss: 1.1273194551467896, acc: 0.6838235259056091)
[2024-11-29 03:06:59,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:00,030][root][INFO] - Training Epoch: 3/10, step 60/574 completed (loss: 1.3258874416351318, acc: 0.6304348111152649)
[2024-11-29 03:07:00,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:00,509][root][INFO] - Training Epoch: 3/10, step 61/574 completed (loss: 1.448173999786377, acc: 0.6000000238418579)
[2024-11-29 03:07:00,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:00,775][root][INFO] - Training Epoch: 3/10, step 62/574 completed (loss: 0.6412497758865356, acc: 0.8235294222831726)
[2024-11-29 03:07:00,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:01,057][root][INFO] - Training Epoch: 3/10, step 63/574 completed (loss: 0.4418696165084839, acc: 0.8333333134651184)
[2024-11-29 03:07:01,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:01,367][root][INFO] - Training Epoch: 3/10, step 64/574 completed (loss: 0.5341098308563232, acc: 0.859375)
[2024-11-29 03:07:01,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:01,696][root][INFO] - Training Epoch: 3/10, step 65/574 completed (loss: 0.3857234716415405, acc: 0.8620689511299133)
[2024-11-29 03:07:01,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:02,010][root][INFO] - Training Epoch: 3/10, step 66/574 completed (loss: 1.3537627458572388, acc: 0.6607142686843872)
[2024-11-29 03:07:02,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:02,321][root][INFO] - Training Epoch: 3/10, step 67/574 completed (loss: 1.1098397970199585, acc: 0.7333333492279053)
[2024-11-29 03:07:02,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:02,643][root][INFO] - Training Epoch: 3/10, step 68/574 completed (loss: 0.20823612809181213, acc: 0.9200000166893005)
[2024-11-29 03:07:02,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:02,955][root][INFO] - Training Epoch: 3/10, step 69/574 completed (loss: 1.4229207038879395, acc: 0.6388888955116272)
[2024-11-29 03:07:03,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:03,234][root][INFO] - Training Epoch: 3/10, step 70/574 completed (loss: 1.638941764831543, acc: 0.6363636255264282)
[2024-11-29 03:07:03,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:03,564][root][INFO] - Training Epoch: 3/10, step 71/574 completed (loss: 1.8896735906600952, acc: 0.5073529481887817)
[2024-11-29 03:07:03,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:03,867][root][INFO] - Training Epoch: 3/10, step 72/574 completed (loss: 1.3960566520690918, acc: 0.6269841194152832)
[2024-11-29 03:07:04,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:04,200][root][INFO] - Training Epoch: 3/10, step 73/574 completed (loss: 2.15301775932312, acc: 0.4923076927661896)
[2024-11-29 03:07:04,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:04,542][root][INFO] - Training Epoch: 3/10, step 74/574 completed (loss: 1.9299803972244263, acc: 0.5306122303009033)
[2024-11-29 03:07:04,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:04,857][root][INFO] - Training Epoch: 3/10, step 75/574 completed (loss: 1.7330985069274902, acc: 0.5223880410194397)
[2024-11-29 03:07:05,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:05,265][root][INFO] - Training Epoch: 3/10, step 76/574 completed (loss: 2.0343759059906006, acc: 0.48175182938575745)
[2024-11-29 03:07:05,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:05,528][root][INFO] - Training Epoch: 3/10, step 77/574 completed (loss: 0.08470984548330307, acc: 1.0)
[2024-11-29 03:07:05,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:05,814][root][INFO] - Training Epoch: 3/10, step 78/574 completed (loss: 0.507881224155426, acc: 0.8333333134651184)
[2024-11-29 03:07:05,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:06,084][root][INFO] - Training Epoch: 3/10, step 79/574 completed (loss: 0.5946449041366577, acc: 0.8484848737716675)
[2024-11-29 03:07:06,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:06,406][root][INFO] - Training Epoch: 3/10, step 80/574 completed (loss: 0.3565663695335388, acc: 0.9230769276618958)
[2024-11-29 03:07:06,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:06,687][root][INFO] - Training Epoch: 3/10, step 81/574 completed (loss: 1.2458446025848389, acc: 0.7115384340286255)
[2024-11-29 03:07:06,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:06,929][root][INFO] - Training Epoch: 3/10, step 82/574 completed (loss: 1.4623627662658691, acc: 0.6538461446762085)
[2024-11-29 03:07:07,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:07,191][root][INFO] - Training Epoch: 3/10, step 83/574 completed (loss: 0.3985357880592346, acc: 0.9375)
[2024-11-29 03:07:07,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:07,465][root][INFO] - Training Epoch: 3/10, step 84/574 completed (loss: 1.1442443132400513, acc: 0.6666666865348816)
[2024-11-29 03:07:07,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:07,815][root][INFO] - Training Epoch: 3/10, step 85/574 completed (loss: 1.0973597764968872, acc: 0.7400000095367432)
[2024-11-29 03:07:07,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:08,105][root][INFO] - Training Epoch: 3/10, step 86/574 completed (loss: 0.39589035511016846, acc: 0.8695651888847351)
[2024-11-29 03:07:08,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:08,678][root][INFO] - Training Epoch: 3/10, step 87/574 completed (loss: 1.6528490781784058, acc: 0.6200000047683716)
[2024-11-29 03:07:08,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:09,023][root][INFO] - Training Epoch: 3/10, step 88/574 completed (loss: 1.5012798309326172, acc: 0.6213592290878296)
[2024-11-29 03:07:10,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:10,666][root][INFO] - Training Epoch: 3/10, step 89/574 completed (loss: 1.5233662128448486, acc: 0.6116504669189453)
[2024-11-29 03:07:11,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:11,821][root][INFO] - Training Epoch: 3/10, step 90/574 completed (loss: 1.9432015419006348, acc: 0.5053763389587402)
[2024-11-29 03:07:12,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:12,948][root][INFO] - Training Epoch: 3/10, step 91/574 completed (loss: 1.6059025526046753, acc: 0.6120689511299133)
[2024-11-29 03:07:13,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:13,991][root][INFO] - Training Epoch: 3/10, step 92/574 completed (loss: 1.391148328781128, acc: 0.6526315808296204)
[2024-11-29 03:07:14,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:15,447][root][INFO] - Training Epoch: 3/10, step 93/574 completed (loss: 2.263795852661133, acc: 0.42574256658554077)
[2024-11-29 03:07:15,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:15,712][root][INFO] - Training Epoch: 3/10, step 94/574 completed (loss: 1.721429467201233, acc: 0.5322580933570862)
[2024-11-29 03:07:15,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:16,024][root][INFO] - Training Epoch: 3/10, step 95/574 completed (loss: 1.2405614852905273, acc: 0.6521739363670349)
[2024-11-29 03:07:16,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:16,365][root][INFO] - Training Epoch: 3/10, step 96/574 completed (loss: 2.144563674926758, acc: 0.36974790692329407)
[2024-11-29 03:07:16,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:16,692][root][INFO] - Training Epoch: 3/10, step 97/574 completed (loss: 2.1516716480255127, acc: 0.39423078298568726)
[2024-11-29 03:07:16,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:17,091][root][INFO] - Training Epoch: 3/10, step 98/574 completed (loss: 2.05775785446167, acc: 0.47445255517959595)
[2024-11-29 03:07:17,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:17,378][root][INFO] - Training Epoch: 3/10, step 99/574 completed (loss: 2.266101121902466, acc: 0.4029850661754608)
[2024-11-29 03:07:17,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:17,654][root][INFO] - Training Epoch: 3/10, step 100/574 completed (loss: 0.8978792428970337, acc: 0.800000011920929)
[2024-11-29 03:07:17,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:17,986][root][INFO] - Training Epoch: 3/10, step 101/574 completed (loss: 0.19935545325279236, acc: 0.9090909361839294)
[2024-11-29 03:07:18,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:18,271][root][INFO] - Training Epoch: 3/10, step 102/574 completed (loss: 0.13051246106624603, acc: 0.95652174949646)
[2024-11-29 03:07:18,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:18,580][root][INFO] - Training Epoch: 3/10, step 103/574 completed (loss: 0.25317147374153137, acc: 0.9545454382896423)
[2024-11-29 03:07:18,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:18,908][root][INFO] - Training Epoch: 3/10, step 104/574 completed (loss: 1.139127254486084, acc: 0.7241379022598267)
[2024-11-29 03:07:19,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:19,187][root][INFO] - Training Epoch: 3/10, step 105/574 completed (loss: 0.6495678424835205, acc: 0.7906976938247681)
[2024-11-29 03:07:19,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:19,465][root][INFO] - Training Epoch: 3/10, step 106/574 completed (loss: 0.5238645076751709, acc: 0.8799999952316284)
[2024-11-29 03:07:19,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:19,727][root][INFO] - Training Epoch: 3/10, step 107/574 completed (loss: 0.04225447028875351, acc: 1.0)
[2024-11-29 03:07:19,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:20,021][root][INFO] - Training Epoch: 3/10, step 108/574 completed (loss: 0.1552611142396927, acc: 0.9230769276618958)
[2024-11-29 03:07:20,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:20,388][root][INFO] - Training Epoch: 3/10, step 109/574 completed (loss: 0.42138949036598206, acc: 0.8809523582458496)
[2024-11-29 03:07:20,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:20,704][root][INFO] - Training Epoch: 3/10, step 110/574 completed (loss: 0.5922183990478516, acc: 0.8153846263885498)
[2024-11-29 03:07:20,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:21,164][root][INFO] - Training Epoch: 3/10, step 111/574 completed (loss: 1.0209591388702393, acc: 0.7017543911933899)
[2024-11-29 03:07:21,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:21,509][root][INFO] - Training Epoch: 3/10, step 112/574 completed (loss: 1.1493897438049316, acc: 0.6666666865348816)
[2024-11-29 03:07:21,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:21,754][root][INFO] - Training Epoch: 3/10, step 113/574 completed (loss: 1.0946743488311768, acc: 0.7179487347602844)
[2024-11-29 03:07:21,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:22,116][root][INFO] - Training Epoch: 3/10, step 114/574 completed (loss: 0.42799392342567444, acc: 0.8775510191917419)
[2024-11-29 03:07:22,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:22,424][root][INFO] - Training Epoch: 3/10, step 115/574 completed (loss: 0.3061773478984833, acc: 0.9545454382896423)
[2024-11-29 03:07:22,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:22,739][root][INFO] - Training Epoch: 3/10, step 116/574 completed (loss: 1.0937532186508179, acc: 0.7142857313156128)
[2024-11-29 03:07:22,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:23,103][root][INFO] - Training Epoch: 3/10, step 117/574 completed (loss: 1.054919958114624, acc: 0.7317073345184326)
[2024-11-29 03:07:23,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:23,428][root][INFO] - Training Epoch: 3/10, step 118/574 completed (loss: 0.7530338764190674, acc: 0.7903226017951965)
[2024-11-29 03:07:24,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:24,611][root][INFO] - Training Epoch: 3/10, step 119/574 completed (loss: 1.5828748941421509, acc: 0.5931559205055237)
[2024-11-29 03:07:24,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:24,904][root][INFO] - Training Epoch: 3/10, step 120/574 completed (loss: 0.8951542973518372, acc: 0.7333333492279053)
[2024-11-29 03:07:25,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:25,352][root][INFO] - Training Epoch: 3/10, step 121/574 completed (loss: 0.9677479863166809, acc: 0.75)
[2024-11-29 03:07:25,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:25,616][root][INFO] - Training Epoch: 3/10, step 122/574 completed (loss: 0.5804350972175598, acc: 0.7916666865348816)
[2024-11-29 03:07:25,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:25,941][root][INFO] - Training Epoch: 3/10, step 123/574 completed (loss: 1.426000952720642, acc: 0.7368420958518982)
[2024-11-29 03:07:26,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:26,268][root][INFO] - Training Epoch: 3/10, step 124/574 completed (loss: 1.9805084466934204, acc: 0.4969325065612793)
[2024-11-29 03:07:26,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:26,624][root][INFO] - Training Epoch: 3/10, step 125/574 completed (loss: 1.900280475616455, acc: 0.5277777910232544)
[2024-11-29 03:07:26,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:26,953][root][INFO] - Training Epoch: 3/10, step 126/574 completed (loss: 1.6643630266189575, acc: 0.5166666507720947)
[2024-11-29 03:07:27,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:27,313][root][INFO] - Training Epoch: 3/10, step 127/574 completed (loss: 2.011809825897217, acc: 0.4702380895614624)
[2024-11-29 03:07:27,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:27,672][root][INFO] - Training Epoch: 3/10, step 128/574 completed (loss: 1.5226876735687256, acc: 0.6358974575996399)
[2024-11-29 03:07:27,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:28,116][root][INFO] - Training Epoch: 3/10, step 129/574 completed (loss: 1.9451148509979248, acc: 0.5367646813392639)
[2024-11-29 03:07:28,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:28,445][root][INFO] - Training Epoch: 3/10, step 130/574 completed (loss: 1.7056180238723755, acc: 0.5384615659713745)
[2024-11-29 03:07:28,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:28,722][root][INFO] - Training Epoch: 3/10, step 131/574 completed (loss: 1.2853615283966064, acc: 0.695652186870575)
[2024-11-29 03:07:28,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:29,035][root][INFO] - Training Epoch: 3/10, step 132/574 completed (loss: 2.5320327281951904, acc: 0.34375)
[2024-11-29 03:07:29,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:29,358][root][INFO] - Training Epoch: 3/10, step 133/574 completed (loss: 1.4788944721221924, acc: 0.6521739363670349)
[2024-11-29 03:07:29,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:29,673][root][INFO] - Training Epoch: 3/10, step 134/574 completed (loss: 1.5238921642303467, acc: 0.6285714507102966)
[2024-11-29 03:07:29,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:29,994][root][INFO] - Training Epoch: 3/10, step 135/574 completed (loss: 1.3749425411224365, acc: 0.4615384638309479)
[2024-11-29 03:07:30,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:30,317][root][INFO] - Training Epoch: 3/10, step 136/574 completed (loss: 1.2275644540786743, acc: 0.738095223903656)
[2024-11-29 03:07:30,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:30,602][root][INFO] - Training Epoch: 3/10, step 137/574 completed (loss: 1.6946769952774048, acc: 0.5333333611488342)
[2024-11-29 03:07:30,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:30,860][root][INFO] - Training Epoch: 3/10, step 138/574 completed (loss: 0.9250308871269226, acc: 0.782608687877655)
[2024-11-29 03:07:31,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:32,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:32,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:32,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:33,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:33,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:34,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:34,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:35,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:35,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:36,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:36,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:37,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:37,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:38,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:38,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:38,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:39,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:39,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:40,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:40,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:41,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:41,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:41,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:42,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:42,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:43,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:43,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:43,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:44,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:44,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:45,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:45,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:45,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:46,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:46,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:47,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:47,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:48,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:48,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:49,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:49,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:49,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:50,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:50,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:51,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:51,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:52,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:52,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:52,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:53,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:53,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:53,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:54,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:54,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:55,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:55,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:55,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:56,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:56,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:56,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:57,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:58,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:58,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:58,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:59,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:07:59,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:00,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:01,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:01,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:01,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:02,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:02,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:03,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:03,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:03,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:04,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:04,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:05,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:05,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:05,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:06,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:06,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:07,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:07,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:08,291][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.1598, device='cuda:0') eval_epoch_loss=tensor(1.1505, device='cuda:0') eval_epoch_acc=tensor(0.7012, device='cuda:0')
[2024-11-29 03:08:08,293][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:08:08,293][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:08:08,629][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_3_step_139_loss_1.150495171546936/model.pt
[2024-11-29 03:08:08,633][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 3 is 1.150495171546936
[2024-11-29 03:08:08,634][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 3 is 0.7011680006980896
[2024-11-29 03:08:08,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:08,911][root][INFO] - Training Epoch: 3/10, step 139/574 completed (loss: 1.2064263820648193, acc: 0.7142857313156128)
[2024-11-29 03:08:09,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:09,263][root][INFO] - Training Epoch: 3/10, step 140/574 completed (loss: 0.8069538474082947, acc: 0.807692289352417)
[2024-11-29 03:08:09,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:09,599][root][INFO] - Training Epoch: 3/10, step 141/574 completed (loss: 1.5320167541503906, acc: 0.5483871102333069)
[2024-11-29 03:08:09,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:09,907][root][INFO] - Training Epoch: 3/10, step 142/574 completed (loss: 0.9041951298713684, acc: 0.7297297120094299)
[2024-11-29 03:08:10,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:10,597][root][INFO] - Training Epoch: 3/10, step 143/574 completed (loss: 1.386690616607666, acc: 0.6140350699424744)
[2024-11-29 03:08:10,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:10,945][root][INFO] - Training Epoch: 3/10, step 144/574 completed (loss: 1.4332547187805176, acc: 0.611940324306488)
[2024-11-29 03:08:11,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:11,283][root][INFO] - Training Epoch: 3/10, step 145/574 completed (loss: 1.2972811460494995, acc: 0.5510203838348389)
[2024-11-29 03:08:11,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:11,835][root][INFO] - Training Epoch: 3/10, step 146/574 completed (loss: 1.6231684684753418, acc: 0.521276593208313)
[2024-11-29 03:08:12,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:12,138][root][INFO] - Training Epoch: 3/10, step 147/574 completed (loss: 1.1439181566238403, acc: 0.6857143044471741)
[2024-11-29 03:08:12,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:12,401][root][INFO] - Training Epoch: 3/10, step 148/574 completed (loss: 1.1797130107879639, acc: 0.6785714030265808)
[2024-11-29 03:08:12,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:12,705][root][INFO] - Training Epoch: 3/10, step 149/574 completed (loss: 1.4830198287963867, acc: 0.6086956262588501)
[2024-11-29 03:08:12,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:13,017][root][INFO] - Training Epoch: 3/10, step 150/574 completed (loss: 1.1862355470657349, acc: 0.7241379022598267)
[2024-11-29 03:08:13,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:13,340][root][INFO] - Training Epoch: 3/10, step 151/574 completed (loss: 1.2844558954238892, acc: 0.6739130616188049)
[2024-11-29 03:08:13,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:13,702][root][INFO] - Training Epoch: 3/10, step 152/574 completed (loss: 1.1182740926742554, acc: 0.7796609997749329)
[2024-11-29 03:08:13,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:14,011][root][INFO] - Training Epoch: 3/10, step 153/574 completed (loss: 1.8111737966537476, acc: 0.5263158082962036)
[2024-11-29 03:08:14,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:14,346][root][INFO] - Training Epoch: 3/10, step 154/574 completed (loss: 1.2176028490066528, acc: 0.6891891956329346)
[2024-11-29 03:08:14,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:14,651][root][INFO] - Training Epoch: 3/10, step 155/574 completed (loss: 0.893783688545227, acc: 0.7857142686843872)
[2024-11-29 03:08:14,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:14,991][root][INFO] - Training Epoch: 3/10, step 156/574 completed (loss: 0.9866446852684021, acc: 0.782608687877655)
[2024-11-29 03:08:15,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:15,321][root][INFO] - Training Epoch: 3/10, step 157/574 completed (loss: 3.532575845718384, acc: 0.10526315867900848)
[2024-11-29 03:08:16,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:17,845][root][INFO] - Training Epoch: 3/10, step 158/574 completed (loss: 2.209559202194214, acc: 0.44594594836235046)
[2024-11-29 03:08:17,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:18,098][root][INFO] - Training Epoch: 3/10, step 159/574 completed (loss: 2.359412431716919, acc: 0.42592594027519226)
[2024-11-29 03:08:18,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:18,565][root][INFO] - Training Epoch: 3/10, step 160/574 completed (loss: 2.5395004749298096, acc: 0.39534884691238403)
[2024-11-29 03:08:19,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:19,385][root][INFO] - Training Epoch: 3/10, step 161/574 completed (loss: 2.57889986038208, acc: 0.4000000059604645)
[2024-11-29 03:08:19,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:20,146][root][INFO] - Training Epoch: 3/10, step 162/574 completed (loss: 2.127572774887085, acc: 0.483146071434021)
[2024-11-29 03:08:20,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:20,416][root][INFO] - Training Epoch: 3/10, step 163/574 completed (loss: 0.7804589867591858, acc: 0.8181818127632141)
[2024-11-29 03:08:20,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:20,671][root][INFO] - Training Epoch: 3/10, step 164/574 completed (loss: 1.0104098320007324, acc: 0.761904776096344)
[2024-11-29 03:08:20,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:20,927][root][INFO] - Training Epoch: 3/10, step 165/574 completed (loss: 1.6596375703811646, acc: 0.5517241358757019)
[2024-11-29 03:08:21,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:21,197][root][INFO] - Training Epoch: 3/10, step 166/574 completed (loss: 0.541074275970459, acc: 0.8367347121238708)
[2024-11-29 03:08:21,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:21,443][root][INFO] - Training Epoch: 3/10, step 167/574 completed (loss: 0.6977006793022156, acc: 0.800000011920929)
[2024-11-29 03:08:21,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:21,892][root][INFO] - Training Epoch: 3/10, step 168/574 completed (loss: 0.915775716304779, acc: 0.75)
[2024-11-29 03:08:22,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:22,187][root][INFO] - Training Epoch: 3/10, step 169/574 completed (loss: 1.4644263982772827, acc: 0.6372548937797546)
[2024-11-29 03:08:23,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:23,784][root][INFO] - Training Epoch: 3/10, step 170/574 completed (loss: 2.0347516536712646, acc: 0.5410959124565125)
[2024-11-29 03:08:23,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:24,017][root][INFO] - Training Epoch: 3/10, step 171/574 completed (loss: 0.5269607901573181, acc: 0.7916666865348816)
[2024-11-29 03:08:24,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:24,260][root][INFO] - Training Epoch: 3/10, step 172/574 completed (loss: 1.9601041078567505, acc: 0.5555555820465088)
[2024-11-29 03:08:24,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:24,509][root][INFO] - Training Epoch: 3/10, step 173/574 completed (loss: 1.136985182762146, acc: 0.7142857313156128)
[2024-11-29 03:08:24,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:25,227][root][INFO] - Training Epoch: 3/10, step 174/574 completed (loss: 1.6863877773284912, acc: 0.5929203629493713)
[2024-11-29 03:08:25,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:25,478][root][INFO] - Training Epoch: 3/10, step 175/574 completed (loss: 1.3893412351608276, acc: 0.6376811861991882)
[2024-11-29 03:08:25,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:25,778][root][INFO] - Training Epoch: 3/10, step 176/574 completed (loss: 0.9071476459503174, acc: 0.7159090638160706)
[2024-11-29 03:08:26,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:27,161][root][INFO] - Training Epoch: 3/10, step 177/574 completed (loss: 2.0535471439361572, acc: 0.5343511700630188)
[2024-11-29 03:08:27,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:28,104][root][INFO] - Training Epoch: 3/10, step 178/574 completed (loss: 1.548917293548584, acc: 0.6074073910713196)
[2024-11-29 03:08:28,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:28,359][root][INFO] - Training Epoch: 3/10, step 179/574 completed (loss: 0.949303388595581, acc: 0.7540983557701111)
[2024-11-29 03:08:28,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:28,605][root][INFO] - Training Epoch: 3/10, step 180/574 completed (loss: 0.16769939661026, acc: 0.9583333134651184)
[2024-11-29 03:08:28,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:28,844][root][INFO] - Training Epoch: 3/10, step 181/574 completed (loss: 0.28309592604637146, acc: 0.9599999785423279)
[2024-11-29 03:08:28,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:29,086][root][INFO] - Training Epoch: 3/10, step 182/574 completed (loss: 0.42221173644065857, acc: 0.8571428656578064)
[2024-11-29 03:08:29,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:29,350][root][INFO] - Training Epoch: 3/10, step 183/574 completed (loss: 0.6033306121826172, acc: 0.8170731663703918)
[2024-11-29 03:08:29,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:29,660][root][INFO] - Training Epoch: 3/10, step 184/574 completed (loss: 1.1871412992477417, acc: 0.7280966639518738)
[2024-11-29 03:08:29,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:29,959][root][INFO] - Training Epoch: 3/10, step 185/574 completed (loss: 1.3420287370681763, acc: 0.6368876099586487)
[2024-11-29 03:08:30,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:30,565][root][INFO] - Training Epoch: 3/10, step 186/574 completed (loss: 1.5277931690216064, acc: 0.6031249761581421)
[2024-11-29 03:08:30,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:31,205][root][INFO] - Training Epoch: 3/10, step 187/574 completed (loss: 1.6653246879577637, acc: 0.5928705334663391)
[2024-11-29 03:08:31,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:31,653][root][INFO] - Training Epoch: 3/10, step 188/574 completed (loss: 1.2256853580474854, acc: 0.6476868391036987)
[2024-11-29 03:08:31,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:31,890][root][INFO] - Training Epoch: 3/10, step 189/574 completed (loss: 1.0664643049240112, acc: 0.7599999904632568)
[2024-11-29 03:08:32,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:32,643][root][INFO] - Training Epoch: 3/10, step 190/574 completed (loss: 1.400168776512146, acc: 0.604651153087616)
[2024-11-29 03:08:33,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:33,815][root][INFO] - Training Epoch: 3/10, step 191/574 completed (loss: 1.9566715955734253, acc: 0.5)
[2024-11-29 03:08:34,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:35,193][root][INFO] - Training Epoch: 3/10, step 192/574 completed (loss: 1.8830242156982422, acc: 0.47727271914482117)
[2024-11-29 03:08:35,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:36,274][root][INFO] - Training Epoch: 3/10, step 193/574 completed (loss: 1.3867496252059937, acc: 0.5882353186607361)
[2024-11-29 03:08:37,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:37,915][root][INFO] - Training Epoch: 3/10, step 194/574 completed (loss: 1.6493492126464844, acc: 0.5493826866149902)
[2024-11-29 03:08:38,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:39,360][root][INFO] - Training Epoch: 3/10, step 195/574 completed (loss: 0.9738914370536804, acc: 0.7096773982048035)
[2024-11-29 03:08:39,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:39,578][root][INFO] - Training Epoch: 3/10, step 196/574 completed (loss: 0.2840219736099243, acc: 0.9285714030265808)
[2024-11-29 03:08:39,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:39,808][root][INFO] - Training Epoch: 3/10, step 197/574 completed (loss: 1.7577626705169678, acc: 0.6000000238418579)
[2024-11-29 03:08:39,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:40,066][root][INFO] - Training Epoch: 3/10, step 198/574 completed (loss: 1.2231608629226685, acc: 0.6176470518112183)
[2024-11-29 03:08:40,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:40,337][root][INFO] - Training Epoch: 3/10, step 199/574 completed (loss: 1.448452353477478, acc: 0.654411792755127)
[2024-11-29 03:08:40,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:40,618][root][INFO] - Training Epoch: 3/10, step 200/574 completed (loss: 1.4013530015945435, acc: 0.6271186470985413)
[2024-11-29 03:08:40,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:40,897][root][INFO] - Training Epoch: 3/10, step 201/574 completed (loss: 1.4366869926452637, acc: 0.5970149040222168)
[2024-11-29 03:08:41,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:41,216][root][INFO] - Training Epoch: 3/10, step 202/574 completed (loss: 1.3481618165969849, acc: 0.6213592290878296)
[2024-11-29 03:08:41,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:41,480][root][INFO] - Training Epoch: 3/10, step 203/574 completed (loss: 1.1217951774597168, acc: 0.60317462682724)
[2024-11-29 03:08:41,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:41,742][root][INFO] - Training Epoch: 3/10, step 204/574 completed (loss: 0.6699824333190918, acc: 0.8241758346557617)
[2024-11-29 03:08:41,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:42,075][root][INFO] - Training Epoch: 3/10, step 205/574 completed (loss: 1.0312292575836182, acc: 0.7219731211662292)
[2024-11-29 03:08:42,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:42,512][root][INFO] - Training Epoch: 3/10, step 206/574 completed (loss: 1.2745152711868286, acc: 0.665354311466217)
[2024-11-29 03:08:42,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:42,785][root][INFO] - Training Epoch: 3/10, step 207/574 completed (loss: 0.9591978788375854, acc: 0.7370689511299133)
[2024-11-29 03:08:42,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:43,131][root][INFO] - Training Epoch: 3/10, step 208/574 completed (loss: 0.7998018264770508, acc: 0.79347825050354)
[2024-11-29 03:08:43,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:43,500][root][INFO] - Training Epoch: 3/10, step 209/574 completed (loss: 0.9390024542808533, acc: 0.7431906461715698)
[2024-11-29 03:08:43,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:43,769][root][INFO] - Training Epoch: 3/10, step 210/574 completed (loss: 0.9097467660903931, acc: 0.760869562625885)
[2024-11-29 03:08:43,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:44,015][root][INFO] - Training Epoch: 3/10, step 211/574 completed (loss: 0.5834844708442688, acc: 0.8260869383811951)
[2024-11-29 03:08:44,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:44,246][root][INFO] - Training Epoch: 3/10, step 212/574 completed (loss: 0.8168991208076477, acc: 0.7142857313156128)
[2024-11-29 03:08:44,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:44,509][root][INFO] - Training Epoch: 3/10, step 213/574 completed (loss: 0.8778358697891235, acc: 0.7872340679168701)
[2024-11-29 03:08:45,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:45,470][root][INFO] - Training Epoch: 3/10, step 214/574 completed (loss: 0.572586178779602, acc: 0.8538461327552795)
[2024-11-29 03:08:45,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:45,783][root][INFO] - Training Epoch: 3/10, step 215/574 completed (loss: 0.3808106780052185, acc: 0.8918918967247009)
[2024-11-29 03:08:45,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:46,078][root][INFO] - Training Epoch: 3/10, step 216/574 completed (loss: 0.34200817346572876, acc: 0.9186046719551086)
[2024-11-29 03:08:46,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:46,792][root][INFO] - Training Epoch: 3/10, step 217/574 completed (loss: 0.539717435836792, acc: 0.8828828930854797)
[2024-11-29 03:08:47,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:47,241][root][INFO] - Training Epoch: 3/10, step 218/574 completed (loss: 0.5624752640724182, acc: 0.8333333134651184)
[2024-11-29 03:08:47,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:47,495][root][INFO] - Training Epoch: 3/10, step 219/574 completed (loss: 0.4018193185329437, acc: 0.8787878751754761)
[2024-11-29 03:08:47,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:47,743][root][INFO] - Training Epoch: 3/10, step 220/574 completed (loss: 0.2282353788614273, acc: 0.8888888955116272)
[2024-11-29 03:08:47,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:47,981][root][INFO] - Training Epoch: 3/10, step 221/574 completed (loss: 0.31409043073654175, acc: 0.8799999952316284)
[2024-11-29 03:08:48,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:48,286][root][INFO] - Training Epoch: 3/10, step 222/574 completed (loss: 1.1617937088012695, acc: 0.692307710647583)
[2024-11-29 03:08:48,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:49,362][root][INFO] - Training Epoch: 3/10, step 223/574 completed (loss: 0.9561890363693237, acc: 0.7663043737411499)
[2024-11-29 03:08:49,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:50,083][root][INFO] - Training Epoch: 3/10, step 224/574 completed (loss: 1.078717827796936, acc: 0.75)
[2024-11-29 03:08:50,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:50,622][root][INFO] - Training Epoch: 3/10, step 225/574 completed (loss: 1.160102367401123, acc: 0.7127659320831299)
[2024-11-29 03:08:50,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:50,971][root][INFO] - Training Epoch: 3/10, step 226/574 completed (loss: 0.7874433398246765, acc: 0.7924528121948242)
[2024-11-29 03:08:51,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:51,300][root][INFO] - Training Epoch: 3/10, step 227/574 completed (loss: 0.53240966796875, acc: 0.8666666746139526)
[2024-11-29 03:08:51,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:51,565][root][INFO] - Training Epoch: 3/10, step 228/574 completed (loss: 0.9307657480239868, acc: 0.7674418687820435)
[2024-11-29 03:08:51,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:51,816][root][INFO] - Training Epoch: 3/10, step 229/574 completed (loss: 2.3251030445098877, acc: 0.4333333373069763)
[2024-11-29 03:08:52,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:52,188][root][INFO] - Training Epoch: 3/10, step 230/574 completed (loss: 3.00486421585083, acc: 0.27368420362472534)
[2024-11-29 03:08:52,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:52,446][root][INFO] - Training Epoch: 3/10, step 231/574 completed (loss: 2.2860705852508545, acc: 0.4444444477558136)
[2024-11-29 03:08:52,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:52,950][root][INFO] - Training Epoch: 3/10, step 232/574 completed (loss: 2.2556865215301514, acc: 0.47777777910232544)
[2024-11-29 03:08:53,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:53,578][root][INFO] - Training Epoch: 3/10, step 233/574 completed (loss: 2.628265380859375, acc: 0.3807339370250702)
[2024-11-29 03:08:53,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:54,180][root][INFO] - Training Epoch: 3/10, step 234/574 completed (loss: 2.540837049484253, acc: 0.4384615421295166)
[2024-11-29 03:08:54,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:54,500][root][INFO] - Training Epoch: 3/10, step 235/574 completed (loss: 0.5500604510307312, acc: 0.8421052694320679)
[2024-11-29 03:08:54,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:54,792][root][INFO] - Training Epoch: 3/10, step 236/574 completed (loss: 0.5949628949165344, acc: 0.8333333134651184)
[2024-11-29 03:08:54,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:55,052][root][INFO] - Training Epoch: 3/10, step 237/574 completed (loss: 1.0605424642562866, acc: 0.6818181872367859)
[2024-11-29 03:08:55,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:55,304][root][INFO] - Training Epoch: 3/10, step 238/574 completed (loss: 1.0866049528121948, acc: 0.7407407164573669)
[2024-11-29 03:08:55,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:55,554][root][INFO] - Training Epoch: 3/10, step 239/574 completed (loss: 0.9437932968139648, acc: 0.6285714507102966)
[2024-11-29 03:08:55,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:55,874][root][INFO] - Training Epoch: 3/10, step 240/574 completed (loss: 1.4687633514404297, acc: 0.6590909361839294)
[2024-11-29 03:08:56,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:56,172][root][INFO] - Training Epoch: 3/10, step 241/574 completed (loss: 0.9463346004486084, acc: 0.7272727489471436)
[2024-11-29 03:08:56,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:56,976][root][INFO] - Training Epoch: 3/10, step 242/574 completed (loss: 1.6724680662155151, acc: 0.5161290168762207)
[2024-11-29 03:08:57,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:57,695][root][INFO] - Training Epoch: 3/10, step 243/574 completed (loss: 1.5830833911895752, acc: 0.5681818127632141)
[2024-11-29 03:08:57,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:57,984][root][INFO] - Training Epoch: 3/10, step 244/574 completed (loss: 0.3762873411178589, acc: 0.9047619104385376)
[2024-11-29 03:08:58,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:58,288][root][INFO] - Training Epoch: 3/10, step 245/574 completed (loss: 1.6440250873565674, acc: 0.6538461446762085)
[2024-11-29 03:08:58,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:58,545][root][INFO] - Training Epoch: 3/10, step 246/574 completed (loss: 1.0178686380386353, acc: 0.7419354915618896)
[2024-11-29 03:08:58,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:58,794][root][INFO] - Training Epoch: 3/10, step 247/574 completed (loss: 0.6549951434135437, acc: 0.8500000238418579)
[2024-11-29 03:08:58,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:59,148][root][INFO] - Training Epoch: 3/10, step 248/574 completed (loss: 1.022971510887146, acc: 0.7837837934494019)
[2024-11-29 03:08:59,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:59,408][root][INFO] - Training Epoch: 3/10, step 249/574 completed (loss: 1.2790162563323975, acc: 0.6756756901741028)
[2024-11-29 03:08:59,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:59,677][root][INFO] - Training Epoch: 3/10, step 250/574 completed (loss: 0.38065212965011597, acc: 0.8648648858070374)
[2024-11-29 03:08:59,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:08:59,975][root][INFO] - Training Epoch: 3/10, step 251/574 completed (loss: 0.7683857679367065, acc: 0.8088235259056091)
[2024-11-29 03:09:00,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:00,246][root][INFO] - Training Epoch: 3/10, step 252/574 completed (loss: 0.26297467947006226, acc: 0.9512194991111755)
[2024-11-29 03:09:00,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:00,552][root][INFO] - Training Epoch: 3/10, step 253/574 completed (loss: 0.38377416133880615, acc: 0.9200000166893005)
[2024-11-29 03:09:00,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:00,815][root][INFO] - Training Epoch: 3/10, step 254/574 completed (loss: 0.08325603604316711, acc: 1.0)
[2024-11-29 03:09:00,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:01,061][root][INFO] - Training Epoch: 3/10, step 255/574 completed (loss: 0.4402046501636505, acc: 0.9032257795333862)
[2024-11-29 03:09:01,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:01,315][root][INFO] - Training Epoch: 3/10, step 256/574 completed (loss: 0.5202019214630127, acc: 0.9122806787490845)
[2024-11-29 03:09:01,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:01,569][root][INFO] - Training Epoch: 3/10, step 257/574 completed (loss: 0.5700523257255554, acc: 0.8285714387893677)
[2024-11-29 03:09:01,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:01,843][root][INFO] - Training Epoch: 3/10, step 258/574 completed (loss: 0.511497437953949, acc: 0.8815789222717285)
[2024-11-29 03:09:02,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:02,607][root][INFO] - Training Epoch: 3/10, step 259/574 completed (loss: 1.0677648782730103, acc: 0.7075471878051758)
[2024-11-29 03:09:03,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:03,394][root][INFO] - Training Epoch: 3/10, step 260/574 completed (loss: 1.0764272212982178, acc: 0.75)
[2024-11-29 03:09:03,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:03,635][root][INFO] - Training Epoch: 3/10, step 261/574 completed (loss: 0.4296400547027588, acc: 0.8611111044883728)
[2024-11-29 03:09:03,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:03,880][root][INFO] - Training Epoch: 3/10, step 262/574 completed (loss: 0.8246155977249146, acc: 0.7096773982048035)
[2024-11-29 03:09:04,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:04,215][root][INFO] - Training Epoch: 3/10, step 263/574 completed (loss: 1.807701826095581, acc: 0.653333306312561)
[2024-11-29 03:09:04,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:04,485][root][INFO] - Training Epoch: 3/10, step 264/574 completed (loss: 1.1763652563095093, acc: 0.625)
[2024-11-29 03:09:05,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:05,691][root][INFO] - Training Epoch: 3/10, step 265/574 completed (loss: 1.8131173849105835, acc: 0.5600000023841858)
[2024-11-29 03:09:05,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:06,001][root][INFO] - Training Epoch: 3/10, step 266/574 completed (loss: 1.4410749673843384, acc: 0.6292135119438171)
[2024-11-29 03:09:06,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:06,354][root][INFO] - Training Epoch: 3/10, step 267/574 completed (loss: 1.7372314929962158, acc: 0.5540540814399719)
[2024-11-29 03:09:06,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:06,923][root][INFO] - Training Epoch: 3/10, step 268/574 completed (loss: 1.15494704246521, acc: 0.7068965435028076)
[2024-11-29 03:09:07,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:07,168][root][INFO] - Training Epoch: 3/10, step 269/574 completed (loss: 0.13908039033412933, acc: 0.9545454382896423)
[2024-11-29 03:09:07,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:07,419][root][INFO] - Training Epoch: 3/10, step 270/574 completed (loss: 0.3501843214035034, acc: 0.8636363744735718)
[2024-11-29 03:09:07,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:07,669][root][INFO] - Training Epoch: 3/10, step 271/574 completed (loss: 0.29708290100097656, acc: 0.875)
[2024-11-29 03:09:07,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:07,920][root][INFO] - Training Epoch: 3/10, step 272/574 completed (loss: 0.32421761751174927, acc: 0.9333333373069763)
[2024-11-29 03:09:08,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:08,333][root][INFO] - Training Epoch: 3/10, step 273/574 completed (loss: 0.889137327671051, acc: 0.75)
[2024-11-29 03:09:08,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:08,606][root][INFO] - Training Epoch: 3/10, step 274/574 completed (loss: 0.37024497985839844, acc: 0.875)
[2024-11-29 03:09:08,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:08,874][root][INFO] - Training Epoch: 3/10, step 275/574 completed (loss: 0.4965130686759949, acc: 0.8333333134651184)
[2024-11-29 03:09:09,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:09,129][root][INFO] - Training Epoch: 3/10, step 276/574 completed (loss: 0.5292423367500305, acc: 0.931034505367279)
[2024-11-29 03:09:09,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:09,377][root][INFO] - Training Epoch: 3/10, step 277/574 completed (loss: 0.3122139573097229, acc: 0.9599999785423279)
[2024-11-29 03:09:09,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:09,633][root][INFO] - Training Epoch: 3/10, step 278/574 completed (loss: 1.0944838523864746, acc: 0.7021276354789734)
[2024-11-29 03:09:09,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:09,924][root][INFO] - Training Epoch: 3/10, step 279/574 completed (loss: 0.5543645024299622, acc: 0.8333333134651184)
[2024-11-29 03:09:10,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:10,172][root][INFO] - Training Epoch: 3/10, step 280/574 completed (loss: 0.44547536969184875, acc: 0.8636363744735718)
[2024-11-29 03:09:10,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:10,660][root][INFO] - Training Epoch: 3/10, step 281/574 completed (loss: 1.5311123132705688, acc: 0.6144578456878662)
[2024-11-29 03:09:11,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:11,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:12,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:12,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:13,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:13,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:14,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:14,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:14,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:15,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:15,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:16,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:16,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:17,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:17,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:18,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:18,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:19,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:19,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:20,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:20,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:20,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:21,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:22,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:22,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:23,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:23,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:23,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:24,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:24,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:25,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:25,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:26,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:26,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:27,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:27,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:27,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:28,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:28,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:29,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:29,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:30,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:30,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:31,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:31,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:32,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:32,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:32,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:33,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:33,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:33,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:34,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:34,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:35,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:35,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:36,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:36,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:37,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:37,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:38,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:38,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:39,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:40,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:40,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:40,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:41,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:41,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:42,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:43,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:43,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:44,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:44,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:45,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:45,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:46,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:46,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:47,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:47,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:47,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:48,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:48,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:49,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:49,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:50,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:50,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:51,265][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.9398, device='cuda:0') eval_epoch_loss=tensor(1.0783, device='cuda:0') eval_epoch_acc=tensor(0.7142, device='cuda:0')
[2024-11-29 03:09:51,266][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:09:51,266][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:09:51,590][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_3_step_282_loss_1.0783368349075317/model.pt
[2024-11-29 03:09:51,597][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 3 is 1.0783368349075317
[2024-11-29 03:09:51,597][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 3 is 0.7141891121864319
[2024-11-29 03:09:51,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:51,979][root][INFO] - Training Epoch: 3/10, step 282/574 completed (loss: 1.4639567136764526, acc: 0.5925925970077515)
[2024-11-29 03:09:52,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:52,248][root][INFO] - Training Epoch: 3/10, step 283/574 completed (loss: 0.3446255326271057, acc: 0.8947368264198303)
[2024-11-29 03:09:52,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:52,483][root][INFO] - Training Epoch: 3/10, step 284/574 completed (loss: 0.5715935230255127, acc: 0.8529411554336548)
[2024-11-29 03:09:52,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:52,737][root][INFO] - Training Epoch: 3/10, step 285/574 completed (loss: 0.7275105118751526, acc: 0.875)
[2024-11-29 03:09:52,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:53,051][root][INFO] - Training Epoch: 3/10, step 286/574 completed (loss: 0.8665659427642822, acc: 0.734375)
[2024-11-29 03:09:53,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:53,376][root][INFO] - Training Epoch: 3/10, step 287/574 completed (loss: 1.036271572113037, acc: 0.7599999904632568)
[2024-11-29 03:09:53,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:53,629][root][INFO] - Training Epoch: 3/10, step 288/574 completed (loss: 0.7878892421722412, acc: 0.8131868243217468)
[2024-11-29 03:09:53,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:53,939][root][INFO] - Training Epoch: 3/10, step 289/574 completed (loss: 0.832875669002533, acc: 0.782608687877655)
[2024-11-29 03:09:54,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:54,302][root][INFO] - Training Epoch: 3/10, step 290/574 completed (loss: 1.0951052904129028, acc: 0.7164948582649231)
[2024-11-29 03:09:54,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:54,561][root][INFO] - Training Epoch: 3/10, step 291/574 completed (loss: 0.193498894572258, acc: 1.0)
[2024-11-29 03:09:54,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:54,787][root][INFO] - Training Epoch: 3/10, step 292/574 completed (loss: 1.2305821180343628, acc: 0.6190476417541504)
[2024-11-29 03:09:54,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:55,055][root][INFO] - Training Epoch: 3/10, step 293/574 completed (loss: 0.6839060187339783, acc: 0.8793103694915771)
[2024-11-29 03:09:55,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:55,654][root][INFO] - Training Epoch: 3/10, step 294/574 completed (loss: 0.8500803112983704, acc: 0.7818182110786438)
[2024-11-29 03:09:56,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:56,372][root][INFO] - Training Epoch: 3/10, step 295/574 completed (loss: 1.1777650117874146, acc: 0.6804123520851135)
[2024-11-29 03:09:56,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:56,624][root][INFO] - Training Epoch: 3/10, step 296/574 completed (loss: 1.26438307762146, acc: 0.6724137663841248)
[2024-11-29 03:09:56,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:56,912][root][INFO] - Training Epoch: 3/10, step 297/574 completed (loss: 0.3371126055717468, acc: 0.9259259104728699)
[2024-11-29 03:09:57,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:57,198][root][INFO] - Training Epoch: 3/10, step 298/574 completed (loss: 0.7550778388977051, acc: 0.7105262875556946)
[2024-11-29 03:09:57,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:57,448][root][INFO] - Training Epoch: 3/10, step 299/574 completed (loss: 0.4756489396095276, acc: 0.8928571343421936)
[2024-11-29 03:09:57,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:57,718][root][INFO] - Training Epoch: 3/10, step 300/574 completed (loss: 0.06924241781234741, acc: 1.0)
[2024-11-29 03:09:57,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:57,988][root][INFO] - Training Epoch: 3/10, step 301/574 completed (loss: 0.5365530252456665, acc: 0.8301886916160583)
[2024-11-29 03:09:58,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:58,258][root][INFO] - Training Epoch: 3/10, step 302/574 completed (loss: 0.26625651121139526, acc: 0.8867924809455872)
[2024-11-29 03:09:58,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:58,556][root][INFO] - Training Epoch: 3/10, step 303/574 completed (loss: 0.3376629054546356, acc: 0.9411764740943909)
[2024-11-29 03:09:58,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:58,814][root][INFO] - Training Epoch: 3/10, step 304/574 completed (loss: 0.29867318272590637, acc: 0.875)
[2024-11-29 03:09:58,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:59,110][root][INFO] - Training Epoch: 3/10, step 305/574 completed (loss: 0.8667153716087341, acc: 0.8196721076965332)
[2024-11-29 03:09:59,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:59,358][root][INFO] - Training Epoch: 3/10, step 306/574 completed (loss: 0.23684494197368622, acc: 0.9333333373069763)
[2024-11-29 03:09:59,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:59,603][root][INFO] - Training Epoch: 3/10, step 307/574 completed (loss: 0.029813895002007484, acc: 1.0)
[2024-11-29 03:09:59,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:09:59,927][root][INFO] - Training Epoch: 3/10, step 308/574 completed (loss: 0.569796621799469, acc: 0.8405796885490417)
[2024-11-29 03:10:00,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:00,414][root][INFO] - Training Epoch: 3/10, step 309/574 completed (loss: 0.6879950165748596, acc: 0.8194444179534912)
[2024-11-29 03:10:00,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:00,688][root][INFO] - Training Epoch: 3/10, step 310/574 completed (loss: 0.6471799612045288, acc: 0.8313252925872803)
[2024-11-29 03:10:00,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:01,002][root][INFO] - Training Epoch: 3/10, step 311/574 completed (loss: 0.7615395784378052, acc: 0.7692307829856873)
[2024-11-29 03:10:01,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:01,356][root][INFO] - Training Epoch: 3/10, step 312/574 completed (loss: 0.4674205780029297, acc: 0.8571428656578064)
[2024-11-29 03:10:01,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:01,607][root][INFO] - Training Epoch: 3/10, step 313/574 completed (loss: 0.12851111590862274, acc: 0.9583333134651184)
[2024-11-29 03:10:01,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:01,882][root][INFO] - Training Epoch: 3/10, step 314/574 completed (loss: 0.2671256363391876, acc: 0.9166666865348816)
[2024-11-29 03:10:02,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:02,223][root][INFO] - Training Epoch: 3/10, step 315/574 completed (loss: 0.4061349630355835, acc: 0.8709677457809448)
[2024-11-29 03:10:02,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:02,497][root][INFO] - Training Epoch: 3/10, step 316/574 completed (loss: 1.7737563848495483, acc: 0.6451612710952759)
[2024-11-29 03:10:02,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:02,805][root][INFO] - Training Epoch: 3/10, step 317/574 completed (loss: 0.5347733497619629, acc: 0.8656716346740723)
[2024-11-29 03:10:02,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:03,103][root][INFO] - Training Epoch: 3/10, step 318/574 completed (loss: 0.3747638463973999, acc: 0.8942307829856873)
[2024-11-29 03:10:03,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:03,350][root][INFO] - Training Epoch: 3/10, step 319/574 completed (loss: 0.3847300708293915, acc: 0.9111111164093018)
[2024-11-29 03:10:03,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:03,596][root][INFO] - Training Epoch: 3/10, step 320/574 completed (loss: 0.2377702295780182, acc: 0.9032257795333862)
[2024-11-29 03:10:03,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:03,863][root][INFO] - Training Epoch: 3/10, step 321/574 completed (loss: 0.03761109709739685, acc: 1.0)
[2024-11-29 03:10:04,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:04,117][root][INFO] - Training Epoch: 3/10, step 322/574 completed (loss: 1.711783766746521, acc: 0.5925925970077515)
[2024-11-29 03:10:04,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:04,417][root][INFO] - Training Epoch: 3/10, step 323/574 completed (loss: 2.461127281188965, acc: 0.37142857909202576)
[2024-11-29 03:10:04,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:04,718][root][INFO] - Training Epoch: 3/10, step 324/574 completed (loss: 2.421788454055786, acc: 0.43589743971824646)
[2024-11-29 03:10:04,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:05,035][root][INFO] - Training Epoch: 3/10, step 325/574 completed (loss: 2.3280270099639893, acc: 0.4146341383457184)
[2024-11-29 03:10:05,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:05,317][root][INFO] - Training Epoch: 3/10, step 326/574 completed (loss: 1.9990930557250977, acc: 0.42105263471603394)
[2024-11-29 03:10:05,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:05,565][root][INFO] - Training Epoch: 3/10, step 327/574 completed (loss: 0.8653681874275208, acc: 0.7368420958518982)
[2024-11-29 03:10:05,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:05,816][root][INFO] - Training Epoch: 3/10, step 328/574 completed (loss: 0.20394648611545563, acc: 0.9642857313156128)
[2024-11-29 03:10:05,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:06,074][root][INFO] - Training Epoch: 3/10, step 329/574 completed (loss: 0.19591303169727325, acc: 0.9259259104728699)
[2024-11-29 03:10:06,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:06,380][root][INFO] - Training Epoch: 3/10, step 330/574 completed (loss: 0.09986484050750732, acc: 0.96875)
[2024-11-29 03:10:06,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:06,671][root][INFO] - Training Epoch: 3/10, step 331/574 completed (loss: 0.851279616355896, acc: 0.7096773982048035)
[2024-11-29 03:10:06,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:07,076][root][INFO] - Training Epoch: 3/10, step 332/574 completed (loss: 0.43731728196144104, acc: 0.9122806787490845)
[2024-11-29 03:10:07,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:07,341][root][INFO] - Training Epoch: 3/10, step 333/574 completed (loss: 0.5298680067062378, acc: 0.875)
[2024-11-29 03:10:07,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:07,631][root][INFO] - Training Epoch: 3/10, step 334/574 completed (loss: 0.205821692943573, acc: 0.9666666388511658)
[2024-11-29 03:10:07,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:07,882][root][INFO] - Training Epoch: 3/10, step 335/574 completed (loss: 0.757519543170929, acc: 0.7368420958518982)
[2024-11-29 03:10:08,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:08,153][root][INFO] - Training Epoch: 3/10, step 336/574 completed (loss: 1.455168604850769, acc: 0.6200000047683716)
[2024-11-29 03:10:08,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:08,475][root][INFO] - Training Epoch: 3/10, step 337/574 completed (loss: 1.9701038599014282, acc: 0.5057471394538879)
[2024-11-29 03:10:08,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:08,791][root][INFO] - Training Epoch: 3/10, step 338/574 completed (loss: 1.7420061826705933, acc: 0.5531914830207825)
[2024-11-29 03:10:08,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:09,086][root][INFO] - Training Epoch: 3/10, step 339/574 completed (loss: 1.8379395008087158, acc: 0.5542168617248535)
[2024-11-29 03:10:09,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:09,335][root][INFO] - Training Epoch: 3/10, step 340/574 completed (loss: 0.19430139660835266, acc: 0.95652174949646)
[2024-11-29 03:10:09,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:09,580][root][INFO] - Training Epoch: 3/10, step 341/574 completed (loss: 0.921640932559967, acc: 0.8461538553237915)
[2024-11-29 03:10:09,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:09,849][root][INFO] - Training Epoch: 3/10, step 342/574 completed (loss: 0.6979495286941528, acc: 0.8433734774589539)
[2024-11-29 03:10:09,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:10,110][root][INFO] - Training Epoch: 3/10, step 343/574 completed (loss: 1.4099334478378296, acc: 0.7358490824699402)
[2024-11-29 03:10:10,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:10,368][root][INFO] - Training Epoch: 3/10, step 344/574 completed (loss: 0.5631662011146545, acc: 0.8607594966888428)
[2024-11-29 03:10:10,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:10,619][root][INFO] - Training Epoch: 3/10, step 345/574 completed (loss: 0.5738421678543091, acc: 0.843137264251709)
[2024-11-29 03:10:10,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:10,884][root][INFO] - Training Epoch: 3/10, step 346/574 completed (loss: 1.1024326086044312, acc: 0.7313432693481445)
[2024-11-29 03:10:11,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:11,136][root][INFO] - Training Epoch: 3/10, step 347/574 completed (loss: 0.10285099595785141, acc: 1.0)
[2024-11-29 03:10:11,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:11,391][root][INFO] - Training Epoch: 3/10, step 348/574 completed (loss: 0.5079715847969055, acc: 0.800000011920929)
[2024-11-29 03:10:11,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:11,829][root][INFO] - Training Epoch: 3/10, step 349/574 completed (loss: 1.0661662817001343, acc: 0.75)
[2024-11-29 03:10:11,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:12,098][root][INFO] - Training Epoch: 3/10, step 350/574 completed (loss: 1.3958598375320435, acc: 0.5581395626068115)
[2024-11-29 03:10:12,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:12,391][root][INFO] - Training Epoch: 3/10, step 351/574 completed (loss: 0.5714400410652161, acc: 0.8717948794364929)
[2024-11-29 03:10:12,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:12,794][root][INFO] - Training Epoch: 3/10, step 352/574 completed (loss: 1.9363539218902588, acc: 0.46666666865348816)
[2024-11-29 03:10:12,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:13,045][root][INFO] - Training Epoch: 3/10, step 353/574 completed (loss: 0.1628250628709793, acc: 0.9130434989929199)
[2024-11-29 03:10:13,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:13,297][root][INFO] - Training Epoch: 3/10, step 354/574 completed (loss: 0.7408584952354431, acc: 0.807692289352417)
[2024-11-29 03:10:13,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:13,619][root][INFO] - Training Epoch: 3/10, step 355/574 completed (loss: 1.5837328433990479, acc: 0.5824176073074341)
[2024-11-29 03:10:13,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:14,268][root][INFO] - Training Epoch: 3/10, step 356/574 completed (loss: 1.1414128541946411, acc: 0.7130434513092041)
[2024-11-29 03:10:14,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:14,579][root][INFO] - Training Epoch: 3/10, step 357/574 completed (loss: 0.9128718972206116, acc: 0.760869562625885)
[2024-11-29 03:10:14,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:14,857][root][INFO] - Training Epoch: 3/10, step 358/574 completed (loss: 0.8686681985855103, acc: 0.7346938848495483)
[2024-11-29 03:10:14,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:15,100][root][INFO] - Training Epoch: 3/10, step 359/574 completed (loss: 0.042025234550237656, acc: 1.0)
[2024-11-29 03:10:15,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:15,390][root][INFO] - Training Epoch: 3/10, step 360/574 completed (loss: 0.6743650436401367, acc: 0.8846153616905212)
[2024-11-29 03:10:15,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:15,693][root][INFO] - Training Epoch: 3/10, step 361/574 completed (loss: 1.2718911170959473, acc: 0.6341463327407837)
[2024-11-29 03:10:15,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:15,951][root][INFO] - Training Epoch: 3/10, step 362/574 completed (loss: 0.7293024063110352, acc: 0.7777777910232544)
[2024-11-29 03:10:16,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:16,215][root][INFO] - Training Epoch: 3/10, step 363/574 completed (loss: 0.6095957159996033, acc: 0.8421052694320679)
[2024-11-29 03:10:16,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:16,472][root][INFO] - Training Epoch: 3/10, step 364/574 completed (loss: 0.4815532863140106, acc: 0.9024389982223511)
[2024-11-29 03:10:16,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:16,727][root][INFO] - Training Epoch: 3/10, step 365/574 completed (loss: 0.31958523392677307, acc: 0.939393937587738)
[2024-11-29 03:10:16,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:17,006][root][INFO] - Training Epoch: 3/10, step 366/574 completed (loss: 0.0265632513910532, acc: 1.0)
[2024-11-29 03:10:17,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:17,252][root][INFO] - Training Epoch: 3/10, step 367/574 completed (loss: 0.1904088705778122, acc: 0.9130434989929199)
[2024-11-29 03:10:17,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:17,506][root][INFO] - Training Epoch: 3/10, step 368/574 completed (loss: 0.3303891122341156, acc: 0.9285714030265808)
[2024-11-29 03:10:17,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:17,757][root][INFO] - Training Epoch: 3/10, step 369/574 completed (loss: 0.7523962259292603, acc: 0.78125)
[2024-11-29 03:10:18,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:18,574][root][INFO] - Training Epoch: 3/10, step 370/574 completed (loss: 1.4743084907531738, acc: 0.6545454263687134)
[2024-11-29 03:10:19,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:19,792][root][INFO] - Training Epoch: 3/10, step 371/574 completed (loss: 0.8548781871795654, acc: 0.8207547068595886)
[2024-11-29 03:10:19,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:20,109][root][INFO] - Training Epoch: 3/10, step 372/574 completed (loss: 0.7136253118515015, acc: 0.800000011920929)
[2024-11-29 03:10:20,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:20,380][root][INFO] - Training Epoch: 3/10, step 373/574 completed (loss: 0.44282153248786926, acc: 0.8928571343421936)
[2024-11-29 03:10:20,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:20,683][root][INFO] - Training Epoch: 3/10, step 374/574 completed (loss: 0.36816927790641785, acc: 0.8857142925262451)
[2024-11-29 03:10:20,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:20,933][root][INFO] - Training Epoch: 3/10, step 375/574 completed (loss: 0.16028842329978943, acc: 0.9599999785423279)
[2024-11-29 03:10:21,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:21,186][root][INFO] - Training Epoch: 3/10, step 376/574 completed (loss: 0.07172562181949615, acc: 0.95652174949646)
[2024-11-29 03:10:21,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:21,449][root][INFO] - Training Epoch: 3/10, step 377/574 completed (loss: 0.6521042585372925, acc: 0.8125)
[2024-11-29 03:10:21,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:21,751][root][INFO] - Training Epoch: 3/10, step 378/574 completed (loss: 0.13725125789642334, acc: 0.9684210419654846)
[2024-11-29 03:10:22,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:22,526][root][INFO] - Training Epoch: 3/10, step 379/574 completed (loss: 0.6565505862236023, acc: 0.8383233547210693)
[2024-11-29 03:10:22,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:22,997][root][INFO] - Training Epoch: 3/10, step 380/574 completed (loss: 0.7562465071678162, acc: 0.8045112490653992)
[2024-11-29 03:10:24,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:24,747][root][INFO] - Training Epoch: 3/10, step 381/574 completed (loss: 1.1348758935928345, acc: 0.7433155179023743)
[2024-11-29 03:10:25,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:25,509][root][INFO] - Training Epoch: 3/10, step 382/574 completed (loss: 0.34071916341781616, acc: 0.9099099040031433)
[2024-11-29 03:10:25,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:25,753][root][INFO] - Training Epoch: 3/10, step 383/574 completed (loss: 0.5044019818305969, acc: 0.8571428656578064)
[2024-11-29 03:10:25,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:26,045][root][INFO] - Training Epoch: 3/10, step 384/574 completed (loss: 0.08456150442361832, acc: 0.9642857313156128)
[2024-11-29 03:10:26,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:26,373][root][INFO] - Training Epoch: 3/10, step 385/574 completed (loss: 0.3775442838668823, acc: 0.875)
[2024-11-29 03:10:26,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:26,664][root][INFO] - Training Epoch: 3/10, step 386/574 completed (loss: 0.12881042063236237, acc: 0.9722222089767456)
[2024-11-29 03:10:26,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:26,952][root][INFO] - Training Epoch: 3/10, step 387/574 completed (loss: 0.1187901645898819, acc: 1.0)
[2024-11-29 03:10:27,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:27,267][root][INFO] - Training Epoch: 3/10, step 388/574 completed (loss: 0.0658455416560173, acc: 1.0)
[2024-11-29 03:10:27,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:27,592][root][INFO] - Training Epoch: 3/10, step 389/574 completed (loss: 0.03342157602310181, acc: 1.0)
[2024-11-29 03:10:27,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:27,923][root][INFO] - Training Epoch: 3/10, step 390/574 completed (loss: 0.7156631946563721, acc: 0.7142857313156128)
[2024-11-29 03:10:28,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:28,257][root][INFO] - Training Epoch: 3/10, step 391/574 completed (loss: 1.3709133863449097, acc: 0.6666666865348816)
[2024-11-29 03:10:28,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:28,566][root][INFO] - Training Epoch: 3/10, step 392/574 completed (loss: 1.6176680326461792, acc: 0.6407766938209534)
[2024-11-29 03:10:28,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:29,251][root][INFO] - Training Epoch: 3/10, step 393/574 completed (loss: 1.396463394165039, acc: 0.6764705777168274)
[2024-11-29 03:10:29,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:29,649][root][INFO] - Training Epoch: 3/10, step 394/574 completed (loss: 1.7217217683792114, acc: 0.5799999833106995)
[2024-11-29 03:10:29,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:30,082][root][INFO] - Training Epoch: 3/10, step 395/574 completed (loss: 1.103371262550354, acc: 0.7083333134651184)
[2024-11-29 03:10:30,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:30,409][root][INFO] - Training Epoch: 3/10, step 396/574 completed (loss: 0.8560603857040405, acc: 0.7906976938247681)
[2024-11-29 03:10:30,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:30,693][root][INFO] - Training Epoch: 3/10, step 397/574 completed (loss: 0.12249007076025009, acc: 0.9583333134651184)
[2024-11-29 03:10:30,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:31,008][root][INFO] - Training Epoch: 3/10, step 398/574 completed (loss: 0.7004257440567017, acc: 0.7906976938247681)
[2024-11-29 03:10:31,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:31,327][root][INFO] - Training Epoch: 3/10, step 399/574 completed (loss: 0.10595928877592087, acc: 1.0)
[2024-11-29 03:10:31,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:32,039][root][INFO] - Training Epoch: 3/10, step 400/574 completed (loss: 1.1138758659362793, acc: 0.7058823704719543)
[2024-11-29 03:10:32,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:32,353][root][INFO] - Training Epoch: 3/10, step 401/574 completed (loss: 0.8558652997016907, acc: 0.7200000286102295)
[2024-11-29 03:10:32,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:32,658][root][INFO] - Training Epoch: 3/10, step 402/574 completed (loss: 0.9981071949005127, acc: 0.7878788113594055)
[2024-11-29 03:10:32,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:32,959][root][INFO] - Training Epoch: 3/10, step 403/574 completed (loss: 0.3197510242462158, acc: 0.939393937587738)
[2024-11-29 03:10:33,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:33,221][root][INFO] - Training Epoch: 3/10, step 404/574 completed (loss: 0.9658844470977783, acc: 0.6774193644523621)
[2024-11-29 03:10:33,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:33,556][root][INFO] - Training Epoch: 3/10, step 405/574 completed (loss: 0.42432811856269836, acc: 0.8518518805503845)
[2024-11-29 03:10:33,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:33,824][root][INFO] - Training Epoch: 3/10, step 406/574 completed (loss: 0.25085440278053284, acc: 0.9599999785423279)
[2024-11-29 03:10:34,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:34,119][root][INFO] - Training Epoch: 3/10, step 407/574 completed (loss: 0.29955947399139404, acc: 0.9166666865348816)
[2024-11-29 03:10:34,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:34,447][root][INFO] - Training Epoch: 3/10, step 408/574 completed (loss: 0.3832981288433075, acc: 0.8888888955116272)
[2024-11-29 03:10:34,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:34,778][root][INFO] - Training Epoch: 3/10, step 409/574 completed (loss: 0.1456703394651413, acc: 0.9615384340286255)
[2024-11-29 03:10:34,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:35,097][root][INFO] - Training Epoch: 3/10, step 410/574 completed (loss: 0.40361979603767395, acc: 0.8965517282485962)
[2024-11-29 03:10:35,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:35,367][root][INFO] - Training Epoch: 3/10, step 411/574 completed (loss: 0.2743132412433624, acc: 0.9285714030265808)
[2024-11-29 03:10:35,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:35,630][root][INFO] - Training Epoch: 3/10, step 412/574 completed (loss: 0.2448677271604538, acc: 0.9666666388511658)
[2024-11-29 03:10:35,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:35,930][root][INFO] - Training Epoch: 3/10, step 413/574 completed (loss: 0.19607968628406525, acc: 0.939393937587738)
[2024-11-29 03:10:36,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:36,231][root][INFO] - Training Epoch: 3/10, step 414/574 completed (loss: 0.07236044108867645, acc: 1.0)
[2024-11-29 03:10:36,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:36,570][root][INFO] - Training Epoch: 3/10, step 415/574 completed (loss: 0.7537293434143066, acc: 0.8039215803146362)
[2024-11-29 03:10:36,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:36,897][root][INFO] - Training Epoch: 3/10, step 416/574 completed (loss: 0.2423626035451889, acc: 0.8846153616905212)
[2024-11-29 03:10:37,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:37,204][root][INFO] - Training Epoch: 3/10, step 417/574 completed (loss: 0.4873623251914978, acc: 0.8888888955116272)
[2024-11-29 03:10:37,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:37,521][root][INFO] - Training Epoch: 3/10, step 418/574 completed (loss: 0.447446346282959, acc: 0.8500000238418579)
[2024-11-29 03:10:37,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:37,836][root][INFO] - Training Epoch: 3/10, step 419/574 completed (loss: 0.385039359331131, acc: 0.8500000238418579)
[2024-11-29 03:10:38,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:38,154][root][INFO] - Training Epoch: 3/10, step 420/574 completed (loss: 0.10578927397727966, acc: 1.0)
[2024-11-29 03:10:38,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:38,425][root][INFO] - Training Epoch: 3/10, step 421/574 completed (loss: 0.09120244532823563, acc: 0.9666666388511658)
[2024-11-29 03:10:38,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:38,723][root][INFO] - Training Epoch: 3/10, step 422/574 completed (loss: 0.628582775592804, acc: 0.84375)
[2024-11-29 03:10:38,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:39,034][root][INFO] - Training Epoch: 3/10, step 423/574 completed (loss: 1.1273589134216309, acc: 0.6944444179534912)
[2024-11-29 03:10:39,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:39,349][root][INFO] - Training Epoch: 3/10, step 424/574 completed (loss: 0.5834677219390869, acc: 0.8888888955116272)
[2024-11-29 03:10:40,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:40,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:41,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:41,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:41,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:42,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:42,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:43,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:43,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:43,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:44,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:45,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:45,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:45,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:46,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:46,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:47,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:47,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:48,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:48,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:48,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:49,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:49,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:50,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:50,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:51,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:51,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:51,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:52,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:52,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:53,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:53,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:53,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:54,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:54,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:55,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:55,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:56,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:56,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:57,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:57,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:57,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:58,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:58,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:59,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:59,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:10:59,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:00,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:00,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:01,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:01,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:01,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:02,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:02,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:03,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:03,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:04,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:04,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:05,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:05,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:05,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:06,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:07,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:07,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:07,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:08,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:08,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:09,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:10,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:10,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:11,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:11,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:12,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:12,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:13,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:13,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:13,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:14,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:14,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:14,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:15,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:15,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:16,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:16,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:17,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:17,776][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.1432, device='cuda:0') eval_epoch_loss=tensor(1.1452, device='cuda:0') eval_epoch_acc=tensor(0.7296, device='cuda:0')
[2024-11-29 03:11:17,777][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:11:17,777][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:11:18,097][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_3_step_425_loss_1.1452292203903198/model.pt
[2024-11-29 03:11:18,101][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 3 is 0.7296116352081299
[2024-11-29 03:11:18,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:18,375][root][INFO] - Training Epoch: 3/10, step 425/574 completed (loss: 0.2908700704574585, acc: 0.9090909361839294)
[2024-11-29 03:11:18,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:18,628][root][INFO] - Training Epoch: 3/10, step 426/574 completed (loss: 0.24536731839179993, acc: 0.95652174949646)
[2024-11-29 03:11:18,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:18,885][root][INFO] - Training Epoch: 3/10, step 427/574 completed (loss: 0.7818284630775452, acc: 0.7837837934494019)
[2024-11-29 03:11:19,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:19,140][root][INFO] - Training Epoch: 3/10, step 428/574 completed (loss: 0.11405463516712189, acc: 1.0)
[2024-11-29 03:11:19,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:19,399][root][INFO] - Training Epoch: 3/10, step 429/574 completed (loss: 0.07406426221132278, acc: 1.0)
[2024-11-29 03:11:19,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:19,645][root][INFO] - Training Epoch: 3/10, step 430/574 completed (loss: 0.013173867017030716, acc: 1.0)
[2024-11-29 03:11:19,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:19,893][root][INFO] - Training Epoch: 3/10, step 431/574 completed (loss: 0.2793422043323517, acc: 0.9259259104728699)
[2024-11-29 03:11:20,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:20,140][root][INFO] - Training Epoch: 3/10, step 432/574 completed (loss: 0.10109040886163712, acc: 1.0)
[2024-11-29 03:11:20,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:20,491][root][INFO] - Training Epoch: 3/10, step 433/574 completed (loss: 0.5301005840301514, acc: 0.8611111044883728)
[2024-11-29 03:11:20,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:20,748][root][INFO] - Training Epoch: 3/10, step 434/574 completed (loss: 0.11695582419633865, acc: 0.9599999785423279)
[2024-11-29 03:11:20,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:20,999][root][INFO] - Training Epoch: 3/10, step 435/574 completed (loss: 0.10944074392318726, acc: 0.939393937587738)
[2024-11-29 03:11:21,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:21,252][root][INFO] - Training Epoch: 3/10, step 436/574 completed (loss: 0.7074951529502869, acc: 0.8333333134651184)
[2024-11-29 03:11:21,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:21,515][root][INFO] - Training Epoch: 3/10, step 437/574 completed (loss: 0.421413391828537, acc: 0.8636363744735718)
[2024-11-29 03:11:21,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:21,790][root][INFO] - Training Epoch: 3/10, step 438/574 completed (loss: 0.02727661281824112, acc: 1.0)
[2024-11-29 03:11:21,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:22,089][root][INFO] - Training Epoch: 3/10, step 439/574 completed (loss: 0.4380338191986084, acc: 0.8461538553237915)
[2024-11-29 03:11:22,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:22,665][root][INFO] - Training Epoch: 3/10, step 440/574 completed (loss: 0.6252514123916626, acc: 0.8636363744735718)
[2024-11-29 03:11:23,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:23,619][root][INFO] - Training Epoch: 3/10, step 441/574 completed (loss: 1.13319993019104, acc: 0.7279999852180481)
[2024-11-29 03:11:23,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:24,081][root][INFO] - Training Epoch: 3/10, step 442/574 completed (loss: 1.221968412399292, acc: 0.7096773982048035)
[2024-11-29 03:11:24,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:24,987][root][INFO] - Training Epoch: 3/10, step 443/574 completed (loss: 1.008965015411377, acc: 0.7711442708969116)
[2024-11-29 03:11:25,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:25,232][root][INFO] - Training Epoch: 3/10, step 444/574 completed (loss: 0.7769666910171509, acc: 0.849056601524353)
[2024-11-29 03:11:25,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:25,733][root][INFO] - Training Epoch: 3/10, step 445/574 completed (loss: 0.29063254594802856, acc: 0.8863636255264282)
[2024-11-29 03:11:25,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:26,030][root][INFO] - Training Epoch: 3/10, step 446/574 completed (loss: 0.8404178619384766, acc: 0.8260869383811951)
[2024-11-29 03:11:26,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:26,287][root][INFO] - Training Epoch: 3/10, step 447/574 completed (loss: 0.6293059587478638, acc: 0.8846153616905212)
[2024-11-29 03:11:26,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:26,586][root][INFO] - Training Epoch: 3/10, step 448/574 completed (loss: 0.3563487231731415, acc: 0.8928571343421936)
[2024-11-29 03:11:26,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:26,851][root][INFO] - Training Epoch: 3/10, step 449/574 completed (loss: 0.31934258341789246, acc: 0.9402984976768494)
[2024-11-29 03:11:26,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:27,109][root][INFO] - Training Epoch: 3/10, step 450/574 completed (loss: 0.2684437930583954, acc: 0.9166666865348816)
[2024-11-29 03:11:27,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:27,367][root][INFO] - Training Epoch: 3/10, step 451/574 completed (loss: 0.20211218297481537, acc: 0.9347826242446899)
[2024-11-29 03:11:27,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:27,629][root][INFO] - Training Epoch: 3/10, step 452/574 completed (loss: 0.5463455319404602, acc: 0.8717948794364929)
[2024-11-29 03:11:27,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:27,900][root][INFO] - Training Epoch: 3/10, step 453/574 completed (loss: 0.7140698432922363, acc: 0.7763158082962036)
[2024-11-29 03:11:28,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:28,169][root][INFO] - Training Epoch: 3/10, step 454/574 completed (loss: 0.4595486521720886, acc: 0.8979591727256775)
[2024-11-29 03:11:28,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:28,428][root][INFO] - Training Epoch: 3/10, step 455/574 completed (loss: 0.43513381481170654, acc: 0.8787878751754761)
[2024-11-29 03:11:28,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:28,697][root][INFO] - Training Epoch: 3/10, step 456/574 completed (loss: 0.9771647453308105, acc: 0.7525773048400879)
[2024-11-29 03:11:28,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:28,976][root][INFO] - Training Epoch: 3/10, step 457/574 completed (loss: 0.40463733673095703, acc: 0.8571428656578064)
[2024-11-29 03:11:29,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:29,396][root][INFO] - Training Epoch: 3/10, step 458/574 completed (loss: 1.1783360242843628, acc: 0.6627907156944275)
[2024-11-29 03:11:29,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:29,642][root][INFO] - Training Epoch: 3/10, step 459/574 completed (loss: 0.5691192746162415, acc: 0.8571428656578064)
[2024-11-29 03:11:29,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:29,920][root][INFO] - Training Epoch: 3/10, step 460/574 completed (loss: 0.7234753966331482, acc: 0.8395061492919922)
[2024-11-29 03:11:30,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:30,169][root][INFO] - Training Epoch: 3/10, step 461/574 completed (loss: 0.6204898357391357, acc: 0.8055555820465088)
[2024-11-29 03:11:30,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:30,431][root][INFO] - Training Epoch: 3/10, step 462/574 completed (loss: 0.2493719607591629, acc: 0.90625)
[2024-11-29 03:11:30,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:30,685][root][INFO] - Training Epoch: 3/10, step 463/574 completed (loss: 0.316811740398407, acc: 0.9230769276618958)
[2024-11-29 03:11:30,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:30,938][root][INFO] - Training Epoch: 3/10, step 464/574 completed (loss: 0.5596815347671509, acc: 0.8913043737411499)
[2024-11-29 03:11:31,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:31,213][root][INFO] - Training Epoch: 3/10, step 465/574 completed (loss: 0.5516310930252075, acc: 0.8452380895614624)
[2024-11-29 03:11:31,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:31,477][root][INFO] - Training Epoch: 3/10, step 466/574 completed (loss: 1.2264727354049683, acc: 0.6987951993942261)
[2024-11-29 03:11:31,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:31,777][root][INFO] - Training Epoch: 3/10, step 467/574 completed (loss: 0.4600578546524048, acc: 0.8828828930854797)
[2024-11-29 03:11:31,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:32,032][root][INFO] - Training Epoch: 3/10, step 468/574 completed (loss: 1.1589677333831787, acc: 0.708737850189209)
[2024-11-29 03:11:32,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:32,304][root][INFO] - Training Epoch: 3/10, step 469/574 completed (loss: 1.5418176651000977, acc: 0.6097561120986938)
[2024-11-29 03:11:32,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:32,535][root][INFO] - Training Epoch: 3/10, step 470/574 completed (loss: 0.3203529417514801, acc: 0.9166666865348816)
[2024-11-29 03:11:32,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:32,771][root][INFO] - Training Epoch: 3/10, step 471/574 completed (loss: 0.4925461411476135, acc: 0.8928571343421936)
[2024-11-29 03:11:33,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:33,246][root][INFO] - Training Epoch: 3/10, step 472/574 completed (loss: 1.1384369134902954, acc: 0.6764705777168274)
[2024-11-29 03:11:33,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:33,622][root][INFO] - Training Epoch: 3/10, step 473/574 completed (loss: 1.3946788311004639, acc: 0.6375545859336853)
[2024-11-29 03:11:33,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:33,942][root][INFO] - Training Epoch: 3/10, step 474/574 completed (loss: 1.0865827798843384, acc: 0.75)
[2024-11-29 03:11:34,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:34,273][root][INFO] - Training Epoch: 3/10, step 475/574 completed (loss: 0.7035768628120422, acc: 0.8159509301185608)
[2024-11-29 03:11:34,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:34,573][root][INFO] - Training Epoch: 3/10, step 476/574 completed (loss: 0.6968128681182861, acc: 0.8057553768157959)
[2024-11-29 03:11:34,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:34,922][root][INFO] - Training Epoch: 3/10, step 477/574 completed (loss: 1.0814372301101685, acc: 0.6683416962623596)
[2024-11-29 03:11:35,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:35,171][root][INFO] - Training Epoch: 3/10, step 478/574 completed (loss: 0.8125500082969666, acc: 0.7777777910232544)
[2024-11-29 03:11:35,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:35,433][root][INFO] - Training Epoch: 3/10, step 479/574 completed (loss: 0.6339055895805359, acc: 0.7878788113594055)
[2024-11-29 03:11:35,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:35,688][root][INFO] - Training Epoch: 3/10, step 480/574 completed (loss: 0.6925005912780762, acc: 0.8518518805503845)
[2024-11-29 03:11:35,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:35,928][root][INFO] - Training Epoch: 3/10, step 481/574 completed (loss: 0.8579730987548828, acc: 0.75)
[2024-11-29 03:11:36,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:36,173][root][INFO] - Training Epoch: 3/10, step 482/574 completed (loss: 1.4492976665496826, acc: 0.75)
[2024-11-29 03:11:36,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:36,582][root][INFO] - Training Epoch: 3/10, step 483/574 completed (loss: 1.2653082609176636, acc: 0.6551724076271057)
[2024-11-29 03:11:36,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:36,831][root][INFO] - Training Epoch: 3/10, step 484/574 completed (loss: 0.2134171575307846, acc: 0.9354838728904724)
[2024-11-29 03:11:36,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:37,064][root][INFO] - Training Epoch: 3/10, step 485/574 completed (loss: 0.4548415541648865, acc: 0.8947368264198303)
[2024-11-29 03:11:37,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:37,308][root][INFO] - Training Epoch: 3/10, step 486/574 completed (loss: 1.5286115407943726, acc: 0.5185185074806213)
[2024-11-29 03:11:37,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:37,553][root][INFO] - Training Epoch: 3/10, step 487/574 completed (loss: 0.8708414435386658, acc: 0.7142857313156128)
[2024-11-29 03:11:37,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:37,795][root][INFO] - Training Epoch: 3/10, step 488/574 completed (loss: 1.4207301139831543, acc: 0.6818181872367859)
[2024-11-29 03:11:37,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:38,142][root][INFO] - Training Epoch: 3/10, step 489/574 completed (loss: 1.3302550315856934, acc: 0.6153846383094788)
[2024-11-29 03:11:38,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:38,427][root][INFO] - Training Epoch: 3/10, step 490/574 completed (loss: 0.33764076232910156, acc: 0.8999999761581421)
[2024-11-29 03:11:38,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:38,676][root][INFO] - Training Epoch: 3/10, step 491/574 completed (loss: 0.5986343622207642, acc: 0.8275862336158752)
[2024-11-29 03:11:38,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:38,930][root][INFO] - Training Epoch: 3/10, step 492/574 completed (loss: 0.780117928981781, acc: 0.7843137383460999)
[2024-11-29 03:11:39,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:39,180][root][INFO] - Training Epoch: 3/10, step 493/574 completed (loss: 0.9067733287811279, acc: 0.7586206793785095)
[2024-11-29 03:11:39,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:39,417][root][INFO] - Training Epoch: 3/10, step 494/574 completed (loss: 0.6452964544296265, acc: 0.8947368264198303)
[2024-11-29 03:11:39,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:39,634][root][INFO] - Training Epoch: 3/10, step 495/574 completed (loss: 1.1897674798965454, acc: 0.7894737124443054)
[2024-11-29 03:11:39,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:39,958][root][INFO] - Training Epoch: 3/10, step 496/574 completed (loss: 1.3875601291656494, acc: 0.6517857313156128)
[2024-11-29 03:11:40,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:40,355][root][INFO] - Training Epoch: 3/10, step 497/574 completed (loss: 0.6164023876190186, acc: 0.8314606547355652)
[2024-11-29 03:11:40,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:40,648][root][INFO] - Training Epoch: 3/10, step 498/574 completed (loss: 1.0295896530151367, acc: 0.6966292262077332)
[2024-11-29 03:11:40,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:40,955][root][INFO] - Training Epoch: 3/10, step 499/574 completed (loss: 1.7563896179199219, acc: 0.5177304744720459)
[2024-11-29 03:11:41,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:41,238][root][INFO] - Training Epoch: 3/10, step 500/574 completed (loss: 1.36112380027771, acc: 0.6630434989929199)
[2024-11-29 03:11:41,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:41,486][root][INFO] - Training Epoch: 3/10, step 501/574 completed (loss: 0.08983422070741653, acc: 1.0)
[2024-11-29 03:11:41,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:41,731][root][INFO] - Training Epoch: 3/10, step 502/574 completed (loss: 0.15128283202648163, acc: 0.9615384340286255)
[2024-11-29 03:11:41,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:41,987][root][INFO] - Training Epoch: 3/10, step 503/574 completed (loss: 0.711298406124115, acc: 0.7777777910232544)
[2024-11-29 03:11:42,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:42,235][root][INFO] - Training Epoch: 3/10, step 504/574 completed (loss: 0.37316587567329407, acc: 0.9629629850387573)
[2024-11-29 03:11:42,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:42,442][root][INFO] - Training Epoch: 3/10, step 505/574 completed (loss: 0.9647871851921082, acc: 0.7735849022865295)
[2024-11-29 03:11:42,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:42,701][root][INFO] - Training Epoch: 3/10, step 506/574 completed (loss: 1.5504295825958252, acc: 0.5517241358757019)
[2024-11-29 03:11:43,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:43,505][root][INFO] - Training Epoch: 3/10, step 507/574 completed (loss: 1.655517339706421, acc: 0.5765765905380249)
[2024-11-29 03:11:43,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:44,053][root][INFO] - Training Epoch: 3/10, step 508/574 completed (loss: 1.292289137840271, acc: 0.6760563254356384)
[2024-11-29 03:11:44,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:44,300][root][INFO] - Training Epoch: 3/10, step 509/574 completed (loss: 0.2571816146373749, acc: 0.949999988079071)
[2024-11-29 03:11:44,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:44,549][root][INFO] - Training Epoch: 3/10, step 510/574 completed (loss: 0.29807326197624207, acc: 0.9333333373069763)
[2024-11-29 03:11:44,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:44,823][root][INFO] - Training Epoch: 3/10, step 511/574 completed (loss: 0.39567962288856506, acc: 0.8846153616905212)
[2024-11-29 03:11:47,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:48,314][root][INFO] - Training Epoch: 3/10, step 512/574 completed (loss: 1.9238468408584595, acc: 0.5)
[2024-11-29 03:11:48,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:49,417][root][INFO] - Training Epoch: 3/10, step 513/574 completed (loss: 0.8286311626434326, acc: 0.7777777910232544)
[2024-11-29 03:11:49,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:49,662][root][INFO] - Training Epoch: 3/10, step 514/574 completed (loss: 0.937530517578125, acc: 0.75)
[2024-11-29 03:11:49,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:49,927][root][INFO] - Training Epoch: 3/10, step 515/574 completed (loss: 0.2084595113992691, acc: 0.9333333373069763)
[2024-11-29 03:11:50,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:50,897][root][INFO] - Training Epoch: 3/10, step 516/574 completed (loss: 0.8138889670372009, acc: 0.75)
[2024-11-29 03:11:51,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:51,140][root][INFO] - Training Epoch: 3/10, step 517/574 completed (loss: 0.11380769312381744, acc: 0.9615384340286255)
[2024-11-29 03:11:51,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:51,409][root][INFO] - Training Epoch: 3/10, step 518/574 completed (loss: 0.4305577576160431, acc: 0.9354838728904724)
[2024-11-29 03:11:51,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:51,647][root][INFO] - Training Epoch: 3/10, step 519/574 completed (loss: 0.4694738984107971, acc: 0.8500000238418579)
[2024-11-29 03:11:51,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:51,902][root][INFO] - Training Epoch: 3/10, step 520/574 completed (loss: 0.19167424738407135, acc: 1.0)
[2024-11-29 03:11:52,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:53,302][root][INFO] - Training Epoch: 3/10, step 521/574 completed (loss: 1.138178825378418, acc: 0.6822034120559692)
[2024-11-29 03:11:53,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:53,663][root][INFO] - Training Epoch: 3/10, step 522/574 completed (loss: 0.5127229690551758, acc: 0.8507462739944458)
[2024-11-29 03:11:53,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:54,046][root][INFO] - Training Epoch: 3/10, step 523/574 completed (loss: 0.6126765012741089, acc: 0.8394160866737366)
[2024-11-29 03:11:54,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:54,788][root][INFO] - Training Epoch: 3/10, step 524/574 completed (loss: 1.055493712425232, acc: 0.7549999952316284)
[2024-11-29 03:11:54,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:55,093][root][INFO] - Training Epoch: 3/10, step 525/574 completed (loss: 0.1047772690653801, acc: 0.9629629850387573)
[2024-11-29 03:11:55,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:55,379][root][INFO] - Training Epoch: 3/10, step 526/574 completed (loss: 0.34559595584869385, acc: 0.8653846383094788)
[2024-11-29 03:11:55,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:55,676][root][INFO] - Training Epoch: 3/10, step 527/574 completed (loss: 0.2945839762687683, acc: 0.9047619104385376)
[2024-11-29 03:11:55,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:55,983][root][INFO] - Training Epoch: 3/10, step 528/574 completed (loss: 2.0258352756500244, acc: 0.4098360538482666)
[2024-11-29 03:11:56,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:56,281][root][INFO] - Training Epoch: 3/10, step 529/574 completed (loss: 0.44667738676071167, acc: 0.9152542352676392)
[2024-11-29 03:11:56,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:56,630][root][INFO] - Training Epoch: 3/10, step 530/574 completed (loss: 2.039339542388916, acc: 0.5348837375640869)
[2024-11-29 03:11:56,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:56,961][root][INFO] - Training Epoch: 3/10, step 531/574 completed (loss: 1.7478455305099487, acc: 0.6136363744735718)
[2024-11-29 03:11:57,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:57,271][root][INFO] - Training Epoch: 3/10, step 532/574 completed (loss: 1.8390508890151978, acc: 0.5660377144813538)
[2024-11-29 03:11:57,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:57,539][root][INFO] - Training Epoch: 3/10, step 533/574 completed (loss: 1.2598133087158203, acc: 0.7272727489471436)
[2024-11-29 03:11:57,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:57,813][root][INFO] - Training Epoch: 3/10, step 534/574 completed (loss: 0.9176083207130432, acc: 0.8399999737739563)
[2024-11-29 03:11:57,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:58,081][root][INFO] - Training Epoch: 3/10, step 535/574 completed (loss: 0.7139342427253723, acc: 0.800000011920929)
[2024-11-29 03:11:58,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:58,373][root][INFO] - Training Epoch: 3/10, step 536/574 completed (loss: 0.303549200296402, acc: 0.9090909361839294)
[2024-11-29 03:11:58,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:58,845][root][INFO] - Training Epoch: 3/10, step 537/574 completed (loss: 1.143760085105896, acc: 0.7384615540504456)
[2024-11-29 03:11:59,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:59,185][root][INFO] - Training Epoch: 3/10, step 538/574 completed (loss: 0.7294487953186035, acc: 0.78125)
[2024-11-29 03:11:59,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:59,629][root][INFO] - Training Epoch: 3/10, step 539/574 completed (loss: 0.6798098683357239, acc: 0.875)
[2024-11-29 03:11:59,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:11:59,965][root][INFO] - Training Epoch: 3/10, step 540/574 completed (loss: 1.4913781881332397, acc: 0.5757575631141663)
[2024-11-29 03:12:00,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:00,280][root][INFO] - Training Epoch: 3/10, step 541/574 completed (loss: 0.35982808470726013, acc: 0.9375)
[2024-11-29 03:12:00,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:00,546][root][INFO] - Training Epoch: 3/10, step 542/574 completed (loss: 0.4121239185333252, acc: 0.9354838728904724)
[2024-11-29 03:12:00,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:00,885][root][INFO] - Training Epoch: 3/10, step 543/574 completed (loss: 0.08507212996482849, acc: 0.95652174949646)
[2024-11-29 03:12:01,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:01,170][root][INFO] - Training Epoch: 3/10, step 544/574 completed (loss: 0.31484612822532654, acc: 0.8999999761581421)
[2024-11-29 03:12:01,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:01,495][root][INFO] - Training Epoch: 3/10, step 545/574 completed (loss: 0.14055386185646057, acc: 0.9756097793579102)
[2024-11-29 03:12:01,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:01,770][root][INFO] - Training Epoch: 3/10, step 546/574 completed (loss: 0.2309037297964096, acc: 0.9428571462631226)
[2024-11-29 03:12:01,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:02,041][root][INFO] - Training Epoch: 3/10, step 547/574 completed (loss: 0.33077603578567505, acc: 0.8947368264198303)
[2024-11-29 03:12:02,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:02,349][root][INFO] - Training Epoch: 3/10, step 548/574 completed (loss: 0.21492162346839905, acc: 0.9354838728904724)
[2024-11-29 03:12:02,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:02,675][root][INFO] - Training Epoch: 3/10, step 549/574 completed (loss: 0.10109005123376846, acc: 0.9599999785423279)
[2024-11-29 03:12:02,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:02,964][root][INFO] - Training Epoch: 3/10, step 550/574 completed (loss: 0.3445970416069031, acc: 0.9090909361839294)
[2024-11-29 03:12:03,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:03,271][root][INFO] - Training Epoch: 3/10, step 551/574 completed (loss: 0.42465606331825256, acc: 0.875)
[2024-11-29 03:12:03,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:03,597][root][INFO] - Training Epoch: 3/10, step 552/574 completed (loss: 0.2870243489742279, acc: 0.9428571462631226)
[2024-11-29 03:12:03,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:03,911][root][INFO] - Training Epoch: 3/10, step 553/574 completed (loss: 0.7136564254760742, acc: 0.8248175382614136)
[2024-11-29 03:12:04,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:04,230][root][INFO] - Training Epoch: 3/10, step 554/574 completed (loss: 0.7257217168807983, acc: 0.7931034564971924)
[2024-11-29 03:12:04,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:04,565][root][INFO] - Training Epoch: 3/10, step 555/574 completed (loss: 0.9769529104232788, acc: 0.7285714149475098)
[2024-11-29 03:12:04,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:04,885][root][INFO] - Training Epoch: 3/10, step 556/574 completed (loss: 0.6522119641304016, acc: 0.8013244867324829)
[2024-11-29 03:12:05,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:05,170][root][INFO] - Training Epoch: 3/10, step 557/574 completed (loss: 0.45495834946632385, acc: 0.8547008633613586)
[2024-11-29 03:12:05,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:05,459][root][INFO] - Training Epoch: 3/10, step 558/574 completed (loss: 0.2056920826435089, acc: 0.9200000166893005)
[2024-11-29 03:12:05,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:05,825][root][INFO] - Training Epoch: 3/10, step 559/574 completed (loss: 0.20315566658973694, acc: 0.9230769276618958)
[2024-11-29 03:12:06,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:06,155][root][INFO] - Training Epoch: 3/10, step 560/574 completed (loss: 0.09052406251430511, acc: 0.9615384340286255)
[2024-11-29 03:12:06,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:06,463][root][INFO] - Training Epoch: 3/10, step 561/574 completed (loss: 0.6223757863044739, acc: 0.8461538553237915)
[2024-11-29 03:12:06,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:06,812][root][INFO] - Training Epoch: 3/10, step 562/574 completed (loss: 0.979352593421936, acc: 0.699999988079071)
[2024-11-29 03:12:06,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:07,102][root][INFO] - Training Epoch: 3/10, step 563/574 completed (loss: 0.8388637900352478, acc: 0.8181818127632141)
[2024-11-29 03:12:07,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:07,365][root][INFO] - Training Epoch: 3/10, step 564/574 completed (loss: 0.41140806674957275, acc: 0.8541666865348816)
[2024-11-29 03:12:07,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:07,632][root][INFO] - Training Epoch: 3/10, step 565/574 completed (loss: 0.5801603198051453, acc: 0.7931034564971924)
[2024-11-29 03:12:07,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:07,950][root][INFO] - Training Epoch: 3/10, step 566/574 completed (loss: 0.6493114829063416, acc: 0.8571428656578064)
[2024-11-29 03:12:08,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:08,264][root][INFO] - Training Epoch: 3/10, step 567/574 completed (loss: 0.045562826097011566, acc: 1.0)
[2024-11-29 03:12:09,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:09,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:10,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:10,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:10,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:11,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:11,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:12,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:12,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:12,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:13,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:13,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:14,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:14,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:15,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:15,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:16,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:16,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:17,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:17,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:17,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:18,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:18,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:19,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:19,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:19,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:20,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:20,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:21,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:21,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:22,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:22,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:22,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:23,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:23,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:24,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:24,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:24,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:25,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:25,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:26,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:26,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:26,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:27,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:27,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:28,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:28,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:28,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:29,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:29,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:29,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:30,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:30,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:31,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:31,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:31,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:32,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:32,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:33,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:33,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:33,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:34,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:35,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:35,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:35,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:36,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:36,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:37,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:37,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:38,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:38,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:38,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:39,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:39,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:40,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:40,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:41,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:41,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:41,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:42,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:42,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:42,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:43,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:43,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:44,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:44,658][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.2363, device='cuda:0') eval_epoch_loss=tensor(1.1744, device='cuda:0') eval_epoch_acc=tensor(0.7169, device='cuda:0')
[2024-11-29 03:12:44,659][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:12:44,659][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:12:44,912][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_3_step_568_loss_1.1744434833526611/model.pt
[2024-11-29 03:12:45,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:45,221][root][INFO] - Training Epoch: 3/10, step 568/574 completed (loss: 0.02349245920777321, acc: 1.0)
[2024-11-29 03:12:45,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:45,621][root][INFO] - Training Epoch: 3/10, step 569/574 completed (loss: 0.7661460041999817, acc: 0.8074866533279419)
[2024-11-29 03:12:45,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:45,924][root][INFO] - Training Epoch: 3/10, step 570/574 completed (loss: 0.18374143540859222, acc: 0.9354838728904724)
[2024-11-29 03:12:46,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:46,252][root][INFO] - Training Epoch: 3/10, step 571/574 completed (loss: 0.8267917633056641, acc: 0.8290598392486572)
[2024-11-29 03:12:46,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:46,540][root][INFO] - Training Epoch: 3/10, step 572/574 completed (loss: 1.196181058883667, acc: 0.6734693646430969)
[2024-11-29 03:12:46,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:46,860][root][INFO] - Training Epoch: 3/10, step 573/574 completed (loss: 1.1880382299423218, acc: 0.698113203048706)
[2024-11-29 03:12:47,288][slam_llm.utils.train_utils][INFO] - Epoch 3: train_perplexity=2.4660, train_epoch_loss=0.9026, epoch time 374.68224744312465s
[2024-11-29 03:12:47,289][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-11-29 03:12:47,289][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 17 GB
[2024-11-29 03:12:47,289][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-11-29 03:12:47,289][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 7
[2024-11-29 03:12:47,289][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-29 03:12:47,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:48,022][root][INFO] - Training Epoch: 4/10, step 0/574 completed (loss: 0.2615288496017456, acc: 0.9259259104728699)
[2024-11-29 03:12:48,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:48,267][root][INFO] - Training Epoch: 4/10, step 1/574 completed (loss: 0.4028356075286865, acc: 0.9200000166893005)
[2024-11-29 03:12:48,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:48,549][root][INFO] - Training Epoch: 4/10, step 2/574 completed (loss: 0.671046257019043, acc: 0.7837837934494019)
[2024-11-29 03:12:48,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:48,911][root][INFO] - Training Epoch: 4/10, step 3/574 completed (loss: 0.7601227164268494, acc: 0.7894737124443054)
[2024-11-29 03:12:49,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:49,258][root][INFO] - Training Epoch: 4/10, step 4/574 completed (loss: 0.4221489429473877, acc: 0.8918918967247009)
[2024-11-29 03:12:49,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:49,565][root][INFO] - Training Epoch: 4/10, step 5/574 completed (loss: 0.2097167819738388, acc: 0.9285714030265808)
[2024-11-29 03:12:49,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:49,912][root][INFO] - Training Epoch: 4/10, step 6/574 completed (loss: 1.135148048400879, acc: 0.7142857313156128)
[2024-11-29 03:12:50,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:50,229][root][INFO] - Training Epoch: 4/10, step 7/574 completed (loss: 0.5777931213378906, acc: 0.8666666746139526)
[2024-11-29 03:12:50,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:50,511][root][INFO] - Training Epoch: 4/10, step 8/574 completed (loss: 0.26521551609039307, acc: 0.9545454382896423)
[2024-11-29 03:12:50,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:50,819][root][INFO] - Training Epoch: 4/10, step 9/574 completed (loss: 0.05013897642493248, acc: 1.0)
[2024-11-29 03:12:51,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:51,136][root][INFO] - Training Epoch: 4/10, step 10/574 completed (loss: 0.18676777184009552, acc: 0.9629629850387573)
[2024-11-29 03:12:51,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:51,463][root][INFO] - Training Epoch: 4/10, step 11/574 completed (loss: 0.5148434638977051, acc: 0.8717948794364929)
[2024-11-29 03:12:51,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:51,751][root][INFO] - Training Epoch: 4/10, step 12/574 completed (loss: 0.09375216066837311, acc: 0.9696969985961914)
[2024-11-29 03:12:51,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:52,059][root][INFO] - Training Epoch: 4/10, step 13/574 completed (loss: 0.5250930190086365, acc: 0.782608687877655)
[2024-11-29 03:12:52,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:52,385][root][INFO] - Training Epoch: 4/10, step 14/574 completed (loss: 0.2833399176597595, acc: 0.9019607901573181)
[2024-11-29 03:12:52,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:52,678][root][INFO] - Training Epoch: 4/10, step 15/574 completed (loss: 0.5993800163269043, acc: 0.8367347121238708)
[2024-11-29 03:12:52,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:52,945][root][INFO] - Training Epoch: 4/10, step 16/574 completed (loss: 0.4525159001350403, acc: 0.7894737124443054)
[2024-11-29 03:12:53,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:53,260][root][INFO] - Training Epoch: 4/10, step 17/574 completed (loss: 0.4584157466888428, acc: 0.8333333134651184)
[2024-11-29 03:12:53,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:53,556][root][INFO] - Training Epoch: 4/10, step 18/574 completed (loss: 1.1703990697860718, acc: 0.6666666865348816)
[2024-11-29 03:12:53,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:53,856][root][INFO] - Training Epoch: 4/10, step 19/574 completed (loss: 0.2299051284790039, acc: 0.9473684430122375)
[2024-11-29 03:12:54,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:54,134][root][INFO] - Training Epoch: 4/10, step 20/574 completed (loss: 0.7250586748123169, acc: 0.8461538553237915)
[2024-11-29 03:12:54,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:54,441][root][INFO] - Training Epoch: 4/10, step 21/574 completed (loss: 0.6497929692268372, acc: 0.7931034564971924)
[2024-11-29 03:12:54,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:54,768][root][INFO] - Training Epoch: 4/10, step 22/574 completed (loss: 0.6715908646583557, acc: 0.8399999737739563)
[2024-11-29 03:12:54,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:55,046][root][INFO] - Training Epoch: 4/10, step 23/574 completed (loss: 1.2172796726226807, acc: 0.761904776096344)
[2024-11-29 03:12:55,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:55,352][root][INFO] - Training Epoch: 4/10, step 24/574 completed (loss: 0.4418354034423828, acc: 0.9375)
[2024-11-29 03:12:55,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:55,707][root][INFO] - Training Epoch: 4/10, step 25/574 completed (loss: 0.9961847066879272, acc: 0.698113203048706)
[2024-11-29 03:12:55,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:55,997][root][INFO] - Training Epoch: 4/10, step 26/574 completed (loss: 0.9978625178337097, acc: 0.7397260069847107)
[2024-11-29 03:12:57,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:57,624][root][INFO] - Training Epoch: 4/10, step 27/574 completed (loss: 1.7332682609558105, acc: 0.5494071245193481)
[2024-11-29 03:12:57,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:57,852][root][INFO] - Training Epoch: 4/10, step 28/574 completed (loss: 0.6396169662475586, acc: 0.8139534592628479)
[2024-11-29 03:12:58,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:58,130][root][INFO] - Training Epoch: 4/10, step 29/574 completed (loss: 1.1222379207611084, acc: 0.6746987700462341)
[2024-11-29 03:12:58,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:58,428][root][INFO] - Training Epoch: 4/10, step 30/574 completed (loss: 1.0467255115509033, acc: 0.7530864477157593)
[2024-11-29 03:12:58,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:58,758][root][INFO] - Training Epoch: 4/10, step 31/574 completed (loss: 0.435259610414505, acc: 0.8571428656578064)
[2024-11-29 03:12:58,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:59,029][root][INFO] - Training Epoch: 4/10, step 32/574 completed (loss: 0.4627557098865509, acc: 0.8518518805503845)
[2024-11-29 03:12:59,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:59,288][root][INFO] - Training Epoch: 4/10, step 33/574 completed (loss: 0.21751435101032257, acc: 0.95652174949646)
[2024-11-29 03:12:59,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:59,570][root][INFO] - Training Epoch: 4/10, step 34/574 completed (loss: 0.8198651075363159, acc: 0.8151260614395142)
[2024-11-29 03:12:59,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:12:59,872][root][INFO] - Training Epoch: 4/10, step 35/574 completed (loss: 0.6606683135032654, acc: 0.8524590134620667)
[2024-11-29 03:13:00,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:00,183][root][INFO] - Training Epoch: 4/10, step 36/574 completed (loss: 0.8587324023246765, acc: 0.7301587462425232)
[2024-11-29 03:13:00,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:00,468][root][INFO] - Training Epoch: 4/10, step 37/574 completed (loss: 0.8009824156761169, acc: 0.7796609997749329)
[2024-11-29 03:13:00,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:00,793][root][INFO] - Training Epoch: 4/10, step 38/574 completed (loss: 0.5389179587364197, acc: 0.8390804529190063)
[2024-11-29 03:13:00,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:01,107][root][INFO] - Training Epoch: 4/10, step 39/574 completed (loss: 0.643057644367218, acc: 0.9047619104385376)
[2024-11-29 03:13:01,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:01,427][root][INFO] - Training Epoch: 4/10, step 40/574 completed (loss: 0.6100833415985107, acc: 0.8846153616905212)
[2024-11-29 03:13:01,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:01,816][root][INFO] - Training Epoch: 4/10, step 41/574 completed (loss: 0.5044074654579163, acc: 0.8783783912658691)
[2024-11-29 03:13:02,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:02,138][root][INFO] - Training Epoch: 4/10, step 42/574 completed (loss: 1.0881954431533813, acc: 0.7076923251152039)
[2024-11-29 03:13:02,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:02,597][root][INFO] - Training Epoch: 4/10, step 43/574 completed (loss: 0.9676799774169922, acc: 0.7676767706871033)
[2024-11-29 03:13:02,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:03,058][root][INFO] - Training Epoch: 4/10, step 44/574 completed (loss: 0.8245548605918884, acc: 0.7731958627700806)
[2024-11-29 03:13:03,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:03,494][root][INFO] - Training Epoch: 4/10, step 45/574 completed (loss: 0.911067008972168, acc: 0.779411792755127)
[2024-11-29 03:13:03,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:03,834][root][INFO] - Training Epoch: 4/10, step 46/574 completed (loss: 0.6812528967857361, acc: 0.807692289352417)
[2024-11-29 03:13:04,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:04,169][root][INFO] - Training Epoch: 4/10, step 47/574 completed (loss: 0.049422916024923325, acc: 1.0)
[2024-11-29 03:13:04,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:04,477][root][INFO] - Training Epoch: 4/10, step 48/574 completed (loss: 0.20715127885341644, acc: 0.9642857313156128)
[2024-11-29 03:13:04,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:04,776][root][INFO] - Training Epoch: 4/10, step 49/574 completed (loss: 0.2550179064273834, acc: 0.9444444179534912)
[2024-11-29 03:13:04,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:05,048][root][INFO] - Training Epoch: 4/10, step 50/574 completed (loss: 0.8361011147499084, acc: 0.8070175647735596)
[2024-11-29 03:13:05,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:05,317][root][INFO] - Training Epoch: 4/10, step 51/574 completed (loss: 1.0281518697738647, acc: 0.682539701461792)
[2024-11-29 03:13:05,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:05,578][root][INFO] - Training Epoch: 4/10, step 52/574 completed (loss: 1.2833760976791382, acc: 0.6619718074798584)
[2024-11-29 03:13:05,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:06,113][root][INFO] - Training Epoch: 4/10, step 53/574 completed (loss: 2.0063316822052, acc: 0.5199999809265137)
[2024-11-29 03:13:06,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:06,460][root][INFO] - Training Epoch: 4/10, step 54/574 completed (loss: 0.8320673108100891, acc: 0.837837815284729)
[2024-11-29 03:13:06,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:06,753][root][INFO] - Training Epoch: 4/10, step 55/574 completed (loss: 0.0988452136516571, acc: 0.9615384340286255)
[2024-11-29 03:13:09,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:10,755][root][INFO] - Training Epoch: 4/10, step 56/574 completed (loss: 1.6879383325576782, acc: 0.5836177468299866)
[2024-11-29 03:13:11,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:12,456][root][INFO] - Training Epoch: 4/10, step 57/574 completed (loss: 1.8580518960952759, acc: 0.5272331237792969)
[2024-11-29 03:13:12,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:13,283][root][INFO] - Training Epoch: 4/10, step 58/574 completed (loss: 1.1115312576293945, acc: 0.7215909361839294)
[2024-11-29 03:13:13,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:14,050][root][INFO] - Training Epoch: 4/10, step 59/574 completed (loss: 0.758273184299469, acc: 0.7867646813392639)
[2024-11-29 03:13:14,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:14,791][root][INFO] - Training Epoch: 4/10, step 60/574 completed (loss: 1.0582671165466309, acc: 0.695652186870575)
[2024-11-29 03:13:15,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:15,273][root][INFO] - Training Epoch: 4/10, step 61/574 completed (loss: 1.1975001096725464, acc: 0.675000011920929)
[2024-11-29 03:13:15,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:15,548][root][INFO] - Training Epoch: 4/10, step 62/574 completed (loss: 0.3761323094367981, acc: 0.8823529481887817)
[2024-11-29 03:13:15,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:15,886][root][INFO] - Training Epoch: 4/10, step 63/574 completed (loss: 0.31758400797843933, acc: 0.8888888955116272)
[2024-11-29 03:13:16,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:16,235][root][INFO] - Training Epoch: 4/10, step 64/574 completed (loss: 0.3343241810798645, acc: 0.90625)
[2024-11-29 03:13:16,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:16,509][root][INFO] - Training Epoch: 4/10, step 65/574 completed (loss: 0.2121197134256363, acc: 0.931034505367279)
[2024-11-29 03:13:16,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:16,806][root][INFO] - Training Epoch: 4/10, step 66/574 completed (loss: 1.0359934568405151, acc: 0.75)
[2024-11-29 03:13:17,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:17,145][root][INFO] - Training Epoch: 4/10, step 67/574 completed (loss: 0.7646421790122986, acc: 0.8166666626930237)
[2024-11-29 03:13:17,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:17,449][root][INFO] - Training Epoch: 4/10, step 68/574 completed (loss: 0.09829414635896683, acc: 1.0)
[2024-11-29 03:13:17,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:17,745][root][INFO] - Training Epoch: 4/10, step 69/574 completed (loss: 1.0087602138519287, acc: 0.6944444179534912)
[2024-11-29 03:13:17,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:18,041][root][INFO] - Training Epoch: 4/10, step 70/574 completed (loss: 0.8723796606063843, acc: 0.7272727489471436)
[2024-11-29 03:13:18,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:18,350][root][INFO] - Training Epoch: 4/10, step 71/574 completed (loss: 1.5258122682571411, acc: 0.6029411554336548)
[2024-11-29 03:13:18,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:18,623][root][INFO] - Training Epoch: 4/10, step 72/574 completed (loss: 0.9970335364341736, acc: 0.7222222089767456)
[2024-11-29 03:13:18,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:18,988][root][INFO] - Training Epoch: 4/10, step 73/574 completed (loss: 1.850716471672058, acc: 0.5384615659713745)
[2024-11-29 03:13:19,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:19,313][root][INFO] - Training Epoch: 4/10, step 74/574 completed (loss: 1.6773803234100342, acc: 0.6020408272743225)
[2024-11-29 03:13:19,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:19,624][root][INFO] - Training Epoch: 4/10, step 75/574 completed (loss: 1.3425310850143433, acc: 0.611940324306488)
[2024-11-29 03:13:19,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:20,029][root][INFO] - Training Epoch: 4/10, step 76/574 completed (loss: 1.8844339847564697, acc: 0.5182482004165649)
[2024-11-29 03:13:20,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:20,313][root][INFO] - Training Epoch: 4/10, step 77/574 completed (loss: 0.03793312981724739, acc: 1.0)
[2024-11-29 03:13:20,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:20,604][root][INFO] - Training Epoch: 4/10, step 78/574 completed (loss: 0.1563233882188797, acc: 0.9583333134651184)
[2024-11-29 03:13:20,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:20,862][root][INFO] - Training Epoch: 4/10, step 79/574 completed (loss: 0.11474646627902985, acc: 0.9696969985961914)
[2024-11-29 03:13:21,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:21,174][root][INFO] - Training Epoch: 4/10, step 80/574 completed (loss: 0.10076414793729782, acc: 0.9615384340286255)
[2024-11-29 03:13:21,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:21,488][root][INFO] - Training Epoch: 4/10, step 81/574 completed (loss: 0.6042734384536743, acc: 0.8461538553237915)
[2024-11-29 03:13:21,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:21,824][root][INFO] - Training Epoch: 4/10, step 82/574 completed (loss: 1.0402098894119263, acc: 0.7115384340286255)
[2024-11-29 03:13:21,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:22,106][root][INFO] - Training Epoch: 4/10, step 83/574 completed (loss: 0.28042495250701904, acc: 0.90625)
[2024-11-29 03:13:22,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:22,421][root][INFO] - Training Epoch: 4/10, step 84/574 completed (loss: 0.7209347486495972, acc: 0.7971014380455017)
[2024-11-29 03:13:22,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:22,747][root][INFO] - Training Epoch: 4/10, step 85/574 completed (loss: 0.8114721775054932, acc: 0.8199999928474426)
[2024-11-29 03:13:22,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:23,024][root][INFO] - Training Epoch: 4/10, step 86/574 completed (loss: 0.21562518179416656, acc: 0.95652174949646)
[2024-11-29 03:13:23,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:23,588][root][INFO] - Training Epoch: 4/10, step 87/574 completed (loss: 1.219894289970398, acc: 0.699999988079071)
[2024-11-29 03:13:23,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:23,925][root][INFO] - Training Epoch: 4/10, step 88/574 completed (loss: 1.2214293479919434, acc: 0.6699029207229614)
[2024-11-29 03:13:24,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:25,549][root][INFO] - Training Epoch: 4/10, step 89/574 completed (loss: 1.2660847902297974, acc: 0.6747573018074036)
[2024-11-29 03:13:26,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:26,702][root][INFO] - Training Epoch: 4/10, step 90/574 completed (loss: 1.72394859790802, acc: 0.5591397881507874)
[2024-11-29 03:13:27,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:27,826][root][INFO] - Training Epoch: 4/10, step 91/574 completed (loss: 1.350918173789978, acc: 0.6508620977401733)
[2024-11-29 03:13:28,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:28,872][root][INFO] - Training Epoch: 4/10, step 92/574 completed (loss: 1.1520389318466187, acc: 0.7052631378173828)
[2024-11-29 03:13:29,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:30,330][root][INFO] - Training Epoch: 4/10, step 93/574 completed (loss: 1.934032678604126, acc: 0.49504950642585754)
[2024-11-29 03:13:30,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:30,659][root][INFO] - Training Epoch: 4/10, step 94/574 completed (loss: 1.3508763313293457, acc: 0.5645161271095276)
[2024-11-29 03:13:30,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:30,976][root][INFO] - Training Epoch: 4/10, step 95/574 completed (loss: 1.0075706243515015, acc: 0.7246376872062683)
[2024-11-29 03:13:31,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:31,338][root][INFO] - Training Epoch: 4/10, step 96/574 completed (loss: 1.5978697538375854, acc: 0.5210084319114685)
[2024-11-29 03:13:31,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:31,688][root][INFO] - Training Epoch: 4/10, step 97/574 completed (loss: 1.8028483390808105, acc: 0.4615384638309479)
[2024-11-29 03:13:31,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:32,100][root][INFO] - Training Epoch: 4/10, step 98/574 completed (loss: 1.8507277965545654, acc: 0.49635037779808044)
[2024-11-29 03:13:32,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:32,413][root][INFO] - Training Epoch: 4/10, step 99/574 completed (loss: 1.6436939239501953, acc: 0.611940324306488)
[2024-11-29 03:13:32,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:32,702][root][INFO] - Training Epoch: 4/10, step 100/574 completed (loss: 0.6048034429550171, acc: 0.800000011920929)
[2024-11-29 03:13:32,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:32,976][root][INFO] - Training Epoch: 4/10, step 101/574 completed (loss: 0.06495801359415054, acc: 1.0)
[2024-11-29 03:13:33,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:33,230][root][INFO] - Training Epoch: 4/10, step 102/574 completed (loss: 0.07985793054103851, acc: 1.0)
[2024-11-29 03:13:33,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:33,510][root][INFO] - Training Epoch: 4/10, step 103/574 completed (loss: 0.08196239173412323, acc: 1.0)
[2024-11-29 03:13:33,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:33,816][root][INFO] - Training Epoch: 4/10, step 104/574 completed (loss: 0.6785528659820557, acc: 0.8275862336158752)
[2024-11-29 03:13:33,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:34,105][root][INFO] - Training Epoch: 4/10, step 105/574 completed (loss: 0.260252982378006, acc: 0.8837209343910217)
[2024-11-29 03:13:34,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:34,392][root][INFO] - Training Epoch: 4/10, step 106/574 completed (loss: 0.24610471725463867, acc: 0.9200000166893005)
[2024-11-29 03:13:34,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:34,676][root][INFO] - Training Epoch: 4/10, step 107/574 completed (loss: 0.0695853903889656, acc: 0.9411764740943909)
[2024-11-29 03:13:34,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:34,986][root][INFO] - Training Epoch: 4/10, step 108/574 completed (loss: 0.019993038848042488, acc: 1.0)
[2024-11-29 03:13:35,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:35,267][root][INFO] - Training Epoch: 4/10, step 109/574 completed (loss: 0.35174402594566345, acc: 0.9047619104385376)
[2024-11-29 03:13:35,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:35,570][root][INFO] - Training Epoch: 4/10, step 110/574 completed (loss: 0.32114696502685547, acc: 0.892307698726654)
[2024-11-29 03:13:35,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:36,020][root][INFO] - Training Epoch: 4/10, step 111/574 completed (loss: 0.671414852142334, acc: 0.7894737124443054)
[2024-11-29 03:13:36,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:36,356][root][INFO] - Training Epoch: 4/10, step 112/574 completed (loss: 0.9784665703773499, acc: 0.7543859481811523)
[2024-11-29 03:13:36,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:36,632][root][INFO] - Training Epoch: 4/10, step 113/574 completed (loss: 0.5336312055587769, acc: 0.8974359035491943)
[2024-11-29 03:13:36,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:36,997][root][INFO] - Training Epoch: 4/10, step 114/574 completed (loss: 0.3215472996234894, acc: 0.8979591727256775)
[2024-11-29 03:13:37,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:37,275][root][INFO] - Training Epoch: 4/10, step 115/574 completed (loss: 0.21070121228694916, acc: 0.9545454382896423)
[2024-11-29 03:13:37,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:37,575][root][INFO] - Training Epoch: 4/10, step 116/574 completed (loss: 0.8716845512390137, acc: 0.7936508059501648)
[2024-11-29 03:13:37,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:37,918][root][INFO] - Training Epoch: 4/10, step 117/574 completed (loss: 0.7939490079879761, acc: 0.7886179089546204)
[2024-11-29 03:13:38,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:38,267][root][INFO] - Training Epoch: 4/10, step 118/574 completed (loss: 0.41244760155677795, acc: 0.8870967626571655)
[2024-11-29 03:13:38,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:39,422][root][INFO] - Training Epoch: 4/10, step 119/574 completed (loss: 1.3303369283676147, acc: 0.6159695982933044)
[2024-11-29 03:13:39,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:39,745][root][INFO] - Training Epoch: 4/10, step 120/574 completed (loss: 0.732404887676239, acc: 0.800000011920929)
[2024-11-29 03:13:39,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:40,199][root][INFO] - Training Epoch: 4/10, step 121/574 completed (loss: 0.6555280089378357, acc: 0.807692289352417)
[2024-11-29 03:13:40,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:40,465][root][INFO] - Training Epoch: 4/10, step 122/574 completed (loss: 0.27222248911857605, acc: 0.9583333134651184)
[2024-11-29 03:13:40,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:40,717][root][INFO] - Training Epoch: 4/10, step 123/574 completed (loss: 0.5779873132705688, acc: 0.8421052694320679)
[2024-11-29 03:13:40,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:41,051][root][INFO] - Training Epoch: 4/10, step 124/574 completed (loss: 1.8247909545898438, acc: 0.546012282371521)
[2024-11-29 03:13:41,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:41,392][root][INFO] - Training Epoch: 4/10, step 125/574 completed (loss: 1.651455283164978, acc: 0.5625)
[2024-11-29 03:13:41,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:41,668][root][INFO] - Training Epoch: 4/10, step 126/574 completed (loss: 1.5145342350006104, acc: 0.6083333492279053)
[2024-11-29 03:13:41,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:41,983][root][INFO] - Training Epoch: 4/10, step 127/574 completed (loss: 1.7102559804916382, acc: 0.5476190447807312)
[2024-11-29 03:13:42,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:42,297][root][INFO] - Training Epoch: 4/10, step 128/574 completed (loss: 1.2873973846435547, acc: 0.656410276889801)
[2024-11-29 03:13:42,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:42,745][root][INFO] - Training Epoch: 4/10, step 129/574 completed (loss: 1.6265769004821777, acc: 0.5882353186607361)
[2024-11-29 03:13:42,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:43,046][root][INFO] - Training Epoch: 4/10, step 130/574 completed (loss: 1.0773555040359497, acc: 0.807692289352417)
[2024-11-29 03:13:43,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:43,345][root][INFO] - Training Epoch: 4/10, step 131/574 completed (loss: 0.9352794885635376, acc: 0.739130437374115)
[2024-11-29 03:13:43,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:43,576][root][INFO] - Training Epoch: 4/10, step 132/574 completed (loss: 1.6327581405639648, acc: 0.625)
[2024-11-29 03:13:43,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:43,871][root][INFO] - Training Epoch: 4/10, step 133/574 completed (loss: 0.8607816100120544, acc: 0.8260869383811951)
[2024-11-29 03:13:44,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:44,145][root][INFO] - Training Epoch: 4/10, step 134/574 completed (loss: 0.8736646771430969, acc: 0.7428571581840515)
[2024-11-29 03:13:44,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:44,454][root][INFO] - Training Epoch: 4/10, step 135/574 completed (loss: 0.8070036768913269, acc: 0.7692307829856873)
[2024-11-29 03:13:44,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:44,760][root][INFO] - Training Epoch: 4/10, step 136/574 completed (loss: 0.896729052066803, acc: 0.8095238208770752)
[2024-11-29 03:13:45,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:46,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:46,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:47,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:47,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:47,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:48,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:48,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:49,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:49,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:50,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:50,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:50,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:51,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:51,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:52,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:52,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:53,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:53,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:54,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:54,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:55,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:55,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:55,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:56,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:56,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:56,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:57,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:57,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:57,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:58,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:59,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:59,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:13:59,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:00,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:00,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:01,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:01,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:01,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:02,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:02,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:03,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:03,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:04,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:04,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:05,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:05,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:06,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:06,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:06,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:07,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:07,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:08,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:08,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:08,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:09,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:09,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:09,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:10,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:10,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:11,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:11,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:12,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:12,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:13,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:13,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:13,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:14,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:15,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:15,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:16,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:16,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:16,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:17,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:17,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:17,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:18,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:18,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:19,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:19,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:19,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:20,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:20,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:21,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:21,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:22,236][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.9822, device='cuda:0') eval_epoch_loss=tensor(1.0927, device='cuda:0') eval_epoch_acc=tensor(0.7241, device='cuda:0')
[2024-11-29 03:14:22,237][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:14:22,238][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:14:22,508][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_4_step_137_loss_1.0926706790924072/model.pt
[2024-11-29 03:14:22,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:22,790][root][INFO] - Training Epoch: 4/10, step 137/574 completed (loss: 1.3292338848114014, acc: 0.6000000238418579)
[2024-11-29 03:14:22,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:23,036][root][INFO] - Training Epoch: 4/10, step 138/574 completed (loss: 0.4887230396270752, acc: 0.8695651888847351)
[2024-11-29 03:14:23,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:23,293][root][INFO] - Training Epoch: 4/10, step 139/574 completed (loss: 0.32186490297317505, acc: 0.9523809552192688)
[2024-11-29 03:14:23,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:23,619][root][INFO] - Training Epoch: 4/10, step 140/574 completed (loss: 0.15128932893276215, acc: 1.0)
[2024-11-29 03:14:23,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:23,928][root][INFO] - Training Epoch: 4/10, step 141/574 completed (loss: 0.8534793853759766, acc: 0.8064516186714172)
[2024-11-29 03:14:24,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:24,191][root][INFO] - Training Epoch: 4/10, step 142/574 completed (loss: 0.8093832731246948, acc: 0.7027027010917664)
[2024-11-29 03:14:24,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:24,897][root][INFO] - Training Epoch: 4/10, step 143/574 completed (loss: 1.081888198852539, acc: 0.6666666865348816)
[2024-11-29 03:14:25,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:25,255][root][INFO] - Training Epoch: 4/10, step 144/574 completed (loss: 1.1077378988265991, acc: 0.6641790866851807)
[2024-11-29 03:14:25,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:25,618][root][INFO] - Training Epoch: 4/10, step 145/574 completed (loss: 0.8830858469009399, acc: 0.7653061151504517)
[2024-11-29 03:14:25,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:26,168][root][INFO] - Training Epoch: 4/10, step 146/574 completed (loss: 1.2024765014648438, acc: 0.585106372833252)
[2024-11-29 03:14:26,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:26,425][root][INFO] - Training Epoch: 4/10, step 147/574 completed (loss: 0.8558944463729858, acc: 0.7428571581840515)
[2024-11-29 03:14:26,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:26,716][root][INFO] - Training Epoch: 4/10, step 148/574 completed (loss: 0.6019473075866699, acc: 0.7857142686843872)
[2024-11-29 03:14:26,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:27,026][root][INFO] - Training Epoch: 4/10, step 149/574 completed (loss: 0.750931441783905, acc: 0.782608687877655)
[2024-11-29 03:14:27,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:27,322][root][INFO] - Training Epoch: 4/10, step 150/574 completed (loss: 0.9817218780517578, acc: 0.7241379022598267)
[2024-11-29 03:14:27,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:27,644][root][INFO] - Training Epoch: 4/10, step 151/574 completed (loss: 1.0276787281036377, acc: 0.717391312122345)
[2024-11-29 03:14:27,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:27,957][root][INFO] - Training Epoch: 4/10, step 152/574 completed (loss: 0.9607763290405273, acc: 0.7288135886192322)
[2024-11-29 03:14:28,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:28,229][root][INFO] - Training Epoch: 4/10, step 153/574 completed (loss: 1.3570501804351807, acc: 0.6666666865348816)
[2024-11-29 03:14:28,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:28,553][root][INFO] - Training Epoch: 4/10, step 154/574 completed (loss: 0.9561858177185059, acc: 0.7702702879905701)
[2024-11-29 03:14:28,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:28,834][root][INFO] - Training Epoch: 4/10, step 155/574 completed (loss: 0.3053077757358551, acc: 0.9285714030265808)
[2024-11-29 03:14:29,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:29,177][root][INFO] - Training Epoch: 4/10, step 156/574 completed (loss: 0.5556410551071167, acc: 0.8695651888847351)
[2024-11-29 03:14:29,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:29,525][root][INFO] - Training Epoch: 4/10, step 157/574 completed (loss: 3.3686158657073975, acc: 0.2631579041481018)
[2024-11-29 03:14:31,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:32,105][root][INFO] - Training Epoch: 4/10, step 158/574 completed (loss: 1.728400707244873, acc: 0.5945945978164673)
[2024-11-29 03:14:32,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:32,415][root][INFO] - Training Epoch: 4/10, step 159/574 completed (loss: 1.8313080072402954, acc: 0.5925925970077515)
[2024-11-29 03:14:32,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:32,886][root][INFO] - Training Epoch: 4/10, step 160/574 completed (loss: 2.05419921875, acc: 0.5)
[2024-11-29 03:14:33,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:33,708][root][INFO] - Training Epoch: 4/10, step 161/574 completed (loss: 2.364377498626709, acc: 0.38823530077934265)
[2024-11-29 03:14:34,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:34,466][root][INFO] - Training Epoch: 4/10, step 162/574 completed (loss: 1.9096146821975708, acc: 0.5280898809432983)
[2024-11-29 03:14:34,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:34,774][root][INFO] - Training Epoch: 4/10, step 163/574 completed (loss: 0.5369887948036194, acc: 0.8181818127632141)
[2024-11-29 03:14:34,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:35,099][root][INFO] - Training Epoch: 4/10, step 164/574 completed (loss: 0.5670136213302612, acc: 0.8571428656578064)
[2024-11-29 03:14:35,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:35,428][root][INFO] - Training Epoch: 4/10, step 165/574 completed (loss: 1.7887095212936401, acc: 0.5862069129943848)
[2024-11-29 03:14:35,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:35,800][root][INFO] - Training Epoch: 4/10, step 166/574 completed (loss: 0.3325441777706146, acc: 0.8979591727256775)
[2024-11-29 03:14:35,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:36,118][root][INFO] - Training Epoch: 4/10, step 167/574 completed (loss: 0.5265902280807495, acc: 0.8600000143051147)
[2024-11-29 03:14:36,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:36,570][root][INFO] - Training Epoch: 4/10, step 168/574 completed (loss: 0.5842034816741943, acc: 0.8472222089767456)
[2024-11-29 03:14:36,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:36,888][root][INFO] - Training Epoch: 4/10, step 169/574 completed (loss: 1.4607243537902832, acc: 0.6666666865348816)
[2024-11-29 03:14:37,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:38,431][root][INFO] - Training Epoch: 4/10, step 170/574 completed (loss: 1.740701675415039, acc: 0.5958904027938843)
[2024-11-29 03:14:38,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:38,746][root][INFO] - Training Epoch: 4/10, step 171/574 completed (loss: 0.35899925231933594, acc: 0.875)
[2024-11-29 03:14:38,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:39,077][root][INFO] - Training Epoch: 4/10, step 172/574 completed (loss: 1.1940512657165527, acc: 0.6666666865348816)
[2024-11-29 03:14:39,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:39,347][root][INFO] - Training Epoch: 4/10, step 173/574 completed (loss: 0.5316274166107178, acc: 0.8571428656578064)
[2024-11-29 03:14:39,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:40,077][root][INFO] - Training Epoch: 4/10, step 174/574 completed (loss: 1.54408597946167, acc: 0.6283186078071594)
[2024-11-29 03:14:40,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:40,360][root][INFO] - Training Epoch: 4/10, step 175/574 completed (loss: 1.1959165334701538, acc: 0.7246376872062683)
[2024-11-29 03:14:40,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:40,704][root][INFO] - Training Epoch: 4/10, step 176/574 completed (loss: 0.6410604119300842, acc: 0.7727272510528564)
[2024-11-29 03:14:41,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:42,105][root][INFO] - Training Epoch: 4/10, step 177/574 completed (loss: 1.687129259109497, acc: 0.5572519302368164)
[2024-11-29 03:14:42,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:43,049][root][INFO] - Training Epoch: 4/10, step 178/574 completed (loss: 1.365060806274414, acc: 0.6518518328666687)
[2024-11-29 03:14:43,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:43,318][root][INFO] - Training Epoch: 4/10, step 179/574 completed (loss: 0.6375158429145813, acc: 0.8196721076965332)
[2024-11-29 03:14:43,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:43,613][root][INFO] - Training Epoch: 4/10, step 180/574 completed (loss: 0.06278499960899353, acc: 1.0)
[2024-11-29 03:14:43,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:43,911][root][INFO] - Training Epoch: 4/10, step 181/574 completed (loss: 0.1380707025527954, acc: 0.9200000166893005)
[2024-11-29 03:14:44,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:44,225][root][INFO] - Training Epoch: 4/10, step 182/574 completed (loss: 0.10733548551797867, acc: 1.0)
[2024-11-29 03:14:44,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:44,549][root][INFO] - Training Epoch: 4/10, step 183/574 completed (loss: 0.34803953766822815, acc: 0.8780487775802612)
[2024-11-29 03:14:44,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:44,915][root][INFO] - Training Epoch: 4/10, step 184/574 completed (loss: 0.9323644638061523, acc: 0.791540801525116)
[2024-11-29 03:14:45,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:45,274][root][INFO] - Training Epoch: 4/10, step 185/574 completed (loss: 1.0736587047576904, acc: 0.7060518860816956)
[2024-11-29 03:14:45,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:45,880][root][INFO] - Training Epoch: 4/10, step 186/574 completed (loss: 1.1676706075668335, acc: 0.690625011920929)
[2024-11-29 03:14:46,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:46,521][root][INFO] - Training Epoch: 4/10, step 187/574 completed (loss: 1.2850180864334106, acc: 0.6885553598403931)
[2024-11-29 03:14:46,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:46,968][root][INFO] - Training Epoch: 4/10, step 188/574 completed (loss: 0.9949715733528137, acc: 0.7330960631370544)
[2024-11-29 03:14:47,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:47,275][root][INFO] - Training Epoch: 4/10, step 189/574 completed (loss: 0.5624786615371704, acc: 0.8799999952316284)
[2024-11-29 03:14:47,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:48,038][root][INFO] - Training Epoch: 4/10, step 190/574 completed (loss: 1.1075999736785889, acc: 0.6744186282157898)
[2024-11-29 03:14:48,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:49,229][root][INFO] - Training Epoch: 4/10, step 191/574 completed (loss: 1.605912446975708, acc: 0.5714285969734192)
[2024-11-29 03:14:50,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:50,608][root][INFO] - Training Epoch: 4/10, step 192/574 completed (loss: 1.6184154748916626, acc: 0.5378788113594055)
[2024-11-29 03:14:51,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:51,701][root][INFO] - Training Epoch: 4/10, step 193/574 completed (loss: 0.9489213824272156, acc: 0.7411764860153198)
[2024-11-29 03:14:52,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:53,348][root][INFO] - Training Epoch: 4/10, step 194/574 completed (loss: 1.5084024667739868, acc: 0.604938268661499)
[2024-11-29 03:14:54,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:54,786][root][INFO] - Training Epoch: 4/10, step 195/574 completed (loss: 0.7635860443115234, acc: 0.774193525314331)
[2024-11-29 03:14:54,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:55,100][root][INFO] - Training Epoch: 4/10, step 196/574 completed (loss: 0.11055725812911987, acc: 0.9642857313156128)
[2024-11-29 03:14:55,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:55,372][root][INFO] - Training Epoch: 4/10, step 197/574 completed (loss: 1.310288906097412, acc: 0.699999988079071)
[2024-11-29 03:14:55,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:55,709][root][INFO] - Training Epoch: 4/10, step 198/574 completed (loss: 1.0682624578475952, acc: 0.6911764740943909)
[2024-11-29 03:14:55,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:56,018][root][INFO] - Training Epoch: 4/10, step 199/574 completed (loss: 1.4650219678878784, acc: 0.6691176295280457)
[2024-11-29 03:14:56,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:56,352][root][INFO] - Training Epoch: 4/10, step 200/574 completed (loss: 1.1706446409225464, acc: 0.6440678238868713)
[2024-11-29 03:14:56,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:56,674][root][INFO] - Training Epoch: 4/10, step 201/574 completed (loss: 1.268102765083313, acc: 0.6716417670249939)
[2024-11-29 03:14:56,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:57,013][root][INFO] - Training Epoch: 4/10, step 202/574 completed (loss: 1.0606651306152344, acc: 0.6796116232872009)
[2024-11-29 03:14:57,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:57,284][root][INFO] - Training Epoch: 4/10, step 203/574 completed (loss: 0.8268948197364807, acc: 0.7460317611694336)
[2024-11-29 03:14:57,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:57,574][root][INFO] - Training Epoch: 4/10, step 204/574 completed (loss: 0.37948450446128845, acc: 0.8791208863258362)
[2024-11-29 03:14:57,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:57,929][root][INFO] - Training Epoch: 4/10, step 205/574 completed (loss: 0.7240460515022278, acc: 0.7982062697410583)
[2024-11-29 03:14:58,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:58,366][root][INFO] - Training Epoch: 4/10, step 206/574 completed (loss: 0.8421177864074707, acc: 0.7440944910049438)
[2024-11-29 03:14:58,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:58,672][root][INFO] - Training Epoch: 4/10, step 207/574 completed (loss: 0.612064003944397, acc: 0.8362069129943848)
[2024-11-29 03:14:58,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:59,032][root][INFO] - Training Epoch: 4/10, step 208/574 completed (loss: 0.7099829316139221, acc: 0.8152173757553101)
[2024-11-29 03:14:59,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:59,419][root][INFO] - Training Epoch: 4/10, step 209/574 completed (loss: 0.7678307890892029, acc: 0.7859922051429749)
[2024-11-29 03:14:59,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:14:59,750][root][INFO] - Training Epoch: 4/10, step 210/574 completed (loss: 0.6094988584518433, acc: 0.8369565010070801)
[2024-11-29 03:14:59,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:00,014][root][INFO] - Training Epoch: 4/10, step 211/574 completed (loss: 0.27382323145866394, acc: 0.8260869383811951)
[2024-11-29 03:15:00,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:00,335][root][INFO] - Training Epoch: 4/10, step 212/574 completed (loss: 0.45554766058921814, acc: 0.8928571343421936)
[2024-11-29 03:15:00,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:00,643][root][INFO] - Training Epoch: 4/10, step 213/574 completed (loss: 0.6490288972854614, acc: 0.8297872543334961)
[2024-11-29 03:15:01,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:01,615][root][INFO] - Training Epoch: 4/10, step 214/574 completed (loss: 0.519305408000946, acc: 0.8769230842590332)
[2024-11-29 03:15:01,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:01,957][root][INFO] - Training Epoch: 4/10, step 215/574 completed (loss: 0.40135830640792847, acc: 0.8783783912658691)
[2024-11-29 03:15:02,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:02,306][root][INFO] - Training Epoch: 4/10, step 216/574 completed (loss: 0.2771345376968384, acc: 0.9186046719551086)
[2024-11-29 03:15:02,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:03,023][root][INFO] - Training Epoch: 4/10, step 217/574 completed (loss: 0.42253902554512024, acc: 0.9009009003639221)
[2024-11-29 03:15:03,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:03,471][root][INFO] - Training Epoch: 4/10, step 218/574 completed (loss: 0.3847671151161194, acc: 0.8999999761581421)
[2024-11-29 03:15:03,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:03,789][root][INFO] - Training Epoch: 4/10, step 219/574 completed (loss: 0.12655557692050934, acc: 1.0)
[2024-11-29 03:15:03,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:04,049][root][INFO] - Training Epoch: 4/10, step 220/574 completed (loss: 0.1403394639492035, acc: 0.9259259104728699)
[2024-11-29 03:15:04,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:04,348][root][INFO] - Training Epoch: 4/10, step 221/574 completed (loss: 0.06919267028570175, acc: 1.0)
[2024-11-29 03:15:04,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:04,678][root][INFO] - Training Epoch: 4/10, step 222/574 completed (loss: 0.888816773891449, acc: 0.7307692170143127)
[2024-11-29 03:15:05,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:05,774][root][INFO] - Training Epoch: 4/10, step 223/574 completed (loss: 0.9042786955833435, acc: 0.7880434989929199)
[2024-11-29 03:15:06,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:06,495][root][INFO] - Training Epoch: 4/10, step 224/574 completed (loss: 1.2064615488052368, acc: 0.7045454382896423)
[2024-11-29 03:15:06,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:07,035][root][INFO] - Training Epoch: 4/10, step 225/574 completed (loss: 1.0388416051864624, acc: 0.7553191781044006)
[2024-11-29 03:15:07,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:07,384][root][INFO] - Training Epoch: 4/10, step 226/574 completed (loss: 0.6122644543647766, acc: 0.8301886916160583)
[2024-11-29 03:15:07,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:07,728][root][INFO] - Training Epoch: 4/10, step 227/574 completed (loss: 0.3306889832019806, acc: 0.9166666865348816)
[2024-11-29 03:15:07,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:08,038][root][INFO] - Training Epoch: 4/10, step 228/574 completed (loss: 0.8703611493110657, acc: 0.7906976938247681)
[2024-11-29 03:15:08,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:08,337][root][INFO] - Training Epoch: 4/10, step 229/574 completed (loss: 2.005511999130249, acc: 0.46666666865348816)
[2024-11-29 03:15:08,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:08,712][root][INFO] - Training Epoch: 4/10, step 230/574 completed (loss: 2.7686100006103516, acc: 0.35789474844932556)
[2024-11-29 03:15:08,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:09,063][root][INFO] - Training Epoch: 4/10, step 231/574 completed (loss: 2.067105293273926, acc: 0.4555555582046509)
[2024-11-29 03:15:09,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:09,570][root][INFO] - Training Epoch: 4/10, step 232/574 completed (loss: 2.0709633827209473, acc: 0.49444442987442017)
[2024-11-29 03:15:09,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:10,199][root][INFO] - Training Epoch: 4/10, step 233/574 completed (loss: 2.406681537628174, acc: 0.39449542760849)
[2024-11-29 03:15:10,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:10,805][root][INFO] - Training Epoch: 4/10, step 234/574 completed (loss: 2.210524082183838, acc: 0.4384615421295166)
[2024-11-29 03:15:10,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:11,113][root][INFO] - Training Epoch: 4/10, step 235/574 completed (loss: 0.11126435548067093, acc: 0.9473684430122375)
[2024-11-29 03:15:11,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:11,456][root][INFO] - Training Epoch: 4/10, step 236/574 completed (loss: 0.2357458919286728, acc: 0.9166666865348816)
[2024-11-29 03:15:11,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:11,786][root][INFO] - Training Epoch: 4/10, step 237/574 completed (loss: 0.6040492653846741, acc: 0.8636363744735718)
[2024-11-29 03:15:11,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:12,104][root][INFO] - Training Epoch: 4/10, step 238/574 completed (loss: 0.9240579009056091, acc: 0.7777777910232544)
[2024-11-29 03:15:12,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:12,423][root][INFO] - Training Epoch: 4/10, step 239/574 completed (loss: 0.8736004829406738, acc: 0.7714285850524902)
[2024-11-29 03:15:12,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:12,784][root][INFO] - Training Epoch: 4/10, step 240/574 completed (loss: 1.2402734756469727, acc: 0.75)
[2024-11-29 03:15:12,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:13,085][root][INFO] - Training Epoch: 4/10, step 241/574 completed (loss: 0.653451681137085, acc: 0.7272727489471436)
[2024-11-29 03:15:13,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:13,891][root][INFO] - Training Epoch: 4/10, step 242/574 completed (loss: 1.6350882053375244, acc: 0.5483871102333069)
[2024-11-29 03:15:14,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:14,618][root][INFO] - Training Epoch: 4/10, step 243/574 completed (loss: 0.8930212259292603, acc: 0.7272727489471436)
[2024-11-29 03:15:14,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:14,887][root][INFO] - Training Epoch: 4/10, step 244/574 completed (loss: 0.0651562437415123, acc: 1.0)
[2024-11-29 03:15:15,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:15,156][root][INFO] - Training Epoch: 4/10, step 245/574 completed (loss: 0.9361697435379028, acc: 0.807692289352417)
[2024-11-29 03:15:15,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:15,435][root][INFO] - Training Epoch: 4/10, step 246/574 completed (loss: 0.2433798462152481, acc: 0.9032257795333862)
[2024-11-29 03:15:15,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:15,728][root][INFO] - Training Epoch: 4/10, step 247/574 completed (loss: 0.32683682441711426, acc: 0.949999988079071)
[2024-11-29 03:15:15,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:16,086][root][INFO] - Training Epoch: 4/10, step 248/574 completed (loss: 0.7387367486953735, acc: 0.837837815284729)
[2024-11-29 03:15:16,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:16,413][root][INFO] - Training Epoch: 4/10, step 249/574 completed (loss: 0.7968177795410156, acc: 0.7567567825317383)
[2024-11-29 03:15:16,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:16,721][root][INFO] - Training Epoch: 4/10, step 250/574 completed (loss: 0.16379913687705994, acc: 0.9729729890823364)
[2024-11-29 03:15:16,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:17,038][root][INFO] - Training Epoch: 4/10, step 251/574 completed (loss: 0.47186970710754395, acc: 0.8676470518112183)
[2024-11-29 03:15:17,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:17,307][root][INFO] - Training Epoch: 4/10, step 252/574 completed (loss: 0.2753729820251465, acc: 0.9268292784690857)
[2024-11-29 03:15:17,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:17,594][root][INFO] - Training Epoch: 4/10, step 253/574 completed (loss: 0.09455398470163345, acc: 1.0)
[2024-11-29 03:15:17,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:17,920][root][INFO] - Training Epoch: 4/10, step 254/574 completed (loss: 0.01764059066772461, acc: 1.0)
[2024-11-29 03:15:18,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:18,232][root][INFO] - Training Epoch: 4/10, step 255/574 completed (loss: 0.1915421485900879, acc: 0.9354838728904724)
[2024-11-29 03:15:18,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:18,534][root][INFO] - Training Epoch: 4/10, step 256/574 completed (loss: 0.504672110080719, acc: 0.9298245906829834)
[2024-11-29 03:15:18,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:18,792][root][INFO] - Training Epoch: 4/10, step 257/574 completed (loss: 0.5435774326324463, acc: 0.8714285492897034)
[2024-11-29 03:15:18,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:19,103][root][INFO] - Training Epoch: 4/10, step 258/574 completed (loss: 0.22122111916542053, acc: 0.9342105388641357)
[2024-11-29 03:15:19,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:19,861][root][INFO] - Training Epoch: 4/10, step 259/574 completed (loss: 0.7272946238517761, acc: 0.8207547068595886)
[2024-11-29 03:15:20,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:20,648][root][INFO] - Training Epoch: 4/10, step 260/574 completed (loss: 0.785429835319519, acc: 0.7583333253860474)
[2024-11-29 03:15:20,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:20,895][root][INFO] - Training Epoch: 4/10, step 261/574 completed (loss: 0.14027339220046997, acc: 0.9722222089767456)
[2024-11-29 03:15:21,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:21,182][root][INFO] - Training Epoch: 4/10, step 262/574 completed (loss: 0.5686782598495483, acc: 0.8064516186714172)
[2024-11-29 03:15:21,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:21,528][root][INFO] - Training Epoch: 4/10, step 263/574 completed (loss: 1.541165828704834, acc: 0.653333306312561)
[2024-11-29 03:15:21,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:21,804][root][INFO] - Training Epoch: 4/10, step 264/574 completed (loss: 1.0332468748092651, acc: 0.6666666865348816)
[2024-11-29 03:15:22,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:23,016][root][INFO] - Training Epoch: 4/10, step 265/574 completed (loss: 1.6391706466674805, acc: 0.5759999752044678)
[2024-11-29 03:15:23,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:23,323][root][INFO] - Training Epoch: 4/10, step 266/574 completed (loss: 1.3252830505371094, acc: 0.584269642829895)
[2024-11-29 03:15:23,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:23,675][root][INFO] - Training Epoch: 4/10, step 267/574 completed (loss: 1.2982099056243896, acc: 0.6351351141929626)
[2024-11-29 03:15:23,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:24,244][root][INFO] - Training Epoch: 4/10, step 268/574 completed (loss: 0.9560086727142334, acc: 0.7068965435028076)
[2024-11-29 03:15:24,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:24,536][root][INFO] - Training Epoch: 4/10, step 269/574 completed (loss: 0.12604093551635742, acc: 0.9545454382896423)
[2024-11-29 03:15:24,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:24,839][root][INFO] - Training Epoch: 4/10, step 270/574 completed (loss: 0.26015016436576843, acc: 0.8636363744735718)
[2024-11-29 03:15:24,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:25,104][root][INFO] - Training Epoch: 4/10, step 271/574 completed (loss: 0.0860544815659523, acc: 0.96875)
[2024-11-29 03:15:25,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:25,376][root][INFO] - Training Epoch: 4/10, step 272/574 completed (loss: 0.24908457696437836, acc: 0.8999999761581421)
[2024-11-29 03:15:25,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:25,813][root][INFO] - Training Epoch: 4/10, step 273/574 completed (loss: 0.5866509675979614, acc: 0.8166666626930237)
[2024-11-29 03:15:26,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:26,130][root][INFO] - Training Epoch: 4/10, step 274/574 completed (loss: 0.14751698076725006, acc: 0.9375)
[2024-11-29 03:15:26,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:26,457][root][INFO] - Training Epoch: 4/10, step 275/574 completed (loss: 0.16677822172641754, acc: 0.9333333373069763)
[2024-11-29 03:15:26,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:26,732][root][INFO] - Training Epoch: 4/10, step 276/574 completed (loss: 0.6296173334121704, acc: 0.8620689511299133)
[2024-11-29 03:15:26,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:27,008][root][INFO] - Training Epoch: 4/10, step 277/574 completed (loss: 0.10961662977933884, acc: 0.9599999785423279)
[2024-11-29 03:15:27,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:27,312][root][INFO] - Training Epoch: 4/10, step 278/574 completed (loss: 0.5603667497634888, acc: 0.8510638475418091)
[2024-11-29 03:15:27,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:27,624][root][INFO] - Training Epoch: 4/10, step 279/574 completed (loss: 0.456005334854126, acc: 0.875)
[2024-11-29 03:15:28,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:28,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:29,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:29,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:30,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:30,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:30,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:31,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:31,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:32,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:32,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:33,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:33,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:34,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:34,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:34,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:35,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:35,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:36,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:36,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:36,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:37,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:37,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:38,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:38,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:39,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:39,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:39,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:40,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:40,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:41,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:41,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:42,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:42,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:42,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:43,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:43,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:44,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:44,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:45,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:45,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:46,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:46,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:46,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:47,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:47,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:48,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:48,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:48,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:49,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:49,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:49,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:50,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:50,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:51,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:51,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:52,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:52,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:53,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:53,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:54,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:54,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:55,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:55,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:56,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:56,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:57,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:57,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:58,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:58,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:58,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:59,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:15:59,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:00,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:00,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:00,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:01,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:01,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:01,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:02,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:02,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:03,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:03,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:03,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:04,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:04,842][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.0303, device='cuda:0') eval_epoch_loss=tensor(1.1087, device='cuda:0') eval_epoch_acc=tensor(0.7232, device='cuda:0')
[2024-11-29 03:16:04,843][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:16:04,844][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:16:05,086][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_4_step_280_loss_1.108673334121704/model.pt
[2024-11-29 03:16:05,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:05,458][root][INFO] - Training Epoch: 4/10, step 280/574 completed (loss: 0.1575789600610733, acc: 0.9772727489471436)
[2024-11-29 03:16:05,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:05,945][root][INFO] - Training Epoch: 4/10, step 281/574 completed (loss: 1.2586427927017212, acc: 0.6626505851745605)
[2024-11-29 03:16:06,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:06,307][root][INFO] - Training Epoch: 4/10, step 282/574 completed (loss: 1.1507306098937988, acc: 0.6666666865348816)
[2024-11-29 03:16:06,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:06,587][root][INFO] - Training Epoch: 4/10, step 283/574 completed (loss: 0.15649521350860596, acc: 0.9736841917037964)
[2024-11-29 03:16:06,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:06,928][root][INFO] - Training Epoch: 4/10, step 284/574 completed (loss: 0.330605685710907, acc: 0.8823529481887817)
[2024-11-29 03:16:07,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:07,234][root][INFO] - Training Epoch: 4/10, step 285/574 completed (loss: 0.47429904341697693, acc: 0.875)
[2024-11-29 03:16:07,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:07,516][root][INFO] - Training Epoch: 4/10, step 286/574 completed (loss: 0.6636790037155151, acc: 0.8203125)
[2024-11-29 03:16:07,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:07,834][root][INFO] - Training Epoch: 4/10, step 287/574 completed (loss: 0.7491894364356995, acc: 0.7839999794960022)
[2024-11-29 03:16:07,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:08,083][root][INFO] - Training Epoch: 4/10, step 288/574 completed (loss: 0.5782097578048706, acc: 0.8461538553237915)
[2024-11-29 03:16:08,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:08,387][root][INFO] - Training Epoch: 4/10, step 289/574 completed (loss: 0.5560885667800903, acc: 0.8447204828262329)
[2024-11-29 03:16:08,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:08,716][root][INFO] - Training Epoch: 4/10, step 290/574 completed (loss: 0.8353568911552429, acc: 0.7731958627700806)
[2024-11-29 03:16:08,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:08,955][root][INFO] - Training Epoch: 4/10, step 291/574 completed (loss: 0.056825198233127594, acc: 1.0)
[2024-11-29 03:16:09,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:09,257][root][INFO] - Training Epoch: 4/10, step 292/574 completed (loss: 0.7308823466300964, acc: 0.8095238208770752)
[2024-11-29 03:16:09,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:09,607][root][INFO] - Training Epoch: 4/10, step 293/574 completed (loss: 0.41241222620010376, acc: 0.9137930870056152)
[2024-11-29 03:16:09,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:10,205][root][INFO] - Training Epoch: 4/10, step 294/574 completed (loss: 0.5090925693511963, acc: 0.8363636136054993)
[2024-11-29 03:16:10,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:10,921][root][INFO] - Training Epoch: 4/10, step 295/574 completed (loss: 1.009981632232666, acc: 0.7164948582649231)
[2024-11-29 03:16:11,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:11,225][root][INFO] - Training Epoch: 4/10, step 296/574 completed (loss: 0.8446038365364075, acc: 0.7758620977401733)
[2024-11-29 03:16:11,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:11,520][root][INFO] - Training Epoch: 4/10, step 297/574 completed (loss: 0.4791124761104584, acc: 0.9259259104728699)
[2024-11-29 03:16:11,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:11,834][root][INFO] - Training Epoch: 4/10, step 298/574 completed (loss: 0.4054950475692749, acc: 0.8684210777282715)
[2024-11-29 03:16:12,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:12,134][root][INFO] - Training Epoch: 4/10, step 299/574 completed (loss: 0.2933107316493988, acc: 0.9107142686843872)
[2024-11-29 03:16:12,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:12,475][root][INFO] - Training Epoch: 4/10, step 300/574 completed (loss: 0.022514598444104195, acc: 1.0)
[2024-11-29 03:16:12,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:12,792][root][INFO] - Training Epoch: 4/10, step 301/574 completed (loss: 0.446132093667984, acc: 0.8301886916160583)
[2024-11-29 03:16:12,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:13,061][root][INFO] - Training Epoch: 4/10, step 302/574 completed (loss: 0.057425860315561295, acc: 0.9811320900917053)
[2024-11-29 03:16:13,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:13,357][root][INFO] - Training Epoch: 4/10, step 303/574 completed (loss: 0.13344620168209076, acc: 0.9411764740943909)
[2024-11-29 03:16:13,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:13,651][root][INFO] - Training Epoch: 4/10, step 304/574 completed (loss: 0.15630125999450684, acc: 0.90625)
[2024-11-29 03:16:13,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:13,990][root][INFO] - Training Epoch: 4/10, step 305/574 completed (loss: 0.7758097052574158, acc: 0.8032786846160889)
[2024-11-29 03:16:14,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:14,286][root][INFO] - Training Epoch: 4/10, step 306/574 completed (loss: 0.15486173331737518, acc: 0.9666666388511658)
[2024-11-29 03:16:14,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:14,584][root][INFO] - Training Epoch: 4/10, step 307/574 completed (loss: 0.0039657787419855595, acc: 1.0)
[2024-11-29 03:16:14,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:14,905][root][INFO] - Training Epoch: 4/10, step 308/574 completed (loss: 0.39466533064842224, acc: 0.8840579986572266)
[2024-11-29 03:16:15,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:15,392][root][INFO] - Training Epoch: 4/10, step 309/574 completed (loss: 0.49894824624061584, acc: 0.8472222089767456)
[2024-11-29 03:16:15,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:15,703][root][INFO] - Training Epoch: 4/10, step 310/574 completed (loss: 0.38633301854133606, acc: 0.9036144614219666)
[2024-11-29 03:16:15,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:15,977][root][INFO] - Training Epoch: 4/10, step 311/574 completed (loss: 0.4374295771121979, acc: 0.8333333134651184)
[2024-11-29 03:16:16,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:16,333][root][INFO] - Training Epoch: 4/10, step 312/574 completed (loss: 0.3674457371234894, acc: 0.8775510191917419)
[2024-11-29 03:16:16,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:16,609][root][INFO] - Training Epoch: 4/10, step 313/574 completed (loss: 0.04148711636662483, acc: 1.0)
[2024-11-29 03:16:16,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:16,879][root][INFO] - Training Epoch: 4/10, step 314/574 completed (loss: 0.09568063169717789, acc: 0.9583333134651184)
[2024-11-29 03:16:17,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:17,167][root][INFO] - Training Epoch: 4/10, step 315/574 completed (loss: 0.23034441471099854, acc: 0.9354838728904724)
[2024-11-29 03:16:17,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:17,490][root][INFO] - Training Epoch: 4/10, step 316/574 completed (loss: 1.6177337169647217, acc: 0.6774193644523621)
[2024-11-29 03:16:17,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:17,841][root][INFO] - Training Epoch: 4/10, step 317/574 completed (loss: 0.4969453513622284, acc: 0.8358209133148193)
[2024-11-29 03:16:18,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:18,172][root][INFO] - Training Epoch: 4/10, step 318/574 completed (loss: 0.3964160680770874, acc: 0.8846153616905212)
[2024-11-29 03:16:18,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:18,444][root][INFO] - Training Epoch: 4/10, step 319/574 completed (loss: 0.12514103949069977, acc: 0.9555555582046509)
[2024-11-29 03:16:18,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:18,711][root][INFO] - Training Epoch: 4/10, step 320/574 completed (loss: 0.31454721093177795, acc: 0.9516128897666931)
[2024-11-29 03:16:18,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:19,018][root][INFO] - Training Epoch: 4/10, step 321/574 completed (loss: 0.02161203883588314, acc: 1.0)
[2024-11-29 03:16:19,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:19,284][root][INFO] - Training Epoch: 4/10, step 322/574 completed (loss: 0.9851451516151428, acc: 0.6296296119689941)
[2024-11-29 03:16:19,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:19,571][root][INFO] - Training Epoch: 4/10, step 323/574 completed (loss: 1.9448539018630981, acc: 0.48571428656578064)
[2024-11-29 03:16:19,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:19,823][root][INFO] - Training Epoch: 4/10, step 324/574 completed (loss: 1.5282001495361328, acc: 0.692307710647583)
[2024-11-29 03:16:20,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:20,131][root][INFO] - Training Epoch: 4/10, step 325/574 completed (loss: 2.3404247760772705, acc: 0.4390243887901306)
[2024-11-29 03:16:20,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:20,397][root][INFO] - Training Epoch: 4/10, step 326/574 completed (loss: 1.5685001611709595, acc: 0.5263158082962036)
[2024-11-29 03:16:20,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:20,705][root][INFO] - Training Epoch: 4/10, step 327/574 completed (loss: 0.4666469991207123, acc: 0.8947368264198303)
[2024-11-29 03:16:20,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:20,988][root][INFO] - Training Epoch: 4/10, step 328/574 completed (loss: 0.11965811252593994, acc: 0.9285714030265808)
[2024-11-29 03:16:21,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:21,314][root][INFO] - Training Epoch: 4/10, step 329/574 completed (loss: 0.07539672404527664, acc: 1.0)
[2024-11-29 03:16:21,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:21,616][root][INFO] - Training Epoch: 4/10, step 330/574 completed (loss: 0.041546959429979324, acc: 1.0)
[2024-11-29 03:16:21,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:21,936][root][INFO] - Training Epoch: 4/10, step 331/574 completed (loss: 0.3330323398113251, acc: 0.8870967626571655)
[2024-11-29 03:16:22,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:22,325][root][INFO] - Training Epoch: 4/10, step 332/574 completed (loss: 0.3308600187301636, acc: 0.9298245906829834)
[2024-11-29 03:16:22,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:22,657][root][INFO] - Training Epoch: 4/10, step 333/574 completed (loss: 0.6878690719604492, acc: 0.875)
[2024-11-29 03:16:22,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:23,003][root][INFO] - Training Epoch: 4/10, step 334/574 completed (loss: 0.16961227357387543, acc: 0.9333333373069763)
[2024-11-29 03:16:23,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:23,324][root][INFO] - Training Epoch: 4/10, step 335/574 completed (loss: 0.30461305379867554, acc: 0.8947368264198303)
[2024-11-29 03:16:23,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:23,628][root][INFO] - Training Epoch: 4/10, step 336/574 completed (loss: 1.3312069177627563, acc: 0.6800000071525574)
[2024-11-29 03:16:23,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:23,955][root][INFO] - Training Epoch: 4/10, step 337/574 completed (loss: 1.8747111558914185, acc: 0.49425286054611206)
[2024-11-29 03:16:24,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:24,275][root][INFO] - Training Epoch: 4/10, step 338/574 completed (loss: 1.6544692516326904, acc: 0.6063829660415649)
[2024-11-29 03:16:24,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:24,582][root][INFO] - Training Epoch: 4/10, step 339/574 completed (loss: 1.688703179359436, acc: 0.5662650465965271)
[2024-11-29 03:16:24,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:24,894][root][INFO] - Training Epoch: 4/10, step 340/574 completed (loss: 0.0327770859003067, acc: 1.0)
[2024-11-29 03:16:25,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:25,209][root][INFO] - Training Epoch: 4/10, step 341/574 completed (loss: 0.58364337682724, acc: 0.8717948794364929)
[2024-11-29 03:16:25,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:25,498][root][INFO] - Training Epoch: 4/10, step 342/574 completed (loss: 0.4353022277355194, acc: 0.891566276550293)
[2024-11-29 03:16:25,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:25,752][root][INFO] - Training Epoch: 4/10, step 343/574 completed (loss: 1.3152779340744019, acc: 0.7169811129570007)
[2024-11-29 03:16:25,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:26,037][root][INFO] - Training Epoch: 4/10, step 344/574 completed (loss: 0.3864511549472809, acc: 0.9113923907279968)
[2024-11-29 03:16:26,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:26,326][root][INFO] - Training Epoch: 4/10, step 345/574 completed (loss: 0.29173004627227783, acc: 0.9215686321258545)
[2024-11-29 03:16:26,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:26,646][root][INFO] - Training Epoch: 4/10, step 346/574 completed (loss: 0.6681609749794006, acc: 0.8208954930305481)
[2024-11-29 03:16:26,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:26,916][root][INFO] - Training Epoch: 4/10, step 347/574 completed (loss: 0.21903324127197266, acc: 0.8999999761581421)
[2024-11-29 03:16:27,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:27,229][root][INFO] - Training Epoch: 4/10, step 348/574 completed (loss: 0.3071763515472412, acc: 0.9200000166893005)
[2024-11-29 03:16:27,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:27,667][root][INFO] - Training Epoch: 4/10, step 349/574 completed (loss: 1.027517318725586, acc: 0.75)
[2024-11-29 03:16:27,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:27,999][root][INFO] - Training Epoch: 4/10, step 350/574 completed (loss: 0.8981287479400635, acc: 0.6976743936538696)
[2024-11-29 03:16:28,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:28,338][root][INFO] - Training Epoch: 4/10, step 351/574 completed (loss: 0.30009007453918457, acc: 0.9230769276618958)
[2024-11-29 03:16:28,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:28,739][root][INFO] - Training Epoch: 4/10, step 352/574 completed (loss: 1.252902626991272, acc: 0.644444465637207)
[2024-11-29 03:16:28,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:29,047][root][INFO] - Training Epoch: 4/10, step 353/574 completed (loss: 0.033793605864048004, acc: 1.0)
[2024-11-29 03:16:29,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:29,350][root][INFO] - Training Epoch: 4/10, step 354/574 completed (loss: 0.46040070056915283, acc: 0.8461538553237915)
[2024-11-29 03:16:29,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:29,723][root][INFO] - Training Epoch: 4/10, step 355/574 completed (loss: 1.1202560663223267, acc: 0.6593406796455383)
[2024-11-29 03:16:30,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:30,373][root][INFO] - Training Epoch: 4/10, step 356/574 completed (loss: 0.8501253724098206, acc: 0.7565217614173889)
[2024-11-29 03:16:30,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:30,700][root][INFO] - Training Epoch: 4/10, step 357/574 completed (loss: 0.6781057119369507, acc: 0.8478260636329651)
[2024-11-29 03:16:30,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:31,026][root][INFO] - Training Epoch: 4/10, step 358/574 completed (loss: 0.6411603689193726, acc: 0.7755101919174194)
[2024-11-29 03:16:31,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:31,340][root][INFO] - Training Epoch: 4/10, step 359/574 completed (loss: 0.009774954058229923, acc: 1.0)
[2024-11-29 03:16:31,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:31,600][root][INFO] - Training Epoch: 4/10, step 360/574 completed (loss: 0.20664340257644653, acc: 0.9615384340286255)
[2024-11-29 03:16:31,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:31,932][root][INFO] - Training Epoch: 4/10, step 361/574 completed (loss: 0.6560269594192505, acc: 0.7317073345184326)
[2024-11-29 03:16:32,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:32,251][root][INFO] - Training Epoch: 4/10, step 362/574 completed (loss: 0.4782785177230835, acc: 0.8666666746139526)
[2024-11-29 03:16:32,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:32,575][root][INFO] - Training Epoch: 4/10, step 363/574 completed (loss: 0.2787129282951355, acc: 0.9342105388641357)
[2024-11-29 03:16:32,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:32,898][root][INFO] - Training Epoch: 4/10, step 364/574 completed (loss: 0.22842536866664886, acc: 0.8780487775802612)
[2024-11-29 03:16:33,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:33,204][root][INFO] - Training Epoch: 4/10, step 365/574 completed (loss: 0.18730612099170685, acc: 0.9090909361839294)
[2024-11-29 03:16:33,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:33,507][root][INFO] - Training Epoch: 4/10, step 366/574 completed (loss: 0.014368548057973385, acc: 1.0)
[2024-11-29 03:16:33,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:33,786][root][INFO] - Training Epoch: 4/10, step 367/574 completed (loss: 0.1677703857421875, acc: 0.9130434989929199)
[2024-11-29 03:16:33,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:34,088][root][INFO] - Training Epoch: 4/10, step 368/574 completed (loss: 0.08252982795238495, acc: 1.0)
[2024-11-29 03:16:34,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:34,494][root][INFO] - Training Epoch: 4/10, step 369/574 completed (loss: 0.6431450247764587, acc: 0.875)
[2024-11-29 03:16:34,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:35,317][root][INFO] - Training Epoch: 4/10, step 370/574 completed (loss: 1.3475061655044556, acc: 0.6727272868156433)
[2024-11-29 03:16:36,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:36,581][root][INFO] - Training Epoch: 4/10, step 371/574 completed (loss: 0.6149343252182007, acc: 0.849056601524353)
[2024-11-29 03:16:36,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:36,897][root][INFO] - Training Epoch: 4/10, step 372/574 completed (loss: 0.5241886377334595, acc: 0.8888888955116272)
[2024-11-29 03:16:37,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:37,208][root][INFO] - Training Epoch: 4/10, step 373/574 completed (loss: 0.2275342047214508, acc: 0.9285714030265808)
[2024-11-29 03:16:37,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:37,538][root][INFO] - Training Epoch: 4/10, step 374/574 completed (loss: 0.1808210164308548, acc: 0.9428571462631226)
[2024-11-29 03:16:37,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:37,881][root][INFO] - Training Epoch: 4/10, step 375/574 completed (loss: 0.20719537138938904, acc: 0.9599999785423279)
[2024-11-29 03:16:38,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:38,195][root][INFO] - Training Epoch: 4/10, step 376/574 completed (loss: 0.014953885227441788, acc: 1.0)
[2024-11-29 03:16:38,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:38,468][root][INFO] - Training Epoch: 4/10, step 377/574 completed (loss: 0.3026403486728668, acc: 0.8958333134651184)
[2024-11-29 03:16:38,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:38,803][root][INFO] - Training Epoch: 4/10, step 378/574 completed (loss: 0.05639979615807533, acc: 1.0)
[2024-11-29 03:16:39,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:39,577][root][INFO] - Training Epoch: 4/10, step 379/574 completed (loss: 0.5593821406364441, acc: 0.8742514848709106)
[2024-11-29 03:16:39,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:40,047][root][INFO] - Training Epoch: 4/10, step 380/574 completed (loss: 0.4297911822795868, acc: 0.9248120188713074)
[2024-11-29 03:16:41,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:41,789][root][INFO] - Training Epoch: 4/10, step 381/574 completed (loss: 0.8705858588218689, acc: 0.7700534462928772)
[2024-11-29 03:16:42,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:42,551][root][INFO] - Training Epoch: 4/10, step 382/574 completed (loss: 0.3049273192882538, acc: 0.9009009003639221)
[2024-11-29 03:16:42,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:42,855][root][INFO] - Training Epoch: 4/10, step 383/574 completed (loss: 0.41250142455101013, acc: 0.8928571343421936)
[2024-11-29 03:16:43,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:43,162][root][INFO] - Training Epoch: 4/10, step 384/574 completed (loss: 0.12501385807991028, acc: 0.9642857313156128)
[2024-11-29 03:16:43,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:43,467][root][INFO] - Training Epoch: 4/10, step 385/574 completed (loss: 0.29386430978775024, acc: 0.9375)
[2024-11-29 03:16:43,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:43,747][root][INFO] - Training Epoch: 4/10, step 386/574 completed (loss: 0.06542709469795227, acc: 0.9722222089767456)
[2024-11-29 03:16:43,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:44,105][root][INFO] - Training Epoch: 4/10, step 387/574 completed (loss: 0.04318215325474739, acc: 1.0)
[2024-11-29 03:16:44,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:44,400][root][INFO] - Training Epoch: 4/10, step 388/574 completed (loss: 0.11614540219306946, acc: 0.9545454382896423)
[2024-11-29 03:16:44,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:44,674][root][INFO] - Training Epoch: 4/10, step 389/574 completed (loss: 0.07673044502735138, acc: 1.0)
[2024-11-29 03:16:44,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:44,935][root][INFO] - Training Epoch: 4/10, step 390/574 completed (loss: 0.2689198851585388, acc: 0.9523809552192688)
[2024-11-29 03:16:45,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:45,199][root][INFO] - Training Epoch: 4/10, step 391/574 completed (loss: 1.2148445844650269, acc: 0.7222222089767456)
[2024-11-29 03:16:45,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:45,505][root][INFO] - Training Epoch: 4/10, step 392/574 completed (loss: 1.061048984527588, acc: 0.6601941585540771)
[2024-11-29 03:16:45,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:46,183][root][INFO] - Training Epoch: 4/10, step 393/574 completed (loss: 1.3032634258270264, acc: 0.7058823704719543)
[2024-11-29 03:16:46,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:46,579][root][INFO] - Training Epoch: 4/10, step 394/574 completed (loss: 1.175432801246643, acc: 0.6933333277702332)
[2024-11-29 03:16:46,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:47,012][root][INFO] - Training Epoch: 4/10, step 395/574 completed (loss: 0.9124021530151367, acc: 0.7638888955116272)
[2024-11-29 03:16:47,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:47,319][root][INFO] - Training Epoch: 4/10, step 396/574 completed (loss: 0.519834578037262, acc: 0.8604651093482971)
[2024-11-29 03:16:47,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:47,638][root][INFO] - Training Epoch: 4/10, step 397/574 completed (loss: 0.09369438141584396, acc: 1.0)
[2024-11-29 03:16:47,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:47,996][root][INFO] - Training Epoch: 4/10, step 398/574 completed (loss: 0.631920337677002, acc: 0.8139534592628479)
[2024-11-29 03:16:48,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:48,331][root][INFO] - Training Epoch: 4/10, step 399/574 completed (loss: 0.39664986729621887, acc: 0.9200000166893005)
[2024-11-29 03:16:48,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:49,044][root][INFO] - Training Epoch: 4/10, step 400/574 completed (loss: 0.4902142882347107, acc: 0.8676470518112183)
[2024-11-29 03:16:49,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:49,298][root][INFO] - Training Epoch: 4/10, step 401/574 completed (loss: 0.7332912683486938, acc: 0.8266666531562805)
[2024-11-29 03:16:49,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:49,598][root][INFO] - Training Epoch: 4/10, step 402/574 completed (loss: 0.6536742448806763, acc: 0.7878788113594055)
[2024-11-29 03:16:49,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:49,879][root][INFO] - Training Epoch: 4/10, step 403/574 completed (loss: 0.43865111470222473, acc: 0.8787878751754761)
[2024-11-29 03:16:50,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:50,159][root][INFO] - Training Epoch: 4/10, step 404/574 completed (loss: 0.45110565423965454, acc: 0.9032257795333862)
[2024-11-29 03:16:50,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:50,454][root][INFO] - Training Epoch: 4/10, step 405/574 completed (loss: 0.27675795555114746, acc: 0.9259259104728699)
[2024-11-29 03:16:50,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:50,749][root][INFO] - Training Epoch: 4/10, step 406/574 completed (loss: 0.15206171572208405, acc: 0.9599999785423279)
[2024-11-29 03:16:50,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:51,076][root][INFO] - Training Epoch: 4/10, step 407/574 completed (loss: 0.10376939922571182, acc: 0.9444444179534912)
[2024-11-29 03:16:51,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:51,407][root][INFO] - Training Epoch: 4/10, step 408/574 completed (loss: 0.16779881715774536, acc: 0.9259259104728699)
[2024-11-29 03:16:51,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:51,706][root][INFO] - Training Epoch: 4/10, step 409/574 completed (loss: 0.1368812918663025, acc: 0.9615384340286255)
[2024-11-29 03:16:51,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:52,014][root][INFO] - Training Epoch: 4/10, step 410/574 completed (loss: 0.17833060026168823, acc: 0.9655172228813171)
[2024-11-29 03:16:52,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:52,297][root][INFO] - Training Epoch: 4/10, step 411/574 completed (loss: 0.10259993374347687, acc: 1.0)
[2024-11-29 03:16:52,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:52,543][root][INFO] - Training Epoch: 4/10, step 412/574 completed (loss: 0.3793143630027771, acc: 0.8999999761581421)
[2024-11-29 03:16:52,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:52,869][root][INFO] - Training Epoch: 4/10, step 413/574 completed (loss: 0.11066806316375732, acc: 0.9696969985961914)
[2024-11-29 03:16:53,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:53,144][root][INFO] - Training Epoch: 4/10, step 414/574 completed (loss: 0.31221452355384827, acc: 0.8636363744735718)
[2024-11-29 03:16:53,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:53,435][root][INFO] - Training Epoch: 4/10, step 415/574 completed (loss: 0.5218434929847717, acc: 0.7843137383460999)
[2024-11-29 03:16:53,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:53,762][root][INFO] - Training Epoch: 4/10, step 416/574 completed (loss: 0.07613027840852737, acc: 0.9615384340286255)
[2024-11-29 03:16:53,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:54,077][root][INFO] - Training Epoch: 4/10, step 417/574 completed (loss: 0.20436711609363556, acc: 0.9444444179534912)
[2024-11-29 03:16:54,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:54,409][root][INFO] - Training Epoch: 4/10, step 418/574 completed (loss: 0.25994807481765747, acc: 0.925000011920929)
[2024-11-29 03:16:54,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:54,684][root][INFO] - Training Epoch: 4/10, step 419/574 completed (loss: 0.08426535874605179, acc: 1.0)
[2024-11-29 03:16:54,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:54,948][root][INFO] - Training Epoch: 4/10, step 420/574 completed (loss: 0.1150263175368309, acc: 1.0)
[2024-11-29 03:16:55,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:55,285][root][INFO] - Training Epoch: 4/10, step 421/574 completed (loss: 0.10658946633338928, acc: 1.0)
[2024-11-29 03:16:55,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:55,575][root][INFO] - Training Epoch: 4/10, step 422/574 completed (loss: 0.30863213539123535, acc: 0.90625)
[2024-11-29 03:16:56,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:56,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:57,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:57,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:58,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:58,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:59,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:16:59,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:00,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:00,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:00,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:01,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:01,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:02,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:02,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:03,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:03,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:03,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:04,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:04,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:05,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:05,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:05,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:06,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:06,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:07,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:07,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:08,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:08,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:08,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:09,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:09,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:10,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:10,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:11,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:11,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:11,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:12,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:12,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:13,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:13,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:14,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:14,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:15,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:15,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:15,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:16,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:16,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:17,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:17,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:17,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:18,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:18,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:19,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:19,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:20,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:20,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:21,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:21,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:21,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:22,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:23,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:23,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:23,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:24,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:24,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:25,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:25,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:26,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:26,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:27,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:27,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:27,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:28,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:28,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:29,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:29,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:29,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:30,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:30,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:31,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:31,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:32,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:32,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:32,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:33,535][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.1843, device='cuda:0') eval_epoch_loss=tensor(1.1582, device='cuda:0') eval_epoch_acc=tensor(0.7220, device='cuda:0')
[2024-11-29 03:17:33,536][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:17:33,536][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:17:33,773][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_4_step_423_loss_1.158241629600525/model.pt
[2024-11-29 03:17:33,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:34,137][root][INFO] - Training Epoch: 4/10, step 423/574 completed (loss: 0.6212897896766663, acc: 0.7777777910232544)
[2024-11-29 03:17:34,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:34,431][root][INFO] - Training Epoch: 4/10, step 424/574 completed (loss: 0.4543842077255249, acc: 0.9259259104728699)
[2024-11-29 03:17:34,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:34,737][root][INFO] - Training Epoch: 4/10, step 425/574 completed (loss: 0.3224213123321533, acc: 0.9090909361839294)
[2024-11-29 03:17:34,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:35,026][root][INFO] - Training Epoch: 4/10, step 426/574 completed (loss: 0.03816342353820801, acc: 1.0)
[2024-11-29 03:17:35,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:35,337][root][INFO] - Training Epoch: 4/10, step 427/574 completed (loss: 0.29080525040626526, acc: 0.8918918967247009)
[2024-11-29 03:17:35,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:35,646][root][INFO] - Training Epoch: 4/10, step 428/574 completed (loss: 0.06040351465344429, acc: 1.0)
[2024-11-29 03:17:35,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:35,927][root][INFO] - Training Epoch: 4/10, step 429/574 completed (loss: 0.15561671555042267, acc: 0.95652174949646)
[2024-11-29 03:17:36,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:36,209][root][INFO] - Training Epoch: 4/10, step 430/574 completed (loss: 0.07256396114826202, acc: 0.9629629850387573)
[2024-11-29 03:17:36,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:36,549][root][INFO] - Training Epoch: 4/10, step 431/574 completed (loss: 0.025072801858186722, acc: 1.0)
[2024-11-29 03:17:36,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:36,855][root][INFO] - Training Epoch: 4/10, step 432/574 completed (loss: 0.04959908872842789, acc: 1.0)
[2024-11-29 03:17:37,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:37,215][root][INFO] - Training Epoch: 4/10, step 433/574 completed (loss: 0.36432334780693054, acc: 0.8611111044883728)
[2024-11-29 03:17:37,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:37,472][root][INFO] - Training Epoch: 4/10, step 434/574 completed (loss: 0.01705954037606716, acc: 1.0)
[2024-11-29 03:17:37,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:37,780][root][INFO] - Training Epoch: 4/10, step 435/574 completed (loss: 0.26688459515571594, acc: 0.8787878751754761)
[2024-11-29 03:17:37,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:38,111][root][INFO] - Training Epoch: 4/10, step 436/574 completed (loss: 0.18595829606056213, acc: 0.9722222089767456)
[2024-11-29 03:17:38,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:38,442][root][INFO] - Training Epoch: 4/10, step 437/574 completed (loss: 0.2840205729007721, acc: 0.8863636255264282)
[2024-11-29 03:17:38,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:38,776][root][INFO] - Training Epoch: 4/10, step 438/574 completed (loss: 0.02017531543970108, acc: 1.0)
[2024-11-29 03:17:38,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:39,105][root][INFO] - Training Epoch: 4/10, step 439/574 completed (loss: 0.2461370825767517, acc: 0.8974359035491943)
[2024-11-29 03:17:39,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:39,692][root][INFO] - Training Epoch: 4/10, step 440/574 completed (loss: 0.5259496569633484, acc: 0.8484848737716675)
[2024-11-29 03:17:40,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:40,648][root][INFO] - Training Epoch: 4/10, step 441/574 completed (loss: 1.051905632019043, acc: 0.7360000014305115)
[2024-11-29 03:17:40,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:41,112][root][INFO] - Training Epoch: 4/10, step 442/574 completed (loss: 1.0231285095214844, acc: 0.7580645084381104)
[2024-11-29 03:17:41,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:42,013][root][INFO] - Training Epoch: 4/10, step 443/574 completed (loss: 0.9067160487174988, acc: 0.7761194109916687)
[2024-11-29 03:17:42,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:42,277][root][INFO] - Training Epoch: 4/10, step 444/574 completed (loss: 0.3144221305847168, acc: 0.8867924809455872)
[2024-11-29 03:17:42,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:42,773][root][INFO] - Training Epoch: 4/10, step 445/574 completed (loss: 0.1530175805091858, acc: 0.9545454382896423)
[2024-11-29 03:17:42,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:43,024][root][INFO] - Training Epoch: 4/10, step 446/574 completed (loss: 0.4597247242927551, acc: 0.782608687877655)
[2024-11-29 03:17:43,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:43,273][root][INFO] - Training Epoch: 4/10, step 447/574 completed (loss: 0.17210593819618225, acc: 0.9615384340286255)
[2024-11-29 03:17:43,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:43,518][root][INFO] - Training Epoch: 4/10, step 448/574 completed (loss: 0.057865776121616364, acc: 1.0)
[2024-11-29 03:17:43,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:43,773][root][INFO] - Training Epoch: 4/10, step 449/574 completed (loss: 0.20732052624225616, acc: 0.9253731369972229)
[2024-11-29 03:17:43,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:44,035][root][INFO] - Training Epoch: 4/10, step 450/574 completed (loss: 0.15648336708545685, acc: 0.9722222089767456)
[2024-11-29 03:17:44,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:44,297][root][INFO] - Training Epoch: 4/10, step 451/574 completed (loss: 0.16851909458637238, acc: 0.9347826242446899)
[2024-11-29 03:17:44,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:44,566][root][INFO] - Training Epoch: 4/10, step 452/574 completed (loss: 0.3692069351673126, acc: 0.9230769276618958)
[2024-11-29 03:17:44,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:44,857][root][INFO] - Training Epoch: 4/10, step 453/574 completed (loss: 0.6831551194190979, acc: 0.8289473652839661)
[2024-11-29 03:17:44,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:45,119][root][INFO] - Training Epoch: 4/10, step 454/574 completed (loss: 0.2796672582626343, acc: 0.9387755393981934)
[2024-11-29 03:17:45,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:45,372][root][INFO] - Training Epoch: 4/10, step 455/574 completed (loss: 0.19044654071331024, acc: 0.939393937587738)
[2024-11-29 03:17:45,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:45,645][root][INFO] - Training Epoch: 4/10, step 456/574 completed (loss: 0.7356776595115662, acc: 0.7835051417350769)
[2024-11-29 03:17:45,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:45,904][root][INFO] - Training Epoch: 4/10, step 457/574 completed (loss: 0.2063675969839096, acc: 0.9714285731315613)
[2024-11-29 03:17:46,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:46,322][root][INFO] - Training Epoch: 4/10, step 458/574 completed (loss: 0.9717010855674744, acc: 0.7790697813034058)
[2024-11-29 03:17:46,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:46,582][root][INFO] - Training Epoch: 4/10, step 459/574 completed (loss: 0.4543907046318054, acc: 0.8928571343421936)
[2024-11-29 03:17:46,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:46,899][root][INFO] - Training Epoch: 4/10, step 460/574 completed (loss: 0.6538338661193848, acc: 0.8148148059844971)
[2024-11-29 03:17:47,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:47,147][root][INFO] - Training Epoch: 4/10, step 461/574 completed (loss: 0.2517569661140442, acc: 0.9444444179534912)
[2024-11-29 03:17:47,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:47,410][root][INFO] - Training Epoch: 4/10, step 462/574 completed (loss: 0.3741036653518677, acc: 0.875)
[2024-11-29 03:17:47,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:47,634][root][INFO] - Training Epoch: 4/10, step 463/574 completed (loss: 0.2846710979938507, acc: 0.8846153616905212)
[2024-11-29 03:17:47,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:47,863][root][INFO] - Training Epoch: 4/10, step 464/574 completed (loss: 0.5383190512657166, acc: 0.8478260636329651)
[2024-11-29 03:17:47,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:48,111][root][INFO] - Training Epoch: 4/10, step 465/574 completed (loss: 0.509577214717865, acc: 0.8571428656578064)
[2024-11-29 03:17:48,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:48,350][root][INFO] - Training Epoch: 4/10, step 466/574 completed (loss: 1.003933072090149, acc: 0.759036123752594)
[2024-11-29 03:17:48,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:48,648][root][INFO] - Training Epoch: 4/10, step 467/574 completed (loss: 0.3561052978038788, acc: 0.9189189076423645)
[2024-11-29 03:17:48,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:48,910][root][INFO] - Training Epoch: 4/10, step 468/574 completed (loss: 0.8994330167770386, acc: 0.7766990065574646)
[2024-11-29 03:17:49,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:49,180][root][INFO] - Training Epoch: 4/10, step 469/574 completed (loss: 1.1973990201950073, acc: 0.707317054271698)
[2024-11-29 03:17:49,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:49,429][root][INFO] - Training Epoch: 4/10, step 470/574 completed (loss: 0.19074900448322296, acc: 0.9166666865348816)
[2024-11-29 03:17:49,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:49,685][root][INFO] - Training Epoch: 4/10, step 471/574 completed (loss: 0.10713247954845428, acc: 1.0)
[2024-11-29 03:17:49,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:50,163][root][INFO] - Training Epoch: 4/10, step 472/574 completed (loss: 0.9085637927055359, acc: 0.6960784196853638)
[2024-11-29 03:17:50,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:50,535][root][INFO] - Training Epoch: 4/10, step 473/574 completed (loss: 1.192271113395691, acc: 0.6593886613845825)
[2024-11-29 03:17:50,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:50,795][root][INFO] - Training Epoch: 4/10, step 474/574 completed (loss: 0.9406044483184814, acc: 0.7395833134651184)
[2024-11-29 03:17:50,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:51,076][root][INFO] - Training Epoch: 4/10, step 475/574 completed (loss: 0.6160373091697693, acc: 0.8220859169960022)
[2024-11-29 03:17:51,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:51,345][root][INFO] - Training Epoch: 4/10, step 476/574 completed (loss: 0.6273850202560425, acc: 0.8489208817481995)
[2024-11-29 03:17:51,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:51,689][root][INFO] - Training Epoch: 4/10, step 477/574 completed (loss: 0.9915172457695007, acc: 0.7085427045822144)
[2024-11-29 03:17:51,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:51,935][root][INFO] - Training Epoch: 4/10, step 478/574 completed (loss: 0.511178731918335, acc: 0.8333333134651184)
[2024-11-29 03:17:52,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:52,197][root][INFO] - Training Epoch: 4/10, step 479/574 completed (loss: 0.5014728903770447, acc: 0.8181818127632141)
[2024-11-29 03:17:52,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:52,431][root][INFO] - Training Epoch: 4/10, step 480/574 completed (loss: 0.5819883942604065, acc: 0.8888888955116272)
[2024-11-29 03:17:52,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:52,674][root][INFO] - Training Epoch: 4/10, step 481/574 completed (loss: 0.7336696982383728, acc: 0.800000011920929)
[2024-11-29 03:17:52,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:52,916][root][INFO] - Training Epoch: 4/10, step 482/574 completed (loss: 1.405940055847168, acc: 0.75)
[2024-11-29 03:17:53,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:53,326][root][INFO] - Training Epoch: 4/10, step 483/574 completed (loss: 1.0570286512374878, acc: 0.6896551847457886)
[2024-11-29 03:17:53,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:53,573][root][INFO] - Training Epoch: 4/10, step 484/574 completed (loss: 0.20361775159835815, acc: 0.9032257795333862)
[2024-11-29 03:17:53,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:53,821][root][INFO] - Training Epoch: 4/10, step 485/574 completed (loss: 0.1645144522190094, acc: 1.0)
[2024-11-29 03:17:53,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:54,070][root][INFO] - Training Epoch: 4/10, step 486/574 completed (loss: 1.1637206077575684, acc: 0.6666666865348816)
[2024-11-29 03:17:54,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:54,315][root][INFO] - Training Epoch: 4/10, step 487/574 completed (loss: 0.8598981499671936, acc: 0.8095238208770752)
[2024-11-29 03:17:54,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:54,562][root][INFO] - Training Epoch: 4/10, step 488/574 completed (loss: 1.0818548202514648, acc: 0.7272727489471436)
[2024-11-29 03:17:54,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:54,903][root][INFO] - Training Epoch: 4/10, step 489/574 completed (loss: 1.0797905921936035, acc: 0.7384615540504456)
[2024-11-29 03:17:55,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:55,154][root][INFO] - Training Epoch: 4/10, step 490/574 completed (loss: 0.2227238118648529, acc: 0.9666666388511658)
[2024-11-29 03:17:55,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:55,396][root][INFO] - Training Epoch: 4/10, step 491/574 completed (loss: 0.6748422384262085, acc: 0.7931034564971924)
[2024-11-29 03:17:55,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:55,654][root][INFO] - Training Epoch: 4/10, step 492/574 completed (loss: 0.5779096484184265, acc: 0.843137264251709)
[2024-11-29 03:17:55,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:55,906][root][INFO] - Training Epoch: 4/10, step 493/574 completed (loss: 0.374777615070343, acc: 0.8620689511299133)
[2024-11-29 03:17:56,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:56,152][root][INFO] - Training Epoch: 4/10, step 494/574 completed (loss: 0.3217771351337433, acc: 0.9473684430122375)
[2024-11-29 03:17:56,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:56,398][root][INFO] - Training Epoch: 4/10, step 495/574 completed (loss: 0.19135798513889313, acc: 0.9473684430122375)
[2024-11-29 03:17:56,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:56,720][root][INFO] - Training Epoch: 4/10, step 496/574 completed (loss: 1.0583510398864746, acc: 0.7232142686843872)
[2024-11-29 03:17:56,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:57,116][root][INFO] - Training Epoch: 4/10, step 497/574 completed (loss: 0.48320966958999634, acc: 0.8651685118675232)
[2024-11-29 03:17:57,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:57,409][root][INFO] - Training Epoch: 4/10, step 498/574 completed (loss: 0.9879762530326843, acc: 0.6966292262077332)
[2024-11-29 03:17:57,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:57,710][root][INFO] - Training Epoch: 4/10, step 499/574 completed (loss: 1.6091994047164917, acc: 0.5815602540969849)
[2024-11-29 03:17:57,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:57,989][root][INFO] - Training Epoch: 4/10, step 500/574 completed (loss: 1.1449910402297974, acc: 0.6739130616188049)
[2024-11-29 03:17:58,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:58,234][root][INFO] - Training Epoch: 4/10, step 501/574 completed (loss: 0.16367439925670624, acc: 0.9200000166893005)
[2024-11-29 03:17:58,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:58,479][root][INFO] - Training Epoch: 4/10, step 502/574 completed (loss: 0.13967305421829224, acc: 0.9615384340286255)
[2024-11-29 03:17:58,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:58,725][root][INFO] - Training Epoch: 4/10, step 503/574 completed (loss: 0.7081405520439148, acc: 0.8888888955116272)
[2024-11-29 03:17:58,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:58,969][root][INFO] - Training Epoch: 4/10, step 504/574 completed (loss: 0.09983571618795395, acc: 1.0)
[2024-11-29 03:17:59,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:59,215][root][INFO] - Training Epoch: 4/10, step 505/574 completed (loss: 0.8104071021080017, acc: 0.7924528121948242)
[2024-11-29 03:17:59,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:17:59,460][root][INFO] - Training Epoch: 4/10, step 506/574 completed (loss: 1.266837239265442, acc: 0.7241379022598267)
[2024-11-29 03:17:59,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:00,265][root][INFO] - Training Epoch: 4/10, step 507/574 completed (loss: 1.3953564167022705, acc: 0.6396396160125732)
[2024-11-29 03:18:00,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:00,804][root][INFO] - Training Epoch: 4/10, step 508/574 completed (loss: 0.7628276348114014, acc: 0.8450704216957092)
[2024-11-29 03:18:00,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:01,047][root][INFO] - Training Epoch: 4/10, step 509/574 completed (loss: 0.09552137553691864, acc: 1.0)
[2024-11-29 03:18:01,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:01,299][root][INFO] - Training Epoch: 4/10, step 510/574 completed (loss: 0.3029627501964569, acc: 0.8999999761581421)
[2024-11-29 03:18:01,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:01,547][root][INFO] - Training Epoch: 4/10, step 511/574 completed (loss: 0.3811039924621582, acc: 0.9230769276618958)
[2024-11-29 03:18:03,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:05,043][root][INFO] - Training Epoch: 4/10, step 512/574 completed (loss: 1.501863956451416, acc: 0.6285714507102966)
[2024-11-29 03:18:05,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:06,144][root][INFO] - Training Epoch: 4/10, step 513/574 completed (loss: 0.4587271511554718, acc: 0.8333333134651184)
[2024-11-29 03:18:06,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:06,390][root][INFO] - Training Epoch: 4/10, step 514/574 completed (loss: 0.8166881203651428, acc: 0.7857142686843872)
[2024-11-29 03:18:06,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:06,653][root][INFO] - Training Epoch: 4/10, step 515/574 completed (loss: 0.2077084332704544, acc: 0.8833333253860474)
[2024-11-29 03:18:07,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:07,623][root][INFO] - Training Epoch: 4/10, step 516/574 completed (loss: 0.6794970035552979, acc: 0.7916666865348816)
[2024-11-29 03:18:07,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:07,861][root][INFO] - Training Epoch: 4/10, step 517/574 completed (loss: 0.10708855837583542, acc: 0.9615384340286255)
[2024-11-29 03:18:07,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:08,106][root][INFO] - Training Epoch: 4/10, step 518/574 completed (loss: 0.16600549221038818, acc: 0.9677419066429138)
[2024-11-29 03:18:08,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:08,346][root][INFO] - Training Epoch: 4/10, step 519/574 completed (loss: 0.21927614510059357, acc: 0.949999988079071)
[2024-11-29 03:18:08,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:08,593][root][INFO] - Training Epoch: 4/10, step 520/574 completed (loss: 0.17657454311847687, acc: 0.9259259104728699)
[2024-11-29 03:18:09,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:09,994][root][INFO] - Training Epoch: 4/10, step 521/574 completed (loss: 1.0041608810424805, acc: 0.7288135886192322)
[2024-11-29 03:18:10,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:10,353][root][INFO] - Training Epoch: 4/10, step 522/574 completed (loss: 0.48652005195617676, acc: 0.8432835936546326)
[2024-11-29 03:18:10,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:10,732][root][INFO] - Training Epoch: 4/10, step 523/574 completed (loss: 0.6014395952224731, acc: 0.8175182342529297)
[2024-11-29 03:18:11,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:11,473][root][INFO] - Training Epoch: 4/10, step 524/574 completed (loss: 0.9379159808158875, acc: 0.7450000047683716)
[2024-11-29 03:18:11,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:11,730][root][INFO] - Training Epoch: 4/10, step 525/574 completed (loss: 0.08049982786178589, acc: 1.0)
[2024-11-29 03:18:11,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:11,990][root][INFO] - Training Epoch: 4/10, step 526/574 completed (loss: 0.154388889670372, acc: 0.942307710647583)
[2024-11-29 03:18:12,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:12,236][root][INFO] - Training Epoch: 4/10, step 527/574 completed (loss: 0.07976007461547852, acc: 1.0)
[2024-11-29 03:18:12,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:12,506][root][INFO] - Training Epoch: 4/10, step 528/574 completed (loss: 1.4790656566619873, acc: 0.688524603843689)
[2024-11-29 03:18:12,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:12,795][root][INFO] - Training Epoch: 4/10, step 529/574 completed (loss: 0.2949112355709076, acc: 0.9491525292396545)
[2024-11-29 03:18:12,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:13,109][root][INFO] - Training Epoch: 4/10, step 530/574 completed (loss: 1.7498197555541992, acc: 0.5813953280448914)
[2024-11-29 03:18:13,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:13,371][root][INFO] - Training Epoch: 4/10, step 531/574 completed (loss: 0.9590192437171936, acc: 0.7954545617103577)
[2024-11-29 03:18:13,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:13,667][root][INFO] - Training Epoch: 4/10, step 532/574 completed (loss: 1.6324418783187866, acc: 0.6226415038108826)
[2024-11-29 03:18:13,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:13,938][root][INFO] - Training Epoch: 4/10, step 533/574 completed (loss: 0.6885148286819458, acc: 0.75)
[2024-11-29 03:18:14,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:14,186][root][INFO] - Training Epoch: 4/10, step 534/574 completed (loss: 0.6387917995452881, acc: 0.8799999952316284)
[2024-11-29 03:18:14,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:14,452][root][INFO] - Training Epoch: 4/10, step 535/574 completed (loss: 0.31149452924728394, acc: 0.8999999761581421)
[2024-11-29 03:18:14,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:14,697][root][INFO] - Training Epoch: 4/10, step 536/574 completed (loss: 0.14880932867527008, acc: 1.0)
[2024-11-29 03:18:14,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:15,162][root][INFO] - Training Epoch: 4/10, step 537/574 completed (loss: 0.7164077162742615, acc: 0.8307692408561707)
[2024-11-29 03:18:15,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:15,478][root][INFO] - Training Epoch: 4/10, step 538/574 completed (loss: 0.630474328994751, acc: 0.859375)
[2024-11-29 03:18:15,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:15,916][root][INFO] - Training Epoch: 4/10, step 539/574 completed (loss: 0.5439268946647644, acc: 0.875)
[2024-11-29 03:18:16,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:16,167][root][INFO] - Training Epoch: 4/10, step 540/574 completed (loss: 1.1611377000808716, acc: 0.6666666865348816)
[2024-11-29 03:18:16,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:16,413][root][INFO] - Training Epoch: 4/10, step 541/574 completed (loss: 0.09962176531553268, acc: 1.0)
[2024-11-29 03:18:16,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:16,667][root][INFO] - Training Epoch: 4/10, step 542/574 completed (loss: 0.13213399052619934, acc: 0.9677419066429138)
[2024-11-29 03:18:16,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:16,903][root][INFO] - Training Epoch: 4/10, step 543/574 completed (loss: 0.028422899544239044, acc: 1.0)
[2024-11-29 03:18:17,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:17,160][root][INFO] - Training Epoch: 4/10, step 544/574 completed (loss: 0.14087432622909546, acc: 0.9333333373069763)
[2024-11-29 03:18:17,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:17,410][root][INFO] - Training Epoch: 4/10, step 545/574 completed (loss: 0.07715076208114624, acc: 0.9756097793579102)
[2024-11-29 03:18:17,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:17,659][root][INFO] - Training Epoch: 4/10, step 546/574 completed (loss: 0.10336607694625854, acc: 0.9714285731315613)
[2024-11-29 03:18:17,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:17,907][root][INFO] - Training Epoch: 4/10, step 547/574 completed (loss: 0.09888597577810287, acc: 0.9473684430122375)
[2024-11-29 03:18:18,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:18,151][root][INFO] - Training Epoch: 4/10, step 548/574 completed (loss: 0.1638091653585434, acc: 0.9354838728904724)
[2024-11-29 03:18:18,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:18,400][root][INFO] - Training Epoch: 4/10, step 549/574 completed (loss: 0.021618230268359184, acc: 1.0)
[2024-11-29 03:18:18,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:18,669][root][INFO] - Training Epoch: 4/10, step 550/574 completed (loss: 0.09174194931983948, acc: 0.9696969985961914)
[2024-11-29 03:18:18,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:18,936][root][INFO] - Training Epoch: 4/10, step 551/574 completed (loss: 0.12241313606500626, acc: 0.949999988079071)
[2024-11-29 03:18:19,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:19,193][root][INFO] - Training Epoch: 4/10, step 552/574 completed (loss: 0.11627356708049774, acc: 0.9714285731315613)
[2024-11-29 03:18:19,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:19,453][root][INFO] - Training Epoch: 4/10, step 553/574 completed (loss: 0.5802675485610962, acc: 0.8905109763145447)
[2024-11-29 03:18:19,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:19,712][root][INFO] - Training Epoch: 4/10, step 554/574 completed (loss: 0.3047889471054077, acc: 0.9034482836723328)
[2024-11-29 03:18:19,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:20,035][root][INFO] - Training Epoch: 4/10, step 555/574 completed (loss: 0.6719081997871399, acc: 0.8357142806053162)
[2024-11-29 03:18:20,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:20,388][root][INFO] - Training Epoch: 4/10, step 556/574 completed (loss: 0.5582094788551331, acc: 0.8543046116828918)
[2024-11-29 03:18:20,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:20,689][root][INFO] - Training Epoch: 4/10, step 557/574 completed (loss: 0.29010799527168274, acc: 0.9145299196243286)
[2024-11-29 03:18:20,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:20,947][root][INFO] - Training Epoch: 4/10, step 558/574 completed (loss: 0.11888826638460159, acc: 0.9200000166893005)
[2024-11-29 03:18:21,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:21,203][root][INFO] - Training Epoch: 4/10, step 559/574 completed (loss: 0.16129790246486664, acc: 0.9615384340286255)
[2024-11-29 03:18:21,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:21,497][root][INFO] - Training Epoch: 4/10, step 560/574 completed (loss: 0.14006343483924866, acc: 0.9615384340286255)
[2024-11-29 03:18:21,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:21,761][root][INFO] - Training Epoch: 4/10, step 561/574 completed (loss: 0.3695541322231293, acc: 0.8717948794364929)
[2024-11-29 03:18:21,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:22,031][root][INFO] - Training Epoch: 4/10, step 562/574 completed (loss: 0.5643798112869263, acc: 0.8444444537162781)
[2024-11-29 03:18:22,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:22,281][root][INFO] - Training Epoch: 4/10, step 563/574 completed (loss: 0.5853472352027893, acc: 0.8831169009208679)
[2024-11-29 03:18:22,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:22,581][root][INFO] - Training Epoch: 4/10, step 564/574 completed (loss: 0.33192893862724304, acc: 0.9166666865348816)
[2024-11-29 03:18:22,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:22,853][root][INFO] - Training Epoch: 4/10, step 565/574 completed (loss: 0.46960076689720154, acc: 0.8620689511299133)
[2024-11-29 03:18:23,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:24,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:24,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:24,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:25,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:25,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:26,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:26,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:27,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:27,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:27,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:28,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:28,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:29,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:29,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:30,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:30,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:31,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:31,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:32,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:32,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:32,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:33,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:33,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:34,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:34,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:35,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:35,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:36,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:36,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:36,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:36,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:37,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:37,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:38,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:38,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:39,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:39,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:40,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:40,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:40,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:41,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:41,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:42,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:42,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:42,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:43,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:43,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:44,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:44,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:44,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:45,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:45,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:46,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:46,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:47,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:47,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:47,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:48,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:48,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:49,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:50,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:50,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:51,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:51,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:51,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:52,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:52,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:53,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:54,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:54,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:54,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:55,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:55,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:56,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:56,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:56,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:57,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:57,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:58,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:58,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:58,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:59,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:18:59,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:00,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:00,820][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.6142, device='cuda:0') eval_epoch_loss=tensor(1.2849, device='cuda:0') eval_epoch_acc=tensor(0.7126, device='cuda:0')
[2024-11-29 03:19:00,821][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:19:00,821][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:19:01,057][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_4_step_566_loss_1.2848684787750244/model.pt
[2024-11-29 03:19:01,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:01,372][root][INFO] - Training Epoch: 4/10, step 566/574 completed (loss: 0.43084049224853516, acc: 0.8928571343421936)
[2024-11-29 03:19:01,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:01,693][root][INFO] - Training Epoch: 4/10, step 567/574 completed (loss: 0.06650874763727188, acc: 0.9736841917037964)
[2024-11-29 03:19:01,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:01,959][root][INFO] - Training Epoch: 4/10, step 568/574 completed (loss: 0.12143419682979584, acc: 0.9629629850387573)
[2024-11-29 03:19:02,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:02,355][root][INFO] - Training Epoch: 4/10, step 569/574 completed (loss: 0.5723204016685486, acc: 0.8823529481887817)
[2024-11-29 03:19:02,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:02,702][root][INFO] - Training Epoch: 4/10, step 570/574 completed (loss: 0.21816149353981018, acc: 0.9516128897666931)
[2024-11-29 03:19:02,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:02,963][root][INFO] - Training Epoch: 4/10, step 571/574 completed (loss: 0.440334677696228, acc: 0.8717948794364929)
[2024-11-29 03:19:03,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:03,237][root][INFO] - Training Epoch: 4/10, step 572/574 completed (loss: 0.9740918874740601, acc: 0.7653061151504517)
[2024-11-29 03:19:03,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:03,588][root][INFO] - Training Epoch: 4/10, step 573/574 completed (loss: 0.8770511746406555, acc: 0.7735849022865295)
[2024-11-29 03:19:04,048][slam_llm.utils.train_utils][INFO] - Epoch 4: train_perplexity=1.9405, train_epoch_loss=0.6629, epoch time 376.757784916088s
[2024-11-29 03:19:04,049][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-11-29 03:19:04,049][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 15 GB
[2024-11-29 03:19:04,049][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-11-29 03:19:04,049][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 9
[2024-11-29 03:19:04,049][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-29 03:19:04,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:04,778][root][INFO] - Training Epoch: 5/10, step 0/574 completed (loss: 0.11166177690029144, acc: 0.9629629850387573)
[2024-11-29 03:19:04,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:05,042][root][INFO] - Training Epoch: 5/10, step 1/574 completed (loss: 0.5382668972015381, acc: 0.8399999737739563)
[2024-11-29 03:19:05,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:05,295][root][INFO] - Training Epoch: 5/10, step 2/574 completed (loss: 0.6148279309272766, acc: 0.837837815284729)
[2024-11-29 03:19:05,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:05,572][root][INFO] - Training Epoch: 5/10, step 3/574 completed (loss: 0.24483126401901245, acc: 0.9210526347160339)
[2024-11-29 03:19:05,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:05,884][root][INFO] - Training Epoch: 5/10, step 4/574 completed (loss: 0.5763071179389954, acc: 0.8108108043670654)
[2024-11-29 03:19:06,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:06,142][root][INFO] - Training Epoch: 5/10, step 5/574 completed (loss: 0.09527076780796051, acc: 1.0)
[2024-11-29 03:19:06,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:06,432][root][INFO] - Training Epoch: 5/10, step 6/574 completed (loss: 0.7716066241264343, acc: 0.7755101919174194)
[2024-11-29 03:19:06,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:06,678][root][INFO] - Training Epoch: 5/10, step 7/574 completed (loss: 0.19954369962215424, acc: 0.8999999761581421)
[2024-11-29 03:19:06,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:06,977][root][INFO] - Training Epoch: 5/10, step 8/574 completed (loss: 0.1954825073480606, acc: 0.9545454382896423)
[2024-11-29 03:19:07,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:07,278][root][INFO] - Training Epoch: 5/10, step 9/574 completed (loss: 0.02472670003771782, acc: 1.0)
[2024-11-29 03:19:07,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:07,538][root][INFO] - Training Epoch: 5/10, step 10/574 completed (loss: 0.06480938196182251, acc: 0.9629629850387573)
[2024-11-29 03:19:07,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:07,859][root][INFO] - Training Epoch: 5/10, step 11/574 completed (loss: 0.24575966596603394, acc: 0.8974359035491943)
[2024-11-29 03:19:08,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:08,169][root][INFO] - Training Epoch: 5/10, step 12/574 completed (loss: 0.05073723942041397, acc: 1.0)
[2024-11-29 03:19:08,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:08,522][root][INFO] - Training Epoch: 5/10, step 13/574 completed (loss: 0.21140709519386292, acc: 0.9130434989929199)
[2024-11-29 03:19:08,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:08,827][root][INFO] - Training Epoch: 5/10, step 14/574 completed (loss: 0.23961468040943146, acc: 0.9607843160629272)
[2024-11-29 03:19:09,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:09,128][root][INFO] - Training Epoch: 5/10, step 15/574 completed (loss: 0.4307422637939453, acc: 0.8775510191917419)
[2024-11-29 03:19:09,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:09,456][root][INFO] - Training Epoch: 5/10, step 16/574 completed (loss: 0.04013040289282799, acc: 1.0)
[2024-11-29 03:19:09,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:09,745][root][INFO] - Training Epoch: 5/10, step 17/574 completed (loss: 0.24198804795742035, acc: 0.9583333134651184)
[2024-11-29 03:19:09,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:10,044][root][INFO] - Training Epoch: 5/10, step 18/574 completed (loss: 0.35162070393562317, acc: 0.8888888955116272)
[2024-11-29 03:19:10,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:10,319][root][INFO] - Training Epoch: 5/10, step 19/574 completed (loss: 0.35467615723609924, acc: 0.8947368264198303)
[2024-11-29 03:19:10,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:10,573][root][INFO] - Training Epoch: 5/10, step 20/574 completed (loss: 0.37068212032318115, acc: 0.9230769276618958)
[2024-11-29 03:19:10,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:10,857][root][INFO] - Training Epoch: 5/10, step 21/574 completed (loss: 0.4408693015575409, acc: 0.8620689511299133)
[2024-11-29 03:19:11,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:11,138][root][INFO] - Training Epoch: 5/10, step 22/574 completed (loss: 0.39892223477363586, acc: 0.8799999952316284)
[2024-11-29 03:19:11,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:11,442][root][INFO] - Training Epoch: 5/10, step 23/574 completed (loss: 0.22973723709583282, acc: 0.9523809552192688)
[2024-11-29 03:19:11,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:11,716][root][INFO] - Training Epoch: 5/10, step 24/574 completed (loss: 0.05839715152978897, acc: 1.0)
[2024-11-29 03:19:11,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:12,050][root][INFO] - Training Epoch: 5/10, step 25/574 completed (loss: 0.8235993981361389, acc: 0.7924528121948242)
[2024-11-29 03:19:12,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:12,347][root][INFO] - Training Epoch: 5/10, step 26/574 completed (loss: 1.1666604280471802, acc: 0.7534246444702148)
[2024-11-29 03:19:13,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:13,933][root][INFO] - Training Epoch: 5/10, step 27/574 completed (loss: 1.8776133060455322, acc: 0.5454545617103577)
[2024-11-29 03:19:14,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:14,286][root][INFO] - Training Epoch: 5/10, step 28/574 completed (loss: 0.6704144477844238, acc: 0.7674418687820435)
[2024-11-29 03:19:14,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:14,593][root][INFO] - Training Epoch: 5/10, step 29/574 completed (loss: 0.7449242472648621, acc: 0.7831325531005859)
[2024-11-29 03:19:14,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:14,896][root][INFO] - Training Epoch: 5/10, step 30/574 completed (loss: 0.7379843592643738, acc: 0.8271604776382446)
[2024-11-29 03:19:15,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:15,205][root][INFO] - Training Epoch: 5/10, step 31/574 completed (loss: 0.5505375862121582, acc: 0.8214285969734192)
[2024-11-29 03:19:15,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:15,472][root][INFO] - Training Epoch: 5/10, step 32/574 completed (loss: 0.36109718680381775, acc: 0.8888888955116272)
[2024-11-29 03:19:15,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:15,755][root][INFO] - Training Epoch: 5/10, step 33/574 completed (loss: 0.18164180219173431, acc: 0.9130434989929199)
[2024-11-29 03:19:15,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:16,051][root][INFO] - Training Epoch: 5/10, step 34/574 completed (loss: 0.6039396524429321, acc: 0.848739504814148)
[2024-11-29 03:19:16,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:16,323][root][INFO] - Training Epoch: 5/10, step 35/574 completed (loss: 0.6127853393554688, acc: 0.8524590134620667)
[2024-11-29 03:19:16,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:16,656][root][INFO] - Training Epoch: 5/10, step 36/574 completed (loss: 0.5238890051841736, acc: 0.8730158805847168)
[2024-11-29 03:19:16,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:16,892][root][INFO] - Training Epoch: 5/10, step 37/574 completed (loss: 0.6702379584312439, acc: 0.8474576473236084)
[2024-11-29 03:19:17,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:17,231][root][INFO] - Training Epoch: 5/10, step 38/574 completed (loss: 0.3826525807380676, acc: 0.8735632300376892)
[2024-11-29 03:19:17,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:17,552][root][INFO] - Training Epoch: 5/10, step 39/574 completed (loss: 0.6000550985336304, acc: 0.8571428656578064)
[2024-11-29 03:19:17,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:17,855][root][INFO] - Training Epoch: 5/10, step 40/574 completed (loss: 0.6483331322669983, acc: 0.8461538553237915)
[2024-11-29 03:19:18,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:18,249][root][INFO] - Training Epoch: 5/10, step 41/574 completed (loss: 0.4134159982204437, acc: 0.8648648858070374)
[2024-11-29 03:19:18,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:18,605][root][INFO] - Training Epoch: 5/10, step 42/574 completed (loss: 0.9061203598976135, acc: 0.7076923251152039)
[2024-11-29 03:19:18,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:19,073][root][INFO] - Training Epoch: 5/10, step 43/574 completed (loss: 0.807576060295105, acc: 0.7878788113594055)
[2024-11-29 03:19:19,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:19,546][root][INFO] - Training Epoch: 5/10, step 44/574 completed (loss: 0.657814621925354, acc: 0.7938144207000732)
[2024-11-29 03:19:19,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:19,981][root][INFO] - Training Epoch: 5/10, step 45/574 completed (loss: 0.6857823133468628, acc: 0.8014705777168274)
[2024-11-29 03:19:20,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:20,227][root][INFO] - Training Epoch: 5/10, step 46/574 completed (loss: 0.40377169847488403, acc: 0.8846153616905212)
[2024-11-29 03:19:20,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:20,479][root][INFO] - Training Epoch: 5/10, step 47/574 completed (loss: 0.05773802474141121, acc: 1.0)
[2024-11-29 03:19:20,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:20,781][root][INFO] - Training Epoch: 5/10, step 48/574 completed (loss: 0.2604624629020691, acc: 0.9642857313156128)
[2024-11-29 03:19:20,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:21,104][root][INFO] - Training Epoch: 5/10, step 49/574 completed (loss: 0.2938648760318756, acc: 0.9166666865348816)
[2024-11-29 03:19:21,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:21,458][root][INFO] - Training Epoch: 5/10, step 50/574 completed (loss: 0.7644777297973633, acc: 0.7543859481811523)
[2024-11-29 03:19:21,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:21,745][root][INFO] - Training Epoch: 5/10, step 51/574 completed (loss: 0.8098770380020142, acc: 0.7460317611694336)
[2024-11-29 03:19:21,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:22,051][root][INFO] - Training Epoch: 5/10, step 52/574 completed (loss: 0.9149472713470459, acc: 0.7605633735656738)
[2024-11-29 03:19:22,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:22,587][root][INFO] - Training Epoch: 5/10, step 53/574 completed (loss: 1.6558221578598022, acc: 0.5666666626930237)
[2024-11-29 03:19:22,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:22,902][root][INFO] - Training Epoch: 5/10, step 54/574 completed (loss: 0.7553513646125793, acc: 0.837837815284729)
[2024-11-29 03:19:23,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:23,207][root][INFO] - Training Epoch: 5/10, step 55/574 completed (loss: 0.13285666704177856, acc: 0.9615384340286255)
[2024-11-29 03:19:25,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:27,122][root][INFO] - Training Epoch: 5/10, step 56/574 completed (loss: 1.5240051746368408, acc: 0.6279863715171814)
[2024-11-29 03:19:28,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:28,853][root][INFO] - Training Epoch: 5/10, step 57/574 completed (loss: 1.5955626964569092, acc: 0.5882353186607361)
[2024-11-29 03:19:29,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:29,679][root][INFO] - Training Epoch: 5/10, step 58/574 completed (loss: 0.8476116061210632, acc: 0.7329545617103577)
[2024-11-29 03:19:30,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:30,444][root][INFO] - Training Epoch: 5/10, step 59/574 completed (loss: 0.6161418557167053, acc: 0.8235294222831726)
[2024-11-29 03:19:30,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:31,184][root][INFO] - Training Epoch: 5/10, step 60/574 completed (loss: 0.960488498210907, acc: 0.7318840622901917)
[2024-11-29 03:19:31,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:31,665][root][INFO] - Training Epoch: 5/10, step 61/574 completed (loss: 0.9950937032699585, acc: 0.762499988079071)
[2024-11-29 03:19:31,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:31,976][root][INFO] - Training Epoch: 5/10, step 62/574 completed (loss: 0.2718775272369385, acc: 0.9411764740943909)
[2024-11-29 03:19:32,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:32,318][root][INFO] - Training Epoch: 5/10, step 63/574 completed (loss: 0.11825084686279297, acc: 0.9722222089767456)
[2024-11-29 03:19:32,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:32,687][root][INFO] - Training Epoch: 5/10, step 64/574 completed (loss: 0.2513250708580017, acc: 0.9375)
[2024-11-29 03:19:32,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:33,022][root][INFO] - Training Epoch: 5/10, step 65/574 completed (loss: 0.3025399148464203, acc: 0.8965517282485962)
[2024-11-29 03:19:33,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:33,344][root][INFO] - Training Epoch: 5/10, step 66/574 completed (loss: 0.7279082536697388, acc: 0.8392857313156128)
[2024-11-29 03:19:33,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:33,700][root][INFO] - Training Epoch: 5/10, step 67/574 completed (loss: 0.5518472790718079, acc: 0.8500000238418579)
[2024-11-29 03:19:33,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:33,988][root][INFO] - Training Epoch: 5/10, step 68/574 completed (loss: 0.02945847250521183, acc: 1.0)
[2024-11-29 03:19:34,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:34,265][root][INFO] - Training Epoch: 5/10, step 69/574 completed (loss: 0.43738120794296265, acc: 0.8611111044883728)
[2024-11-29 03:19:34,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:34,536][root][INFO] - Training Epoch: 5/10, step 70/574 completed (loss: 0.5474892258644104, acc: 0.8484848737716675)
[2024-11-29 03:19:34,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:34,847][root][INFO] - Training Epoch: 5/10, step 71/574 completed (loss: 1.3672451972961426, acc: 0.6470588445663452)
[2024-11-29 03:19:35,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:35,153][root][INFO] - Training Epoch: 5/10, step 72/574 completed (loss: 0.9060366153717041, acc: 0.7539682388305664)
[2024-11-29 03:19:35,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:35,457][root][INFO] - Training Epoch: 5/10, step 73/574 completed (loss: 1.734032392501831, acc: 0.5435897707939148)
[2024-11-29 03:19:35,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:35,784][root][INFO] - Training Epoch: 5/10, step 74/574 completed (loss: 1.1371026039123535, acc: 0.704081654548645)
[2024-11-29 03:19:35,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:36,097][root][INFO] - Training Epoch: 5/10, step 75/574 completed (loss: 1.2236055135726929, acc: 0.6940298676490784)
[2024-11-29 03:19:36,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:36,503][root][INFO] - Training Epoch: 5/10, step 76/574 completed (loss: 1.8028165102005005, acc: 0.4781021773815155)
[2024-11-29 03:19:36,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:36,754][root][INFO] - Training Epoch: 5/10, step 77/574 completed (loss: 0.02289390191435814, acc: 1.0)
[2024-11-29 03:19:36,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:37,037][root][INFO] - Training Epoch: 5/10, step 78/574 completed (loss: 0.13382545113563538, acc: 1.0)
[2024-11-29 03:19:37,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:37,323][root][INFO] - Training Epoch: 5/10, step 79/574 completed (loss: 0.12248605489730835, acc: 0.9696969985961914)
[2024-11-29 03:19:37,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:37,632][root][INFO] - Training Epoch: 5/10, step 80/574 completed (loss: 0.19316188991069794, acc: 0.8846153616905212)
[2024-11-29 03:19:37,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:37,956][root][INFO] - Training Epoch: 5/10, step 81/574 completed (loss: 0.5066674947738647, acc: 0.8461538553237915)
[2024-11-29 03:19:38,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:38,260][root][INFO] - Training Epoch: 5/10, step 82/574 completed (loss: 0.7625446319580078, acc: 0.7692307829856873)
[2024-11-29 03:19:38,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:38,539][root][INFO] - Training Epoch: 5/10, step 83/574 completed (loss: 0.14900459349155426, acc: 0.9375)
[2024-11-29 03:19:38,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:38,836][root][INFO] - Training Epoch: 5/10, step 84/574 completed (loss: 0.4587644338607788, acc: 0.8840579986572266)
[2024-11-29 03:19:38,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:39,116][root][INFO] - Training Epoch: 5/10, step 85/574 completed (loss: 0.5923912525177002, acc: 0.8199999928474426)
[2024-11-29 03:19:39,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:39,414][root][INFO] - Training Epoch: 5/10, step 86/574 completed (loss: 0.1630004644393921, acc: 1.0)
[2024-11-29 03:19:39,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:40,005][root][INFO] - Training Epoch: 5/10, step 87/574 completed (loss: 1.074758529663086, acc: 0.7599999904632568)
[2024-11-29 03:19:40,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:40,349][root][INFO] - Training Epoch: 5/10, step 88/574 completed (loss: 1.154868245124817, acc: 0.6893203854560852)
[2024-11-29 03:19:41,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:41,992][root][INFO] - Training Epoch: 5/10, step 89/574 completed (loss: 1.1513941287994385, acc: 0.708737850189209)
[2024-11-29 03:19:42,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:43,150][root][INFO] - Training Epoch: 5/10, step 90/574 completed (loss: 1.5936925411224365, acc: 0.5645161271095276)
[2024-11-29 03:19:43,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:44,277][root][INFO] - Training Epoch: 5/10, step 91/574 completed (loss: 1.2285586595535278, acc: 0.693965494632721)
[2024-11-29 03:19:44,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:45,320][root][INFO] - Training Epoch: 5/10, step 92/574 completed (loss: 0.9529293775558472, acc: 0.7368420958518982)
[2024-11-29 03:19:46,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:46,776][root][INFO] - Training Epoch: 5/10, step 93/574 completed (loss: 1.7772895097732544, acc: 0.5544554591178894)
[2024-11-29 03:19:47,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:47,146][root][INFO] - Training Epoch: 5/10, step 94/574 completed (loss: 1.0068916082382202, acc: 0.7903226017951965)
[2024-11-29 03:19:47,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:47,531][root][INFO] - Training Epoch: 5/10, step 95/574 completed (loss: 0.8238170146942139, acc: 0.7536231875419617)
[2024-11-29 03:19:47,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:47,870][root][INFO] - Training Epoch: 5/10, step 96/574 completed (loss: 1.328890085220337, acc: 0.5630252361297607)
[2024-11-29 03:19:48,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:48,236][root][INFO] - Training Epoch: 5/10, step 97/574 completed (loss: 1.5342351198196411, acc: 0.5288461446762085)
[2024-11-29 03:19:48,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:48,637][root][INFO] - Training Epoch: 5/10, step 98/574 completed (loss: 1.6356496810913086, acc: 0.5912408828735352)
[2024-11-29 03:19:48,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:48,956][root][INFO] - Training Epoch: 5/10, step 99/574 completed (loss: 1.488115668296814, acc: 0.611940324306488)
[2024-11-29 03:19:49,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:49,271][root][INFO] - Training Epoch: 5/10, step 100/574 completed (loss: 0.5985630750656128, acc: 0.8500000238418579)
[2024-11-29 03:19:49,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:49,550][root][INFO] - Training Epoch: 5/10, step 101/574 completed (loss: 0.030589597299695015, acc: 1.0)
[2024-11-29 03:19:49,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:49,813][root][INFO] - Training Epoch: 5/10, step 102/574 completed (loss: 0.03723554685711861, acc: 1.0)
[2024-11-29 03:19:49,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:50,081][root][INFO] - Training Epoch: 5/10, step 103/574 completed (loss: 0.038689032196998596, acc: 1.0)
[2024-11-29 03:19:50,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:50,396][root][INFO] - Training Epoch: 5/10, step 104/574 completed (loss: 0.4922548532485962, acc: 0.8793103694915771)
[2024-11-29 03:19:50,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:50,695][root][INFO] - Training Epoch: 5/10, step 105/574 completed (loss: 0.1859893798828125, acc: 0.9069767594337463)
[2024-11-29 03:19:50,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:50,996][root][INFO] - Training Epoch: 5/10, step 106/574 completed (loss: 0.1799466907978058, acc: 0.9200000166893005)
[2024-11-29 03:19:51,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:51,279][root][INFO] - Training Epoch: 5/10, step 107/574 completed (loss: 0.016420360654592514, acc: 1.0)
[2024-11-29 03:19:51,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:51,553][root][INFO] - Training Epoch: 5/10, step 108/574 completed (loss: 0.01228058710694313, acc: 1.0)
[2024-11-29 03:19:51,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:51,840][root][INFO] - Training Epoch: 5/10, step 109/574 completed (loss: 0.19075247645378113, acc: 0.9523809552192688)
[2024-11-29 03:19:52,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:52,141][root][INFO] - Training Epoch: 5/10, step 110/574 completed (loss: 0.311003714799881, acc: 0.9076923131942749)
[2024-11-29 03:19:52,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:52,586][root][INFO] - Training Epoch: 5/10, step 111/574 completed (loss: 0.4532676637172699, acc: 0.859649121761322)
[2024-11-29 03:19:52,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:52,941][root][INFO] - Training Epoch: 5/10, step 112/574 completed (loss: 0.7582716941833496, acc: 0.7894737124443054)
[2024-11-29 03:19:53,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:53,268][root][INFO] - Training Epoch: 5/10, step 113/574 completed (loss: 0.3260557949542999, acc: 0.9487179517745972)
[2024-11-29 03:19:53,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:53,664][root][INFO] - Training Epoch: 5/10, step 114/574 completed (loss: 0.29806414246559143, acc: 0.8775510191917419)
[2024-11-29 03:19:53,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:53,973][root][INFO] - Training Epoch: 5/10, step 115/574 completed (loss: 0.05459786579012871, acc: 1.0)
[2024-11-29 03:19:54,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:54,293][root][INFO] - Training Epoch: 5/10, step 116/574 completed (loss: 0.686614990234375, acc: 0.841269850730896)
[2024-11-29 03:19:54,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:54,657][root][INFO] - Training Epoch: 5/10, step 117/574 completed (loss: 0.6025473475456238, acc: 0.8373983502388)
[2024-11-29 03:19:54,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:55,021][root][INFO] - Training Epoch: 5/10, step 118/574 completed (loss: 0.2293367236852646, acc: 0.9516128897666931)
[2024-11-29 03:19:55,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:56,232][root][INFO] - Training Epoch: 5/10, step 119/574 completed (loss: 1.1481519937515259, acc: 0.7034220695495605)
[2024-11-29 03:19:56,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:56,525][root][INFO] - Training Epoch: 5/10, step 120/574 completed (loss: 0.2977235019207001, acc: 0.9066666960716248)
[2024-11-29 03:19:56,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:56,973][root][INFO] - Training Epoch: 5/10, step 121/574 completed (loss: 0.3751028776168823, acc: 0.8846153616905212)
[2024-11-29 03:19:57,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:57,310][root][INFO] - Training Epoch: 5/10, step 122/574 completed (loss: 0.09190104156732559, acc: 0.9583333134651184)
[2024-11-29 03:19:57,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:57,610][root][INFO] - Training Epoch: 5/10, step 123/574 completed (loss: 0.6489924192428589, acc: 0.8421052694320679)
[2024-11-29 03:19:57,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:57,974][root][INFO] - Training Epoch: 5/10, step 124/574 completed (loss: 1.370131492614746, acc: 0.6564416885375977)
[2024-11-29 03:19:58,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:58,320][root][INFO] - Training Epoch: 5/10, step 125/574 completed (loss: 1.426760196685791, acc: 0.6180555820465088)
[2024-11-29 03:19:58,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:58,671][root][INFO] - Training Epoch: 5/10, step 126/574 completed (loss: 1.1976577043533325, acc: 0.6583333611488342)
[2024-11-29 03:19:58,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:59,007][root][INFO] - Training Epoch: 5/10, step 127/574 completed (loss: 1.3643661737442017, acc: 0.601190447807312)
[2024-11-29 03:19:59,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:59,316][root][INFO] - Training Epoch: 5/10, step 128/574 completed (loss: 1.2287886142730713, acc: 0.6461538672447205)
[2024-11-29 03:19:59,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:19:59,759][root][INFO] - Training Epoch: 5/10, step 129/574 completed (loss: 1.270165205001831, acc: 0.6764705777168274)
[2024-11-29 03:19:59,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:00,041][root][INFO] - Training Epoch: 5/10, step 130/574 completed (loss: 0.4618004262447357, acc: 0.7692307829856873)
[2024-11-29 03:20:00,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:00,293][root][INFO] - Training Epoch: 5/10, step 131/574 completed (loss: 0.5488426089286804, acc: 0.9130434989929199)
[2024-11-29 03:20:00,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:00,586][root][INFO] - Training Epoch: 5/10, step 132/574 completed (loss: 1.1685776710510254, acc: 0.71875)
[2024-11-29 03:20:00,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:00,916][root][INFO] - Training Epoch: 5/10, step 133/574 completed (loss: 0.42079249024391174, acc: 0.8260869383811951)
[2024-11-29 03:20:01,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:01,209][root][INFO] - Training Epoch: 5/10, step 134/574 completed (loss: 0.5085679888725281, acc: 0.8285714387893677)
[2024-11-29 03:20:02,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:02,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:02,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:03,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:03,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:04,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:04,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:05,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:05,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:05,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:06,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:06,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:07,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:07,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:08,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:08,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:09,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:09,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:10,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:10,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:10,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:11,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:11,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:12,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:12,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:13,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:13,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:14,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:14,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:15,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:15,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:16,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:16,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:17,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:17,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:18,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:18,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:18,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:19,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:19,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:20,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:20,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:20,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:21,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:21,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:22,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:22,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:23,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:23,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:23,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:24,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:24,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:24,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:25,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:25,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:26,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:26,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:27,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:27,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:28,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:28,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:29,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:30,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:30,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:30,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:31,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:31,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:32,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:32,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:33,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:33,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:34,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:34,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:35,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:35,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:35,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:36,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:36,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:36,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:37,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:37,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:37,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:38,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:38,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:39,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:39,803][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.8762, device='cuda:0') eval_epoch_loss=tensor(1.0565, device='cuda:0') eval_epoch_acc=tensor(0.7431, device='cuda:0')
[2024-11-29 03:20:39,804][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:20:39,804][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:20:40,084][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_5_step_135_loss_1.0564724206924438/model.pt
[2024-11-29 03:20:40,088][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 5 is 1.0564724206924438
[2024-11-29 03:20:40,089][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 5 is 0.7430768013000488
[2024-11-29 03:20:40,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:40,425][root][INFO] - Training Epoch: 5/10, step 135/574 completed (loss: 0.3070600628852844, acc: 0.9230769276618958)
[2024-11-29 03:20:40,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:40,694][root][INFO] - Training Epoch: 5/10, step 136/574 completed (loss: 0.6161348223686218, acc: 0.8809523582458496)
[2024-11-29 03:20:40,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:40,974][root][INFO] - Training Epoch: 5/10, step 137/574 completed (loss: 1.3580213785171509, acc: 0.7333333492279053)
[2024-11-29 03:20:41,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:41,255][root][INFO] - Training Epoch: 5/10, step 138/574 completed (loss: 0.23972637951374054, acc: 0.9130434989929199)
[2024-11-29 03:20:41,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:41,534][root][INFO] - Training Epoch: 5/10, step 139/574 completed (loss: 0.21956586837768555, acc: 0.9523809552192688)
[2024-11-29 03:20:41,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:41,871][root][INFO] - Training Epoch: 5/10, step 140/574 completed (loss: 0.11770470440387726, acc: 1.0)
[2024-11-29 03:20:42,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:42,215][root][INFO] - Training Epoch: 5/10, step 141/574 completed (loss: 0.4126081168651581, acc: 0.8064516186714172)
[2024-11-29 03:20:42,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:42,523][root][INFO] - Training Epoch: 5/10, step 142/574 completed (loss: 0.24284906685352325, acc: 0.9459459185600281)
[2024-11-29 03:20:42,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:43,217][root][INFO] - Training Epoch: 5/10, step 143/574 completed (loss: 0.6963726282119751, acc: 0.780701756477356)
[2024-11-29 03:20:43,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:43,560][root][INFO] - Training Epoch: 5/10, step 144/574 completed (loss: 0.957664966583252, acc: 0.7089552283287048)
[2024-11-29 03:20:43,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:43,910][root][INFO] - Training Epoch: 5/10, step 145/574 completed (loss: 0.7049152851104736, acc: 0.795918345451355)
[2024-11-29 03:20:44,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:44,461][root][INFO] - Training Epoch: 5/10, step 146/574 completed (loss: 0.9426956176757812, acc: 0.7127659320831299)
[2024-11-29 03:20:44,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:44,743][root][INFO] - Training Epoch: 5/10, step 147/574 completed (loss: 0.8900470733642578, acc: 0.6857143044471741)
[2024-11-29 03:20:44,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:45,032][root][INFO] - Training Epoch: 5/10, step 148/574 completed (loss: 0.29143598675727844, acc: 0.9285714030265808)
[2024-11-29 03:20:45,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:45,325][root][INFO] - Training Epoch: 5/10, step 149/574 completed (loss: 0.518125593662262, acc: 0.8260869383811951)
[2024-11-29 03:20:45,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:45,605][root][INFO] - Training Epoch: 5/10, step 150/574 completed (loss: 0.3783347010612488, acc: 0.931034505367279)
[2024-11-29 03:20:45,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:45,918][root][INFO] - Training Epoch: 5/10, step 151/574 completed (loss: 0.7298324704170227, acc: 0.8260869383811951)
[2024-11-29 03:20:46,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:46,205][root][INFO] - Training Epoch: 5/10, step 152/574 completed (loss: 0.7183407545089722, acc: 0.7796609997749329)
[2024-11-29 03:20:46,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:46,519][root][INFO] - Training Epoch: 5/10, step 153/574 completed (loss: 0.9705950021743774, acc: 0.7368420958518982)
[2024-11-29 03:20:46,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:46,805][root][INFO] - Training Epoch: 5/10, step 154/574 completed (loss: 0.726416826248169, acc: 0.8108108043670654)
[2024-11-29 03:20:46,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:47,088][root][INFO] - Training Epoch: 5/10, step 155/574 completed (loss: 0.23684802651405334, acc: 0.9642857313156128)
[2024-11-29 03:20:47,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:47,315][root][INFO] - Training Epoch: 5/10, step 156/574 completed (loss: 0.8912128806114197, acc: 0.695652186870575)
[2024-11-29 03:20:47,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:47,606][root][INFO] - Training Epoch: 5/10, step 157/574 completed (loss: 2.830744504928589, acc: 0.31578946113586426)
[2024-11-29 03:20:49,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:50,108][root][INFO] - Training Epoch: 5/10, step 158/574 completed (loss: 1.8951302766799927, acc: 0.5135135054588318)
[2024-11-29 03:20:50,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:50,363][root][INFO] - Training Epoch: 5/10, step 159/574 completed (loss: 1.936447262763977, acc: 0.4444444477558136)
[2024-11-29 03:20:50,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:50,833][root][INFO] - Training Epoch: 5/10, step 160/574 completed (loss: 1.7980095148086548, acc: 0.5348837375640869)
[2024-11-29 03:20:51,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:51,654][root][INFO] - Training Epoch: 5/10, step 161/574 completed (loss: 1.8596857786178589, acc: 0.529411792755127)
[2024-11-29 03:20:52,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:52,412][root][INFO] - Training Epoch: 5/10, step 162/574 completed (loss: 1.7162458896636963, acc: 0.584269642829895)
[2024-11-29 03:20:52,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:52,679][root][INFO] - Training Epoch: 5/10, step 163/574 completed (loss: 0.43504220247268677, acc: 0.8636363744735718)
[2024-11-29 03:20:52,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:52,952][root][INFO] - Training Epoch: 5/10, step 164/574 completed (loss: 0.3847476541996002, acc: 0.8571428656578064)
[2024-11-29 03:20:53,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:53,207][root][INFO] - Training Epoch: 5/10, step 165/574 completed (loss: 1.4572371244430542, acc: 0.6206896305084229)
[2024-11-29 03:20:53,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:53,485][root][INFO] - Training Epoch: 5/10, step 166/574 completed (loss: 0.2306782603263855, acc: 0.8979591727256775)
[2024-11-29 03:20:53,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:53,767][root][INFO] - Training Epoch: 5/10, step 167/574 completed (loss: 0.3585963845252991, acc: 0.9200000166893005)
[2024-11-29 03:20:54,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:54,218][root][INFO] - Training Epoch: 5/10, step 168/574 completed (loss: 0.5051446557044983, acc: 0.8472222089767456)
[2024-11-29 03:20:54,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:54,532][root][INFO] - Training Epoch: 5/10, step 169/574 completed (loss: 1.230189323425293, acc: 0.6960784196853638)
[2024-11-29 03:20:55,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:56,073][root][INFO] - Training Epoch: 5/10, step 170/574 completed (loss: 1.5066405534744263, acc: 0.6438356041908264)
[2024-11-29 03:20:56,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:56,350][root][INFO] - Training Epoch: 5/10, step 171/574 completed (loss: 0.3472275733947754, acc: 0.9583333134651184)
[2024-11-29 03:20:56,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:56,642][root][INFO] - Training Epoch: 5/10, step 172/574 completed (loss: 1.0177115201950073, acc: 0.7407407164573669)
[2024-11-29 03:20:56,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:56,969][root][INFO] - Training Epoch: 5/10, step 173/574 completed (loss: 0.2420807182788849, acc: 0.8928571343421936)
[2024-11-29 03:20:57,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:57,692][root][INFO] - Training Epoch: 5/10, step 174/574 completed (loss: 1.4426554441452026, acc: 0.6460176706314087)
[2024-11-29 03:20:57,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:58,016][root][INFO] - Training Epoch: 5/10, step 175/574 completed (loss: 0.8515229821205139, acc: 0.7971014380455017)
[2024-11-29 03:20:58,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:58,368][root][INFO] - Training Epoch: 5/10, step 176/574 completed (loss: 0.5512498021125793, acc: 0.8409090638160706)
[2024-11-29 03:20:59,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:20:59,720][root][INFO] - Training Epoch: 5/10, step 177/574 completed (loss: 1.4525998830795288, acc: 0.6259542107582092)
[2024-11-29 03:21:00,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:00,663][root][INFO] - Training Epoch: 5/10, step 178/574 completed (loss: 1.1106421947479248, acc: 0.6814814805984497)
[2024-11-29 03:21:00,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:00,924][root][INFO] - Training Epoch: 5/10, step 179/574 completed (loss: 0.3135308027267456, acc: 0.8852459192276001)
[2024-11-29 03:21:01,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:01,251][root][INFO] - Training Epoch: 5/10, step 180/574 completed (loss: 0.025129711255431175, acc: 1.0)
[2024-11-29 03:21:01,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:01,593][root][INFO] - Training Epoch: 5/10, step 181/574 completed (loss: 0.06940283626317978, acc: 1.0)
[2024-11-29 03:21:01,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:01,889][root][INFO] - Training Epoch: 5/10, step 182/574 completed (loss: 0.06093057990074158, acc: 1.0)
[2024-11-29 03:21:02,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:02,218][root][INFO] - Training Epoch: 5/10, step 183/574 completed (loss: 0.2497614622116089, acc: 0.9512194991111755)
[2024-11-29 03:21:02,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:02,562][root][INFO] - Training Epoch: 5/10, step 184/574 completed (loss: 0.8759874701499939, acc: 0.7945619225502014)
[2024-11-29 03:21:02,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:02,885][root][INFO] - Training Epoch: 5/10, step 185/574 completed (loss: 1.0910680294036865, acc: 0.680115282535553)
[2024-11-29 03:21:03,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:03,490][root][INFO] - Training Epoch: 5/10, step 186/574 completed (loss: 0.9461420178413391, acc: 0.7281249761581421)
[2024-11-29 03:21:03,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:04,127][root][INFO] - Training Epoch: 5/10, step 187/574 completed (loss: 1.2039064168930054, acc: 0.707317054271698)
[2024-11-29 03:21:04,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:04,573][root][INFO] - Training Epoch: 5/10, step 188/574 completed (loss: 0.8362639546394348, acc: 0.7651245594024658)
[2024-11-29 03:21:04,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:04,914][root][INFO] - Training Epoch: 5/10, step 189/574 completed (loss: 0.36621177196502686, acc: 0.8399999737739563)
[2024-11-29 03:21:05,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:05,670][root][INFO] - Training Epoch: 5/10, step 190/574 completed (loss: 1.1372259855270386, acc: 0.7209302186965942)
[2024-11-29 03:21:06,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:06,839][root][INFO] - Training Epoch: 5/10, step 191/574 completed (loss: 1.7231265306472778, acc: 0.5476190447807312)
[2024-11-29 03:21:07,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:08,215][root][INFO] - Training Epoch: 5/10, step 192/574 completed (loss: 1.6472936868667603, acc: 0.5681818127632141)
[2024-11-29 03:21:08,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:09,297][root][INFO] - Training Epoch: 5/10, step 193/574 completed (loss: 0.8661395907402039, acc: 0.7529411911964417)
[2024-11-29 03:21:10,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:10,939][root][INFO] - Training Epoch: 5/10, step 194/574 completed (loss: 1.2827037572860718, acc: 0.6419752836227417)
[2024-11-29 03:21:11,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:12,376][root][INFO] - Training Epoch: 5/10, step 195/574 completed (loss: 0.4887521266937256, acc: 0.8064516186714172)
[2024-11-29 03:21:12,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:12,622][root][INFO] - Training Epoch: 5/10, step 196/574 completed (loss: 0.05152854695916176, acc: 0.9642857313156128)
[2024-11-29 03:21:12,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:12,885][root][INFO] - Training Epoch: 5/10, step 197/574 completed (loss: 0.5754953622817993, acc: 0.875)
[2024-11-29 03:21:13,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:13,229][root][INFO] - Training Epoch: 5/10, step 198/574 completed (loss: 0.7029984593391418, acc: 0.7941176295280457)
[2024-11-29 03:21:13,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:13,532][root][INFO] - Training Epoch: 5/10, step 199/574 completed (loss: 1.4087356328964233, acc: 0.6911764740943909)
[2024-11-29 03:21:13,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:13,873][root][INFO] - Training Epoch: 5/10, step 200/574 completed (loss: 1.187901496887207, acc: 0.6864407062530518)
[2024-11-29 03:21:14,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:14,190][root][INFO] - Training Epoch: 5/10, step 201/574 completed (loss: 1.132726788520813, acc: 0.7014925479888916)
[2024-11-29 03:21:14,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:14,508][root][INFO] - Training Epoch: 5/10, step 202/574 completed (loss: 1.0758980512619019, acc: 0.708737850189209)
[2024-11-29 03:21:14,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:14,848][root][INFO] - Training Epoch: 5/10, step 203/574 completed (loss: 0.7452867031097412, acc: 0.7142857313156128)
[2024-11-29 03:21:15,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:15,148][root][INFO] - Training Epoch: 5/10, step 204/574 completed (loss: 0.18611404299736023, acc: 0.9450549483299255)
[2024-11-29 03:21:15,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:15,457][root][INFO] - Training Epoch: 5/10, step 205/574 completed (loss: 0.5553587675094604, acc: 0.834080696105957)
[2024-11-29 03:21:15,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:15,894][root][INFO] - Training Epoch: 5/10, step 206/574 completed (loss: 0.7478052377700806, acc: 0.7716535329818726)
[2024-11-29 03:21:16,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:16,187][root][INFO] - Training Epoch: 5/10, step 207/574 completed (loss: 0.524091899394989, acc: 0.8620689511299133)
[2024-11-29 03:21:16,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:16,528][root][INFO] - Training Epoch: 5/10, step 208/574 completed (loss: 0.6149702668190002, acc: 0.8405796885490417)
[2024-11-29 03:21:16,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:16,900][root][INFO] - Training Epoch: 5/10, step 209/574 completed (loss: 0.5654245018959045, acc: 0.8249027132987976)
[2024-11-29 03:21:17,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:17,208][root][INFO] - Training Epoch: 5/10, step 210/574 completed (loss: 0.5098785161972046, acc: 0.8478260636329651)
[2024-11-29 03:21:17,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:17,470][root][INFO] - Training Epoch: 5/10, step 211/574 completed (loss: 0.204913929104805, acc: 0.9130434989929199)
[2024-11-29 03:21:17,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:17,766][root][INFO] - Training Epoch: 5/10, step 212/574 completed (loss: 0.14264672994613647, acc: 0.9642857313156128)
[2024-11-29 03:21:17,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:18,051][root][INFO] - Training Epoch: 5/10, step 213/574 completed (loss: 0.48138195276260376, acc: 0.8723404407501221)
[2024-11-29 03:21:18,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:19,020][root][INFO] - Training Epoch: 5/10, step 214/574 completed (loss: 0.3082875907421112, acc: 0.9230769276618958)
[2024-11-29 03:21:19,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:19,369][root][INFO] - Training Epoch: 5/10, step 215/574 completed (loss: 0.3122926652431488, acc: 0.9324324131011963)
[2024-11-29 03:21:19,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:19,674][root][INFO] - Training Epoch: 5/10, step 216/574 completed (loss: 0.18912261724472046, acc: 0.9534883499145508)
[2024-11-29 03:21:20,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:20,387][root][INFO] - Training Epoch: 5/10, step 217/574 completed (loss: 0.3455519676208496, acc: 0.9009009003639221)
[2024-11-29 03:21:20,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:20,835][root][INFO] - Training Epoch: 5/10, step 218/574 completed (loss: 0.3722400367259979, acc: 0.8666666746139526)
[2024-11-29 03:21:21,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:21,118][root][INFO] - Training Epoch: 5/10, step 219/574 completed (loss: 0.17434684932231903, acc: 0.939393937587738)
[2024-11-29 03:21:21,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:21,405][root][INFO] - Training Epoch: 5/10, step 220/574 completed (loss: 0.10246666520833969, acc: 0.9259259104728699)
[2024-11-29 03:21:21,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:21,698][root][INFO] - Training Epoch: 5/10, step 221/574 completed (loss: 0.346456378698349, acc: 0.8799999952316284)
[2024-11-29 03:21:21,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:22,026][root][INFO] - Training Epoch: 5/10, step 222/574 completed (loss: 0.7610471248626709, acc: 0.807692289352417)
[2024-11-29 03:21:22,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:23,098][root][INFO] - Training Epoch: 5/10, step 223/574 completed (loss: 0.5439485311508179, acc: 0.8695651888847351)
[2024-11-29 03:21:23,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:23,818][root][INFO] - Training Epoch: 5/10, step 224/574 completed (loss: 0.8240709900856018, acc: 0.7954545617103577)
[2024-11-29 03:21:24,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:24,356][root][INFO] - Training Epoch: 5/10, step 225/574 completed (loss: 0.8230738639831543, acc: 0.7553191781044006)
[2024-11-29 03:21:24,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:24,704][root][INFO] - Training Epoch: 5/10, step 226/574 completed (loss: 0.5646612644195557, acc: 0.8301886916160583)
[2024-11-29 03:21:24,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:25,054][root][INFO] - Training Epoch: 5/10, step 227/574 completed (loss: 0.31447455286979675, acc: 0.9333333373069763)
[2024-11-29 03:21:25,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:25,367][root][INFO] - Training Epoch: 5/10, step 228/574 completed (loss: 0.9652944803237915, acc: 0.7441860437393188)
[2024-11-29 03:21:25,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:25,701][root][INFO] - Training Epoch: 5/10, step 229/574 completed (loss: 2.383281946182251, acc: 0.4333333373069763)
[2024-11-29 03:21:25,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:26,076][root][INFO] - Training Epoch: 5/10, step 230/574 completed (loss: 2.7244300842285156, acc: 0.3684210479259491)
[2024-11-29 03:21:26,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:26,356][root][INFO] - Training Epoch: 5/10, step 231/574 completed (loss: 1.9258863925933838, acc: 0.5)
[2024-11-29 03:21:26,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:26,861][root][INFO] - Training Epoch: 5/10, step 232/574 completed (loss: 2.0536556243896484, acc: 0.5)
[2024-11-29 03:21:27,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:27,491][root][INFO] - Training Epoch: 5/10, step 233/574 completed (loss: 2.37567400932312, acc: 0.44495412707328796)
[2024-11-29 03:21:27,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:28,091][root][INFO] - Training Epoch: 5/10, step 234/574 completed (loss: 2.122331142425537, acc: 0.5153846144676208)
[2024-11-29 03:21:28,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:28,332][root][INFO] - Training Epoch: 5/10, step 235/574 completed (loss: 0.23128293454647064, acc: 0.8947368264198303)
[2024-11-29 03:21:28,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:28,581][root][INFO] - Training Epoch: 5/10, step 236/574 completed (loss: 0.2804628014564514, acc: 0.9166666865348816)
[2024-11-29 03:21:28,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:28,823][root][INFO] - Training Epoch: 5/10, step 237/574 completed (loss: 0.47445347905158997, acc: 0.8636363744735718)
[2024-11-29 03:21:28,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:29,102][root][INFO] - Training Epoch: 5/10, step 238/574 completed (loss: 0.9617735743522644, acc: 0.7407407164573669)
[2024-11-29 03:21:29,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:29,398][root][INFO] - Training Epoch: 5/10, step 239/574 completed (loss: 0.6068044900894165, acc: 0.8571428656578064)
[2024-11-29 03:21:29,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:29,746][root][INFO] - Training Epoch: 5/10, step 240/574 completed (loss: 0.9834243655204773, acc: 0.7954545617103577)
[2024-11-29 03:21:29,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:30,058][root][INFO] - Training Epoch: 5/10, step 241/574 completed (loss: 0.5341556072235107, acc: 0.7954545617103577)
[2024-11-29 03:21:30,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:30,866][root][INFO] - Training Epoch: 5/10, step 242/574 completed (loss: 1.2480236291885376, acc: 0.5645161271095276)
[2024-11-29 03:21:31,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:31,582][root][INFO] - Training Epoch: 5/10, step 243/574 completed (loss: 0.9272915124893188, acc: 0.7272727489471436)
[2024-11-29 03:21:31,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:31,823][root][INFO] - Training Epoch: 5/10, step 244/574 completed (loss: 0.03742161765694618, acc: 1.0)
[2024-11-29 03:21:31,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:32,084][root][INFO] - Training Epoch: 5/10, step 245/574 completed (loss: 0.5627923607826233, acc: 0.8461538553237915)
[2024-11-29 03:21:32,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:32,330][root][INFO] - Training Epoch: 5/10, step 246/574 completed (loss: 0.2968839406967163, acc: 0.9032257795333862)
[2024-11-29 03:21:32,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:32,653][root][INFO] - Training Epoch: 5/10, step 247/574 completed (loss: 0.07924078404903412, acc: 1.0)
[2024-11-29 03:21:32,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:33,016][root][INFO] - Training Epoch: 5/10, step 248/574 completed (loss: 0.34963563084602356, acc: 0.9189189076423645)
[2024-11-29 03:21:33,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:33,332][root][INFO] - Training Epoch: 5/10, step 249/574 completed (loss: 0.3354041576385498, acc: 0.8648648858070374)
[2024-11-29 03:21:33,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:33,668][root][INFO] - Training Epoch: 5/10, step 250/574 completed (loss: 0.08842691034078598, acc: 1.0)
[2024-11-29 03:21:33,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:33,999][root][INFO] - Training Epoch: 5/10, step 251/574 completed (loss: 0.23854370415210724, acc: 0.9411764740943909)
[2024-11-29 03:21:34,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:34,298][root][INFO] - Training Epoch: 5/10, step 252/574 completed (loss: 0.06295419484376907, acc: 1.0)
[2024-11-29 03:21:34,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:34,618][root][INFO] - Training Epoch: 5/10, step 253/574 completed (loss: 0.22638481855392456, acc: 0.9599999785423279)
[2024-11-29 03:21:34,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:34,927][root][INFO] - Training Epoch: 5/10, step 254/574 completed (loss: 0.016390332952141762, acc: 1.0)
[2024-11-29 03:21:35,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:35,216][root][INFO] - Training Epoch: 5/10, step 255/574 completed (loss: 0.24577239155769348, acc: 0.9354838728904724)
[2024-11-29 03:21:35,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:35,512][root][INFO] - Training Epoch: 5/10, step 256/574 completed (loss: 0.24066954851150513, acc: 0.9473684430122375)
[2024-11-29 03:21:35,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:35,787][root][INFO] - Training Epoch: 5/10, step 257/574 completed (loss: 0.24785248935222626, acc: 0.9142857193946838)
[2024-11-29 03:21:35,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:36,101][root][INFO] - Training Epoch: 5/10, step 258/574 completed (loss: 0.18773463368415833, acc: 0.9473684430122375)
[2024-11-29 03:21:36,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:36,877][root][INFO] - Training Epoch: 5/10, step 259/574 completed (loss: 0.6177087426185608, acc: 0.8301886916160583)
[2024-11-29 03:21:37,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:37,664][root][INFO] - Training Epoch: 5/10, step 260/574 completed (loss: 0.574471116065979, acc: 0.8166666626930237)
[2024-11-29 03:21:37,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:37,987][root][INFO] - Training Epoch: 5/10, step 261/574 completed (loss: 0.1975611001253128, acc: 0.9444444179534912)
[2024-11-29 03:21:38,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:38,292][root][INFO] - Training Epoch: 5/10, step 262/574 completed (loss: 0.3058360815048218, acc: 0.9354838728904724)
[2024-11-29 03:21:38,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:38,672][root][INFO] - Training Epoch: 5/10, step 263/574 completed (loss: 1.206797480583191, acc: 0.6933333277702332)
[2024-11-29 03:21:38,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:39,031][root][INFO] - Training Epoch: 5/10, step 264/574 completed (loss: 0.7309796214103699, acc: 0.8125)
[2024-11-29 03:21:39,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:40,262][root][INFO] - Training Epoch: 5/10, step 265/574 completed (loss: 1.4706801176071167, acc: 0.5680000185966492)
[2024-11-29 03:21:40,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:40,607][root][INFO] - Training Epoch: 5/10, step 266/574 completed (loss: 1.0309962034225464, acc: 0.6966292262077332)
[2024-11-29 03:21:40,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:40,964][root][INFO] - Training Epoch: 5/10, step 267/574 completed (loss: 1.0844782590866089, acc: 0.6891891956329346)
[2024-11-29 03:21:41,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:41,531][root][INFO] - Training Epoch: 5/10, step 268/574 completed (loss: 0.817345142364502, acc: 0.7241379022598267)
[2024-11-29 03:21:41,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:41,791][root][INFO] - Training Epoch: 5/10, step 269/574 completed (loss: 0.10529118031263351, acc: 0.9545454382896423)
[2024-11-29 03:21:41,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:42,115][root][INFO] - Training Epoch: 5/10, step 270/574 completed (loss: 0.10619860142469406, acc: 0.9545454382896423)
[2024-11-29 03:21:42,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:42,419][root][INFO] - Training Epoch: 5/10, step 271/574 completed (loss: 0.07853984832763672, acc: 0.96875)
[2024-11-29 03:21:42,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:42,659][root][INFO] - Training Epoch: 5/10, step 272/574 completed (loss: 0.13153769075870514, acc: 0.9666666388511658)
[2024-11-29 03:21:42,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:43,065][root][INFO] - Training Epoch: 5/10, step 273/574 completed (loss: 0.488773912191391, acc: 0.8500000238418579)
[2024-11-29 03:21:43,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:43,365][root][INFO] - Training Epoch: 5/10, step 274/574 completed (loss: 0.11441388726234436, acc: 0.9375)
[2024-11-29 03:21:43,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:43,679][root][INFO] - Training Epoch: 5/10, step 275/574 completed (loss: 0.1266939789056778, acc: 0.9666666388511658)
[2024-11-29 03:21:43,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:44,039][root][INFO] - Training Epoch: 5/10, step 276/574 completed (loss: 0.5122490525245667, acc: 0.8965517282485962)
[2024-11-29 03:21:44,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:44,362][root][INFO] - Training Epoch: 5/10, step 277/574 completed (loss: 0.22198651731014252, acc: 0.9200000166893005)
[2024-11-29 03:21:45,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:45,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:46,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:46,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:46,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:47,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:47,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:47,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:48,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:48,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:49,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:49,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:50,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:50,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:51,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:51,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:51,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:52,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:52,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:53,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:53,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:54,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:54,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:54,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:55,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:55,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:56,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:56,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:56,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:57,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:57,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:58,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:58,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:58,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:59,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:59,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:21:59,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:00,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:00,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:01,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:01,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:01,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:02,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:02,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:03,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:03,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:03,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:04,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:04,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:05,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:05,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:05,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:06,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:06,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:07,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:07,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:08,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:08,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:09,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:09,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:09,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:10,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:11,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:11,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:11,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:12,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:12,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:13,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:13,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:14,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:14,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:14,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:15,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:15,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:16,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:16,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:16,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:17,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:17,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:17,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:18,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:18,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:18,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:19,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:20,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:20,642][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.3941, device='cuda:0') eval_epoch_loss=tensor(1.2220, device='cuda:0') eval_epoch_acc=tensor(0.7167, device='cuda:0')
[2024-11-29 03:22:20,644][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:22:20,644][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:22:20,896][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_5_step_278_loss_1.2220250368118286/model.pt
[2024-11-29 03:22:21,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:21,258][root][INFO] - Training Epoch: 5/10, step 278/574 completed (loss: 0.43381690979003906, acc: 0.8723404407501221)
[2024-11-29 03:22:21,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:21,580][root][INFO] - Training Epoch: 5/10, step 279/574 completed (loss: 0.3777420222759247, acc: 0.9166666865348816)
[2024-11-29 03:22:21,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:21,908][root][INFO] - Training Epoch: 5/10, step 280/574 completed (loss: 0.24101115763187408, acc: 0.9090909361839294)
[2024-11-29 03:22:22,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:22,395][root][INFO] - Training Epoch: 5/10, step 281/574 completed (loss: 1.2953490018844604, acc: 0.6626505851745605)
[2024-11-29 03:22:22,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:22,780][root][INFO] - Training Epoch: 5/10, step 282/574 completed (loss: 1.0519651174545288, acc: 0.7222222089767456)
[2024-11-29 03:22:22,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:23,076][root][INFO] - Training Epoch: 5/10, step 283/574 completed (loss: 0.05975494906306267, acc: 1.0)
[2024-11-29 03:22:23,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:23,369][root][INFO] - Training Epoch: 5/10, step 284/574 completed (loss: 0.2967769205570221, acc: 0.9411764740943909)
[2024-11-29 03:22:23,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:23,673][root][INFO] - Training Epoch: 5/10, step 285/574 completed (loss: 0.2624155879020691, acc: 0.925000011920929)
[2024-11-29 03:22:23,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:23,972][root][INFO] - Training Epoch: 5/10, step 286/574 completed (loss: 0.5837067365646362, acc: 0.84375)
[2024-11-29 03:22:24,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:24,349][root][INFO] - Training Epoch: 5/10, step 287/574 completed (loss: 0.7892656326293945, acc: 0.7919999957084656)
[2024-11-29 03:22:24,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:24,671][root][INFO] - Training Epoch: 5/10, step 288/574 completed (loss: 0.5739869475364685, acc: 0.8351648449897766)
[2024-11-29 03:22:24,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:24,993][root][INFO] - Training Epoch: 5/10, step 289/574 completed (loss: 0.4983590245246887, acc: 0.8757764101028442)
[2024-11-29 03:22:25,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:25,321][root][INFO] - Training Epoch: 5/10, step 290/574 completed (loss: 0.7729945778846741, acc: 0.7938144207000732)
[2024-11-29 03:22:25,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:25,595][root][INFO] - Training Epoch: 5/10, step 291/574 completed (loss: 0.09202220290899277, acc: 1.0)
[2024-11-29 03:22:25,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:25,905][root][INFO] - Training Epoch: 5/10, step 292/574 completed (loss: 0.5167654752731323, acc: 0.9047619104385376)
[2024-11-29 03:22:26,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:26,208][root][INFO] - Training Epoch: 5/10, step 293/574 completed (loss: 0.2739022970199585, acc: 0.931034505367279)
[2024-11-29 03:22:26,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:26,802][root][INFO] - Training Epoch: 5/10, step 294/574 completed (loss: 0.5134174227714539, acc: 0.9090909361839294)
[2024-11-29 03:22:27,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:27,519][root][INFO] - Training Epoch: 5/10, step 295/574 completed (loss: 1.0014675855636597, acc: 0.7628865838050842)
[2024-11-29 03:22:27,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:27,771][root][INFO] - Training Epoch: 5/10, step 296/574 completed (loss: 0.45806923508644104, acc: 0.931034505367279)
[2024-11-29 03:22:27,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:28,070][root][INFO] - Training Epoch: 5/10, step 297/574 completed (loss: 0.13658565282821655, acc: 0.9629629850387573)
[2024-11-29 03:22:28,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:28,389][root][INFO] - Training Epoch: 5/10, step 298/574 completed (loss: 0.2970796525478363, acc: 0.8684210777282715)
[2024-11-29 03:22:28,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:28,703][root][INFO] - Training Epoch: 5/10, step 299/574 completed (loss: 0.19501034915447235, acc: 0.9642857313156128)
[2024-11-29 03:22:28,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:28,988][root][INFO] - Training Epoch: 5/10, step 300/574 completed (loss: 0.05375954136252403, acc: 0.96875)
[2024-11-29 03:22:29,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:29,335][root][INFO] - Training Epoch: 5/10, step 301/574 completed (loss: 0.3399761915206909, acc: 0.9245283007621765)
[2024-11-29 03:22:29,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:29,649][root][INFO] - Training Epoch: 5/10, step 302/574 completed (loss: 0.051147378981113434, acc: 0.9811320900917053)
[2024-11-29 03:22:29,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:30,014][root][INFO] - Training Epoch: 5/10, step 303/574 completed (loss: 0.33514776825904846, acc: 0.970588207244873)
[2024-11-29 03:22:30,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:30,316][root][INFO] - Training Epoch: 5/10, step 304/574 completed (loss: 0.04581376910209656, acc: 1.0)
[2024-11-29 03:22:30,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:30,645][root][INFO] - Training Epoch: 5/10, step 305/574 completed (loss: 0.5750272274017334, acc: 0.8524590134620667)
[2024-11-29 03:22:30,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:31,000][root][INFO] - Training Epoch: 5/10, step 306/574 completed (loss: 0.10132741928100586, acc: 0.9666666388511658)
[2024-11-29 03:22:31,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:31,329][root][INFO] - Training Epoch: 5/10, step 307/574 completed (loss: 0.012760601006448269, acc: 1.0)
[2024-11-29 03:22:31,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:31,652][root][INFO] - Training Epoch: 5/10, step 308/574 completed (loss: 0.278872013092041, acc: 0.9420289993286133)
[2024-11-29 03:22:31,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:32,143][root][INFO] - Training Epoch: 5/10, step 309/574 completed (loss: 0.2583744525909424, acc: 0.9583333134651184)
[2024-11-29 03:22:32,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:32,455][root][INFO] - Training Epoch: 5/10, step 310/574 completed (loss: 0.3752833306789398, acc: 0.9036144614219666)
[2024-11-29 03:22:32,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:32,738][root][INFO] - Training Epoch: 5/10, step 311/574 completed (loss: 0.4552419185638428, acc: 0.8205128312110901)
[2024-11-29 03:22:32,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:33,114][root][INFO] - Training Epoch: 5/10, step 312/574 completed (loss: 0.24282822012901306, acc: 0.918367326259613)
[2024-11-29 03:22:33,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:33,358][root][INFO] - Training Epoch: 5/10, step 313/574 completed (loss: 0.08136535435914993, acc: 0.9583333134651184)
[2024-11-29 03:22:33,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:33,652][root][INFO] - Training Epoch: 5/10, step 314/574 completed (loss: 0.10869435220956802, acc: 0.9166666865348816)
[2024-11-29 03:22:33,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:33,967][root][INFO] - Training Epoch: 5/10, step 315/574 completed (loss: 0.17428377270698547, acc: 0.9677419066429138)
[2024-11-29 03:22:34,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:34,275][root][INFO] - Training Epoch: 5/10, step 316/574 completed (loss: 1.2067986726760864, acc: 0.7096773982048035)
[2024-11-29 03:22:34,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:34,612][root][INFO] - Training Epoch: 5/10, step 317/574 completed (loss: 0.18955440819263458, acc: 0.9253731369972229)
[2024-11-29 03:22:34,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:34,921][root][INFO] - Training Epoch: 5/10, step 318/574 completed (loss: 0.15308450162410736, acc: 0.9615384340286255)
[2024-11-29 03:22:35,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:35,197][root][INFO] - Training Epoch: 5/10, step 319/574 completed (loss: 0.082858145236969, acc: 0.9777777791023254)
[2024-11-29 03:22:35,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:35,508][root][INFO] - Training Epoch: 5/10, step 320/574 completed (loss: 0.3383850157260895, acc: 0.9193548560142517)
[2024-11-29 03:22:35,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:35,822][root][INFO] - Training Epoch: 5/10, step 321/574 completed (loss: 0.15546934306621552, acc: 0.9399999976158142)
[2024-11-29 03:22:36,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:36,141][root][INFO] - Training Epoch: 5/10, step 322/574 completed (loss: 0.6195583343505859, acc: 0.8518518805503845)
[2024-11-29 03:22:36,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:36,430][root][INFO] - Training Epoch: 5/10, step 323/574 completed (loss: 1.6002686023712158, acc: 0.5428571701049805)
[2024-11-29 03:22:36,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:36,692][root][INFO] - Training Epoch: 5/10, step 324/574 completed (loss: 1.1315382719039917, acc: 0.6410256624221802)
[2024-11-29 03:22:36,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:36,977][root][INFO] - Training Epoch: 5/10, step 325/574 completed (loss: 2.014901876449585, acc: 0.46341463923454285)
[2024-11-29 03:22:37,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:37,291][root][INFO] - Training Epoch: 5/10, step 326/574 completed (loss: 1.073433518409729, acc: 0.6842105388641357)
[2024-11-29 03:22:37,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:37,569][root][INFO] - Training Epoch: 5/10, step 327/574 completed (loss: 0.5190587043762207, acc: 0.8421052694320679)
[2024-11-29 03:22:37,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:37,860][root][INFO] - Training Epoch: 5/10, step 328/574 completed (loss: 0.06463588029146194, acc: 0.9642857313156128)
[2024-11-29 03:22:38,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:38,226][root][INFO] - Training Epoch: 5/10, step 329/574 completed (loss: 0.09558520466089249, acc: 0.9629629850387573)
[2024-11-29 03:22:38,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:38,536][root][INFO] - Training Epoch: 5/10, step 330/574 completed (loss: 0.028260381892323494, acc: 1.0)
[2024-11-29 03:22:38,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:38,812][root][INFO] - Training Epoch: 5/10, step 331/574 completed (loss: 0.3886602520942688, acc: 0.8548387289047241)
[2024-11-29 03:22:39,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:39,197][root][INFO] - Training Epoch: 5/10, step 332/574 completed (loss: 0.13849209249019623, acc: 0.9473684430122375)
[2024-11-29 03:22:39,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:39,492][root][INFO] - Training Epoch: 5/10, step 333/574 completed (loss: 0.326978474855423, acc: 0.90625)
[2024-11-29 03:22:39,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:39,822][root][INFO] - Training Epoch: 5/10, step 334/574 completed (loss: 0.10448139160871506, acc: 0.9666666388511658)
[2024-11-29 03:22:40,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:40,121][root][INFO] - Training Epoch: 5/10, step 335/574 completed (loss: 0.18926003575325012, acc: 0.9473684430122375)
[2024-11-29 03:22:40,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:40,451][root][INFO] - Training Epoch: 5/10, step 336/574 completed (loss: 0.9949201941490173, acc: 0.7200000286102295)
[2024-11-29 03:22:40,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:40,801][root][INFO] - Training Epoch: 5/10, step 337/574 completed (loss: 1.4778364896774292, acc: 0.6321839094161987)
[2024-11-29 03:22:41,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:41,146][root][INFO] - Training Epoch: 5/10, step 338/574 completed (loss: 1.473573923110962, acc: 0.6063829660415649)
[2024-11-29 03:22:41,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:41,434][root][INFO] - Training Epoch: 5/10, step 339/574 completed (loss: 1.525002121925354, acc: 0.6385542154312134)
[2024-11-29 03:22:41,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:41,771][root][INFO] - Training Epoch: 5/10, step 340/574 completed (loss: 0.029860297217965126, acc: 1.0)
[2024-11-29 03:22:41,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:42,105][root][INFO] - Training Epoch: 5/10, step 341/574 completed (loss: 0.3344796597957611, acc: 0.8974359035491943)
[2024-11-29 03:22:42,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:42,399][root][INFO] - Training Epoch: 5/10, step 342/574 completed (loss: 0.44305214285850525, acc: 0.8674699068069458)
[2024-11-29 03:22:42,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:42,704][root][INFO] - Training Epoch: 5/10, step 343/574 completed (loss: 1.2320207357406616, acc: 0.7358490824699402)
[2024-11-29 03:22:42,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:43,006][root][INFO] - Training Epoch: 5/10, step 344/574 completed (loss: 0.189467191696167, acc: 0.9367088675498962)
[2024-11-29 03:22:43,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:43,298][root][INFO] - Training Epoch: 5/10, step 345/574 completed (loss: 0.199362114071846, acc: 0.9215686321258545)
[2024-11-29 03:22:43,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:43,581][root][INFO] - Training Epoch: 5/10, step 346/574 completed (loss: 0.5647076964378357, acc: 0.8208954930305481)
[2024-11-29 03:22:43,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:43,888][root][INFO] - Training Epoch: 5/10, step 347/574 completed (loss: 0.27294522523880005, acc: 0.8999999761581421)
[2024-11-29 03:22:44,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:44,231][root][INFO] - Training Epoch: 5/10, step 348/574 completed (loss: 0.15854312479496002, acc: 0.9599999785423279)
[2024-11-29 03:22:44,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:44,694][root][INFO] - Training Epoch: 5/10, step 349/574 completed (loss: 0.814326286315918, acc: 0.8055555820465088)
[2024-11-29 03:22:44,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:45,018][root][INFO] - Training Epoch: 5/10, step 350/574 completed (loss: 0.6393634676933289, acc: 0.7674418687820435)
[2024-11-29 03:22:45,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:45,331][root][INFO] - Training Epoch: 5/10, step 351/574 completed (loss: 0.2724749445915222, acc: 0.9230769276618958)
[2024-11-29 03:22:45,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:45,736][root][INFO] - Training Epoch: 5/10, step 352/574 completed (loss: 1.114529013633728, acc: 0.6222222447395325)
[2024-11-29 03:22:45,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:46,043][root][INFO] - Training Epoch: 5/10, step 353/574 completed (loss: 0.28063780069351196, acc: 0.9130434989929199)
[2024-11-29 03:22:46,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:46,402][root][INFO] - Training Epoch: 5/10, step 354/574 completed (loss: 0.7066301703453064, acc: 0.7307692170143127)
[2024-11-29 03:22:46,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:46,753][root][INFO] - Training Epoch: 5/10, step 355/574 completed (loss: 1.014132022857666, acc: 0.6703296899795532)
[2024-11-29 03:22:47,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:47,428][root][INFO] - Training Epoch: 5/10, step 356/574 completed (loss: 0.7521306872367859, acc: 0.782608687877655)
[2024-11-29 03:22:47,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:47,751][root][INFO] - Training Epoch: 5/10, step 357/574 completed (loss: 0.4388056695461273, acc: 0.8804348111152649)
[2024-11-29 03:22:47,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:48,055][root][INFO] - Training Epoch: 5/10, step 358/574 completed (loss: 0.45006245374679565, acc: 0.918367326259613)
[2024-11-29 03:22:48,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:48,304][root][INFO] - Training Epoch: 5/10, step 359/574 completed (loss: 0.01255776360630989, acc: 1.0)
[2024-11-29 03:22:48,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:48,610][root][INFO] - Training Epoch: 5/10, step 360/574 completed (loss: 0.28143036365509033, acc: 0.9230769276618958)
[2024-11-29 03:22:48,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:48,917][root][INFO] - Training Epoch: 5/10, step 361/574 completed (loss: 0.5545002222061157, acc: 0.8780487775802612)
[2024-11-29 03:22:49,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:49,249][root][INFO] - Training Epoch: 5/10, step 362/574 completed (loss: 0.49586495757102966, acc: 0.8666666746139526)
[2024-11-29 03:22:49,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:49,586][root][INFO] - Training Epoch: 5/10, step 363/574 completed (loss: 0.15252287685871124, acc: 0.9736841917037964)
[2024-11-29 03:22:49,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:49,905][root][INFO] - Training Epoch: 5/10, step 364/574 completed (loss: 0.25362229347229004, acc: 0.9268292784690857)
[2024-11-29 03:22:50,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:50,223][root][INFO] - Training Epoch: 5/10, step 365/574 completed (loss: 0.13066916167736053, acc: 0.9696969985961914)
[2024-11-29 03:22:50,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:50,538][root][INFO] - Training Epoch: 5/10, step 366/574 completed (loss: 0.01989937387406826, acc: 1.0)
[2024-11-29 03:22:50,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:50,887][root][INFO] - Training Epoch: 5/10, step 367/574 completed (loss: 0.03940149396657944, acc: 1.0)
[2024-11-29 03:22:51,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:51,219][root][INFO] - Training Epoch: 5/10, step 368/574 completed (loss: 0.3615824580192566, acc: 0.8928571343421936)
[2024-11-29 03:22:51,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:51,521][root][INFO] - Training Epoch: 5/10, step 369/574 completed (loss: 0.5039263367652893, acc: 0.875)
[2024-11-29 03:22:51,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:52,339][root][INFO] - Training Epoch: 5/10, step 370/574 completed (loss: 0.9270408153533936, acc: 0.7333333492279053)
[2024-11-29 03:22:53,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:53,552][root][INFO] - Training Epoch: 5/10, step 371/574 completed (loss: 0.6177465319633484, acc: 0.8584905862808228)
[2024-11-29 03:22:53,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:53,879][root][INFO] - Training Epoch: 5/10, step 372/574 completed (loss: 0.47102266550064087, acc: 0.8444444537162781)
[2024-11-29 03:22:54,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:54,201][root][INFO] - Training Epoch: 5/10, step 373/574 completed (loss: 0.12439458072185516, acc: 0.9642857313156128)
[2024-11-29 03:22:54,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:54,542][root][INFO] - Training Epoch: 5/10, step 374/574 completed (loss: 0.06930490583181381, acc: 0.9714285731315613)
[2024-11-29 03:22:54,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:54,891][root][INFO] - Training Epoch: 5/10, step 375/574 completed (loss: 0.16878630220890045, acc: 0.9599999785423279)
[2024-11-29 03:22:55,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:55,229][root][INFO] - Training Epoch: 5/10, step 376/574 completed (loss: 0.04625288397073746, acc: 1.0)
[2024-11-29 03:22:55,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:55,517][root][INFO] - Training Epoch: 5/10, step 377/574 completed (loss: 0.1561151146888733, acc: 0.9583333134651184)
[2024-11-29 03:22:55,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:55,848][root][INFO] - Training Epoch: 5/10, step 378/574 completed (loss: 0.04206516221165657, acc: 1.0)
[2024-11-29 03:22:56,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:56,626][root][INFO] - Training Epoch: 5/10, step 379/574 completed (loss: 0.40777236223220825, acc: 0.916167676448822)
[2024-11-29 03:22:56,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:57,088][root][INFO] - Training Epoch: 5/10, step 380/574 completed (loss: 0.3904874920845032, acc: 0.932330846786499)
[2024-11-29 03:22:58,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:58,909][root][INFO] - Training Epoch: 5/10, step 381/574 completed (loss: 0.72260981798172, acc: 0.8181818127632141)
[2024-11-29 03:22:59,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:59,673][root][INFO] - Training Epoch: 5/10, step 382/574 completed (loss: 0.22212907671928406, acc: 0.9459459185600281)
[2024-11-29 03:22:59,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:22:59,927][root][INFO] - Training Epoch: 5/10, step 383/574 completed (loss: 0.13107730448246002, acc: 0.9642857313156128)
[2024-11-29 03:23:00,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:00,193][root][INFO] - Training Epoch: 5/10, step 384/574 completed (loss: 0.06335441023111343, acc: 1.0)
[2024-11-29 03:23:00,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:00,493][root][INFO] - Training Epoch: 5/10, step 385/574 completed (loss: 0.13000881671905518, acc: 0.9375)
[2024-11-29 03:23:00,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:00,794][root][INFO] - Training Epoch: 5/10, step 386/574 completed (loss: 0.021984411403536797, acc: 1.0)
[2024-11-29 03:23:00,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:01,062][root][INFO] - Training Epoch: 5/10, step 387/574 completed (loss: 0.11992882192134857, acc: 0.9736841917037964)
[2024-11-29 03:23:01,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:01,332][root][INFO] - Training Epoch: 5/10, step 388/574 completed (loss: 0.025187058374285698, acc: 1.0)
[2024-11-29 03:23:01,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:01,659][root][INFO] - Training Epoch: 5/10, step 389/574 completed (loss: 0.017697207629680634, acc: 1.0)
[2024-11-29 03:23:01,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:02,012][root][INFO] - Training Epoch: 5/10, step 390/574 completed (loss: 0.27410954236984253, acc: 0.9047619104385376)
[2024-11-29 03:23:02,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:02,330][root][INFO] - Training Epoch: 5/10, step 391/574 completed (loss: 0.8767144680023193, acc: 0.8148148059844971)
[2024-11-29 03:23:02,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:02,682][root][INFO] - Training Epoch: 5/10, step 392/574 completed (loss: 0.933929979801178, acc: 0.7281553149223328)
[2024-11-29 03:23:03,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:03,361][root][INFO] - Training Epoch: 5/10, step 393/574 completed (loss: 1.152505874633789, acc: 0.7426470518112183)
[2024-11-29 03:23:03,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:03,750][root][INFO] - Training Epoch: 5/10, step 394/574 completed (loss: 0.9175236225128174, acc: 0.7333333492279053)
[2024-11-29 03:23:03,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:04,186][root][INFO] - Training Epoch: 5/10, step 395/574 completed (loss: 0.6627547740936279, acc: 0.8055555820465088)
[2024-11-29 03:23:04,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:04,498][root][INFO] - Training Epoch: 5/10, step 396/574 completed (loss: 0.31207188963890076, acc: 0.8837209343910217)
[2024-11-29 03:23:04,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:04,754][root][INFO] - Training Epoch: 5/10, step 397/574 completed (loss: 0.0569295696914196, acc: 1.0)
[2024-11-29 03:23:04,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:05,071][root][INFO] - Training Epoch: 5/10, step 398/574 completed (loss: 0.40678489208221436, acc: 0.9069767594337463)
[2024-11-29 03:23:05,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:05,368][root][INFO] - Training Epoch: 5/10, step 399/574 completed (loss: 0.0376947745680809, acc: 1.0)
[2024-11-29 03:23:05,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:06,084][root][INFO] - Training Epoch: 5/10, step 400/574 completed (loss: 0.417423278093338, acc: 0.8823529481887817)
[2024-11-29 03:23:06,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:06,386][root][INFO] - Training Epoch: 5/10, step 401/574 completed (loss: 0.638064980506897, acc: 0.8533333539962769)
[2024-11-29 03:23:06,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:06,691][root][INFO] - Training Epoch: 5/10, step 402/574 completed (loss: 0.41257357597351074, acc: 0.8787878751754761)
[2024-11-29 03:23:06,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:06,972][root][INFO] - Training Epoch: 5/10, step 403/574 completed (loss: 0.19387297332286835, acc: 0.9696969985961914)
[2024-11-29 03:23:07,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:07,292][root][INFO] - Training Epoch: 5/10, step 404/574 completed (loss: 0.2609793245792389, acc: 0.9354838728904724)
[2024-11-29 03:23:07,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:07,610][root][INFO] - Training Epoch: 5/10, step 405/574 completed (loss: 0.02198234386742115, acc: 1.0)
[2024-11-29 03:23:07,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:07,879][root][INFO] - Training Epoch: 5/10, step 406/574 completed (loss: 0.18320482969284058, acc: 0.9599999785423279)
[2024-11-29 03:23:08,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:08,159][root][INFO] - Training Epoch: 5/10, step 407/574 completed (loss: 0.030596163123846054, acc: 1.0)
[2024-11-29 03:23:08,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:08,417][root][INFO] - Training Epoch: 5/10, step 408/574 completed (loss: 0.03786320984363556, acc: 1.0)
[2024-11-29 03:23:08,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:08,754][root][INFO] - Training Epoch: 5/10, step 409/574 completed (loss: 0.03285234421491623, acc: 1.0)
[2024-11-29 03:23:08,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:09,064][root][INFO] - Training Epoch: 5/10, step 410/574 completed (loss: 0.13814009726047516, acc: 0.9137930870056152)
[2024-11-29 03:23:09,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:09,317][root][INFO] - Training Epoch: 5/10, step 411/574 completed (loss: 0.2792002260684967, acc: 0.9285714030265808)
[2024-11-29 03:23:09,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:09,604][root][INFO] - Training Epoch: 5/10, step 412/574 completed (loss: 0.04978862777352333, acc: 1.0)
[2024-11-29 03:23:09,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:09,936][root][INFO] - Training Epoch: 5/10, step 413/574 completed (loss: 0.1365547925233841, acc: 0.939393937587738)
[2024-11-29 03:23:10,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:10,199][root][INFO] - Training Epoch: 5/10, step 414/574 completed (loss: 0.0719321221113205, acc: 1.0)
[2024-11-29 03:23:10,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:10,483][root][INFO] - Training Epoch: 5/10, step 415/574 completed (loss: 0.2379292994737625, acc: 0.9019607901573181)
[2024-11-29 03:23:10,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:10,759][root][INFO] - Training Epoch: 5/10, step 416/574 completed (loss: 0.19974398612976074, acc: 0.9615384340286255)
[2024-11-29 03:23:10,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:11,032][root][INFO] - Training Epoch: 5/10, step 417/574 completed (loss: 0.19999590516090393, acc: 0.8888888955116272)
[2024-11-29 03:23:11,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:11,317][root][INFO] - Training Epoch: 5/10, step 418/574 completed (loss: 0.521368145942688, acc: 0.875)
[2024-11-29 03:23:11,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:11,622][root][INFO] - Training Epoch: 5/10, step 419/574 completed (loss: 0.15038925409317017, acc: 0.949999988079071)
[2024-11-29 03:23:11,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:11,918][root][INFO] - Training Epoch: 5/10, step 420/574 completed (loss: 0.053201187402009964, acc: 1.0)
[2024-11-29 03:23:12,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:13,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:13,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:14,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:14,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:14,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:15,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:15,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:16,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:16,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:16,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:17,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:17,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:18,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:18,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:19,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:19,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:20,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:20,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:21,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:21,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:21,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:22,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:22,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:23,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:23,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:24,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:24,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:25,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:25,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:25,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:26,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:26,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:27,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:27,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:27,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:28,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:28,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:29,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:29,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:30,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:30,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:30,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:31,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:31,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:31,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:32,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:32,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:33,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:33,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:33,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:34,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:35,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:35,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:35,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:36,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:36,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:36,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:37,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:37,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:38,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:38,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:39,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:39,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:40,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:40,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:41,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:41,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:42,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:42,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:43,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:43,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:43,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:44,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:44,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:45,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:45,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:46,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:46,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:46,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:47,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:47,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:48,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:48,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:48,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:49,456][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.8609, device='cuda:0') eval_epoch_loss=tensor(1.0511, device='cuda:0') eval_epoch_acc=tensor(0.7452, device='cuda:0')
[2024-11-29 03:23:49,457][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:23:49,457][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:23:49,682][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_5_step_421_loss_1.0511255264282227/model.pt
[2024-11-29 03:23:49,697][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 5 is 1.0511255264282227
[2024-11-29 03:23:49,698][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 5 is 0.7451885342597961
[2024-11-29 03:23:49,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:50,031][root][INFO] - Training Epoch: 5/10, step 421/574 completed (loss: 0.09143088757991791, acc: 0.9666666388511658)
[2024-11-29 03:23:50,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:50,304][root][INFO] - Training Epoch: 5/10, step 422/574 completed (loss: 0.11450336128473282, acc: 0.96875)
[2024-11-29 03:23:50,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:50,579][root][INFO] - Training Epoch: 5/10, step 423/574 completed (loss: 0.32282838225364685, acc: 0.9166666865348816)
[2024-11-29 03:23:50,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:50,906][root][INFO] - Training Epoch: 5/10, step 424/574 completed (loss: 0.13637922704219818, acc: 0.9629629850387573)
[2024-11-29 03:23:51,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:51,181][root][INFO] - Training Epoch: 5/10, step 425/574 completed (loss: 0.052238162606954575, acc: 1.0)
[2024-11-29 03:23:51,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:51,475][root][INFO] - Training Epoch: 5/10, step 426/574 completed (loss: 0.020704323425889015, acc: 1.0)
[2024-11-29 03:23:51,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:51,748][root][INFO] - Training Epoch: 5/10, step 427/574 completed (loss: 0.07474162429571152, acc: 1.0)
[2024-11-29 03:23:51,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:52,044][root][INFO] - Training Epoch: 5/10, step 428/574 completed (loss: 0.20200134813785553, acc: 0.8888888955116272)
[2024-11-29 03:23:52,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:52,345][root][INFO] - Training Epoch: 5/10, step 429/574 completed (loss: 0.14875222742557526, acc: 0.9130434989929199)
[2024-11-29 03:23:52,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:52,608][root][INFO] - Training Epoch: 5/10, step 430/574 completed (loss: 0.01595296524465084, acc: 1.0)
[2024-11-29 03:23:52,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:52,896][root][INFO] - Training Epoch: 5/10, step 431/574 completed (loss: 0.024085862562060356, acc: 1.0)
[2024-11-29 03:23:53,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:53,189][root][INFO] - Training Epoch: 5/10, step 432/574 completed (loss: 0.008137105964124203, acc: 1.0)
[2024-11-29 03:23:53,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:53,540][root][INFO] - Training Epoch: 5/10, step 433/574 completed (loss: 0.12050041556358337, acc: 0.9444444179534912)
[2024-11-29 03:23:53,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:53,816][root][INFO] - Training Epoch: 5/10, step 434/574 completed (loss: 0.01952996291220188, acc: 1.0)
[2024-11-29 03:23:54,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:54,144][root][INFO] - Training Epoch: 5/10, step 435/574 completed (loss: 0.022028716281056404, acc: 1.0)
[2024-11-29 03:23:54,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:54,469][root][INFO] - Training Epoch: 5/10, step 436/574 completed (loss: 0.2254067063331604, acc: 0.9444444179534912)
[2024-11-29 03:23:54,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:54,762][root][INFO] - Training Epoch: 5/10, step 437/574 completed (loss: 0.17454728484153748, acc: 0.9545454382896423)
[2024-11-29 03:23:54,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:55,002][root][INFO] - Training Epoch: 5/10, step 438/574 completed (loss: 0.07584990561008453, acc: 0.9523809552192688)
[2024-11-29 03:23:55,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:55,249][root][INFO] - Training Epoch: 5/10, step 439/574 completed (loss: 0.27210116386413574, acc: 0.9230769276618958)
[2024-11-29 03:23:55,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:55,825][root][INFO] - Training Epoch: 5/10, step 440/574 completed (loss: 0.4258657395839691, acc: 0.8636363744735718)
[2024-11-29 03:23:56,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:56,775][root][INFO] - Training Epoch: 5/10, step 441/574 completed (loss: 0.7342304587364197, acc: 0.8159999847412109)
[2024-11-29 03:23:57,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:57,235][root][INFO] - Training Epoch: 5/10, step 442/574 completed (loss: 0.9450717568397522, acc: 0.7338709831237793)
[2024-11-29 03:23:57,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:58,138][root][INFO] - Training Epoch: 5/10, step 443/574 completed (loss: 0.7236039638519287, acc: 0.8258706331253052)
[2024-11-29 03:23:58,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:58,413][root][INFO] - Training Epoch: 5/10, step 444/574 completed (loss: 0.29067882895469666, acc: 0.9245283007621765)
[2024-11-29 03:23:58,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:58,909][root][INFO] - Training Epoch: 5/10, step 445/574 completed (loss: 0.0773920938372612, acc: 1.0)
[2024-11-29 03:23:59,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:59,161][root][INFO] - Training Epoch: 5/10, step 446/574 completed (loss: 0.4273250699043274, acc: 0.8695651888847351)
[2024-11-29 03:23:59,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:59,456][root][INFO] - Training Epoch: 5/10, step 447/574 completed (loss: 0.33771976828575134, acc: 0.8846153616905212)
[2024-11-29 03:23:59,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:23:59,795][root][INFO] - Training Epoch: 5/10, step 448/574 completed (loss: 0.4348030388355255, acc: 0.9285714030265808)
[2024-11-29 03:24:00,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:00,164][root][INFO] - Training Epoch: 5/10, step 449/574 completed (loss: 0.226302370429039, acc: 0.9104477763175964)
[2024-11-29 03:24:00,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:00,467][root][INFO] - Training Epoch: 5/10, step 450/574 completed (loss: 0.14830859005451202, acc: 0.9444444179534912)
[2024-11-29 03:24:00,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:00,757][root][INFO] - Training Epoch: 5/10, step 451/574 completed (loss: 0.10974634438753128, acc: 0.97826087474823)
[2024-11-29 03:24:00,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:01,111][root][INFO] - Training Epoch: 5/10, step 452/574 completed (loss: 0.3026520311832428, acc: 0.9230769276618958)
[2024-11-29 03:24:01,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:01,413][root][INFO] - Training Epoch: 5/10, step 453/574 completed (loss: 0.3489445745944977, acc: 0.8684210777282715)
[2024-11-29 03:24:01,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:01,724][root][INFO] - Training Epoch: 5/10, step 454/574 completed (loss: 0.30354660749435425, acc: 0.9387755393981934)
[2024-11-29 03:24:01,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:02,054][root][INFO] - Training Epoch: 5/10, step 455/574 completed (loss: 0.07684630900621414, acc: 0.9696969985961914)
[2024-11-29 03:24:02,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:02,398][root][INFO] - Training Epoch: 5/10, step 456/574 completed (loss: 0.522641122341156, acc: 0.8969072103500366)
[2024-11-29 03:24:02,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:02,730][root][INFO] - Training Epoch: 5/10, step 457/574 completed (loss: 0.2623896598815918, acc: 0.9285714030265808)
[2024-11-29 03:24:02,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:03,158][root][INFO] - Training Epoch: 5/10, step 458/574 completed (loss: 0.6810706853866577, acc: 0.8081395626068115)
[2024-11-29 03:24:03,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:03,425][root][INFO] - Training Epoch: 5/10, step 459/574 completed (loss: 0.4390661418437958, acc: 0.8571428656578064)
[2024-11-29 03:24:03,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:03,732][root][INFO] - Training Epoch: 5/10, step 460/574 completed (loss: 0.3200409710407257, acc: 0.8888888955116272)
[2024-11-29 03:24:03,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:03,985][root][INFO] - Training Epoch: 5/10, step 461/574 completed (loss: 0.23460753262043, acc: 0.9166666865348816)
[2024-11-29 03:24:04,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:04,273][root][INFO] - Training Epoch: 5/10, step 462/574 completed (loss: 0.46313878893852234, acc: 0.90625)
[2024-11-29 03:24:04,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:04,574][root][INFO] - Training Epoch: 5/10, step 463/574 completed (loss: 0.3891969919204712, acc: 0.9615384340286255)
[2024-11-29 03:24:04,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:04,871][root][INFO] - Training Epoch: 5/10, step 464/574 completed (loss: 0.3077095150947571, acc: 0.9130434989929199)
[2024-11-29 03:24:05,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:05,123][root][INFO] - Training Epoch: 5/10, step 465/574 completed (loss: 0.4303971827030182, acc: 0.8928571343421936)
[2024-11-29 03:24:05,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:05,403][root][INFO] - Training Epoch: 5/10, step 466/574 completed (loss: 0.9883273839950562, acc: 0.759036123752594)
[2024-11-29 03:24:05,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:05,744][root][INFO] - Training Epoch: 5/10, step 467/574 completed (loss: 0.23773697018623352, acc: 0.9279279112815857)
[2024-11-29 03:24:05,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:06,023][root][INFO] - Training Epoch: 5/10, step 468/574 completed (loss: 0.8076351881027222, acc: 0.7864077687263489)
[2024-11-29 03:24:06,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:06,336][root][INFO] - Training Epoch: 5/10, step 469/574 completed (loss: 1.0292786359786987, acc: 0.7398374080657959)
[2024-11-29 03:24:06,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:06,624][root][INFO] - Training Epoch: 5/10, step 470/574 completed (loss: 0.18044354021549225, acc: 0.9583333134651184)
[2024-11-29 03:24:06,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:06,867][root][INFO] - Training Epoch: 5/10, step 471/574 completed (loss: 0.10984764993190765, acc: 0.9642857313156128)
[2024-11-29 03:24:07,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:07,342][root][INFO] - Training Epoch: 5/10, step 472/574 completed (loss: 0.679148256778717, acc: 0.7647058963775635)
[2024-11-29 03:24:07,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:07,718][root][INFO] - Training Epoch: 5/10, step 473/574 completed (loss: 1.067622423171997, acc: 0.7074235677719116)
[2024-11-29 03:24:07,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:08,030][root][INFO] - Training Epoch: 5/10, step 474/574 completed (loss: 0.7163357734680176, acc: 0.8229166865348816)
[2024-11-29 03:24:08,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:08,325][root][INFO] - Training Epoch: 5/10, step 475/574 completed (loss: 0.5419846773147583, acc: 0.8527607321739197)
[2024-11-29 03:24:08,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:08,652][root][INFO] - Training Epoch: 5/10, step 476/574 completed (loss: 0.5259981155395508, acc: 0.8705036044120789)
[2024-11-29 03:24:08,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:09,017][root][INFO] - Training Epoch: 5/10, step 477/574 completed (loss: 0.7295400500297546, acc: 0.7788944840431213)
[2024-11-29 03:24:09,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:09,315][root][INFO] - Training Epoch: 5/10, step 478/574 completed (loss: 0.2810957133769989, acc: 0.9166666865348816)
[2024-11-29 03:24:09,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:09,609][root][INFO] - Training Epoch: 5/10, step 479/574 completed (loss: 0.3744460642337799, acc: 0.939393937587738)
[2024-11-29 03:24:09,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:09,913][root][INFO] - Training Epoch: 5/10, step 480/574 completed (loss: 0.39967453479766846, acc: 0.9259259104728699)
[2024-11-29 03:24:10,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:10,206][root][INFO] - Training Epoch: 5/10, step 481/574 completed (loss: 0.6738864183425903, acc: 0.800000011920929)
[2024-11-29 03:24:10,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:10,489][root][INFO] - Training Epoch: 5/10, step 482/574 completed (loss: 1.057612657546997, acc: 0.800000011920929)
[2024-11-29 03:24:10,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:10,900][root][INFO] - Training Epoch: 5/10, step 483/574 completed (loss: 0.9139470458030701, acc: 0.7241379022598267)
[2024-11-29 03:24:11,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:11,188][root][INFO] - Training Epoch: 5/10, step 484/574 completed (loss: 0.05018075555562973, acc: 1.0)
[2024-11-29 03:24:11,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:11,494][root][INFO] - Training Epoch: 5/10, step 485/574 completed (loss: 0.08016611635684967, acc: 0.9473684430122375)
[2024-11-29 03:24:11,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:11,777][root][INFO] - Training Epoch: 5/10, step 486/574 completed (loss: 0.6260382533073425, acc: 0.8148148059844971)
[2024-11-29 03:24:11,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:12,089][root][INFO] - Training Epoch: 5/10, step 487/574 completed (loss: 0.8677309155464172, acc: 0.761904776096344)
[2024-11-29 03:24:12,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:12,388][root][INFO] - Training Epoch: 5/10, step 488/574 completed (loss: 0.37312400341033936, acc: 0.7727272510528564)
[2024-11-29 03:24:12,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:12,733][root][INFO] - Training Epoch: 5/10, step 489/574 completed (loss: 0.971314013004303, acc: 0.7538461685180664)
[2024-11-29 03:24:12,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:13,047][root][INFO] - Training Epoch: 5/10, step 490/574 completed (loss: 0.13713282346725464, acc: 0.9666666388511658)
[2024-11-29 03:24:13,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:13,306][root][INFO] - Training Epoch: 5/10, step 491/574 completed (loss: 0.20045949518680573, acc: 0.931034505367279)
[2024-11-29 03:24:13,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:13,610][root][INFO] - Training Epoch: 5/10, step 492/574 completed (loss: 0.3648640811443329, acc: 0.8627451062202454)
[2024-11-29 03:24:13,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:13,936][root][INFO] - Training Epoch: 5/10, step 493/574 completed (loss: 0.16238097846508026, acc: 0.931034505367279)
[2024-11-29 03:24:14,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:14,208][root][INFO] - Training Epoch: 5/10, step 494/574 completed (loss: 0.37283164262771606, acc: 0.8947368264198303)
[2024-11-29 03:24:14,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:14,472][root][INFO] - Training Epoch: 5/10, step 495/574 completed (loss: 0.2189849615097046, acc: 0.9473684430122375)
[2024-11-29 03:24:14,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:14,840][root][INFO] - Training Epoch: 5/10, step 496/574 completed (loss: 1.0681307315826416, acc: 0.7142857313156128)
[2024-11-29 03:24:15,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:15,241][root][INFO] - Training Epoch: 5/10, step 497/574 completed (loss: 0.34938469529151917, acc: 0.8876404762268066)
[2024-11-29 03:24:15,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:15,552][root][INFO] - Training Epoch: 5/10, step 498/574 completed (loss: 0.8175811767578125, acc: 0.6853932738304138)
[2024-11-29 03:24:15,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:15,878][root][INFO] - Training Epoch: 5/10, step 499/574 completed (loss: 1.3212941884994507, acc: 0.6241135001182556)
[2024-11-29 03:24:16,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:16,209][root][INFO] - Training Epoch: 5/10, step 500/574 completed (loss: 0.883451521396637, acc: 0.760869562625885)
[2024-11-29 03:24:16,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:16,474][root][INFO] - Training Epoch: 5/10, step 501/574 completed (loss: 0.07449852675199509, acc: 0.9599999785423279)
[2024-11-29 03:24:16,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:16,788][root][INFO] - Training Epoch: 5/10, step 502/574 completed (loss: 0.03149786964058876, acc: 1.0)
[2024-11-29 03:24:16,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:17,106][root][INFO] - Training Epoch: 5/10, step 503/574 completed (loss: 0.381496787071228, acc: 0.9259259104728699)
[2024-11-29 03:24:17,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:17,412][root][INFO] - Training Epoch: 5/10, step 504/574 completed (loss: 0.06203301250934601, acc: 1.0)
[2024-11-29 03:24:17,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:17,730][root][INFO] - Training Epoch: 5/10, step 505/574 completed (loss: 0.6556326150894165, acc: 0.8679245114326477)
[2024-11-29 03:24:17,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:18,039][root][INFO] - Training Epoch: 5/10, step 506/574 completed (loss: 1.0656462907791138, acc: 0.7931034564971924)
[2024-11-29 03:24:18,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:18,842][root][INFO] - Training Epoch: 5/10, step 507/574 completed (loss: 1.3737984895706177, acc: 0.6576576828956604)
[2024-11-29 03:24:19,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:19,380][root][INFO] - Training Epoch: 5/10, step 508/574 completed (loss: 0.8703125715255737, acc: 0.8028169274330139)
[2024-11-29 03:24:19,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:19,639][root][INFO] - Training Epoch: 5/10, step 509/574 completed (loss: 0.2951342463493347, acc: 0.8999999761581421)
[2024-11-29 03:24:19,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:19,952][root][INFO] - Training Epoch: 5/10, step 510/574 completed (loss: 0.1349518895149231, acc: 0.9666666388511658)
[2024-11-29 03:24:20,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:20,242][root][INFO] - Training Epoch: 5/10, step 511/574 completed (loss: 0.14128847420215607, acc: 0.9615384340286255)
[2024-11-29 03:24:22,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:23,728][root][INFO] - Training Epoch: 5/10, step 512/574 completed (loss: 1.2645069360733032, acc: 0.699999988079071)
[2024-11-29 03:24:24,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:24,829][root][INFO] - Training Epoch: 5/10, step 513/574 completed (loss: 0.2947387993335724, acc: 0.9285714030265808)
[2024-11-29 03:24:24,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:25,124][root][INFO] - Training Epoch: 5/10, step 514/574 completed (loss: 0.6358187794685364, acc: 0.8571428656578064)
[2024-11-29 03:24:25,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:25,431][root][INFO] - Training Epoch: 5/10, step 515/574 completed (loss: 0.15266074240207672, acc: 0.949999988079071)
[2024-11-29 03:24:25,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:26,404][root][INFO] - Training Epoch: 5/10, step 516/574 completed (loss: 0.48860469460487366, acc: 0.875)
[2024-11-29 03:24:26,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:26,673][root][INFO] - Training Epoch: 5/10, step 517/574 completed (loss: 0.007387728430330753, acc: 1.0)
[2024-11-29 03:24:26,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:26,939][root][INFO] - Training Epoch: 5/10, step 518/574 completed (loss: 0.18231962621212006, acc: 0.9354838728904724)
[2024-11-29 03:24:27,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:27,245][root][INFO] - Training Epoch: 5/10, step 519/574 completed (loss: 0.16984300315380096, acc: 0.949999988079071)
[2024-11-29 03:24:27,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:27,555][root][INFO] - Training Epoch: 5/10, step 520/574 completed (loss: 0.28893154859542847, acc: 0.8888888955116272)
[2024-11-29 03:24:28,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:28,954][root][INFO] - Training Epoch: 5/10, step 521/574 completed (loss: 1.1101289987564087, acc: 0.7118644118309021)
[2024-11-29 03:24:29,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:29,307][root][INFO] - Training Epoch: 5/10, step 522/574 completed (loss: 0.3596894443035126, acc: 0.9029850959777832)
[2024-11-29 03:24:29,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:29,679][root][INFO] - Training Epoch: 5/10, step 523/574 completed (loss: 0.5481189489364624, acc: 0.8321167826652527)
[2024-11-29 03:24:30,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:30,418][root][INFO] - Training Epoch: 5/10, step 524/574 completed (loss: 0.8300195932388306, acc: 0.7850000262260437)
[2024-11-29 03:24:30,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:30,720][root][INFO] - Training Epoch: 5/10, step 525/574 completed (loss: 0.06257028132677078, acc: 0.9629629850387573)
[2024-11-29 03:24:30,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:31,040][root][INFO] - Training Epoch: 5/10, step 526/574 completed (loss: 0.18785668909549713, acc: 0.942307710647583)
[2024-11-29 03:24:31,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:31,344][root][INFO] - Training Epoch: 5/10, step 527/574 completed (loss: 0.04897636920213699, acc: 1.0)
[2024-11-29 03:24:31,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:31,654][root][INFO] - Training Epoch: 5/10, step 528/574 completed (loss: 1.2747994661331177, acc: 0.7049180269241333)
[2024-11-29 03:24:31,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:31,917][root][INFO] - Training Epoch: 5/10, step 529/574 completed (loss: 0.258675217628479, acc: 0.9152542352676392)
[2024-11-29 03:24:32,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:32,238][root][INFO] - Training Epoch: 5/10, step 530/574 completed (loss: 1.746955394744873, acc: 0.6279069781303406)
[2024-11-29 03:24:32,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:32,527][root][INFO] - Training Epoch: 5/10, step 531/574 completed (loss: 0.5791677236557007, acc: 0.8409090638160706)
[2024-11-29 03:24:32,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:32,832][root][INFO] - Training Epoch: 5/10, step 532/574 completed (loss: 1.185370922088623, acc: 0.6603773832321167)
[2024-11-29 03:24:32,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:33,096][root][INFO] - Training Epoch: 5/10, step 533/574 completed (loss: 0.9038417935371399, acc: 0.75)
[2024-11-29 03:24:33,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:33,364][root][INFO] - Training Epoch: 5/10, step 534/574 completed (loss: 0.5332919359207153, acc: 0.8799999952316284)
[2024-11-29 03:24:33,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:33,680][root][INFO] - Training Epoch: 5/10, step 535/574 completed (loss: 0.13202939927577972, acc: 1.0)
[2024-11-29 03:24:33,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:34,016][root][INFO] - Training Epoch: 5/10, step 536/574 completed (loss: 0.10027909278869629, acc: 1.0)
[2024-11-29 03:24:34,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:34,469][root][INFO] - Training Epoch: 5/10, step 537/574 completed (loss: 0.6218596696853638, acc: 0.8307692408561707)
[2024-11-29 03:24:34,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:34,812][root][INFO] - Training Epoch: 5/10, step 538/574 completed (loss: 0.34311047196388245, acc: 0.890625)
[2024-11-29 03:24:35,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:35,249][root][INFO] - Training Epoch: 5/10, step 539/574 completed (loss: 0.35473519563674927, acc: 0.90625)
[2024-11-29 03:24:35,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:35,524][root][INFO] - Training Epoch: 5/10, step 540/574 completed (loss: 1.0028079748153687, acc: 0.6666666865348816)
[2024-11-29 03:24:35,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:35,784][root][INFO] - Training Epoch: 5/10, step 541/574 completed (loss: 0.15907183289527893, acc: 0.875)
[2024-11-29 03:24:35,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:36,075][root][INFO] - Training Epoch: 5/10, step 542/574 completed (loss: 0.05267805606126785, acc: 0.9677419066429138)
[2024-11-29 03:24:36,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:36,369][root][INFO] - Training Epoch: 5/10, step 543/574 completed (loss: 0.013322395272552967, acc: 1.0)
[2024-11-29 03:24:36,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:36,658][root][INFO] - Training Epoch: 5/10, step 544/574 completed (loss: 0.12458541989326477, acc: 0.9333333373069763)
[2024-11-29 03:24:36,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:36,960][root][INFO] - Training Epoch: 5/10, step 545/574 completed (loss: 0.10768262296915054, acc: 0.9756097793579102)
[2024-11-29 03:24:37,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:37,239][root][INFO] - Training Epoch: 5/10, step 546/574 completed (loss: 0.2477831393480301, acc: 0.9428571462631226)
[2024-11-29 03:24:37,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:37,532][root][INFO] - Training Epoch: 5/10, step 547/574 completed (loss: 0.060043077915906906, acc: 0.9736841917037964)
[2024-11-29 03:24:37,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:37,786][root][INFO] - Training Epoch: 5/10, step 548/574 completed (loss: 0.06476697325706482, acc: 1.0)
[2024-11-29 03:24:37,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:38,067][root][INFO] - Training Epoch: 5/10, step 549/574 completed (loss: 0.040711577981710434, acc: 1.0)
[2024-11-29 03:24:38,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:38,365][root][INFO] - Training Epoch: 5/10, step 550/574 completed (loss: 0.07593447715044022, acc: 0.9696969985961914)
[2024-11-29 03:24:38,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:38,682][root][INFO] - Training Epoch: 5/10, step 551/574 completed (loss: 0.3367686867713928, acc: 0.8999999761581421)
[2024-11-29 03:24:38,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:38,955][root][INFO] - Training Epoch: 5/10, step 552/574 completed (loss: 0.3621673583984375, acc: 0.9285714030265808)
[2024-11-29 03:24:39,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:39,333][root][INFO] - Training Epoch: 5/10, step 553/574 completed (loss: 0.7046359181404114, acc: 0.8248175382614136)
[2024-11-29 03:24:39,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:39,691][root][INFO] - Training Epoch: 5/10, step 554/574 completed (loss: 0.5475982427597046, acc: 0.8551723957061768)
[2024-11-29 03:24:39,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:39,999][root][INFO] - Training Epoch: 5/10, step 555/574 completed (loss: 0.7484960556030273, acc: 0.8071428537368774)
[2024-11-29 03:24:40,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:40,338][root][INFO] - Training Epoch: 5/10, step 556/574 completed (loss: 0.6271448135375977, acc: 0.8476821184158325)
[2024-11-29 03:24:40,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:40,614][root][INFO] - Training Epoch: 5/10, step 557/574 completed (loss: 0.19367310404777527, acc: 0.94017094373703)
[2024-11-29 03:24:40,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:40,917][root][INFO] - Training Epoch: 5/10, step 558/574 completed (loss: 0.08816185593605042, acc: 0.9599999785423279)
[2024-11-29 03:24:41,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:41,201][root][INFO] - Training Epoch: 5/10, step 559/574 completed (loss: 0.07730215042829514, acc: 0.9615384340286255)
[2024-11-29 03:24:41,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:41,515][root][INFO] - Training Epoch: 5/10, step 560/574 completed (loss: 0.11049351096153259, acc: 0.9615384340286255)
[2024-11-29 03:24:41,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:41,861][root][INFO] - Training Epoch: 5/10, step 561/574 completed (loss: 0.21292442083358765, acc: 0.9487179517745972)
[2024-11-29 03:24:42,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:42,175][root][INFO] - Training Epoch: 5/10, step 562/574 completed (loss: 0.489151269197464, acc: 0.8333333134651184)
[2024-11-29 03:24:42,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:42,509][root][INFO] - Training Epoch: 5/10, step 563/574 completed (loss: 0.38086622953414917, acc: 0.8831169009208679)
[2024-11-29 03:24:43,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:43,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:44,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:44,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:44,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:45,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:45,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:46,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:46,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:47,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:47,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:48,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:48,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:49,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:49,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:50,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:50,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:51,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:51,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:51,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:52,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:52,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:53,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:53,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:54,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:54,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:54,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:55,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:55,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:56,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:56,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:57,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:57,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:57,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:58,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:58,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:59,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:59,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:24:59,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:00,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:00,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:01,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:01,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:02,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:02,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:02,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:03,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:03,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:04,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:04,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:05,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:05,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:06,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:06,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:07,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:07,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:07,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:08,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:08,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:09,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:09,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:10,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:10,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:11,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:11,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:12,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:12,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:12,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:13,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:14,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:14,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:14,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:15,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:15,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:16,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:16,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:16,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:17,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:17,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:18,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:18,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:18,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:19,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:19,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:20,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:21,008][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(4.0555, device='cuda:0') eval_epoch_loss=tensor(1.4001, device='cuda:0') eval_epoch_acc=tensor(0.6909, device='cuda:0')
[2024-11-29 03:25:21,009][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:25:21,009][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:25:21,248][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_5_step_564_loss_1.4000693559646606/model.pt
[2024-11-29 03:25:21,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:21,577][root][INFO] - Training Epoch: 5/10, step 564/574 completed (loss: 0.5253796577453613, acc: 0.8333333134651184)
[2024-11-29 03:25:21,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:21,901][root][INFO] - Training Epoch: 5/10, step 565/574 completed (loss: 0.2853933572769165, acc: 0.9482758641242981)
[2024-11-29 03:25:22,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:22,221][root][INFO] - Training Epoch: 5/10, step 566/574 completed (loss: 0.39604029059410095, acc: 0.9285714030265808)
[2024-11-29 03:25:22,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:22,577][root][INFO] - Training Epoch: 5/10, step 567/574 completed (loss: 0.09197303652763367, acc: 0.9736841917037964)
[2024-11-29 03:25:22,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:22,879][root][INFO] - Training Epoch: 5/10, step 568/574 completed (loss: 0.07142645865678787, acc: 0.9629629850387573)
[2024-11-29 03:25:23,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:23,300][root][INFO] - Training Epoch: 5/10, step 569/574 completed (loss: 0.6682161688804626, acc: 0.8395721912384033)
[2024-11-29 03:25:23,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:23,564][root][INFO] - Training Epoch: 5/10, step 570/574 completed (loss: 0.363785058259964, acc: 0.9354838728904724)
[2024-11-29 03:25:23,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:23,879][root][INFO] - Training Epoch: 5/10, step 571/574 completed (loss: 0.44692572951316833, acc: 0.8803418874740601)
[2024-11-29 03:25:24,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:24,151][root][INFO] - Training Epoch: 5/10, step 572/574 completed (loss: 0.9147254228591919, acc: 0.7653061151504517)
[2024-11-29 03:25:24,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:24,476][root][INFO] - Training Epoch: 5/10, step 573/574 completed (loss: 0.6978726387023926, acc: 0.7924528121948242)
[2024-11-29 03:25:24,996][slam_llm.utils.train_utils][INFO] - Epoch 5: train_perplexity=1.7112, train_epoch_loss=0.5372, epoch time 380.9450770840049s
[2024-11-29 03:25:24,997][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-11-29 03:25:24,997][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 16 GB
[2024-11-29 03:25:24,997][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-11-29 03:25:24,997][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 11
[2024-11-29 03:25:24,997][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-29 03:25:25,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:25,725][root][INFO] - Training Epoch: 6/10, step 0/574 completed (loss: 0.14830543100833893, acc: 0.9629629850387573)
[2024-11-29 03:25:25,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:26,039][root][INFO] - Training Epoch: 6/10, step 1/574 completed (loss: 0.15766486525535583, acc: 0.9599999785423279)
[2024-11-29 03:25:26,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:26,347][root][INFO] - Training Epoch: 6/10, step 2/574 completed (loss: 0.3914622366428375, acc: 0.8648648858070374)
[2024-11-29 03:25:26,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:26,652][root][INFO] - Training Epoch: 6/10, step 3/574 completed (loss: 0.3802841603755951, acc: 0.9210526347160339)
[2024-11-29 03:25:26,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:26,926][root][INFO] - Training Epoch: 6/10, step 4/574 completed (loss: 0.24874965846538544, acc: 0.8648648858070374)
[2024-11-29 03:25:27,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:27,180][root][INFO] - Training Epoch: 6/10, step 5/574 completed (loss: 0.08835726231336594, acc: 0.9642857313156128)
[2024-11-29 03:25:27,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:27,455][root][INFO] - Training Epoch: 6/10, step 6/574 completed (loss: 0.30829381942749023, acc: 0.8571428656578064)
[2024-11-29 03:25:27,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:27,702][root][INFO] - Training Epoch: 6/10, step 7/574 completed (loss: 0.23033253848552704, acc: 0.9666666388511658)
[2024-11-29 03:25:27,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:28,001][root][INFO] - Training Epoch: 6/10, step 8/574 completed (loss: 0.012913919053971767, acc: 1.0)
[2024-11-29 03:25:28,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:28,274][root][INFO] - Training Epoch: 6/10, step 9/574 completed (loss: 0.1225392073392868, acc: 0.9615384340286255)
[2024-11-29 03:25:28,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:28,520][root][INFO] - Training Epoch: 6/10, step 10/574 completed (loss: 0.17099887132644653, acc: 0.8888888955116272)
[2024-11-29 03:25:28,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:28,780][root][INFO] - Training Epoch: 6/10, step 11/574 completed (loss: 0.2194904237985611, acc: 0.9487179517745972)
[2024-11-29 03:25:28,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:29,043][root][INFO] - Training Epoch: 6/10, step 12/574 completed (loss: 0.09177913516759872, acc: 0.939393937587738)
[2024-11-29 03:25:29,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:29,307][root][INFO] - Training Epoch: 6/10, step 13/574 completed (loss: 0.15786278247833252, acc: 0.9347826242446899)
[2024-11-29 03:25:29,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:29,563][root][INFO] - Training Epoch: 6/10, step 14/574 completed (loss: 0.1665351390838623, acc: 0.9215686321258545)
[2024-11-29 03:25:29,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:29,831][root][INFO] - Training Epoch: 6/10, step 15/574 completed (loss: 0.20830248296260834, acc: 0.9795918464660645)
[2024-11-29 03:25:29,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:30,083][root][INFO] - Training Epoch: 6/10, step 16/574 completed (loss: 0.013051553629338741, acc: 1.0)
[2024-11-29 03:25:30,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:30,346][root][INFO] - Training Epoch: 6/10, step 17/574 completed (loss: 0.32922568917274475, acc: 0.9166666865348816)
[2024-11-29 03:25:30,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:30,600][root][INFO] - Training Epoch: 6/10, step 18/574 completed (loss: 0.4778391122817993, acc: 0.8333333134651184)
[2024-11-29 03:25:30,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:30,856][root][INFO] - Training Epoch: 6/10, step 19/574 completed (loss: 0.21250328421592712, acc: 0.9473684430122375)
[2024-11-29 03:25:31,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:31,117][root][INFO] - Training Epoch: 6/10, step 20/574 completed (loss: 0.13468223810195923, acc: 0.9615384340286255)
[2024-11-29 03:25:31,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:31,360][root][INFO] - Training Epoch: 6/10, step 21/574 completed (loss: 0.2909826338291168, acc: 0.931034505367279)
[2024-11-29 03:25:31,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:31,653][root][INFO] - Training Epoch: 6/10, step 22/574 completed (loss: 0.28185853362083435, acc: 0.8399999737739563)
[2024-11-29 03:25:31,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:31,960][root][INFO] - Training Epoch: 6/10, step 23/574 completed (loss: 0.09054705500602722, acc: 1.0)
[2024-11-29 03:25:32,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:32,280][root][INFO] - Training Epoch: 6/10, step 24/574 completed (loss: 0.050448570400476456, acc: 1.0)
[2024-11-29 03:25:32,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:32,608][root][INFO] - Training Epoch: 6/10, step 25/574 completed (loss: 0.4101700782775879, acc: 0.8867924809455872)
[2024-11-29 03:25:32,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:32,909][root][INFO] - Training Epoch: 6/10, step 26/574 completed (loss: 0.9295804500579834, acc: 0.698630154132843)
[2024-11-29 03:25:33,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:34,570][root][INFO] - Training Epoch: 6/10, step 27/574 completed (loss: 1.4998005628585815, acc: 0.6166008114814758)
[2024-11-29 03:25:34,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:34,887][root][INFO] - Training Epoch: 6/10, step 28/574 completed (loss: 0.3008490800857544, acc: 0.930232584476471)
[2024-11-29 03:25:35,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:35,212][root][INFO] - Training Epoch: 6/10, step 29/574 completed (loss: 0.6426552534103394, acc: 0.8192771077156067)
[2024-11-29 03:25:35,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:35,522][root][INFO] - Training Epoch: 6/10, step 30/574 completed (loss: 0.8391603827476501, acc: 0.8024691343307495)
[2024-11-29 03:25:35,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:35,851][root][INFO] - Training Epoch: 6/10, step 31/574 completed (loss: 0.4119739532470703, acc: 0.8928571343421936)
[2024-11-29 03:25:36,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:36,158][root][INFO] - Training Epoch: 6/10, step 32/574 completed (loss: 0.07046211510896683, acc: 1.0)
[2024-11-29 03:25:36,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:36,452][root][INFO] - Training Epoch: 6/10, step 33/574 completed (loss: 0.04968767240643501, acc: 1.0)
[2024-11-29 03:25:36,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:36,833][root][INFO] - Training Epoch: 6/10, step 34/574 completed (loss: 0.589063286781311, acc: 0.848739504814148)
[2024-11-29 03:25:37,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:37,144][root][INFO] - Training Epoch: 6/10, step 35/574 completed (loss: 0.27151185274124146, acc: 0.9508196711540222)
[2024-11-29 03:25:37,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:37,413][root][INFO] - Training Epoch: 6/10, step 36/574 completed (loss: 0.4982631802558899, acc: 0.8888888955116272)
[2024-11-29 03:25:37,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:37,662][root][INFO] - Training Epoch: 6/10, step 37/574 completed (loss: 0.44895145297050476, acc: 0.8983050584793091)
[2024-11-29 03:25:37,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:37,969][root][INFO] - Training Epoch: 6/10, step 38/574 completed (loss: 0.232962504029274, acc: 0.954023003578186)
[2024-11-29 03:25:38,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:38,298][root][INFO] - Training Epoch: 6/10, step 39/574 completed (loss: 0.6961992979049683, acc: 0.8095238208770752)
[2024-11-29 03:25:38,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:38,672][root][INFO] - Training Epoch: 6/10, step 40/574 completed (loss: 0.4470193088054657, acc: 0.8846153616905212)
[2024-11-29 03:25:38,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:39,070][root][INFO] - Training Epoch: 6/10, step 41/574 completed (loss: 0.18967832624912262, acc: 0.9189189076423645)
[2024-11-29 03:25:39,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:39,405][root][INFO] - Training Epoch: 6/10, step 42/574 completed (loss: 0.6689380407333374, acc: 0.8307692408561707)
[2024-11-29 03:25:39,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:39,877][root][INFO] - Training Epoch: 6/10, step 43/574 completed (loss: 0.704066276550293, acc: 0.808080792427063)
[2024-11-29 03:25:40,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:40,346][root][INFO] - Training Epoch: 6/10, step 44/574 completed (loss: 0.6424950361251831, acc: 0.8144329786300659)
[2024-11-29 03:25:40,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:40,787][root][INFO] - Training Epoch: 6/10, step 45/574 completed (loss: 0.62233567237854, acc: 0.8088235259056091)
[2024-11-29 03:25:40,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:41,056][root][INFO] - Training Epoch: 6/10, step 46/574 completed (loss: 0.2141251564025879, acc: 0.9615384340286255)
[2024-11-29 03:25:41,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:41,325][root][INFO] - Training Epoch: 6/10, step 47/574 completed (loss: 0.12820088863372803, acc: 0.9629629850387573)
[2024-11-29 03:25:41,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:41,555][root][INFO] - Training Epoch: 6/10, step 48/574 completed (loss: 0.04929462447762489, acc: 1.0)
[2024-11-29 03:25:41,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:41,807][root][INFO] - Training Epoch: 6/10, step 49/574 completed (loss: 0.12860481441020966, acc: 0.9722222089767456)
[2024-11-29 03:25:41,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:42,063][root][INFO] - Training Epoch: 6/10, step 50/574 completed (loss: 0.6115837693214417, acc: 0.859649121761322)
[2024-11-29 03:25:42,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:42,325][root][INFO] - Training Epoch: 6/10, step 51/574 completed (loss: 0.6252967119216919, acc: 0.7936508059501648)
[2024-11-29 03:25:42,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:42,605][root][INFO] - Training Epoch: 6/10, step 52/574 completed (loss: 0.8758864402770996, acc: 0.7464788556098938)
[2024-11-29 03:25:42,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:43,149][root][INFO] - Training Epoch: 6/10, step 53/574 completed (loss: 1.5271934270858765, acc: 0.5799999833106995)
[2024-11-29 03:25:43,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:43,398][root][INFO] - Training Epoch: 6/10, step 54/574 completed (loss: 0.49857592582702637, acc: 0.837837815284729)
[2024-11-29 03:25:43,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:43,679][root][INFO] - Training Epoch: 6/10, step 55/574 completed (loss: 0.08937627822160721, acc: 0.9615384340286255)
[2024-11-29 03:25:46,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:47,641][root][INFO] - Training Epoch: 6/10, step 56/574 completed (loss: 1.354963779449463, acc: 0.6518771052360535)
[2024-11-29 03:25:48,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:49,370][root][INFO] - Training Epoch: 6/10, step 57/574 completed (loss: 1.5058085918426514, acc: 0.6034858226776123)
[2024-11-29 03:25:49,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:50,195][root][INFO] - Training Epoch: 6/10, step 58/574 completed (loss: 0.7825994491577148, acc: 0.7613636255264282)
[2024-11-29 03:25:50,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:50,964][root][INFO] - Training Epoch: 6/10, step 59/574 completed (loss: 0.4280834197998047, acc: 0.875)
[2024-11-29 03:25:51,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:51,715][root][INFO] - Training Epoch: 6/10, step 60/574 completed (loss: 0.8833888173103333, acc: 0.7318840622901917)
[2024-11-29 03:25:51,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:52,205][root][INFO] - Training Epoch: 6/10, step 61/574 completed (loss: 0.744507908821106, acc: 0.8125)
[2024-11-29 03:25:52,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:52,463][root][INFO] - Training Epoch: 6/10, step 62/574 completed (loss: 0.2329580932855606, acc: 0.8823529481887817)
[2024-11-29 03:25:52,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:52,783][root][INFO] - Training Epoch: 6/10, step 63/574 completed (loss: 0.03252086043357849, acc: 1.0)
[2024-11-29 03:25:52,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:53,126][root][INFO] - Training Epoch: 6/10, step 64/574 completed (loss: 0.09674576669931412, acc: 0.984375)
[2024-11-29 03:25:53,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:53,462][root][INFO] - Training Epoch: 6/10, step 65/574 completed (loss: 0.21985900402069092, acc: 0.9655172228813171)
[2024-11-29 03:25:53,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:53,824][root][INFO] - Training Epoch: 6/10, step 66/574 completed (loss: 0.5596114993095398, acc: 0.8928571343421936)
[2024-11-29 03:25:53,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:54,126][root][INFO] - Training Epoch: 6/10, step 67/574 completed (loss: 0.2810315489768982, acc: 0.9333333373069763)
[2024-11-29 03:25:54,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:54,383][root][INFO] - Training Epoch: 6/10, step 68/574 completed (loss: 0.017285512760281563, acc: 1.0)
[2024-11-29 03:25:54,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:54,682][root][INFO] - Training Epoch: 6/10, step 69/574 completed (loss: 0.3823751211166382, acc: 0.8888888955116272)
[2024-11-29 03:25:54,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:55,063][root][INFO] - Training Epoch: 6/10, step 70/574 completed (loss: 0.28224146366119385, acc: 0.939393937587738)
[2024-11-29 03:25:55,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:55,439][root][INFO] - Training Epoch: 6/10, step 71/574 completed (loss: 1.3155571222305298, acc: 0.6397058963775635)
[2024-11-29 03:25:55,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:55,779][root][INFO] - Training Epoch: 6/10, step 72/574 completed (loss: 0.7321097254753113, acc: 0.7857142686843872)
[2024-11-29 03:25:55,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:56,106][root][INFO] - Training Epoch: 6/10, step 73/574 completed (loss: 1.5873212814331055, acc: 0.6153846383094788)
[2024-11-29 03:25:56,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:56,420][root][INFO] - Training Epoch: 6/10, step 74/574 completed (loss: 1.034395456314087, acc: 0.7346938848495483)
[2024-11-29 03:25:56,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:56,706][root][INFO] - Training Epoch: 6/10, step 75/574 completed (loss: 1.2424812316894531, acc: 0.7089552283287048)
[2024-11-29 03:25:56,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:57,170][root][INFO] - Training Epoch: 6/10, step 76/574 completed (loss: 1.740308403968811, acc: 0.5510948896408081)
[2024-11-29 03:25:57,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:57,481][root][INFO] - Training Epoch: 6/10, step 77/574 completed (loss: 0.010825060307979584, acc: 1.0)
[2024-11-29 03:25:57,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:57,812][root][INFO] - Training Epoch: 6/10, step 78/574 completed (loss: 0.08523628860712051, acc: 1.0)
[2024-11-29 03:25:57,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:58,123][root][INFO] - Training Epoch: 6/10, step 79/574 completed (loss: 0.1515955626964569, acc: 0.939393937587738)
[2024-11-29 03:25:58,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:58,436][root][INFO] - Training Epoch: 6/10, step 80/574 completed (loss: 0.1195736974477768, acc: 0.9615384340286255)
[2024-11-29 03:25:58,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:58,749][root][INFO] - Training Epoch: 6/10, step 81/574 completed (loss: 0.2961231470108032, acc: 0.9038461446762085)
[2024-11-29 03:25:58,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:59,059][root][INFO] - Training Epoch: 6/10, step 82/574 completed (loss: 0.5053961277008057, acc: 0.8846153616905212)
[2024-11-29 03:25:59,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:59,369][root][INFO] - Training Epoch: 6/10, step 83/574 completed (loss: 0.1528427004814148, acc: 0.96875)
[2024-11-29 03:25:59,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:25:59,695][root][INFO] - Training Epoch: 6/10, step 84/574 completed (loss: 0.27500036358833313, acc: 0.9275362491607666)
[2024-11-29 03:25:59,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:00,029][root][INFO] - Training Epoch: 6/10, step 85/574 completed (loss: 0.40350842475891113, acc: 0.8600000143051147)
[2024-11-29 03:26:00,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:00,388][root][INFO] - Training Epoch: 6/10, step 86/574 completed (loss: 0.04846128076314926, acc: 1.0)
[2024-11-29 03:26:00,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:01,026][root][INFO] - Training Epoch: 6/10, step 87/574 completed (loss: 0.8196196556091309, acc: 0.7200000286102295)
[2024-11-29 03:26:01,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:01,426][root][INFO] - Training Epoch: 6/10, step 88/574 completed (loss: 0.9039932489395142, acc: 0.7669903039932251)
[2024-11-29 03:26:02,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:03,121][root][INFO] - Training Epoch: 6/10, step 89/574 completed (loss: 1.0661107301712036, acc: 0.708737850189209)
[2024-11-29 03:26:03,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:04,292][root][INFO] - Training Epoch: 6/10, step 90/574 completed (loss: 1.456403374671936, acc: 0.6666666865348816)
[2024-11-29 03:26:05,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:05,544][root][INFO] - Training Epoch: 6/10, step 91/574 completed (loss: 1.1142443418502808, acc: 0.7155172228813171)
[2024-11-29 03:26:06,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:06,591][root][INFO] - Training Epoch: 6/10, step 92/574 completed (loss: 1.0118358135223389, acc: 0.7368420958518982)
[2024-11-29 03:26:07,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:08,129][root][INFO] - Training Epoch: 6/10, step 93/574 completed (loss: 1.343557357788086, acc: 0.6633663177490234)
[2024-11-29 03:26:08,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:08,419][root][INFO] - Training Epoch: 6/10, step 94/574 completed (loss: 1.0093733072280884, acc: 0.6935483813285828)
[2024-11-29 03:26:08,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:08,733][root][INFO] - Training Epoch: 6/10, step 95/574 completed (loss: 0.6299945712089539, acc: 0.8260869383811951)
[2024-11-29 03:26:08,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:09,095][root][INFO] - Training Epoch: 6/10, step 96/574 completed (loss: 1.1757071018218994, acc: 0.6134454011917114)
[2024-11-29 03:26:09,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:09,442][root][INFO] - Training Epoch: 6/10, step 97/574 completed (loss: 1.299013614654541, acc: 0.6153846383094788)
[2024-11-29 03:26:09,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:09,843][root][INFO] - Training Epoch: 6/10, step 98/574 completed (loss: 1.489661455154419, acc: 0.5620437860488892)
[2024-11-29 03:26:09,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:10,121][root][INFO] - Training Epoch: 6/10, step 99/574 completed (loss: 1.173681378364563, acc: 0.6716417670249939)
[2024-11-29 03:26:10,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:10,379][root][INFO] - Training Epoch: 6/10, step 100/574 completed (loss: 0.4698517918586731, acc: 0.800000011920929)
[2024-11-29 03:26:10,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:10,696][root][INFO] - Training Epoch: 6/10, step 101/574 completed (loss: 0.009854650124907494, acc: 1.0)
[2024-11-29 03:26:10,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:10,996][root][INFO] - Training Epoch: 6/10, step 102/574 completed (loss: 0.03159736469388008, acc: 1.0)
[2024-11-29 03:26:11,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:11,308][root][INFO] - Training Epoch: 6/10, step 103/574 completed (loss: 0.04978816211223602, acc: 0.9772727489471436)
[2024-11-29 03:26:11,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:11,591][root][INFO] - Training Epoch: 6/10, step 104/574 completed (loss: 0.5473441481590271, acc: 0.8448275923728943)
[2024-11-29 03:26:11,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:11,896][root][INFO] - Training Epoch: 6/10, step 105/574 completed (loss: 0.1949349343776703, acc: 0.9534883499145508)
[2024-11-29 03:26:12,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:12,220][root][INFO] - Training Epoch: 6/10, step 106/574 completed (loss: 0.17259936034679413, acc: 0.9200000166893005)
[2024-11-29 03:26:12,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:12,555][root][INFO] - Training Epoch: 6/10, step 107/574 completed (loss: 0.032124727964401245, acc: 1.0)
[2024-11-29 03:26:12,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:12,921][root][INFO] - Training Epoch: 6/10, step 108/574 completed (loss: 0.01206484530121088, acc: 1.0)
[2024-11-29 03:26:13,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:13,273][root][INFO] - Training Epoch: 6/10, step 109/574 completed (loss: 0.06431623548269272, acc: 0.976190447807312)
[2024-11-29 03:26:13,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:13,598][root][INFO] - Training Epoch: 6/10, step 110/574 completed (loss: 0.1952807456254959, acc: 0.9384615421295166)
[2024-11-29 03:26:13,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:14,066][root][INFO] - Training Epoch: 6/10, step 111/574 completed (loss: 0.3847895562648773, acc: 0.8771929740905762)
[2024-11-29 03:26:14,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:14,421][root][INFO] - Training Epoch: 6/10, step 112/574 completed (loss: 0.5082458257675171, acc: 0.8421052694320679)
[2024-11-29 03:26:14,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:14,765][root][INFO] - Training Epoch: 6/10, step 113/574 completed (loss: 0.3306601643562317, acc: 0.9230769276618958)
[2024-11-29 03:26:14,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:15,138][root][INFO] - Training Epoch: 6/10, step 114/574 completed (loss: 0.18318569660186768, acc: 0.9387755393981934)
[2024-11-29 03:26:15,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:15,387][root][INFO] - Training Epoch: 6/10, step 115/574 completed (loss: 0.01992572285234928, acc: 1.0)
[2024-11-29 03:26:15,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:15,756][root][INFO] - Training Epoch: 6/10, step 116/574 completed (loss: 0.48551592230796814, acc: 0.8888888955116272)
[2024-11-29 03:26:15,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:16,128][root][INFO] - Training Epoch: 6/10, step 117/574 completed (loss: 0.45195895433425903, acc: 0.8780487775802612)
[2024-11-29 03:26:16,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:16,456][root][INFO] - Training Epoch: 6/10, step 118/574 completed (loss: 0.24399708211421967, acc: 0.9516128897666931)
[2024-11-29 03:26:17,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:17,649][root][INFO] - Training Epoch: 6/10, step 119/574 completed (loss: 1.0156999826431274, acc: 0.730038046836853)
[2024-11-29 03:26:17,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:17,972][root][INFO] - Training Epoch: 6/10, step 120/574 completed (loss: 0.29779142141342163, acc: 0.9333333373069763)
[2024-11-29 03:26:18,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:18,421][root][INFO] - Training Epoch: 6/10, step 121/574 completed (loss: 0.30623510479927063, acc: 0.9230769276618958)
[2024-11-29 03:26:18,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:18,664][root][INFO] - Training Epoch: 6/10, step 122/574 completed (loss: 0.014533759094774723, acc: 1.0)
[2024-11-29 03:26:18,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:18,979][root][INFO] - Training Epoch: 6/10, step 123/574 completed (loss: 0.23950213193893433, acc: 0.9473684430122375)
[2024-11-29 03:26:19,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:19,334][root][INFO] - Training Epoch: 6/10, step 124/574 completed (loss: 1.4900833368301392, acc: 0.6073619723320007)
[2024-11-29 03:26:19,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:19,684][root][INFO] - Training Epoch: 6/10, step 125/574 completed (loss: 1.3069519996643066, acc: 0.6597222089767456)
[2024-11-29 03:26:19,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:19,954][root][INFO] - Training Epoch: 6/10, step 126/574 completed (loss: 1.04608952999115, acc: 0.6916666626930237)
[2024-11-29 03:26:20,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:20,297][root][INFO] - Training Epoch: 6/10, step 127/574 completed (loss: 1.2435070276260376, acc: 0.6547619104385376)
[2024-11-29 03:26:20,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:20,650][root][INFO] - Training Epoch: 6/10, step 128/574 completed (loss: 0.9905409812927246, acc: 0.7384615540504456)
[2024-11-29 03:26:20,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:21,092][root][INFO] - Training Epoch: 6/10, step 129/574 completed (loss: 1.0637034177780151, acc: 0.6911764740943909)
[2024-11-29 03:26:21,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:21,399][root][INFO] - Training Epoch: 6/10, step 130/574 completed (loss: 0.5960817933082581, acc: 0.807692289352417)
[2024-11-29 03:26:21,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:21,720][root][INFO] - Training Epoch: 6/10, step 131/574 completed (loss: 0.6455286741256714, acc: 0.782608687877655)
[2024-11-29 03:26:21,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:22,029][root][INFO] - Training Epoch: 6/10, step 132/574 completed (loss: 0.8159081935882568, acc: 0.8125)
[2024-11-29 03:26:23,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:23,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:24,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:24,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:24,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:25,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:25,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:26,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:26,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:27,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:27,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:28,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:28,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:29,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:29,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:29,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:30,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:30,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:31,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:31,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:32,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:32,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:32,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:33,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:33,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:34,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:34,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:35,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:35,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:35,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:36,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:36,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:37,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:37,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:38,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:38,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:38,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:39,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:39,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:40,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:40,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:41,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:41,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:41,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:42,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:42,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:43,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:43,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:43,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:44,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:44,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:44,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:45,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:45,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:46,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:46,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:46,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:47,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:47,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:48,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:48,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:49,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:49,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:50,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:50,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:51,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:51,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:52,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:52,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:53,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:53,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:54,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:54,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:55,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:55,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:55,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:56,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:56,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:57,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:57,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:58,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:58,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:59,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:26:59,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:00,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:00,992][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.7781, device='cuda:0') eval_epoch_loss=tensor(1.0218, device='cuda:0') eval_epoch_acc=tensor(0.7605, device='cuda:0')
[2024-11-29 03:27:00,994][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:27:00,994][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:27:01,316][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_6_step_133_loss_1.0217609405517578/model.pt
[2024-11-29 03:27:01,322][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 6 is 1.0217609405517578
[2024-11-29 03:27:01,322][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 6 is 0.7604701519012451
[2024-11-29 03:27:01,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:01,615][root][INFO] - Training Epoch: 6/10, step 133/574 completed (loss: 0.21270199120044708, acc: 0.95652174949646)
[2024-11-29 03:27:01,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:01,882][root][INFO] - Training Epoch: 6/10, step 134/574 completed (loss: 0.5560274720191956, acc: 0.800000011920929)
[2024-11-29 03:27:02,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:02,156][root][INFO] - Training Epoch: 6/10, step 135/574 completed (loss: 0.37437868118286133, acc: 0.8846153616905212)
[2024-11-29 03:27:02,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:02,463][root][INFO] - Training Epoch: 6/10, step 136/574 completed (loss: 0.44968491792678833, acc: 0.8809523582458496)
[2024-11-29 03:27:02,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:02,731][root][INFO] - Training Epoch: 6/10, step 137/574 completed (loss: 1.351983904838562, acc: 0.699999988079071)
[2024-11-29 03:27:02,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:02,977][root][INFO] - Training Epoch: 6/10, step 138/574 completed (loss: 0.48097336292266846, acc: 0.8695651888847351)
[2024-11-29 03:27:03,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:03,247][root][INFO] - Training Epoch: 6/10, step 139/574 completed (loss: 0.11567860841751099, acc: 0.9523809552192688)
[2024-11-29 03:27:03,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:03,501][root][INFO] - Training Epoch: 6/10, step 140/574 completed (loss: 0.17107318341732025, acc: 0.9615384340286255)
[2024-11-29 03:27:03,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:03,759][root][INFO] - Training Epoch: 6/10, step 141/574 completed (loss: 0.32916370034217834, acc: 0.9354838728904724)
[2024-11-29 03:27:03,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:04,006][root][INFO] - Training Epoch: 6/10, step 142/574 completed (loss: 0.1323012113571167, acc: 0.9729729890823364)
[2024-11-29 03:27:04,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:04,798][root][INFO] - Training Epoch: 6/10, step 143/574 completed (loss: 0.676873505115509, acc: 0.8157894611358643)
[2024-11-29 03:27:04,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:05,120][root][INFO] - Training Epoch: 6/10, step 144/574 completed (loss: 0.808329701423645, acc: 0.7985074520111084)
[2024-11-29 03:27:05,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:05,451][root][INFO] - Training Epoch: 6/10, step 145/574 completed (loss: 0.5246153473854065, acc: 0.8163265585899353)
[2024-11-29 03:27:05,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:06,002][root][INFO] - Training Epoch: 6/10, step 146/574 completed (loss: 0.976424515247345, acc: 0.7446808218955994)
[2024-11-29 03:27:06,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:06,283][root][INFO] - Training Epoch: 6/10, step 147/574 completed (loss: 0.6682376265525818, acc: 0.7714285850524902)
[2024-11-29 03:27:06,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:06,580][root][INFO] - Training Epoch: 6/10, step 148/574 completed (loss: 0.3763594925403595, acc: 0.9285714030265808)
[2024-11-29 03:27:06,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:06,832][root][INFO] - Training Epoch: 6/10, step 149/574 completed (loss: 0.993054211139679, acc: 0.695652186870575)
[2024-11-29 03:27:06,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:07,092][root][INFO] - Training Epoch: 6/10, step 150/574 completed (loss: 0.4548489451408386, acc: 0.931034505367279)
[2024-11-29 03:27:07,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:07,382][root][INFO] - Training Epoch: 6/10, step 151/574 completed (loss: 0.6216645836830139, acc: 0.8260869383811951)
[2024-11-29 03:27:07,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:07,676][root][INFO] - Training Epoch: 6/10, step 152/574 completed (loss: 0.7098625898361206, acc: 0.8305084705352783)
[2024-11-29 03:27:07,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:08,044][root][INFO] - Training Epoch: 6/10, step 153/574 completed (loss: 0.7870307564735413, acc: 0.7894737124443054)
[2024-11-29 03:27:08,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:08,340][root][INFO] - Training Epoch: 6/10, step 154/574 completed (loss: 0.4883502125740051, acc: 0.8918918967247009)
[2024-11-29 03:27:08,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:08,588][root][INFO] - Training Epoch: 6/10, step 155/574 completed (loss: 0.10648269206285477, acc: 0.9642857313156128)
[2024-11-29 03:27:08,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:08,852][root][INFO] - Training Epoch: 6/10, step 156/574 completed (loss: 0.7485459446907043, acc: 0.8695651888847351)
[2024-11-29 03:27:09,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:09,176][root][INFO] - Training Epoch: 6/10, step 157/574 completed (loss: 3.287670850753784, acc: 0.10526315867900848)
[2024-11-29 03:27:10,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:11,816][root][INFO] - Training Epoch: 6/10, step 158/574 completed (loss: 1.6257741451263428, acc: 0.5405405163764954)
[2024-11-29 03:27:12,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:12,174][root][INFO] - Training Epoch: 6/10, step 159/574 completed (loss: 1.407856822013855, acc: 0.5740740895271301)
[2024-11-29 03:27:12,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:12,659][root][INFO] - Training Epoch: 6/10, step 160/574 completed (loss: 1.6236934661865234, acc: 0.5581395626068115)
[2024-11-29 03:27:13,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:13,524][root][INFO] - Training Epoch: 6/10, step 161/574 completed (loss: 1.8571760654449463, acc: 0.4941176474094391)
[2024-11-29 03:27:13,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:14,288][root][INFO] - Training Epoch: 6/10, step 162/574 completed (loss: 1.538031816482544, acc: 0.5955055952072144)
[2024-11-29 03:27:14,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:14,614][root][INFO] - Training Epoch: 6/10, step 163/574 completed (loss: 0.4982990026473999, acc: 0.8181818127632141)
[2024-11-29 03:27:14,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:14,870][root][INFO] - Training Epoch: 6/10, step 164/574 completed (loss: 0.7681798338890076, acc: 0.761904776096344)
[2024-11-29 03:27:15,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:15,151][root][INFO] - Training Epoch: 6/10, step 165/574 completed (loss: 1.856398344039917, acc: 0.6206896305084229)
[2024-11-29 03:27:15,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:15,470][root][INFO] - Training Epoch: 6/10, step 166/574 completed (loss: 0.12667328119277954, acc: 0.9387755393981934)
[2024-11-29 03:27:15,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:15,735][root][INFO] - Training Epoch: 6/10, step 167/574 completed (loss: 0.31973618268966675, acc: 0.9200000166893005)
[2024-11-29 03:27:15,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:16,193][root][INFO] - Training Epoch: 6/10, step 168/574 completed (loss: 0.5467679500579834, acc: 0.8055555820465088)
[2024-11-29 03:27:16,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:16,502][root][INFO] - Training Epoch: 6/10, step 169/574 completed (loss: 1.1284457445144653, acc: 0.7156862616539001)
[2024-11-29 03:27:17,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:18,226][root][INFO] - Training Epoch: 6/10, step 170/574 completed (loss: 1.3487548828125, acc: 0.6506849527359009)
[2024-11-29 03:27:18,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:18,527][root][INFO] - Training Epoch: 6/10, step 171/574 completed (loss: 0.31272760033607483, acc: 0.9166666865348816)
[2024-11-29 03:27:18,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:18,863][root][INFO] - Training Epoch: 6/10, step 172/574 completed (loss: 1.227264404296875, acc: 0.7407407164573669)
[2024-11-29 03:27:19,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:19,171][root][INFO] - Training Epoch: 6/10, step 173/574 completed (loss: 0.20689842104911804, acc: 0.9285714030265808)
[2024-11-29 03:27:19,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:19,896][root][INFO] - Training Epoch: 6/10, step 174/574 completed (loss: 1.2071561813354492, acc: 0.7168141603469849)
[2024-11-29 03:27:20,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:20,230][root][INFO] - Training Epoch: 6/10, step 175/574 completed (loss: 0.6534151434898376, acc: 0.7971014380455017)
[2024-11-29 03:27:20,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:20,557][root][INFO] - Training Epoch: 6/10, step 176/574 completed (loss: 0.42268991470336914, acc: 0.875)
[2024-11-29 03:27:21,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:21,951][root][INFO] - Training Epoch: 6/10, step 177/574 completed (loss: 1.2408860921859741, acc: 0.694656491279602)
[2024-11-29 03:27:22,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:22,891][root][INFO] - Training Epoch: 6/10, step 178/574 completed (loss: 1.0400840044021606, acc: 0.7111111283302307)
[2024-11-29 03:27:23,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:23,208][root][INFO] - Training Epoch: 6/10, step 179/574 completed (loss: 0.22678297758102417, acc: 0.9016393423080444)
[2024-11-29 03:27:23,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:23,458][root][INFO] - Training Epoch: 6/10, step 180/574 completed (loss: 0.02037237025797367, acc: 1.0)
[2024-11-29 03:27:23,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:23,766][root][INFO] - Training Epoch: 6/10, step 181/574 completed (loss: 0.015675624832510948, acc: 1.0)
[2024-11-29 03:27:23,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:24,062][root][INFO] - Training Epoch: 6/10, step 182/574 completed (loss: 0.050328198820352554, acc: 1.0)
[2024-11-29 03:27:24,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:24,395][root][INFO] - Training Epoch: 6/10, step 183/574 completed (loss: 0.21949872374534607, acc: 0.9024389982223511)
[2024-11-29 03:27:24,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:24,750][root][INFO] - Training Epoch: 6/10, step 184/574 completed (loss: 0.8406984210014343, acc: 0.7945619225502014)
[2024-11-29 03:27:24,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:25,095][root][INFO] - Training Epoch: 6/10, step 185/574 completed (loss: 0.9342247843742371, acc: 0.7377521395683289)
[2024-11-29 03:27:25,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:25,702][root][INFO] - Training Epoch: 6/10, step 186/574 completed (loss: 0.8541553616523743, acc: 0.746874988079071)
[2024-11-29 03:27:26,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:26,358][root][INFO] - Training Epoch: 6/10, step 187/574 completed (loss: 1.1123183965682983, acc: 0.7110694050788879)
[2024-11-29 03:27:26,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:26,805][root][INFO] - Training Epoch: 6/10, step 188/574 completed (loss: 0.7334983944892883, acc: 0.7793594598770142)
[2024-11-29 03:27:26,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:27,140][root][INFO] - Training Epoch: 6/10, step 189/574 completed (loss: 0.5143066048622131, acc: 0.800000011920929)
[2024-11-29 03:27:27,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:27,898][root][INFO] - Training Epoch: 6/10, step 190/574 completed (loss: 0.8339601755142212, acc: 0.7209302186965942)
[2024-11-29 03:27:28,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:29,103][root][INFO] - Training Epoch: 6/10, step 191/574 completed (loss: 1.292085886001587, acc: 0.6507936716079712)
[2024-11-29 03:27:29,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:30,500][root][INFO] - Training Epoch: 6/10, step 192/574 completed (loss: 1.2897206544876099, acc: 0.6590909361839294)
[2024-11-29 03:27:31,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:31,579][root][INFO] - Training Epoch: 6/10, step 193/574 completed (loss: 0.7663655877113342, acc: 0.7529411911964417)
[2024-11-29 03:27:32,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:33,211][root][INFO] - Training Epoch: 6/10, step 194/574 completed (loss: 1.2210063934326172, acc: 0.6790123581886292)
[2024-11-29 03:27:34,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:34,670][root][INFO] - Training Epoch: 6/10, step 195/574 completed (loss: 0.3916102945804596, acc: 0.8709677457809448)
[2024-11-29 03:27:34,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:34,967][root][INFO] - Training Epoch: 6/10, step 196/574 completed (loss: 0.11918120831251144, acc: 0.9285714030265808)
[2024-11-29 03:27:35,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:35,300][root][INFO] - Training Epoch: 6/10, step 197/574 completed (loss: 0.6021565198898315, acc: 0.824999988079071)
[2024-11-29 03:27:35,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:35,609][root][INFO] - Training Epoch: 6/10, step 198/574 completed (loss: 0.38477712869644165, acc: 0.8970588445663452)
[2024-11-29 03:27:35,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:35,930][root][INFO] - Training Epoch: 6/10, step 199/574 completed (loss: 1.2310643196105957, acc: 0.7573529481887817)
[2024-11-29 03:27:36,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:36,300][root][INFO] - Training Epoch: 6/10, step 200/574 completed (loss: 0.8656584024429321, acc: 0.7542372941970825)
[2024-11-29 03:27:36,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:36,624][root][INFO] - Training Epoch: 6/10, step 201/574 completed (loss: 1.034317135810852, acc: 0.7238805890083313)
[2024-11-29 03:27:36,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:36,983][root][INFO] - Training Epoch: 6/10, step 202/574 completed (loss: 0.7951233983039856, acc: 0.7475728392601013)
[2024-11-29 03:27:37,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:37,315][root][INFO] - Training Epoch: 6/10, step 203/574 completed (loss: 0.4582888185977936, acc: 0.8571428656578064)
[2024-11-29 03:27:37,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:37,604][root][INFO] - Training Epoch: 6/10, step 204/574 completed (loss: 0.18056920170783997, acc: 0.9340659379959106)
[2024-11-29 03:27:37,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:37,919][root][INFO] - Training Epoch: 6/10, step 205/574 completed (loss: 0.4448346197605133, acc: 0.847533643245697)
[2024-11-29 03:27:38,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:38,369][root][INFO] - Training Epoch: 6/10, step 206/574 completed (loss: 0.6823047995567322, acc: 0.8110235929489136)
[2024-11-29 03:27:38,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:38,740][root][INFO] - Training Epoch: 6/10, step 207/574 completed (loss: 0.46827325224876404, acc: 0.8491379022598267)
[2024-11-29 03:27:38,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:39,088][root][INFO] - Training Epoch: 6/10, step 208/574 completed (loss: 0.5843032598495483, acc: 0.8514492511749268)
[2024-11-29 03:27:39,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:39,457][root][INFO] - Training Epoch: 6/10, step 209/574 completed (loss: 0.46803826093673706, acc: 0.8560311198234558)
[2024-11-29 03:27:39,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:39,755][root][INFO] - Training Epoch: 6/10, step 210/574 completed (loss: 0.3851591646671295, acc: 0.8913043737411499)
[2024-11-29 03:27:39,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:40,083][root][INFO] - Training Epoch: 6/10, step 211/574 completed (loss: 0.17150363326072693, acc: 0.95652174949646)
[2024-11-29 03:27:40,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:40,417][root][INFO] - Training Epoch: 6/10, step 212/574 completed (loss: 0.07820989191532135, acc: 1.0)
[2024-11-29 03:27:40,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:40,701][root][INFO] - Training Epoch: 6/10, step 213/574 completed (loss: 0.6520906686782837, acc: 0.8723404407501221)
[2024-11-29 03:27:41,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:41,670][root][INFO] - Training Epoch: 6/10, step 214/574 completed (loss: 0.3163711428642273, acc: 0.9461538195610046)
[2024-11-29 03:27:41,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:42,013][root][INFO] - Training Epoch: 6/10, step 215/574 completed (loss: 0.10758116096258163, acc: 0.9729729890823364)
[2024-11-29 03:27:42,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:42,349][root][INFO] - Training Epoch: 6/10, step 216/574 completed (loss: 0.13909639418125153, acc: 0.9651162624359131)
[2024-11-29 03:27:42,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:43,065][root][INFO] - Training Epoch: 6/10, step 217/574 completed (loss: 0.25568461418151855, acc: 0.9009009003639221)
[2024-11-29 03:27:43,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:43,522][root][INFO] - Training Epoch: 6/10, step 218/574 completed (loss: 0.27904874086380005, acc: 0.8999999761581421)
[2024-11-29 03:27:43,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:43,841][root][INFO] - Training Epoch: 6/10, step 219/574 completed (loss: 0.16765983402729034, acc: 0.939393937587738)
[2024-11-29 03:27:44,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:44,152][root][INFO] - Training Epoch: 6/10, step 220/574 completed (loss: 0.08120722323656082, acc: 0.9629629850387573)
[2024-11-29 03:27:44,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:44,467][root][INFO] - Training Epoch: 6/10, step 221/574 completed (loss: 0.051526185125112534, acc: 0.9599999785423279)
[2024-11-29 03:27:44,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:44,770][root][INFO] - Training Epoch: 6/10, step 222/574 completed (loss: 0.6172572374343872, acc: 0.807692289352417)
[2024-11-29 03:27:45,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:45,863][root][INFO] - Training Epoch: 6/10, step 223/574 completed (loss: 0.4613843858242035, acc: 0.875)
[2024-11-29 03:27:46,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:46,584][root][INFO] - Training Epoch: 6/10, step 224/574 completed (loss: 0.651106059551239, acc: 0.8409090638160706)
[2024-11-29 03:27:46,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:47,125][root][INFO] - Training Epoch: 6/10, step 225/574 completed (loss: 0.7517150640487671, acc: 0.7765957713127136)
[2024-11-29 03:27:47,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:47,479][root][INFO] - Training Epoch: 6/10, step 226/574 completed (loss: 0.3165817856788635, acc: 0.8679245114326477)
[2024-11-29 03:27:47,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:47,805][root][INFO] - Training Epoch: 6/10, step 227/574 completed (loss: 0.18616388738155365, acc: 0.9333333373069763)
[2024-11-29 03:27:47,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:48,072][root][INFO] - Training Epoch: 6/10, step 228/574 completed (loss: 0.9436080455780029, acc: 0.8139534592628479)
[2024-11-29 03:27:48,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:48,325][root][INFO] - Training Epoch: 6/10, step 229/574 completed (loss: 2.0944595336914062, acc: 0.46666666865348816)
[2024-11-29 03:27:48,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:48,701][root][INFO] - Training Epoch: 6/10, step 230/574 completed (loss: 2.5555052757263184, acc: 0.410526305437088)
[2024-11-29 03:27:48,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:48,975][root][INFO] - Training Epoch: 6/10, step 231/574 completed (loss: 2.0294859409332275, acc: 0.5111111402511597)
[2024-11-29 03:27:49,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:49,478][root][INFO] - Training Epoch: 6/10, step 232/574 completed (loss: 1.9249018430709839, acc: 0.5166666507720947)
[2024-11-29 03:27:49,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:50,106][root][INFO] - Training Epoch: 6/10, step 233/574 completed (loss: 2.3195419311523438, acc: 0.4357798099517822)
[2024-11-29 03:27:50,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:50,706][root][INFO] - Training Epoch: 6/10, step 234/574 completed (loss: 1.9773198366165161, acc: 0.5230769515037537)
[2024-11-29 03:27:50,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:51,000][root][INFO] - Training Epoch: 6/10, step 235/574 completed (loss: 0.11634333431720734, acc: 0.9473684430122375)
[2024-11-29 03:27:51,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:51,268][root][INFO] - Training Epoch: 6/10, step 236/574 completed (loss: 0.04541444405913353, acc: 1.0)
[2024-11-29 03:27:51,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:51,590][root][INFO] - Training Epoch: 6/10, step 237/574 completed (loss: 0.2266748994588852, acc: 0.9545454382896423)
[2024-11-29 03:27:51,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:51,936][root][INFO] - Training Epoch: 6/10, step 238/574 completed (loss: 0.6433907151222229, acc: 0.8148148059844971)
[2024-11-29 03:27:52,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:52,292][root][INFO] - Training Epoch: 6/10, step 239/574 completed (loss: 0.4509270489215851, acc: 0.8285714387893677)
[2024-11-29 03:27:52,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:52,669][root][INFO] - Training Epoch: 6/10, step 240/574 completed (loss: 0.7640092968940735, acc: 0.7954545617103577)
[2024-11-29 03:27:52,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:53,021][root][INFO] - Training Epoch: 6/10, step 241/574 completed (loss: 0.31516820192337036, acc: 0.9090909361839294)
[2024-11-29 03:27:53,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:53,838][root][INFO] - Training Epoch: 6/10, step 242/574 completed (loss: 0.959541380405426, acc: 0.6612903475761414)
[2024-11-29 03:27:54,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:54,552][root][INFO] - Training Epoch: 6/10, step 243/574 completed (loss: 0.5725199580192566, acc: 0.8636363744735718)
[2024-11-29 03:27:54,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:54,804][root][INFO] - Training Epoch: 6/10, step 244/574 completed (loss: 0.05559792369604111, acc: 0.9523809552192688)
[2024-11-29 03:27:54,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:55,068][root][INFO] - Training Epoch: 6/10, step 245/574 completed (loss: 0.6345890760421753, acc: 0.7692307829856873)
[2024-11-29 03:27:55,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:55,325][root][INFO] - Training Epoch: 6/10, step 246/574 completed (loss: 0.21371202170848846, acc: 0.9677419066429138)
[2024-11-29 03:27:55,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:55,616][root][INFO] - Training Epoch: 6/10, step 247/574 completed (loss: 0.10957368463277817, acc: 0.949999988079071)
[2024-11-29 03:27:55,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:55,979][root][INFO] - Training Epoch: 6/10, step 248/574 completed (loss: 0.18853974342346191, acc: 0.9459459185600281)
[2024-11-29 03:27:56,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:56,255][root][INFO] - Training Epoch: 6/10, step 249/574 completed (loss: 0.20269449055194855, acc: 0.9189189076423645)
[2024-11-29 03:27:56,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:56,524][root][INFO] - Training Epoch: 6/10, step 250/574 completed (loss: 0.04018346220254898, acc: 1.0)
[2024-11-29 03:27:56,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:56,828][root][INFO] - Training Epoch: 6/10, step 251/574 completed (loss: 0.33451607823371887, acc: 0.8823529481887817)
[2024-11-29 03:27:56,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:57,095][root][INFO] - Training Epoch: 6/10, step 252/574 completed (loss: 0.08111260831356049, acc: 0.9756097793579102)
[2024-11-29 03:27:57,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:57,344][root][INFO] - Training Epoch: 6/10, step 253/574 completed (loss: 0.034543588757514954, acc: 1.0)
[2024-11-29 03:27:57,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:57,602][root][INFO] - Training Epoch: 6/10, step 254/574 completed (loss: 0.014431873336434364, acc: 1.0)
[2024-11-29 03:27:57,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:57,870][root][INFO] - Training Epoch: 6/10, step 255/574 completed (loss: 0.11833453178405762, acc: 0.9677419066429138)
[2024-11-29 03:27:58,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:58,122][root][INFO] - Training Epoch: 6/10, step 256/574 completed (loss: 0.2388986051082611, acc: 0.8947368264198303)
[2024-11-29 03:27:58,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:58,375][root][INFO] - Training Epoch: 6/10, step 257/574 completed (loss: 0.22352586686611176, acc: 0.9285714030265808)
[2024-11-29 03:27:58,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:58,651][root][INFO] - Training Epoch: 6/10, step 258/574 completed (loss: 0.10254493355751038, acc: 0.9736841917037964)
[2024-11-29 03:27:59,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:27:59,417][root][INFO] - Training Epoch: 6/10, step 259/574 completed (loss: 0.3850206732749939, acc: 0.8679245114326477)
[2024-11-29 03:27:59,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:00,208][root][INFO] - Training Epoch: 6/10, step 260/574 completed (loss: 0.4838421940803528, acc: 0.8916666507720947)
[2024-11-29 03:28:00,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:00,448][root][INFO] - Training Epoch: 6/10, step 261/574 completed (loss: 0.1132090762257576, acc: 0.9722222089767456)
[2024-11-29 03:28:00,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:00,682][root][INFO] - Training Epoch: 6/10, step 262/574 completed (loss: 0.11592602729797363, acc: 0.9677419066429138)
[2024-11-29 03:28:00,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:01,019][root][INFO] - Training Epoch: 6/10, step 263/574 completed (loss: 0.8893357515335083, acc: 0.800000011920929)
[2024-11-29 03:28:01,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:01,291][root][INFO] - Training Epoch: 6/10, step 264/574 completed (loss: 0.5726935267448425, acc: 0.8333333134651184)
[2024-11-29 03:28:01,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:02,498][root][INFO] - Training Epoch: 6/10, step 265/574 completed (loss: 1.2831557989120483, acc: 0.6320000290870667)
[2024-11-29 03:28:02,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:02,810][root][INFO] - Training Epoch: 6/10, step 266/574 completed (loss: 0.9397845268249512, acc: 0.7303370833396912)
[2024-11-29 03:28:03,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:03,167][root][INFO] - Training Epoch: 6/10, step 267/574 completed (loss: 0.881916344165802, acc: 0.7297297120094299)
[2024-11-29 03:28:03,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:03,734][root][INFO] - Training Epoch: 6/10, step 268/574 completed (loss: 0.5609448552131653, acc: 0.8103448152542114)
[2024-11-29 03:28:03,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:03,986][root][INFO] - Training Epoch: 6/10, step 269/574 completed (loss: 0.010991591028869152, acc: 1.0)
[2024-11-29 03:28:04,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:04,249][root][INFO] - Training Epoch: 6/10, step 270/574 completed (loss: 0.02538342960178852, acc: 1.0)
[2024-11-29 03:28:04,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:04,501][root][INFO] - Training Epoch: 6/10, step 271/574 completed (loss: 0.055491894483566284, acc: 0.96875)
[2024-11-29 03:28:04,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:04,768][root][INFO] - Training Epoch: 6/10, step 272/574 completed (loss: 0.04151846095919609, acc: 1.0)
[2024-11-29 03:28:04,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:05,186][root][INFO] - Training Epoch: 6/10, step 273/574 completed (loss: 0.30972471833229065, acc: 0.9333333373069763)
[2024-11-29 03:28:05,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:05,439][root][INFO] - Training Epoch: 6/10, step 274/574 completed (loss: 0.24507974088191986, acc: 0.9375)
[2024-11-29 03:28:05,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:05,731][root][INFO] - Training Epoch: 6/10, step 275/574 completed (loss: 0.17319078743457794, acc: 0.9333333373069763)
[2024-11-29 03:28:06,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:07,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:07,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:08,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:08,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:09,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:09,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:09,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:10,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:10,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:11,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:11,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:12,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:12,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:13,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:13,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:14,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:14,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:15,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:15,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:16,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:16,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:16,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:17,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:17,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:18,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:18,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:19,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:19,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:20,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:20,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:21,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:21,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:21,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:22,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:22,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:23,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:23,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:23,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:24,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:24,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:25,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:25,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:26,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:26,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:27,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:27,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:27,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:28,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:28,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:29,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:29,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:29,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:30,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:30,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:31,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:31,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:32,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:32,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:33,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:33,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:34,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:34,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:35,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:35,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:35,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:36,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:36,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:37,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:37,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:38,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:38,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:39,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:39,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:40,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:40,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:40,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:41,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:41,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:41,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:42,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:42,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:43,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:43,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:44,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:44,883][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.9227, device='cuda:0') eval_epoch_loss=tensor(1.0725, device='cuda:0') eval_epoch_acc=tensor(0.7455, device='cuda:0')
[2024-11-29 03:28:44,884][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:28:44,884][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:28:45,189][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_6_step_276_loss_1.0724979639053345/model.pt
[2024-11-29 03:28:45,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:45,559][root][INFO] - Training Epoch: 6/10, step 276/574 completed (loss: 0.07472818344831467, acc: 1.0)
[2024-11-29 03:28:45,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:45,822][root][INFO] - Training Epoch: 6/10, step 277/574 completed (loss: 0.11075402051210403, acc: 0.9599999785423279)
[2024-11-29 03:28:45,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:46,084][root][INFO] - Training Epoch: 6/10, step 278/574 completed (loss: 0.28636977076530457, acc: 0.8936170339584351)
[2024-11-29 03:28:46,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:46,392][root][INFO] - Training Epoch: 6/10, step 279/574 completed (loss: 0.347287654876709, acc: 0.9166666865348816)
[2024-11-29 03:28:46,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:46,668][root][INFO] - Training Epoch: 6/10, step 280/574 completed (loss: 0.051422957330942154, acc: 1.0)
[2024-11-29 03:28:46,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:47,155][root][INFO] - Training Epoch: 6/10, step 281/574 completed (loss: 0.9340941905975342, acc: 0.7710843086242676)
[2024-11-29 03:28:47,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:47,524][root][INFO] - Training Epoch: 6/10, step 282/574 completed (loss: 0.9196319580078125, acc: 0.7222222089767456)
[2024-11-29 03:28:47,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:47,772][root][INFO] - Training Epoch: 6/10, step 283/574 completed (loss: 0.12387151271104813, acc: 0.9736841917037964)
[2024-11-29 03:28:47,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:48,000][root][INFO] - Training Epoch: 6/10, step 284/574 completed (loss: 0.3149759769439697, acc: 0.9117646813392639)
[2024-11-29 03:28:48,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:48,247][root][INFO] - Training Epoch: 6/10, step 285/574 completed (loss: 0.16996516287326813, acc: 0.949999988079071)
[2024-11-29 03:28:48,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:48,505][root][INFO] - Training Epoch: 6/10, step 286/574 completed (loss: 0.4794747233390808, acc: 0.875)
[2024-11-29 03:28:48,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:48,828][root][INFO] - Training Epoch: 6/10, step 287/574 completed (loss: 0.7956619262695312, acc: 0.7760000228881836)
[2024-11-29 03:28:48,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:49,089][root][INFO] - Training Epoch: 6/10, step 288/574 completed (loss: 0.5034664869308472, acc: 0.8681318759918213)
[2024-11-29 03:28:49,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:49,381][root][INFO] - Training Epoch: 6/10, step 289/574 completed (loss: 0.41046807169914246, acc: 0.8322981595993042)
[2024-11-29 03:28:49,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:49,703][root][INFO] - Training Epoch: 6/10, step 290/574 completed (loss: 0.6832494735717773, acc: 0.8144329786300659)
[2024-11-29 03:28:49,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:49,992][root][INFO] - Training Epoch: 6/10, step 291/574 completed (loss: 0.07312066853046417, acc: 1.0)
[2024-11-29 03:28:50,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:50,309][root][INFO] - Training Epoch: 6/10, step 292/574 completed (loss: 0.3553536832332611, acc: 0.9047619104385376)
[2024-11-29 03:28:50,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:50,642][root][INFO] - Training Epoch: 6/10, step 293/574 completed (loss: 0.30555489659309387, acc: 0.9137930870056152)
[2024-11-29 03:28:50,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:51,234][root][INFO] - Training Epoch: 6/10, step 294/574 completed (loss: 0.5331712365150452, acc: 0.8181818127632141)
[2024-11-29 03:28:51,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:51,951][root][INFO] - Training Epoch: 6/10, step 295/574 completed (loss: 0.7675579190254211, acc: 0.7731958627700806)
[2024-11-29 03:28:52,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:52,266][root][INFO] - Training Epoch: 6/10, step 296/574 completed (loss: 0.47448262572288513, acc: 0.8620689511299133)
[2024-11-29 03:28:52,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:52,600][root][INFO] - Training Epoch: 6/10, step 297/574 completed (loss: 0.06829027086496353, acc: 1.0)
[2024-11-29 03:28:52,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:52,944][root][INFO] - Training Epoch: 6/10, step 298/574 completed (loss: 0.4256604313850403, acc: 0.8684210777282715)
[2024-11-29 03:28:53,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:53,280][root][INFO] - Training Epoch: 6/10, step 299/574 completed (loss: 0.2516915500164032, acc: 0.9285714030265808)
[2024-11-29 03:28:53,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:53,595][root][INFO] - Training Epoch: 6/10, step 300/574 completed (loss: 0.27640438079833984, acc: 0.9375)
[2024-11-29 03:28:53,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:53,939][root][INFO] - Training Epoch: 6/10, step 301/574 completed (loss: 0.4332791566848755, acc: 0.8867924809455872)
[2024-11-29 03:28:54,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:54,255][root][INFO] - Training Epoch: 6/10, step 302/574 completed (loss: 0.05716840550303459, acc: 0.9811320900917053)
[2024-11-29 03:28:54,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:54,556][root][INFO] - Training Epoch: 6/10, step 303/574 completed (loss: 0.12256716191768646, acc: 0.970588207244873)
[2024-11-29 03:28:54,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:54,839][root][INFO] - Training Epoch: 6/10, step 304/574 completed (loss: 0.13419674336910248, acc: 0.96875)
[2024-11-29 03:28:55,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:55,181][root][INFO] - Training Epoch: 6/10, step 305/574 completed (loss: 0.5189846754074097, acc: 0.8524590134620667)
[2024-11-29 03:28:55,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:55,484][root][INFO] - Training Epoch: 6/10, step 306/574 completed (loss: 0.16850490868091583, acc: 0.9333333373069763)
[2024-11-29 03:28:55,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:55,795][root][INFO] - Training Epoch: 6/10, step 307/574 completed (loss: 0.0189705528318882, acc: 1.0)
[2024-11-29 03:28:55,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:56,111][root][INFO] - Training Epoch: 6/10, step 308/574 completed (loss: 0.23394843935966492, acc: 0.9420289993286133)
[2024-11-29 03:28:56,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:56,599][root][INFO] - Training Epoch: 6/10, step 309/574 completed (loss: 0.3175849914550781, acc: 0.9027777910232544)
[2024-11-29 03:28:56,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:56,897][root][INFO] - Training Epoch: 6/10, step 310/574 completed (loss: 0.40439268946647644, acc: 0.8795180916786194)
[2024-11-29 03:28:57,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:57,225][root][INFO] - Training Epoch: 6/10, step 311/574 completed (loss: 0.4050988554954529, acc: 0.8974359035491943)
[2024-11-29 03:28:57,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:57,585][root][INFO] - Training Epoch: 6/10, step 312/574 completed (loss: 0.25394198298454285, acc: 0.9387755393981934)
[2024-11-29 03:28:57,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:57,895][root][INFO] - Training Epoch: 6/10, step 313/574 completed (loss: 0.031354084610939026, acc: 1.0)
[2024-11-29 03:28:58,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:58,171][root][INFO] - Training Epoch: 6/10, step 314/574 completed (loss: 0.08587812632322311, acc: 1.0)
[2024-11-29 03:28:58,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:58,495][root][INFO] - Training Epoch: 6/10, step 315/574 completed (loss: 0.37282606959342957, acc: 0.8709677457809448)
[2024-11-29 03:28:58,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:58,810][root][INFO] - Training Epoch: 6/10, step 316/574 completed (loss: 1.7733955383300781, acc: 0.6451612710952759)
[2024-11-29 03:28:59,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:59,166][root][INFO] - Training Epoch: 6/10, step 317/574 completed (loss: 0.2325652837753296, acc: 0.9104477763175964)
[2024-11-29 03:28:59,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:59,499][root][INFO] - Training Epoch: 6/10, step 318/574 completed (loss: 0.2627686858177185, acc: 0.9134615659713745)
[2024-11-29 03:28:59,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:28:59,801][root][INFO] - Training Epoch: 6/10, step 319/574 completed (loss: 0.13288208842277527, acc: 0.9333333373069763)
[2024-11-29 03:28:59,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:00,087][root][INFO] - Training Epoch: 6/10, step 320/574 completed (loss: 0.15619447827339172, acc: 0.9516128897666931)
[2024-11-29 03:29:00,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:00,356][root][INFO] - Training Epoch: 6/10, step 321/574 completed (loss: 0.0730573832988739, acc: 0.9800000190734863)
[2024-11-29 03:29:00,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:00,696][root][INFO] - Training Epoch: 6/10, step 322/574 completed (loss: 1.181741714477539, acc: 0.5925925970077515)
[2024-11-29 03:29:00,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:01,025][root][INFO] - Training Epoch: 6/10, step 323/574 completed (loss: 1.4345861673355103, acc: 0.6000000238418579)
[2024-11-29 03:29:01,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:01,342][root][INFO] - Training Epoch: 6/10, step 324/574 completed (loss: 1.1576100587844849, acc: 0.7692307829856873)
[2024-11-29 03:29:01,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:01,623][root][INFO] - Training Epoch: 6/10, step 325/574 completed (loss: 1.9297734498977661, acc: 0.46341463923454285)
[2024-11-29 03:29:01,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:01,964][root][INFO] - Training Epoch: 6/10, step 326/574 completed (loss: 0.9844056963920593, acc: 0.7105262875556946)
[2024-11-29 03:29:02,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:02,310][root][INFO] - Training Epoch: 6/10, step 327/574 completed (loss: 0.5370936393737793, acc: 0.8947368264198303)
[2024-11-29 03:29:02,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:02,635][root][INFO] - Training Epoch: 6/10, step 328/574 completed (loss: 0.0997253805398941, acc: 0.9642857313156128)
[2024-11-29 03:29:02,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:02,966][root][INFO] - Training Epoch: 6/10, step 329/574 completed (loss: 0.06670883297920227, acc: 0.9629629850387573)
[2024-11-29 03:29:03,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:03,259][root][INFO] - Training Epoch: 6/10, step 330/574 completed (loss: 0.04168558120727539, acc: 1.0)
[2024-11-29 03:29:03,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:03,527][root][INFO] - Training Epoch: 6/10, step 331/574 completed (loss: 0.2868857979774475, acc: 0.9032257795333862)
[2024-11-29 03:29:03,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:03,916][root][INFO] - Training Epoch: 6/10, step 332/574 completed (loss: 0.0773906260728836, acc: 0.9824561476707458)
[2024-11-29 03:29:04,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:04,173][root][INFO] - Training Epoch: 6/10, step 333/574 completed (loss: 0.378814697265625, acc: 0.90625)
[2024-11-29 03:29:04,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:04,455][root][INFO] - Training Epoch: 6/10, step 334/574 completed (loss: 0.08257746696472168, acc: 0.9666666388511658)
[2024-11-29 03:29:04,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:04,698][root][INFO] - Training Epoch: 6/10, step 335/574 completed (loss: 0.21627597510814667, acc: 0.8947368264198303)
[2024-11-29 03:29:04,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:04,960][root][INFO] - Training Epoch: 6/10, step 336/574 completed (loss: 1.0398006439208984, acc: 0.6800000071525574)
[2024-11-29 03:29:05,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:05,289][root][INFO] - Training Epoch: 6/10, step 337/574 completed (loss: 1.3455129861831665, acc: 0.5747126340866089)
[2024-11-29 03:29:05,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:05,607][root][INFO] - Training Epoch: 6/10, step 338/574 completed (loss: 1.2228114604949951, acc: 0.6914893388748169)
[2024-11-29 03:29:05,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:05,895][root][INFO] - Training Epoch: 6/10, step 339/574 completed (loss: 1.335399866104126, acc: 0.7108433842658997)
[2024-11-29 03:29:06,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:06,153][root][INFO] - Training Epoch: 6/10, step 340/574 completed (loss: 0.015660012140870094, acc: 1.0)
[2024-11-29 03:29:06,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:06,469][root][INFO] - Training Epoch: 6/10, step 341/574 completed (loss: 0.23087464272975922, acc: 0.8974359035491943)
[2024-11-29 03:29:06,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:06,806][root][INFO] - Training Epoch: 6/10, step 342/574 completed (loss: 0.3125442862510681, acc: 0.9156626462936401)
[2024-11-29 03:29:07,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:07,147][root][INFO] - Training Epoch: 6/10, step 343/574 completed (loss: 0.942061722278595, acc: 0.7924528121948242)
[2024-11-29 03:29:07,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:07,473][root][INFO] - Training Epoch: 6/10, step 344/574 completed (loss: 0.10840780287981033, acc: 0.9620253443717957)
[2024-11-29 03:29:07,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:07,785][root][INFO] - Training Epoch: 6/10, step 345/574 completed (loss: 0.0714275911450386, acc: 0.9803921580314636)
[2024-11-29 03:29:07,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:08,057][root][INFO] - Training Epoch: 6/10, step 346/574 completed (loss: 0.4540060758590698, acc: 0.8656716346740723)
[2024-11-29 03:29:08,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:08,308][root][INFO] - Training Epoch: 6/10, step 347/574 completed (loss: 0.007960015907883644, acc: 1.0)
[2024-11-29 03:29:08,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:08,568][root][INFO] - Training Epoch: 6/10, step 348/574 completed (loss: 0.06170631945133209, acc: 0.9599999785423279)
[2024-11-29 03:29:08,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:09,004][root][INFO] - Training Epoch: 6/10, step 349/574 completed (loss: 0.6966840624809265, acc: 0.8055555820465088)
[2024-11-29 03:29:09,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:09,286][root][INFO] - Training Epoch: 6/10, step 350/574 completed (loss: 0.5050925612449646, acc: 0.8372092843055725)
[2024-11-29 03:29:09,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:09,577][root][INFO] - Training Epoch: 6/10, step 351/574 completed (loss: 0.10170219093561172, acc: 0.9743589758872986)
[2024-11-29 03:29:09,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:09,990][root][INFO] - Training Epoch: 6/10, step 352/574 completed (loss: 0.7385332584381104, acc: 0.7555555701255798)
[2024-11-29 03:29:10,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:10,236][root][INFO] - Training Epoch: 6/10, step 353/574 completed (loss: 0.016489723697304726, acc: 1.0)
[2024-11-29 03:29:10,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:10,479][root][INFO] - Training Epoch: 6/10, step 354/574 completed (loss: 0.312726229429245, acc: 0.8846153616905212)
[2024-11-29 03:29:10,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:10,846][root][INFO] - Training Epoch: 6/10, step 355/574 completed (loss: 0.6248321533203125, acc: 0.791208803653717)
[2024-11-29 03:29:11,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:11,521][root][INFO] - Training Epoch: 6/10, step 356/574 completed (loss: 0.5494092106819153, acc: 0.843478262424469)
[2024-11-29 03:29:11,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:11,837][root][INFO] - Training Epoch: 6/10, step 357/574 completed (loss: 0.5203884840011597, acc: 0.8260869383811951)
[2024-11-29 03:29:11,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:12,121][root][INFO] - Training Epoch: 6/10, step 358/574 completed (loss: 0.4041033089160919, acc: 0.8571428656578064)
[2024-11-29 03:29:12,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:12,369][root][INFO] - Training Epoch: 6/10, step 359/574 completed (loss: 0.007839908823370934, acc: 1.0)
[2024-11-29 03:29:12,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:12,632][root][INFO] - Training Epoch: 6/10, step 360/574 completed (loss: 0.08525573462247849, acc: 0.9615384340286255)
[2024-11-29 03:29:12,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:12,957][root][INFO] - Training Epoch: 6/10, step 361/574 completed (loss: 0.32371118664741516, acc: 0.9268292784690857)
[2024-11-29 03:29:13,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:13,256][root][INFO] - Training Epoch: 6/10, step 362/574 completed (loss: 0.5324965715408325, acc: 0.8888888955116272)
[2024-11-29 03:29:13,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:13,521][root][INFO] - Training Epoch: 6/10, step 363/574 completed (loss: 0.20909841358661652, acc: 0.9473684430122375)
[2024-11-29 03:29:13,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:13,799][root][INFO] - Training Epoch: 6/10, step 364/574 completed (loss: 0.09144315123558044, acc: 0.9756097793579102)
[2024-11-29 03:29:13,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:14,052][root][INFO] - Training Epoch: 6/10, step 365/574 completed (loss: 0.1956769824028015, acc: 0.9090909361839294)
[2024-11-29 03:29:14,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:14,303][root][INFO] - Training Epoch: 6/10, step 366/574 completed (loss: 0.009633715264499187, acc: 1.0)
[2024-11-29 03:29:14,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:14,570][root][INFO] - Training Epoch: 6/10, step 367/574 completed (loss: 0.034036438912153244, acc: 1.0)
[2024-11-29 03:29:14,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:14,863][root][INFO] - Training Epoch: 6/10, step 368/574 completed (loss: 0.2028355747461319, acc: 0.9642857313156128)
[2024-11-29 03:29:15,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:15,159][root][INFO] - Training Epoch: 6/10, step 369/574 completed (loss: 0.47836214303970337, acc: 0.90625)
[2024-11-29 03:29:15,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:15,988][root][INFO] - Training Epoch: 6/10, step 370/574 completed (loss: 0.9004597067832947, acc: 0.7515151500701904)
[2024-11-29 03:29:16,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:17,237][root][INFO] - Training Epoch: 6/10, step 371/574 completed (loss: 0.49904534220695496, acc: 0.8679245114326477)
[2024-11-29 03:29:17,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:17,550][root][INFO] - Training Epoch: 6/10, step 372/574 completed (loss: 0.25298193097114563, acc: 0.9333333373069763)
[2024-11-29 03:29:17,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:17,826][root][INFO] - Training Epoch: 6/10, step 373/574 completed (loss: 0.16272993385791779, acc: 0.9464285969734192)
[2024-11-29 03:29:18,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:18,154][root][INFO] - Training Epoch: 6/10, step 374/574 completed (loss: 0.08943445980548859, acc: 0.9714285731315613)
[2024-11-29 03:29:18,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:18,446][root][INFO] - Training Epoch: 6/10, step 375/574 completed (loss: 0.022878684103488922, acc: 1.0)
[2024-11-29 03:29:18,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:18,715][root][INFO] - Training Epoch: 6/10, step 376/574 completed (loss: 0.009155550971627235, acc: 1.0)
[2024-11-29 03:29:18,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:18,966][root][INFO] - Training Epoch: 6/10, step 377/574 completed (loss: 0.08519835025072098, acc: 0.9791666865348816)
[2024-11-29 03:29:19,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:19,266][root][INFO] - Training Epoch: 6/10, step 378/574 completed (loss: 0.11941084265708923, acc: 0.9473684430122375)
[2024-11-29 03:29:19,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:20,040][root][INFO] - Training Epoch: 6/10, step 379/574 completed (loss: 0.4088256359100342, acc: 0.886227548122406)
[2024-11-29 03:29:20,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:20,506][root][INFO] - Training Epoch: 6/10, step 380/574 completed (loss: 0.3521212339401245, acc: 0.8947368264198303)
[2024-11-29 03:29:21,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:22,253][root][INFO] - Training Epoch: 6/10, step 381/574 completed (loss: 0.7578253149986267, acc: 0.8021390438079834)
[2024-11-29 03:29:22,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:23,016][root][INFO] - Training Epoch: 6/10, step 382/574 completed (loss: 0.24719087779521942, acc: 0.9459459185600281)
[2024-11-29 03:29:23,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:23,258][root][INFO] - Training Epoch: 6/10, step 383/574 completed (loss: 0.03915950283408165, acc: 1.0)
[2024-11-29 03:29:23,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:23,510][root][INFO] - Training Epoch: 6/10, step 384/574 completed (loss: 0.17839927971363068, acc: 0.9642857313156128)
[2024-11-29 03:29:23,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:23,771][root][INFO] - Training Epoch: 6/10, step 385/574 completed (loss: 0.17173193395137787, acc: 0.9375)
[2024-11-29 03:29:23,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:24,024][root][INFO] - Training Epoch: 6/10, step 386/574 completed (loss: 0.1581033319234848, acc: 0.9444444179534912)
[2024-11-29 03:29:24,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:24,283][root][INFO] - Training Epoch: 6/10, step 387/574 completed (loss: 0.054021984338760376, acc: 0.9736841917037964)
[2024-11-29 03:29:24,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:24,536][root][INFO] - Training Epoch: 6/10, step 388/574 completed (loss: 0.031802933663129807, acc: 1.0)
[2024-11-29 03:29:24,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:24,782][root][INFO] - Training Epoch: 6/10, step 389/574 completed (loss: 0.02010023035109043, acc: 1.0)
[2024-11-29 03:29:24,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:25,039][root][INFO] - Training Epoch: 6/10, step 390/574 completed (loss: 0.16513130068778992, acc: 0.9523809552192688)
[2024-11-29 03:29:25,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:25,297][root][INFO] - Training Epoch: 6/10, step 391/574 completed (loss: 0.8158292174339294, acc: 0.7592592835426331)
[2024-11-29 03:29:25,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:25,601][root][INFO] - Training Epoch: 6/10, step 392/574 completed (loss: 0.6994758248329163, acc: 0.7572815418243408)
[2024-11-29 03:29:25,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:26,275][root][INFO] - Training Epoch: 6/10, step 393/574 completed (loss: 0.9906759858131409, acc: 0.779411792755127)
[2024-11-29 03:29:26,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:26,664][root][INFO] - Training Epoch: 6/10, step 394/574 completed (loss: 0.764115571975708, acc: 0.753333330154419)
[2024-11-29 03:29:26,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:27,097][root][INFO] - Training Epoch: 6/10, step 395/574 completed (loss: 0.673649251461029, acc: 0.8263888955116272)
[2024-11-29 03:29:27,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:27,368][root][INFO] - Training Epoch: 6/10, step 396/574 completed (loss: 0.1676173359155655, acc: 0.9534883499145508)
[2024-11-29 03:29:27,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:27,617][root][INFO] - Training Epoch: 6/10, step 397/574 completed (loss: 0.0916612446308136, acc: 0.9583333134651184)
[2024-11-29 03:29:27,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:27,886][root][INFO] - Training Epoch: 6/10, step 398/574 completed (loss: 0.40953969955444336, acc: 0.8604651093482971)
[2024-11-29 03:29:28,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:28,136][root][INFO] - Training Epoch: 6/10, step 399/574 completed (loss: 0.04166383296251297, acc: 1.0)
[2024-11-29 03:29:28,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:28,845][root][INFO] - Training Epoch: 6/10, step 400/574 completed (loss: 0.31088268756866455, acc: 0.9117646813392639)
[2024-11-29 03:29:29,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:29,121][root][INFO] - Training Epoch: 6/10, step 401/574 completed (loss: 0.37685883045196533, acc: 0.9066666960716248)
[2024-11-29 03:29:29,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:29,375][root][INFO] - Training Epoch: 6/10, step 402/574 completed (loss: 0.3128209114074707, acc: 0.9090909361839294)
[2024-11-29 03:29:29,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:29,625][root][INFO] - Training Epoch: 6/10, step 403/574 completed (loss: 0.08976985514163971, acc: 0.9696969985961914)
[2024-11-29 03:29:29,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:29,869][root][INFO] - Training Epoch: 6/10, step 404/574 completed (loss: 0.33283209800720215, acc: 0.8387096524238586)
[2024-11-29 03:29:30,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:30,118][root][INFO] - Training Epoch: 6/10, step 405/574 completed (loss: 0.4055705666542053, acc: 0.9259259104728699)
[2024-11-29 03:29:30,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:30,365][root][INFO] - Training Epoch: 6/10, step 406/574 completed (loss: 0.06283699721097946, acc: 0.9599999785423279)
[2024-11-29 03:29:30,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:30,625][root][INFO] - Training Epoch: 6/10, step 407/574 completed (loss: 0.03926549851894379, acc: 1.0)
[2024-11-29 03:29:30,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:30,870][root][INFO] - Training Epoch: 6/10, step 408/574 completed (loss: 0.14572817087173462, acc: 0.9259259104728699)
[2024-11-29 03:29:31,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:31,133][root][INFO] - Training Epoch: 6/10, step 409/574 completed (loss: 0.03902836889028549, acc: 1.0)
[2024-11-29 03:29:31,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:31,393][root][INFO] - Training Epoch: 6/10, step 410/574 completed (loss: 0.13336844742298126, acc: 0.9482758641242981)
[2024-11-29 03:29:31,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:31,651][root][INFO] - Training Epoch: 6/10, step 411/574 completed (loss: 0.09268594533205032, acc: 0.9642857313156128)
[2024-11-29 03:29:31,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:31,899][root][INFO] - Training Epoch: 6/10, step 412/574 completed (loss: 0.02345040813088417, acc: 1.0)
[2024-11-29 03:29:32,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:32,152][root][INFO] - Training Epoch: 6/10, step 413/574 completed (loss: 0.3231695592403412, acc: 0.939393937587738)
[2024-11-29 03:29:32,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:32,407][root][INFO] - Training Epoch: 6/10, step 414/574 completed (loss: 0.11557020992040634, acc: 0.9545454382896423)
[2024-11-29 03:29:32,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:32,680][root][INFO] - Training Epoch: 6/10, step 415/574 completed (loss: 0.29541635513305664, acc: 0.8823529481887817)
[2024-11-29 03:29:32,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:32,953][root][INFO] - Training Epoch: 6/10, step 416/574 completed (loss: 0.0686606615781784, acc: 1.0)
[2024-11-29 03:29:33,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:33,213][root][INFO] - Training Epoch: 6/10, step 417/574 completed (loss: 0.1049489825963974, acc: 0.9444444179534912)
[2024-11-29 03:29:33,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:33,497][root][INFO] - Training Epoch: 6/10, step 418/574 completed (loss: 0.20040807127952576, acc: 0.949999988079071)
[2024-11-29 03:29:34,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:34,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:35,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:35,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:35,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:36,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:36,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:37,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:37,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:38,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:38,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:39,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:39,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:39,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:40,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:40,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:41,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:41,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:42,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:42,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:43,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:43,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:43,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:44,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:44,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:45,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:45,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:46,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:46,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:47,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:47,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:47,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:48,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:48,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:49,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:49,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:50,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:50,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:51,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:51,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:51,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:52,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:52,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:53,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:53,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:53,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:54,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:54,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:55,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:55,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:56,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:56,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:56,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:57,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:57,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:58,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:58,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:58,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:59,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:29:59,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:00,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:01,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:01,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:02,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:02,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:02,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:03,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:03,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:04,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:04,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:05,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:06,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:06,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:06,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:07,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:07,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:08,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:08,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:08,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:09,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:09,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:10,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:10,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:11,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:11,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:12,224][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.8776, device='cuda:0') eval_epoch_loss=tensor(1.0570, device='cuda:0') eval_epoch_acc=tensor(0.7462, device='cuda:0')
[2024-11-29 03:30:12,226][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:30:12,226][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:30:12,736][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_6_step_419_loss_1.0569605827331543/model.pt
[2024-11-29 03:30:12,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:13,003][root][INFO] - Training Epoch: 6/10, step 419/574 completed (loss: 0.29349252581596375, acc: 0.8999999761581421)
[2024-11-29 03:30:13,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:13,305][root][INFO] - Training Epoch: 6/10, step 420/574 completed (loss: 0.07486601918935776, acc: 1.0)
[2024-11-29 03:30:13,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:13,659][root][INFO] - Training Epoch: 6/10, step 421/574 completed (loss: 0.1274642050266266, acc: 0.9666666388511658)
[2024-11-29 03:30:13,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:13,997][root][INFO] - Training Epoch: 6/10, step 422/574 completed (loss: 0.5579896569252014, acc: 0.90625)
[2024-11-29 03:30:14,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:14,325][root][INFO] - Training Epoch: 6/10, step 423/574 completed (loss: 0.2912505567073822, acc: 0.9166666865348816)
[2024-11-29 03:30:14,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:14,592][root][INFO] - Training Epoch: 6/10, step 424/574 completed (loss: 0.2465202957391739, acc: 0.9259259104728699)
[2024-11-29 03:30:14,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:14,882][root][INFO] - Training Epoch: 6/10, step 425/574 completed (loss: 0.04918334633111954, acc: 1.0)
[2024-11-29 03:30:15,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:15,203][root][INFO] - Training Epoch: 6/10, step 426/574 completed (loss: 0.1119072213768959, acc: 0.95652174949646)
[2024-11-29 03:30:15,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:15,563][root][INFO] - Training Epoch: 6/10, step 427/574 completed (loss: 0.04762505367398262, acc: 1.0)
[2024-11-29 03:30:15,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:15,857][root][INFO] - Training Epoch: 6/10, step 428/574 completed (loss: 0.03392396494746208, acc: 1.0)
[2024-11-29 03:30:16,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:16,161][root][INFO] - Training Epoch: 6/10, step 429/574 completed (loss: 0.018638333305716515, acc: 1.0)
[2024-11-29 03:30:16,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:16,465][root][INFO] - Training Epoch: 6/10, step 430/574 completed (loss: 0.021850310266017914, acc: 1.0)
[2024-11-29 03:30:16,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:16,823][root][INFO] - Training Epoch: 6/10, step 431/574 completed (loss: 0.036112260073423386, acc: 1.0)
[2024-11-29 03:30:17,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:17,172][root][INFO] - Training Epoch: 6/10, step 432/574 completed (loss: 0.06502603739500046, acc: 0.95652174949646)
[2024-11-29 03:30:17,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:17,547][root][INFO] - Training Epoch: 6/10, step 433/574 completed (loss: 0.2257395088672638, acc: 0.9166666865348816)
[2024-11-29 03:30:17,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:17,888][root][INFO] - Training Epoch: 6/10, step 434/574 completed (loss: 0.006882691290229559, acc: 1.0)
[2024-11-29 03:30:18,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:18,216][root][INFO] - Training Epoch: 6/10, step 435/574 completed (loss: 0.028565190732479095, acc: 1.0)
[2024-11-29 03:30:18,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:18,533][root][INFO] - Training Epoch: 6/10, step 436/574 completed (loss: 0.2281886786222458, acc: 0.9444444179534912)
[2024-11-29 03:30:18,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:18,819][root][INFO] - Training Epoch: 6/10, step 437/574 completed (loss: 0.049730658531188965, acc: 0.9772727489471436)
[2024-11-29 03:30:18,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:19,080][root][INFO] - Training Epoch: 6/10, step 438/574 completed (loss: 0.0030018943361938, acc: 1.0)
[2024-11-29 03:30:19,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:19,385][root][INFO] - Training Epoch: 6/10, step 439/574 completed (loss: 0.17351405322551727, acc: 0.9230769276618958)
[2024-11-29 03:30:19,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:19,977][root][INFO] - Training Epoch: 6/10, step 440/574 completed (loss: 0.23722559213638306, acc: 0.9090909361839294)
[2024-11-29 03:30:20,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:20,977][root][INFO] - Training Epoch: 6/10, step 441/574 completed (loss: 0.867072343826294, acc: 0.7519999742507935)
[2024-11-29 03:30:21,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:21,442][root][INFO] - Training Epoch: 6/10, step 442/574 completed (loss: 0.8206204175949097, acc: 0.75)
[2024-11-29 03:30:21,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:22,343][root][INFO] - Training Epoch: 6/10, step 443/574 completed (loss: 0.7023714780807495, acc: 0.8258706331253052)
[2024-11-29 03:30:22,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:22,645][root][INFO] - Training Epoch: 6/10, step 444/574 completed (loss: 0.090058833360672, acc: 0.9811320900917053)
[2024-11-29 03:30:22,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:23,154][root][INFO] - Training Epoch: 6/10, step 445/574 completed (loss: 0.09667182713747025, acc: 0.9772727489471436)
[2024-11-29 03:30:23,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:23,466][root][INFO] - Training Epoch: 6/10, step 446/574 completed (loss: 0.13164643943309784, acc: 0.95652174949646)
[2024-11-29 03:30:23,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:23,762][root][INFO] - Training Epoch: 6/10, step 447/574 completed (loss: 0.0455029271543026, acc: 1.0)
[2024-11-29 03:30:23,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:24,086][root][INFO] - Training Epoch: 6/10, step 448/574 completed (loss: 0.02632066234946251, acc: 1.0)
[2024-11-29 03:30:24,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:24,422][root][INFO] - Training Epoch: 6/10, step 449/574 completed (loss: 0.10906930267810822, acc: 0.9552238583564758)
[2024-11-29 03:30:24,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:24,766][root][INFO] - Training Epoch: 6/10, step 450/574 completed (loss: 0.04991164058446884, acc: 0.9861111044883728)
[2024-11-29 03:30:24,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:25,084][root][INFO] - Training Epoch: 6/10, step 451/574 completed (loss: 0.048957839608192444, acc: 1.0)
[2024-11-29 03:30:25,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:25,368][root][INFO] - Training Epoch: 6/10, step 452/574 completed (loss: 0.2209729701280594, acc: 0.9230769276618958)
[2024-11-29 03:30:25,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:25,644][root][INFO] - Training Epoch: 6/10, step 453/574 completed (loss: 0.24231469631195068, acc: 0.9210526347160339)
[2024-11-29 03:30:25,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:25,953][root][INFO] - Training Epoch: 6/10, step 454/574 completed (loss: 0.2997041642665863, acc: 0.918367326259613)
[2024-11-29 03:30:26,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:26,271][root][INFO] - Training Epoch: 6/10, step 455/574 completed (loss: 0.24436461925506592, acc: 0.939393937587738)
[2024-11-29 03:30:26,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:26,517][root][INFO] - Training Epoch: 6/10, step 456/574 completed (loss: 0.5202410817146301, acc: 0.8865979313850403)
[2024-11-29 03:30:26,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:26,807][root][INFO] - Training Epoch: 6/10, step 457/574 completed (loss: 0.08764808624982834, acc: 0.9571428298950195)
[2024-11-29 03:30:27,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:27,237][root][INFO] - Training Epoch: 6/10, step 458/574 completed (loss: 0.5604509115219116, acc: 0.8372092843055725)
[2024-11-29 03:30:27,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:27,561][root][INFO] - Training Epoch: 6/10, step 459/574 completed (loss: 0.1692255437374115, acc: 0.9464285969734192)
[2024-11-29 03:30:27,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:27,846][root][INFO] - Training Epoch: 6/10, step 460/574 completed (loss: 0.27455005049705505, acc: 0.9012345671653748)
[2024-11-29 03:30:28,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:28,147][root][INFO] - Training Epoch: 6/10, step 461/574 completed (loss: 0.12820833921432495, acc: 0.9722222089767456)
[2024-11-29 03:30:28,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:28,508][root][INFO] - Training Epoch: 6/10, step 462/574 completed (loss: 0.2775934636592865, acc: 0.9375)
[2024-11-29 03:30:28,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:28,814][root][INFO] - Training Epoch: 6/10, step 463/574 completed (loss: 0.26614728569984436, acc: 0.9230769276618958)
[2024-11-29 03:30:28,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:29,090][root][INFO] - Training Epoch: 6/10, step 464/574 completed (loss: 0.2958889901638031, acc: 0.95652174949646)
[2024-11-29 03:30:29,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:29,444][root][INFO] - Training Epoch: 6/10, step 465/574 completed (loss: 0.34498700499534607, acc: 0.8928571343421936)
[2024-11-29 03:30:29,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:29,747][root][INFO] - Training Epoch: 6/10, step 466/574 completed (loss: 0.9465534090995789, acc: 0.7951807379722595)
[2024-11-29 03:30:29,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:30,067][root][INFO] - Training Epoch: 6/10, step 467/574 completed (loss: 0.24542132019996643, acc: 0.9279279112815857)
[2024-11-29 03:30:30,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:30,386][root][INFO] - Training Epoch: 6/10, step 468/574 completed (loss: 0.8494265079498291, acc: 0.7669903039932251)
[2024-11-29 03:30:30,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:30,701][root][INFO] - Training Epoch: 6/10, step 469/574 completed (loss: 1.131765604019165, acc: 0.6991869807243347)
[2024-11-29 03:30:30,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:31,013][root][INFO] - Training Epoch: 6/10, step 470/574 completed (loss: 0.07167615741491318, acc: 1.0)
[2024-11-29 03:30:31,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:31,307][root][INFO] - Training Epoch: 6/10, step 471/574 completed (loss: 0.2528741657733917, acc: 0.8928571343421936)
[2024-11-29 03:30:31,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:31,797][root][INFO] - Training Epoch: 6/10, step 472/574 completed (loss: 0.4821401834487915, acc: 0.8823529481887817)
[2024-11-29 03:30:32,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:32,184][root][INFO] - Training Epoch: 6/10, step 473/574 completed (loss: 0.9409811496734619, acc: 0.7467249035835266)
[2024-11-29 03:30:32,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:32,505][root][INFO] - Training Epoch: 6/10, step 474/574 completed (loss: 0.4380790889263153, acc: 0.8645833134651184)
[2024-11-29 03:30:32,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:32,829][root][INFO] - Training Epoch: 6/10, step 475/574 completed (loss: 0.41481828689575195, acc: 0.8834356069564819)
[2024-11-29 03:30:32,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:33,120][root][INFO] - Training Epoch: 6/10, step 476/574 completed (loss: 0.5162270665168762, acc: 0.8417266011238098)
[2024-11-29 03:30:33,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:33,469][root][INFO] - Training Epoch: 6/10, step 477/574 completed (loss: 0.8520653247833252, acc: 0.7085427045822144)
[2024-11-29 03:30:33,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:33,768][root][INFO] - Training Epoch: 6/10, step 478/574 completed (loss: 0.5725790858268738, acc: 0.75)
[2024-11-29 03:30:33,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:34,076][root][INFO] - Training Epoch: 6/10, step 479/574 completed (loss: 0.24248440563678741, acc: 0.9696969985961914)
[2024-11-29 03:30:34,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:34,388][root][INFO] - Training Epoch: 6/10, step 480/574 completed (loss: 0.782516598701477, acc: 0.8148148059844971)
[2024-11-29 03:30:34,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:34,705][root][INFO] - Training Epoch: 6/10, step 481/574 completed (loss: 0.40319162607192993, acc: 0.8500000238418579)
[2024-11-29 03:30:34,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:35,039][root][INFO] - Training Epoch: 6/10, step 482/574 completed (loss: 1.0082247257232666, acc: 0.75)
[2024-11-29 03:30:35,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:35,459][root][INFO] - Training Epoch: 6/10, step 483/574 completed (loss: 0.7930869460105896, acc: 0.7758620977401733)
[2024-11-29 03:30:35,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:35,742][root][INFO] - Training Epoch: 6/10, step 484/574 completed (loss: 0.09652829170227051, acc: 0.9677419066429138)
[2024-11-29 03:30:35,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:36,054][root][INFO] - Training Epoch: 6/10, step 485/574 completed (loss: 0.08646979182958603, acc: 1.0)
[2024-11-29 03:30:36,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:36,358][root][INFO] - Training Epoch: 6/10, step 486/574 completed (loss: 0.8421583771705627, acc: 0.7407407164573669)
[2024-11-29 03:30:36,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:36,649][root][INFO] - Training Epoch: 6/10, step 487/574 completed (loss: 0.6393159031867981, acc: 0.8571428656578064)
[2024-11-29 03:30:36,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:36,923][root][INFO] - Training Epoch: 6/10, step 488/574 completed (loss: 0.38314488530158997, acc: 0.8181818127632141)
[2024-11-29 03:30:37,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:37,274][root][INFO] - Training Epoch: 6/10, step 489/574 completed (loss: 0.8147669434547424, acc: 0.7230769395828247)
[2024-11-29 03:30:37,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:37,585][root][INFO] - Training Epoch: 6/10, step 490/574 completed (loss: 0.16710858047008514, acc: 0.9666666388511658)
[2024-11-29 03:30:37,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:37,898][root][INFO] - Training Epoch: 6/10, step 491/574 completed (loss: 0.2693100571632385, acc: 0.8965517282485962)
[2024-11-29 03:30:38,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:38,197][root][INFO] - Training Epoch: 6/10, step 492/574 completed (loss: 0.30457133054733276, acc: 0.843137264251709)
[2024-11-29 03:30:38,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:38,499][root][INFO] - Training Epoch: 6/10, step 493/574 completed (loss: 0.3580925464630127, acc: 0.931034505367279)
[2024-11-29 03:30:38,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:38,856][root][INFO] - Training Epoch: 6/10, step 494/574 completed (loss: 0.5972025990486145, acc: 0.8947368264198303)
[2024-11-29 03:30:39,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:39,195][root][INFO] - Training Epoch: 6/10, step 495/574 completed (loss: 0.031051892787218094, acc: 1.0)
[2024-11-29 03:30:39,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:39,533][root][INFO] - Training Epoch: 6/10, step 496/574 completed (loss: 0.7381166815757751, acc: 0.8035714030265808)
[2024-11-29 03:30:39,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:39,944][root][INFO] - Training Epoch: 6/10, step 497/574 completed (loss: 0.31289783120155334, acc: 0.9213483333587646)
[2024-11-29 03:30:40,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:40,285][root][INFO] - Training Epoch: 6/10, step 498/574 completed (loss: 0.5128762125968933, acc: 0.8202247023582458)
[2024-11-29 03:30:40,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:40,596][root][INFO] - Training Epoch: 6/10, step 499/574 completed (loss: 1.2052357196807861, acc: 0.652482271194458)
[2024-11-29 03:30:40,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:40,876][root][INFO] - Training Epoch: 6/10, step 500/574 completed (loss: 0.6892048120498657, acc: 0.79347825050354)
[2024-11-29 03:30:41,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:41,142][root][INFO] - Training Epoch: 6/10, step 501/574 completed (loss: 0.13406984508037567, acc: 0.9200000166893005)
[2024-11-29 03:30:41,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:41,432][root][INFO] - Training Epoch: 6/10, step 502/574 completed (loss: 0.022675367072224617, acc: 1.0)
[2024-11-29 03:30:41,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:41,734][root][INFO] - Training Epoch: 6/10, step 503/574 completed (loss: 0.6201968789100647, acc: 0.8518518805503845)
[2024-11-29 03:30:41,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:42,018][root][INFO] - Training Epoch: 6/10, step 504/574 completed (loss: 0.05126969888806343, acc: 1.0)
[2024-11-29 03:30:42,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:42,272][root][INFO] - Training Epoch: 6/10, step 505/574 completed (loss: 0.8633675575256348, acc: 0.8113207817077637)
[2024-11-29 03:30:42,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:42,524][root][INFO] - Training Epoch: 6/10, step 506/574 completed (loss: 1.2239601612091064, acc: 0.7241379022598267)
[2024-11-29 03:30:42,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:43,334][root][INFO] - Training Epoch: 6/10, step 507/574 completed (loss: 1.231422781944275, acc: 0.684684693813324)
[2024-11-29 03:30:43,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:43,875][root][INFO] - Training Epoch: 6/10, step 508/574 completed (loss: 0.693008303642273, acc: 0.8309859037399292)
[2024-11-29 03:30:44,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:44,134][root][INFO] - Training Epoch: 6/10, step 509/574 completed (loss: 0.028755981475114822, acc: 1.0)
[2024-11-29 03:30:44,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:44,386][root][INFO] - Training Epoch: 6/10, step 510/574 completed (loss: 0.1672196388244629, acc: 0.9666666388511658)
[2024-11-29 03:30:44,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:44,636][root][INFO] - Training Epoch: 6/10, step 511/574 completed (loss: 0.20413967967033386, acc: 0.9615384340286255)
[2024-11-29 03:30:46,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:48,100][root][INFO] - Training Epoch: 6/10, step 512/574 completed (loss: 0.9588924050331116, acc: 0.7071428298950195)
[2024-11-29 03:30:48,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:49,210][root][INFO] - Training Epoch: 6/10, step 513/574 completed (loss: 0.3753935992717743, acc: 0.8730158805847168)
[2024-11-29 03:30:49,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:49,463][root][INFO] - Training Epoch: 6/10, step 514/574 completed (loss: 0.6847492456436157, acc: 0.8571428656578064)
[2024-11-29 03:30:49,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:49,734][root][INFO] - Training Epoch: 6/10, step 515/574 completed (loss: 0.0624115876853466, acc: 0.9666666388511658)
[2024-11-29 03:30:50,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:50,715][root][INFO] - Training Epoch: 6/10, step 516/574 completed (loss: 0.4433879554271698, acc: 0.8888888955116272)
[2024-11-29 03:30:50,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:51,035][root][INFO] - Training Epoch: 6/10, step 517/574 completed (loss: 0.009511016309261322, acc: 1.0)
[2024-11-29 03:30:51,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:51,316][root][INFO] - Training Epoch: 6/10, step 518/574 completed (loss: 0.18069282174110413, acc: 0.9354838728904724)
[2024-11-29 03:30:51,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:51,573][root][INFO] - Training Epoch: 6/10, step 519/574 completed (loss: 0.23284217715263367, acc: 0.8999999761581421)
[2024-11-29 03:30:51,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:51,894][root][INFO] - Training Epoch: 6/10, step 520/574 completed (loss: 0.5232664942741394, acc: 0.8518518805503845)
[2024-11-29 03:30:52,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:53,390][root][INFO] - Training Epoch: 6/10, step 521/574 completed (loss: 0.8166488409042358, acc: 0.7796609997749329)
[2024-11-29 03:30:53,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:53,798][root][INFO] - Training Epoch: 6/10, step 522/574 completed (loss: 0.3745872378349304, acc: 0.8656716346740723)
[2024-11-29 03:30:54,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:54,196][root][INFO] - Training Epoch: 6/10, step 523/574 completed (loss: 0.564031720161438, acc: 0.8102189898490906)
[2024-11-29 03:30:54,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:54,937][root][INFO] - Training Epoch: 6/10, step 524/574 completed (loss: 0.7839839458465576, acc: 0.7699999809265137)
[2024-11-29 03:30:55,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:55,244][root][INFO] - Training Epoch: 6/10, step 525/574 completed (loss: 0.17268358170986176, acc: 0.9629629850387573)
[2024-11-29 03:30:55,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:55,541][root][INFO] - Training Epoch: 6/10, step 526/574 completed (loss: 0.15935245156288147, acc: 0.942307710647583)
[2024-11-29 03:30:55,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:55,829][root][INFO] - Training Epoch: 6/10, step 527/574 completed (loss: 0.1606990396976471, acc: 0.9523809552192688)
[2024-11-29 03:30:56,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:56,143][root][INFO] - Training Epoch: 6/10, step 528/574 completed (loss: 1.3335322141647339, acc: 0.5901639461517334)
[2024-11-29 03:30:56,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:56,462][root][INFO] - Training Epoch: 6/10, step 529/574 completed (loss: 0.25570905208587646, acc: 0.9322034120559692)
[2024-11-29 03:30:56,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:56,763][root][INFO] - Training Epoch: 6/10, step 530/574 completed (loss: 1.6307755708694458, acc: 0.5813953280448914)
[2024-11-29 03:30:56,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:57,114][root][INFO] - Training Epoch: 6/10, step 531/574 completed (loss: 0.581054151058197, acc: 0.8409090638160706)
[2024-11-29 03:30:57,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:57,433][root][INFO] - Training Epoch: 6/10, step 532/574 completed (loss: 0.9203998446464539, acc: 0.7924528121948242)
[2024-11-29 03:30:57,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:57,723][root][INFO] - Training Epoch: 6/10, step 533/574 completed (loss: 0.7696512341499329, acc: 0.7954545617103577)
[2024-11-29 03:30:57,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:58,036][root][INFO] - Training Epoch: 6/10, step 534/574 completed (loss: 0.46994245052337646, acc: 0.8799999952316284)
[2024-11-29 03:30:58,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:58,405][root][INFO] - Training Epoch: 6/10, step 535/574 completed (loss: 0.07569439709186554, acc: 1.0)
[2024-11-29 03:30:58,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:58,703][root][INFO] - Training Epoch: 6/10, step 536/574 completed (loss: 0.11460945010185242, acc: 1.0)
[2024-11-29 03:30:58,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:59,153][root][INFO] - Training Epoch: 6/10, step 537/574 completed (loss: 0.4968143701553345, acc: 0.8615384697914124)
[2024-11-29 03:30:59,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:59,469][root][INFO] - Training Epoch: 6/10, step 538/574 completed (loss: 0.36486467719078064, acc: 0.890625)
[2024-11-29 03:30:59,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:30:59,906][root][INFO] - Training Epoch: 6/10, step 539/574 completed (loss: 0.430243581533432, acc: 0.875)
[2024-11-29 03:31:00,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:00,198][root][INFO] - Training Epoch: 6/10, step 540/574 completed (loss: 0.8374534249305725, acc: 0.8181818127632141)
[2024-11-29 03:31:00,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:00,467][root][INFO] - Training Epoch: 6/10, step 541/574 completed (loss: 0.05233690142631531, acc: 1.0)
[2024-11-29 03:31:00,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:00,784][root][INFO] - Training Epoch: 6/10, step 542/574 completed (loss: 0.12516480684280396, acc: 0.9354838728904724)
[2024-11-29 03:31:00,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:01,084][root][INFO] - Training Epoch: 6/10, step 543/574 completed (loss: 0.02608339861035347, acc: 1.0)
[2024-11-29 03:31:01,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:01,359][root][INFO] - Training Epoch: 6/10, step 544/574 completed (loss: 0.13225293159484863, acc: 0.9333333373069763)
[2024-11-29 03:31:01,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:01,678][root][INFO] - Training Epoch: 6/10, step 545/574 completed (loss: 0.060255639255046844, acc: 0.9756097793579102)
[2024-11-29 03:31:01,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:01,973][root][INFO] - Training Epoch: 6/10, step 546/574 completed (loss: 0.25907984375953674, acc: 0.9142857193946838)
[2024-11-29 03:31:02,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:02,251][root][INFO] - Training Epoch: 6/10, step 547/574 completed (loss: 0.022119419649243355, acc: 1.0)
[2024-11-29 03:31:02,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:02,551][root][INFO] - Training Epoch: 6/10, step 548/574 completed (loss: 0.09375730156898499, acc: 0.9677419066429138)
[2024-11-29 03:31:02,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:02,858][root][INFO] - Training Epoch: 6/10, step 549/574 completed (loss: 0.021820245310664177, acc: 1.0)
[2024-11-29 03:31:03,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:03,183][root][INFO] - Training Epoch: 6/10, step 550/574 completed (loss: 0.1073385700583458, acc: 0.9696969985961914)
[2024-11-29 03:31:03,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:03,510][root][INFO] - Training Epoch: 6/10, step 551/574 completed (loss: 0.5887916088104248, acc: 0.875)
[2024-11-29 03:31:03,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:03,806][root][INFO] - Training Epoch: 6/10, step 552/574 completed (loss: 0.3923363983631134, acc: 0.8999999761581421)
[2024-11-29 03:31:03,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:04,084][root][INFO] - Training Epoch: 6/10, step 553/574 completed (loss: 0.47912007570266724, acc: 0.8540145754814148)
[2024-11-29 03:31:04,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:04,445][root][INFO] - Training Epoch: 6/10, step 554/574 completed (loss: 0.2919560670852661, acc: 0.8896551728248596)
[2024-11-29 03:31:04,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:04,785][root][INFO] - Training Epoch: 6/10, step 555/574 completed (loss: 0.5294950604438782, acc: 0.8571428656578064)
[2024-11-29 03:31:04,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:05,120][root][INFO] - Training Epoch: 6/10, step 556/574 completed (loss: 0.4509531855583191, acc: 0.8807947039604187)
[2024-11-29 03:31:05,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:05,423][root][INFO] - Training Epoch: 6/10, step 557/574 completed (loss: 0.19900931417942047, acc: 0.94017094373703)
[2024-11-29 03:31:05,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:05,719][root][INFO] - Training Epoch: 6/10, step 558/574 completed (loss: 0.04761326685547829, acc: 1.0)
[2024-11-29 03:31:05,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:06,049][root][INFO] - Training Epoch: 6/10, step 559/574 completed (loss: 0.07530594617128372, acc: 0.9615384340286255)
[2024-11-29 03:31:06,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:06,322][root][INFO] - Training Epoch: 6/10, step 560/574 completed (loss: 0.09827987849712372, acc: 0.9615384340286255)
[2024-11-29 03:31:06,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:06,616][root][INFO] - Training Epoch: 6/10, step 561/574 completed (loss: 0.1837783306837082, acc: 0.9487179517745972)
[2024-11-29 03:31:07,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:07,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:08,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:08,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:09,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:09,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:09,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:10,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:10,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:11,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:11,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:12,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:12,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:12,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:13,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:13,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:14,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:14,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:15,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:15,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:16,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:16,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:16,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:17,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:17,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:18,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:18,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:18,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:19,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:19,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:20,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:20,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:21,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:21,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:22,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:22,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:22,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:23,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:23,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:24,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:24,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:25,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:25,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:26,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:26,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:27,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:27,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:28,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:28,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:28,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:29,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:29,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:29,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:30,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:30,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:31,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:31,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:31,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:32,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:32,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:33,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:33,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:34,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:34,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:35,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:35,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:36,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:36,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:37,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:37,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:38,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:38,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:39,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:39,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:40,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:40,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:40,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:41,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:41,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:42,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:42,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:42,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:43,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:43,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:44,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:44,924][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.1960, device='cuda:0') eval_epoch_loss=tensor(1.1619, device='cuda:0') eval_epoch_acc=tensor(0.7563, device='cuda:0')
[2024-11-29 03:31:44,926][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:31:44,926][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:31:45,358][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_6_step_562_loss_1.1619058847427368/model.pt
[2024-11-29 03:31:45,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:45,735][root][INFO] - Training Epoch: 6/10, step 562/574 completed (loss: 0.6450725197792053, acc: 0.7888888716697693)
[2024-11-29 03:31:45,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:45,998][root][INFO] - Training Epoch: 6/10, step 563/574 completed (loss: 0.6127380728721619, acc: 0.8701298832893372)
[2024-11-29 03:31:46,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:46,250][root][INFO] - Training Epoch: 6/10, step 564/574 completed (loss: 0.6689634323120117, acc: 0.8541666865348816)
[2024-11-29 03:31:46,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:46,508][root][INFO] - Training Epoch: 6/10, step 565/574 completed (loss: 0.13566020131111145, acc: 0.9655172228813171)
[2024-11-29 03:31:46,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:46,767][root][INFO] - Training Epoch: 6/10, step 566/574 completed (loss: 0.26422521471977234, acc: 0.9404761791229248)
[2024-11-29 03:31:46,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:47,021][root][INFO] - Training Epoch: 6/10, step 567/574 completed (loss: 0.02319185994565487, acc: 1.0)
[2024-11-29 03:31:47,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:47,275][root][INFO] - Training Epoch: 6/10, step 568/574 completed (loss: 0.030772678554058075, acc: 1.0)
[2024-11-29 03:31:47,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:47,686][root][INFO] - Training Epoch: 6/10, step 569/574 completed (loss: 0.4085892140865326, acc: 0.8983957171440125)
[2024-11-29 03:31:47,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:47,927][root][INFO] - Training Epoch: 6/10, step 570/574 completed (loss: 0.37188997864723206, acc: 0.9354838728904724)
[2024-11-29 03:31:48,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:48,186][root][INFO] - Training Epoch: 6/10, step 571/574 completed (loss: 0.34750375151634216, acc: 0.9145299196243286)
[2024-11-29 03:31:48,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:48,542][root][INFO] - Training Epoch: 6/10, step 572/574 completed (loss: 0.7436358332633972, acc: 0.795918345451355)
[2024-11-29 03:31:48,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:48,879][root][INFO] - Training Epoch: 6/10, step 573/574 completed (loss: 0.6537483930587769, acc: 0.8301886916160583)
[2024-11-29 03:31:49,609][slam_llm.utils.train_utils][INFO] - Epoch 6: train_perplexity=1.5942, train_epoch_loss=0.4664, epoch time 384.6095090433955s
[2024-11-29 03:31:49,609][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-11-29 03:31:49,609][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 22 GB
[2024-11-29 03:31:49,610][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-11-29 03:31:49,610][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 12
[2024-11-29 03:31:49,610][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-29 03:31:50,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:50,488][root][INFO] - Training Epoch: 7/10, step 0/574 completed (loss: 0.17008034884929657, acc: 1.0)
[2024-11-29 03:31:50,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:50,803][root][INFO] - Training Epoch: 7/10, step 1/574 completed (loss: 0.500546932220459, acc: 0.9200000166893005)
[2024-11-29 03:31:50,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:51,125][root][INFO] - Training Epoch: 7/10, step 2/574 completed (loss: 0.18081249296665192, acc: 0.9459459185600281)
[2024-11-29 03:31:51,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:51,466][root][INFO] - Training Epoch: 7/10, step 3/574 completed (loss: 0.275464802980423, acc: 0.9210526347160339)
[2024-11-29 03:31:51,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:51,766][root][INFO] - Training Epoch: 7/10, step 4/574 completed (loss: 0.17189420759677887, acc: 0.9729729890823364)
[2024-11-29 03:31:51,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:52,065][root][INFO] - Training Epoch: 7/10, step 5/574 completed (loss: 0.18983101844787598, acc: 0.9642857313156128)
[2024-11-29 03:31:52,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:52,353][root][INFO] - Training Epoch: 7/10, step 6/574 completed (loss: 0.3404349386692047, acc: 0.8979591727256775)
[2024-11-29 03:31:52,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:52,696][root][INFO] - Training Epoch: 7/10, step 7/574 completed (loss: 0.06808695942163467, acc: 0.9666666388511658)
[2024-11-29 03:31:52,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:53,083][root][INFO] - Training Epoch: 7/10, step 8/574 completed (loss: 0.09459313750267029, acc: 0.9545454382896423)
[2024-11-29 03:31:53,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:53,380][root][INFO] - Training Epoch: 7/10, step 9/574 completed (loss: 0.027425412088632584, acc: 1.0)
[2024-11-29 03:31:53,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:53,706][root][INFO] - Training Epoch: 7/10, step 10/574 completed (loss: 0.31858500838279724, acc: 0.9259259104728699)
[2024-11-29 03:31:53,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:54,037][root][INFO] - Training Epoch: 7/10, step 11/574 completed (loss: 0.12022813409566879, acc: 0.9743589758872986)
[2024-11-29 03:31:54,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:54,397][root][INFO] - Training Epoch: 7/10, step 12/574 completed (loss: 0.04043017327785492, acc: 1.0)
[2024-11-29 03:31:54,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:54,745][root][INFO] - Training Epoch: 7/10, step 13/574 completed (loss: 0.0603334903717041, acc: 1.0)
[2024-11-29 03:31:54,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:55,033][root][INFO] - Training Epoch: 7/10, step 14/574 completed (loss: 0.056022897362709045, acc: 0.9803921580314636)
[2024-11-29 03:31:55,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:55,303][root][INFO] - Training Epoch: 7/10, step 15/574 completed (loss: 0.24524642527103424, acc: 0.9387755393981934)
[2024-11-29 03:31:55,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:55,619][root][INFO] - Training Epoch: 7/10, step 16/574 completed (loss: 0.29582682251930237, acc: 0.9473684430122375)
[2024-11-29 03:31:55,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:55,943][root][INFO] - Training Epoch: 7/10, step 17/574 completed (loss: 0.2320161610841751, acc: 0.9583333134651184)
[2024-11-29 03:31:56,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:56,215][root][INFO] - Training Epoch: 7/10, step 18/574 completed (loss: 0.3067830801010132, acc: 0.8888888955116272)
[2024-11-29 03:31:56,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:56,480][root][INFO] - Training Epoch: 7/10, step 19/574 completed (loss: 0.06411176919937134, acc: 0.9473684430122375)
[2024-11-29 03:31:56,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:56,804][root][INFO] - Training Epoch: 7/10, step 20/574 completed (loss: 0.11367566138505936, acc: 0.9615384340286255)
[2024-11-29 03:31:56,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:57,110][root][INFO] - Training Epoch: 7/10, step 21/574 completed (loss: 0.43142998218536377, acc: 0.9655172228813171)
[2024-11-29 03:31:57,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:57,421][root][INFO] - Training Epoch: 7/10, step 22/574 completed (loss: 0.22842085361480713, acc: 0.9200000166893005)
[2024-11-29 03:31:57,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:57,708][root][INFO] - Training Epoch: 7/10, step 23/574 completed (loss: 0.07041211426258087, acc: 1.0)
[2024-11-29 03:31:57,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:58,032][root][INFO] - Training Epoch: 7/10, step 24/574 completed (loss: 0.2582746744155884, acc: 0.9375)
[2024-11-29 03:31:58,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:58,361][root][INFO] - Training Epoch: 7/10, step 25/574 completed (loss: 0.6456891298294067, acc: 0.8301886916160583)
[2024-11-29 03:31:58,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:31:58,657][root][INFO] - Training Epoch: 7/10, step 26/574 completed (loss: 1.0066027641296387, acc: 0.7397260069847107)
[2024-11-29 03:31:59,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:00,364][root][INFO] - Training Epoch: 7/10, step 27/574 completed (loss: 1.2051246166229248, acc: 0.6679841876029968)
[2024-11-29 03:32:00,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:00,641][root][INFO] - Training Epoch: 7/10, step 28/574 completed (loss: 0.2079102247953415, acc: 0.9534883499145508)
[2024-11-29 03:32:00,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:00,917][root][INFO] - Training Epoch: 7/10, step 29/574 completed (loss: 0.4935851991176605, acc: 0.8433734774589539)
[2024-11-29 03:32:01,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:01,197][root][INFO] - Training Epoch: 7/10, step 30/574 completed (loss: 0.6292147636413574, acc: 0.8148148059844971)
[2024-11-29 03:32:01,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:01,447][root][INFO] - Training Epoch: 7/10, step 31/574 completed (loss: 0.21418319642543793, acc: 0.9642857313156128)
[2024-11-29 03:32:01,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:01,678][root][INFO] - Training Epoch: 7/10, step 32/574 completed (loss: 0.12260513752698898, acc: 0.9629629850387573)
[2024-11-29 03:32:01,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:01,918][root][INFO] - Training Epoch: 7/10, step 33/574 completed (loss: 0.028719265013933182, acc: 1.0)
[2024-11-29 03:32:02,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:02,208][root][INFO] - Training Epoch: 7/10, step 34/574 completed (loss: 0.5228852033615112, acc: 0.8739495873451233)
[2024-11-29 03:32:02,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:02,478][root][INFO] - Training Epoch: 7/10, step 35/574 completed (loss: 0.18253612518310547, acc: 0.9508196711540222)
[2024-11-29 03:32:02,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:02,763][root][INFO] - Training Epoch: 7/10, step 36/574 completed (loss: 0.35945451259613037, acc: 0.8888888955116272)
[2024-11-29 03:32:02,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:03,019][root][INFO] - Training Epoch: 7/10, step 37/574 completed (loss: 0.23592549562454224, acc: 0.9322034120559692)
[2024-11-29 03:32:03,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:03,337][root][INFO] - Training Epoch: 7/10, step 38/574 completed (loss: 0.30890005826950073, acc: 0.9080459475517273)
[2024-11-29 03:32:03,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:03,593][root][INFO] - Training Epoch: 7/10, step 39/574 completed (loss: 0.6062018275260925, acc: 0.8571428656578064)
[2024-11-29 03:32:03,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:03,849][root][INFO] - Training Epoch: 7/10, step 40/574 completed (loss: 0.5253604054450989, acc: 0.807692289352417)
[2024-11-29 03:32:04,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:04,236][root][INFO] - Training Epoch: 7/10, step 41/574 completed (loss: 0.23483425378799438, acc: 0.8918918967247009)
[2024-11-29 03:32:04,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:04,570][root][INFO] - Training Epoch: 7/10, step 42/574 completed (loss: 0.4913542568683624, acc: 0.8461538553237915)
[2024-11-29 03:32:04,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:05,048][root][INFO] - Training Epoch: 7/10, step 43/574 completed (loss: 0.5244452357292175, acc: 0.8484848737716675)
[2024-11-29 03:32:05,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:05,521][root][INFO] - Training Epoch: 7/10, step 44/574 completed (loss: 0.471975177526474, acc: 0.876288652420044)
[2024-11-29 03:32:05,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:05,971][root][INFO] - Training Epoch: 7/10, step 45/574 completed (loss: 0.5875187516212463, acc: 0.8235294222831726)
[2024-11-29 03:32:06,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:06,272][root][INFO] - Training Epoch: 7/10, step 46/574 completed (loss: 0.09377170354127884, acc: 1.0)
[2024-11-29 03:32:06,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:06,545][root][INFO] - Training Epoch: 7/10, step 47/574 completed (loss: 0.05536649748682976, acc: 1.0)
[2024-11-29 03:32:06,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:06,857][root][INFO] - Training Epoch: 7/10, step 48/574 completed (loss: 0.04304690286517143, acc: 1.0)
[2024-11-29 03:32:07,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:07,184][root][INFO] - Training Epoch: 7/10, step 49/574 completed (loss: 0.06918875128030777, acc: 1.0)
[2024-11-29 03:32:07,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:07,458][root][INFO] - Training Epoch: 7/10, step 50/574 completed (loss: 0.7326470613479614, acc: 0.7894737124443054)
[2024-11-29 03:32:07,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:07,733][root][INFO] - Training Epoch: 7/10, step 51/574 completed (loss: 0.40251263976097107, acc: 0.920634925365448)
[2024-11-29 03:32:07,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:08,005][root][INFO] - Training Epoch: 7/10, step 52/574 completed (loss: 0.8777817487716675, acc: 0.7605633735656738)
[2024-11-29 03:32:08,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:08,577][root][INFO] - Training Epoch: 7/10, step 53/574 completed (loss: 1.3607145547866821, acc: 0.6133333444595337)
[2024-11-29 03:32:08,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:08,840][root][INFO] - Training Epoch: 7/10, step 54/574 completed (loss: 0.44317761063575745, acc: 0.8648648858070374)
[2024-11-29 03:32:08,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:09,127][root][INFO] - Training Epoch: 7/10, step 55/574 completed (loss: 0.04816989228129387, acc: 1.0)
[2024-11-29 03:32:12,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:13,834][root][INFO] - Training Epoch: 7/10, step 56/574 completed (loss: 1.2346454858779907, acc: 0.6655290126800537)
[2024-11-29 03:32:14,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:15,568][root][INFO] - Training Epoch: 7/10, step 57/574 completed (loss: 1.475885272026062, acc: 0.5925925970077515)
[2024-11-29 03:32:16,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:16,394][root][INFO] - Training Epoch: 7/10, step 58/574 completed (loss: 0.6642696857452393, acc: 0.8409090638160706)
[2024-11-29 03:32:16,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:17,160][root][INFO] - Training Epoch: 7/10, step 59/574 completed (loss: 0.34207725524902344, acc: 0.9117646813392639)
[2024-11-29 03:32:17,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:17,901][root][INFO] - Training Epoch: 7/10, step 60/574 completed (loss: 0.6449670791625977, acc: 0.804347813129425)
[2024-11-29 03:32:18,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:18,382][root][INFO] - Training Epoch: 7/10, step 61/574 completed (loss: 0.7443256378173828, acc: 0.8125)
[2024-11-29 03:32:18,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:18,660][root][INFO] - Training Epoch: 7/10, step 62/574 completed (loss: 0.05217486992478371, acc: 1.0)
[2024-11-29 03:32:18,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:18,937][root][INFO] - Training Epoch: 7/10, step 63/574 completed (loss: 0.08668002486228943, acc: 0.9722222089767456)
[2024-11-29 03:32:19,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:19,251][root][INFO] - Training Epoch: 7/10, step 64/574 completed (loss: 0.12615461647510529, acc: 0.96875)
[2024-11-29 03:32:19,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:19,505][root][INFO] - Training Epoch: 7/10, step 65/574 completed (loss: 0.06815817952156067, acc: 1.0)
[2024-11-29 03:32:19,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:19,803][root][INFO] - Training Epoch: 7/10, step 66/574 completed (loss: 0.6259055137634277, acc: 0.7857142686843872)
[2024-11-29 03:32:19,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:20,098][root][INFO] - Training Epoch: 7/10, step 67/574 completed (loss: 0.37751466035842896, acc: 0.8999999761581421)
[2024-11-29 03:32:20,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:20,356][root][INFO] - Training Epoch: 7/10, step 68/574 completed (loss: 0.016589919105172157, acc: 1.0)
[2024-11-29 03:32:20,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:20,617][root][INFO] - Training Epoch: 7/10, step 69/574 completed (loss: 0.3975081443786621, acc: 0.8611111044883728)
[2024-11-29 03:32:20,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:20,873][root][INFO] - Training Epoch: 7/10, step 70/574 completed (loss: 0.19445332884788513, acc: 0.939393937587738)
[2024-11-29 03:32:21,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:21,241][root][INFO] - Training Epoch: 7/10, step 71/574 completed (loss: 1.1295928955078125, acc: 0.7058823704719543)
[2024-11-29 03:32:21,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:21,590][root][INFO] - Training Epoch: 7/10, step 72/574 completed (loss: 0.6808250546455383, acc: 0.8015872836112976)
[2024-11-29 03:32:21,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:21,891][root][INFO] - Training Epoch: 7/10, step 73/574 completed (loss: 1.325255274772644, acc: 0.6717948913574219)
[2024-11-29 03:32:22,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:22,149][root][INFO] - Training Epoch: 7/10, step 74/574 completed (loss: 0.8285182118415833, acc: 0.7755101919174194)
[2024-11-29 03:32:22,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:22,410][root][INFO] - Training Epoch: 7/10, step 75/574 completed (loss: 0.9167383313179016, acc: 0.7388059496879578)
[2024-11-29 03:32:22,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:22,818][root][INFO] - Training Epoch: 7/10, step 76/574 completed (loss: 1.614758849143982, acc: 0.6021897792816162)
[2024-11-29 03:32:22,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:23,110][root][INFO] - Training Epoch: 7/10, step 77/574 completed (loss: 0.02684098109602928, acc: 1.0)
[2024-11-29 03:32:23,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:23,377][root][INFO] - Training Epoch: 7/10, step 78/574 completed (loss: 0.03871649503707886, acc: 1.0)
[2024-11-29 03:32:23,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:23,635][root][INFO] - Training Epoch: 7/10, step 79/574 completed (loss: 0.17811176180839539, acc: 0.939393937587738)
[2024-11-29 03:32:23,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:23,898][root][INFO] - Training Epoch: 7/10, step 80/574 completed (loss: 0.021230021491646767, acc: 1.0)
[2024-11-29 03:32:24,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:24,187][root][INFO] - Training Epoch: 7/10, step 81/574 completed (loss: 0.3428848087787628, acc: 0.9038461446762085)
[2024-11-29 03:32:24,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:24,446][root][INFO] - Training Epoch: 7/10, step 82/574 completed (loss: 0.6031954288482666, acc: 0.8461538553237915)
[2024-11-29 03:32:24,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:24,709][root][INFO] - Training Epoch: 7/10, step 83/574 completed (loss: 0.06937964260578156, acc: 1.0)
[2024-11-29 03:32:24,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:24,980][root][INFO] - Training Epoch: 7/10, step 84/574 completed (loss: 0.2784147262573242, acc: 0.8985507488250732)
[2024-11-29 03:32:25,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:25,255][root][INFO] - Training Epoch: 7/10, step 85/574 completed (loss: 0.21723152697086334, acc: 0.9599999785423279)
[2024-11-29 03:32:25,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:25,511][root][INFO] - Training Epoch: 7/10, step 86/574 completed (loss: 0.322882741689682, acc: 0.95652174949646)
[2024-11-29 03:32:25,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:26,084][root][INFO] - Training Epoch: 7/10, step 87/574 completed (loss: 0.885105311870575, acc: 0.699999988079071)
[2024-11-29 03:32:26,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:26,441][root][INFO] - Training Epoch: 7/10, step 88/574 completed (loss: 0.8786187767982483, acc: 0.7864077687263489)
[2024-11-29 03:32:27,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:28,129][root][INFO] - Training Epoch: 7/10, step 89/574 completed (loss: 0.9337100982666016, acc: 0.7572815418243408)
[2024-11-29 03:32:28,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:29,287][root][INFO] - Training Epoch: 7/10, step 90/574 completed (loss: 1.2504767179489136, acc: 0.6827957034111023)
[2024-11-29 03:32:29,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:30,432][root][INFO] - Training Epoch: 7/10, step 91/574 completed (loss: 1.0912171602249146, acc: 0.7068965435028076)
[2024-11-29 03:32:31,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:31,666][root][INFO] - Training Epoch: 7/10, step 92/574 completed (loss: 0.7434400320053101, acc: 0.800000011920929)
[2024-11-29 03:32:32,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:33,207][root][INFO] - Training Epoch: 7/10, step 93/574 completed (loss: 1.1257119178771973, acc: 0.6831682920455933)
[2024-11-29 03:32:33,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:33,452][root][INFO] - Training Epoch: 7/10, step 94/574 completed (loss: 0.6643447875976562, acc: 0.7903226017951965)
[2024-11-29 03:32:33,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:33,755][root][INFO] - Training Epoch: 7/10, step 95/574 completed (loss: 0.5185540914535522, acc: 0.8695651888847351)
[2024-11-29 03:32:33,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:34,107][root][INFO] - Training Epoch: 7/10, step 96/574 completed (loss: 1.044883131980896, acc: 0.6638655662536621)
[2024-11-29 03:32:34,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:34,448][root][INFO] - Training Epoch: 7/10, step 97/574 completed (loss: 1.1367653608322144, acc: 0.6538461446762085)
[2024-11-29 03:32:34,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:34,853][root][INFO] - Training Epoch: 7/10, step 98/574 completed (loss: 1.4475853443145752, acc: 0.6131386756896973)
[2024-11-29 03:32:35,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:35,142][root][INFO] - Training Epoch: 7/10, step 99/574 completed (loss: 0.7548803687095642, acc: 0.7611940503120422)
[2024-11-29 03:32:35,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:35,458][root][INFO] - Training Epoch: 7/10, step 100/574 completed (loss: 0.32288771867752075, acc: 0.949999988079071)
[2024-11-29 03:32:35,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:35,794][root][INFO] - Training Epoch: 7/10, step 101/574 completed (loss: 0.03200426325201988, acc: 1.0)
[2024-11-29 03:32:35,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:36,123][root][INFO] - Training Epoch: 7/10, step 102/574 completed (loss: 0.023265667259693146, acc: 1.0)
[2024-11-29 03:32:36,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:36,403][root][INFO] - Training Epoch: 7/10, step 103/574 completed (loss: 0.03804505988955498, acc: 1.0)
[2024-11-29 03:32:36,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:36,728][root][INFO] - Training Epoch: 7/10, step 104/574 completed (loss: 0.2775711119174957, acc: 0.9482758641242981)
[2024-11-29 03:32:36,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:37,021][root][INFO] - Training Epoch: 7/10, step 105/574 completed (loss: 0.056344036012887955, acc: 0.9767441749572754)
[2024-11-29 03:32:37,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:37,312][root][INFO] - Training Epoch: 7/10, step 106/574 completed (loss: 0.1475447565317154, acc: 0.9200000166893005)
[2024-11-29 03:32:37,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:37,572][root][INFO] - Training Epoch: 7/10, step 107/574 completed (loss: 0.012333137914538383, acc: 1.0)
[2024-11-29 03:32:37,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:37,834][root][INFO] - Training Epoch: 7/10, step 108/574 completed (loss: 0.020078811794519424, acc: 1.0)
[2024-11-29 03:32:37,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:38,090][root][INFO] - Training Epoch: 7/10, step 109/574 completed (loss: 0.04951239749789238, acc: 0.976190447807312)
[2024-11-29 03:32:38,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:38,374][root][INFO] - Training Epoch: 7/10, step 110/574 completed (loss: 0.15146170556545258, acc: 0.9846153855323792)
[2024-11-29 03:32:38,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:38,836][root][INFO] - Training Epoch: 7/10, step 111/574 completed (loss: 0.3461798429489136, acc: 0.8947368264198303)
[2024-11-29 03:32:39,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:39,194][root][INFO] - Training Epoch: 7/10, step 112/574 completed (loss: 0.4403177797794342, acc: 0.859649121761322)
[2024-11-29 03:32:39,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:39,477][root][INFO] - Training Epoch: 7/10, step 113/574 completed (loss: 0.11993280053138733, acc: 0.9743589758872986)
[2024-11-29 03:32:39,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:39,854][root][INFO] - Training Epoch: 7/10, step 114/574 completed (loss: 0.347693532705307, acc: 0.8571428656578064)
[2024-11-29 03:32:40,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:40,166][root][INFO] - Training Epoch: 7/10, step 115/574 completed (loss: 0.04262008145451546, acc: 1.0)
[2024-11-29 03:32:40,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:40,553][root][INFO] - Training Epoch: 7/10, step 116/574 completed (loss: 0.23899133503437042, acc: 0.9047619104385376)
[2024-11-29 03:32:40,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:40,895][root][INFO] - Training Epoch: 7/10, step 117/574 completed (loss: 0.38850075006484985, acc: 0.8943089246749878)
[2024-11-29 03:32:41,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:41,229][root][INFO] - Training Epoch: 7/10, step 118/574 completed (loss: 0.1925196349620819, acc: 0.9516128897666931)
[2024-11-29 03:32:41,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:42,440][root][INFO] - Training Epoch: 7/10, step 119/574 completed (loss: 0.9808961153030396, acc: 0.7490494251251221)
[2024-11-29 03:32:42,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:42,775][root][INFO] - Training Epoch: 7/10, step 120/574 completed (loss: 0.26376578211784363, acc: 0.9200000166893005)
[2024-11-29 03:32:43,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:43,224][root][INFO] - Training Epoch: 7/10, step 121/574 completed (loss: 0.13722705841064453, acc: 0.9807692170143127)
[2024-11-29 03:32:43,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:43,516][root][INFO] - Training Epoch: 7/10, step 122/574 completed (loss: 0.08927632123231888, acc: 0.9583333134651184)
[2024-11-29 03:32:43,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:43,892][root][INFO] - Training Epoch: 7/10, step 123/574 completed (loss: 0.13763225078582764, acc: 1.0)
[2024-11-29 03:32:44,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:44,237][root][INFO] - Training Epoch: 7/10, step 124/574 completed (loss: 1.2691700458526611, acc: 0.6257668733596802)
[2024-11-29 03:32:44,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:44,576][root][INFO] - Training Epoch: 7/10, step 125/574 completed (loss: 1.0891165733337402, acc: 0.7222222089767456)
[2024-11-29 03:32:44,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:44,905][root][INFO] - Training Epoch: 7/10, step 126/574 completed (loss: 0.9546213746070862, acc: 0.7083333134651184)
[2024-11-29 03:32:45,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:45,276][root][INFO] - Training Epoch: 7/10, step 127/574 completed (loss: 1.0552202463150024, acc: 0.6964285969734192)
[2024-11-29 03:32:45,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:45,597][root][INFO] - Training Epoch: 7/10, step 128/574 completed (loss: 0.7432244420051575, acc: 0.8051282167434692)
[2024-11-29 03:32:45,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:46,043][root][INFO] - Training Epoch: 7/10, step 129/574 completed (loss: 0.9946239590644836, acc: 0.7352941036224365)
[2024-11-29 03:32:46,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:46,364][root][INFO] - Training Epoch: 7/10, step 130/574 completed (loss: 0.12454843521118164, acc: 0.9615384340286255)
[2024-11-29 03:32:47,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:47,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:48,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:48,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:49,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:49,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:49,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:50,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:50,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:51,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:51,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:52,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:52,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:53,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:53,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:54,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:54,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:55,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:55,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:56,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:56,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:56,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:57,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:57,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:58,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:58,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:58,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:32:59,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:00,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:00,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:00,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:01,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:01,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:02,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:02,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:03,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:03,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:04,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:04,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:05,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:05,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:05,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:06,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:06,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:07,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:07,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:08,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:08,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:08,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:09,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:09,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:10,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:10,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:10,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:11,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:11,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:12,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:12,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:12,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:13,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:14,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:14,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:15,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:15,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:16,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:16,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:17,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:17,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:18,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:18,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:19,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:19,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:20,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:20,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:21,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:21,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:21,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:22,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:22,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:23,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:23,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:24,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:24,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:25,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:25,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:26,317][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.8788, device='cuda:0') eval_epoch_loss=tensor(1.0574, device='cuda:0') eval_epoch_acc=tensor(0.7732, device='cuda:0')
[2024-11-29 03:33:26,318][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:33:26,318][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:33:26,608][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_7_step_131_loss_1.0573904514312744/model.pt
[2024-11-29 03:33:26,612][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 7 is 0.773209273815155
[2024-11-29 03:33:26,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:26,865][root][INFO] - Training Epoch: 7/10, step 131/574 completed (loss: 0.2697046101093292, acc: 0.95652174949646)
[2024-11-29 03:33:26,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:27,112][root][INFO] - Training Epoch: 7/10, step 132/574 completed (loss: 0.635460376739502, acc: 0.84375)
[2024-11-29 03:33:27,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:27,370][root][INFO] - Training Epoch: 7/10, step 133/574 completed (loss: 0.15971718728542328, acc: 0.95652174949646)
[2024-11-29 03:33:27,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:27,660][root][INFO] - Training Epoch: 7/10, step 134/574 completed (loss: 0.26800045371055603, acc: 0.9142857193946838)
[2024-11-29 03:33:27,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:27,918][root][INFO] - Training Epoch: 7/10, step 135/574 completed (loss: 0.15521477162837982, acc: 0.9615384340286255)
[2024-11-29 03:33:28,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:28,162][root][INFO] - Training Epoch: 7/10, step 136/574 completed (loss: 0.3512561023235321, acc: 0.8809523582458496)
[2024-11-29 03:33:28,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:28,406][root][INFO] - Training Epoch: 7/10, step 137/574 completed (loss: 0.9805670976638794, acc: 0.7666666507720947)
[2024-11-29 03:33:28,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:28,652][root][INFO] - Training Epoch: 7/10, step 138/574 completed (loss: 0.043813299387693405, acc: 1.0)
[2024-11-29 03:33:28,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:28,901][root][INFO] - Training Epoch: 7/10, step 139/574 completed (loss: 0.04554858058691025, acc: 1.0)
[2024-11-29 03:33:29,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:29,154][root][INFO] - Training Epoch: 7/10, step 140/574 completed (loss: 0.5718068480491638, acc: 0.8461538553237915)
[2024-11-29 03:33:29,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:29,407][root][INFO] - Training Epoch: 7/10, step 141/574 completed (loss: 0.13367725908756256, acc: 0.9677419066429138)
[2024-11-29 03:33:29,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:29,660][root][INFO] - Training Epoch: 7/10, step 142/574 completed (loss: 0.2684396207332611, acc: 0.9189189076423645)
[2024-11-29 03:33:30,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:30,351][root][INFO] - Training Epoch: 7/10, step 143/574 completed (loss: 0.591334879398346, acc: 0.7631579041481018)
[2024-11-29 03:33:30,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:30,668][root][INFO] - Training Epoch: 7/10, step 144/574 completed (loss: 0.7629235982894897, acc: 0.7611940503120422)
[2024-11-29 03:33:30,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:30,986][root][INFO] - Training Epoch: 7/10, step 145/574 completed (loss: 0.4160287082195282, acc: 0.8469387888908386)
[2024-11-29 03:33:31,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:31,536][root][INFO] - Training Epoch: 7/10, step 146/574 completed (loss: 0.8375372290611267, acc: 0.7446808218955994)
[2024-11-29 03:33:31,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:31,792][root][INFO] - Training Epoch: 7/10, step 147/574 completed (loss: 0.49285098910331726, acc: 0.8428571224212646)
[2024-11-29 03:33:31,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:32,035][root][INFO] - Training Epoch: 7/10, step 148/574 completed (loss: 0.11061067879199982, acc: 0.9642857313156128)
[2024-11-29 03:33:32,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:32,284][root][INFO] - Training Epoch: 7/10, step 149/574 completed (loss: 0.35961395502090454, acc: 0.8695651888847351)
[2024-11-29 03:33:32,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:32,538][root][INFO] - Training Epoch: 7/10, step 150/574 completed (loss: 0.41855111718177795, acc: 0.8965517282485962)
[2024-11-29 03:33:32,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:32,843][root][INFO] - Training Epoch: 7/10, step 151/574 completed (loss: 0.6439710855484009, acc: 0.8478260636329651)
[2024-11-29 03:33:33,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:33,134][root][INFO] - Training Epoch: 7/10, step 152/574 completed (loss: 0.48120343685150146, acc: 0.8813559412956238)
[2024-11-29 03:33:33,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:33,393][root][INFO] - Training Epoch: 7/10, step 153/574 completed (loss: 0.6788745522499084, acc: 0.7368420958518982)
[2024-11-29 03:33:33,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:33,680][root][INFO] - Training Epoch: 7/10, step 154/574 completed (loss: 0.3670964241027832, acc: 0.8918918967247009)
[2024-11-29 03:33:33,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:33,923][root][INFO] - Training Epoch: 7/10, step 155/574 completed (loss: 0.3660852909088135, acc: 0.8928571343421936)
[2024-11-29 03:33:34,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:34,167][root][INFO] - Training Epoch: 7/10, step 156/574 completed (loss: 0.29557329416275024, acc: 0.9130434989929199)
[2024-11-29 03:33:34,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:34,487][root][INFO] - Training Epoch: 7/10, step 157/574 completed (loss: 3.1000208854675293, acc: 0.2631579041481018)
[2024-11-29 03:33:36,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:37,028][root][INFO] - Training Epoch: 7/10, step 158/574 completed (loss: 1.0984106063842773, acc: 0.7297297120094299)
[2024-11-29 03:33:37,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:37,298][root][INFO] - Training Epoch: 7/10, step 159/574 completed (loss: 1.0232115983963013, acc: 0.7407407164573669)
[2024-11-29 03:33:37,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:37,764][root][INFO] - Training Epoch: 7/10, step 160/574 completed (loss: 1.3806415796279907, acc: 0.6511628031730652)
[2024-11-29 03:33:38,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:38,583][root][INFO] - Training Epoch: 7/10, step 161/574 completed (loss: 1.7596356868743896, acc: 0.5647059082984924)
[2024-11-29 03:33:39,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:39,340][root][INFO] - Training Epoch: 7/10, step 162/574 completed (loss: 1.4821338653564453, acc: 0.6404494643211365)
[2024-11-29 03:33:39,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:39,659][root][INFO] - Training Epoch: 7/10, step 163/574 completed (loss: 0.5556557178497314, acc: 0.8636363744735718)
[2024-11-29 03:33:39,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:40,002][root][INFO] - Training Epoch: 7/10, step 164/574 completed (loss: 0.4035731852054596, acc: 0.9047619104385376)
[2024-11-29 03:33:40,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:40,331][root][INFO] - Training Epoch: 7/10, step 165/574 completed (loss: 1.821455955505371, acc: 0.517241358757019)
[2024-11-29 03:33:40,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:40,671][root][INFO] - Training Epoch: 7/10, step 166/574 completed (loss: 0.12121473997831345, acc: 0.9795918464660645)
[2024-11-29 03:33:40,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:40,960][root][INFO] - Training Epoch: 7/10, step 167/574 completed (loss: 0.19979776442050934, acc: 0.9599999785423279)
[2024-11-29 03:33:41,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:41,409][root][INFO] - Training Epoch: 7/10, step 168/574 completed (loss: 0.30147233605384827, acc: 0.8888888955116272)
[2024-11-29 03:33:41,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:41,742][root][INFO] - Training Epoch: 7/10, step 169/574 completed (loss: 1.0723668336868286, acc: 0.7647058963775635)
[2024-11-29 03:33:42,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:43,287][root][INFO] - Training Epoch: 7/10, step 170/574 completed (loss: 1.2331936359405518, acc: 0.732876718044281)
[2024-11-29 03:33:43,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:43,542][root][INFO] - Training Epoch: 7/10, step 171/574 completed (loss: 0.11972951143980026, acc: 0.9583333134651184)
[2024-11-29 03:33:43,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:43,807][root][INFO] - Training Epoch: 7/10, step 172/574 completed (loss: 0.8125316500663757, acc: 0.7407407164573669)
[2024-11-29 03:33:43,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:44,056][root][INFO] - Training Epoch: 7/10, step 173/574 completed (loss: 0.4696679711341858, acc: 0.8571428656578064)
[2024-11-29 03:33:44,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:44,776][root][INFO] - Training Epoch: 7/10, step 174/574 completed (loss: 1.2947734594345093, acc: 0.6725663542747498)
[2024-11-29 03:33:44,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:45,024][root][INFO] - Training Epoch: 7/10, step 175/574 completed (loss: 0.7193173766136169, acc: 0.782608687877655)
[2024-11-29 03:33:45,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:45,349][root][INFO] - Training Epoch: 7/10, step 176/574 completed (loss: 0.39600932598114014, acc: 0.8863636255264282)
[2024-11-29 03:33:46,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:46,711][root][INFO] - Training Epoch: 7/10, step 177/574 completed (loss: 1.2446907758712769, acc: 0.694656491279602)
[2024-11-29 03:33:47,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:47,659][root][INFO] - Training Epoch: 7/10, step 178/574 completed (loss: 0.8967485427856445, acc: 0.7481481432914734)
[2024-11-29 03:33:47,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:47,926][root][INFO] - Training Epoch: 7/10, step 179/574 completed (loss: 0.27325239777565, acc: 0.9508196711540222)
[2024-11-29 03:33:48,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:48,224][root][INFO] - Training Epoch: 7/10, step 180/574 completed (loss: 0.04532778263092041, acc: 1.0)
[2024-11-29 03:33:48,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:48,551][root][INFO] - Training Epoch: 7/10, step 181/574 completed (loss: 0.010972733609378338, acc: 1.0)
[2024-11-29 03:33:48,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:48,805][root][INFO] - Training Epoch: 7/10, step 182/574 completed (loss: 0.24630863964557648, acc: 0.8928571343421936)
[2024-11-29 03:33:48,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:49,077][root][INFO] - Training Epoch: 7/10, step 183/574 completed (loss: 0.16386188566684723, acc: 0.9634146094322205)
[2024-11-29 03:33:49,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:49,392][root][INFO] - Training Epoch: 7/10, step 184/574 completed (loss: 0.7196612358093262, acc: 0.8247734308242798)
[2024-11-29 03:33:49,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:49,720][root][INFO] - Training Epoch: 7/10, step 185/574 completed (loss: 0.8052521347999573, acc: 0.7780979871749878)
[2024-11-29 03:33:50,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:50,329][root][INFO] - Training Epoch: 7/10, step 186/574 completed (loss: 0.7388949394226074, acc: 0.8031250238418579)
[2024-11-29 03:33:50,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:50,978][root][INFO] - Training Epoch: 7/10, step 187/574 completed (loss: 0.995099663734436, acc: 0.7467166781425476)
[2024-11-29 03:33:51,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:51,428][root][INFO] - Training Epoch: 7/10, step 188/574 completed (loss: 0.6822705864906311, acc: 0.8149465918540955)
[2024-11-29 03:33:51,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:51,659][root][INFO] - Training Epoch: 7/10, step 189/574 completed (loss: 0.19909876585006714, acc: 0.9200000166893005)
[2024-11-29 03:33:52,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:52,437][root][INFO] - Training Epoch: 7/10, step 190/574 completed (loss: 0.6103001236915588, acc: 0.8255813717842102)
[2024-11-29 03:33:53,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:53,615][root][INFO] - Training Epoch: 7/10, step 191/574 completed (loss: 1.2062219381332397, acc: 0.6666666865348816)
[2024-11-29 03:33:54,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:55,023][root][INFO] - Training Epoch: 7/10, step 192/574 completed (loss: 1.0249799489974976, acc: 0.6818181872367859)
[2024-11-29 03:33:55,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:56,116][root][INFO] - Training Epoch: 7/10, step 193/574 completed (loss: 0.5637728571891785, acc: 0.8235294222831726)
[2024-11-29 03:33:57,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:57,825][root][INFO] - Training Epoch: 7/10, step 194/574 completed (loss: 1.1119225025177002, acc: 0.6975308656692505)
[2024-11-29 03:33:58,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:59,271][root][INFO] - Training Epoch: 7/10, step 195/574 completed (loss: 0.25668326020240784, acc: 0.9193548560142517)
[2024-11-29 03:33:59,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:59,555][root][INFO] - Training Epoch: 7/10, step 196/574 completed (loss: 0.03476066142320633, acc: 1.0)
[2024-11-29 03:33:59,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:33:59,861][root][INFO] - Training Epoch: 7/10, step 197/574 completed (loss: 0.5025784969329834, acc: 0.875)
[2024-11-29 03:34:00,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:00,157][root][INFO] - Training Epoch: 7/10, step 198/574 completed (loss: 0.36367255449295044, acc: 0.8970588445663452)
[2024-11-29 03:34:00,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:00,466][root][INFO] - Training Epoch: 7/10, step 199/574 completed (loss: 1.103895902633667, acc: 0.75)
[2024-11-29 03:34:00,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:00,776][root][INFO] - Training Epoch: 7/10, step 200/574 completed (loss: 0.6727338433265686, acc: 0.7881355881690979)
[2024-11-29 03:34:00,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:01,092][root][INFO] - Training Epoch: 7/10, step 201/574 completed (loss: 0.7050442695617676, acc: 0.7835820913314819)
[2024-11-29 03:34:01,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:01,435][root][INFO] - Training Epoch: 7/10, step 202/574 completed (loss: 0.6646837592124939, acc: 0.7961165308952332)
[2024-11-29 03:34:01,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:01,761][root][INFO] - Training Epoch: 7/10, step 203/574 completed (loss: 0.38889825344085693, acc: 0.8888888955116272)
[2024-11-29 03:34:02,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:02,142][root][INFO] - Training Epoch: 7/10, step 204/574 completed (loss: 0.1626441478729248, acc: 0.9450549483299255)
[2024-11-29 03:34:02,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:02,492][root][INFO] - Training Epoch: 7/10, step 205/574 completed (loss: 0.42306825518608093, acc: 0.8744394779205322)
[2024-11-29 03:34:02,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:02,929][root][INFO] - Training Epoch: 7/10, step 206/574 completed (loss: 0.550648033618927, acc: 0.8385826945304871)
[2024-11-29 03:34:03,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:03,263][root][INFO] - Training Epoch: 7/10, step 207/574 completed (loss: 0.3166423439979553, acc: 0.9051724076271057)
[2024-11-29 03:34:03,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:03,606][root][INFO] - Training Epoch: 7/10, step 208/574 completed (loss: 0.3994859457015991, acc: 0.9094203114509583)
[2024-11-29 03:34:03,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:04,001][root][INFO] - Training Epoch: 7/10, step 209/574 completed (loss: 0.4408453404903412, acc: 0.8404669165611267)
[2024-11-29 03:34:04,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:04,316][root][INFO] - Training Epoch: 7/10, step 210/574 completed (loss: 0.23512473702430725, acc: 0.9239130616188049)
[2024-11-29 03:34:04,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:04,601][root][INFO] - Training Epoch: 7/10, step 211/574 completed (loss: 0.027147868648171425, acc: 1.0)
[2024-11-29 03:34:04,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:04,972][root][INFO] - Training Epoch: 7/10, step 212/574 completed (loss: 0.05858147516846657, acc: 1.0)
[2024-11-29 03:34:05,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:05,257][root][INFO] - Training Epoch: 7/10, step 213/574 completed (loss: 0.4904969334602356, acc: 0.8936170339584351)
[2024-11-29 03:34:05,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:06,228][root][INFO] - Training Epoch: 7/10, step 214/574 completed (loss: 0.18543726205825806, acc: 0.9692307710647583)
[2024-11-29 03:34:06,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:06,572][root][INFO] - Training Epoch: 7/10, step 215/574 completed (loss: 0.08169268816709518, acc: 1.0)
[2024-11-29 03:34:06,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:06,925][root][INFO] - Training Epoch: 7/10, step 216/574 completed (loss: 0.09749948978424072, acc: 0.9767441749572754)
[2024-11-29 03:34:07,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:07,643][root][INFO] - Training Epoch: 7/10, step 217/574 completed (loss: 0.16198958456516266, acc: 0.9369369149208069)
[2024-11-29 03:34:07,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:08,093][root][INFO] - Training Epoch: 7/10, step 218/574 completed (loss: 0.1934044063091278, acc: 0.9333333373069763)
[2024-11-29 03:34:08,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:08,342][root][INFO] - Training Epoch: 7/10, step 219/574 completed (loss: 0.3570079505443573, acc: 0.939393937587738)
[2024-11-29 03:34:08,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:08,604][root][INFO] - Training Epoch: 7/10, step 220/574 completed (loss: 0.08068351447582245, acc: 0.9629629850387573)
[2024-11-29 03:34:08,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:08,882][root][INFO] - Training Epoch: 7/10, step 221/574 completed (loss: 0.021791579201817513, acc: 1.0)
[2024-11-29 03:34:09,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:09,151][root][INFO] - Training Epoch: 7/10, step 222/574 completed (loss: 0.490104079246521, acc: 0.8846153616905212)
[2024-11-29 03:34:09,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:10,227][root][INFO] - Training Epoch: 7/10, step 223/574 completed (loss: 0.486537367105484, acc: 0.85326087474823)
[2024-11-29 03:34:10,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:10,949][root][INFO] - Training Epoch: 7/10, step 224/574 completed (loss: 0.6094402074813843, acc: 0.8409090638160706)
[2024-11-29 03:34:11,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:11,490][root][INFO] - Training Epoch: 7/10, step 225/574 completed (loss: 0.6911232471466064, acc: 0.8191489577293396)
[2024-11-29 03:34:11,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:11,836][root][INFO] - Training Epoch: 7/10, step 226/574 completed (loss: 0.26373085379600525, acc: 0.9245283007621765)
[2024-11-29 03:34:12,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:12,179][root][INFO] - Training Epoch: 7/10, step 227/574 completed (loss: 0.14330892264842987, acc: 0.949999988079071)
[2024-11-29 03:34:12,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:12,448][root][INFO] - Training Epoch: 7/10, step 228/574 completed (loss: 0.944760262966156, acc: 0.7906976938247681)
[2024-11-29 03:34:12,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:12,742][root][INFO] - Training Epoch: 7/10, step 229/574 completed (loss: 1.6314589977264404, acc: 0.6666666865348816)
[2024-11-29 03:34:12,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:13,113][root][INFO] - Training Epoch: 7/10, step 230/574 completed (loss: 2.3959455490112305, acc: 0.4000000059604645)
[2024-11-29 03:34:13,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:13,416][root][INFO] - Training Epoch: 7/10, step 231/574 completed (loss: 1.668067455291748, acc: 0.5888888835906982)
[2024-11-29 03:34:13,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:13,927][root][INFO] - Training Epoch: 7/10, step 232/574 completed (loss: 1.869846224784851, acc: 0.5222222208976746)
[2024-11-29 03:34:14,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:14,553][root][INFO] - Training Epoch: 7/10, step 233/574 completed (loss: 2.1365606784820557, acc: 0.44954127073287964)
[2024-11-29 03:34:14,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:15,152][root][INFO] - Training Epoch: 7/10, step 234/574 completed (loss: 1.7452365159988403, acc: 0.5692307949066162)
[2024-11-29 03:34:15,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:15,468][root][INFO] - Training Epoch: 7/10, step 235/574 completed (loss: 0.5699578523635864, acc: 0.8947368264198303)
[2024-11-29 03:34:15,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:15,785][root][INFO] - Training Epoch: 7/10, step 236/574 completed (loss: 0.23935675621032715, acc: 0.9166666865348816)
[2024-11-29 03:34:15,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:16,054][root][INFO] - Training Epoch: 7/10, step 237/574 completed (loss: 0.10652785748243332, acc: 1.0)
[2024-11-29 03:34:16,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:16,386][root][INFO] - Training Epoch: 7/10, step 238/574 completed (loss: 0.7624531984329224, acc: 0.8148148059844971)
[2024-11-29 03:34:16,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:16,674][root][INFO] - Training Epoch: 7/10, step 239/574 completed (loss: 0.36872532963752747, acc: 0.8571428656578064)
[2024-11-29 03:34:16,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:17,029][root][INFO] - Training Epoch: 7/10, step 240/574 completed (loss: 0.5466678142547607, acc: 0.8863636255264282)
[2024-11-29 03:34:17,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:17,340][root][INFO] - Training Epoch: 7/10, step 241/574 completed (loss: 0.27755007147789, acc: 0.8409090638160706)
[2024-11-29 03:34:17,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:18,147][root][INFO] - Training Epoch: 7/10, step 242/574 completed (loss: 0.8937628269195557, acc: 0.7096773982048035)
[2024-11-29 03:34:18,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:18,863][root][INFO] - Training Epoch: 7/10, step 243/574 completed (loss: 0.637533962726593, acc: 0.7954545617103577)
[2024-11-29 03:34:19,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:19,114][root][INFO] - Training Epoch: 7/10, step 244/574 completed (loss: 0.02669607102870941, acc: 1.0)
[2024-11-29 03:34:19,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:19,364][root][INFO] - Training Epoch: 7/10, step 245/574 completed (loss: 0.496334969997406, acc: 0.8461538553237915)
[2024-11-29 03:34:19,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:19,617][root][INFO] - Training Epoch: 7/10, step 246/574 completed (loss: 0.10290388017892838, acc: 0.9677419066429138)
[2024-11-29 03:34:19,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:19,928][root][INFO] - Training Epoch: 7/10, step 247/574 completed (loss: 0.05710162594914436, acc: 1.0)
[2024-11-29 03:34:20,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:20,298][root][INFO] - Training Epoch: 7/10, step 248/574 completed (loss: 0.18231651186943054, acc: 0.9189189076423645)
[2024-11-29 03:34:20,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:20,581][root][INFO] - Training Epoch: 7/10, step 249/574 completed (loss: 0.18111173808574677, acc: 0.9729729890823364)
[2024-11-29 03:34:20,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:20,853][root][INFO] - Training Epoch: 7/10, step 250/574 completed (loss: 0.027410021051764488, acc: 1.0)
[2024-11-29 03:34:21,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:21,148][root][INFO] - Training Epoch: 7/10, step 251/574 completed (loss: 0.23257091641426086, acc: 0.9264705777168274)
[2024-11-29 03:34:21,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:21,415][root][INFO] - Training Epoch: 7/10, step 252/574 completed (loss: 0.03539668768644333, acc: 1.0)
[2024-11-29 03:34:21,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:21,663][root][INFO] - Training Epoch: 7/10, step 253/574 completed (loss: 0.05458461120724678, acc: 1.0)
[2024-11-29 03:34:21,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:21,894][root][INFO] - Training Epoch: 7/10, step 254/574 completed (loss: 0.00812777690589428, acc: 1.0)
[2024-11-29 03:34:22,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:22,145][root][INFO] - Training Epoch: 7/10, step 255/574 completed (loss: 0.2588999271392822, acc: 0.9354838728904724)
[2024-11-29 03:34:22,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:22,404][root][INFO] - Training Epoch: 7/10, step 256/574 completed (loss: 0.1870494931936264, acc: 0.9473684430122375)
[2024-11-29 03:34:22,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:22,660][root][INFO] - Training Epoch: 7/10, step 257/574 completed (loss: 0.20246925950050354, acc: 0.9285714030265808)
[2024-11-29 03:34:22,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:22,990][root][INFO] - Training Epoch: 7/10, step 258/574 completed (loss: 0.05563076585531235, acc: 0.9868420958518982)
[2024-11-29 03:34:23,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:23,750][root][INFO] - Training Epoch: 7/10, step 259/574 completed (loss: 0.45483797788619995, acc: 0.8679245114326477)
[2024-11-29 03:34:24,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:24,537][root][INFO] - Training Epoch: 7/10, step 260/574 completed (loss: 0.34678637981414795, acc: 0.8833333253860474)
[2024-11-29 03:34:24,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:24,839][root][INFO] - Training Epoch: 7/10, step 261/574 completed (loss: 0.031065089628100395, acc: 1.0)
[2024-11-29 03:34:25,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:25,130][root][INFO] - Training Epoch: 7/10, step 262/574 completed (loss: 0.13649652898311615, acc: 0.9354838728904724)
[2024-11-29 03:34:25,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:25,461][root][INFO] - Training Epoch: 7/10, step 263/574 completed (loss: 0.6875778436660767, acc: 0.800000011920929)
[2024-11-29 03:34:25,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:25,731][root][INFO] - Training Epoch: 7/10, step 264/574 completed (loss: 0.46196702122688293, acc: 0.8541666865348816)
[2024-11-29 03:34:26,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:26,968][root][INFO] - Training Epoch: 7/10, step 265/574 completed (loss: 1.1016982793807983, acc: 0.7039999961853027)
[2024-11-29 03:34:27,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:27,275][root][INFO] - Training Epoch: 7/10, step 266/574 completed (loss: 0.7592369914054871, acc: 0.7752808928489685)
[2024-11-29 03:34:27,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:27,627][root][INFO] - Training Epoch: 7/10, step 267/574 completed (loss: 0.7421994805335999, acc: 0.7432432174682617)
[2024-11-29 03:34:27,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:28,195][root][INFO] - Training Epoch: 7/10, step 268/574 completed (loss: 0.39650845527648926, acc: 0.8965517282485962)
[2024-11-29 03:34:28,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:28,508][root][INFO] - Training Epoch: 7/10, step 269/574 completed (loss: 0.02920587733387947, acc: 1.0)
[2024-11-29 03:34:28,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:28,782][root][INFO] - Training Epoch: 7/10, step 270/574 completed (loss: 0.04278314486145973, acc: 1.0)
[2024-11-29 03:34:28,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:29,020][root][INFO] - Training Epoch: 7/10, step 271/574 completed (loss: 0.12166030704975128, acc: 0.96875)
[2024-11-29 03:34:29,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:29,308][root][INFO] - Training Epoch: 7/10, step 272/574 completed (loss: 0.02673715353012085, acc: 1.0)
[2024-11-29 03:34:29,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:29,719][root][INFO] - Training Epoch: 7/10, step 273/574 completed (loss: 0.21068325638771057, acc: 0.9666666388511658)
[2024-11-29 03:34:30,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:31,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:31,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:31,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:32,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:32,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:33,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:33,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:33,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:34,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:34,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:35,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:35,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:35,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:36,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:36,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:37,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:38,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:38,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:38,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:39,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:39,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:40,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:40,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:40,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:41,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:41,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:42,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:42,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:43,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:43,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:43,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:44,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:44,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:44,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:45,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:45,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:46,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:46,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:47,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:47,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:47,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:48,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:48,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:49,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:49,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:50,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:50,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:51,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:51,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:51,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:52,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:52,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:53,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:53,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:53,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:54,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:54,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:54,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:55,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:55,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:56,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:56,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:57,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:57,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:58,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:58,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:59,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:34:59,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:00,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:00,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:01,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:01,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:02,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:02,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:02,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:03,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:03,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:04,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:04,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:04,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:05,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:05,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:06,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:06,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:07,206][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.0605, device='cuda:0') eval_epoch_loss=tensor(1.1186, device='cuda:0') eval_epoch_acc=tensor(0.7594, device='cuda:0')
[2024-11-29 03:35:07,208][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:35:07,208][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:35:07,500][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_7_step_274_loss_1.1185938119888306/model.pt
[2024-11-29 03:35:07,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:07,879][root][INFO] - Training Epoch: 7/10, step 274/574 completed (loss: 0.026286492124199867, acc: 1.0)
[2024-11-29 03:35:08,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:08,191][root][INFO] - Training Epoch: 7/10, step 275/574 completed (loss: 0.06691848486661911, acc: 0.9666666388511658)
[2024-11-29 03:35:08,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:08,499][root][INFO] - Training Epoch: 7/10, step 276/574 completed (loss: 0.13255664706230164, acc: 0.9655172228813171)
[2024-11-29 03:35:08,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:08,777][root][INFO] - Training Epoch: 7/10, step 277/574 completed (loss: 0.013352615758776665, acc: 1.0)
[2024-11-29 03:35:08,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:09,040][root][INFO] - Training Epoch: 7/10, step 278/574 completed (loss: 0.11522194743156433, acc: 0.936170220375061)
[2024-11-29 03:35:09,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:09,375][root][INFO] - Training Epoch: 7/10, step 279/574 completed (loss: 0.30154457688331604, acc: 0.8958333134651184)
[2024-11-29 03:35:09,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:09,656][root][INFO] - Training Epoch: 7/10, step 280/574 completed (loss: 0.05907762423157692, acc: 0.9772727489471436)
[2024-11-29 03:35:09,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:10,144][root][INFO] - Training Epoch: 7/10, step 281/574 completed (loss: 0.5469814538955688, acc: 0.8192771077156067)
[2024-11-29 03:35:10,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:10,510][root][INFO] - Training Epoch: 7/10, step 282/574 completed (loss: 0.7174096703529358, acc: 0.7962962985038757)
[2024-11-29 03:35:10,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:10,840][root][INFO] - Training Epoch: 7/10, step 283/574 completed (loss: 0.3971918523311615, acc: 0.9210526347160339)
[2024-11-29 03:35:11,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:11,140][root][INFO] - Training Epoch: 7/10, step 284/574 completed (loss: 0.28950440883636475, acc: 0.9117646813392639)
[2024-11-29 03:35:11,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:11,436][root][INFO] - Training Epoch: 7/10, step 285/574 completed (loss: 0.10307648032903671, acc: 0.925000011920929)
[2024-11-29 03:35:11,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:11,794][root][INFO] - Training Epoch: 7/10, step 286/574 completed (loss: 0.41014763712882996, acc: 0.875)
[2024-11-29 03:35:12,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:12,152][root][INFO] - Training Epoch: 7/10, step 287/574 completed (loss: 0.5636613965034485, acc: 0.871999979019165)
[2024-11-29 03:35:12,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:12,501][root][INFO] - Training Epoch: 7/10, step 288/574 completed (loss: 0.29524025321006775, acc: 0.8901098966598511)
[2024-11-29 03:35:12,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:12,827][root][INFO] - Training Epoch: 7/10, step 289/574 completed (loss: 0.2779462933540344, acc: 0.9254658222198486)
[2024-11-29 03:35:13,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:13,170][root][INFO] - Training Epoch: 7/10, step 290/574 completed (loss: 0.5315831899642944, acc: 0.8505154848098755)
[2024-11-29 03:35:13,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:13,474][root][INFO] - Training Epoch: 7/10, step 291/574 completed (loss: 0.19037364423274994, acc: 0.9545454382896423)
[2024-11-29 03:35:13,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:13,816][root][INFO] - Training Epoch: 7/10, step 292/574 completed (loss: 0.2831757366657257, acc: 0.9285714030265808)
[2024-11-29 03:35:14,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:14,175][root][INFO] - Training Epoch: 7/10, step 293/574 completed (loss: 0.15908461809158325, acc: 0.9655172228813171)
[2024-11-29 03:35:14,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:14,796][root][INFO] - Training Epoch: 7/10, step 294/574 completed (loss: 0.4002716839313507, acc: 0.8909090757369995)
[2024-11-29 03:35:15,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:15,513][root][INFO] - Training Epoch: 7/10, step 295/574 completed (loss: 0.9619026780128479, acc: 0.7164948582649231)
[2024-11-29 03:35:15,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:15,838][root][INFO] - Training Epoch: 7/10, step 296/574 completed (loss: 0.32815882563591003, acc: 0.931034505367279)
[2024-11-29 03:35:16,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:16,139][root][INFO] - Training Epoch: 7/10, step 297/574 completed (loss: 0.09878239035606384, acc: 0.9629629850387573)
[2024-11-29 03:35:16,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:16,423][root][INFO] - Training Epoch: 7/10, step 298/574 completed (loss: 0.13601207733154297, acc: 0.9473684430122375)
[2024-11-29 03:35:16,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:16,710][root][INFO] - Training Epoch: 7/10, step 299/574 completed (loss: 0.09044475108385086, acc: 0.9642857313156128)
[2024-11-29 03:35:16,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:17,023][root][INFO] - Training Epoch: 7/10, step 300/574 completed (loss: 0.0756077840924263, acc: 0.96875)
[2024-11-29 03:35:17,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:17,317][root][INFO] - Training Epoch: 7/10, step 301/574 completed (loss: 0.13285252451896667, acc: 0.9433962106704712)
[2024-11-29 03:35:17,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:17,607][root][INFO] - Training Epoch: 7/10, step 302/574 completed (loss: 0.03670491278171539, acc: 0.9811320900917053)
[2024-11-29 03:35:17,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:17,888][root][INFO] - Training Epoch: 7/10, step 303/574 completed (loss: 0.056618012487888336, acc: 1.0)
[2024-11-29 03:35:18,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:18,180][root][INFO] - Training Epoch: 7/10, step 304/574 completed (loss: 0.11813942342996597, acc: 0.96875)
[2024-11-29 03:35:18,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:18,496][root][INFO] - Training Epoch: 7/10, step 305/574 completed (loss: 0.34291115403175354, acc: 0.9180327653884888)
[2024-11-29 03:35:18,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:18,807][root][INFO] - Training Epoch: 7/10, step 306/574 completed (loss: 0.07888489216566086, acc: 0.9666666388511658)
[2024-11-29 03:35:18,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:19,067][root][INFO] - Training Epoch: 7/10, step 307/574 completed (loss: 0.006692994385957718, acc: 1.0)
[2024-11-29 03:35:19,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:19,363][root][INFO] - Training Epoch: 7/10, step 308/574 completed (loss: 0.16343377530574799, acc: 0.95652174949646)
[2024-11-29 03:35:19,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:19,848][root][INFO] - Training Epoch: 7/10, step 309/574 completed (loss: 0.20546665787696838, acc: 0.9444444179534912)
[2024-11-29 03:35:20,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:20,176][root][INFO] - Training Epoch: 7/10, step 310/574 completed (loss: 0.20771239697933197, acc: 0.9277108311653137)
[2024-11-29 03:35:20,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:20,464][root][INFO] - Training Epoch: 7/10, step 311/574 completed (loss: 0.1889002025127411, acc: 0.9487179517745972)
[2024-11-29 03:35:20,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:20,813][root][INFO] - Training Epoch: 7/10, step 312/574 completed (loss: 0.18877297639846802, acc: 0.9489796161651611)
[2024-11-29 03:35:20,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:21,124][root][INFO] - Training Epoch: 7/10, step 313/574 completed (loss: 0.04581327736377716, acc: 1.0)
[2024-11-29 03:35:21,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:21,389][root][INFO] - Training Epoch: 7/10, step 314/574 completed (loss: 0.05552356317639351, acc: 0.9583333134651184)
[2024-11-29 03:35:21,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:21,685][root][INFO] - Training Epoch: 7/10, step 315/574 completed (loss: 0.19615280628204346, acc: 0.9677419066429138)
[2024-11-29 03:35:21,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:22,018][root][INFO] - Training Epoch: 7/10, step 316/574 completed (loss: 1.1449154615402222, acc: 0.7419354915618896)
[2024-11-29 03:35:22,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:22,350][root][INFO] - Training Epoch: 7/10, step 317/574 completed (loss: 0.09442511945962906, acc: 0.9701492786407471)
[2024-11-29 03:35:22,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:22,709][root][INFO] - Training Epoch: 7/10, step 318/574 completed (loss: 0.10693521052598953, acc: 0.9615384340286255)
[2024-11-29 03:35:22,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:22,975][root][INFO] - Training Epoch: 7/10, step 319/574 completed (loss: 0.042828187346458435, acc: 1.0)
[2024-11-29 03:35:23,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:23,234][root][INFO] - Training Epoch: 7/10, step 320/574 completed (loss: 0.0640878900885582, acc: 0.9838709831237793)
[2024-11-29 03:35:23,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:23,553][root][INFO] - Training Epoch: 7/10, step 321/574 completed (loss: 0.01003195159137249, acc: 1.0)
[2024-11-29 03:35:23,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:23,867][root][INFO] - Training Epoch: 7/10, step 322/574 completed (loss: 0.47045060992240906, acc: 0.8888888955116272)
[2024-11-29 03:35:24,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:24,197][root][INFO] - Training Epoch: 7/10, step 323/574 completed (loss: 1.2430273294448853, acc: 0.7142857313156128)
[2024-11-29 03:35:24,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:24,474][root][INFO] - Training Epoch: 7/10, step 324/574 completed (loss: 0.590765118598938, acc: 0.7948718070983887)
[2024-11-29 03:35:24,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:24,753][root][INFO] - Training Epoch: 7/10, step 325/574 completed (loss: 1.8221571445465088, acc: 0.4878048896789551)
[2024-11-29 03:35:24,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:25,029][root][INFO] - Training Epoch: 7/10, step 326/574 completed (loss: 0.7671198844909668, acc: 0.7894737124443054)
[2024-11-29 03:35:25,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:25,345][root][INFO] - Training Epoch: 7/10, step 327/574 completed (loss: 0.39678749442100525, acc: 0.8947368264198303)
[2024-11-29 03:35:25,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:25,636][root][INFO] - Training Epoch: 7/10, step 328/574 completed (loss: 0.024947140365839005, acc: 1.0)
[2024-11-29 03:35:25,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:25,980][root][INFO] - Training Epoch: 7/10, step 329/574 completed (loss: 0.02715306542813778, acc: 1.0)
[2024-11-29 03:35:26,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:26,337][root][INFO] - Training Epoch: 7/10, step 330/574 completed (loss: 0.027913562953472137, acc: 1.0)
[2024-11-29 03:35:26,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:26,623][root][INFO] - Training Epoch: 7/10, step 331/574 completed (loss: 0.19304616749286652, acc: 0.9677419066429138)
[2024-11-29 03:35:26,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:27,011][root][INFO] - Training Epoch: 7/10, step 332/574 completed (loss: 0.11533434689044952, acc: 0.9649122953414917)
[2024-11-29 03:35:27,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:27,284][root][INFO] - Training Epoch: 7/10, step 333/574 completed (loss: 0.1362162083387375, acc: 0.96875)
[2024-11-29 03:35:27,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:27,609][root][INFO] - Training Epoch: 7/10, step 334/574 completed (loss: 0.11121369153261185, acc: 0.9666666388511658)
[2024-11-29 03:35:27,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:27,909][root][INFO] - Training Epoch: 7/10, step 335/574 completed (loss: 0.019564922899007797, acc: 1.0)
[2024-11-29 03:35:28,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:28,245][root][INFO] - Training Epoch: 7/10, step 336/574 completed (loss: 0.6920621991157532, acc: 0.8399999737739563)
[2024-11-29 03:35:28,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:28,596][root][INFO] - Training Epoch: 7/10, step 337/574 completed (loss: 0.9249936938285828, acc: 0.7126436829566956)
[2024-11-29 03:35:28,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:28,943][root][INFO] - Training Epoch: 7/10, step 338/574 completed (loss: 1.0869828462600708, acc: 0.6808510422706604)
[2024-11-29 03:35:29,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:29,251][root][INFO] - Training Epoch: 7/10, step 339/574 completed (loss: 0.9195166826248169, acc: 0.7469879388809204)
[2024-11-29 03:35:29,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:29,566][root][INFO] - Training Epoch: 7/10, step 340/574 completed (loss: 0.017178906127810478, acc: 1.0)
[2024-11-29 03:35:29,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:29,810][root][INFO] - Training Epoch: 7/10, step 341/574 completed (loss: 0.28143081068992615, acc: 0.9230769276618958)
[2024-11-29 03:35:30,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:30,134][root][INFO] - Training Epoch: 7/10, step 342/574 completed (loss: 0.21949660778045654, acc: 0.9277108311653137)
[2024-11-29 03:35:30,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:30,476][root][INFO] - Training Epoch: 7/10, step 343/574 completed (loss: 0.866700291633606, acc: 0.8113207817077637)
[2024-11-29 03:35:30,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:30,804][root][INFO] - Training Epoch: 7/10, step 344/574 completed (loss: 0.05387989431619644, acc: 0.9873417615890503)
[2024-11-29 03:35:31,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:31,133][root][INFO] - Training Epoch: 7/10, step 345/574 completed (loss: 0.09197796881198883, acc: 0.9607843160629272)
[2024-11-29 03:35:31,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:31,377][root][INFO] - Training Epoch: 7/10, step 346/574 completed (loss: 0.2885783910751343, acc: 0.9253731369972229)
[2024-11-29 03:35:31,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:31,668][root][INFO] - Training Epoch: 7/10, step 347/574 completed (loss: 0.13257665932178497, acc: 0.949999988079071)
[2024-11-29 03:35:31,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:31,966][root][INFO] - Training Epoch: 7/10, step 348/574 completed (loss: 0.2893662750720978, acc: 0.8799999952316284)
[2024-11-29 03:35:32,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:32,405][root][INFO] - Training Epoch: 7/10, step 349/574 completed (loss: 0.6974886655807495, acc: 0.8333333134651184)
[2024-11-29 03:35:32,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:32,669][root][INFO] - Training Epoch: 7/10, step 350/574 completed (loss: 0.41422727704048157, acc: 0.8837209343910217)
[2024-11-29 03:35:32,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:32,957][root][INFO] - Training Epoch: 7/10, step 351/574 completed (loss: 0.26931434869766235, acc: 0.9230769276618958)
[2024-11-29 03:35:33,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:33,373][root][INFO] - Training Epoch: 7/10, step 352/574 completed (loss: 0.33491891622543335, acc: 0.9111111164093018)
[2024-11-29 03:35:33,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:33,633][root][INFO] - Training Epoch: 7/10, step 353/574 completed (loss: 0.05023865029215813, acc: 1.0)
[2024-11-29 03:35:33,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:33,882][root][INFO] - Training Epoch: 7/10, step 354/574 completed (loss: 0.18068650364875793, acc: 0.9615384340286255)
[2024-11-29 03:35:34,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:34,201][root][INFO] - Training Epoch: 7/10, step 355/574 completed (loss: 0.5461983680725098, acc: 0.8241758346557617)
[2024-11-29 03:35:34,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:34,852][root][INFO] - Training Epoch: 7/10, step 356/574 completed (loss: 0.46443650126457214, acc: 0.852173924446106)
[2024-11-29 03:35:35,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:35,167][root][INFO] - Training Epoch: 7/10, step 357/574 completed (loss: 0.2510208189487457, acc: 0.9239130616188049)
[2024-11-29 03:35:35,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:35,459][root][INFO] - Training Epoch: 7/10, step 358/574 completed (loss: 0.3453657925128937, acc: 0.8571428656578064)
[2024-11-29 03:35:35,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:35,752][root][INFO] - Training Epoch: 7/10, step 359/574 completed (loss: 0.018938841298222542, acc: 1.0)
[2024-11-29 03:35:35,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:36,078][root][INFO] - Training Epoch: 7/10, step 360/574 completed (loss: 0.03162521496415138, acc: 1.0)
[2024-11-29 03:35:36,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:36,388][root][INFO] - Training Epoch: 7/10, step 361/574 completed (loss: 0.2674369513988495, acc: 0.9024389982223511)
[2024-11-29 03:35:36,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:36,721][root][INFO] - Training Epoch: 7/10, step 362/574 completed (loss: 0.3881235420703888, acc: 0.9111111164093018)
[2024-11-29 03:35:36,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:37,036][root][INFO] - Training Epoch: 7/10, step 363/574 completed (loss: 0.10292942821979523, acc: 0.9736841917037964)
[2024-11-29 03:35:37,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:37,360][root][INFO] - Training Epoch: 7/10, step 364/574 completed (loss: 0.026832042261958122, acc: 1.0)
[2024-11-29 03:35:37,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:37,654][root][INFO] - Training Epoch: 7/10, step 365/574 completed (loss: 0.2678970396518707, acc: 0.8787878751754761)
[2024-11-29 03:35:37,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:37,914][root][INFO] - Training Epoch: 7/10, step 366/574 completed (loss: 0.004347526002675295, acc: 1.0)
[2024-11-29 03:35:38,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:38,173][root][INFO] - Training Epoch: 7/10, step 367/574 completed (loss: 0.03057669848203659, acc: 1.0)
[2024-11-29 03:35:38,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:38,435][root][INFO] - Training Epoch: 7/10, step 368/574 completed (loss: 0.03231503441929817, acc: 1.0)
[2024-11-29 03:35:38,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:38,714][root][INFO] - Training Epoch: 7/10, step 369/574 completed (loss: 0.2400449961423874, acc: 0.9375)
[2024-11-29 03:35:39,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:39,537][root][INFO] - Training Epoch: 7/10, step 370/574 completed (loss: 0.5967561602592468, acc: 0.842424213886261)
[2024-11-29 03:35:40,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:40,753][root][INFO] - Training Epoch: 7/10, step 371/574 completed (loss: 0.2760463058948517, acc: 0.9245283007621765)
[2024-11-29 03:35:40,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:41,090][root][INFO] - Training Epoch: 7/10, step 372/574 completed (loss: 0.1686951071023941, acc: 0.9666666388511658)
[2024-11-29 03:35:41,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:41,400][root][INFO] - Training Epoch: 7/10, step 373/574 completed (loss: 0.07533202320337296, acc: 0.9821428656578064)
[2024-11-29 03:35:41,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:41,720][root][INFO] - Training Epoch: 7/10, step 374/574 completed (loss: 0.03408381715416908, acc: 1.0)
[2024-11-29 03:35:41,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:42,067][root][INFO] - Training Epoch: 7/10, step 375/574 completed (loss: 0.04987311735749245, acc: 1.0)
[2024-11-29 03:35:42,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:42,427][root][INFO] - Training Epoch: 7/10, step 376/574 completed (loss: 0.009636367671191692, acc: 1.0)
[2024-11-29 03:35:42,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:42,760][root][INFO] - Training Epoch: 7/10, step 377/574 completed (loss: 0.21421484649181366, acc: 0.9375)
[2024-11-29 03:35:42,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:43,106][root][INFO] - Training Epoch: 7/10, step 378/574 completed (loss: 0.03244458884000778, acc: 1.0)
[2024-11-29 03:35:43,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:43,893][root][INFO] - Training Epoch: 7/10, step 379/574 completed (loss: 0.3489963710308075, acc: 0.910179615020752)
[2024-11-29 03:35:44,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:44,357][root][INFO] - Training Epoch: 7/10, step 380/574 completed (loss: 0.28599560260772705, acc: 0.9248120188713074)
[2024-11-29 03:35:45,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:45,953][root][INFO] - Training Epoch: 7/10, step 381/574 completed (loss: 0.5291374921798706, acc: 0.855614960193634)
[2024-11-29 03:35:46,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:46,716][root][INFO] - Training Epoch: 7/10, step 382/574 completed (loss: 0.23952315747737885, acc: 0.9369369149208069)
[2024-11-29 03:35:46,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:46,991][root][INFO] - Training Epoch: 7/10, step 383/574 completed (loss: 0.12358535081148148, acc: 0.9642857313156128)
[2024-11-29 03:35:47,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:47,287][root][INFO] - Training Epoch: 7/10, step 384/574 completed (loss: 0.011365200392901897, acc: 1.0)
[2024-11-29 03:35:47,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:47,579][root][INFO] - Training Epoch: 7/10, step 385/574 completed (loss: 0.20923705399036407, acc: 0.96875)
[2024-11-29 03:35:47,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:47,835][root][INFO] - Training Epoch: 7/10, step 386/574 completed (loss: 0.16617363691329956, acc: 0.9444444179534912)
[2024-11-29 03:35:47,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:48,096][root][INFO] - Training Epoch: 7/10, step 387/574 completed (loss: 0.030695077031850815, acc: 1.0)
[2024-11-29 03:35:48,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:48,393][root][INFO] - Training Epoch: 7/10, step 388/574 completed (loss: 0.02622048184275627, acc: 1.0)
[2024-11-29 03:35:48,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:48,722][root][INFO] - Training Epoch: 7/10, step 389/574 completed (loss: 0.040135834366083145, acc: 1.0)
[2024-11-29 03:35:48,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:49,055][root][INFO] - Training Epoch: 7/10, step 390/574 completed (loss: 0.24243229627609253, acc: 0.9047619104385376)
[2024-11-29 03:35:49,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:49,415][root][INFO] - Training Epoch: 7/10, step 391/574 completed (loss: 0.5080980658531189, acc: 0.8888888955116272)
[2024-11-29 03:35:49,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:49,759][root][INFO] - Training Epoch: 7/10, step 392/574 completed (loss: 0.5662292242050171, acc: 0.8252426981925964)
[2024-11-29 03:35:50,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:50,435][root][INFO] - Training Epoch: 7/10, step 393/574 completed (loss: 0.9273495674133301, acc: 0.7867646813392639)
[2024-11-29 03:35:50,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:50,822][root][INFO] - Training Epoch: 7/10, step 394/574 completed (loss: 0.6324576735496521, acc: 0.7933333516120911)
[2024-11-29 03:35:51,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:51,255][root][INFO] - Training Epoch: 7/10, step 395/574 completed (loss: 0.5040940642356873, acc: 0.8680555820465088)
[2024-11-29 03:35:51,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:51,525][root][INFO] - Training Epoch: 7/10, step 396/574 completed (loss: 0.337140291929245, acc: 0.9534883499145508)
[2024-11-29 03:35:51,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:51,803][root][INFO] - Training Epoch: 7/10, step 397/574 completed (loss: 0.034976739436388016, acc: 1.0)
[2024-11-29 03:35:52,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:52,132][root][INFO] - Training Epoch: 7/10, step 398/574 completed (loss: 0.25135043263435364, acc: 0.930232584476471)
[2024-11-29 03:35:52,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:52,394][root][INFO] - Training Epoch: 7/10, step 399/574 completed (loss: 0.07741949707269669, acc: 0.9599999785423279)
[2024-11-29 03:35:52,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:53,104][root][INFO] - Training Epoch: 7/10, step 400/574 completed (loss: 0.2190006673336029, acc: 0.9558823704719543)
[2024-11-29 03:35:53,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:53,390][root][INFO] - Training Epoch: 7/10, step 401/574 completed (loss: 0.3883879482746124, acc: 0.9200000166893005)
[2024-11-29 03:35:53,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:53,649][root][INFO] - Training Epoch: 7/10, step 402/574 completed (loss: 0.2323777675628662, acc: 0.939393937587738)
[2024-11-29 03:35:53,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:53,906][root][INFO] - Training Epoch: 7/10, step 403/574 completed (loss: 0.10638025403022766, acc: 0.9696969985961914)
[2024-11-29 03:35:54,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:54,210][root][INFO] - Training Epoch: 7/10, step 404/574 completed (loss: 0.19944047927856445, acc: 0.9677419066429138)
[2024-11-29 03:35:54,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:54,492][root][INFO] - Training Epoch: 7/10, step 405/574 completed (loss: 0.07178157567977905, acc: 0.9629629850387573)
[2024-11-29 03:35:54,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:54,744][root][INFO] - Training Epoch: 7/10, step 406/574 completed (loss: 0.03406940773129463, acc: 1.0)
[2024-11-29 03:35:54,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:55,009][root][INFO] - Training Epoch: 7/10, step 407/574 completed (loss: 0.022547241300344467, acc: 1.0)
[2024-11-29 03:35:55,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:55,294][root][INFO] - Training Epoch: 7/10, step 408/574 completed (loss: 0.01866491697728634, acc: 1.0)
[2024-11-29 03:35:55,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:55,639][root][INFO] - Training Epoch: 7/10, step 409/574 completed (loss: 0.046091027557849884, acc: 0.9615384340286255)
[2024-11-29 03:35:55,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:55,978][root][INFO] - Training Epoch: 7/10, step 410/574 completed (loss: 0.1078188493847847, acc: 0.9655172228813171)
[2024-11-29 03:35:56,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:56,310][root][INFO] - Training Epoch: 7/10, step 411/574 completed (loss: 0.047528114169836044, acc: 1.0)
[2024-11-29 03:35:56,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:56,605][root][INFO] - Training Epoch: 7/10, step 412/574 completed (loss: 0.049203552305698395, acc: 0.9666666388511658)
[2024-11-29 03:35:56,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:56,913][root][INFO] - Training Epoch: 7/10, step 413/574 completed (loss: 0.063078373670578, acc: 0.9696969985961914)
[2024-11-29 03:35:57,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:57,223][root][INFO] - Training Epoch: 7/10, step 414/574 completed (loss: 0.031812433153390884, acc: 1.0)
[2024-11-29 03:35:57,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:57,520][root][INFO] - Training Epoch: 7/10, step 415/574 completed (loss: 0.18917502462863922, acc: 0.9411764740943909)
[2024-11-29 03:35:57,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:57,839][root][INFO] - Training Epoch: 7/10, step 416/574 completed (loss: 0.04766372963786125, acc: 1.0)
[2024-11-29 03:35:58,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:59,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:59,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:35:59,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:00,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:00,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:01,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:01,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:02,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:02,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:02,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:03,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:03,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:04,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:04,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:05,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:05,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:06,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:06,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:06,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:07,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:07,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:08,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:08,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:08,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:09,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:09,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:10,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:10,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:11,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:11,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:11,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:12,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:12,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:13,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:13,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:14,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:14,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:15,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:15,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:15,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:16,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:16,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:17,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:17,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:18,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:18,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:19,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:19,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:19,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:20,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:20,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:21,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:21,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:22,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:22,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:22,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:23,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:23,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:24,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:24,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:25,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:26,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:26,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:26,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:27,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:27,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:28,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:28,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:29,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:29,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:29,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:30,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:30,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:31,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:31,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:32,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:32,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:33,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:33,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:34,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:34,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:35,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:35,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:35,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:36,517][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.0349, device='cuda:0') eval_epoch_loss=tensor(1.1102, device='cuda:0') eval_epoch_acc=tensor(0.7421, device='cuda:0')
[2024-11-29 03:36:36,520][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:36:36,520][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:36:36,833][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_7_step_417_loss_1.1101661920547485/model.pt
[2024-11-29 03:36:37,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:37,191][root][INFO] - Training Epoch: 7/10, step 417/574 completed (loss: 0.069306880235672, acc: 1.0)
[2024-11-29 03:36:37,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:37,474][root][INFO] - Training Epoch: 7/10, step 418/574 completed (loss: 0.3048783540725708, acc: 0.949999988079071)
[2024-11-29 03:36:37,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:37,728][root][INFO] - Training Epoch: 7/10, step 419/574 completed (loss: 0.1926095187664032, acc: 0.8999999761581421)
[2024-11-29 03:36:37,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:37,981][root][INFO] - Training Epoch: 7/10, step 420/574 completed (loss: 0.01725783571600914, acc: 1.0)
[2024-11-29 03:36:38,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:38,229][root][INFO] - Training Epoch: 7/10, step 421/574 completed (loss: 0.06777722388505936, acc: 1.0)
[2024-11-29 03:36:38,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:38,473][root][INFO] - Training Epoch: 7/10, step 422/574 completed (loss: 0.07432519644498825, acc: 0.96875)
[2024-11-29 03:36:38,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:38,740][root][INFO] - Training Epoch: 7/10, step 423/574 completed (loss: 0.1378297209739685, acc: 0.9722222089767456)
[2024-11-29 03:36:38,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:38,998][root][INFO] - Training Epoch: 7/10, step 424/574 completed (loss: 0.055377766489982605, acc: 0.9629629850387573)
[2024-11-29 03:36:39,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:39,300][root][INFO] - Training Epoch: 7/10, step 425/574 completed (loss: 0.027743123471736908, acc: 1.0)
[2024-11-29 03:36:39,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:39,548][root][INFO] - Training Epoch: 7/10, step 426/574 completed (loss: 0.03009987063705921, acc: 1.0)
[2024-11-29 03:36:39,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:39,805][root][INFO] - Training Epoch: 7/10, step 427/574 completed (loss: 0.05892786383628845, acc: 1.0)
[2024-11-29 03:36:39,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:40,041][root][INFO] - Training Epoch: 7/10, step 428/574 completed (loss: 0.027234897017478943, acc: 1.0)
[2024-11-29 03:36:40,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:40,283][root][INFO] - Training Epoch: 7/10, step 429/574 completed (loss: 0.017985409125685692, acc: 1.0)
[2024-11-29 03:36:40,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:40,531][root][INFO] - Training Epoch: 7/10, step 430/574 completed (loss: 0.007944855839014053, acc: 1.0)
[2024-11-29 03:36:40,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:40,788][root][INFO] - Training Epoch: 7/10, step 431/574 completed (loss: 0.008559011854231358, acc: 1.0)
[2024-11-29 03:36:40,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:41,030][root][INFO] - Training Epoch: 7/10, step 432/574 completed (loss: 0.017579348757863045, acc: 1.0)
[2024-11-29 03:36:41,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:41,381][root][INFO] - Training Epoch: 7/10, step 433/574 completed (loss: 0.043431952595710754, acc: 1.0)
[2024-11-29 03:36:41,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:41,620][root][INFO] - Training Epoch: 7/10, step 434/574 completed (loss: 0.005237982142716646, acc: 1.0)
[2024-11-29 03:36:41,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:41,869][root][INFO] - Training Epoch: 7/10, step 435/574 completed (loss: 0.03132911026477814, acc: 1.0)
[2024-11-29 03:36:42,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:42,124][root][INFO] - Training Epoch: 7/10, step 436/574 completed (loss: 0.2590673565864563, acc: 0.9722222089767456)
[2024-11-29 03:36:42,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:42,386][root][INFO] - Training Epoch: 7/10, step 437/574 completed (loss: 0.0634244754910469, acc: 0.9772727489471436)
[2024-11-29 03:36:42,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:42,636][root][INFO] - Training Epoch: 7/10, step 438/574 completed (loss: 0.008742691949009895, acc: 1.0)
[2024-11-29 03:36:42,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:42,879][root][INFO] - Training Epoch: 7/10, step 439/574 completed (loss: 0.04300312697887421, acc: 1.0)
[2024-11-29 03:36:43,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:43,455][root][INFO] - Training Epoch: 7/10, step 440/574 completed (loss: 0.14909717440605164, acc: 0.9696969985961914)
[2024-11-29 03:36:43,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:44,408][root][INFO] - Training Epoch: 7/10, step 441/574 completed (loss: 0.7325775027275085, acc: 0.7680000066757202)
[2024-11-29 03:36:44,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:44,870][root][INFO] - Training Epoch: 7/10, step 442/574 completed (loss: 0.6049530506134033, acc: 0.8145161271095276)
[2024-11-29 03:36:45,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:45,773][root][INFO] - Training Epoch: 7/10, step 443/574 completed (loss: 0.5451620221138, acc: 0.8457711338996887)
[2024-11-29 03:36:45,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:46,022][root][INFO] - Training Epoch: 7/10, step 444/574 completed (loss: 0.19633346796035767, acc: 0.9245283007621765)
[2024-11-29 03:36:46,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:46,518][root][INFO] - Training Epoch: 7/10, step 445/574 completed (loss: 0.03423381596803665, acc: 1.0)
[2024-11-29 03:36:46,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:46,752][root][INFO] - Training Epoch: 7/10, step 446/574 completed (loss: 0.13314883410930634, acc: 1.0)
[2024-11-29 03:36:46,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:47,042][root][INFO] - Training Epoch: 7/10, step 447/574 completed (loss: 0.0927526205778122, acc: 0.9615384340286255)
[2024-11-29 03:36:47,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:47,298][root][INFO] - Training Epoch: 7/10, step 448/574 completed (loss: 0.14335162937641144, acc: 0.9285714030265808)
[2024-11-29 03:36:47,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:47,560][root][INFO] - Training Epoch: 7/10, step 449/574 completed (loss: 0.02372131496667862, acc: 1.0)
[2024-11-29 03:36:47,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:47,836][root][INFO] - Training Epoch: 7/10, step 450/574 completed (loss: 0.17304082214832306, acc: 0.9444444179534912)
[2024-11-29 03:36:47,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:48,111][root][INFO] - Training Epoch: 7/10, step 451/574 completed (loss: 0.049487948417663574, acc: 0.989130437374115)
[2024-11-29 03:36:48,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:48,387][root][INFO] - Training Epoch: 7/10, step 452/574 completed (loss: 0.18058867752552032, acc: 0.9358974099159241)
[2024-11-29 03:36:48,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:48,642][root][INFO] - Training Epoch: 7/10, step 453/574 completed (loss: 0.3701920509338379, acc: 0.9078947305679321)
[2024-11-29 03:36:48,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:48,963][root][INFO] - Training Epoch: 7/10, step 454/574 completed (loss: 0.0839066132903099, acc: 1.0)
[2024-11-29 03:36:49,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:49,252][root][INFO] - Training Epoch: 7/10, step 455/574 completed (loss: 0.07899674028158188, acc: 0.9696969985961914)
[2024-11-29 03:36:49,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:49,513][root][INFO] - Training Epoch: 7/10, step 456/574 completed (loss: 0.4070774018764496, acc: 0.8969072103500366)
[2024-11-29 03:36:49,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:49,802][root][INFO] - Training Epoch: 7/10, step 457/574 completed (loss: 0.04648933187127113, acc: 1.0)
[2024-11-29 03:36:50,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:50,224][root][INFO] - Training Epoch: 7/10, step 458/574 completed (loss: 0.329485148191452, acc: 0.9011628031730652)
[2024-11-29 03:36:50,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:50,479][root][INFO] - Training Epoch: 7/10, step 459/574 completed (loss: 0.07960186153650284, acc: 0.9642857313156128)
[2024-11-29 03:36:50,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:50,773][root][INFO] - Training Epoch: 7/10, step 460/574 completed (loss: 0.1221635639667511, acc: 0.9629629850387573)
[2024-11-29 03:36:50,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:51,022][root][INFO] - Training Epoch: 7/10, step 461/574 completed (loss: 0.04121323302388191, acc: 1.0)
[2024-11-29 03:36:51,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:51,270][root][INFO] - Training Epoch: 7/10, step 462/574 completed (loss: 0.07922623306512833, acc: 1.0)
[2024-11-29 03:36:51,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:51,517][root][INFO] - Training Epoch: 7/10, step 463/574 completed (loss: 0.2723351716995239, acc: 0.9615384340286255)
[2024-11-29 03:36:51,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:51,770][root][INFO] - Training Epoch: 7/10, step 464/574 completed (loss: 0.14703500270843506, acc: 0.95652174949646)
[2024-11-29 03:36:51,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:52,040][root][INFO] - Training Epoch: 7/10, step 465/574 completed (loss: 0.12449481338262558, acc: 0.988095223903656)
[2024-11-29 03:36:52,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:52,289][root][INFO] - Training Epoch: 7/10, step 466/574 completed (loss: 0.7017576694488525, acc: 0.8192771077156067)
[2024-11-29 03:36:52,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:52,580][root][INFO] - Training Epoch: 7/10, step 467/574 completed (loss: 0.104133740067482, acc: 0.9729729890823364)
[2024-11-29 03:36:52,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:52,853][root][INFO] - Training Epoch: 7/10, step 468/574 completed (loss: 0.5318937301635742, acc: 0.844660222530365)
[2024-11-29 03:36:53,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:53,176][root][INFO] - Training Epoch: 7/10, step 469/574 completed (loss: 0.8010863065719604, acc: 0.8048780560493469)
[2024-11-29 03:36:53,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:53,439][root][INFO] - Training Epoch: 7/10, step 470/574 completed (loss: 0.0881236121058464, acc: 0.9583333134651184)
[2024-11-29 03:36:53,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:53,684][root][INFO] - Training Epoch: 7/10, step 471/574 completed (loss: 0.6204768419265747, acc: 0.8928571343421936)
[2024-11-29 03:36:53,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:54,158][root][INFO] - Training Epoch: 7/10, step 472/574 completed (loss: 0.3004401922225952, acc: 0.9313725233078003)
[2024-11-29 03:36:54,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:54,531][root][INFO] - Training Epoch: 7/10, step 473/574 completed (loss: 0.8490294218063354, acc: 0.7641921639442444)
[2024-11-29 03:36:54,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:54,806][root][INFO] - Training Epoch: 7/10, step 474/574 completed (loss: 0.3440490961074829, acc: 0.8333333134651184)
[2024-11-29 03:36:54,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:55,093][root][INFO] - Training Epoch: 7/10, step 475/574 completed (loss: 0.32486531138420105, acc: 0.8834356069564819)
[2024-11-29 03:36:55,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:55,360][root][INFO] - Training Epoch: 7/10, step 476/574 completed (loss: 0.3726959824562073, acc: 0.8848921060562134)
[2024-11-29 03:36:55,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:55,707][root][INFO] - Training Epoch: 7/10, step 477/574 completed (loss: 0.5433809161186218, acc: 0.8140703439712524)
[2024-11-29 03:36:55,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:55,967][root][INFO] - Training Epoch: 7/10, step 478/574 completed (loss: 0.30757156014442444, acc: 0.9166666865348816)
[2024-11-29 03:36:56,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:56,216][root][INFO] - Training Epoch: 7/10, step 479/574 completed (loss: 0.13865914940834045, acc: 0.9696969985961914)
[2024-11-29 03:36:56,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:56,454][root][INFO] - Training Epoch: 7/10, step 480/574 completed (loss: 0.4720204174518585, acc: 0.8518518805503845)
[2024-11-29 03:36:56,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:56,697][root][INFO] - Training Epoch: 7/10, step 481/574 completed (loss: 0.1523234099149704, acc: 0.949999988079071)
[2024-11-29 03:36:56,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:56,942][root][INFO] - Training Epoch: 7/10, step 482/574 completed (loss: 0.8535995483398438, acc: 0.75)
[2024-11-29 03:36:57,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:57,352][root][INFO] - Training Epoch: 7/10, step 483/574 completed (loss: 0.5107095837593079, acc: 0.8448275923728943)
[2024-11-29 03:36:57,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:57,602][root][INFO] - Training Epoch: 7/10, step 484/574 completed (loss: 0.047746285796165466, acc: 0.9677419066429138)
[2024-11-29 03:36:57,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:57,848][root][INFO] - Training Epoch: 7/10, step 485/574 completed (loss: 0.01253138855099678, acc: 1.0)
[2024-11-29 03:36:57,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:58,095][root][INFO] - Training Epoch: 7/10, step 486/574 completed (loss: 0.20733442902565002, acc: 0.9629629850387573)
[2024-11-29 03:36:58,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:58,321][root][INFO] - Training Epoch: 7/10, step 487/574 completed (loss: 0.5768067836761475, acc: 0.9047619104385376)
[2024-11-29 03:36:58,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:58,570][root][INFO] - Training Epoch: 7/10, step 488/574 completed (loss: 0.3319712281227112, acc: 0.8636363744735718)
[2024-11-29 03:36:58,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:58,916][root][INFO] - Training Epoch: 7/10, step 489/574 completed (loss: 0.6903571486473083, acc: 0.7846153974533081)
[2024-11-29 03:36:59,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:59,167][root][INFO] - Training Epoch: 7/10, step 490/574 completed (loss: 0.0665024071931839, acc: 1.0)
[2024-11-29 03:36:59,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:59,447][root][INFO] - Training Epoch: 7/10, step 491/574 completed (loss: 0.16034001111984253, acc: 0.9655172228813171)
[2024-11-29 03:36:59,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:36:59,708][root][INFO] - Training Epoch: 7/10, step 492/574 completed (loss: 0.1938958615064621, acc: 0.9019607901573181)
[2024-11-29 03:36:59,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:00,000][root][INFO] - Training Epoch: 7/10, step 493/574 completed (loss: 0.0456954725086689, acc: 1.0)
[2024-11-29 03:37:00,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:00,251][root][INFO] - Training Epoch: 7/10, step 494/574 completed (loss: 0.11966384202241898, acc: 1.0)
[2024-11-29 03:37:00,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:00,513][root][INFO] - Training Epoch: 7/10, step 495/574 completed (loss: 0.20378807187080383, acc: 0.8947368264198303)
[2024-11-29 03:37:00,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:00,834][root][INFO] - Training Epoch: 7/10, step 496/574 completed (loss: 0.5356089472770691, acc: 0.8571428656578064)
[2024-11-29 03:37:01,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:01,232][root][INFO] - Training Epoch: 7/10, step 497/574 completed (loss: 0.2322598099708557, acc: 0.9101123809814453)
[2024-11-29 03:37:01,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:01,538][root][INFO] - Training Epoch: 7/10, step 498/574 completed (loss: 0.4083430767059326, acc: 0.8651685118675232)
[2024-11-29 03:37:01,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:01,920][root][INFO] - Training Epoch: 7/10, step 499/574 completed (loss: 1.1193010807037354, acc: 0.673758864402771)
[2024-11-29 03:37:02,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:02,242][root][INFO] - Training Epoch: 7/10, step 500/574 completed (loss: 0.4603753387928009, acc: 0.8369565010070801)
[2024-11-29 03:37:02,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:02,481][root][INFO] - Training Epoch: 7/10, step 501/574 completed (loss: 0.07052776962518692, acc: 0.9599999785423279)
[2024-11-29 03:37:02,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:02,724][root][INFO] - Training Epoch: 7/10, step 502/574 completed (loss: 0.020125459879636765, acc: 1.0)
[2024-11-29 03:37:02,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:02,954][root][INFO] - Training Epoch: 7/10, step 503/574 completed (loss: 0.838097095489502, acc: 0.7777777910232544)
[2024-11-29 03:37:03,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:03,202][root][INFO] - Training Epoch: 7/10, step 504/574 completed (loss: 0.19205114245414734, acc: 0.9629629850387573)
[2024-11-29 03:37:03,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:03,457][root][INFO] - Training Epoch: 7/10, step 505/574 completed (loss: 0.6625595688819885, acc: 0.849056601524353)
[2024-11-29 03:37:03,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:03,729][root][INFO] - Training Epoch: 7/10, step 506/574 completed (loss: 1.3397469520568848, acc: 0.6551724076271057)
[2024-11-29 03:37:04,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:04,555][root][INFO] - Training Epoch: 7/10, step 507/574 completed (loss: 1.0166206359863281, acc: 0.7747747898101807)
[2024-11-29 03:37:04,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:05,093][root][INFO] - Training Epoch: 7/10, step 508/574 completed (loss: 0.7289789915084839, acc: 0.8450704216957092)
[2024-11-29 03:37:05,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:05,335][root][INFO] - Training Epoch: 7/10, step 509/574 completed (loss: 0.02909872494637966, acc: 1.0)
[2024-11-29 03:37:05,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:05,585][root][INFO] - Training Epoch: 7/10, step 510/574 completed (loss: 0.06104842945933342, acc: 1.0)
[2024-11-29 03:37:05,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:05,836][root][INFO] - Training Epoch: 7/10, step 511/574 completed (loss: 0.04992840811610222, acc: 1.0)
[2024-11-29 03:37:08,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:09,524][root][INFO] - Training Epoch: 7/10, step 512/574 completed (loss: 1.0064016580581665, acc: 0.75)
[2024-11-29 03:37:10,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:10,625][root][INFO] - Training Epoch: 7/10, step 513/574 completed (loss: 0.3575609624385834, acc: 0.920634925365448)
[2024-11-29 03:37:10,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:10,868][root][INFO] - Training Epoch: 7/10, step 514/574 completed (loss: 0.5084846019744873, acc: 0.8571428656578064)
[2024-11-29 03:37:11,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:11,126][root][INFO] - Training Epoch: 7/10, step 515/574 completed (loss: 0.08753437548875809, acc: 0.9833333492279053)
[2024-11-29 03:37:11,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:12,097][root][INFO] - Training Epoch: 7/10, step 516/574 completed (loss: 0.3962811529636383, acc: 0.8888888955116272)
[2024-11-29 03:37:12,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:12,351][root][INFO] - Training Epoch: 7/10, step 517/574 completed (loss: 0.13781042397022247, acc: 0.9615384340286255)
[2024-11-29 03:37:12,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:12,596][root][INFO] - Training Epoch: 7/10, step 518/574 completed (loss: 0.025504086166620255, acc: 1.0)
[2024-11-29 03:37:12,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:12,872][root][INFO] - Training Epoch: 7/10, step 519/574 completed (loss: 0.11089418083429337, acc: 0.949999988079071)
[2024-11-29 03:37:13,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:13,118][root][INFO] - Training Epoch: 7/10, step 520/574 completed (loss: 0.35973799228668213, acc: 0.8518518805503845)
[2024-11-29 03:37:13,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:14,520][root][INFO] - Training Epoch: 7/10, step 521/574 completed (loss: 0.807162344455719, acc: 0.7711864113807678)
[2024-11-29 03:37:14,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:14,881][root][INFO] - Training Epoch: 7/10, step 522/574 completed (loss: 0.29982495307922363, acc: 0.888059675693512)
[2024-11-29 03:37:15,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:15,267][root][INFO] - Training Epoch: 7/10, step 523/574 completed (loss: 0.301337331533432, acc: 0.9270073175430298)
[2024-11-29 03:37:15,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:16,008][root][INFO] - Training Epoch: 7/10, step 524/574 completed (loss: 0.6528346538543701, acc: 0.8199999928474426)
[2024-11-29 03:37:16,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:16,281][root][INFO] - Training Epoch: 7/10, step 525/574 completed (loss: 0.04890018329024315, acc: 1.0)
[2024-11-29 03:37:16,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:16,605][root][INFO] - Training Epoch: 7/10, step 526/574 completed (loss: 0.06118899583816528, acc: 1.0)
[2024-11-29 03:37:16,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:16,890][root][INFO] - Training Epoch: 7/10, step 527/574 completed (loss: 0.13543179631233215, acc: 0.9523809552192688)
[2024-11-29 03:37:17,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:17,214][root][INFO] - Training Epoch: 7/10, step 528/574 completed (loss: 1.1147085428237915, acc: 0.7377049326896667)
[2024-11-29 03:37:17,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:17,551][root][INFO] - Training Epoch: 7/10, step 529/574 completed (loss: 0.2755177915096283, acc: 0.9322034120559692)
[2024-11-29 03:37:17,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:17,816][root][INFO] - Training Epoch: 7/10, step 530/574 completed (loss: 1.2431416511535645, acc: 0.6744186282157898)
[2024-11-29 03:37:17,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:18,042][root][INFO] - Training Epoch: 7/10, step 531/574 completed (loss: 0.6108882427215576, acc: 0.7954545617103577)
[2024-11-29 03:37:18,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:18,298][root][INFO] - Training Epoch: 7/10, step 532/574 completed (loss: 0.7318902015686035, acc: 0.7735849022865295)
[2024-11-29 03:37:18,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:18,586][root][INFO] - Training Epoch: 7/10, step 533/574 completed (loss: 0.36110296845436096, acc: 0.8636363744735718)
[2024-11-29 03:37:18,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:18,954][root][INFO] - Training Epoch: 7/10, step 534/574 completed (loss: 0.42497920989990234, acc: 0.9200000166893005)
[2024-11-29 03:37:19,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:19,263][root][INFO] - Training Epoch: 7/10, step 535/574 completed (loss: 0.0551140233874321, acc: 1.0)
[2024-11-29 03:37:19,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:19,536][root][INFO] - Training Epoch: 7/10, step 536/574 completed (loss: 0.07720959931612015, acc: 1.0)
[2024-11-29 03:37:19,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:19,996][root][INFO] - Training Epoch: 7/10, step 537/574 completed (loss: 0.3933994770050049, acc: 0.8769230842590332)
[2024-11-29 03:37:20,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:20,317][root][INFO] - Training Epoch: 7/10, step 538/574 completed (loss: 0.3759719729423523, acc: 0.890625)
[2024-11-29 03:37:20,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:20,754][root][INFO] - Training Epoch: 7/10, step 539/574 completed (loss: 0.5355126261711121, acc: 0.84375)
[2024-11-29 03:37:20,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:21,073][root][INFO] - Training Epoch: 7/10, step 540/574 completed (loss: 0.7196677327156067, acc: 0.8181818127632141)
[2024-11-29 03:37:21,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:21,397][root][INFO] - Training Epoch: 7/10, step 541/574 completed (loss: 0.08765316754579544, acc: 1.0)
[2024-11-29 03:37:21,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:21,658][root][INFO] - Training Epoch: 7/10, step 542/574 completed (loss: 0.10240475088357925, acc: 0.9677419066429138)
[2024-11-29 03:37:21,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:21,944][root][INFO] - Training Epoch: 7/10, step 543/574 completed (loss: 0.014470329508185387, acc: 1.0)
[2024-11-29 03:37:22,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:22,221][root][INFO] - Training Epoch: 7/10, step 544/574 completed (loss: 0.1033569797873497, acc: 0.9666666388511658)
[2024-11-29 03:37:22,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:22,501][root][INFO] - Training Epoch: 7/10, step 545/574 completed (loss: 0.029561888426542282, acc: 1.0)
[2024-11-29 03:37:22,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:22,784][root][INFO] - Training Epoch: 7/10, step 546/574 completed (loss: 0.056631024926900864, acc: 1.0)
[2024-11-29 03:37:22,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:23,091][root][INFO] - Training Epoch: 7/10, step 547/574 completed (loss: 0.03683456778526306, acc: 1.0)
[2024-11-29 03:37:23,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:23,366][root][INFO] - Training Epoch: 7/10, step 548/574 completed (loss: 0.02732032537460327, acc: 1.0)
[2024-11-29 03:37:23,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:23,675][root][INFO] - Training Epoch: 7/10, step 549/574 completed (loss: 0.050415195524692535, acc: 1.0)
[2024-11-29 03:37:23,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:23,964][root][INFO] - Training Epoch: 7/10, step 550/574 completed (loss: 0.03627409785985947, acc: 1.0)
[2024-11-29 03:37:24,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:24,280][root][INFO] - Training Epoch: 7/10, step 551/574 completed (loss: 0.08052629977464676, acc: 0.949999988079071)
[2024-11-29 03:37:24,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:24,615][root][INFO] - Training Epoch: 7/10, step 552/574 completed (loss: 0.14998143911361694, acc: 0.9714285731315613)
[2024-11-29 03:37:24,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:24,978][root][INFO] - Training Epoch: 7/10, step 553/574 completed (loss: 0.3674130141735077, acc: 0.9197080135345459)
[2024-11-29 03:37:25,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:25,281][root][INFO] - Training Epoch: 7/10, step 554/574 completed (loss: 0.21820785105228424, acc: 0.9241379499435425)
[2024-11-29 03:37:25,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:25,576][root][INFO] - Training Epoch: 7/10, step 555/574 completed (loss: 0.4296810030937195, acc: 0.8642857074737549)
[2024-11-29 03:37:25,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:25,870][root][INFO] - Training Epoch: 7/10, step 556/574 completed (loss: 0.3264874517917633, acc: 0.9006622433662415)
[2024-11-29 03:37:26,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:26,216][root][INFO] - Training Epoch: 7/10, step 557/574 completed (loss: 0.12845948338508606, acc: 0.9658119678497314)
[2024-11-29 03:37:26,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:26,498][root][INFO] - Training Epoch: 7/10, step 558/574 completed (loss: 0.3000723123550415, acc: 0.9599999785423279)
[2024-11-29 03:37:26,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:26,754][root][INFO] - Training Epoch: 7/10, step 559/574 completed (loss: 0.028664281591773033, acc: 1.0)
[2024-11-29 03:37:27,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:28,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:28,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:29,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:29,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:29,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:30,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:30,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:31,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:31,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:32,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:32,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:33,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:34,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:34,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:35,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:35,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:35,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:36,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:36,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:37,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:37,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:38,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:38,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:38,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:39,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:39,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:40,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:40,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:41,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:41,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:42,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:42,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:43,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:43,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:43,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:44,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:44,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:45,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:45,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:46,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:46,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:46,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:47,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:47,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:48,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:48,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:49,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:49,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:50,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:50,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:51,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:51,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:51,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:52,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:52,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:53,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:53,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:54,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:54,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:55,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:55,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:56,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:56,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:57,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:57,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:58,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:58,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:59,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:37:59,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:00,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:00,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:01,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:01,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:02,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:02,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:02,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:03,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:03,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:04,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:04,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:04,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:05,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:05,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:06,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:06,837][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.2696, device='cuda:0') eval_epoch_loss=tensor(1.1847, device='cuda:0') eval_epoch_acc=tensor(0.7512, device='cuda:0')
[2024-11-29 03:38:06,838][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:38:06,838][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:38:07,159][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_7_step_560_loss_1.1846665143966675/model.pt
[2024-11-29 03:38:07,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:07,519][root][INFO] - Training Epoch: 7/10, step 560/574 completed (loss: 0.014751041308045387, acc: 1.0)
[2024-11-29 03:38:07,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:07,793][root][INFO] - Training Epoch: 7/10, step 561/574 completed (loss: 0.09283468127250671, acc: 0.9743589758872986)
[2024-11-29 03:38:07,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:08,129][root][INFO] - Training Epoch: 7/10, step 562/574 completed (loss: 0.37552279233932495, acc: 0.8666666746139526)
[2024-11-29 03:38:08,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:08,436][root][INFO] - Training Epoch: 7/10, step 563/574 completed (loss: 0.11312445253133774, acc: 0.9610389471054077)
[2024-11-29 03:38:08,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:08,724][root][INFO] - Training Epoch: 7/10, step 564/574 completed (loss: 0.17215527594089508, acc: 0.9375)
[2024-11-29 03:38:08,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:09,033][root][INFO] - Training Epoch: 7/10, step 565/574 completed (loss: 0.13474884629249573, acc: 0.9655172228813171)
[2024-11-29 03:38:09,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:09,336][root][INFO] - Training Epoch: 7/10, step 566/574 completed (loss: 0.13106493651866913, acc: 0.9285714030265808)
[2024-11-29 03:38:09,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:09,641][root][INFO] - Training Epoch: 7/10, step 567/574 completed (loss: 0.09763438999652863, acc: 0.9736841917037964)
[2024-11-29 03:38:09,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:10,007][root][INFO] - Training Epoch: 7/10, step 568/574 completed (loss: 0.004519466310739517, acc: 1.0)
[2024-11-29 03:38:10,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:10,433][root][INFO] - Training Epoch: 7/10, step 569/574 completed (loss: 0.38559868931770325, acc: 0.9144384860992432)
[2024-11-29 03:38:10,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:10,702][root][INFO] - Training Epoch: 7/10, step 570/574 completed (loss: 0.12390022724866867, acc: 0.9677419066429138)
[2024-11-29 03:38:10,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:11,015][root][INFO] - Training Epoch: 7/10, step 571/574 completed (loss: 0.3382098078727722, acc: 0.9145299196243286)
[2024-11-29 03:38:11,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:11,285][root][INFO] - Training Epoch: 7/10, step 572/574 completed (loss: 0.9438575506210327, acc: 0.7653061151504517)
[2024-11-29 03:38:11,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:11,618][root][INFO] - Training Epoch: 7/10, step 573/574 completed (loss: 0.6082373857498169, acc: 0.8113207817077637)
[2024-11-29 03:38:12,213][slam_llm.utils.train_utils][INFO] - Epoch 7: train_perplexity=1.4578, train_epoch_loss=0.3769, epoch time 382.60191859677434s
[2024-11-29 03:38:12,214][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-11-29 03:38:12,214][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 17 GB
[2024-11-29 03:38:12,214][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-11-29 03:38:12,214][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 14
[2024-11-29 03:38:12,214][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-29 03:38:12,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:13,038][root][INFO] - Training Epoch: 8/10, step 0/574 completed (loss: 0.01198075246065855, acc: 1.0)
[2024-11-29 03:38:13,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:13,384][root][INFO] - Training Epoch: 8/10, step 1/574 completed (loss: 0.09074469655752182, acc: 0.9599999785423279)
[2024-11-29 03:38:13,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:13,753][root][INFO] - Training Epoch: 8/10, step 2/574 completed (loss: 0.17771793901920319, acc: 0.9189189076423645)
[2024-11-29 03:38:13,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:14,068][root][INFO] - Training Epoch: 8/10, step 3/574 completed (loss: 0.07629825174808502, acc: 0.9736841917037964)
[2024-11-29 03:38:14,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:14,335][root][INFO] - Training Epoch: 8/10, step 4/574 completed (loss: 0.2785249650478363, acc: 0.9189189076423645)
[2024-11-29 03:38:14,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:14,583][root][INFO] - Training Epoch: 8/10, step 5/574 completed (loss: 0.1191573292016983, acc: 0.9642857313156128)
[2024-11-29 03:38:14,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:14,859][root][INFO] - Training Epoch: 8/10, step 6/574 completed (loss: 0.2993425130844116, acc: 0.8775510191917419)
[2024-11-29 03:38:14,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:15,103][root][INFO] - Training Epoch: 8/10, step 7/574 completed (loss: 0.24355849623680115, acc: 0.8999999761581421)
[2024-11-29 03:38:15,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:15,351][root][INFO] - Training Epoch: 8/10, step 8/574 completed (loss: 0.036881789565086365, acc: 1.0)
[2024-11-29 03:38:15,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:15,593][root][INFO] - Training Epoch: 8/10, step 9/574 completed (loss: 0.07944135367870331, acc: 0.9615384340286255)
[2024-11-29 03:38:15,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:15,853][root][INFO] - Training Epoch: 8/10, step 10/574 completed (loss: 0.01878170482814312, acc: 1.0)
[2024-11-29 03:38:15,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:16,104][root][INFO] - Training Epoch: 8/10, step 11/574 completed (loss: 0.1503760814666748, acc: 0.9487179517745972)
[2024-11-29 03:38:16,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:16,378][root][INFO] - Training Epoch: 8/10, step 12/574 completed (loss: 0.029367342591285706, acc: 1.0)
[2024-11-29 03:38:16,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:16,638][root][INFO] - Training Epoch: 8/10, step 13/574 completed (loss: 0.07208019495010376, acc: 0.97826087474823)
[2024-11-29 03:38:16,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:16,899][root][INFO] - Training Epoch: 8/10, step 14/574 completed (loss: 0.02992119826376438, acc: 1.0)
[2024-11-29 03:38:17,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:17,156][root][INFO] - Training Epoch: 8/10, step 15/574 completed (loss: 0.053825296461582184, acc: 0.9795918464660645)
[2024-11-29 03:38:17,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:17,411][root][INFO] - Training Epoch: 8/10, step 16/574 completed (loss: 0.04685310646891594, acc: 1.0)
[2024-11-29 03:38:17,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:17,658][root][INFO] - Training Epoch: 8/10, step 17/574 completed (loss: 0.020291265100240707, acc: 1.0)
[2024-11-29 03:38:17,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:17,963][root][INFO] - Training Epoch: 8/10, step 18/574 completed (loss: 0.22420576214790344, acc: 0.8611111044883728)
[2024-11-29 03:38:18,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:18,223][root][INFO] - Training Epoch: 8/10, step 19/574 completed (loss: 0.08528950810432434, acc: 0.9473684430122375)
[2024-11-29 03:38:18,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:18,469][root][INFO] - Training Epoch: 8/10, step 20/574 completed (loss: 0.289419561624527, acc: 0.8846153616905212)
[2024-11-29 03:38:18,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:18,722][root][INFO] - Training Epoch: 8/10, step 21/574 completed (loss: 0.12077563256025314, acc: 1.0)
[2024-11-29 03:38:18,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:18,970][root][INFO] - Training Epoch: 8/10, step 22/574 completed (loss: 0.2964271605014801, acc: 0.9200000166893005)
[2024-11-29 03:38:19,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:19,225][root][INFO] - Training Epoch: 8/10, step 23/574 completed (loss: 0.1423826515674591, acc: 0.9523809552192688)
[2024-11-29 03:38:19,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:19,473][root][INFO] - Training Epoch: 8/10, step 24/574 completed (loss: 0.24122926592826843, acc: 0.9375)
[2024-11-29 03:38:19,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:19,722][root][INFO] - Training Epoch: 8/10, step 25/574 completed (loss: 0.18697498738765717, acc: 0.9245283007621765)
[2024-11-29 03:38:19,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:19,975][root][INFO] - Training Epoch: 8/10, step 26/574 completed (loss: 0.5463126301765442, acc: 0.835616409778595)
[2024-11-29 03:38:21,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:21,616][root][INFO] - Training Epoch: 8/10, step 27/574 completed (loss: 0.963580846786499, acc: 0.7233201861381531)
[2024-11-29 03:38:21,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:21,855][root][INFO] - Training Epoch: 8/10, step 28/574 completed (loss: 0.29475051164627075, acc: 0.8837209343910217)
[2024-11-29 03:38:21,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:22,104][root][INFO] - Training Epoch: 8/10, step 29/574 completed (loss: 0.506713330745697, acc: 0.8313252925872803)
[2024-11-29 03:38:22,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:22,365][root][INFO] - Training Epoch: 8/10, step 30/574 completed (loss: 0.5761519074440002, acc: 0.8395061492919922)
[2024-11-29 03:38:22,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:22,659][root][INFO] - Training Epoch: 8/10, step 31/574 completed (loss: 0.16348226368427277, acc: 0.9642857313156128)
[2024-11-29 03:38:22,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:22,921][root][INFO] - Training Epoch: 8/10, step 32/574 completed (loss: 0.18664483726024628, acc: 0.9629629850387573)
[2024-11-29 03:38:23,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:23,184][root][INFO] - Training Epoch: 8/10, step 33/574 completed (loss: 0.1960311084985733, acc: 0.9130434989929199)
[2024-11-29 03:38:23,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:23,459][root][INFO] - Training Epoch: 8/10, step 34/574 completed (loss: 0.3808360695838928, acc: 0.8991596698760986)
[2024-11-29 03:38:23,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:23,707][root][INFO] - Training Epoch: 8/10, step 35/574 completed (loss: 0.2738991975784302, acc: 0.8852459192276001)
[2024-11-29 03:38:23,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:23,985][root][INFO] - Training Epoch: 8/10, step 36/574 completed (loss: 0.2739866375923157, acc: 0.9365079402923584)
[2024-11-29 03:38:24,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:24,237][root][INFO] - Training Epoch: 8/10, step 37/574 completed (loss: 0.1910528987646103, acc: 0.9491525292396545)
[2024-11-29 03:38:24,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:24,540][root][INFO] - Training Epoch: 8/10, step 38/574 completed (loss: 0.20507167279720306, acc: 0.9425287246704102)
[2024-11-29 03:38:24,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:24,781][root][INFO] - Training Epoch: 8/10, step 39/574 completed (loss: 0.37461113929748535, acc: 0.9047619104385376)
[2024-11-29 03:38:24,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:25,039][root][INFO] - Training Epoch: 8/10, step 40/574 completed (loss: 0.1850530356168747, acc: 0.9230769276618958)
[2024-11-29 03:38:25,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:25,420][root][INFO] - Training Epoch: 8/10, step 41/574 completed (loss: 0.20705880224704742, acc: 0.9324324131011963)
[2024-11-29 03:38:25,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:25,749][root][INFO] - Training Epoch: 8/10, step 42/574 completed (loss: 0.4113897681236267, acc: 0.8615384697914124)
[2024-11-29 03:38:26,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:26,214][root][INFO] - Training Epoch: 8/10, step 43/574 completed (loss: 0.46691200137138367, acc: 0.868686854839325)
[2024-11-29 03:38:26,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:26,696][root][INFO] - Training Epoch: 8/10, step 44/574 completed (loss: 0.3652479946613312, acc: 0.876288652420044)
[2024-11-29 03:38:26,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:27,138][root][INFO] - Training Epoch: 8/10, step 45/574 completed (loss: 0.3965774476528168, acc: 0.875)
[2024-11-29 03:38:27,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:27,386][root][INFO] - Training Epoch: 8/10, step 46/574 completed (loss: 0.12768599390983582, acc: 0.9615384340286255)
[2024-11-29 03:38:27,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:27,647][root][INFO] - Training Epoch: 8/10, step 47/574 completed (loss: 0.012173422612249851, acc: 1.0)
[2024-11-29 03:38:27,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:27,907][root][INFO] - Training Epoch: 8/10, step 48/574 completed (loss: 0.05143055319786072, acc: 1.0)
[2024-11-29 03:38:28,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:28,150][root][INFO] - Training Epoch: 8/10, step 49/574 completed (loss: 0.03365803509950638, acc: 1.0)
[2024-11-29 03:38:28,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:28,427][root][INFO] - Training Epoch: 8/10, step 50/574 completed (loss: 0.44110384583473206, acc: 0.8771929740905762)
[2024-11-29 03:38:28,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:28,691][root][INFO] - Training Epoch: 8/10, step 51/574 completed (loss: 0.3186171352863312, acc: 0.920634925365448)
[2024-11-29 03:38:28,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:28,958][root][INFO] - Training Epoch: 8/10, step 52/574 completed (loss: 0.6717538833618164, acc: 0.8450704216957092)
[2024-11-29 03:38:29,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:29,494][root][INFO] - Training Epoch: 8/10, step 53/574 completed (loss: 1.19413161277771, acc: 0.6600000262260437)
[2024-11-29 03:38:29,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:29,755][root][INFO] - Training Epoch: 8/10, step 54/574 completed (loss: 0.45341265201568604, acc: 0.8918918967247009)
[2024-11-29 03:38:29,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:30,011][root][INFO] - Training Epoch: 8/10, step 55/574 completed (loss: 0.0332389734685421, acc: 1.0)
[2024-11-29 03:38:32,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:34,094][root][INFO] - Training Epoch: 8/10, step 56/574 completed (loss: 1.1481130123138428, acc: 0.6757678985595703)
[2024-11-29 03:38:35,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:35,837][root][INFO] - Training Epoch: 8/10, step 57/574 completed (loss: 1.5028284788131714, acc: 0.601307213306427)
[2024-11-29 03:38:36,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:36,668][root][INFO] - Training Epoch: 8/10, step 58/574 completed (loss: 0.527043342590332, acc: 0.8068181872367859)
[2024-11-29 03:38:37,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:37,436][root][INFO] - Training Epoch: 8/10, step 59/574 completed (loss: 0.28324419260025024, acc: 0.9264705777168274)
[2024-11-29 03:38:37,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:38,179][root][INFO] - Training Epoch: 8/10, step 60/574 completed (loss: 0.7030500769615173, acc: 0.8115941882133484)
[2024-11-29 03:38:38,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:38,660][root][INFO] - Training Epoch: 8/10, step 61/574 completed (loss: 0.5497746467590332, acc: 0.875)
[2024-11-29 03:38:38,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:38,922][root][INFO] - Training Epoch: 8/10, step 62/574 completed (loss: 0.047418370842933655, acc: 0.970588207244873)
[2024-11-29 03:38:39,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:39,223][root][INFO] - Training Epoch: 8/10, step 63/574 completed (loss: 0.05742385610938072, acc: 0.9722222089767456)
[2024-11-29 03:38:39,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:39,531][root][INFO] - Training Epoch: 8/10, step 64/574 completed (loss: 0.08354451507329941, acc: 0.96875)
[2024-11-29 03:38:39,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:39,768][root][INFO] - Training Epoch: 8/10, step 65/574 completed (loss: 0.10003805160522461, acc: 0.9655172228813171)
[2024-11-29 03:38:39,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:40,061][root][INFO] - Training Epoch: 8/10, step 66/574 completed (loss: 0.2674524486064911, acc: 0.9107142686843872)
[2024-11-29 03:38:40,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:40,352][root][INFO] - Training Epoch: 8/10, step 67/574 completed (loss: 0.10901367664337158, acc: 0.9666666388511658)
[2024-11-29 03:38:40,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:40,599][root][INFO] - Training Epoch: 8/10, step 68/574 completed (loss: 0.0052291033789515495, acc: 1.0)
[2024-11-29 03:38:40,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:40,861][root][INFO] - Training Epoch: 8/10, step 69/574 completed (loss: 0.1207420825958252, acc: 0.9722222089767456)
[2024-11-29 03:38:41,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:41,135][root][INFO] - Training Epoch: 8/10, step 70/574 completed (loss: 0.09980212152004242, acc: 0.9696969985961914)
[2024-11-29 03:38:41,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:41,454][root][INFO] - Training Epoch: 8/10, step 71/574 completed (loss: 0.9592909216880798, acc: 0.7279411554336548)
[2024-11-29 03:38:41,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:41,772][root][INFO] - Training Epoch: 8/10, step 72/574 completed (loss: 0.5125114321708679, acc: 0.8809523582458496)
[2024-11-29 03:38:41,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:42,122][root][INFO] - Training Epoch: 8/10, step 73/574 completed (loss: 1.3164423704147339, acc: 0.6358974575996399)
[2024-11-29 03:38:42,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:42,448][root][INFO] - Training Epoch: 8/10, step 74/574 completed (loss: 0.5886042714118958, acc: 0.8061224222183228)
[2024-11-29 03:38:42,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:42,740][root][INFO] - Training Epoch: 8/10, step 75/574 completed (loss: 0.8072696328163147, acc: 0.7835820913314819)
[2024-11-29 03:38:42,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:43,153][root][INFO] - Training Epoch: 8/10, step 76/574 completed (loss: 1.594918966293335, acc: 0.5766423344612122)
[2024-11-29 03:38:43,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:43,400][root][INFO] - Training Epoch: 8/10, step 77/574 completed (loss: 0.019675275310873985, acc: 1.0)
[2024-11-29 03:38:43,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:43,699][root][INFO] - Training Epoch: 8/10, step 78/574 completed (loss: 0.06872717291116714, acc: 0.9583333134651184)
[2024-11-29 03:38:43,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:43,976][root][INFO] - Training Epoch: 8/10, step 79/574 completed (loss: 0.01681302674114704, acc: 1.0)
[2024-11-29 03:38:44,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:44,262][root][INFO] - Training Epoch: 8/10, step 80/574 completed (loss: 0.10308332741260529, acc: 0.9615384340286255)
[2024-11-29 03:38:44,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:44,557][root][INFO] - Training Epoch: 8/10, step 81/574 completed (loss: 0.14153078198432922, acc: 0.942307710647583)
[2024-11-29 03:38:44,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:44,893][root][INFO] - Training Epoch: 8/10, step 82/574 completed (loss: 0.4503718614578247, acc: 0.8653846383094788)
[2024-11-29 03:38:45,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:45,216][root][INFO] - Training Epoch: 8/10, step 83/574 completed (loss: 0.06453343480825424, acc: 0.96875)
[2024-11-29 03:38:45,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:45,473][root][INFO] - Training Epoch: 8/10, step 84/574 completed (loss: 0.18988412618637085, acc: 0.9420289993286133)
[2024-11-29 03:38:45,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:45,774][root][INFO] - Training Epoch: 8/10, step 85/574 completed (loss: 0.2015664130449295, acc: 0.9599999785423279)
[2024-11-29 03:38:45,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:46,120][root][INFO] - Training Epoch: 8/10, step 86/574 completed (loss: 0.124167300760746, acc: 0.95652174949646)
[2024-11-29 03:38:46,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:46,695][root][INFO] - Training Epoch: 8/10, step 87/574 completed (loss: 0.4921557605266571, acc: 0.8600000143051147)
[2024-11-29 03:38:46,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:47,049][root][INFO] - Training Epoch: 8/10, step 88/574 completed (loss: 0.7555075287818909, acc: 0.8349514603614807)
[2024-11-29 03:38:48,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:48,669][root][INFO] - Training Epoch: 8/10, step 89/574 completed (loss: 0.8669580221176147, acc: 0.7572815418243408)
[2024-11-29 03:38:49,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:49,825][root][INFO] - Training Epoch: 8/10, step 90/574 completed (loss: 1.2036036252975464, acc: 0.6774193644523621)
[2024-11-29 03:38:50,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:50,963][root][INFO] - Training Epoch: 8/10, step 91/574 completed (loss: 0.965874195098877, acc: 0.75)
[2024-11-29 03:38:51,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:52,008][root][INFO] - Training Epoch: 8/10, step 92/574 completed (loss: 0.7736677527427673, acc: 0.7789473533630371)
[2024-11-29 03:38:52,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:53,465][root][INFO] - Training Epoch: 8/10, step 93/574 completed (loss: 0.858598530292511, acc: 0.7623762488365173)
[2024-11-29 03:38:53,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:53,796][root][INFO] - Training Epoch: 8/10, step 94/574 completed (loss: 0.4403255879878998, acc: 0.8387096524238586)
[2024-11-29 03:38:53,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:54,106][root][INFO] - Training Epoch: 8/10, step 95/574 completed (loss: 0.3635950982570648, acc: 0.8695651888847351)
[2024-11-29 03:38:54,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:54,424][root][INFO] - Training Epoch: 8/10, step 96/574 completed (loss: 0.7861499786376953, acc: 0.7647058963775635)
[2024-11-29 03:38:54,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:54,763][root][INFO] - Training Epoch: 8/10, step 97/574 completed (loss: 0.9600363373756409, acc: 0.682692289352417)
[2024-11-29 03:38:54,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:55,164][root][INFO] - Training Epoch: 8/10, step 98/574 completed (loss: 1.1321961879730225, acc: 0.6788321137428284)
[2024-11-29 03:38:55,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:55,432][root][INFO] - Training Epoch: 8/10, step 99/574 completed (loss: 0.6365653276443481, acc: 0.7910447716712952)
[2024-11-29 03:38:55,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:55,752][root][INFO] - Training Epoch: 8/10, step 100/574 completed (loss: 0.5865892767906189, acc: 0.8999999761581421)
[2024-11-29 03:38:55,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:56,010][root][INFO] - Training Epoch: 8/10, step 101/574 completed (loss: 0.020600752905011177, acc: 1.0)
[2024-11-29 03:38:56,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:56,343][root][INFO] - Training Epoch: 8/10, step 102/574 completed (loss: 0.01903354749083519, acc: 1.0)
[2024-11-29 03:38:56,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:56,644][root][INFO] - Training Epoch: 8/10, step 103/574 completed (loss: 0.017728043720126152, acc: 1.0)
[2024-11-29 03:38:56,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:56,929][root][INFO] - Training Epoch: 8/10, step 104/574 completed (loss: 0.2586866319179535, acc: 0.9482758641242981)
[2024-11-29 03:38:57,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:57,243][root][INFO] - Training Epoch: 8/10, step 105/574 completed (loss: 0.09746472537517548, acc: 0.9767441749572754)
[2024-11-29 03:38:57,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:57,519][root][INFO] - Training Epoch: 8/10, step 106/574 completed (loss: 0.15878748893737793, acc: 0.9599999785423279)
[2024-11-29 03:38:57,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:57,795][root][INFO] - Training Epoch: 8/10, step 107/574 completed (loss: 0.06161576136946678, acc: 0.9411764740943909)
[2024-11-29 03:38:58,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:58,152][root][INFO] - Training Epoch: 8/10, step 108/574 completed (loss: 0.018390266224741936, acc: 1.0)
[2024-11-29 03:38:58,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:58,497][root][INFO] - Training Epoch: 8/10, step 109/574 completed (loss: 0.13966725766658783, acc: 0.976190447807312)
[2024-11-29 03:38:58,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:58,799][root][INFO] - Training Epoch: 8/10, step 110/574 completed (loss: 0.27869755029678345, acc: 0.9230769276618958)
[2024-11-29 03:38:59,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:59,246][root][INFO] - Training Epoch: 8/10, step 111/574 completed (loss: 0.4388773441314697, acc: 0.859649121761322)
[2024-11-29 03:38:59,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:59,594][root][INFO] - Training Epoch: 8/10, step 112/574 completed (loss: 0.4952062666416168, acc: 0.8771929740905762)
[2024-11-29 03:38:59,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:38:59,913][root][INFO] - Training Epoch: 8/10, step 113/574 completed (loss: 0.16018706560134888, acc: 0.9743589758872986)
[2024-11-29 03:39:00,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:00,279][root][INFO] - Training Epoch: 8/10, step 114/574 completed (loss: 0.4858820140361786, acc: 0.8367347121238708)
[2024-11-29 03:39:00,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:00,532][root][INFO] - Training Epoch: 8/10, step 115/574 completed (loss: 0.039203837513923645, acc: 1.0)
[2024-11-29 03:39:00,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:00,874][root][INFO] - Training Epoch: 8/10, step 116/574 completed (loss: 0.2372550070285797, acc: 0.9523809552192688)
[2024-11-29 03:39:01,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:01,175][root][INFO] - Training Epoch: 8/10, step 117/574 completed (loss: 0.384444922208786, acc: 0.9024389982223511)
[2024-11-29 03:39:01,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:01,479][root][INFO] - Training Epoch: 8/10, step 118/574 completed (loss: 0.1467321366071701, acc: 0.9516128897666931)
[2024-11-29 03:39:02,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:02,632][root][INFO] - Training Epoch: 8/10, step 119/574 completed (loss: 0.9586162567138672, acc: 0.7490494251251221)
[2024-11-29 03:39:02,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:02,953][root][INFO] - Training Epoch: 8/10, step 120/574 completed (loss: 0.18299883604049683, acc: 0.9333333373069763)
[2024-11-29 03:39:03,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:03,402][root][INFO] - Training Epoch: 8/10, step 121/574 completed (loss: 0.24066084623336792, acc: 0.9230769276618958)
[2024-11-29 03:39:03,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:03,678][root][INFO] - Training Epoch: 8/10, step 122/574 completed (loss: 0.04640163481235504, acc: 1.0)
[2024-11-29 03:39:03,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:04,013][root][INFO] - Training Epoch: 8/10, step 123/574 completed (loss: 0.22556674480438232, acc: 0.9473684430122375)
[2024-11-29 03:39:04,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:04,372][root][INFO] - Training Epoch: 8/10, step 124/574 completed (loss: 1.02011239528656, acc: 0.699386477470398)
[2024-11-29 03:39:04,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:04,715][root][INFO] - Training Epoch: 8/10, step 125/574 completed (loss: 0.9041369557380676, acc: 0.7291666865348816)
[2024-11-29 03:39:04,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:04,984][root][INFO] - Training Epoch: 8/10, step 126/574 completed (loss: 0.8137330412864685, acc: 0.75)
[2024-11-29 03:39:05,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:05,326][root][INFO] - Training Epoch: 8/10, step 127/574 completed (loss: 1.1213020086288452, acc: 0.6845238208770752)
[2024-11-29 03:39:05,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:05,665][root][INFO] - Training Epoch: 8/10, step 128/574 completed (loss: 0.8042407035827637, acc: 0.7948718070983887)
[2024-11-29 03:39:06,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:07,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:07,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:08,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:08,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:08,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:09,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:09,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:10,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:10,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:11,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:11,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:12,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:12,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:12,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:13,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:13,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:14,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:14,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:14,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:15,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:15,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:16,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:16,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:16,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:17,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:17,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:18,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:18,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:19,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:19,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:19,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:20,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:20,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:21,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:21,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:21,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:22,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:22,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:23,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:23,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:24,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:24,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:24,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:25,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:25,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:26,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:26,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:26,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:27,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:27,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:28,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:28,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:29,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:29,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:29,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:30,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:30,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:30,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:31,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:31,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:32,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:33,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:33,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:33,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:34,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:34,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:35,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:35,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:36,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:36,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:37,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:37,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:38,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:38,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:39,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:39,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:39,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:40,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:40,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:41,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:41,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:42,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:42,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:43,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:43,864][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.8062, device='cuda:0') eval_epoch_loss=tensor(1.0318, device='cuda:0') eval_epoch_acc=tensor(0.7630, device='cuda:0')
[2024-11-29 03:39:43,865][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:39:43,866][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:39:44,170][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_8_step_129_loss_1.0318297147750854/model.pt
[2024-11-29 03:39:44,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:44,636][root][INFO] - Training Epoch: 8/10, step 129/574 completed (loss: 0.9876837730407715, acc: 0.720588207244873)
[2024-11-29 03:39:44,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:44,887][root][INFO] - Training Epoch: 8/10, step 130/574 completed (loss: 0.590621829032898, acc: 0.807692289352417)
[2024-11-29 03:39:45,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:45,134][root][INFO] - Training Epoch: 8/10, step 131/574 completed (loss: 0.423196405172348, acc: 0.8695651888847351)
[2024-11-29 03:39:45,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:45,381][root][INFO] - Training Epoch: 8/10, step 132/574 completed (loss: 0.4241775870323181, acc: 0.9375)
[2024-11-29 03:39:45,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:45,630][root][INFO] - Training Epoch: 8/10, step 133/574 completed (loss: 0.24408842623233795, acc: 0.8695651888847351)
[2024-11-29 03:39:45,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:45,877][root][INFO] - Training Epoch: 8/10, step 134/574 completed (loss: 0.14726078510284424, acc: 0.9714285731315613)
[2024-11-29 03:39:46,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:46,107][root][INFO] - Training Epoch: 8/10, step 135/574 completed (loss: 0.2132631242275238, acc: 0.9230769276618958)
[2024-11-29 03:39:46,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:46,351][root][INFO] - Training Epoch: 8/10, step 136/574 completed (loss: 0.2412622570991516, acc: 0.8809523582458496)
[2024-11-29 03:39:46,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:46,596][root][INFO] - Training Epoch: 8/10, step 137/574 completed (loss: 0.9487939476966858, acc: 0.7333333492279053)
[2024-11-29 03:39:46,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:46,839][root][INFO] - Training Epoch: 8/10, step 138/574 completed (loss: 0.0335630364716053, acc: 1.0)
[2024-11-29 03:39:46,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:47,088][root][INFO] - Training Epoch: 8/10, step 139/574 completed (loss: 0.03990237042307854, acc: 1.0)
[2024-11-29 03:39:47,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:47,333][root][INFO] - Training Epoch: 8/10, step 140/574 completed (loss: 0.20004330575466156, acc: 0.9230769276618958)
[2024-11-29 03:39:47,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:47,570][root][INFO] - Training Epoch: 8/10, step 141/574 completed (loss: 0.24298952519893646, acc: 0.8709677457809448)
[2024-11-29 03:39:47,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:47,838][root][INFO] - Training Epoch: 8/10, step 142/574 completed (loss: 0.37223559617996216, acc: 0.9459459185600281)
[2024-11-29 03:39:48,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:48,526][root][INFO] - Training Epoch: 8/10, step 143/574 completed (loss: 0.3952357769012451, acc: 0.8859649300575256)
[2024-11-29 03:39:48,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:48,845][root][INFO] - Training Epoch: 8/10, step 144/574 completed (loss: 0.5682310461997986, acc: 0.8134328126907349)
[2024-11-29 03:39:49,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:49,192][root][INFO] - Training Epoch: 8/10, step 145/574 completed (loss: 0.43375125527381897, acc: 0.8673469424247742)
[2024-11-29 03:39:49,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:49,747][root][INFO] - Training Epoch: 8/10, step 146/574 completed (loss: 0.7017036080360413, acc: 0.7659574747085571)
[2024-11-29 03:39:49,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:50,065][root][INFO] - Training Epoch: 8/10, step 147/574 completed (loss: 0.4125020503997803, acc: 0.8428571224212646)
[2024-11-29 03:39:50,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:50,383][root][INFO] - Training Epoch: 8/10, step 148/574 completed (loss: 0.15157057344913483, acc: 0.9285714030265808)
[2024-11-29 03:39:50,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:50,665][root][INFO] - Training Epoch: 8/10, step 149/574 completed (loss: 0.2755921483039856, acc: 0.95652174949646)
[2024-11-29 03:39:50,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:50,978][root][INFO] - Training Epoch: 8/10, step 150/574 completed (loss: 0.0924820825457573, acc: 0.9655172228813171)
[2024-11-29 03:39:51,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:51,263][root][INFO] - Training Epoch: 8/10, step 151/574 completed (loss: 0.6812410950660706, acc: 0.8478260636329651)
[2024-11-29 03:39:51,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:51,552][root][INFO] - Training Epoch: 8/10, step 152/574 completed (loss: 0.4813377857208252, acc: 0.8305084705352783)
[2024-11-29 03:39:51,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:51,867][root][INFO] - Training Epoch: 8/10, step 153/574 completed (loss: 0.4901522994041443, acc: 0.8771929740905762)
[2024-11-29 03:39:52,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:52,189][root][INFO] - Training Epoch: 8/10, step 154/574 completed (loss: 0.2506161630153656, acc: 0.9054054021835327)
[2024-11-29 03:39:52,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:52,495][root][INFO] - Training Epoch: 8/10, step 155/574 completed (loss: 0.08783627301454544, acc: 1.0)
[2024-11-29 03:39:52,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:52,835][root][INFO] - Training Epoch: 8/10, step 156/574 completed (loss: 0.561707615852356, acc: 0.8695651888847351)
[2024-11-29 03:39:53,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:53,123][root][INFO] - Training Epoch: 8/10, step 157/574 completed (loss: 2.60086989402771, acc: 0.42105263471603394)
[2024-11-29 03:39:54,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:55,627][root][INFO] - Training Epoch: 8/10, step 158/574 completed (loss: 1.272511601448059, acc: 0.662162184715271)
[2024-11-29 03:39:55,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:55,884][root][INFO] - Training Epoch: 8/10, step 159/574 completed (loss: 0.7139400243759155, acc: 0.8333333134651184)
[2024-11-29 03:39:56,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:56,351][root][INFO] - Training Epoch: 8/10, step 160/574 completed (loss: 1.37293541431427, acc: 0.6860465407371521)
[2024-11-29 03:39:56,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:57,171][root][INFO] - Training Epoch: 8/10, step 161/574 completed (loss: 1.580461025238037, acc: 0.6352941393852234)
[2024-11-29 03:39:57,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:57,928][root][INFO] - Training Epoch: 8/10, step 162/574 completed (loss: 1.3314752578735352, acc: 0.7078651785850525)
[2024-11-29 03:39:58,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:58,196][root][INFO] - Training Epoch: 8/10, step 163/574 completed (loss: 0.46119070053100586, acc: 0.8863636255264282)
[2024-11-29 03:39:58,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:58,437][root][INFO] - Training Epoch: 8/10, step 164/574 completed (loss: 0.3004884421825409, acc: 0.9523809552192688)
[2024-11-29 03:39:58,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:58,689][root][INFO] - Training Epoch: 8/10, step 165/574 completed (loss: 2.0700066089630127, acc: 0.5517241358757019)
[2024-11-29 03:39:58,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:58,959][root][INFO] - Training Epoch: 8/10, step 166/574 completed (loss: 0.09098393470048904, acc: 0.9591836929321289)
[2024-11-29 03:39:59,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:59,226][root][INFO] - Training Epoch: 8/10, step 167/574 completed (loss: 0.16365419328212738, acc: 0.9399999976158142)
[2024-11-29 03:39:59,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:39:59,676][root][INFO] - Training Epoch: 8/10, step 168/574 completed (loss: 0.2730114758014679, acc: 0.8888888955116272)
[2024-11-29 03:39:59,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:00,029][root][INFO] - Training Epoch: 8/10, step 169/574 completed (loss: 1.0825859308242798, acc: 0.8039215803146362)
[2024-11-29 03:40:00,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:01,576][root][INFO] - Training Epoch: 8/10, step 170/574 completed (loss: 1.0145739316940308, acc: 0.7465753555297852)
[2024-11-29 03:40:01,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:01,861][root][INFO] - Training Epoch: 8/10, step 171/574 completed (loss: 0.49654266238212585, acc: 0.9166666865348816)
[2024-11-29 03:40:02,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:02,129][root][INFO] - Training Epoch: 8/10, step 172/574 completed (loss: 0.6177707314491272, acc: 0.8148148059844971)
[2024-11-29 03:40:02,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:02,386][root][INFO] - Training Epoch: 8/10, step 173/574 completed (loss: 0.15159402787685394, acc: 0.9642857313156128)
[2024-11-29 03:40:02,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:03,106][root][INFO] - Training Epoch: 8/10, step 174/574 completed (loss: 1.2753655910491943, acc: 0.6725663542747498)
[2024-11-29 03:40:03,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:03,459][root][INFO] - Training Epoch: 8/10, step 175/574 completed (loss: 0.5784547924995422, acc: 0.8405796885490417)
[2024-11-29 03:40:03,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:03,782][root][INFO] - Training Epoch: 8/10, step 176/574 completed (loss: 0.3049963414669037, acc: 0.8977272510528564)
[2024-11-29 03:40:04,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:05,130][root][INFO] - Training Epoch: 8/10, step 177/574 completed (loss: 0.9395084977149963, acc: 0.7480915784835815)
[2024-11-29 03:40:05,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:06,073][root][INFO] - Training Epoch: 8/10, step 178/574 completed (loss: 0.7683869004249573, acc: 0.770370364189148)
[2024-11-29 03:40:06,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:06,324][root][INFO] - Training Epoch: 8/10, step 179/574 completed (loss: 0.24638475477695465, acc: 0.9016393423080444)
[2024-11-29 03:40:06,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:06,617][root][INFO] - Training Epoch: 8/10, step 180/574 completed (loss: 0.017442502081394196, acc: 1.0)
[2024-11-29 03:40:06,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:06,894][root][INFO] - Training Epoch: 8/10, step 181/574 completed (loss: 0.04124295711517334, acc: 0.9599999785423279)
[2024-11-29 03:40:07,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:07,152][root][INFO] - Training Epoch: 8/10, step 182/574 completed (loss: 0.2427140325307846, acc: 0.9285714030265808)
[2024-11-29 03:40:07,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:07,444][root][INFO] - Training Epoch: 8/10, step 183/574 completed (loss: 0.10812010616064072, acc: 0.9878048896789551)
[2024-11-29 03:40:07,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:07,775][root][INFO] - Training Epoch: 8/10, step 184/574 completed (loss: 0.6263339519500732, acc: 0.8398791551589966)
[2024-11-29 03:40:07,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:08,120][root][INFO] - Training Epoch: 8/10, step 185/574 completed (loss: 0.6963908076286316, acc: 0.8155619502067566)
[2024-11-29 03:40:08,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:08,724][root][INFO] - Training Epoch: 8/10, step 186/574 completed (loss: 0.6404934525489807, acc: 0.8031250238418579)
[2024-11-29 03:40:09,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:09,361][root][INFO] - Training Epoch: 8/10, step 187/574 completed (loss: 0.9774225950241089, acc: 0.7429643273353577)
[2024-11-29 03:40:09,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:09,807][root][INFO] - Training Epoch: 8/10, step 188/574 completed (loss: 0.6141356229782104, acc: 0.7971529960632324)
[2024-11-29 03:40:09,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:10,088][root][INFO] - Training Epoch: 8/10, step 189/574 completed (loss: 0.17783424258232117, acc: 0.9599999785423279)
[2024-11-29 03:40:10,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:10,841][root][INFO] - Training Epoch: 8/10, step 190/574 completed (loss: 0.5117413997650146, acc: 0.7790697813034058)
[2024-11-29 03:40:11,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:12,011][root][INFO] - Training Epoch: 8/10, step 191/574 completed (loss: 0.9417725205421448, acc: 0.7460317611694336)
[2024-11-29 03:40:12,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:13,388][root][INFO] - Training Epoch: 8/10, step 192/574 completed (loss: 0.953649640083313, acc: 0.7424242496490479)
[2024-11-29 03:40:14,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:14,469][root][INFO] - Training Epoch: 8/10, step 193/574 completed (loss: 0.3853471577167511, acc: 0.8823529481887817)
[2024-11-29 03:40:15,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:16,110][root][INFO] - Training Epoch: 8/10, step 194/574 completed (loss: 1.096728801727295, acc: 0.6975308656692505)
[2024-11-29 03:40:16,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:17,546][root][INFO] - Training Epoch: 8/10, step 195/574 completed (loss: 0.18601210415363312, acc: 0.9516128897666931)
[2024-11-29 03:40:17,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:17,833][root][INFO] - Training Epoch: 8/10, step 196/574 completed (loss: 0.07241423428058624, acc: 0.9642857313156128)
[2024-11-29 03:40:18,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:18,137][root][INFO] - Training Epoch: 8/10, step 197/574 completed (loss: 0.3528990149497986, acc: 0.925000011920929)
[2024-11-29 03:40:18,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:18,455][root][INFO] - Training Epoch: 8/10, step 198/574 completed (loss: 0.1965663880109787, acc: 0.970588207244873)
[2024-11-29 03:40:18,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:18,780][root][INFO] - Training Epoch: 8/10, step 199/574 completed (loss: 0.9860737919807434, acc: 0.779411792755127)
[2024-11-29 03:40:18,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:19,111][root][INFO] - Training Epoch: 8/10, step 200/574 completed (loss: 0.6028997302055359, acc: 0.805084764957428)
[2024-11-29 03:40:19,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:19,412][root][INFO] - Training Epoch: 8/10, step 201/574 completed (loss: 0.5821509957313538, acc: 0.8059701323509216)
[2024-11-29 03:40:19,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:19,738][root][INFO] - Training Epoch: 8/10, step 202/574 completed (loss: 0.5462624430656433, acc: 0.844660222530365)
[2024-11-29 03:40:19,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:20,078][root][INFO] - Training Epoch: 8/10, step 203/574 completed (loss: 0.34277769923210144, acc: 0.9523809552192688)
[2024-11-29 03:40:20,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:20,410][root][INFO] - Training Epoch: 8/10, step 204/574 completed (loss: 0.08944431692361832, acc: 0.9890109896659851)
[2024-11-29 03:40:20,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:20,734][root][INFO] - Training Epoch: 8/10, step 205/574 completed (loss: 0.28504759073257446, acc: 0.9282511472702026)
[2024-11-29 03:40:20,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:21,175][root][INFO] - Training Epoch: 8/10, step 206/574 completed (loss: 0.4791249632835388, acc: 0.8622047305107117)
[2024-11-29 03:40:21,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:21,516][root][INFO] - Training Epoch: 8/10, step 207/574 completed (loss: 0.22871775925159454, acc: 0.9353448152542114)
[2024-11-29 03:40:21,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:21,890][root][INFO] - Training Epoch: 8/10, step 208/574 completed (loss: 0.40374070405960083, acc: 0.8985507488250732)
[2024-11-29 03:40:22,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:22,267][root][INFO] - Training Epoch: 8/10, step 209/574 completed (loss: 0.3445725739002228, acc: 0.8793774247169495)
[2024-11-29 03:40:22,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:22,550][root][INFO] - Training Epoch: 8/10, step 210/574 completed (loss: 0.2406151443719864, acc: 0.9239130616188049)
[2024-11-29 03:40:22,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:22,819][root][INFO] - Training Epoch: 8/10, step 211/574 completed (loss: 0.014000631868839264, acc: 1.0)
[2024-11-29 03:40:23,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:23,144][root][INFO] - Training Epoch: 8/10, step 212/574 completed (loss: 0.09378600120544434, acc: 0.9285714030265808)
[2024-11-29 03:40:23,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:23,475][root][INFO] - Training Epoch: 8/10, step 213/574 completed (loss: 0.36291348934173584, acc: 0.8936170339584351)
[2024-11-29 03:40:24,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:24,429][root][INFO] - Training Epoch: 8/10, step 214/574 completed (loss: 0.18515928089618683, acc: 0.9615384340286255)
[2024-11-29 03:40:24,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:24,806][root][INFO] - Training Epoch: 8/10, step 215/574 completed (loss: 0.12836013734340668, acc: 0.9594594836235046)
[2024-11-29 03:40:25,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:25,151][root][INFO] - Training Epoch: 8/10, step 216/574 completed (loss: 0.052902355790138245, acc: 0.9883720874786377)
[2024-11-29 03:40:25,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:25,866][root][INFO] - Training Epoch: 8/10, step 217/574 completed (loss: 0.12573523819446564, acc: 0.954954981803894)
[2024-11-29 03:40:26,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:26,316][root][INFO] - Training Epoch: 8/10, step 218/574 completed (loss: 0.11272021383047104, acc: 0.9666666388511658)
[2024-11-29 03:40:26,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:26,574][root][INFO] - Training Epoch: 8/10, step 219/574 completed (loss: 0.04685541242361069, acc: 1.0)
[2024-11-29 03:40:26,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:26,890][root][INFO] - Training Epoch: 8/10, step 220/574 completed (loss: 0.028221582993865013, acc: 1.0)
[2024-11-29 03:40:27,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:27,184][root][INFO] - Training Epoch: 8/10, step 221/574 completed (loss: 0.008800026960670948, acc: 1.0)
[2024-11-29 03:40:27,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:27,510][root][INFO] - Training Epoch: 8/10, step 222/574 completed (loss: 0.32032310962677, acc: 0.8846153616905212)
[2024-11-29 03:40:28,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:28,592][root][INFO] - Training Epoch: 8/10, step 223/574 completed (loss: 0.37894946336746216, acc: 0.8913043737411499)
[2024-11-29 03:40:28,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:29,317][root][INFO] - Training Epoch: 8/10, step 224/574 completed (loss: 0.46504566073417664, acc: 0.8863636255264282)
[2024-11-29 03:40:29,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:29,856][root][INFO] - Training Epoch: 8/10, step 225/574 completed (loss: 0.5299967527389526, acc: 0.8829787373542786)
[2024-11-29 03:40:30,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:30,202][root][INFO] - Training Epoch: 8/10, step 226/574 completed (loss: 0.2645810544490814, acc: 0.9622641801834106)
[2024-11-29 03:40:30,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:30,531][root][INFO] - Training Epoch: 8/10, step 227/574 completed (loss: 0.11810283362865448, acc: 0.9666666388511658)
[2024-11-29 03:40:30,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:30,847][root][INFO] - Training Epoch: 8/10, step 228/574 completed (loss: 0.6819039583206177, acc: 0.8604651093482971)
[2024-11-29 03:40:31,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:31,139][root][INFO] - Training Epoch: 8/10, step 229/574 completed (loss: 1.1682655811309814, acc: 0.699999988079071)
[2024-11-29 03:40:31,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:31,510][root][INFO] - Training Epoch: 8/10, step 230/574 completed (loss: 2.1900429725646973, acc: 0.5052631497383118)
[2024-11-29 03:40:31,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:31,815][root][INFO] - Training Epoch: 8/10, step 231/574 completed (loss: 1.700105905532837, acc: 0.6111111044883728)
[2024-11-29 03:40:32,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:32,322][root][INFO] - Training Epoch: 8/10, step 232/574 completed (loss: 1.7852067947387695, acc: 0.5666666626930237)
[2024-11-29 03:40:32,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:32,949][root][INFO] - Training Epoch: 8/10, step 233/574 completed (loss: 2.136636257171631, acc: 0.47706422209739685)
[2024-11-29 03:40:33,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:33,549][root][INFO] - Training Epoch: 8/10, step 234/574 completed (loss: 1.6356635093688965, acc: 0.5846154093742371)
[2024-11-29 03:40:33,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:33,849][root][INFO] - Training Epoch: 8/10, step 235/574 completed (loss: 0.02625236101448536, acc: 1.0)
[2024-11-29 03:40:34,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:34,142][root][INFO] - Training Epoch: 8/10, step 236/574 completed (loss: 0.07537583261728287, acc: 1.0)
[2024-11-29 03:40:34,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:34,440][root][INFO] - Training Epoch: 8/10, step 237/574 completed (loss: 0.13039882481098175, acc: 1.0)
[2024-11-29 03:40:34,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:34,742][root][INFO] - Training Epoch: 8/10, step 238/574 completed (loss: 0.31045079231262207, acc: 0.9259259104728699)
[2024-11-29 03:40:34,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:35,027][root][INFO] - Training Epoch: 8/10, step 239/574 completed (loss: 0.2787610590457916, acc: 0.9142857193946838)
[2024-11-29 03:40:35,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:35,376][root][INFO] - Training Epoch: 8/10, step 240/574 completed (loss: 0.49983108043670654, acc: 0.8636363744735718)
[2024-11-29 03:40:35,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:35,664][root][INFO] - Training Epoch: 8/10, step 241/574 completed (loss: 0.10784242302179337, acc: 0.9772727489471436)
[2024-11-29 03:40:36,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:36,468][root][INFO] - Training Epoch: 8/10, step 242/574 completed (loss: 0.6686128377914429, acc: 0.8064516186714172)
[2024-11-29 03:40:36,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:37,186][root][INFO] - Training Epoch: 8/10, step 243/574 completed (loss: 0.4419153928756714, acc: 0.8636363744735718)
[2024-11-29 03:40:37,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:37,437][root][INFO] - Training Epoch: 8/10, step 244/574 completed (loss: 0.010177720338106155, acc: 1.0)
[2024-11-29 03:40:37,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:37,705][root][INFO] - Training Epoch: 8/10, step 245/574 completed (loss: 0.4244736135005951, acc: 0.8846153616905212)
[2024-11-29 03:40:37,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:38,004][root][INFO] - Training Epoch: 8/10, step 246/574 completed (loss: 0.08984079211950302, acc: 0.9677419066429138)
[2024-11-29 03:40:38,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:38,288][root][INFO] - Training Epoch: 8/10, step 247/574 completed (loss: 0.08533723652362823, acc: 1.0)
[2024-11-29 03:40:38,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:38,657][root][INFO] - Training Epoch: 8/10, step 248/574 completed (loss: 0.16483590006828308, acc: 0.9729729890823364)
[2024-11-29 03:40:38,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:38,921][root][INFO] - Training Epoch: 8/10, step 249/574 completed (loss: 0.08120149374008179, acc: 1.0)
[2024-11-29 03:40:39,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:39,225][root][INFO] - Training Epoch: 8/10, step 250/574 completed (loss: 0.019486043602228165, acc: 1.0)
[2024-11-29 03:40:39,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:39,549][root][INFO] - Training Epoch: 8/10, step 251/574 completed (loss: 0.1685134619474411, acc: 0.9558823704719543)
[2024-11-29 03:40:39,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:39,871][root][INFO] - Training Epoch: 8/10, step 252/574 completed (loss: 0.08342412859201431, acc: 0.9512194991111755)
[2024-11-29 03:40:40,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:40,159][root][INFO] - Training Epoch: 8/10, step 253/574 completed (loss: 0.06448718160390854, acc: 0.9599999785423279)
[2024-11-29 03:40:40,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:40,474][root][INFO] - Training Epoch: 8/10, step 254/574 completed (loss: 0.004619738552719355, acc: 1.0)
[2024-11-29 03:40:40,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:40,784][root][INFO] - Training Epoch: 8/10, step 255/574 completed (loss: 0.06857029348611832, acc: 0.9677419066429138)
[2024-11-29 03:40:40,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:41,118][root][INFO] - Training Epoch: 8/10, step 256/574 completed (loss: 0.2097844034433365, acc: 0.9473684430122375)
[2024-11-29 03:40:41,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:41,430][root][INFO] - Training Epoch: 8/10, step 257/574 completed (loss: 0.21644295752048492, acc: 0.8999999761581421)
[2024-11-29 03:40:41,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:41,727][root][INFO] - Training Epoch: 8/10, step 258/574 completed (loss: 0.1959962546825409, acc: 0.9473684430122375)
[2024-11-29 03:40:42,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:42,517][root][INFO] - Training Epoch: 8/10, step 259/574 completed (loss: 0.38063105940818787, acc: 0.8679245114326477)
[2024-11-29 03:40:42,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:43,305][root][INFO] - Training Epoch: 8/10, step 260/574 completed (loss: 0.30958035588264465, acc: 0.8999999761581421)
[2024-11-29 03:40:43,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:43,614][root][INFO] - Training Epoch: 8/10, step 261/574 completed (loss: 0.03546573221683502, acc: 1.0)
[2024-11-29 03:40:43,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:43,939][root][INFO] - Training Epoch: 8/10, step 262/574 completed (loss: 0.16496123373508453, acc: 0.9354838728904724)
[2024-11-29 03:40:44,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:44,300][root][INFO] - Training Epoch: 8/10, step 263/574 completed (loss: 0.7204726338386536, acc: 0.800000011920929)
[2024-11-29 03:40:44,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:44,641][root][INFO] - Training Epoch: 8/10, step 264/574 completed (loss: 0.3574248254299164, acc: 0.8541666865348816)
[2024-11-29 03:40:45,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:45,902][root][INFO] - Training Epoch: 8/10, step 265/574 completed (loss: 1.106753945350647, acc: 0.6959999799728394)
[2024-11-29 03:40:46,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:46,207][root][INFO] - Training Epoch: 8/10, step 266/574 completed (loss: 0.6734328269958496, acc: 0.7865168452262878)
[2024-11-29 03:40:46,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:46,560][root][INFO] - Training Epoch: 8/10, step 267/574 completed (loss: 0.6247056722640991, acc: 0.8108108043670654)
[2024-11-29 03:40:46,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:47,128][root][INFO] - Training Epoch: 8/10, step 268/574 completed (loss: 0.3154458999633789, acc: 0.8793103694915771)
[2024-11-29 03:40:47,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:47,466][root][INFO] - Training Epoch: 8/10, step 269/574 completed (loss: 0.2817871570587158, acc: 0.9545454382896423)
[2024-11-29 03:40:47,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:47,771][root][INFO] - Training Epoch: 8/10, step 270/574 completed (loss: 0.06613904982805252, acc: 0.9545454382896423)
[2024-11-29 03:40:47,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:48,073][root][INFO] - Training Epoch: 8/10, step 271/574 completed (loss: 0.1811724454164505, acc: 0.9375)
[2024-11-29 03:40:48,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:49,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:49,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:50,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:50,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:51,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:51,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:51,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:52,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:52,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:53,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:53,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:54,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:54,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:55,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:55,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:56,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:56,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:56,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:57,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:57,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:58,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:58,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:59,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:59,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:40:59,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:00,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:00,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:01,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:01,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:02,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:02,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:02,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:03,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:03,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:04,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:04,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:05,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:05,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:06,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:06,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:06,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:07,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:07,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:08,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:08,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:09,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:09,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:09,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:10,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:10,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:11,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:11,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:12,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:12,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:13,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:13,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:14,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:14,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:14,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:15,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:16,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:16,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:17,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:17,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:18,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:18,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:19,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:19,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:20,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:20,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:21,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:21,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:22,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:22,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:23,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:23,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:23,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:24,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:24,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:25,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:25,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:26,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:26,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:27,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:27,772][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.8044, device='cuda:0') eval_epoch_loss=tensor(1.0312, device='cuda:0') eval_epoch_acc=tensor(0.7691, device='cuda:0')
[2024-11-29 03:41:27,773][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:41:27,774][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:41:28,018][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_8_step_272_loss_1.0311802625656128/model.pt
[2024-11-29 03:41:28,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:28,304][root][INFO] - Training Epoch: 8/10, step 272/574 completed (loss: 0.08790038526058197, acc: 0.9666666388511658)
[2024-11-29 03:41:28,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:28,721][root][INFO] - Training Epoch: 8/10, step 273/574 completed (loss: 0.3422093987464905, acc: 0.8500000238418579)
[2024-11-29 03:41:28,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:28,987][root][INFO] - Training Epoch: 8/10, step 274/574 completed (loss: 0.03927527368068695, acc: 1.0)
[2024-11-29 03:41:29,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:29,264][root][INFO] - Training Epoch: 8/10, step 275/574 completed (loss: 0.04910045117139816, acc: 1.0)
[2024-11-29 03:41:29,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:29,570][root][INFO] - Training Epoch: 8/10, step 276/574 completed (loss: 0.10713992267847061, acc: 0.9655172228813171)
[2024-11-29 03:41:29,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:29,922][root][INFO] - Training Epoch: 8/10, step 277/574 completed (loss: 0.07163003832101822, acc: 0.9599999785423279)
[2024-11-29 03:41:30,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:30,248][root][INFO] - Training Epoch: 8/10, step 278/574 completed (loss: 0.35842055082321167, acc: 0.914893627166748)
[2024-11-29 03:41:30,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:30,574][root][INFO] - Training Epoch: 8/10, step 279/574 completed (loss: 0.12061066180467606, acc: 0.9583333134651184)
[2024-11-29 03:41:30,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:30,834][root][INFO] - Training Epoch: 8/10, step 280/574 completed (loss: 0.06179194152355194, acc: 0.9545454382896423)
[2024-11-29 03:41:31,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:31,331][root][INFO] - Training Epoch: 8/10, step 281/574 completed (loss: 0.41000062227249146, acc: 0.8554216623306274)
[2024-11-29 03:41:31,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:31,699][root][INFO] - Training Epoch: 8/10, step 282/574 completed (loss: 0.5207371115684509, acc: 0.8611111044883728)
[2024-11-29 03:41:31,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:31,954][root][INFO] - Training Epoch: 8/10, step 283/574 completed (loss: 0.23727215826511383, acc: 0.8947368264198303)
[2024-11-29 03:41:32,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:32,292][root][INFO] - Training Epoch: 8/10, step 284/574 completed (loss: 0.046336397528648376, acc: 1.0)
[2024-11-29 03:41:32,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:32,629][root][INFO] - Training Epoch: 8/10, step 285/574 completed (loss: 0.05322848632931709, acc: 0.9750000238418579)
[2024-11-29 03:41:32,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:32,966][root][INFO] - Training Epoch: 8/10, step 286/574 completed (loss: 0.4186137616634369, acc: 0.859375)
[2024-11-29 03:41:33,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:33,309][root][INFO] - Training Epoch: 8/10, step 287/574 completed (loss: 0.36240071058273315, acc: 0.9039999842643738)
[2024-11-29 03:41:33,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:33,579][root][INFO] - Training Epoch: 8/10, step 288/574 completed (loss: 0.15087012946605682, acc: 0.9560439586639404)
[2024-11-29 03:41:33,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:33,900][root][INFO] - Training Epoch: 8/10, step 289/574 completed (loss: 0.20416195690631866, acc: 0.9378882050514221)
[2024-11-29 03:41:34,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:34,274][root][INFO] - Training Epoch: 8/10, step 290/574 completed (loss: 0.46995264291763306, acc: 0.8608247637748718)
[2024-11-29 03:41:34,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:34,638][root][INFO] - Training Epoch: 8/10, step 291/574 completed (loss: 0.23546527326107025, acc: 0.9545454382896423)
[2024-11-29 03:41:34,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:34,935][root][INFO] - Training Epoch: 8/10, step 292/574 completed (loss: 0.18939384818077087, acc: 0.9523809552192688)
[2024-11-29 03:41:35,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:35,234][root][INFO] - Training Epoch: 8/10, step 293/574 completed (loss: 0.12344255298376083, acc: 0.982758641242981)
[2024-11-29 03:41:35,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:35,853][root][INFO] - Training Epoch: 8/10, step 294/574 completed (loss: 0.3849615752696991, acc: 0.9272727370262146)
[2024-11-29 03:41:36,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:36,576][root][INFO] - Training Epoch: 8/10, step 295/574 completed (loss: 0.7155475616455078, acc: 0.7938144207000732)
[2024-11-29 03:41:36,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:36,959][root][INFO] - Training Epoch: 8/10, step 296/574 completed (loss: 0.38679951429367065, acc: 0.931034505367279)
[2024-11-29 03:41:37,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:37,287][root][INFO] - Training Epoch: 8/10, step 297/574 completed (loss: 0.0383760966360569, acc: 1.0)
[2024-11-29 03:41:37,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:37,622][root][INFO] - Training Epoch: 8/10, step 298/574 completed (loss: 0.42240118980407715, acc: 0.8947368264198303)
[2024-11-29 03:41:37,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:37,888][root][INFO] - Training Epoch: 8/10, step 299/574 completed (loss: 0.198244109749794, acc: 0.9464285969734192)
[2024-11-29 03:41:38,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:38,151][root][INFO] - Training Epoch: 8/10, step 300/574 completed (loss: 0.02533949725329876, acc: 1.0)
[2024-11-29 03:41:38,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:38,428][root][INFO] - Training Epoch: 8/10, step 301/574 completed (loss: 0.12530218064785004, acc: 0.9433962106704712)
[2024-11-29 03:41:38,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:38,698][root][INFO] - Training Epoch: 8/10, step 302/574 completed (loss: 0.01877646893262863, acc: 1.0)
[2024-11-29 03:41:38,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:38,960][root][INFO] - Training Epoch: 8/10, step 303/574 completed (loss: 0.048644743859767914, acc: 1.0)
[2024-11-29 03:41:39,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:39,219][root][INFO] - Training Epoch: 8/10, step 304/574 completed (loss: 0.06483928114175797, acc: 0.96875)
[2024-11-29 03:41:39,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:39,528][root][INFO] - Training Epoch: 8/10, step 305/574 completed (loss: 0.4973578155040741, acc: 0.868852436542511)
[2024-11-29 03:41:39,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:39,879][root][INFO] - Training Epoch: 8/10, step 306/574 completed (loss: 0.057191189378499985, acc: 1.0)
[2024-11-29 03:41:40,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:40,170][root][INFO] - Training Epoch: 8/10, step 307/574 completed (loss: 0.028348857536911964, acc: 1.0)
[2024-11-29 03:41:40,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:40,459][root][INFO] - Training Epoch: 8/10, step 308/574 completed (loss: 0.1505182534456253, acc: 0.9710144996643066)
[2024-11-29 03:41:40,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:40,953][root][INFO] - Training Epoch: 8/10, step 309/574 completed (loss: 0.1245148554444313, acc: 0.9444444179534912)
[2024-11-29 03:41:41,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:41,243][root][INFO] - Training Epoch: 8/10, step 310/574 completed (loss: 0.15099658071994781, acc: 0.9759036302566528)
[2024-11-29 03:41:41,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:41,587][root][INFO] - Training Epoch: 8/10, step 311/574 completed (loss: 0.1611504852771759, acc: 0.9230769276618958)
[2024-11-29 03:41:41,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:41,960][root][INFO] - Training Epoch: 8/10, step 312/574 completed (loss: 0.17761094868183136, acc: 0.9387755393981934)
[2024-11-29 03:41:42,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:42,233][root][INFO] - Training Epoch: 8/10, step 313/574 completed (loss: 0.014128333888947964, acc: 1.0)
[2024-11-29 03:41:42,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:42,503][root][INFO] - Training Epoch: 8/10, step 314/574 completed (loss: 0.02521701157093048, acc: 1.0)
[2024-11-29 03:41:42,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:42,764][root][INFO] - Training Epoch: 8/10, step 315/574 completed (loss: 0.038560666143894196, acc: 1.0)
[2024-11-29 03:41:42,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:43,027][root][INFO] - Training Epoch: 8/10, step 316/574 completed (loss: 1.0214956998825073, acc: 0.7419354915618896)
[2024-11-29 03:41:43,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:43,337][root][INFO] - Training Epoch: 8/10, step 317/574 completed (loss: 0.08728615194559097, acc: 0.9850746393203735)
[2024-11-29 03:41:43,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:43,637][root][INFO] - Training Epoch: 8/10, step 318/574 completed (loss: 0.09064754098653793, acc: 0.9807692170143127)
[2024-11-29 03:41:43,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:43,888][root][INFO] - Training Epoch: 8/10, step 319/574 completed (loss: 0.15139664709568024, acc: 0.9333333373069763)
[2024-11-29 03:41:44,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:44,145][root][INFO] - Training Epoch: 8/10, step 320/574 completed (loss: 0.07142584025859833, acc: 0.9838709831237793)
[2024-11-29 03:41:44,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:44,402][root][INFO] - Training Epoch: 8/10, step 321/574 completed (loss: 0.006938878446817398, acc: 1.0)
[2024-11-29 03:41:44,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:44,666][root][INFO] - Training Epoch: 8/10, step 322/574 completed (loss: 0.5627033114433289, acc: 0.7777777910232544)
[2024-11-29 03:41:44,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:44,929][root][INFO] - Training Epoch: 8/10, step 323/574 completed (loss: 1.3544135093688965, acc: 0.7142857313156128)
[2024-11-29 03:41:45,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:45,188][root][INFO] - Training Epoch: 8/10, step 324/574 completed (loss: 0.7459077835083008, acc: 0.7692307829856873)
[2024-11-29 03:41:45,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:45,471][root][INFO] - Training Epoch: 8/10, step 325/574 completed (loss: 1.486970067024231, acc: 0.5121951103210449)
[2024-11-29 03:41:45,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:45,742][root][INFO] - Training Epoch: 8/10, step 326/574 completed (loss: 0.5363745093345642, acc: 0.8421052694320679)
[2024-11-29 03:41:45,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:46,004][root][INFO] - Training Epoch: 8/10, step 327/574 completed (loss: 0.2951659858226776, acc: 0.9473684430122375)
[2024-11-29 03:41:46,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:46,335][root][INFO] - Training Epoch: 8/10, step 328/574 completed (loss: 0.025686638429760933, acc: 1.0)
[2024-11-29 03:41:46,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:46,640][root][INFO] - Training Epoch: 8/10, step 329/574 completed (loss: 0.017015280202031136, acc: 1.0)
[2024-11-29 03:41:46,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:46,967][root][INFO] - Training Epoch: 8/10, step 330/574 completed (loss: 0.05491295084357262, acc: 0.96875)
[2024-11-29 03:41:47,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:47,249][root][INFO] - Training Epoch: 8/10, step 331/574 completed (loss: 0.127605140209198, acc: 0.9516128897666931)
[2024-11-29 03:41:47,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:47,654][root][INFO] - Training Epoch: 8/10, step 332/574 completed (loss: 0.07956235110759735, acc: 0.9824561476707458)
[2024-11-29 03:41:47,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:47,948][root][INFO] - Training Epoch: 8/10, step 333/574 completed (loss: 0.05039181932806969, acc: 1.0)
[2024-11-29 03:41:48,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:48,282][root][INFO] - Training Epoch: 8/10, step 334/574 completed (loss: 0.027371693402528763, acc: 1.0)
[2024-11-29 03:41:48,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:48,574][root][INFO] - Training Epoch: 8/10, step 335/574 completed (loss: 0.09478788822889328, acc: 0.8947368264198303)
[2024-11-29 03:41:48,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:48,902][root][INFO] - Training Epoch: 8/10, step 336/574 completed (loss: 0.6877274513244629, acc: 0.7599999904632568)
[2024-11-29 03:41:49,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:49,281][root][INFO] - Training Epoch: 8/10, step 337/574 completed (loss: 0.6832906603813171, acc: 0.8045976758003235)
[2024-11-29 03:41:49,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:49,633][root][INFO] - Training Epoch: 8/10, step 338/574 completed (loss: 0.7967227101325989, acc: 0.7659574747085571)
[2024-11-29 03:41:49,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:49,935][root][INFO] - Training Epoch: 8/10, step 339/574 completed (loss: 0.6756768822669983, acc: 0.8313252925872803)
[2024-11-29 03:41:50,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:50,195][root][INFO] - Training Epoch: 8/10, step 340/574 completed (loss: 0.29912933707237244, acc: 0.9130434989929199)
[2024-11-29 03:41:50,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:50,492][root][INFO] - Training Epoch: 8/10, step 341/574 completed (loss: 0.420929878950119, acc: 0.8974359035491943)
[2024-11-29 03:41:50,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:50,800][root][INFO] - Training Epoch: 8/10, step 342/574 completed (loss: 0.15202897787094116, acc: 0.9397590160369873)
[2024-11-29 03:41:50,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:51,094][root][INFO] - Training Epoch: 8/10, step 343/574 completed (loss: 0.8703582882881165, acc: 0.7735849022865295)
[2024-11-29 03:41:51,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:51,400][root][INFO] - Training Epoch: 8/10, step 344/574 completed (loss: 0.17465680837631226, acc: 0.9367088675498962)
[2024-11-29 03:41:51,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:51,673][root][INFO] - Training Epoch: 8/10, step 345/574 completed (loss: 0.27027955651283264, acc: 0.9411764740943909)
[2024-11-29 03:41:51,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:52,039][root][INFO] - Training Epoch: 8/10, step 346/574 completed (loss: 0.32197707891464233, acc: 0.9104477763175964)
[2024-11-29 03:41:52,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:52,361][root][INFO] - Training Epoch: 8/10, step 347/574 completed (loss: 0.005528810899704695, acc: 1.0)
[2024-11-29 03:41:52,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:52,720][root][INFO] - Training Epoch: 8/10, step 348/574 completed (loss: 0.23946858942508698, acc: 0.9599999785423279)
[2024-11-29 03:41:52,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:53,186][root][INFO] - Training Epoch: 8/10, step 349/574 completed (loss: 0.5018483996391296, acc: 0.8055555820465088)
[2024-11-29 03:41:53,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:53,487][root][INFO] - Training Epoch: 8/10, step 350/574 completed (loss: 0.5017204880714417, acc: 0.8372092843055725)
[2024-11-29 03:41:53,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:53,780][root][INFO] - Training Epoch: 8/10, step 351/574 completed (loss: 0.18645904958248138, acc: 0.9487179517745972)
[2024-11-29 03:41:53,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:54,184][root][INFO] - Training Epoch: 8/10, step 352/574 completed (loss: 0.42922693490982056, acc: 0.8222222328186035)
[2024-11-29 03:41:54,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:54,514][root][INFO] - Training Epoch: 8/10, step 353/574 completed (loss: 0.018084488809108734, acc: 1.0)
[2024-11-29 03:41:54,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:54,884][root][INFO] - Training Epoch: 8/10, step 354/574 completed (loss: 0.16725203394889832, acc: 0.9230769276618958)
[2024-11-29 03:41:55,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:55,231][root][INFO] - Training Epoch: 8/10, step 355/574 completed (loss: 0.4548424184322357, acc: 0.8791208863258362)
[2024-11-29 03:41:55,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:55,909][root][INFO] - Training Epoch: 8/10, step 356/574 completed (loss: 0.5730088353157043, acc: 0.8695651888847351)
[2024-11-29 03:41:56,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:56,232][root][INFO] - Training Epoch: 8/10, step 357/574 completed (loss: 0.1500403732061386, acc: 0.97826087474823)
[2024-11-29 03:41:56,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:56,553][root][INFO] - Training Epoch: 8/10, step 358/574 completed (loss: 0.2454458475112915, acc: 0.9387755393981934)
[2024-11-29 03:41:56,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:56,860][root][INFO] - Training Epoch: 8/10, step 359/574 completed (loss: 0.023245831951498985, acc: 1.0)
[2024-11-29 03:41:57,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:57,187][root][INFO] - Training Epoch: 8/10, step 360/574 completed (loss: 0.16368533670902252, acc: 0.9615384340286255)
[2024-11-29 03:41:57,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:57,462][root][INFO] - Training Epoch: 8/10, step 361/574 completed (loss: 0.2732529938220978, acc: 0.9756097793579102)
[2024-11-29 03:41:57,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:57,808][root][INFO] - Training Epoch: 8/10, step 362/574 completed (loss: 0.29064708948135376, acc: 0.8888888955116272)
[2024-11-29 03:41:57,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:58,092][root][INFO] - Training Epoch: 8/10, step 363/574 completed (loss: 0.09163433313369751, acc: 0.9868420958518982)
[2024-11-29 03:41:58,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:58,414][root][INFO] - Training Epoch: 8/10, step 364/574 completed (loss: 0.014212855137884617, acc: 1.0)
[2024-11-29 03:41:58,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:58,704][root][INFO] - Training Epoch: 8/10, step 365/574 completed (loss: 0.05988654866814613, acc: 0.9696969985961914)
[2024-11-29 03:41:58,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:58,961][root][INFO] - Training Epoch: 8/10, step 366/574 completed (loss: 0.006849698256701231, acc: 1.0)
[2024-11-29 03:41:59,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:59,299][root][INFO] - Training Epoch: 8/10, step 367/574 completed (loss: 0.08215183019638062, acc: 0.95652174949646)
[2024-11-29 03:41:59,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:59,636][root][INFO] - Training Epoch: 8/10, step 368/574 completed (loss: 0.02372693456709385, acc: 1.0)
[2024-11-29 03:41:59,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:41:59,969][root][INFO] - Training Epoch: 8/10, step 369/574 completed (loss: 0.4871829152107239, acc: 0.84375)
[2024-11-29 03:42:00,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:00,812][root][INFO] - Training Epoch: 8/10, step 370/574 completed (loss: 0.6512808799743652, acc: 0.8181818127632141)
[2024-11-29 03:42:01,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:02,034][root][INFO] - Training Epoch: 8/10, step 371/574 completed (loss: 0.3608972132205963, acc: 0.9056603908538818)
[2024-11-29 03:42:02,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:02,450][root][INFO] - Training Epoch: 8/10, step 372/574 completed (loss: 0.12057911604642868, acc: 0.9666666388511658)
[2024-11-29 03:42:02,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:02,759][root][INFO] - Training Epoch: 8/10, step 373/574 completed (loss: 0.12590016424655914, acc: 0.9642857313156128)
[2024-11-29 03:42:02,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:03,062][root][INFO] - Training Epoch: 8/10, step 374/574 completed (loss: 0.10821910947561264, acc: 0.9428571462631226)
[2024-11-29 03:42:03,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:03,326][root][INFO] - Training Epoch: 8/10, step 375/574 completed (loss: 0.24370259046554565, acc: 0.9599999785423279)
[2024-11-29 03:42:03,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:03,606][root][INFO] - Training Epoch: 8/10, step 376/574 completed (loss: 0.008180811069905758, acc: 1.0)
[2024-11-29 03:42:03,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:03,886][root][INFO] - Training Epoch: 8/10, step 377/574 completed (loss: 0.10788192600011826, acc: 0.9791666865348816)
[2024-11-29 03:42:04,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:04,191][root][INFO] - Training Epoch: 8/10, step 378/574 completed (loss: 0.2559063732624054, acc: 0.9578947424888611)
[2024-11-29 03:42:04,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:04,984][root][INFO] - Training Epoch: 8/10, step 379/574 completed (loss: 0.19478186964988708, acc: 0.946107804775238)
[2024-11-29 03:42:05,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:05,454][root][INFO] - Training Epoch: 8/10, step 380/574 completed (loss: 0.20283648371696472, acc: 0.932330846786499)
[2024-11-29 03:42:06,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:07,257][root][INFO] - Training Epoch: 8/10, step 381/574 completed (loss: 0.6160520911216736, acc: 0.8235294222831726)
[2024-11-29 03:42:07,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:08,021][root][INFO] - Training Epoch: 8/10, step 382/574 completed (loss: 0.1868838518857956, acc: 0.9639639854431152)
[2024-11-29 03:42:08,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:08,344][root][INFO] - Training Epoch: 8/10, step 383/574 completed (loss: 0.2716311812400818, acc: 0.9285714030265808)
[2024-11-29 03:42:08,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:08,628][root][INFO] - Training Epoch: 8/10, step 384/574 completed (loss: 0.16758444905281067, acc: 0.9642857313156128)
[2024-11-29 03:42:08,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:08,885][root][INFO] - Training Epoch: 8/10, step 385/574 completed (loss: 0.0637039914727211, acc: 1.0)
[2024-11-29 03:42:09,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:09,167][root][INFO] - Training Epoch: 8/10, step 386/574 completed (loss: 0.07293122261762619, acc: 0.9722222089767456)
[2024-11-29 03:42:09,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:09,506][root][INFO] - Training Epoch: 8/10, step 387/574 completed (loss: 0.011816042475402355, acc: 1.0)
[2024-11-29 03:42:09,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:09,806][root][INFO] - Training Epoch: 8/10, step 388/574 completed (loss: 0.01744394190609455, acc: 1.0)
[2024-11-29 03:42:09,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:10,072][root][INFO] - Training Epoch: 8/10, step 389/574 completed (loss: 0.027752075344324112, acc: 1.0)
[2024-11-29 03:42:10,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:10,396][root][INFO] - Training Epoch: 8/10, step 390/574 completed (loss: 0.46099966764450073, acc: 0.9047619104385376)
[2024-11-29 03:42:10,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:10,732][root][INFO] - Training Epoch: 8/10, step 391/574 completed (loss: 0.5140441060066223, acc: 0.8518518805503845)
[2024-11-29 03:42:10,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:11,068][root][INFO] - Training Epoch: 8/10, step 392/574 completed (loss: 0.6057937145233154, acc: 0.7669903039932251)
[2024-11-29 03:42:11,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:11,755][root][INFO] - Training Epoch: 8/10, step 393/574 completed (loss: 0.8720699548721313, acc: 0.779411792755127)
[2024-11-29 03:42:11,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:12,153][root][INFO] - Training Epoch: 8/10, step 394/574 completed (loss: 0.4881725013256073, acc: 0.8533333539962769)
[2024-11-29 03:42:12,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:12,592][root][INFO] - Training Epoch: 8/10, step 395/574 completed (loss: 0.4802309572696686, acc: 0.8472222089767456)
[2024-11-29 03:42:12,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:12,865][root][INFO] - Training Epoch: 8/10, step 396/574 completed (loss: 0.15029530227184296, acc: 0.9534883499145508)
[2024-11-29 03:42:13,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:13,179][root][INFO] - Training Epoch: 8/10, step 397/574 completed (loss: 0.016902094706892967, acc: 1.0)
[2024-11-29 03:42:13,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:13,518][root][INFO] - Training Epoch: 8/10, step 398/574 completed (loss: 0.35497209429740906, acc: 0.9069767594337463)
[2024-11-29 03:42:13,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:13,853][root][INFO] - Training Epoch: 8/10, step 399/574 completed (loss: 0.14349891245365143, acc: 0.9200000166893005)
[2024-11-29 03:42:14,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:14,572][root][INFO] - Training Epoch: 8/10, step 400/574 completed (loss: 0.2271280586719513, acc: 0.970588207244873)
[2024-11-29 03:42:14,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:14,913][root][INFO] - Training Epoch: 8/10, step 401/574 completed (loss: 0.19790594279766083, acc: 0.9466666579246521)
[2024-11-29 03:42:15,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:15,236][root][INFO] - Training Epoch: 8/10, step 402/574 completed (loss: 0.2301279455423355, acc: 0.939393937587738)
[2024-11-29 03:42:15,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:15,563][root][INFO] - Training Epoch: 8/10, step 403/574 completed (loss: 0.22708995640277863, acc: 0.939393937587738)
[2024-11-29 03:42:15,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:15,826][root][INFO] - Training Epoch: 8/10, step 404/574 completed (loss: 0.34658750891685486, acc: 0.8387096524238586)
[2024-11-29 03:42:16,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:16,132][root][INFO] - Training Epoch: 8/10, step 405/574 completed (loss: 0.0101469112560153, acc: 1.0)
[2024-11-29 03:42:16,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:16,430][root][INFO] - Training Epoch: 8/10, step 406/574 completed (loss: 0.035363055765628815, acc: 1.0)
[2024-11-29 03:42:16,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:16,739][root][INFO] - Training Epoch: 8/10, step 407/574 completed (loss: 0.04178043454885483, acc: 1.0)
[2024-11-29 03:42:16,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:17,030][root][INFO] - Training Epoch: 8/10, step 408/574 completed (loss: 0.06950728595256805, acc: 0.9629629850387573)
[2024-11-29 03:42:17,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:17,289][root][INFO] - Training Epoch: 8/10, step 409/574 completed (loss: 0.07475808262825012, acc: 1.0)
[2024-11-29 03:42:17,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:17,594][root][INFO] - Training Epoch: 8/10, step 410/574 completed (loss: 0.08583258092403412, acc: 0.982758641242981)
[2024-11-29 03:42:17,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:17,887][root][INFO] - Training Epoch: 8/10, step 411/574 completed (loss: 0.3304792046546936, acc: 0.9285714030265808)
[2024-11-29 03:42:18,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:18,204][root][INFO] - Training Epoch: 8/10, step 412/574 completed (loss: 0.013464645482599735, acc: 1.0)
[2024-11-29 03:42:18,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:18,490][root][INFO] - Training Epoch: 8/10, step 413/574 completed (loss: 0.11561279743909836, acc: 0.9696969985961914)
[2024-11-29 03:42:18,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:18,755][root][INFO] - Training Epoch: 8/10, step 414/574 completed (loss: 0.024582169950008392, acc: 1.0)
[2024-11-29 03:42:19,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:20,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:20,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:20,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:21,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:21,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:22,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:22,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:23,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:23,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:24,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:24,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:25,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:25,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:25,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:26,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:26,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:27,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:27,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:28,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:28,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:28,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:29,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:29,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:30,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:30,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:31,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:31,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:32,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:32,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:32,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:33,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:33,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:34,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:34,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:34,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:35,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:35,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:36,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:36,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:36,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:37,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:37,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:38,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:38,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:39,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:39,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:39,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:40,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:40,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:41,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:41,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:42,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:42,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:42,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:43,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:43,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:44,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:44,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:45,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:45,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:46,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:46,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:47,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:47,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:48,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:48,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:49,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:49,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:50,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:50,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:51,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:51,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:51,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:52,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:52,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:52,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:53,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:53,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:54,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:54,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:55,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:55,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:56,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:56,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:57,183][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.9778, device='cuda:0') eval_epoch_loss=tensor(1.0912, device='cuda:0') eval_epoch_acc=tensor(0.7432, device='cuda:0')
[2024-11-29 03:42:57,185][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:42:57,185][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:42:57,451][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_8_step_415_loss_1.091199517250061/model.pt
[2024-11-29 03:42:57,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:57,823][root][INFO] - Training Epoch: 8/10, step 415/574 completed (loss: 0.09521495550870895, acc: 0.9607843160629272)
[2024-11-29 03:42:58,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:58,133][root][INFO] - Training Epoch: 8/10, step 416/574 completed (loss: 0.030490301549434662, acc: 1.0)
[2024-11-29 03:42:58,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:58,399][root][INFO] - Training Epoch: 8/10, step 417/574 completed (loss: 0.07776789367198944, acc: 0.9444444179534912)
[2024-11-29 03:42:58,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:58,719][root][INFO] - Training Epoch: 8/10, step 418/574 completed (loss: 0.1503344625234604, acc: 0.9750000238418579)
[2024-11-29 03:42:58,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:59,023][root][INFO] - Training Epoch: 8/10, step 419/574 completed (loss: 0.14208975434303284, acc: 0.949999988079071)
[2024-11-29 03:42:59,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:59,297][root][INFO] - Training Epoch: 8/10, step 420/574 completed (loss: 0.013806192204356194, acc: 1.0)
[2024-11-29 03:42:59,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:59,557][root][INFO] - Training Epoch: 8/10, step 421/574 completed (loss: 0.10747437179088593, acc: 0.9666666388511658)
[2024-11-29 03:42:59,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:42:59,820][root][INFO] - Training Epoch: 8/10, step 422/574 completed (loss: 0.06423729658126831, acc: 1.0)
[2024-11-29 03:42:59,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:00,107][root][INFO] - Training Epoch: 8/10, step 423/574 completed (loss: 0.2965308129787445, acc: 0.8888888955116272)
[2024-11-29 03:43:00,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:00,360][root][INFO] - Training Epoch: 8/10, step 424/574 completed (loss: 0.045679882168769836, acc: 1.0)
[2024-11-29 03:43:00,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:00,641][root][INFO] - Training Epoch: 8/10, step 425/574 completed (loss: 0.05984216928482056, acc: 1.0)
[2024-11-29 03:43:00,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:00,930][root][INFO] - Training Epoch: 8/10, step 426/574 completed (loss: 0.046780046075582504, acc: 1.0)
[2024-11-29 03:43:01,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:01,228][root][INFO] - Training Epoch: 8/10, step 427/574 completed (loss: 0.05186028033494949, acc: 1.0)
[2024-11-29 03:43:01,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:01,506][root][INFO] - Training Epoch: 8/10, step 428/574 completed (loss: 0.07588101178407669, acc: 1.0)
[2024-11-29 03:43:01,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:01,824][root][INFO] - Training Epoch: 8/10, step 429/574 completed (loss: 0.05541647598147392, acc: 0.95652174949646)
[2024-11-29 03:43:02,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:02,131][root][INFO] - Training Epoch: 8/10, step 430/574 completed (loss: 0.01128699816763401, acc: 1.0)
[2024-11-29 03:43:02,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:02,401][root][INFO] - Training Epoch: 8/10, step 431/574 completed (loss: 0.024127475917339325, acc: 1.0)
[2024-11-29 03:43:02,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:02,655][root][INFO] - Training Epoch: 8/10, step 432/574 completed (loss: 0.009100944735109806, acc: 1.0)
[2024-11-29 03:43:02,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:03,008][root][INFO] - Training Epoch: 8/10, step 433/574 completed (loss: 0.02334292232990265, acc: 1.0)
[2024-11-29 03:43:03,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:03,262][root][INFO] - Training Epoch: 8/10, step 434/574 completed (loss: 0.0028281090781092644, acc: 1.0)
[2024-11-29 03:43:03,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:03,521][root][INFO] - Training Epoch: 8/10, step 435/574 completed (loss: 0.017148902639746666, acc: 1.0)
[2024-11-29 03:43:03,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:03,779][root][INFO] - Training Epoch: 8/10, step 436/574 completed (loss: 0.04665815830230713, acc: 1.0)
[2024-11-29 03:43:03,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:04,046][root][INFO] - Training Epoch: 8/10, step 437/574 completed (loss: 0.034377988427877426, acc: 1.0)
[2024-11-29 03:43:04,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:04,299][root][INFO] - Training Epoch: 8/10, step 438/574 completed (loss: 0.01083820965141058, acc: 1.0)
[2024-11-29 03:43:04,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:04,559][root][INFO] - Training Epoch: 8/10, step 439/574 completed (loss: 0.05178707093000412, acc: 0.9743589758872986)
[2024-11-29 03:43:04,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:05,135][root][INFO] - Training Epoch: 8/10, step 440/574 completed (loss: 0.21121223270893097, acc: 0.8939393758773804)
[2024-11-29 03:43:05,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:06,087][root][INFO] - Training Epoch: 8/10, step 441/574 completed (loss: 0.6787611842155457, acc: 0.8159999847412109)
[2024-11-29 03:43:06,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:06,550][root][INFO] - Training Epoch: 8/10, step 442/574 completed (loss: 0.547385036945343, acc: 0.8387096524238586)
[2024-11-29 03:43:07,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:07,467][root][INFO] - Training Epoch: 8/10, step 443/574 completed (loss: 0.5476211309432983, acc: 0.8557214140892029)
[2024-11-29 03:43:07,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:07,690][root][INFO] - Training Epoch: 8/10, step 444/574 completed (loss: 0.20087547600269318, acc: 0.9056603908538818)
[2024-11-29 03:43:07,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:08,186][root][INFO] - Training Epoch: 8/10, step 445/574 completed (loss: 0.028599141165614128, acc: 1.0)
[2024-11-29 03:43:08,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:08,436][root][INFO] - Training Epoch: 8/10, step 446/574 completed (loss: 0.1055908203125, acc: 0.95652174949646)
[2024-11-29 03:43:08,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:08,684][root][INFO] - Training Epoch: 8/10, step 447/574 completed (loss: 0.05675286054611206, acc: 1.0)
[2024-11-29 03:43:08,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:08,927][root][INFO] - Training Epoch: 8/10, step 448/574 completed (loss: 0.06699201464653015, acc: 0.9642857313156128)
[2024-11-29 03:43:09,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:09,183][root][INFO] - Training Epoch: 8/10, step 449/574 completed (loss: 0.11288224160671234, acc: 0.9552238583564758)
[2024-11-29 03:43:09,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:09,453][root][INFO] - Training Epoch: 8/10, step 450/574 completed (loss: 0.13814255595207214, acc: 0.9722222089767456)
[2024-11-29 03:43:09,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:09,711][root][INFO] - Training Epoch: 8/10, step 451/574 completed (loss: 0.058547310531139374, acc: 0.97826087474823)
[2024-11-29 03:43:09,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:09,986][root][INFO] - Training Epoch: 8/10, step 452/574 completed (loss: 0.17893563210964203, acc: 0.9487179517745972)
[2024-11-29 03:43:10,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:10,258][root][INFO] - Training Epoch: 8/10, step 453/574 completed (loss: 0.16866298019886017, acc: 0.9210526347160339)
[2024-11-29 03:43:10,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:10,568][root][INFO] - Training Epoch: 8/10, step 454/574 completed (loss: 0.07306987047195435, acc: 1.0)
[2024-11-29 03:43:10,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:10,822][root][INFO] - Training Epoch: 8/10, step 455/574 completed (loss: 0.13412342965602875, acc: 0.939393937587738)
[2024-11-29 03:43:10,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:11,092][root][INFO] - Training Epoch: 8/10, step 456/574 completed (loss: 0.30281808972358704, acc: 0.9278350472450256)
[2024-11-29 03:43:11,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:11,354][root][INFO] - Training Epoch: 8/10, step 457/574 completed (loss: 0.04481176659464836, acc: 1.0)
[2024-11-29 03:43:11,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:11,773][root][INFO] - Training Epoch: 8/10, step 458/574 completed (loss: 0.35078009963035583, acc: 0.8895348906517029)
[2024-11-29 03:43:11,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:12,020][root][INFO] - Training Epoch: 8/10, step 459/574 completed (loss: 0.14043329656124115, acc: 0.9642857313156128)
[2024-11-29 03:43:12,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:12,274][root][INFO] - Training Epoch: 8/10, step 460/574 completed (loss: 0.23336540162563324, acc: 0.9012345671653748)
[2024-11-29 03:43:12,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:12,498][root][INFO] - Training Epoch: 8/10, step 461/574 completed (loss: 0.11699768155813217, acc: 0.9722222089767456)
[2024-11-29 03:43:12,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:12,750][root][INFO] - Training Epoch: 8/10, step 462/574 completed (loss: 0.046950142830610275, acc: 1.0)
[2024-11-29 03:43:12,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:13,004][root][INFO] - Training Epoch: 8/10, step 463/574 completed (loss: 0.16462305188179016, acc: 0.9615384340286255)
[2024-11-29 03:43:13,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:13,264][root][INFO] - Training Epoch: 8/10, step 464/574 completed (loss: 0.19699428975582123, acc: 0.9347826242446899)
[2024-11-29 03:43:13,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:13,517][root][INFO] - Training Epoch: 8/10, step 465/574 completed (loss: 0.13137654960155487, acc: 0.976190447807312)
[2024-11-29 03:43:13,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:13,768][root][INFO] - Training Epoch: 8/10, step 466/574 completed (loss: 0.6307946443557739, acc: 0.8554216623306274)
[2024-11-29 03:43:13,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:14,068][root][INFO] - Training Epoch: 8/10, step 467/574 completed (loss: 0.1617845892906189, acc: 0.9459459185600281)
[2024-11-29 03:43:14,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:14,324][root][INFO] - Training Epoch: 8/10, step 468/574 completed (loss: 0.47644007205963135, acc: 0.8640776872634888)
[2024-11-29 03:43:14,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:14,593][root][INFO] - Training Epoch: 8/10, step 469/574 completed (loss: 0.5450278520584106, acc: 0.8943089246749878)
[2024-11-29 03:43:14,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:14,844][root][INFO] - Training Epoch: 8/10, step 470/574 completed (loss: 0.0619104765355587, acc: 1.0)
[2024-11-29 03:43:14,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:15,093][root][INFO] - Training Epoch: 8/10, step 471/574 completed (loss: 0.12347377836704254, acc: 0.9642857313156128)
[2024-11-29 03:43:15,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:15,568][root][INFO] - Training Epoch: 8/10, step 472/574 completed (loss: 0.36879849433898926, acc: 0.8725489974021912)
[2024-11-29 03:43:15,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:15,941][root][INFO] - Training Epoch: 8/10, step 473/574 completed (loss: 0.705142080783844, acc: 0.7816593647003174)
[2024-11-29 03:43:16,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:16,207][root][INFO] - Training Epoch: 8/10, step 474/574 completed (loss: 0.28601428866386414, acc: 0.9375)
[2024-11-29 03:43:16,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:16,517][root][INFO] - Training Epoch: 8/10, step 475/574 completed (loss: 0.18430763483047485, acc: 0.9325153231620789)
[2024-11-29 03:43:16,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:16,840][root][INFO] - Training Epoch: 8/10, step 476/574 completed (loss: 0.3053295910358429, acc: 0.9208633303642273)
[2024-11-29 03:43:17,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:17,191][root][INFO] - Training Epoch: 8/10, step 477/574 completed (loss: 0.4553099274635315, acc: 0.8793969750404358)
[2024-11-29 03:43:17,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:17,448][root][INFO] - Training Epoch: 8/10, step 478/574 completed (loss: 0.2919416129589081, acc: 0.9444444179534912)
[2024-11-29 03:43:17,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:17,744][root][INFO] - Training Epoch: 8/10, step 479/574 completed (loss: 0.14830484986305237, acc: 0.9696969985961914)
[2024-11-29 03:43:17,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:18,034][root][INFO] - Training Epoch: 8/10, step 480/574 completed (loss: 0.1363661140203476, acc: 0.9629629850387573)
[2024-11-29 03:43:18,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:18,322][root][INFO] - Training Epoch: 8/10, step 481/574 completed (loss: 0.27816036343574524, acc: 0.949999988079071)
[2024-11-29 03:43:18,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:18,634][root][INFO] - Training Epoch: 8/10, step 482/574 completed (loss: 0.4199579358100891, acc: 0.8999999761581421)
[2024-11-29 03:43:18,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:19,059][root][INFO] - Training Epoch: 8/10, step 483/574 completed (loss: 0.47068464756011963, acc: 0.8793103694915771)
[2024-11-29 03:43:19,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:19,315][root][INFO] - Training Epoch: 8/10, step 484/574 completed (loss: 0.1544554978609085, acc: 0.9677419066429138)
[2024-11-29 03:43:19,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:19,617][root][INFO] - Training Epoch: 8/10, step 485/574 completed (loss: 0.032111845910549164, acc: 1.0)
[2024-11-29 03:43:19,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:19,894][root][INFO] - Training Epoch: 8/10, step 486/574 completed (loss: 0.2707710862159729, acc: 0.9629629850387573)
[2024-11-29 03:43:20,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:20,190][root][INFO] - Training Epoch: 8/10, step 487/574 completed (loss: 0.22923490405082703, acc: 0.9523809552192688)
[2024-11-29 03:43:20,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:20,467][root][INFO] - Training Epoch: 8/10, step 488/574 completed (loss: 0.339126855134964, acc: 0.9090909361839294)
[2024-11-29 03:43:20,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:20,812][root][INFO] - Training Epoch: 8/10, step 489/574 completed (loss: 0.41901376843452454, acc: 0.8307692408561707)
[2024-11-29 03:43:20,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:21,116][root][INFO] - Training Epoch: 8/10, step 490/574 completed (loss: 0.015233578160405159, acc: 1.0)
[2024-11-29 03:43:21,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:21,402][root][INFO] - Training Epoch: 8/10, step 491/574 completed (loss: 0.026081839576363564, acc: 1.0)
[2024-11-29 03:43:21,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:21,672][root][INFO] - Training Epoch: 8/10, step 492/574 completed (loss: 0.08410850167274475, acc: 0.9607843160629272)
[2024-11-29 03:43:21,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:21,971][root][INFO] - Training Epoch: 8/10, step 493/574 completed (loss: 0.25880977511405945, acc: 0.931034505367279)
[2024-11-29 03:43:22,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:22,301][root][INFO] - Training Epoch: 8/10, step 494/574 completed (loss: 0.07240061461925507, acc: 1.0)
[2024-11-29 03:43:22,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:22,655][root][INFO] - Training Epoch: 8/10, step 495/574 completed (loss: 0.4292130768299103, acc: 0.9473684430122375)
[2024-11-29 03:43:22,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:23,019][root][INFO] - Training Epoch: 8/10, step 496/574 completed (loss: 0.5399595499038696, acc: 0.8482142686843872)
[2024-11-29 03:43:23,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:23,419][root][INFO] - Training Epoch: 8/10, step 497/574 completed (loss: 0.3092142939567566, acc: 0.9101123809814453)
[2024-11-29 03:43:23,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:23,739][root][INFO] - Training Epoch: 8/10, step 498/574 completed (loss: 0.4464719891548157, acc: 0.8539325594902039)
[2024-11-29 03:43:23,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:24,087][root][INFO] - Training Epoch: 8/10, step 499/574 completed (loss: 1.09321129322052, acc: 0.7021276354789734)
[2024-11-29 03:43:24,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:24,444][root][INFO] - Training Epoch: 8/10, step 500/574 completed (loss: 0.5302773714065552, acc: 0.8586956262588501)
[2024-11-29 03:43:24,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:24,745][root][INFO] - Training Epoch: 8/10, step 501/574 completed (loss: 0.048862531781196594, acc: 1.0)
[2024-11-29 03:43:24,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:25,052][root][INFO] - Training Epoch: 8/10, step 502/574 completed (loss: 0.02162102982401848, acc: 1.0)
[2024-11-29 03:43:25,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:25,345][root][INFO] - Training Epoch: 8/10, step 503/574 completed (loss: 0.2102777510881424, acc: 0.9629629850387573)
[2024-11-29 03:43:25,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:25,674][root][INFO] - Training Epoch: 8/10, step 504/574 completed (loss: 0.05712394788861275, acc: 1.0)
[2024-11-29 03:43:25,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:26,023][root][INFO] - Training Epoch: 8/10, step 505/574 completed (loss: 0.49022814631462097, acc: 0.8867924809455872)
[2024-11-29 03:43:26,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:26,346][root][INFO] - Training Epoch: 8/10, step 506/574 completed (loss: 0.984000563621521, acc: 0.7931034564971924)
[2024-11-29 03:43:26,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:27,153][root][INFO] - Training Epoch: 8/10, step 507/574 completed (loss: 0.9064027667045593, acc: 0.7747747898101807)
[2024-11-29 03:43:27,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:27,691][root][INFO] - Training Epoch: 8/10, step 508/574 completed (loss: 0.640742301940918, acc: 0.8028169274330139)
[2024-11-29 03:43:27,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:27,972][root][INFO] - Training Epoch: 8/10, step 509/574 completed (loss: 0.0611330047249794, acc: 0.949999988079071)
[2024-11-29 03:43:28,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:28,289][root][INFO] - Training Epoch: 8/10, step 510/574 completed (loss: 0.06293177604675293, acc: 1.0)
[2024-11-29 03:43:28,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:28,642][root][INFO] - Training Epoch: 8/10, step 511/574 completed (loss: 0.34400779008865356, acc: 0.8846153616905212)
[2024-11-29 03:43:31,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:32,606][root][INFO] - Training Epoch: 8/10, step 512/574 completed (loss: 0.9394615292549133, acc: 0.7214285731315613)
[2024-11-29 03:43:33,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:33,704][root][INFO] - Training Epoch: 8/10, step 513/574 completed (loss: 0.3308844268321991, acc: 0.9047619104385376)
[2024-11-29 03:43:33,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:33,957][root][INFO] - Training Epoch: 8/10, step 514/574 completed (loss: 0.44226425886154175, acc: 0.8928571343421936)
[2024-11-29 03:43:34,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:34,226][root][INFO] - Training Epoch: 8/10, step 515/574 completed (loss: 0.02412772923707962, acc: 1.0)
[2024-11-29 03:43:34,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:35,192][root][INFO] - Training Epoch: 8/10, step 516/574 completed (loss: 0.4106787145137787, acc: 0.8888888955116272)
[2024-11-29 03:43:35,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:35,436][root][INFO] - Training Epoch: 8/10, step 517/574 completed (loss: 0.0056134420447051525, acc: 1.0)
[2024-11-29 03:43:35,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:35,688][root][INFO] - Training Epoch: 8/10, step 518/574 completed (loss: 0.050588298588991165, acc: 1.0)
[2024-11-29 03:43:35,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:35,996][root][INFO] - Training Epoch: 8/10, step 519/574 completed (loss: 0.06152072548866272, acc: 0.949999988079071)
[2024-11-29 03:43:36,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:36,272][root][INFO] - Training Epoch: 8/10, step 520/574 completed (loss: 0.10718976706266403, acc: 0.9629629850387573)
[2024-11-29 03:43:37,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:37,808][root][INFO] - Training Epoch: 8/10, step 521/574 completed (loss: 0.7789463400840759, acc: 0.7881355881690979)
[2024-11-29 03:43:38,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:38,173][root][INFO] - Training Epoch: 8/10, step 522/574 completed (loss: 0.30632680654525757, acc: 0.888059675693512)
[2024-11-29 03:43:38,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:38,553][root][INFO] - Training Epoch: 8/10, step 523/574 completed (loss: 0.31656989455223083, acc: 0.9124087691307068)
[2024-11-29 03:43:38,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:39,292][root][INFO] - Training Epoch: 8/10, step 524/574 completed (loss: 0.7635812163352966, acc: 0.8100000023841858)
[2024-11-29 03:43:39,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:39,591][root][INFO] - Training Epoch: 8/10, step 525/574 completed (loss: 0.026698725298047066, acc: 1.0)
[2024-11-29 03:43:39,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:39,892][root][INFO] - Training Epoch: 8/10, step 526/574 completed (loss: 0.06739666312932968, acc: 0.9807692170143127)
[2024-11-29 03:43:40,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:40,159][root][INFO] - Training Epoch: 8/10, step 527/574 completed (loss: 0.13201673328876495, acc: 1.0)
[2024-11-29 03:43:40,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:40,442][root][INFO] - Training Epoch: 8/10, step 528/574 completed (loss: 0.935020923614502, acc: 0.7049180269241333)
[2024-11-29 03:43:40,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:40,764][root][INFO] - Training Epoch: 8/10, step 529/574 completed (loss: 0.07304566353559494, acc: 0.9830508232116699)
[2024-11-29 03:43:40,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:41,043][root][INFO] - Training Epoch: 8/10, step 530/574 completed (loss: 1.0274219512939453, acc: 0.7674418687820435)
[2024-11-29 03:43:41,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:41,324][root][INFO] - Training Epoch: 8/10, step 531/574 completed (loss: 0.32507726550102234, acc: 0.9318181872367859)
[2024-11-29 03:43:41,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:41,622][root][INFO] - Training Epoch: 8/10, step 532/574 completed (loss: 0.6316022872924805, acc: 0.849056601524353)
[2024-11-29 03:43:41,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:41,902][root][INFO] - Training Epoch: 8/10, step 533/574 completed (loss: 0.46353331208229065, acc: 0.8636363744735718)
[2024-11-29 03:43:42,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:42,172][root][INFO] - Training Epoch: 8/10, step 534/574 completed (loss: 0.3981114625930786, acc: 0.9200000166893005)
[2024-11-29 03:43:42,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:42,469][root][INFO] - Training Epoch: 8/10, step 535/574 completed (loss: 0.17117595672607422, acc: 0.8999999761581421)
[2024-11-29 03:43:42,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:42,809][root][INFO] - Training Epoch: 8/10, step 536/574 completed (loss: 0.06288158148527145, acc: 1.0)
[2024-11-29 03:43:43,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:43,261][root][INFO] - Training Epoch: 8/10, step 537/574 completed (loss: 0.3615936040878296, acc: 0.892307698726654)
[2024-11-29 03:43:43,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:43,594][root][INFO] - Training Epoch: 8/10, step 538/574 completed (loss: 0.32282018661499023, acc: 0.90625)
[2024-11-29 03:43:43,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:44,033][root][INFO] - Training Epoch: 8/10, step 539/574 completed (loss: 0.34734147787094116, acc: 0.875)
[2024-11-29 03:43:44,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:44,337][root][INFO] - Training Epoch: 8/10, step 540/574 completed (loss: 0.7287545204162598, acc: 0.7878788113594055)
[2024-11-29 03:43:44,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:44,623][root][INFO] - Training Epoch: 8/10, step 541/574 completed (loss: 0.25867995619773865, acc: 0.9375)
[2024-11-29 03:43:44,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:44,890][root][INFO] - Training Epoch: 8/10, step 542/574 completed (loss: 0.05695703253149986, acc: 1.0)
[2024-11-29 03:43:45,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:45,142][root][INFO] - Training Epoch: 8/10, step 543/574 completed (loss: 0.011016765609383583, acc: 1.0)
[2024-11-29 03:43:45,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:45,399][root][INFO] - Training Epoch: 8/10, step 544/574 completed (loss: 0.1400686800479889, acc: 0.9666666388511658)
[2024-11-29 03:43:45,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:45,669][root][INFO] - Training Epoch: 8/10, step 545/574 completed (loss: 0.0738847553730011, acc: 0.9512194991111755)
[2024-11-29 03:43:45,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:45,913][root][INFO] - Training Epoch: 8/10, step 546/574 completed (loss: 0.024517295882105827, acc: 1.0)
[2024-11-29 03:43:46,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:46,167][root][INFO] - Training Epoch: 8/10, step 547/574 completed (loss: 0.0326768234372139, acc: 1.0)
[2024-11-29 03:43:46,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:46,419][root][INFO] - Training Epoch: 8/10, step 548/574 completed (loss: 0.15329070389270782, acc: 0.9677419066429138)
[2024-11-29 03:43:46,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:46,662][root][INFO] - Training Epoch: 8/10, step 549/574 completed (loss: 0.02025734633207321, acc: 1.0)
[2024-11-29 03:43:46,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:46,910][root][INFO] - Training Epoch: 8/10, step 550/574 completed (loss: 0.08486653119325638, acc: 0.9696969985961914)
[2024-11-29 03:43:47,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:47,165][root][INFO] - Training Epoch: 8/10, step 551/574 completed (loss: 0.10108008235692978, acc: 0.9750000238418579)
[2024-11-29 03:43:47,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:47,436][root][INFO] - Training Epoch: 8/10, step 552/574 completed (loss: 0.09983358532190323, acc: 0.9857142567634583)
[2024-11-29 03:43:47,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:47,722][root][INFO] - Training Epoch: 8/10, step 553/574 completed (loss: 0.4405444264411926, acc: 0.8905109763145447)
[2024-11-29 03:43:47,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:48,016][root][INFO] - Training Epoch: 8/10, step 554/574 completed (loss: 0.2228429913520813, acc: 0.9379310607910156)
[2024-11-29 03:43:48,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:48,289][root][INFO] - Training Epoch: 8/10, step 555/574 completed (loss: 0.4252336919307709, acc: 0.8857142925262451)
[2024-11-29 03:43:48,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:48,591][root][INFO] - Training Epoch: 8/10, step 556/574 completed (loss: 0.42415276169776917, acc: 0.8675496578216553)
[2024-11-29 03:43:48,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:48,874][root][INFO] - Training Epoch: 8/10, step 557/574 completed (loss: 0.11373451352119446, acc: 0.9572649598121643)
[2024-11-29 03:43:49,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:50,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:50,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:50,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:51,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:52,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:52,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:52,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:53,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:53,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:54,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:54,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:55,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:55,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:56,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:56,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:57,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:57,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:57,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:58,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:58,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:59,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:59,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:43:59,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:00,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:00,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:01,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:01,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:02,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:02,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:03,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:03,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:04,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:04,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:04,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:05,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:05,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:06,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:06,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:06,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:07,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:07,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:08,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:08,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:09,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:09,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:10,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:10,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:11,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:11,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:11,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:12,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:12,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:13,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:13,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:14,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:14,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:15,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:15,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:15,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:16,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:17,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:17,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:18,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:18,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:18,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:19,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:19,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:20,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:21,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:21,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:21,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:22,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:22,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:23,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:23,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:24,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:24,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:25,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:25,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:26,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:26,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:26,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:27,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:27,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:28,542][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.0654, device='cuda:0') eval_epoch_loss=tensor(1.1202, device='cuda:0') eval_epoch_acc=tensor(0.7582, device='cuda:0')
[2024-11-29 03:44:28,543][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:44:28,544][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:44:28,788][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_8_step_558_loss_1.1201694011688232/model.pt
[2024-11-29 03:44:28,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:29,123][root][INFO] - Training Epoch: 8/10, step 558/574 completed (loss: 0.0788876935839653, acc: 0.9599999785423279)
[2024-11-29 03:44:29,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:29,423][root][INFO] - Training Epoch: 8/10, step 559/574 completed (loss: 0.14996272325515747, acc: 0.9615384340286255)
[2024-11-29 03:44:29,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:29,693][root][INFO] - Training Epoch: 8/10, step 560/574 completed (loss: 0.03156319633126259, acc: 1.0)
[2024-11-29 03:44:29,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:29,959][root][INFO] - Training Epoch: 8/10, step 561/574 completed (loss: 0.04943237826228142, acc: 1.0)
[2024-11-29 03:44:30,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:30,251][root][INFO] - Training Epoch: 8/10, step 562/574 completed (loss: 0.17766451835632324, acc: 0.9444444179534912)
[2024-11-29 03:44:30,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:30,496][root][INFO] - Training Epoch: 8/10, step 563/574 completed (loss: 0.18896032869815826, acc: 0.9220778942108154)
[2024-11-29 03:44:30,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:30,753][root][INFO] - Training Epoch: 8/10, step 564/574 completed (loss: 0.25705257058143616, acc: 0.9583333134651184)
[2024-11-29 03:44:30,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:31,026][root][INFO] - Training Epoch: 8/10, step 565/574 completed (loss: 0.12466103583574295, acc: 0.9482758641242981)
[2024-11-29 03:44:31,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:31,301][root][INFO] - Training Epoch: 8/10, step 566/574 completed (loss: 0.19640952348709106, acc: 0.9404761791229248)
[2024-11-29 03:44:31,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:31,552][root][INFO] - Training Epoch: 8/10, step 567/574 completed (loss: 0.02149406634271145, acc: 1.0)
[2024-11-29 03:44:31,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:31,807][root][INFO] - Training Epoch: 8/10, step 568/574 completed (loss: 0.008255991153419018, acc: 1.0)
[2024-11-29 03:44:32,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:32,204][root][INFO] - Training Epoch: 8/10, step 569/574 completed (loss: 0.28769227862358093, acc: 0.9358288645744324)
[2024-11-29 03:44:32,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:32,456][root][INFO] - Training Epoch: 8/10, step 570/574 completed (loss: 0.02680959179997444, acc: 1.0)
[2024-11-29 03:44:32,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:32,715][root][INFO] - Training Epoch: 8/10, step 571/574 completed (loss: 0.19163133203983307, acc: 0.9658119678497314)
[2024-11-29 03:44:32,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:32,982][root][INFO] - Training Epoch: 8/10, step 572/574 completed (loss: 0.5598241090774536, acc: 0.831632673740387)
[2024-11-29 03:44:33,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:33,306][root][INFO] - Training Epoch: 8/10, step 573/574 completed (loss: 0.43764159083366394, acc: 0.849056601524353)
[2024-11-29 03:44:33,737][slam_llm.utils.train_utils][INFO] - Epoch 8: train_perplexity=1.3907, train_epoch_loss=0.3298, epoch time 381.5220239330083s
[2024-11-29 03:44:33,738][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-11-29 03:44:33,738][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 16 GB
[2024-11-29 03:44:33,738][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-11-29 03:44:33,738][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 16
[2024-11-29 03:44:33,738][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-29 03:44:34,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:34,505][root][INFO] - Training Epoch: 9/10, step 0/574 completed (loss: 0.117713563144207, acc: 0.9629629850387573)
[2024-11-29 03:44:34,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:34,747][root][INFO] - Training Epoch: 9/10, step 1/574 completed (loss: 0.01566767506301403, acc: 1.0)
[2024-11-29 03:44:34,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:34,999][root][INFO] - Training Epoch: 9/10, step 2/574 completed (loss: 0.2919881343841553, acc: 0.8918918967247009)
[2024-11-29 03:44:35,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:35,278][root][INFO] - Training Epoch: 9/10, step 3/574 completed (loss: 0.09427628666162491, acc: 0.9473684430122375)
[2024-11-29 03:44:35,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:35,541][root][INFO] - Training Epoch: 9/10, step 4/574 completed (loss: 0.04872344806790352, acc: 1.0)
[2024-11-29 03:44:35,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:35,854][root][INFO] - Training Epoch: 9/10, step 5/574 completed (loss: 0.05687053129076958, acc: 1.0)
[2024-11-29 03:44:36,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:36,161][root][INFO] - Training Epoch: 9/10, step 6/574 completed (loss: 0.3672220706939697, acc: 0.8775510191917419)
[2024-11-29 03:44:36,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:36,413][root][INFO] - Training Epoch: 9/10, step 7/574 completed (loss: 0.042676668614149094, acc: 1.0)
[2024-11-29 03:44:36,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:36,673][root][INFO] - Training Epoch: 9/10, step 8/574 completed (loss: 0.04361134395003319, acc: 1.0)
[2024-11-29 03:44:36,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:36,926][root][INFO] - Training Epoch: 9/10, step 9/574 completed (loss: 0.007964413613080978, acc: 1.0)
[2024-11-29 03:44:37,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:37,181][root][INFO] - Training Epoch: 9/10, step 10/574 completed (loss: 0.029193218797445297, acc: 1.0)
[2024-11-29 03:44:37,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:37,443][root][INFO] - Training Epoch: 9/10, step 11/574 completed (loss: 0.10496540367603302, acc: 0.9487179517745972)
[2024-11-29 03:44:37,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:37,704][root][INFO] - Training Epoch: 9/10, step 12/574 completed (loss: 0.08437036722898483, acc: 0.9696969985961914)
[2024-11-29 03:44:37,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:38,025][root][INFO] - Training Epoch: 9/10, step 13/574 completed (loss: 0.3034953773021698, acc: 0.95652174949646)
[2024-11-29 03:44:38,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:38,319][root][INFO] - Training Epoch: 9/10, step 14/574 completed (loss: 0.11578775197267532, acc: 0.9803921580314636)
[2024-11-29 03:44:38,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:38,582][root][INFO] - Training Epoch: 9/10, step 15/574 completed (loss: 0.08023469150066376, acc: 0.9795918464660645)
[2024-11-29 03:44:38,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:38,812][root][INFO] - Training Epoch: 9/10, step 16/574 completed (loss: 0.08750012516975403, acc: 1.0)
[2024-11-29 03:44:38,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:39,041][root][INFO] - Training Epoch: 9/10, step 17/574 completed (loss: 0.026507355272769928, acc: 1.0)
[2024-11-29 03:44:39,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:39,332][root][INFO] - Training Epoch: 9/10, step 18/574 completed (loss: 0.12221797555685043, acc: 0.9444444179534912)
[2024-11-29 03:44:39,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:39,587][root][INFO] - Training Epoch: 9/10, step 19/574 completed (loss: 0.03816705942153931, acc: 1.0)
[2024-11-29 03:44:39,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:39,836][root][INFO] - Training Epoch: 9/10, step 20/574 completed (loss: 0.053354982286691666, acc: 1.0)
[2024-11-29 03:44:39,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:40,088][root][INFO] - Training Epoch: 9/10, step 21/574 completed (loss: 0.030525783076882362, acc: 1.0)
[2024-11-29 03:44:40,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:40,329][root][INFO] - Training Epoch: 9/10, step 22/574 completed (loss: 0.012797391042113304, acc: 1.0)
[2024-11-29 03:44:40,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:40,583][root][INFO] - Training Epoch: 9/10, step 23/574 completed (loss: 0.015607250854372978, acc: 1.0)
[2024-11-29 03:44:40,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:40,844][root][INFO] - Training Epoch: 9/10, step 24/574 completed (loss: 0.011732807382941246, acc: 1.0)
[2024-11-29 03:44:40,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:41,110][root][INFO] - Training Epoch: 9/10, step 25/574 completed (loss: 0.20071594417095184, acc: 0.9245283007621765)
[2024-11-29 03:44:41,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:41,364][root][INFO] - Training Epoch: 9/10, step 26/574 completed (loss: 0.4986085295677185, acc: 0.8493150472640991)
[2024-11-29 03:44:42,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:42,950][root][INFO] - Training Epoch: 9/10, step 27/574 completed (loss: 0.9834355115890503, acc: 0.7035573124885559)
[2024-11-29 03:44:43,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:43,192][root][INFO] - Training Epoch: 9/10, step 28/574 completed (loss: 0.2316175252199173, acc: 0.8837209343910217)
[2024-11-29 03:44:43,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:43,452][root][INFO] - Training Epoch: 9/10, step 29/574 completed (loss: 0.2737795114517212, acc: 0.9156626462936401)
[2024-11-29 03:44:43,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:43,719][root][INFO] - Training Epoch: 9/10, step 30/574 completed (loss: 0.3746209144592285, acc: 0.9135802388191223)
[2024-11-29 03:44:43,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:44,027][root][INFO] - Training Epoch: 9/10, step 31/574 completed (loss: 0.03671475127339363, acc: 1.0)
[2024-11-29 03:44:44,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:44,274][root][INFO] - Training Epoch: 9/10, step 32/574 completed (loss: 0.03338835760951042, acc: 1.0)
[2024-11-29 03:44:44,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:44,527][root][INFO] - Training Epoch: 9/10, step 33/574 completed (loss: 0.03484272584319115, acc: 1.0)
[2024-11-29 03:44:44,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:44,865][root][INFO] - Training Epoch: 9/10, step 34/574 completed (loss: 0.2545050084590912, acc: 0.9159663915634155)
[2024-11-29 03:44:45,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:45,148][root][INFO] - Training Epoch: 9/10, step 35/574 completed (loss: 0.1514093428850174, acc: 0.9672130942344666)
[2024-11-29 03:44:45,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:45,458][root][INFO] - Training Epoch: 9/10, step 36/574 completed (loss: 0.4085215628147125, acc: 0.8571428656578064)
[2024-11-29 03:44:45,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:45,715][root][INFO] - Training Epoch: 9/10, step 37/574 completed (loss: 0.23273912072181702, acc: 0.9322034120559692)
[2024-11-29 03:44:45,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:46,016][root][INFO] - Training Epoch: 9/10, step 38/574 completed (loss: 0.235770583152771, acc: 0.931034505367279)
[2024-11-29 03:44:46,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:46,271][root][INFO] - Training Epoch: 9/10, step 39/574 completed (loss: 0.27864745259284973, acc: 0.9047619104385376)
[2024-11-29 03:44:46,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:46,562][root][INFO] - Training Epoch: 9/10, step 40/574 completed (loss: 0.30364149808883667, acc: 0.9230769276618958)
[2024-11-29 03:44:46,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:46,944][root][INFO] - Training Epoch: 9/10, step 41/574 completed (loss: 0.14661259949207306, acc: 0.9459459185600281)
[2024-11-29 03:44:47,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:47,276][root][INFO] - Training Epoch: 9/10, step 42/574 completed (loss: 0.3527747094631195, acc: 0.8769230842590332)
[2024-11-29 03:44:47,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:47,740][root][INFO] - Training Epoch: 9/10, step 43/574 completed (loss: 0.5061325430870056, acc: 0.8484848737716675)
[2024-11-29 03:44:47,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:48,207][root][INFO] - Training Epoch: 9/10, step 44/574 completed (loss: 0.3263460397720337, acc: 0.8969072103500366)
[2024-11-29 03:44:48,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:48,643][root][INFO] - Training Epoch: 9/10, step 45/574 completed (loss: 0.4421439468860626, acc: 0.8897058963775635)
[2024-11-29 03:44:48,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:48,894][root][INFO] - Training Epoch: 9/10, step 46/574 completed (loss: 0.0321773923933506, acc: 1.0)
[2024-11-29 03:44:49,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:49,147][root][INFO] - Training Epoch: 9/10, step 47/574 completed (loss: 0.04824433475732803, acc: 1.0)
[2024-11-29 03:44:49,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:49,407][root][INFO] - Training Epoch: 9/10, step 48/574 completed (loss: 0.011374473571777344, acc: 1.0)
[2024-11-29 03:44:49,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:49,663][root][INFO] - Training Epoch: 9/10, step 49/574 completed (loss: 0.044067371636629105, acc: 1.0)
[2024-11-29 03:44:49,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:50,010][root][INFO] - Training Epoch: 9/10, step 50/574 completed (loss: 0.3968634605407715, acc: 0.8947368264198303)
[2024-11-29 03:44:50,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:50,293][root][INFO] - Training Epoch: 9/10, step 51/574 completed (loss: 0.25239816308021545, acc: 0.920634925365448)
[2024-11-29 03:44:50,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:50,599][root][INFO] - Training Epoch: 9/10, step 52/574 completed (loss: 0.5254947543144226, acc: 0.8309859037399292)
[2024-11-29 03:44:50,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:51,148][root][INFO] - Training Epoch: 9/10, step 53/574 completed (loss: 1.0344477891921997, acc: 0.6933333277702332)
[2024-11-29 03:44:51,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:51,459][root][INFO] - Training Epoch: 9/10, step 54/574 completed (loss: 0.18642723560333252, acc: 0.9459459185600281)
[2024-11-29 03:44:51,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:51,773][root][INFO] - Training Epoch: 9/10, step 55/574 completed (loss: 0.07636714726686478, acc: 0.9615384340286255)
[2024-11-29 03:44:54,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:56,062][root][INFO] - Training Epoch: 9/10, step 56/574 completed (loss: 1.188103437423706, acc: 0.6894198060035706)
[2024-11-29 03:44:57,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:57,757][root][INFO] - Training Epoch: 9/10, step 57/574 completed (loss: 1.3275917768478394, acc: 0.6405228972434998)
[2024-11-29 03:44:58,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:58,582][root][INFO] - Training Epoch: 9/10, step 58/574 completed (loss: 0.5458914637565613, acc: 0.8465909361839294)
[2024-11-29 03:44:59,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:44:59,347][root][INFO] - Training Epoch: 9/10, step 59/574 completed (loss: 0.3747881054878235, acc: 0.9264705777168274)
[2024-11-29 03:44:59,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:00,087][root][INFO] - Training Epoch: 9/10, step 60/574 completed (loss: 0.6470639109611511, acc: 0.8405796885490417)
[2024-11-29 03:45:00,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:00,567][root][INFO] - Training Epoch: 9/10, step 61/574 completed (loss: 0.4941065311431885, acc: 0.8999999761581421)
[2024-11-29 03:45:00,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:00,820][root][INFO] - Training Epoch: 9/10, step 62/574 completed (loss: 0.08756572008132935, acc: 0.970588207244873)
[2024-11-29 03:45:00,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:01,088][root][INFO] - Training Epoch: 9/10, step 63/574 completed (loss: 0.11899793148040771, acc: 0.9722222089767456)
[2024-11-29 03:45:01,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:01,396][root][INFO] - Training Epoch: 9/10, step 64/574 completed (loss: 0.11995924264192581, acc: 0.953125)
[2024-11-29 03:45:01,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:01,715][root][INFO] - Training Epoch: 9/10, step 65/574 completed (loss: 0.08873379975557327, acc: 0.931034505367279)
[2024-11-29 03:45:01,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:02,034][root][INFO] - Training Epoch: 9/10, step 66/574 completed (loss: 0.2508462369441986, acc: 0.9107142686843872)
[2024-11-29 03:45:02,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:02,314][root][INFO] - Training Epoch: 9/10, step 67/574 completed (loss: 0.1326545774936676, acc: 0.9333333373069763)
[2024-11-29 03:45:02,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:02,566][root][INFO] - Training Epoch: 9/10, step 68/574 completed (loss: 0.06913658231496811, acc: 0.9599999785423279)
[2024-11-29 03:45:02,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:02,820][root][INFO] - Training Epoch: 9/10, step 69/574 completed (loss: 0.16116708517074585, acc: 0.9444444179534912)
[2024-11-29 03:45:02,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:03,086][root][INFO] - Training Epoch: 9/10, step 70/574 completed (loss: 0.3308689594268799, acc: 0.9696969985961914)
[2024-11-29 03:45:03,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:03,363][root][INFO] - Training Epoch: 9/10, step 71/574 completed (loss: 0.7517476081848145, acc: 0.7941176295280457)
[2024-11-29 03:45:03,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:03,623][root][INFO] - Training Epoch: 9/10, step 72/574 completed (loss: 0.44818753004074097, acc: 0.8650793433189392)
[2024-11-29 03:45:03,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:03,917][root][INFO] - Training Epoch: 9/10, step 73/574 completed (loss: 1.061684012413025, acc: 0.7179487347602844)
[2024-11-29 03:45:04,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:04,171][root][INFO] - Training Epoch: 9/10, step 74/574 completed (loss: 0.6267883777618408, acc: 0.8061224222183228)
[2024-11-29 03:45:04,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:04,433][root][INFO] - Training Epoch: 9/10, step 75/574 completed (loss: 0.7251664996147156, acc: 0.7835820913314819)
[2024-11-29 03:45:04,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:04,838][root][INFO] - Training Epoch: 9/10, step 76/574 completed (loss: 1.4644606113433838, acc: 0.5912408828735352)
[2024-11-29 03:45:04,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:05,085][root][INFO] - Training Epoch: 9/10, step 77/574 completed (loss: 0.014316895045340061, acc: 1.0)
[2024-11-29 03:45:05,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:05,341][root][INFO] - Training Epoch: 9/10, step 78/574 completed (loss: 0.012052991427481174, acc: 1.0)
[2024-11-29 03:45:05,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:05,589][root][INFO] - Training Epoch: 9/10, step 79/574 completed (loss: 0.02880997397005558, acc: 1.0)
[2024-11-29 03:45:05,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:05,839][root][INFO] - Training Epoch: 9/10, step 80/574 completed (loss: 0.05717400833964348, acc: 1.0)
[2024-11-29 03:45:05,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:06,105][root][INFO] - Training Epoch: 9/10, step 81/574 completed (loss: 0.17925232648849487, acc: 0.9807692170143127)
[2024-11-29 03:45:06,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:06,376][root][INFO] - Training Epoch: 9/10, step 82/574 completed (loss: 0.4544409513473511, acc: 0.8461538553237915)
[2024-11-29 03:45:06,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:06,626][root][INFO] - Training Epoch: 9/10, step 83/574 completed (loss: 0.06797216087579727, acc: 0.96875)
[2024-11-29 03:45:06,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:06,897][root][INFO] - Training Epoch: 9/10, step 84/574 completed (loss: 0.08904378861188889, acc: 0.9855072498321533)
[2024-11-29 03:45:07,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:07,165][root][INFO] - Training Epoch: 9/10, step 85/574 completed (loss: 0.07214713841676712, acc: 0.9800000190734863)
[2024-11-29 03:45:07,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:07,415][root][INFO] - Training Epoch: 9/10, step 86/574 completed (loss: 0.17832113802433014, acc: 0.9130434989929199)
[2024-11-29 03:45:07,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:07,982][root][INFO] - Training Epoch: 9/10, step 87/574 completed (loss: 0.28662505745887756, acc: 0.9200000166893005)
[2024-11-29 03:45:08,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:08,290][root][INFO] - Training Epoch: 9/10, step 88/574 completed (loss: 0.6511126160621643, acc: 0.8349514603614807)
[2024-11-29 03:45:09,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:09,939][root][INFO] - Training Epoch: 9/10, step 89/574 completed (loss: 0.8700735569000244, acc: 0.7815533876419067)
[2024-11-29 03:45:10,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:11,090][root][INFO] - Training Epoch: 9/10, step 90/574 completed (loss: 1.1088151931762695, acc: 0.7204301357269287)
[2024-11-29 03:45:11,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:12,214][root][INFO] - Training Epoch: 9/10, step 91/574 completed (loss: 1.0048645734786987, acc: 0.732758641242981)
[2024-11-29 03:45:12,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:13,255][root][INFO] - Training Epoch: 9/10, step 92/574 completed (loss: 0.672823429107666, acc: 0.8526315689086914)
[2024-11-29 03:45:14,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:14,708][root][INFO] - Training Epoch: 9/10, step 93/574 completed (loss: 0.9905218482017517, acc: 0.7128713130950928)
[2024-11-29 03:45:14,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:14,996][root][INFO] - Training Epoch: 9/10, step 94/574 completed (loss: 0.4266554117202759, acc: 0.8387096524238586)
[2024-11-29 03:45:15,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:15,321][root][INFO] - Training Epoch: 9/10, step 95/574 completed (loss: 0.2874271273612976, acc: 0.95652174949646)
[2024-11-29 03:45:15,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:15,630][root][INFO] - Training Epoch: 9/10, step 96/574 completed (loss: 0.7338855266571045, acc: 0.7478991746902466)
[2024-11-29 03:45:15,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:15,959][root][INFO] - Training Epoch: 9/10, step 97/574 completed (loss: 0.7229661345481873, acc: 0.7884615659713745)
[2024-11-29 03:45:16,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:16,359][root][INFO] - Training Epoch: 9/10, step 98/574 completed (loss: 0.909770667552948, acc: 0.7591241002082825)
[2024-11-29 03:45:16,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:16,676][root][INFO] - Training Epoch: 9/10, step 99/574 completed (loss: 0.713333785533905, acc: 0.7164179086685181)
[2024-11-29 03:45:16,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:16,998][root][INFO] - Training Epoch: 9/10, step 100/574 completed (loss: 0.2537589371204376, acc: 0.949999988079071)
[2024-11-29 03:45:17,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:17,289][root][INFO] - Training Epoch: 9/10, step 101/574 completed (loss: 0.00874140951782465, acc: 1.0)
[2024-11-29 03:45:17,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:17,602][root][INFO] - Training Epoch: 9/10, step 102/574 completed (loss: 0.013129579834640026, acc: 1.0)
[2024-11-29 03:45:17,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:17,880][root][INFO] - Training Epoch: 9/10, step 103/574 completed (loss: 0.05420282855629921, acc: 0.9772727489471436)
[2024-11-29 03:45:18,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:18,157][root][INFO] - Training Epoch: 9/10, step 104/574 completed (loss: 0.1504608690738678, acc: 0.982758641242981)
[2024-11-29 03:45:18,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:18,469][root][INFO] - Training Epoch: 9/10, step 105/574 completed (loss: 0.06634823232889175, acc: 0.9767441749572754)
[2024-11-29 03:45:18,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:18,780][root][INFO] - Training Epoch: 9/10, step 106/574 completed (loss: 0.02356206625699997, acc: 1.0)
[2024-11-29 03:45:18,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:19,069][root][INFO] - Training Epoch: 9/10, step 107/574 completed (loss: 0.01041761040687561, acc: 1.0)
[2024-11-29 03:45:19,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:19,414][root][INFO] - Training Epoch: 9/10, step 108/574 completed (loss: 0.00654479768127203, acc: 1.0)
[2024-11-29 03:45:19,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:19,755][root][INFO] - Training Epoch: 9/10, step 109/574 completed (loss: 0.01305434387177229, acc: 1.0)
[2024-11-29 03:45:19,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:20,100][root][INFO] - Training Epoch: 9/10, step 110/574 completed (loss: 0.0503695048391819, acc: 0.9846153855323792)
[2024-11-29 03:45:20,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:20,552][root][INFO] - Training Epoch: 9/10, step 111/574 completed (loss: 0.20653021335601807, acc: 0.9298245906829834)
[2024-11-29 03:45:20,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:20,904][root][INFO] - Training Epoch: 9/10, step 112/574 completed (loss: 0.30535659193992615, acc: 0.8771929740905762)
[2024-11-29 03:45:21,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:21,200][root][INFO] - Training Epoch: 9/10, step 113/574 completed (loss: 0.10836933553218842, acc: 0.9487179517745972)
[2024-11-29 03:45:21,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:21,581][root][INFO] - Training Epoch: 9/10, step 114/574 completed (loss: 0.16332021355628967, acc: 0.9591836929321289)
[2024-11-29 03:45:21,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:21,874][root][INFO] - Training Epoch: 9/10, step 115/574 completed (loss: 0.015984760597348213, acc: 1.0)
[2024-11-29 03:45:22,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:22,225][root][INFO] - Training Epoch: 9/10, step 116/574 completed (loss: 0.33551764488220215, acc: 0.9523809552192688)
[2024-11-29 03:45:22,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:22,547][root][INFO] - Training Epoch: 9/10, step 117/574 completed (loss: 0.3872123658657074, acc: 0.8861788511276245)
[2024-11-29 03:45:22,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:22,841][root][INFO] - Training Epoch: 9/10, step 118/574 completed (loss: 0.22730636596679688, acc: 0.9516128897666931)
[2024-11-29 03:45:23,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:24,010][root][INFO] - Training Epoch: 9/10, step 119/574 completed (loss: 0.7802684307098389, acc: 0.7718631029129028)
[2024-11-29 03:45:24,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:24,316][root][INFO] - Training Epoch: 9/10, step 120/574 completed (loss: 0.06562379747629166, acc: 0.9733333587646484)
[2024-11-29 03:45:24,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:24,767][root][INFO] - Training Epoch: 9/10, step 121/574 completed (loss: 0.12744615972042084, acc: 0.9615384340286255)
[2024-11-29 03:45:24,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:25,077][root][INFO] - Training Epoch: 9/10, step 122/574 completed (loss: 0.011616737581789494, acc: 1.0)
[2024-11-29 03:45:25,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:25,381][root][INFO] - Training Epoch: 9/10, step 123/574 completed (loss: 0.11783366650342941, acc: 1.0)
[2024-11-29 03:45:25,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:25,726][root][INFO] - Training Epoch: 9/10, step 124/574 completed (loss: 0.7392548322677612, acc: 0.7730061411857605)
[2024-11-29 03:45:25,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:26,081][root][INFO] - Training Epoch: 9/10, step 125/574 completed (loss: 0.8840765953063965, acc: 0.7361111044883728)
[2024-11-29 03:45:26,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:26,434][root][INFO] - Training Epoch: 9/10, step 126/574 completed (loss: 0.6509723663330078, acc: 0.800000011920929)
[2024-11-29 03:45:27,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:27,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:28,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:28,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:29,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:29,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:29,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:30,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:30,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:31,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:31,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:32,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:32,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:32,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:33,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:33,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:34,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:34,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:35,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:35,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:35,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:36,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:36,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:36,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:37,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:37,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:38,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:38,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:39,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:39,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:39,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:40,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:40,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:41,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:41,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:42,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:42,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:43,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:43,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:44,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:44,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:45,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:45,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:46,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:46,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:47,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:47,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:47,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:48,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:48,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:49,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:49,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:49,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:50,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:50,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:51,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:51,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:52,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:52,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:52,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:53,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:54,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:54,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:55,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:55,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:55,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:56,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:56,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:57,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:57,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:58,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:58,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:59,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:45:59,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:00,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:00,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:01,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:01,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:02,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:02,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:02,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:03,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:03,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:04,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:04,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:05,461][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.0089, device='cuda:0') eval_epoch_loss=tensor(1.1016, device='cuda:0') eval_epoch_acc=tensor(0.7653, device='cuda:0')
[2024-11-29 03:46:05,462][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:46:05,462][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:46:06,050][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_9_step_127_loss_1.1015815734863281/model.pt
[2024-11-29 03:46:06,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:06,390][root][INFO] - Training Epoch: 9/10, step 127/574 completed (loss: 0.9347715973854065, acc: 0.7440476417541504)
[2024-11-29 03:46:06,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:06,702][root][INFO] - Training Epoch: 9/10, step 128/574 completed (loss: 0.6467150449752808, acc: 0.8153846263885498)
[2024-11-29 03:46:06,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:07,143][root][INFO] - Training Epoch: 9/10, step 129/574 completed (loss: 0.7646032571792603, acc: 0.7647058963775635)
[2024-11-29 03:46:07,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:07,389][root][INFO] - Training Epoch: 9/10, step 130/574 completed (loss: 0.11943940073251724, acc: 0.9615384340286255)
[2024-11-29 03:46:07,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:07,639][root][INFO] - Training Epoch: 9/10, step 131/574 completed (loss: 0.17770884931087494, acc: 0.95652174949646)
[2024-11-29 03:46:07,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:07,892][root][INFO] - Training Epoch: 9/10, step 132/574 completed (loss: 0.19480958580970764, acc: 0.96875)
[2024-11-29 03:46:08,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:08,146][root][INFO] - Training Epoch: 9/10, step 133/574 completed (loss: 0.15097613632678986, acc: 0.95652174949646)
[2024-11-29 03:46:08,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:08,400][root][INFO] - Training Epoch: 9/10, step 134/574 completed (loss: 0.11429361253976822, acc: 0.9714285731315613)
[2024-11-29 03:46:08,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:08,686][root][INFO] - Training Epoch: 9/10, step 135/574 completed (loss: 0.14114099740982056, acc: 0.9230769276618958)
[2024-11-29 03:46:08,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:08,941][root][INFO] - Training Epoch: 9/10, step 136/574 completed (loss: 0.2795009911060333, acc: 0.9523809552192688)
[2024-11-29 03:46:09,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:09,196][root][INFO] - Training Epoch: 9/10, step 137/574 completed (loss: 0.5721612572669983, acc: 0.8666666746139526)
[2024-11-29 03:46:09,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:09,448][root][INFO] - Training Epoch: 9/10, step 138/574 completed (loss: 0.0634227842092514, acc: 1.0)
[2024-11-29 03:46:09,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:09,705][root][INFO] - Training Epoch: 9/10, step 139/574 completed (loss: 0.10380558669567108, acc: 0.9523809552192688)
[2024-11-29 03:46:09,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:09,957][root][INFO] - Training Epoch: 9/10, step 140/574 completed (loss: 0.10028038918972015, acc: 0.9615384340286255)
[2024-11-29 03:46:10,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:10,232][root][INFO] - Training Epoch: 9/10, step 141/574 completed (loss: 0.16569998860359192, acc: 0.9677419066429138)
[2024-11-29 03:46:10,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:10,485][root][INFO] - Training Epoch: 9/10, step 142/574 completed (loss: 0.2698065936565399, acc: 0.9189189076423645)
[2024-11-29 03:46:10,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:11,173][root][INFO] - Training Epoch: 9/10, step 143/574 completed (loss: 0.4623687267303467, acc: 0.859649121761322)
[2024-11-29 03:46:11,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:11,489][root][INFO] - Training Epoch: 9/10, step 144/574 completed (loss: 0.6049171686172485, acc: 0.8358209133148193)
[2024-11-29 03:46:11,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:11,862][root][INFO] - Training Epoch: 9/10, step 145/574 completed (loss: 0.4572525918483734, acc: 0.8571428656578064)
[2024-11-29 03:46:12,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:12,416][root][INFO] - Training Epoch: 9/10, step 146/574 completed (loss: 0.6528283953666687, acc: 0.7978723645210266)
[2024-11-29 03:46:12,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:12,678][root][INFO] - Training Epoch: 9/10, step 147/574 completed (loss: 0.2833978533744812, acc: 0.9285714030265808)
[2024-11-29 03:46:12,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:12,940][root][INFO] - Training Epoch: 9/10, step 148/574 completed (loss: 0.1255398690700531, acc: 0.9642857313156128)
[2024-11-29 03:46:13,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:13,160][root][INFO] - Training Epoch: 9/10, step 149/574 completed (loss: 0.1585070788860321, acc: 0.9130434989929199)
[2024-11-29 03:46:13,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:13,408][root][INFO] - Training Epoch: 9/10, step 150/574 completed (loss: 0.07356288284063339, acc: 0.9655172228813171)
[2024-11-29 03:46:13,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:13,666][root][INFO] - Training Epoch: 9/10, step 151/574 completed (loss: 0.32649916410446167, acc: 0.9130434989929199)
[2024-11-29 03:46:13,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:13,954][root][INFO] - Training Epoch: 9/10, step 152/574 completed (loss: 0.37673619389533997, acc: 0.8813559412956238)
[2024-11-29 03:46:14,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:14,230][root][INFO] - Training Epoch: 9/10, step 153/574 completed (loss: 0.25544971227645874, acc: 0.9298245906829834)
[2024-11-29 03:46:14,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:14,521][root][INFO] - Training Epoch: 9/10, step 154/574 completed (loss: 0.2579275369644165, acc: 0.9459459185600281)
[2024-11-29 03:46:14,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:14,769][root][INFO] - Training Epoch: 9/10, step 155/574 completed (loss: 0.08251103013753891, acc: 0.9642857313156128)
[2024-11-29 03:46:14,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:15,016][root][INFO] - Training Epoch: 9/10, step 156/574 completed (loss: 0.12731587886810303, acc: 0.95652174949646)
[2024-11-29 03:46:15,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:15,302][root][INFO] - Training Epoch: 9/10, step 157/574 completed (loss: 2.1105892658233643, acc: 0.31578946113586426)
[2024-11-29 03:46:16,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:17,844][root][INFO] - Training Epoch: 9/10, step 158/574 completed (loss: 1.3082373142242432, acc: 0.6891891956329346)
[2024-11-29 03:46:17,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:18,111][root][INFO] - Training Epoch: 9/10, step 159/574 completed (loss: 1.0374181270599365, acc: 0.7037037014961243)
[2024-11-29 03:46:18,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:18,581][root][INFO] - Training Epoch: 9/10, step 160/574 completed (loss: 1.2463644742965698, acc: 0.6627907156944275)
[2024-11-29 03:46:19,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:19,401][root][INFO] - Training Epoch: 9/10, step 161/574 completed (loss: 1.3687576055526733, acc: 0.6823529601097107)
[2024-11-29 03:46:19,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:20,160][root][INFO] - Training Epoch: 9/10, step 162/574 completed (loss: 1.3029966354370117, acc: 0.6853932738304138)
[2024-11-29 03:46:20,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:20,439][root][INFO] - Training Epoch: 9/10, step 163/574 completed (loss: 0.3080886900424957, acc: 0.8863636255264282)
[2024-11-29 03:46:20,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:20,695][root][INFO] - Training Epoch: 9/10, step 164/574 completed (loss: 0.16477978229522705, acc: 0.9523809552192688)
[2024-11-29 03:46:20,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:20,991][root][INFO] - Training Epoch: 9/10, step 165/574 completed (loss: 1.315696358680725, acc: 0.6551724076271057)
[2024-11-29 03:46:21,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:21,264][root][INFO] - Training Epoch: 9/10, step 166/574 completed (loss: 0.0933307409286499, acc: 0.9795918464660645)
[2024-11-29 03:46:21,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:21,520][root][INFO] - Training Epoch: 9/10, step 167/574 completed (loss: 0.1042679101228714, acc: 0.9599999785423279)
[2024-11-29 03:46:21,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:21,970][root][INFO] - Training Epoch: 9/10, step 168/574 completed (loss: 0.4142935872077942, acc: 0.8888888955116272)
[2024-11-29 03:46:22,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:22,268][root][INFO] - Training Epoch: 9/10, step 169/574 completed (loss: 0.9901525974273682, acc: 0.7745097875595093)
[2024-11-29 03:46:23,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:23,806][root][INFO] - Training Epoch: 9/10, step 170/574 completed (loss: 0.9608351588249207, acc: 0.7602739930152893)
[2024-11-29 03:46:23,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:24,041][root][INFO] - Training Epoch: 9/10, step 171/574 completed (loss: 0.07157950848340988, acc: 1.0)
[2024-11-29 03:46:24,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:24,294][root][INFO] - Training Epoch: 9/10, step 172/574 completed (loss: 0.5553336143493652, acc: 0.8148148059844971)
[2024-11-29 03:46:24,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:24,559][root][INFO] - Training Epoch: 9/10, step 173/574 completed (loss: 0.1951393187046051, acc: 0.9642857313156128)
[2024-11-29 03:46:24,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:25,277][root][INFO] - Training Epoch: 9/10, step 174/574 completed (loss: 1.013321876525879, acc: 0.7256637215614319)
[2024-11-29 03:46:25,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:25,526][root][INFO] - Training Epoch: 9/10, step 175/574 completed (loss: 0.9205131530761719, acc: 0.8405796885490417)
[2024-11-29 03:46:25,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:25,817][root][INFO] - Training Epoch: 9/10, step 176/574 completed (loss: 0.2768250107765198, acc: 0.9090909361839294)
[2024-11-29 03:46:26,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:27,161][root][INFO] - Training Epoch: 9/10, step 177/574 completed (loss: 0.8174487948417664, acc: 0.7633587718009949)
[2024-11-29 03:46:27,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:28,112][root][INFO] - Training Epoch: 9/10, step 178/574 completed (loss: 0.6995114684104919, acc: 0.7851851582527161)
[2024-11-29 03:46:28,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:28,390][root][INFO] - Training Epoch: 9/10, step 179/574 completed (loss: 0.22879359126091003, acc: 0.9508196711540222)
[2024-11-29 03:46:28,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:28,648][root][INFO] - Training Epoch: 9/10, step 180/574 completed (loss: 0.00564552703872323, acc: 1.0)
[2024-11-29 03:46:28,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:28,890][root][INFO] - Training Epoch: 9/10, step 181/574 completed (loss: 0.01259082555770874, acc: 1.0)
[2024-11-29 03:46:29,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:29,138][root][INFO] - Training Epoch: 9/10, step 182/574 completed (loss: 0.15464921295642853, acc: 0.9642857313156128)
[2024-11-29 03:46:29,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:29,402][root][INFO] - Training Epoch: 9/10, step 183/574 completed (loss: 0.08871378004550934, acc: 0.9756097793579102)
[2024-11-29 03:46:29,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:29,716][root][INFO] - Training Epoch: 9/10, step 184/574 completed (loss: 0.5079584717750549, acc: 0.8580060601234436)
[2024-11-29 03:46:29,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:30,016][root][INFO] - Training Epoch: 9/10, step 185/574 completed (loss: 0.6378416419029236, acc: 0.8213256597518921)
[2024-11-29 03:46:30,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:30,626][root][INFO] - Training Epoch: 9/10, step 186/574 completed (loss: 0.5732716917991638, acc: 0.8343750238418579)
[2024-11-29 03:46:30,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:31,261][root][INFO] - Training Epoch: 9/10, step 187/574 completed (loss: 0.9029124975204468, acc: 0.7579737305641174)
[2024-11-29 03:46:31,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:31,708][root][INFO] - Training Epoch: 9/10, step 188/574 completed (loss: 0.5359147191047668, acc: 0.8505337834358215)
[2024-11-29 03:46:31,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:31,944][root][INFO] - Training Epoch: 9/10, step 189/574 completed (loss: 0.33062079548835754, acc: 0.9200000166893005)
[2024-11-29 03:46:32,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:32,700][root][INFO] - Training Epoch: 9/10, step 190/574 completed (loss: 0.5552250742912292, acc: 0.8139534592628479)
[2024-11-29 03:46:33,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:33,873][root][INFO] - Training Epoch: 9/10, step 191/574 completed (loss: 1.0232524871826172, acc: 0.6984127163887024)
[2024-11-29 03:46:34,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:35,256][root][INFO] - Training Epoch: 9/10, step 192/574 completed (loss: 1.0081050395965576, acc: 0.7121211886405945)
[2024-11-29 03:46:35,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:36,336][root][INFO] - Training Epoch: 9/10, step 193/574 completed (loss: 0.5189467072486877, acc: 0.8588235378265381)
[2024-11-29 03:46:37,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:37,980][root][INFO] - Training Epoch: 9/10, step 194/574 completed (loss: 0.865756094455719, acc: 0.7530864477157593)
[2024-11-29 03:46:38,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:39,420][root][INFO] - Training Epoch: 9/10, step 195/574 completed (loss: 0.2223534882068634, acc: 0.9516128897666931)
[2024-11-29 03:46:39,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:39,745][root][INFO] - Training Epoch: 9/10, step 196/574 completed (loss: 0.015174249187111855, acc: 1.0)
[2024-11-29 03:46:39,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:40,070][root][INFO] - Training Epoch: 9/10, step 197/574 completed (loss: 0.3513999879360199, acc: 0.875)
[2024-11-29 03:46:40,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:40,380][root][INFO] - Training Epoch: 9/10, step 198/574 completed (loss: 0.0937136709690094, acc: 0.9852941036224365)
[2024-11-29 03:46:40,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:40,672][root][INFO] - Training Epoch: 9/10, step 199/574 completed (loss: 0.8694006204605103, acc: 0.8308823704719543)
[2024-11-29 03:46:40,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:40,966][root][INFO] - Training Epoch: 9/10, step 200/574 completed (loss: 0.5687647461891174, acc: 0.8220338821411133)
[2024-11-29 03:46:41,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:41,278][root][INFO] - Training Epoch: 9/10, step 201/574 completed (loss: 0.54610276222229, acc: 0.8283582329750061)
[2024-11-29 03:46:41,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:41,642][root][INFO] - Training Epoch: 9/10, step 202/574 completed (loss: 0.4390494227409363, acc: 0.9126213788986206)
[2024-11-29 03:46:41,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:41,958][root][INFO] - Training Epoch: 9/10, step 203/574 completed (loss: 0.38636574149131775, acc: 0.920634925365448)
[2024-11-29 03:46:42,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:42,225][root][INFO] - Training Epoch: 9/10, step 204/574 completed (loss: 0.10412020236253738, acc: 0.9780219793319702)
[2024-11-29 03:46:42,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:42,587][root][INFO] - Training Epoch: 9/10, step 205/574 completed (loss: 0.23590898513793945, acc: 0.9237667918205261)
[2024-11-29 03:46:42,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:43,024][root][INFO] - Training Epoch: 9/10, step 206/574 completed (loss: 0.46859097480773926, acc: 0.8779527544975281)
[2024-11-29 03:46:43,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:43,358][root][INFO] - Training Epoch: 9/10, step 207/574 completed (loss: 0.20550228655338287, acc: 0.943965494632721)
[2024-11-29 03:46:43,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:43,733][root][INFO] - Training Epoch: 9/10, step 208/574 completed (loss: 0.31159672141075134, acc: 0.9311594367027283)
[2024-11-29 03:46:43,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:44,102][root][INFO] - Training Epoch: 9/10, step 209/574 completed (loss: 0.278659850358963, acc: 0.9143968820571899)
[2024-11-29 03:46:44,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:44,387][root][INFO] - Training Epoch: 9/10, step 210/574 completed (loss: 0.279459148645401, acc: 0.9239130616188049)
[2024-11-29 03:46:44,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:44,669][root][INFO] - Training Epoch: 9/10, step 211/574 completed (loss: 0.0348195917904377, acc: 1.0)
[2024-11-29 03:46:44,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:44,990][root][INFO] - Training Epoch: 9/10, step 212/574 completed (loss: 0.12027662992477417, acc: 0.9285714030265808)
[2024-11-29 03:46:45,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:45,301][root][INFO] - Training Epoch: 9/10, step 213/574 completed (loss: 0.33293402194976807, acc: 0.914893627166748)
[2024-11-29 03:46:45,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:46,260][root][INFO] - Training Epoch: 9/10, step 214/574 completed (loss: 0.144395112991333, acc: 0.9769230484962463)
[2024-11-29 03:46:46,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:46,588][root][INFO] - Training Epoch: 9/10, step 215/574 completed (loss: 0.05382310599088669, acc: 0.9864864945411682)
[2024-11-29 03:46:46,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:46,935][root][INFO] - Training Epoch: 9/10, step 216/574 completed (loss: 0.029588591307401657, acc: 1.0)
[2024-11-29 03:46:47,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:47,651][root][INFO] - Training Epoch: 9/10, step 217/574 completed (loss: 0.1310640573501587, acc: 0.9639639854431152)
[2024-11-29 03:46:47,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:48,100][root][INFO] - Training Epoch: 9/10, step 218/574 completed (loss: 0.14818647503852844, acc: 0.9777777791023254)
[2024-11-29 03:46:48,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:48,354][root][INFO] - Training Epoch: 9/10, step 219/574 completed (loss: 0.04241231828927994, acc: 0.9696969985961914)
[2024-11-29 03:46:48,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:48,622][root][INFO] - Training Epoch: 9/10, step 220/574 completed (loss: 0.024580422788858414, acc: 1.0)
[2024-11-29 03:46:48,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:48,939][root][INFO] - Training Epoch: 9/10, step 221/574 completed (loss: 0.0801563486456871, acc: 0.9599999785423279)
[2024-11-29 03:46:49,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:49,246][root][INFO] - Training Epoch: 9/10, step 222/574 completed (loss: 0.25659120082855225, acc: 0.9230769276618958)
[2024-11-29 03:46:49,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:50,388][root][INFO] - Training Epoch: 9/10, step 223/574 completed (loss: 0.3459905683994293, acc: 0.9130434989929199)
[2024-11-29 03:46:50,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:51,109][root][INFO] - Training Epoch: 9/10, step 224/574 completed (loss: 0.4019218385219574, acc: 0.875)
[2024-11-29 03:46:51,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:51,647][root][INFO] - Training Epoch: 9/10, step 225/574 completed (loss: 0.44822365045547485, acc: 0.8510638475418091)
[2024-11-29 03:46:51,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:51,997][root][INFO] - Training Epoch: 9/10, step 226/574 completed (loss: 0.10991552472114563, acc: 1.0)
[2024-11-29 03:46:52,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:52,365][root][INFO] - Training Epoch: 9/10, step 227/574 completed (loss: 0.12199001014232635, acc: 0.9666666388511658)
[2024-11-29 03:46:52,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:52,723][root][INFO] - Training Epoch: 9/10, step 228/574 completed (loss: 0.6881522536277771, acc: 0.8604651093482971)
[2024-11-29 03:46:52,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:53,083][root][INFO] - Training Epoch: 9/10, step 229/574 completed (loss: 1.288796305656433, acc: 0.6666666865348816)
[2024-11-29 03:46:53,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:53,461][root][INFO] - Training Epoch: 9/10, step 230/574 completed (loss: 1.9362356662750244, acc: 0.5052631497383118)
[2024-11-29 03:46:53,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:53,784][root][INFO] - Training Epoch: 9/10, step 231/574 completed (loss: 1.6301623582839966, acc: 0.6111111044883728)
[2024-11-29 03:46:54,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:54,304][root][INFO] - Training Epoch: 9/10, step 232/574 completed (loss: 1.7421754598617554, acc: 0.5777778029441833)
[2024-11-29 03:46:54,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:54,931][root][INFO] - Training Epoch: 9/10, step 233/574 completed (loss: 2.263402223587036, acc: 0.4403669834136963)
[2024-11-29 03:46:55,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:55,530][root][INFO] - Training Epoch: 9/10, step 234/574 completed (loss: 1.6187068223953247, acc: 0.5230769515037537)
[2024-11-29 03:46:55,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:55,759][root][INFO] - Training Epoch: 9/10, step 235/574 completed (loss: 0.02624254673719406, acc: 1.0)
[2024-11-29 03:46:55,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:56,061][root][INFO] - Training Epoch: 9/10, step 236/574 completed (loss: 0.030595457181334496, acc: 1.0)
[2024-11-29 03:46:56,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:56,363][root][INFO] - Training Epoch: 9/10, step 237/574 completed (loss: 0.3301483690738678, acc: 0.9090909361839294)
[2024-11-29 03:46:56,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:56,637][root][INFO] - Training Epoch: 9/10, step 238/574 completed (loss: 0.317214697599411, acc: 0.9259259104728699)
[2024-11-29 03:46:56,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:56,894][root][INFO] - Training Epoch: 9/10, step 239/574 completed (loss: 0.48939481377601624, acc: 0.8857142925262451)
[2024-11-29 03:46:57,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:57,240][root][INFO] - Training Epoch: 9/10, step 240/574 completed (loss: 0.4194850027561188, acc: 0.8636363744735718)
[2024-11-29 03:46:57,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:57,535][root][INFO] - Training Epoch: 9/10, step 241/574 completed (loss: 0.07378050684928894, acc: 1.0)
[2024-11-29 03:46:58,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:58,355][root][INFO] - Training Epoch: 9/10, step 242/574 completed (loss: 0.44463443756103516, acc: 0.8548387289047241)
[2024-11-29 03:46:58,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:59,071][root][INFO] - Training Epoch: 9/10, step 243/574 completed (loss: 0.3758753836154938, acc: 0.9090909361839294)
[2024-11-29 03:46:59,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:59,374][root][INFO] - Training Epoch: 9/10, step 244/574 completed (loss: 0.013646779581904411, acc: 1.0)
[2024-11-29 03:46:59,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:59,663][root][INFO] - Training Epoch: 9/10, step 245/574 completed (loss: 0.28471675515174866, acc: 0.9615384340286255)
[2024-11-29 03:46:59,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:46:59,904][root][INFO] - Training Epoch: 9/10, step 246/574 completed (loss: 0.02269274927675724, acc: 1.0)
[2024-11-29 03:47:00,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:00,160][root][INFO] - Training Epoch: 9/10, step 247/574 completed (loss: 0.04592986777424812, acc: 1.0)
[2024-11-29 03:47:00,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:00,533][root][INFO] - Training Epoch: 9/10, step 248/574 completed (loss: 0.15095087885856628, acc: 0.9459459185600281)
[2024-11-29 03:47:00,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:00,814][root][INFO] - Training Epoch: 9/10, step 249/574 completed (loss: 0.1548624038696289, acc: 0.9459459185600281)
[2024-11-29 03:47:01,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:01,156][root][INFO] - Training Epoch: 9/10, step 250/574 completed (loss: 0.072667196393013, acc: 0.9729729890823364)
[2024-11-29 03:47:01,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:01,454][root][INFO] - Training Epoch: 9/10, step 251/574 completed (loss: 0.052288759499788284, acc: 0.9852941036224365)
[2024-11-29 03:47:01,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:01,754][root][INFO] - Training Epoch: 9/10, step 252/574 completed (loss: 0.06225983798503876, acc: 0.9756097793579102)
[2024-11-29 03:47:01,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:02,019][root][INFO] - Training Epoch: 9/10, step 253/574 completed (loss: 0.05117696151137352, acc: 1.0)
[2024-11-29 03:47:02,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:02,342][root][INFO] - Training Epoch: 9/10, step 254/574 completed (loss: 0.022334657609462738, acc: 1.0)
[2024-11-29 03:47:02,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:02,625][root][INFO] - Training Epoch: 9/10, step 255/574 completed (loss: 0.09972874820232391, acc: 0.9032257795333862)
[2024-11-29 03:47:02,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:02,891][root][INFO] - Training Epoch: 9/10, step 256/574 completed (loss: 0.11315102130174637, acc: 0.9649122953414917)
[2024-11-29 03:47:03,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:03,152][root][INFO] - Training Epoch: 9/10, step 257/574 completed (loss: 0.15566542744636536, acc: 0.9428571462631226)
[2024-11-29 03:47:03,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:03,424][root][INFO] - Training Epoch: 9/10, step 258/574 completed (loss: 0.08909163624048233, acc: 0.9736841917037964)
[2024-11-29 03:47:03,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:04,210][root][INFO] - Training Epoch: 9/10, step 259/574 completed (loss: 0.22148571908473969, acc: 0.9245283007621765)
[2024-11-29 03:47:04,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:04,995][root][INFO] - Training Epoch: 9/10, step 260/574 completed (loss: 0.3920529782772064, acc: 0.9083333611488342)
[2024-11-29 03:47:05,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:05,237][root][INFO] - Training Epoch: 9/10, step 261/574 completed (loss: 0.06844297051429749, acc: 0.9722222089767456)
[2024-11-29 03:47:05,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:05,491][root][INFO] - Training Epoch: 9/10, step 262/574 completed (loss: 0.17856402695178986, acc: 0.9032257795333862)
[2024-11-29 03:47:05,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:05,837][root][INFO] - Training Epoch: 9/10, step 263/574 completed (loss: 0.5529041290283203, acc: 0.8533333539962769)
[2024-11-29 03:47:05,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:06,107][root][INFO] - Training Epoch: 9/10, step 264/574 completed (loss: 0.4040120840072632, acc: 0.8333333134651184)
[2024-11-29 03:47:06,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:07,320][root][INFO] - Training Epoch: 9/10, step 265/574 completed (loss: 1.0198290348052979, acc: 0.7120000123977661)
[2024-11-29 03:47:07,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:07,626][root][INFO] - Training Epoch: 9/10, step 266/574 completed (loss: 0.6201897263526917, acc: 0.7752808928489685)
[2024-11-29 03:47:07,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:07,981][root][INFO] - Training Epoch: 9/10, step 267/574 completed (loss: 0.4506208002567291, acc: 0.8918918967247009)
[2024-11-29 03:47:08,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:08,548][root][INFO] - Training Epoch: 9/10, step 268/574 completed (loss: 0.439180463552475, acc: 0.8620689511299133)
[2024-11-29 03:47:08,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:08,872][root][INFO] - Training Epoch: 9/10, step 269/574 completed (loss: 0.03644808754324913, acc: 1.0)
[2024-11-29 03:47:09,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:10,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:10,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:11,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:11,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:12,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:12,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:12,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:13,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:13,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:14,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:14,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:15,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:15,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:16,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:16,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:16,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:17,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:17,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:17,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:18,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:18,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:18,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:19,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:19,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:20,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:20,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:21,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:21,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:21,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:22,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:22,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:23,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:23,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:24,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:24,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:24,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:25,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:25,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:26,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:26,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:26,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:27,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:27,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:28,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:28,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:29,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:29,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:30,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:30,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:30,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:31,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:31,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:32,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:32,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:33,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:33,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:33,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:34,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:34,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:35,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:35,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:36,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:36,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:37,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:37,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:38,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:38,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:39,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:39,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:40,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:40,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:41,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:41,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:42,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:42,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:42,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:43,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:43,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:44,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:44,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:45,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:45,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:45,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:46,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:46,829][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.0128, device='cuda:0') eval_epoch_loss=tensor(1.1029, device='cuda:0') eval_epoch_acc=tensor(0.7615, device='cuda:0')
[2024-11-29 03:47:46,831][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:47:46,831][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:47:47,248][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_9_step_270_loss_1.1028718948364258/model.pt
[2024-11-29 03:47:47,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:47,542][root][INFO] - Training Epoch: 9/10, step 270/574 completed (loss: 0.14037637412548065, acc: 0.9545454382896423)
[2024-11-29 03:47:47,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:47,825][root][INFO] - Training Epoch: 9/10, step 271/574 completed (loss: 0.17971105873584747, acc: 0.96875)
[2024-11-29 03:47:48,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:48,139][root][INFO] - Training Epoch: 9/10, step 272/574 completed (loss: 0.010245230980217457, acc: 1.0)
[2024-11-29 03:47:48,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:48,562][root][INFO] - Training Epoch: 9/10, step 273/574 completed (loss: 0.2620624303817749, acc: 0.9166666865348816)
[2024-11-29 03:47:48,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:48,834][root][INFO] - Training Epoch: 9/10, step 274/574 completed (loss: 0.06883738934993744, acc: 0.96875)
[2024-11-29 03:47:48,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:49,105][root][INFO] - Training Epoch: 9/10, step 275/574 completed (loss: 0.09479312598705292, acc: 0.9333333373069763)
[2024-11-29 03:47:49,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:49,366][root][INFO] - Training Epoch: 9/10, step 276/574 completed (loss: 0.10054124146699905, acc: 0.9655172228813171)
[2024-11-29 03:47:49,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:49,626][root][INFO] - Training Epoch: 9/10, step 277/574 completed (loss: 0.011811885982751846, acc: 1.0)
[2024-11-29 03:47:49,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:49,890][root][INFO] - Training Epoch: 9/10, step 278/574 completed (loss: 0.49106365442276, acc: 0.8723404407501221)
[2024-11-29 03:47:50,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:50,187][root][INFO] - Training Epoch: 9/10, step 279/574 completed (loss: 0.17749284207820892, acc: 0.9375)
[2024-11-29 03:47:50,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:50,462][root][INFO] - Training Epoch: 9/10, step 280/574 completed (loss: 0.062020231038331985, acc: 0.9545454382896423)
[2024-11-29 03:47:50,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:50,971][root][INFO] - Training Epoch: 9/10, step 281/574 completed (loss: 0.5134676694869995, acc: 0.8192771077156067)
[2024-11-29 03:47:51,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:51,327][root][INFO] - Training Epoch: 9/10, step 282/574 completed (loss: 0.8294478058815002, acc: 0.7314814925193787)
[2024-11-29 03:47:51,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:51,591][root][INFO] - Training Epoch: 9/10, step 283/574 completed (loss: 0.08165892213582993, acc: 0.9736841917037964)
[2024-11-29 03:47:51,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:51,841][root][INFO] - Training Epoch: 9/10, step 284/574 completed (loss: 0.18518507480621338, acc: 0.9411764740943909)
[2024-11-29 03:47:51,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:52,095][root][INFO] - Training Epoch: 9/10, step 285/574 completed (loss: 0.1956363171339035, acc: 0.949999988079071)
[2024-11-29 03:47:52,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:52,365][root][INFO] - Training Epoch: 9/10, step 286/574 completed (loss: 0.22820650041103363, acc: 0.9296875)
[2024-11-29 03:47:52,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:52,688][root][INFO] - Training Epoch: 9/10, step 287/574 completed (loss: 0.4579598009586334, acc: 0.8799999952316284)
[2024-11-29 03:47:52,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:52,952][root][INFO] - Training Epoch: 9/10, step 288/574 completed (loss: 0.20758932828903198, acc: 0.9340659379959106)
[2024-11-29 03:47:53,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:53,210][root][INFO] - Training Epoch: 9/10, step 289/574 completed (loss: 0.2501746416091919, acc: 0.9254658222198486)
[2024-11-29 03:47:53,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:53,541][root][INFO] - Training Epoch: 9/10, step 290/574 completed (loss: 0.4126286506652832, acc: 0.876288652420044)
[2024-11-29 03:47:53,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:53,791][root][INFO] - Training Epoch: 9/10, step 291/574 completed (loss: 0.03182157501578331, acc: 1.0)
[2024-11-29 03:47:53,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:54,045][root][INFO] - Training Epoch: 9/10, step 292/574 completed (loss: 0.21491773426532745, acc: 0.9047619104385376)
[2024-11-29 03:47:54,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:54,328][root][INFO] - Training Epoch: 9/10, step 293/574 completed (loss: 0.09726493060588837, acc: 0.982758641242981)
[2024-11-29 03:47:54,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:54,946][root][INFO] - Training Epoch: 9/10, step 294/574 completed (loss: 0.31586235761642456, acc: 0.8909090757369995)
[2024-11-29 03:47:55,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:55,663][root][INFO] - Training Epoch: 9/10, step 295/574 completed (loss: 0.7196347117424011, acc: 0.7989690899848938)
[2024-11-29 03:47:55,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:55,921][root][INFO] - Training Epoch: 9/10, step 296/574 completed (loss: 0.2904713749885559, acc: 0.931034505367279)
[2024-11-29 03:47:56,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:56,200][root][INFO] - Training Epoch: 9/10, step 297/574 completed (loss: 0.048847220838069916, acc: 1.0)
[2024-11-29 03:47:56,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:56,539][root][INFO] - Training Epoch: 9/10, step 298/574 completed (loss: 0.3799585998058319, acc: 0.9473684430122375)
[2024-11-29 03:47:56,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:56,856][root][INFO] - Training Epoch: 9/10, step 299/574 completed (loss: 0.039235860109329224, acc: 1.0)
[2024-11-29 03:47:56,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:57,125][root][INFO] - Training Epoch: 9/10, step 300/574 completed (loss: 0.0062132119201123714, acc: 1.0)
[2024-11-29 03:47:57,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:57,440][root][INFO] - Training Epoch: 9/10, step 301/574 completed (loss: 0.022652851417660713, acc: 1.0)
[2024-11-29 03:47:57,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:57,711][root][INFO] - Training Epoch: 9/10, step 302/574 completed (loss: 0.014306489378213882, acc: 1.0)
[2024-11-29 03:47:57,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:57,970][root][INFO] - Training Epoch: 9/10, step 303/574 completed (loss: 0.02881506457924843, acc: 1.0)
[2024-11-29 03:47:58,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:58,224][root][INFO] - Training Epoch: 9/10, step 304/574 completed (loss: 0.017198676243424416, acc: 1.0)
[2024-11-29 03:47:58,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:58,521][root][INFO] - Training Epoch: 9/10, step 305/574 completed (loss: 0.23158124089241028, acc: 0.9016393423080444)
[2024-11-29 03:47:58,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:58,774][root][INFO] - Training Epoch: 9/10, step 306/574 completed (loss: 0.17599795758724213, acc: 0.9333333373069763)
[2024-11-29 03:47:58,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:59,021][root][INFO] - Training Epoch: 9/10, step 307/574 completed (loss: 0.00950197409838438, acc: 1.0)
[2024-11-29 03:47:59,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:59,288][root][INFO] - Training Epoch: 9/10, step 308/574 completed (loss: 0.12538963556289673, acc: 0.95652174949646)
[2024-11-29 03:47:59,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:47:59,776][root][INFO] - Training Epoch: 9/10, step 309/574 completed (loss: 0.09570401161909103, acc: 0.9861111044883728)
[2024-11-29 03:47:59,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:00,037][root][INFO] - Training Epoch: 9/10, step 310/574 completed (loss: 0.10919634252786636, acc: 0.9759036302566528)
[2024-11-29 03:48:00,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:00,303][root][INFO] - Training Epoch: 9/10, step 311/574 completed (loss: 0.13261045515537262, acc: 0.9615384340286255)
[2024-11-29 03:48:00,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:00,658][root][INFO] - Training Epoch: 9/10, step 312/574 completed (loss: 0.12650997936725616, acc: 0.9693877696990967)
[2024-11-29 03:48:00,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:00,907][root][INFO] - Training Epoch: 9/10, step 313/574 completed (loss: 0.017055435106158257, acc: 1.0)
[2024-11-29 03:48:01,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:01,154][root][INFO] - Training Epoch: 9/10, step 314/574 completed (loss: 0.011372137814760208, acc: 1.0)
[2024-11-29 03:48:01,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:01,412][root][INFO] - Training Epoch: 9/10, step 315/574 completed (loss: 0.052452873438596725, acc: 0.9677419066429138)
[2024-11-29 03:48:01,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:01,664][root][INFO] - Training Epoch: 9/10, step 316/574 completed (loss: 0.8628187775611877, acc: 0.8064516186714172)
[2024-11-29 03:48:01,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:01,975][root][INFO] - Training Epoch: 9/10, step 317/574 completed (loss: 0.05586361512541771, acc: 1.0)
[2024-11-29 03:48:02,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:02,270][root][INFO] - Training Epoch: 9/10, step 318/574 completed (loss: 0.09594258666038513, acc: 0.9903846383094788)
[2024-11-29 03:48:02,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:02,518][root][INFO] - Training Epoch: 9/10, step 319/574 completed (loss: 0.08074160665273666, acc: 0.9555555582046509)
[2024-11-29 03:48:02,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:02,765][root][INFO] - Training Epoch: 9/10, step 320/574 completed (loss: 0.018297791481018066, acc: 1.0)
[2024-11-29 03:48:02,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:03,013][root][INFO] - Training Epoch: 9/10, step 321/574 completed (loss: 0.005520442500710487, acc: 1.0)
[2024-11-29 03:48:03,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:03,266][root][INFO] - Training Epoch: 9/10, step 322/574 completed (loss: 0.370883971452713, acc: 0.8148148059844971)
[2024-11-29 03:48:03,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:03,525][root][INFO] - Training Epoch: 9/10, step 323/574 completed (loss: 1.0355725288391113, acc: 0.7428571581840515)
[2024-11-29 03:48:03,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:03,840][root][INFO] - Training Epoch: 9/10, step 324/574 completed (loss: 0.38331323862075806, acc: 0.8974359035491943)
[2024-11-29 03:48:04,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:04,132][root][INFO] - Training Epoch: 9/10, step 325/574 completed (loss: 1.1794663667678833, acc: 0.6829268336296082)
[2024-11-29 03:48:04,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:04,394][root][INFO] - Training Epoch: 9/10, step 326/574 completed (loss: 0.4368493854999542, acc: 0.8684210777282715)
[2024-11-29 03:48:04,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:04,664][root][INFO] - Training Epoch: 9/10, step 327/574 completed (loss: 0.35114502906799316, acc: 0.8947368264198303)
[2024-11-29 03:48:04,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:04,952][root][INFO] - Training Epoch: 9/10, step 328/574 completed (loss: 0.02082391455769539, acc: 1.0)
[2024-11-29 03:48:05,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:05,221][root][INFO] - Training Epoch: 9/10, step 329/574 completed (loss: 0.008210631087422371, acc: 1.0)
[2024-11-29 03:48:05,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:05,480][root][INFO] - Training Epoch: 9/10, step 330/574 completed (loss: 0.0036429613828659058, acc: 1.0)
[2024-11-29 03:48:05,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:05,758][root][INFO] - Training Epoch: 9/10, step 331/574 completed (loss: 0.1020861491560936, acc: 0.9677419066429138)
[2024-11-29 03:48:05,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:06,154][root][INFO] - Training Epoch: 9/10, step 332/574 completed (loss: 0.03368757665157318, acc: 1.0)
[2024-11-29 03:48:06,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:06,463][root][INFO] - Training Epoch: 9/10, step 333/574 completed (loss: 0.1506071388721466, acc: 0.96875)
[2024-11-29 03:48:06,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:06,788][root][INFO] - Training Epoch: 9/10, step 334/574 completed (loss: 0.026544498279690742, acc: 1.0)
[2024-11-29 03:48:06,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:07,045][root][INFO] - Training Epoch: 9/10, step 335/574 completed (loss: 0.010104290209710598, acc: 1.0)
[2024-11-29 03:48:07,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:07,314][root][INFO] - Training Epoch: 9/10, step 336/574 completed (loss: 0.4209130108356476, acc: 0.8600000143051147)
[2024-11-29 03:48:07,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:07,641][root][INFO] - Training Epoch: 9/10, step 337/574 completed (loss: 0.7140510678291321, acc: 0.7931034564971924)
[2024-11-29 03:48:07,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:07,956][root][INFO] - Training Epoch: 9/10, step 338/574 completed (loss: 0.7915395498275757, acc: 0.7765957713127136)
[2024-11-29 03:48:08,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:08,245][root][INFO] - Training Epoch: 9/10, step 339/574 completed (loss: 0.7009061574935913, acc: 0.8313252925872803)
[2024-11-29 03:48:08,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:08,504][root][INFO] - Training Epoch: 9/10, step 340/574 completed (loss: 0.014259245246648788, acc: 1.0)
[2024-11-29 03:48:08,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:08,750][root][INFO] - Training Epoch: 9/10, step 341/574 completed (loss: 0.17480778694152832, acc: 0.9487179517745972)
[2024-11-29 03:48:08,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:09,021][root][INFO] - Training Epoch: 9/10, step 342/574 completed (loss: 0.1720445305109024, acc: 0.9638554453849792)
[2024-11-29 03:48:09,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:09,273][root][INFO] - Training Epoch: 9/10, step 343/574 completed (loss: 0.8191163539886475, acc: 0.7924528121948242)
[2024-11-29 03:48:09,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:09,527][root][INFO] - Training Epoch: 9/10, step 344/574 completed (loss: 0.11892924457788467, acc: 0.9620253443717957)
[2024-11-29 03:48:09,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:09,788][root][INFO] - Training Epoch: 9/10, step 345/574 completed (loss: 0.07015905529260635, acc: 0.9803921580314636)
[2024-11-29 03:48:09,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:10,041][root][INFO] - Training Epoch: 9/10, step 346/574 completed (loss: 0.12051116675138474, acc: 0.9701492786407471)
[2024-11-29 03:48:10,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:10,292][root][INFO] - Training Epoch: 9/10, step 347/574 completed (loss: 0.06656321883201599, acc: 0.949999988079071)
[2024-11-29 03:48:10,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:10,600][root][INFO] - Training Epoch: 9/10, step 348/574 completed (loss: 0.29439008235931396, acc: 0.9200000166893005)
[2024-11-29 03:48:10,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:11,041][root][INFO] - Training Epoch: 9/10, step 349/574 completed (loss: 0.4001120328903198, acc: 0.8333333134651184)
[2024-11-29 03:48:11,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:11,307][root][INFO] - Training Epoch: 9/10, step 350/574 completed (loss: 0.24511700868606567, acc: 0.930232584476471)
[2024-11-29 03:48:11,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:11,601][root][INFO] - Training Epoch: 9/10, step 351/574 completed (loss: 0.09151306003332138, acc: 0.9743589758872986)
[2024-11-29 03:48:11,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:12,003][root][INFO] - Training Epoch: 9/10, step 352/574 completed (loss: 0.3287850022315979, acc: 0.8444444537162781)
[2024-11-29 03:48:12,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:12,250][root][INFO] - Training Epoch: 9/10, step 353/574 completed (loss: 0.003760342253372073, acc: 1.0)
[2024-11-29 03:48:12,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:12,508][root][INFO] - Training Epoch: 9/10, step 354/574 completed (loss: 0.15928244590759277, acc: 0.9615384340286255)
[2024-11-29 03:48:12,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:12,828][root][INFO] - Training Epoch: 9/10, step 355/574 completed (loss: 0.3418843746185303, acc: 0.8681318759918213)
[2024-11-29 03:48:13,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:13,496][root][INFO] - Training Epoch: 9/10, step 356/574 completed (loss: 0.3287273347377777, acc: 0.886956512928009)
[2024-11-29 03:48:13,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:13,821][root][INFO] - Training Epoch: 9/10, step 357/574 completed (loss: 0.19323758780956268, acc: 0.9239130616188049)
[2024-11-29 03:48:14,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:14,131][root][INFO] - Training Epoch: 9/10, step 358/574 completed (loss: 0.0770326554775238, acc: 0.9795918464660645)
[2024-11-29 03:48:14,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:14,380][root][INFO] - Training Epoch: 9/10, step 359/574 completed (loss: 0.002291325479745865, acc: 1.0)
[2024-11-29 03:48:14,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:14,723][root][INFO] - Training Epoch: 9/10, step 360/574 completed (loss: 0.154374897480011, acc: 0.9615384340286255)
[2024-11-29 03:48:14,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:15,045][root][INFO] - Training Epoch: 9/10, step 361/574 completed (loss: 0.44526147842407227, acc: 0.8292682766914368)
[2024-11-29 03:48:15,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:15,383][root][INFO] - Training Epoch: 9/10, step 362/574 completed (loss: 0.35226428508758545, acc: 0.9333333373069763)
[2024-11-29 03:48:15,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:15,681][root][INFO] - Training Epoch: 9/10, step 363/574 completed (loss: 0.06176769733428955, acc: 0.9868420958518982)
[2024-11-29 03:48:15,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:15,957][root][INFO] - Training Epoch: 9/10, step 364/574 completed (loss: 0.052565593272447586, acc: 1.0)
[2024-11-29 03:48:16,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:16,240][root][INFO] - Training Epoch: 9/10, step 365/574 completed (loss: 0.019112976267933846, acc: 1.0)
[2024-11-29 03:48:16,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:16,548][root][INFO] - Training Epoch: 9/10, step 366/574 completed (loss: 0.007798371836543083, acc: 1.0)
[2024-11-29 03:48:16,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:16,856][root][INFO] - Training Epoch: 9/10, step 367/574 completed (loss: 0.006438866723328829, acc: 1.0)
[2024-11-29 03:48:17,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:17,222][root][INFO] - Training Epoch: 9/10, step 368/574 completed (loss: 0.015297623351216316, acc: 1.0)
[2024-11-29 03:48:17,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:17,507][root][INFO] - Training Epoch: 9/10, step 369/574 completed (loss: 0.523459792137146, acc: 0.84375)
[2024-11-29 03:48:17,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:18,326][root][INFO] - Training Epoch: 9/10, step 370/574 completed (loss: 0.4735183119773865, acc: 0.8727272748947144)
[2024-11-29 03:48:19,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:19,551][root][INFO] - Training Epoch: 9/10, step 371/574 completed (loss: 0.15401937067508698, acc: 0.9339622855186462)
[2024-11-29 03:48:19,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:19,867][root][INFO] - Training Epoch: 9/10, step 372/574 completed (loss: 0.1727602481842041, acc: 0.9444444179534912)
[2024-11-29 03:48:20,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:20,158][root][INFO] - Training Epoch: 9/10, step 373/574 completed (loss: 0.05435126647353172, acc: 0.9821428656578064)
[2024-11-29 03:48:20,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:20,442][root][INFO] - Training Epoch: 9/10, step 374/574 completed (loss: 0.42741093039512634, acc: 0.9428571462631226)
[2024-11-29 03:48:20,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:20,696][root][INFO] - Training Epoch: 9/10, step 375/574 completed (loss: 0.03787139803171158, acc: 0.9599999785423279)
[2024-11-29 03:48:20,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:21,025][root][INFO] - Training Epoch: 9/10, step 376/574 completed (loss: 0.0023802302312105894, acc: 1.0)
[2024-11-29 03:48:21,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:21,333][root][INFO] - Training Epoch: 9/10, step 377/574 completed (loss: 0.08992382138967514, acc: 1.0)
[2024-11-29 03:48:21,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:21,724][root][INFO] - Training Epoch: 9/10, step 378/574 completed (loss: 0.05791979283094406, acc: 0.9789473414421082)
[2024-11-29 03:48:22,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:22,544][root][INFO] - Training Epoch: 9/10, step 379/574 completed (loss: 0.23777714371681213, acc: 0.9341317415237427)
[2024-11-29 03:48:22,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:23,008][root][INFO] - Training Epoch: 9/10, step 380/574 completed (loss: 0.3095242381095886, acc: 0.8947368264198303)
[2024-11-29 03:48:24,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:24,815][root][INFO] - Training Epoch: 9/10, step 381/574 completed (loss: 0.5466811060905457, acc: 0.8395721912384033)
[2024-11-29 03:48:25,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:25,577][root][INFO] - Training Epoch: 9/10, step 382/574 completed (loss: 0.17001624405384064, acc: 0.9369369149208069)
[2024-11-29 03:48:25,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:25,862][root][INFO] - Training Epoch: 9/10, step 383/574 completed (loss: 0.3612990379333496, acc: 0.9285714030265808)
[2024-11-29 03:48:26,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:26,158][root][INFO] - Training Epoch: 9/10, step 384/574 completed (loss: 0.020788798108696938, acc: 1.0)
[2024-11-29 03:48:26,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:26,455][root][INFO] - Training Epoch: 9/10, step 385/574 completed (loss: 0.013468912802636623, acc: 1.0)
[2024-11-29 03:48:26,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:26,716][root][INFO] - Training Epoch: 9/10, step 386/574 completed (loss: 0.010401668958365917, acc: 1.0)
[2024-11-29 03:48:26,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:27,003][root][INFO] - Training Epoch: 9/10, step 387/574 completed (loss: 0.053299445658922195, acc: 0.9736841917037964)
[2024-11-29 03:48:27,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:27,294][root][INFO] - Training Epoch: 9/10, step 388/574 completed (loss: 0.0049654762260615826, acc: 1.0)
[2024-11-29 03:48:27,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:27,575][root][INFO] - Training Epoch: 9/10, step 389/574 completed (loss: 0.019452545791864395, acc: 1.0)
[2024-11-29 03:48:27,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:27,895][root][INFO] - Training Epoch: 9/10, step 390/574 completed (loss: 0.22086511552333832, acc: 1.0)
[2024-11-29 03:48:28,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:28,240][root][INFO] - Training Epoch: 9/10, step 391/574 completed (loss: 0.7333970069885254, acc: 0.7777777910232544)
[2024-11-29 03:48:28,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:28,569][root][INFO] - Training Epoch: 9/10, step 392/574 completed (loss: 0.6165708303451538, acc: 0.8349514603614807)
[2024-11-29 03:48:28,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:29,246][root][INFO] - Training Epoch: 9/10, step 393/574 completed (loss: 0.8218371272087097, acc: 0.8014705777168274)
[2024-11-29 03:48:29,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:29,635][root][INFO] - Training Epoch: 9/10, step 394/574 completed (loss: 0.5530820488929749, acc: 0.8399999737739563)
[2024-11-29 03:48:29,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:30,070][root][INFO] - Training Epoch: 9/10, step 395/574 completed (loss: 0.4527089297771454, acc: 0.875)
[2024-11-29 03:48:30,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:30,389][root][INFO] - Training Epoch: 9/10, step 396/574 completed (loss: 0.0290717501193285, acc: 1.0)
[2024-11-29 03:48:30,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:30,676][root][INFO] - Training Epoch: 9/10, step 397/574 completed (loss: 0.10251029580831528, acc: 0.9583333134651184)
[2024-11-29 03:48:30,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:31,012][root][INFO] - Training Epoch: 9/10, step 398/574 completed (loss: 0.13217169046401978, acc: 0.9767441749572754)
[2024-11-29 03:48:31,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:31,359][root][INFO] - Training Epoch: 9/10, step 399/574 completed (loss: 0.14568115770816803, acc: 0.9599999785423279)
[2024-11-29 03:48:31,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:32,110][root][INFO] - Training Epoch: 9/10, step 400/574 completed (loss: 0.1728380024433136, acc: 0.9411764740943909)
[2024-11-29 03:48:32,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:32,432][root][INFO] - Training Epoch: 9/10, step 401/574 completed (loss: 0.2558610141277313, acc: 0.9066666960716248)
[2024-11-29 03:48:32,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:32,704][root][INFO] - Training Epoch: 9/10, step 402/574 completed (loss: 0.10585468262434006, acc: 0.9696969985961914)
[2024-11-29 03:48:32,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:32,977][root][INFO] - Training Epoch: 9/10, step 403/574 completed (loss: 0.255291610956192, acc: 0.939393937587738)
[2024-11-29 03:48:33,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:33,284][root][INFO] - Training Epoch: 9/10, step 404/574 completed (loss: 0.2727973461151123, acc: 0.9032257795333862)
[2024-11-29 03:48:33,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:33,582][root][INFO] - Training Epoch: 9/10, step 405/574 completed (loss: 0.061062440276145935, acc: 0.9629629850387573)
[2024-11-29 03:48:33,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:33,857][root][INFO] - Training Epoch: 9/10, step 406/574 completed (loss: 0.03675593435764313, acc: 1.0)
[2024-11-29 03:48:34,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:34,139][root][INFO] - Training Epoch: 9/10, step 407/574 completed (loss: 0.032706525176763535, acc: 1.0)
[2024-11-29 03:48:34,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:34,424][root][INFO] - Training Epoch: 9/10, step 408/574 completed (loss: 0.024828948080539703, acc: 1.0)
[2024-11-29 03:48:34,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:34,688][root][INFO] - Training Epoch: 9/10, step 409/574 completed (loss: 0.02191927284002304, acc: 1.0)
[2024-11-29 03:48:34,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:35,005][root][INFO] - Training Epoch: 9/10, step 410/574 completed (loss: 0.04755942523479462, acc: 1.0)
[2024-11-29 03:48:35,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:35,279][root][INFO] - Training Epoch: 9/10, step 411/574 completed (loss: 0.16172091662883759, acc: 0.9642857313156128)
[2024-11-29 03:48:35,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:35,554][root][INFO] - Training Epoch: 9/10, step 412/574 completed (loss: 0.13460741937160492, acc: 0.9666666388511658)
[2024-11-29 03:48:36,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:36,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:37,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:37,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:38,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:38,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:38,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:39,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:39,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:40,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:40,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:41,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:41,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:42,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:42,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:43,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:43,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:43,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:44,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:44,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:44,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:45,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:45,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:46,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:46,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:47,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:47,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:48,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:48,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:48,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:49,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:49,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:50,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:50,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:51,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:51,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:51,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:52,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:52,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:52,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:53,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:53,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:54,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:54,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:54,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:55,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:55,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:56,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:56,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:57,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:57,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:57,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:58,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:58,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:59,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:59,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:48:59,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:00,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:00,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:01,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:01,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:02,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:02,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:03,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:03,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:04,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:04,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:04,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:05,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:06,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:06,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:06,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:07,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:07,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:08,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:08,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:08,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:09,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:09,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:09,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:10,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:10,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:11,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:11,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:12,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:12,699][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.4058, device='cuda:0') eval_epoch_loss=tensor(1.2255, device='cuda:0') eval_epoch_acc=tensor(0.7238, device='cuda:0')
[2024-11-29 03:49:12,701][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:49:12,701][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:49:13,002][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_9_step_413_loss_1.2254910469055176/model.pt
[2024-11-29 03:49:13,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:13,284][root][INFO] - Training Epoch: 9/10, step 413/574 completed (loss: 0.013101466000080109, acc: 1.0)
[2024-11-29 03:49:13,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:13,537][root][INFO] - Training Epoch: 9/10, step 414/574 completed (loss: 0.22119855880737305, acc: 0.9090909361839294)
[2024-11-29 03:49:13,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:13,807][root][INFO] - Training Epoch: 9/10, step 415/574 completed (loss: 0.33394551277160645, acc: 0.9019607901573181)
[2024-11-29 03:49:13,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:14,068][root][INFO] - Training Epoch: 9/10, step 416/574 completed (loss: 0.11996196955442429, acc: 0.9615384340286255)
[2024-11-29 03:49:14,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:14,337][root][INFO] - Training Epoch: 9/10, step 417/574 completed (loss: 0.04974895715713501, acc: 1.0)
[2024-11-29 03:49:14,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:14,638][root][INFO] - Training Epoch: 9/10, step 418/574 completed (loss: 0.12819138169288635, acc: 0.925000011920929)
[2024-11-29 03:49:14,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:14,969][root][INFO] - Training Epoch: 9/10, step 419/574 completed (loss: 0.02992364764213562, acc: 1.0)
[2024-11-29 03:49:15,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:15,268][root][INFO] - Training Epoch: 9/10, step 420/574 completed (loss: 0.05969235301017761, acc: 1.0)
[2024-11-29 03:49:15,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:15,596][root][INFO] - Training Epoch: 9/10, step 421/574 completed (loss: 0.04373716935515404, acc: 1.0)
[2024-11-29 03:49:15,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:15,916][root][INFO] - Training Epoch: 9/10, step 422/574 completed (loss: 0.3322998583316803, acc: 0.9375)
[2024-11-29 03:49:16,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:16,202][root][INFO] - Training Epoch: 9/10, step 423/574 completed (loss: 0.12624694406986237, acc: 0.9444444179534912)
[2024-11-29 03:49:16,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:16,458][root][INFO] - Training Epoch: 9/10, step 424/574 completed (loss: 0.039301879703998566, acc: 1.0)
[2024-11-29 03:49:16,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:16,719][root][INFO] - Training Epoch: 9/10, step 425/574 completed (loss: 0.046565111726522446, acc: 1.0)
[2024-11-29 03:49:16,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:17,030][root][INFO] - Training Epoch: 9/10, step 426/574 completed (loss: 0.16208817064762115, acc: 0.95652174949646)
[2024-11-29 03:49:17,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:17,337][root][INFO] - Training Epoch: 9/10, step 427/574 completed (loss: 0.13005425035953522, acc: 0.9459459185600281)
[2024-11-29 03:49:17,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:17,586][root][INFO] - Training Epoch: 9/10, step 428/574 completed (loss: 0.014140521176159382, acc: 1.0)
[2024-11-29 03:49:17,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:17,834][root][INFO] - Training Epoch: 9/10, step 429/574 completed (loss: 0.01112945657223463, acc: 1.0)
[2024-11-29 03:49:17,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:18,079][root][INFO] - Training Epoch: 9/10, step 430/574 completed (loss: 0.011120366863906384, acc: 1.0)
[2024-11-29 03:49:18,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:18,328][root][INFO] - Training Epoch: 9/10, step 431/574 completed (loss: 0.008794452995061874, acc: 1.0)
[2024-11-29 03:49:18,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:18,587][root][INFO] - Training Epoch: 9/10, step 432/574 completed (loss: 0.10998579859733582, acc: 0.95652174949646)
[2024-11-29 03:49:18,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:18,937][root][INFO] - Training Epoch: 9/10, step 433/574 completed (loss: 0.22632724046707153, acc: 0.9166666865348816)
[2024-11-29 03:49:19,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:19,190][root][INFO] - Training Epoch: 9/10, step 434/574 completed (loss: 0.00566354813054204, acc: 1.0)
[2024-11-29 03:49:19,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:19,441][root][INFO] - Training Epoch: 9/10, step 435/574 completed (loss: 0.05069061368703842, acc: 1.0)
[2024-11-29 03:49:19,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:19,699][root][INFO] - Training Epoch: 9/10, step 436/574 completed (loss: 0.2646223306655884, acc: 0.9444444179534912)
[2024-11-29 03:49:19,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:19,963][root][INFO] - Training Epoch: 9/10, step 437/574 completed (loss: 0.0767698809504509, acc: 0.9545454382896423)
[2024-11-29 03:49:20,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:20,224][root][INFO] - Training Epoch: 9/10, step 438/574 completed (loss: 0.011229033581912518, acc: 1.0)
[2024-11-29 03:49:20,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:20,474][root][INFO] - Training Epoch: 9/10, step 439/574 completed (loss: 0.3853544294834137, acc: 0.9487179517745972)
[2024-11-29 03:49:20,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:21,060][root][INFO] - Training Epoch: 9/10, step 440/574 completed (loss: 0.1753595471382141, acc: 0.939393937587738)
[2024-11-29 03:49:21,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:22,053][root][INFO] - Training Epoch: 9/10, step 441/574 completed (loss: 0.667576253414154, acc: 0.7680000066757202)
[2024-11-29 03:49:22,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:22,523][root][INFO] - Training Epoch: 9/10, step 442/574 completed (loss: 0.6461053490638733, acc: 0.7983871102333069)
[2024-11-29 03:49:23,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:23,431][root][INFO] - Training Epoch: 9/10, step 443/574 completed (loss: 0.5422894954681396, acc: 0.8407959938049316)
[2024-11-29 03:49:23,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:23,753][root][INFO] - Training Epoch: 9/10, step 444/574 completed (loss: 0.34395357966423035, acc: 0.9433962106704712)
[2024-11-29 03:49:24,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:24,259][root][INFO] - Training Epoch: 9/10, step 445/574 completed (loss: 0.1412084996700287, acc: 0.9090909361839294)
[2024-11-29 03:49:24,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:24,576][root][INFO] - Training Epoch: 9/10, step 446/574 completed (loss: 0.17474278807640076, acc: 0.95652174949646)
[2024-11-29 03:49:24,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:24,881][root][INFO] - Training Epoch: 9/10, step 447/574 completed (loss: 0.013390539214015007, acc: 1.0)
[2024-11-29 03:49:25,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:25,144][root][INFO] - Training Epoch: 9/10, step 448/574 completed (loss: 0.03138979524374008, acc: 1.0)
[2024-11-29 03:49:25,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:25,404][root][INFO] - Training Epoch: 9/10, step 449/574 completed (loss: 0.05370495095849037, acc: 0.9701492786407471)
[2024-11-29 03:49:25,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:25,672][root][INFO] - Training Epoch: 9/10, step 450/574 completed (loss: 0.04516386613249779, acc: 0.9861111044883728)
[2024-11-29 03:49:25,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:25,937][root][INFO] - Training Epoch: 9/10, step 451/574 completed (loss: 0.1812441051006317, acc: 0.989130437374115)
[2024-11-29 03:49:26,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:26,210][root][INFO] - Training Epoch: 9/10, step 452/574 completed (loss: 0.17257796227931976, acc: 0.9487179517745972)
[2024-11-29 03:49:26,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:26,487][root][INFO] - Training Epoch: 9/10, step 453/574 completed (loss: 0.18430326879024506, acc: 0.9605262875556946)
[2024-11-29 03:49:26,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:26,749][root][INFO] - Training Epoch: 9/10, step 454/574 completed (loss: 0.18679995834827423, acc: 0.9387755393981934)
[2024-11-29 03:49:26,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:26,999][root][INFO] - Training Epoch: 9/10, step 455/574 completed (loss: 0.1849524974822998, acc: 0.939393937587738)
[2024-11-29 03:49:27,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:27,274][root][INFO] - Training Epoch: 9/10, step 456/574 completed (loss: 0.4163375794887543, acc: 0.907216489315033)
[2024-11-29 03:49:27,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:27,550][root][INFO] - Training Epoch: 9/10, step 457/574 completed (loss: 0.15992820262908936, acc: 0.9428571462631226)
[2024-11-29 03:49:27,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:27,977][root][INFO] - Training Epoch: 9/10, step 458/574 completed (loss: 0.34053972363471985, acc: 0.9186046719551086)
[2024-11-29 03:49:28,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:28,267][root][INFO] - Training Epoch: 9/10, step 459/574 completed (loss: 0.05581030622124672, acc: 1.0)
[2024-11-29 03:49:28,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:28,552][root][INFO] - Training Epoch: 9/10, step 460/574 completed (loss: 0.17220208048820496, acc: 0.9506173133850098)
[2024-11-29 03:49:28,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:28,822][root][INFO] - Training Epoch: 9/10, step 461/574 completed (loss: 0.270241916179657, acc: 0.9444444179534912)
[2024-11-29 03:49:28,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:29,069][root][INFO] - Training Epoch: 9/10, step 462/574 completed (loss: 0.11662302166223526, acc: 0.9375)
[2024-11-29 03:49:29,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:29,322][root][INFO] - Training Epoch: 9/10, step 463/574 completed (loss: 0.04155942052602768, acc: 1.0)
[2024-11-29 03:49:29,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:29,582][root][INFO] - Training Epoch: 9/10, step 464/574 completed (loss: 0.06675894558429718, acc: 0.97826087474823)
[2024-11-29 03:49:29,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:29,906][root][INFO] - Training Epoch: 9/10, step 465/574 completed (loss: 0.2738381028175354, acc: 0.9404761791229248)
[2024-11-29 03:49:30,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:30,229][root][INFO] - Training Epoch: 9/10, step 466/574 completed (loss: 0.7049275636672974, acc: 0.8433734774589539)
[2024-11-29 03:49:30,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:30,534][root][INFO] - Training Epoch: 9/10, step 467/574 completed (loss: 0.17184896767139435, acc: 0.954954981803894)
[2024-11-29 03:49:30,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:30,805][root][INFO] - Training Epoch: 9/10, step 468/574 completed (loss: 0.5178258419036865, acc: 0.8640776872634888)
[2024-11-29 03:49:30,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:31,091][root][INFO] - Training Epoch: 9/10, step 469/574 completed (loss: 0.5841730237007141, acc: 0.8455284833908081)
[2024-11-29 03:49:31,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:31,348][root][INFO] - Training Epoch: 9/10, step 470/574 completed (loss: 0.04291549697518349, acc: 1.0)
[2024-11-29 03:49:31,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:31,629][root][INFO] - Training Epoch: 9/10, step 471/574 completed (loss: 0.07873376458883286, acc: 1.0)
[2024-11-29 03:49:31,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:32,112][root][INFO] - Training Epoch: 9/10, step 472/574 completed (loss: 0.4376119077205658, acc: 0.8725489974021912)
[2024-11-29 03:49:32,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:32,485][root][INFO] - Training Epoch: 9/10, step 473/574 completed (loss: 0.6918051242828369, acc: 0.7772925496101379)
[2024-11-29 03:49:32,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:32,858][root][INFO] - Training Epoch: 9/10, step 474/574 completed (loss: 0.242032989859581, acc: 0.9166666865348816)
[2024-11-29 03:49:33,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:33,192][root][INFO] - Training Epoch: 9/10, step 475/574 completed (loss: 0.13956987857818604, acc: 0.9693251252174377)
[2024-11-29 03:49:33,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:33,489][root][INFO] - Training Epoch: 9/10, step 476/574 completed (loss: 0.29983237385749817, acc: 0.9280575513839722)
[2024-11-29 03:49:33,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:33,893][root][INFO] - Training Epoch: 9/10, step 477/574 completed (loss: 0.42726045846939087, acc: 0.8894472122192383)
[2024-11-29 03:49:34,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:34,156][root][INFO] - Training Epoch: 9/10, step 478/574 completed (loss: 0.22847488522529602, acc: 0.9166666865348816)
[2024-11-29 03:49:34,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:34,428][root][INFO] - Training Epoch: 9/10, step 479/574 completed (loss: 0.06596173346042633, acc: 1.0)
[2024-11-29 03:49:34,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:34,718][root][INFO] - Training Epoch: 9/10, step 480/574 completed (loss: 0.36679351329803467, acc: 0.8888888955116272)
[2024-11-29 03:49:34,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:34,970][root][INFO] - Training Epoch: 9/10, step 481/574 completed (loss: 0.5638110041618347, acc: 0.8999999761581421)
[2024-11-29 03:49:35,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:35,227][root][INFO] - Training Epoch: 9/10, step 482/574 completed (loss: 0.502621054649353, acc: 0.8999999761581421)
[2024-11-29 03:49:35,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:35,642][root][INFO] - Training Epoch: 9/10, step 483/574 completed (loss: 0.3636402487754822, acc: 0.8793103694915771)
[2024-11-29 03:49:35,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:35,927][root][INFO] - Training Epoch: 9/10, step 484/574 completed (loss: 0.045123711228370667, acc: 1.0)
[2024-11-29 03:49:36,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:36,201][root][INFO] - Training Epoch: 9/10, step 485/574 completed (loss: 0.01856043003499508, acc: 1.0)
[2024-11-29 03:49:36,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:36,452][root][INFO] - Training Epoch: 9/10, step 486/574 completed (loss: 0.3644835650920868, acc: 0.9629629850387573)
[2024-11-29 03:49:36,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:36,707][root][INFO] - Training Epoch: 9/10, step 487/574 completed (loss: 0.4046095311641693, acc: 0.9047619104385376)
[2024-11-29 03:49:36,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:36,958][root][INFO] - Training Epoch: 9/10, step 488/574 completed (loss: 0.19797958433628082, acc: 0.9545454382896423)
[2024-11-29 03:49:37,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:37,304][root][INFO] - Training Epoch: 9/10, step 489/574 completed (loss: 0.44209024310112, acc: 0.8615384697914124)
[2024-11-29 03:49:37,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:37,587][root][INFO] - Training Epoch: 9/10, step 490/574 completed (loss: 0.14789755642414093, acc: 0.9666666388511658)
[2024-11-29 03:49:37,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:37,889][root][INFO] - Training Epoch: 9/10, step 491/574 completed (loss: 0.17097361385822296, acc: 0.931034505367279)
[2024-11-29 03:49:38,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:38,203][root][INFO] - Training Epoch: 9/10, step 492/574 completed (loss: 0.19178427755832672, acc: 0.9411764740943909)
[2024-11-29 03:49:38,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:38,541][root][INFO] - Training Epoch: 9/10, step 493/574 completed (loss: 0.13401231169700623, acc: 0.931034505367279)
[2024-11-29 03:49:38,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:38,867][root][INFO] - Training Epoch: 9/10, step 494/574 completed (loss: 0.3131304681301117, acc: 0.8421052694320679)
[2024-11-29 03:49:39,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:39,165][root][INFO] - Training Epoch: 9/10, step 495/574 completed (loss: 0.18985851109027863, acc: 0.9473684430122375)
[2024-11-29 03:49:39,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:39,502][root][INFO] - Training Epoch: 9/10, step 496/574 completed (loss: 0.5715960264205933, acc: 0.8392857313156128)
[2024-11-29 03:49:39,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:39,902][root][INFO] - Training Epoch: 9/10, step 497/574 completed (loss: 0.2229005992412567, acc: 0.932584285736084)
[2024-11-29 03:49:40,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:40,198][root][INFO] - Training Epoch: 9/10, step 498/574 completed (loss: 0.28183117508888245, acc: 0.898876428604126)
[2024-11-29 03:49:40,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:40,501][root][INFO] - Training Epoch: 9/10, step 499/574 completed (loss: 0.854550838470459, acc: 0.7659574747085571)
[2024-11-29 03:49:40,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:40,786][root][INFO] - Training Epoch: 9/10, step 500/574 completed (loss: 0.3996502757072449, acc: 0.8586956262588501)
[2024-11-29 03:49:40,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:41,034][root][INFO] - Training Epoch: 9/10, step 501/574 completed (loss: 0.015744350850582123, acc: 1.0)
[2024-11-29 03:49:41,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:41,311][root][INFO] - Training Epoch: 9/10, step 502/574 completed (loss: 0.012092792429029942, acc: 1.0)
[2024-11-29 03:49:41,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:41,582][root][INFO] - Training Epoch: 9/10, step 503/574 completed (loss: 0.21906350553035736, acc: 0.9629629850387573)
[2024-11-29 03:49:41,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:41,879][root][INFO] - Training Epoch: 9/10, step 504/574 completed (loss: 0.06242738664150238, acc: 1.0)
[2024-11-29 03:49:42,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:42,184][root][INFO] - Training Epoch: 9/10, step 505/574 completed (loss: 0.5383972525596619, acc: 0.8301886916160583)
[2024-11-29 03:49:42,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:42,525][root][INFO] - Training Epoch: 9/10, step 506/574 completed (loss: 0.9601166844367981, acc: 0.7241379022598267)
[2024-11-29 03:49:43,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:43,390][root][INFO] - Training Epoch: 9/10, step 507/574 completed (loss: 0.9863156676292419, acc: 0.7117117047309875)
[2024-11-29 03:49:43,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:43,933][root][INFO] - Training Epoch: 9/10, step 508/574 completed (loss: 0.6757329106330872, acc: 0.8450704216957092)
[2024-11-29 03:49:44,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:44,231][root][INFO] - Training Epoch: 9/10, step 509/574 completed (loss: 0.0678827241063118, acc: 0.949999988079071)
[2024-11-29 03:49:44,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:44,525][root][INFO] - Training Epoch: 9/10, step 510/574 completed (loss: 0.06550263613462448, acc: 0.9666666388511658)
[2024-11-29 03:49:44,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:44,781][root][INFO] - Training Epoch: 9/10, step 511/574 completed (loss: 0.013375901617109776, acc: 1.0)
[2024-11-29 03:49:47,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:48,190][root][INFO] - Training Epoch: 9/10, step 512/574 completed (loss: 0.7598127722740173, acc: 0.7857142686843872)
[2024-11-29 03:49:48,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:49,319][root][INFO] - Training Epoch: 9/10, step 513/574 completed (loss: 0.2564530074596405, acc: 0.920634925365448)
[2024-11-29 03:49:49,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:49,612][root][INFO] - Training Epoch: 9/10, step 514/574 completed (loss: 0.5365080237388611, acc: 0.8571428656578064)
[2024-11-29 03:49:49,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:49,922][root][INFO] - Training Epoch: 9/10, step 515/574 completed (loss: 0.06780495494604111, acc: 0.9666666388511658)
[2024-11-29 03:49:50,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:50,938][root][INFO] - Training Epoch: 9/10, step 516/574 completed (loss: 0.3697170615196228, acc: 0.875)
[2024-11-29 03:49:51,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:51,189][root][INFO] - Training Epoch: 9/10, step 517/574 completed (loss: 0.009181691333651543, acc: 1.0)
[2024-11-29 03:49:51,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:51,431][root][INFO] - Training Epoch: 9/10, step 518/574 completed (loss: 0.17485038936138153, acc: 0.9354838728904724)
[2024-11-29 03:49:51,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:51,676][root][INFO] - Training Epoch: 9/10, step 519/574 completed (loss: 0.2842637002468109, acc: 0.8999999761581421)
[2024-11-29 03:49:51,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:51,997][root][INFO] - Training Epoch: 9/10, step 520/574 completed (loss: 0.1252451390028, acc: 0.9629629850387573)
[2024-11-29 03:49:52,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:53,489][root][INFO] - Training Epoch: 9/10, step 521/574 completed (loss: 0.6294830441474915, acc: 0.8262711763381958)
[2024-11-29 03:49:53,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:53,850][root][INFO] - Training Epoch: 9/10, step 522/574 completed (loss: 0.2931312024593353, acc: 0.9029850959777832)
[2024-11-29 03:49:54,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:54,241][root][INFO] - Training Epoch: 9/10, step 523/574 completed (loss: 0.33375784754753113, acc: 0.9124087691307068)
[2024-11-29 03:49:54,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:54,992][root][INFO] - Training Epoch: 9/10, step 524/574 completed (loss: 0.481154203414917, acc: 0.8550000190734863)
[2024-11-29 03:49:55,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:55,308][root][INFO] - Training Epoch: 9/10, step 525/574 completed (loss: 0.07767666131258011, acc: 0.9444444179534912)
[2024-11-29 03:49:55,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:55,578][root][INFO] - Training Epoch: 9/10, step 526/574 completed (loss: 0.04145921766757965, acc: 1.0)
[2024-11-29 03:49:55,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:55,829][root][INFO] - Training Epoch: 9/10, step 527/574 completed (loss: 0.22600966691970825, acc: 0.9523809552192688)
[2024-11-29 03:49:55,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:56,102][root][INFO] - Training Epoch: 9/10, step 528/574 completed (loss: 0.48862841725349426, acc: 0.868852436542511)
[2024-11-29 03:49:56,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:56,356][root][INFO] - Training Epoch: 9/10, step 529/574 completed (loss: 0.10813557356595993, acc: 0.9661017060279846)
[2024-11-29 03:49:56,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:56,605][root][INFO] - Training Epoch: 9/10, step 530/574 completed (loss: 1.0004981756210327, acc: 0.7674418687820435)
[2024-11-29 03:49:56,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:56,871][root][INFO] - Training Epoch: 9/10, step 531/574 completed (loss: 0.38290974497795105, acc: 0.8863636255264282)
[2024-11-29 03:49:57,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:57,126][root][INFO] - Training Epoch: 9/10, step 532/574 completed (loss: 0.5843604207038879, acc: 0.849056601524353)
[2024-11-29 03:49:57,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:57,392][root][INFO] - Training Epoch: 9/10, step 533/574 completed (loss: 0.24102924764156342, acc: 0.9318181872367859)
[2024-11-29 03:49:57,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:57,645][root][INFO] - Training Epoch: 9/10, step 534/574 completed (loss: 0.38429495692253113, acc: 0.8799999952316284)
[2024-11-29 03:49:57,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:57,898][root][INFO] - Training Epoch: 9/10, step 535/574 completed (loss: 0.14478902518749237, acc: 0.949999988079071)
[2024-11-29 03:49:58,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:58,144][root][INFO] - Training Epoch: 9/10, step 536/574 completed (loss: 0.07449163496494293, acc: 1.0)
[2024-11-29 03:49:58,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:58,614][root][INFO] - Training Epoch: 9/10, step 537/574 completed (loss: 0.33498862385749817, acc: 0.9230769276618958)
[2024-11-29 03:49:58,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:58,931][root][INFO] - Training Epoch: 9/10, step 538/574 completed (loss: 0.30560892820358276, acc: 0.921875)
[2024-11-29 03:49:59,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:59,378][root][INFO] - Training Epoch: 9/10, step 539/574 completed (loss: 0.32133400440216064, acc: 0.875)
[2024-11-29 03:49:59,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:59,633][root][INFO] - Training Epoch: 9/10, step 540/574 completed (loss: 0.968007504940033, acc: 0.7575757503509521)
[2024-11-29 03:49:59,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:49:59,887][root][INFO] - Training Epoch: 9/10, step 541/574 completed (loss: 0.2546837627887726, acc: 0.9375)
[2024-11-29 03:50:00,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:00,132][root][INFO] - Training Epoch: 9/10, step 542/574 completed (loss: 0.05624206364154816, acc: 1.0)
[2024-11-29 03:50:00,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:00,379][root][INFO] - Training Epoch: 9/10, step 543/574 completed (loss: 0.006434232462197542, acc: 1.0)
[2024-11-29 03:50:00,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:00,682][root][INFO] - Training Epoch: 9/10, step 544/574 completed (loss: 0.11618672311306, acc: 0.9333333373069763)
[2024-11-29 03:50:00,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:00,953][root][INFO] - Training Epoch: 9/10, step 545/574 completed (loss: 0.06741437315940857, acc: 0.9756097793579102)
[2024-11-29 03:50:01,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:01,207][root][INFO] - Training Epoch: 9/10, step 546/574 completed (loss: 0.0650346651673317, acc: 0.9714285731315613)
[2024-11-29 03:50:01,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:01,466][root][INFO] - Training Epoch: 9/10, step 547/574 completed (loss: 0.049036696553230286, acc: 0.9736841917037964)
[2024-11-29 03:50:01,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:01,725][root][INFO] - Training Epoch: 9/10, step 548/574 completed (loss: 0.051356278359889984, acc: 1.0)
[2024-11-29 03:50:01,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:02,022][root][INFO] - Training Epoch: 9/10, step 549/574 completed (loss: 0.020641852170228958, acc: 1.0)
[2024-11-29 03:50:02,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:02,303][root][INFO] - Training Epoch: 9/10, step 550/574 completed (loss: 0.05044102296233177, acc: 0.9696969985961914)
[2024-11-29 03:50:02,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:02,599][root][INFO] - Training Epoch: 9/10, step 551/574 completed (loss: 0.0425766259431839, acc: 1.0)
[2024-11-29 03:50:02,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:02,909][root][INFO] - Training Epoch: 9/10, step 552/574 completed (loss: 0.04852878302335739, acc: 0.9857142567634583)
[2024-11-29 03:50:03,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:03,220][root][INFO] - Training Epoch: 9/10, step 553/574 completed (loss: 0.281691312789917, acc: 0.9343065619468689)
[2024-11-29 03:50:03,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:03,495][root][INFO] - Training Epoch: 9/10, step 554/574 completed (loss: 0.19496379792690277, acc: 0.931034505367279)
[2024-11-29 03:50:03,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:03,817][root][INFO] - Training Epoch: 9/10, step 555/574 completed (loss: 0.26285234093666077, acc: 0.9071428775787354)
[2024-11-29 03:50:04,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:05,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:05,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:06,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:06,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:06,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:07,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:07,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:08,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:08,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:08,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:09,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:09,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:09,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:10,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:10,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:11,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:11,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:11,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:12,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:12,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:13,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:13,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:14,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:14,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:14,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:15,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:15,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:16,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:16,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:17,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:17,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:18,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:18,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:19,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:19,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:19,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:20,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:20,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:21,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:21,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:21,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:22,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:22,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:22,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:23,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:23,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:24,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:24,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:24,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:25,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:25,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:26,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:26,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:27,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:27,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:28,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:28,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:29,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:29,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:29,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:30,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:30,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:31,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:31,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:32,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:32,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:33,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:33,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:34,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:34,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:35,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:35,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:36,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:36,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:37,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:37,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:37,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:38,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:38,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:38,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:39,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:39,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:40,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:40,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:41,296][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.2091, device='cuda:0') eval_epoch_loss=tensor(1.1660, device='cuda:0') eval_epoch_acc=tensor(0.7561, device='cuda:0')
[2024-11-29 03:50:41,297][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:50:41,298][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:50:41,589][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_9_step_556_loss_1.1660046577453613/model.pt
[2024-11-29 03:50:41,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:41,907][root][INFO] - Training Epoch: 9/10, step 556/574 completed (loss: 0.27843692898750305, acc: 0.9205297827720642)
[2024-11-29 03:50:42,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:42,179][root][INFO] - Training Epoch: 9/10, step 557/574 completed (loss: 0.06046958640217781, acc: 0.9829059839248657)
[2024-11-29 03:50:42,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:42,496][root][INFO] - Training Epoch: 9/10, step 558/574 completed (loss: 0.023288553580641747, acc: 1.0)
[2024-11-29 03:50:42,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:42,810][root][INFO] - Training Epoch: 9/10, step 559/574 completed (loss: 0.048427775502204895, acc: 0.9615384340286255)
[2024-11-29 03:50:42,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:43,096][root][INFO] - Training Epoch: 9/10, step 560/574 completed (loss: 0.020362259820103645, acc: 1.0)
[2024-11-29 03:50:43,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:43,375][root][INFO] - Training Epoch: 9/10, step 561/574 completed (loss: 0.055735308676958084, acc: 1.0)
[2024-11-29 03:50:43,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:43,701][root][INFO] - Training Epoch: 9/10, step 562/574 completed (loss: 0.11920588463544846, acc: 0.9777777791023254)
[2024-11-29 03:50:43,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:43,981][root][INFO] - Training Epoch: 9/10, step 563/574 completed (loss: 0.26414725184440613, acc: 0.9350649118423462)
[2024-11-29 03:50:44,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:44,285][root][INFO] - Training Epoch: 9/10, step 564/574 completed (loss: 0.13405410945415497, acc: 0.9583333134651184)
[2024-11-29 03:50:44,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:44,564][root][INFO] - Training Epoch: 9/10, step 565/574 completed (loss: 0.12780651450157166, acc: 0.9482758641242981)
[2024-11-29 03:50:44,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:44,829][root][INFO] - Training Epoch: 9/10, step 566/574 completed (loss: 0.1669692099094391, acc: 0.9285714030265808)
[2024-11-29 03:50:44,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:45,119][root][INFO] - Training Epoch: 9/10, step 567/574 completed (loss: 0.09501034021377563, acc: 0.9473684430122375)
[2024-11-29 03:50:45,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:45,471][root][INFO] - Training Epoch: 9/10, step 568/574 completed (loss: 0.20090068876743317, acc: 0.9629629850387573)
[2024-11-29 03:50:45,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:45,871][root][INFO] - Training Epoch: 9/10, step 569/574 completed (loss: 0.3003336787223816, acc: 0.9251337051391602)
[2024-11-29 03:50:46,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:46,170][root][INFO] - Training Epoch: 9/10, step 570/574 completed (loss: 0.02420840784907341, acc: 1.0)
[2024-11-29 03:50:46,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:46,512][root][INFO] - Training Epoch: 9/10, step 571/574 completed (loss: 0.12494407594203949, acc: 0.9743589758872986)
[2024-11-29 03:50:46,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:46,835][root][INFO] - Training Epoch: 9/10, step 572/574 completed (loss: 0.49337631464004517, acc: 0.8673469424247742)
[2024-11-29 03:50:47,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:47,161][root][INFO] - Training Epoch: 9/10, step 573/574 completed (loss: 0.4093475937843323, acc: 0.8679245114326477)
[2024-11-29 03:50:47,668][slam_llm.utils.train_utils][INFO] - Epoch 9: train_perplexity=1.3423, train_epoch_loss=0.2944, epoch time 373.9293520320207s
[2024-11-29 03:50:47,669][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-11-29 03:50:47,669][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 22 GB
[2024-11-29 03:50:47,669][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-11-29 03:50:47,669][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 18
[2024-11-29 03:50:47,669][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-29 03:50:48,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:48,369][root][INFO] - Training Epoch: 10/10, step 0/574 completed (loss: 0.011743917129933834, acc: 1.0)
[2024-11-29 03:50:48,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:48,684][root][INFO] - Training Epoch: 10/10, step 1/574 completed (loss: 0.012616169638931751, acc: 1.0)
[2024-11-29 03:50:48,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:48,995][root][INFO] - Training Epoch: 10/10, step 2/574 completed (loss: 0.17174649238586426, acc: 0.9189189076423645)
[2024-11-29 03:50:49,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:49,294][root][INFO] - Training Epoch: 10/10, step 3/574 completed (loss: 0.07891712337732315, acc: 0.9736841917037964)
[2024-11-29 03:50:49,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:49,623][root][INFO] - Training Epoch: 10/10, step 4/574 completed (loss: 0.15715886652469635, acc: 0.9729729890823364)
[2024-11-29 03:50:49,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:49,926][root][INFO] - Training Epoch: 10/10, step 5/574 completed (loss: 0.011718027293682098, acc: 1.0)
[2024-11-29 03:50:50,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:50,214][root][INFO] - Training Epoch: 10/10, step 6/574 completed (loss: 0.13504405319690704, acc: 0.9387755393981934)
[2024-11-29 03:50:50,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:50,521][root][INFO] - Training Epoch: 10/10, step 7/574 completed (loss: 0.027938688173890114, acc: 0.9666666388511658)
[2024-11-29 03:50:50,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:50,832][root][INFO] - Training Epoch: 10/10, step 8/574 completed (loss: 0.07114507257938385, acc: 0.9545454382896423)
[2024-11-29 03:50:50,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:51,138][root][INFO] - Training Epoch: 10/10, step 9/574 completed (loss: 0.011093535460531712, acc: 1.0)
[2024-11-29 03:50:51,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:51,486][root][INFO] - Training Epoch: 10/10, step 10/574 completed (loss: 0.00601908890530467, acc: 1.0)
[2024-11-29 03:50:51,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:51,792][root][INFO] - Training Epoch: 10/10, step 11/574 completed (loss: 0.1416511833667755, acc: 0.9743589758872986)
[2024-11-29 03:50:51,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:52,130][root][INFO] - Training Epoch: 10/10, step 12/574 completed (loss: 0.021668141707777977, acc: 1.0)
[2024-11-29 03:50:52,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:52,464][root][INFO] - Training Epoch: 10/10, step 13/574 completed (loss: 0.048779312521219254, acc: 1.0)
[2024-11-29 03:50:52,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:52,775][root][INFO] - Training Epoch: 10/10, step 14/574 completed (loss: 0.08002414554357529, acc: 0.9803921580314636)
[2024-11-29 03:50:52,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:53,089][root][INFO] - Training Epoch: 10/10, step 15/574 completed (loss: 0.10233752429485321, acc: 0.9387755393981934)
[2024-11-29 03:50:53,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:53,404][root][INFO] - Training Epoch: 10/10, step 16/574 completed (loss: 0.0020506561268121004, acc: 1.0)
[2024-11-29 03:50:53,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:53,706][root][INFO] - Training Epoch: 10/10, step 17/574 completed (loss: 0.0742514356970787, acc: 0.9583333134651184)
[2024-11-29 03:50:53,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:53,969][root][INFO] - Training Epoch: 10/10, step 18/574 completed (loss: 0.23693479597568512, acc: 0.9722222089767456)
[2024-11-29 03:50:54,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:54,261][root][INFO] - Training Epoch: 10/10, step 19/574 completed (loss: 0.021296627819538116, acc: 1.0)
[2024-11-29 03:50:54,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:54,586][root][INFO] - Training Epoch: 10/10, step 20/574 completed (loss: 0.32284945249557495, acc: 0.8461538553237915)
[2024-11-29 03:50:54,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:54,885][root][INFO] - Training Epoch: 10/10, step 21/574 completed (loss: 0.09149732440710068, acc: 0.9655172228813171)
[2024-11-29 03:50:55,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:55,186][root][INFO] - Training Epoch: 10/10, step 22/574 completed (loss: 0.10888201743364334, acc: 0.9599999785423279)
[2024-11-29 03:50:55,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:55,502][root][INFO] - Training Epoch: 10/10, step 23/574 completed (loss: 0.0069373794831335545, acc: 1.0)
[2024-11-29 03:50:55,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:55,857][root][INFO] - Training Epoch: 10/10, step 24/574 completed (loss: 0.0032627666369080544, acc: 1.0)
[2024-11-29 03:50:56,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:56,212][root][INFO] - Training Epoch: 10/10, step 25/574 completed (loss: 0.14701849222183228, acc: 0.9622641801834106)
[2024-11-29 03:50:56,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:56,543][root][INFO] - Training Epoch: 10/10, step 26/574 completed (loss: 0.2735365629196167, acc: 0.9178082346916199)
[2024-11-29 03:50:57,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:58,368][root][INFO] - Training Epoch: 10/10, step 27/574 completed (loss: 0.9468880891799927, acc: 0.731225311756134)
[2024-11-29 03:50:58,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:58,624][root][INFO] - Training Epoch: 10/10, step 28/574 completed (loss: 0.3229389488697052, acc: 0.930232584476471)
[2024-11-29 03:50:58,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:58,969][root][INFO] - Training Epoch: 10/10, step 29/574 completed (loss: 0.29653599858283997, acc: 0.9036144614219666)
[2024-11-29 03:50:59,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:59,257][root][INFO] - Training Epoch: 10/10, step 30/574 completed (loss: 0.4916626811027527, acc: 0.8765432238578796)
[2024-11-29 03:50:59,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:59,534][root][INFO] - Training Epoch: 10/10, step 31/574 completed (loss: 0.039171524345874786, acc: 0.9642857313156128)
[2024-11-29 03:50:59,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:50:59,869][root][INFO] - Training Epoch: 10/10, step 32/574 completed (loss: 0.004637414589524269, acc: 1.0)
[2024-11-29 03:51:00,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:00,176][root][INFO] - Training Epoch: 10/10, step 33/574 completed (loss: 0.016946125775575638, acc: 1.0)
[2024-11-29 03:51:00,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:00,466][root][INFO] - Training Epoch: 10/10, step 34/574 completed (loss: 0.2751563787460327, acc: 0.8991596698760986)
[2024-11-29 03:51:00,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:00,730][root][INFO] - Training Epoch: 10/10, step 35/574 completed (loss: 0.26783978939056396, acc: 0.9344262480735779)
[2024-11-29 03:51:00,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:01,024][root][INFO] - Training Epoch: 10/10, step 36/574 completed (loss: 0.7270042896270752, acc: 0.8095238208770752)
[2024-11-29 03:51:01,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:01,297][root][INFO] - Training Epoch: 10/10, step 37/574 completed (loss: 0.10430996119976044, acc: 0.9661017060279846)
[2024-11-29 03:51:01,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:01,604][root][INFO] - Training Epoch: 10/10, step 38/574 completed (loss: 0.1932181715965271, acc: 0.9425287246704102)
[2024-11-29 03:51:01,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:01,860][root][INFO] - Training Epoch: 10/10, step 39/574 completed (loss: 0.30929937958717346, acc: 0.9047619104385376)
[2024-11-29 03:51:02,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:02,123][root][INFO] - Training Epoch: 10/10, step 40/574 completed (loss: 0.09461355954408646, acc: 0.9615384340286255)
[2024-11-29 03:51:02,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:02,505][root][INFO] - Training Epoch: 10/10, step 41/574 completed (loss: 0.2897668480873108, acc: 0.8648648858070374)
[2024-11-29 03:51:02,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:02,834][root][INFO] - Training Epoch: 10/10, step 42/574 completed (loss: 0.477146178483963, acc: 0.8461538553237915)
[2024-11-29 03:51:03,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:03,299][root][INFO] - Training Epoch: 10/10, step 43/574 completed (loss: 0.583015501499176, acc: 0.8484848737716675)
[2024-11-29 03:51:03,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:03,764][root][INFO] - Training Epoch: 10/10, step 44/574 completed (loss: 0.30898669362068176, acc: 0.8969072103500366)
[2024-11-29 03:51:03,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:04,203][root][INFO] - Training Epoch: 10/10, step 45/574 completed (loss: 0.3258299231529236, acc: 0.8602941036224365)
[2024-11-29 03:51:04,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:04,484][root][INFO] - Training Epoch: 10/10, step 46/574 completed (loss: 0.24489592015743256, acc: 0.9230769276618958)
[2024-11-29 03:51:04,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:04,735][root][INFO] - Training Epoch: 10/10, step 47/574 completed (loss: 0.05269375443458557, acc: 0.9629629850387573)
[2024-11-29 03:51:04,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:04,991][root][INFO] - Training Epoch: 10/10, step 48/574 completed (loss: 0.09941738843917847, acc: 0.9285714030265808)
[2024-11-29 03:51:05,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:05,254][root][INFO] - Training Epoch: 10/10, step 49/574 completed (loss: 0.04497584328055382, acc: 1.0)
[2024-11-29 03:51:05,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:05,532][root][INFO] - Training Epoch: 10/10, step 50/574 completed (loss: 0.47640788555145264, acc: 0.8947368264198303)
[2024-11-29 03:51:05,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:05,837][root][INFO] - Training Epoch: 10/10, step 51/574 completed (loss: 0.2524721324443817, acc: 0.920634925365448)
[2024-11-29 03:51:06,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:06,145][root][INFO] - Training Epoch: 10/10, step 52/574 completed (loss: 0.5355157852172852, acc: 0.8873239159584045)
[2024-11-29 03:51:06,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:06,694][root][INFO] - Training Epoch: 10/10, step 53/574 completed (loss: 1.0051689147949219, acc: 0.7200000286102295)
[2024-11-29 03:51:06,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:07,018][root][INFO] - Training Epoch: 10/10, step 54/574 completed (loss: 0.3442750573158264, acc: 0.8918918967247009)
[2024-11-29 03:51:07,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:07,308][root][INFO] - Training Epoch: 10/10, step 55/574 completed (loss: 0.022306064143776894, acc: 1.0)
[2024-11-29 03:51:10,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:11,885][root][INFO] - Training Epoch: 10/10, step 56/574 completed (loss: 1.215821623802185, acc: 0.6655290126800537)
[2024-11-29 03:51:13,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:13,724][root][INFO] - Training Epoch: 10/10, step 57/574 completed (loss: 1.4237473011016846, acc: 0.6100217700004578)
[2024-11-29 03:51:14,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:14,554][root][INFO] - Training Epoch: 10/10, step 58/574 completed (loss: 0.5992566347122192, acc: 0.8011363744735718)
[2024-11-29 03:51:14,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:15,333][root][INFO] - Training Epoch: 10/10, step 59/574 completed (loss: 0.2937588691711426, acc: 0.9117646813392639)
[2024-11-29 03:51:15,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:16,083][root][INFO] - Training Epoch: 10/10, step 60/574 completed (loss: 0.6444505453109741, acc: 0.8478260636329651)
[2024-11-29 03:51:16,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:16,572][root][INFO] - Training Epoch: 10/10, step 61/574 completed (loss: 0.4277381896972656, acc: 0.875)
[2024-11-29 03:51:16,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:16,896][root][INFO] - Training Epoch: 10/10, step 62/574 completed (loss: 0.021576032042503357, acc: 1.0)
[2024-11-29 03:51:17,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:17,239][root][INFO] - Training Epoch: 10/10, step 63/574 completed (loss: 0.046646613627672195, acc: 1.0)
[2024-11-29 03:51:17,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:17,560][root][INFO] - Training Epoch: 10/10, step 64/574 completed (loss: 0.08823056519031525, acc: 0.953125)
[2024-11-29 03:51:17,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:17,901][root][INFO] - Training Epoch: 10/10, step 65/574 completed (loss: 0.0876520574092865, acc: 0.9655172228813171)
[2024-11-29 03:51:18,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:18,216][root][INFO] - Training Epoch: 10/10, step 66/574 completed (loss: 0.34647971391677856, acc: 0.9285714030265808)
[2024-11-29 03:51:18,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:18,519][root][INFO] - Training Epoch: 10/10, step 67/574 completed (loss: 0.07267996668815613, acc: 0.9833333492279053)
[2024-11-29 03:51:18,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:18,791][root][INFO] - Training Epoch: 10/10, step 68/574 completed (loss: 0.0388452522456646, acc: 1.0)
[2024-11-29 03:51:18,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:19,120][root][INFO] - Training Epoch: 10/10, step 69/574 completed (loss: 0.04630337283015251, acc: 1.0)
[2024-11-29 03:51:19,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:19,368][root][INFO] - Training Epoch: 10/10, step 70/574 completed (loss: 0.4153292179107666, acc: 0.8787878751754761)
[2024-11-29 03:51:19,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:19,707][root][INFO] - Training Epoch: 10/10, step 71/574 completed (loss: 0.7218260765075684, acc: 0.7573529481887817)
[2024-11-29 03:51:19,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:20,019][root][INFO] - Training Epoch: 10/10, step 72/574 completed (loss: 0.3363300859928131, acc: 0.8809523582458496)
[2024-11-29 03:51:20,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:20,339][root][INFO] - Training Epoch: 10/10, step 73/574 completed (loss: 1.1142606735229492, acc: 0.6820513010025024)
[2024-11-29 03:51:20,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:20,692][root][INFO] - Training Epoch: 10/10, step 74/574 completed (loss: 0.6648728251457214, acc: 0.8265306353569031)
[2024-11-29 03:51:20,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:21,007][root][INFO] - Training Epoch: 10/10, step 75/574 completed (loss: 0.6420891284942627, acc: 0.8283582329750061)
[2024-11-29 03:51:21,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:21,437][root][INFO] - Training Epoch: 10/10, step 76/574 completed (loss: 1.371655821800232, acc: 0.6423357725143433)
[2024-11-29 03:51:21,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:21,688][root][INFO] - Training Epoch: 10/10, step 77/574 completed (loss: 0.014688042923808098, acc: 1.0)
[2024-11-29 03:51:21,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:21,938][root][INFO] - Training Epoch: 10/10, step 78/574 completed (loss: 0.011639605276286602, acc: 1.0)
[2024-11-29 03:51:22,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:22,203][root][INFO] - Training Epoch: 10/10, step 79/574 completed (loss: 0.020067250356078148, acc: 1.0)
[2024-11-29 03:51:22,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:22,463][root][INFO] - Training Epoch: 10/10, step 80/574 completed (loss: 0.033653609454631805, acc: 1.0)
[2024-11-29 03:51:22,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:22,731][root][INFO] - Training Epoch: 10/10, step 81/574 completed (loss: 0.1699105203151703, acc: 0.9230769276618958)
[2024-11-29 03:51:22,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:23,049][root][INFO] - Training Epoch: 10/10, step 82/574 completed (loss: 0.2072860598564148, acc: 0.9038461446762085)
[2024-11-29 03:51:23,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:23,315][root][INFO] - Training Epoch: 10/10, step 83/574 completed (loss: 0.10538141429424286, acc: 0.96875)
[2024-11-29 03:51:23,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:23,581][root][INFO] - Training Epoch: 10/10, step 84/574 completed (loss: 0.12130992859601974, acc: 0.9710144996643066)
[2024-11-29 03:51:23,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:23,856][root][INFO] - Training Epoch: 10/10, step 85/574 completed (loss: 0.16889624297618866, acc: 0.9200000166893005)
[2024-11-29 03:51:23,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:24,110][root][INFO] - Training Epoch: 10/10, step 86/574 completed (loss: 0.04985487088561058, acc: 1.0)
[2024-11-29 03:51:24,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:24,691][root][INFO] - Training Epoch: 10/10, step 87/574 completed (loss: 0.5689694285392761, acc: 0.8199999928474426)
[2024-11-29 03:51:24,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:25,010][root][INFO] - Training Epoch: 10/10, step 88/574 completed (loss: 0.7570622563362122, acc: 0.8058252334594727)
[2024-11-29 03:51:25,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:26,617][root][INFO] - Training Epoch: 10/10, step 89/574 completed (loss: 0.8039841651916504, acc: 0.7718446850776672)
[2024-11-29 03:51:27,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:27,782][root][INFO] - Training Epoch: 10/10, step 90/574 completed (loss: 0.9276720285415649, acc: 0.7580645084381104)
[2024-11-29 03:51:28,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:28,936][root][INFO] - Training Epoch: 10/10, step 91/574 completed (loss: 0.965179443359375, acc: 0.7543103694915771)
[2024-11-29 03:51:29,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:29,979][root][INFO] - Training Epoch: 10/10, step 92/574 completed (loss: 0.5200424790382385, acc: 0.8526315689086914)
[2024-11-29 03:51:30,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:31,431][root][INFO] - Training Epoch: 10/10, step 93/574 completed (loss: 1.0469799041748047, acc: 0.7128713130950928)
[2024-11-29 03:51:31,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:31,679][root][INFO] - Training Epoch: 10/10, step 94/574 completed (loss: 0.3523672819137573, acc: 0.9032257795333862)
[2024-11-29 03:51:31,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:32,001][root][INFO] - Training Epoch: 10/10, step 95/574 completed (loss: 0.42355290055274963, acc: 0.8985507488250732)
[2024-11-29 03:51:32,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:32,328][root][INFO] - Training Epoch: 10/10, step 96/574 completed (loss: 0.6577001810073853, acc: 0.8067227005958557)
[2024-11-29 03:51:32,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:32,626][root][INFO] - Training Epoch: 10/10, step 97/574 completed (loss: 0.7446549534797668, acc: 0.7019230723381042)
[2024-11-29 03:51:32,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:33,026][root][INFO] - Training Epoch: 10/10, step 98/574 completed (loss: 0.954849123954773, acc: 0.7372262477874756)
[2024-11-29 03:51:33,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:33,283][root][INFO] - Training Epoch: 10/10, step 99/574 completed (loss: 0.5151571035385132, acc: 0.8507462739944458)
[2024-11-29 03:51:33,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:33,537][root][INFO] - Training Epoch: 10/10, step 100/574 completed (loss: 0.3802122175693512, acc: 0.8999999761581421)
[2024-11-29 03:51:33,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:33,855][root][INFO] - Training Epoch: 10/10, step 101/574 completed (loss: 0.016452712938189507, acc: 1.0)
[2024-11-29 03:51:34,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:34,187][root][INFO] - Training Epoch: 10/10, step 102/574 completed (loss: 0.010163288563489914, acc: 1.0)
[2024-11-29 03:51:34,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:34,498][root][INFO] - Training Epoch: 10/10, step 103/574 completed (loss: 0.011823118664324284, acc: 1.0)
[2024-11-29 03:51:34,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:34,829][root][INFO] - Training Epoch: 10/10, step 104/574 completed (loss: 0.19246011972427368, acc: 0.9482758641242981)
[2024-11-29 03:51:35,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:35,141][root][INFO] - Training Epoch: 10/10, step 105/574 completed (loss: 0.011288076639175415, acc: 1.0)
[2024-11-29 03:51:35,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:35,443][root][INFO] - Training Epoch: 10/10, step 106/574 completed (loss: 0.035674870014190674, acc: 1.0)
[2024-11-29 03:51:35,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:35,738][root][INFO] - Training Epoch: 10/10, step 107/574 completed (loss: 0.008106824941933155, acc: 1.0)
[2024-11-29 03:51:35,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:36,039][root][INFO] - Training Epoch: 10/10, step 108/574 completed (loss: 0.0032802915666252375, acc: 1.0)
[2024-11-29 03:51:36,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:36,307][root][INFO] - Training Epoch: 10/10, step 109/574 completed (loss: 0.06048194691538811, acc: 0.976190447807312)
[2024-11-29 03:51:36,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:36,618][root][INFO] - Training Epoch: 10/10, step 110/574 completed (loss: 0.15185007452964783, acc: 0.9846153855323792)
[2024-11-29 03:51:36,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:37,069][root][INFO] - Training Epoch: 10/10, step 111/574 completed (loss: 0.12039738893508911, acc: 0.9824561476707458)
[2024-11-29 03:51:37,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:37,414][root][INFO] - Training Epoch: 10/10, step 112/574 completed (loss: 0.30292966961860657, acc: 0.9473684430122375)
[2024-11-29 03:51:37,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:37,703][root][INFO] - Training Epoch: 10/10, step 113/574 completed (loss: 0.12805964052677155, acc: 0.9743589758872986)
[2024-11-29 03:51:37,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:38,065][root][INFO] - Training Epoch: 10/10, step 114/574 completed (loss: 0.1551215648651123, acc: 0.9387755393981934)
[2024-11-29 03:51:38,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:38,315][root][INFO] - Training Epoch: 10/10, step 115/574 completed (loss: 0.023852860555052757, acc: 1.0)
[2024-11-29 03:51:38,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:38,616][root][INFO] - Training Epoch: 10/10, step 116/574 completed (loss: 0.3773477375507355, acc: 0.8888888955116272)
[2024-11-29 03:51:38,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:38,938][root][INFO] - Training Epoch: 10/10, step 117/574 completed (loss: 0.34005311131477356, acc: 0.8943089246749878)
[2024-11-29 03:51:39,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:39,204][root][INFO] - Training Epoch: 10/10, step 118/574 completed (loss: 0.09728933125734329, acc: 0.9677419066429138)
[2024-11-29 03:51:39,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:40,376][root][INFO] - Training Epoch: 10/10, step 119/574 completed (loss: 0.81878662109375, acc: 0.7984790802001953)
[2024-11-29 03:51:40,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:40,664][root][INFO] - Training Epoch: 10/10, step 120/574 completed (loss: 0.10851169377565384, acc: 0.9733333587646484)
[2024-11-29 03:51:40,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:41,120][root][INFO] - Training Epoch: 10/10, step 121/574 completed (loss: 0.17755497992038727, acc: 0.9615384340286255)
[2024-11-29 03:51:41,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:41,398][root][INFO] - Training Epoch: 10/10, step 122/574 completed (loss: 0.006829952355474234, acc: 1.0)
[2024-11-29 03:51:41,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:41,694][root][INFO] - Training Epoch: 10/10, step 123/574 completed (loss: 0.09866157174110413, acc: 0.9473684430122375)
[2024-11-29 03:51:41,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:41,984][root][INFO] - Training Epoch: 10/10, step 124/574 completed (loss: 0.802077054977417, acc: 0.7852760553359985)
[2024-11-29 03:51:42,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:43,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:43,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:44,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:44,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:45,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:45,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:45,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:46,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:46,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:47,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:47,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:48,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:48,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:49,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:49,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:50,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:50,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:50,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:51,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:51,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:52,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:52,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:52,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:53,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:53,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:54,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:54,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:55,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:55,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:56,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:56,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:56,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:57,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:57,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:58,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:58,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:58,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:59,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:51:59,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:00,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:00,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:00,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:01,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:01,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:02,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:02,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:03,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:03,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:03,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:04,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:04,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:05,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:05,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:05,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:06,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:06,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:07,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:07,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:08,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:08,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:09,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:09,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:10,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:10,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:11,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:11,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:11,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:12,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:13,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:13,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:14,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:14,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:15,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:15,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:15,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:16,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:16,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:17,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:17,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:17,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:18,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:18,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:18,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:19,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:20,063][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.2009, device='cuda:0') eval_epoch_loss=tensor(1.1634, device='cuda:0') eval_epoch_acc=tensor(0.7595, device='cuda:0')
[2024-11-29 03:52:20,064][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:52:20,065][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:52:20,338][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_10_step_125_loss_1.1634467840194702/model.pt
[2024-11-29 03:52:20,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:20,686][root][INFO] - Training Epoch: 10/10, step 125/574 completed (loss: 0.7705585956573486, acc: 0.7152777910232544)
[2024-11-29 03:52:20,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:20,952][root][INFO] - Training Epoch: 10/10, step 126/574 completed (loss: 0.5804197788238525, acc: 0.7833333611488342)
[2024-11-29 03:52:21,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:21,264][root][INFO] - Training Epoch: 10/10, step 127/574 completed (loss: 0.6865946650505066, acc: 0.8154761791229248)
[2024-11-29 03:52:21,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:21,577][root][INFO] - Training Epoch: 10/10, step 128/574 completed (loss: 0.567256510257721, acc: 0.8205128312110901)
[2024-11-29 03:52:21,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:22,021][root][INFO] - Training Epoch: 10/10, step 129/574 completed (loss: 0.699506938457489, acc: 0.8014705777168274)
[2024-11-29 03:52:22,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:22,290][root][INFO] - Training Epoch: 10/10, step 130/574 completed (loss: 0.17772755026817322, acc: 0.9615384340286255)
[2024-11-29 03:52:22,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:22,601][root][INFO] - Training Epoch: 10/10, step 131/574 completed (loss: 0.12688860297203064, acc: 1.0)
[2024-11-29 03:52:22,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:22,913][root][INFO] - Training Epoch: 10/10, step 132/574 completed (loss: 0.16749969124794006, acc: 0.96875)
[2024-11-29 03:52:23,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:23,169][root][INFO] - Training Epoch: 10/10, step 133/574 completed (loss: 0.18933725357055664, acc: 0.95652174949646)
[2024-11-29 03:52:23,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:23,424][root][INFO] - Training Epoch: 10/10, step 134/574 completed (loss: 0.21336568892002106, acc: 0.9142857193946838)
[2024-11-29 03:52:23,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:23,683][root][INFO] - Training Epoch: 10/10, step 135/574 completed (loss: 0.25697723031044006, acc: 0.9230769276618958)
[2024-11-29 03:52:23,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:24,007][root][INFO] - Training Epoch: 10/10, step 136/574 completed (loss: 0.36598408222198486, acc: 0.9047619104385376)
[2024-11-29 03:52:24,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:24,297][root][INFO] - Training Epoch: 10/10, step 137/574 completed (loss: 0.4091821312904358, acc: 0.8666666746139526)
[2024-11-29 03:52:24,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:24,548][root][INFO] - Training Epoch: 10/10, step 138/574 completed (loss: 0.033395204693078995, acc: 1.0)
[2024-11-29 03:52:24,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:24,866][root][INFO] - Training Epoch: 10/10, step 139/574 completed (loss: 0.018141351640224457, acc: 1.0)
[2024-11-29 03:52:25,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:25,169][root][INFO] - Training Epoch: 10/10, step 140/574 completed (loss: 0.21547657251358032, acc: 0.9230769276618958)
[2024-11-29 03:52:25,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:25,449][root][INFO] - Training Epoch: 10/10, step 141/574 completed (loss: 0.2773711383342743, acc: 0.9032257795333862)
[2024-11-29 03:52:25,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:25,696][root][INFO] - Training Epoch: 10/10, step 142/574 completed (loss: 0.1025923639535904, acc: 0.9729729890823364)
[2024-11-29 03:52:26,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:26,389][root][INFO] - Training Epoch: 10/10, step 143/574 completed (loss: 0.40302765369415283, acc: 0.859649121761322)
[2024-11-29 03:52:26,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:26,709][root][INFO] - Training Epoch: 10/10, step 144/574 completed (loss: 0.5157499313354492, acc: 0.8432835936546326)
[2024-11-29 03:52:26,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:27,056][root][INFO] - Training Epoch: 10/10, step 145/574 completed (loss: 0.24415011703968048, acc: 0.8877550959587097)
[2024-11-29 03:52:27,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:27,608][root][INFO] - Training Epoch: 10/10, step 146/574 completed (loss: 0.521939218044281, acc: 0.8617021441459656)
[2024-11-29 03:52:27,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:27,873][root][INFO] - Training Epoch: 10/10, step 147/574 completed (loss: 0.3085455894470215, acc: 0.8999999761581421)
[2024-11-29 03:52:28,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:28,110][root][INFO] - Training Epoch: 10/10, step 148/574 completed (loss: 0.1990598440170288, acc: 0.9285714030265808)
[2024-11-29 03:52:28,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:28,347][root][INFO] - Training Epoch: 10/10, step 149/574 completed (loss: 0.0992317646741867, acc: 0.95652174949646)
[2024-11-29 03:52:28,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:28,600][root][INFO] - Training Epoch: 10/10, step 150/574 completed (loss: 0.0762176662683487, acc: 0.9655172228813171)
[2024-11-29 03:52:28,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:28,922][root][INFO] - Training Epoch: 10/10, step 151/574 completed (loss: 0.2568603456020355, acc: 0.9130434989929199)
[2024-11-29 03:52:29,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:29,233][root][INFO] - Training Epoch: 10/10, step 152/574 completed (loss: 0.38218846917152405, acc: 0.8983050584793091)
[2024-11-29 03:52:29,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:29,495][root][INFO] - Training Epoch: 10/10, step 153/574 completed (loss: 0.2899577021598816, acc: 0.9473684430122375)
[2024-11-29 03:52:29,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:29,784][root][INFO] - Training Epoch: 10/10, step 154/574 completed (loss: 0.42513275146484375, acc: 0.8513513803482056)
[2024-11-29 03:52:29,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:30,043][root][INFO] - Training Epoch: 10/10, step 155/574 completed (loss: 0.01750023290514946, acc: 1.0)
[2024-11-29 03:52:30,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:30,293][root][INFO] - Training Epoch: 10/10, step 156/574 completed (loss: 0.1619761735200882, acc: 0.9130434989929199)
[2024-11-29 03:52:30,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:30,620][root][INFO] - Training Epoch: 10/10, step 157/574 completed (loss: 1.695814609527588, acc: 0.6315789222717285)
[2024-11-29 03:52:32,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:33,193][root][INFO] - Training Epoch: 10/10, step 158/574 completed (loss: 1.0322800874710083, acc: 0.7432432174682617)
[2024-11-29 03:52:33,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:33,454][root][INFO] - Training Epoch: 10/10, step 159/574 completed (loss: 0.8845503330230713, acc: 0.7222222089767456)
[2024-11-29 03:52:33,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:33,922][root][INFO] - Training Epoch: 10/10, step 160/574 completed (loss: 1.131987452507019, acc: 0.7209302186965942)
[2024-11-29 03:52:34,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:34,741][root][INFO] - Training Epoch: 10/10, step 161/574 completed (loss: 1.4971355199813843, acc: 0.6470588445663452)
[2024-11-29 03:52:35,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:35,499][root][INFO] - Training Epoch: 10/10, step 162/574 completed (loss: 0.9398073554039001, acc: 0.7528089880943298)
[2024-11-29 03:52:35,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:35,754][root][INFO] - Training Epoch: 10/10, step 163/574 completed (loss: 0.43235886096954346, acc: 0.8863636255264282)
[2024-11-29 03:52:35,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:35,998][root][INFO] - Training Epoch: 10/10, step 164/574 completed (loss: 0.0668666735291481, acc: 1.0)
[2024-11-29 03:52:36,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:36,254][root][INFO] - Training Epoch: 10/10, step 165/574 completed (loss: 1.0948678255081177, acc: 0.6896551847457886)
[2024-11-29 03:52:36,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:36,533][root][INFO] - Training Epoch: 10/10, step 166/574 completed (loss: 0.13823771476745605, acc: 0.9387755393981934)
[2024-11-29 03:52:36,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:36,808][root][INFO] - Training Epoch: 10/10, step 167/574 completed (loss: 0.1647452563047409, acc: 0.9599999785423279)
[2024-11-29 03:52:37,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:37,262][root][INFO] - Training Epoch: 10/10, step 168/574 completed (loss: 0.3450062572956085, acc: 0.9027777910232544)
[2024-11-29 03:52:37,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:37,570][root][INFO] - Training Epoch: 10/10, step 169/574 completed (loss: 0.8185819983482361, acc: 0.8039215803146362)
[2024-11-29 03:52:38,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:39,109][root][INFO] - Training Epoch: 10/10, step 170/574 completed (loss: 0.6626695990562439, acc: 0.835616409778595)
[2024-11-29 03:52:39,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:39,357][root][INFO] - Training Epoch: 10/10, step 171/574 completed (loss: 0.0380651019513607, acc: 1.0)
[2024-11-29 03:52:39,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:39,594][root][INFO] - Training Epoch: 10/10, step 172/574 completed (loss: 0.5626806616783142, acc: 0.8148148059844971)
[2024-11-29 03:52:39,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:39,918][root][INFO] - Training Epoch: 10/10, step 173/574 completed (loss: 0.1902356892824173, acc: 0.9642857313156128)
[2024-11-29 03:52:40,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:40,686][root][INFO] - Training Epoch: 10/10, step 174/574 completed (loss: 0.9052524566650391, acc: 0.7256637215614319)
[2024-11-29 03:52:40,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:40,930][root][INFO] - Training Epoch: 10/10, step 175/574 completed (loss: 0.6567004323005676, acc: 0.782608687877655)
[2024-11-29 03:52:41,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:41,220][root][INFO] - Training Epoch: 10/10, step 176/574 completed (loss: 0.3106328845024109, acc: 0.9090909361839294)
[2024-11-29 03:52:42,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:42,595][root][INFO] - Training Epoch: 10/10, step 177/574 completed (loss: 0.9246906638145447, acc: 0.732824444770813)
[2024-11-29 03:52:43,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:43,534][root][INFO] - Training Epoch: 10/10, step 178/574 completed (loss: 0.7466209530830383, acc: 0.7629629373550415)
[2024-11-29 03:52:43,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:43,806][root][INFO] - Training Epoch: 10/10, step 179/574 completed (loss: 0.19059965014457703, acc: 0.9508196711540222)
[2024-11-29 03:52:43,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:44,053][root][INFO] - Training Epoch: 10/10, step 180/574 completed (loss: 0.013831344433128834, acc: 1.0)
[2024-11-29 03:52:44,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:44,302][root][INFO] - Training Epoch: 10/10, step 181/574 completed (loss: 0.00794739555567503, acc: 1.0)
[2024-11-29 03:52:44,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:44,541][root][INFO] - Training Epoch: 10/10, step 182/574 completed (loss: 0.056300610303878784, acc: 0.9642857313156128)
[2024-11-29 03:52:44,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:44,805][root][INFO] - Training Epoch: 10/10, step 183/574 completed (loss: 0.10505136847496033, acc: 0.9756097793579102)
[2024-11-29 03:52:44,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:45,124][root][INFO] - Training Epoch: 10/10, step 184/574 completed (loss: 0.5539277195930481, acc: 0.8549848794937134)
[2024-11-29 03:52:45,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:45,437][root][INFO] - Training Epoch: 10/10, step 185/574 completed (loss: 0.621691107749939, acc: 0.818443775177002)
[2024-11-29 03:52:45,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:46,041][root][INFO] - Training Epoch: 10/10, step 186/574 completed (loss: 0.551865816116333, acc: 0.84375)
[2024-11-29 03:52:46,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:46,676][root][INFO] - Training Epoch: 10/10, step 187/574 completed (loss: 0.8836460709571838, acc: 0.7598499059677124)
[2024-11-29 03:52:46,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:47,124][root][INFO] - Training Epoch: 10/10, step 188/574 completed (loss: 0.52167147397995, acc: 0.8576512336730957)
[2024-11-29 03:52:47,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:47,366][root][INFO] - Training Epoch: 10/10, step 189/574 completed (loss: 0.1394280195236206, acc: 0.9599999785423279)
[2024-11-29 03:52:47,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:48,117][root][INFO] - Training Epoch: 10/10, step 190/574 completed (loss: 0.43259337544441223, acc: 0.8488371968269348)
[2024-11-29 03:52:48,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:49,286][root][INFO] - Training Epoch: 10/10, step 191/574 completed (loss: 1.0330758094787598, acc: 0.738095223903656)
[2024-11-29 03:52:50,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:50,664][root][INFO] - Training Epoch: 10/10, step 192/574 completed (loss: 0.9800662398338318, acc: 0.75)
[2024-11-29 03:52:51,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:51,745][root][INFO] - Training Epoch: 10/10, step 193/574 completed (loss: 0.32620006799697876, acc: 0.9058823585510254)
[2024-11-29 03:52:52,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:53,387][root][INFO] - Training Epoch: 10/10, step 194/574 completed (loss: 0.8578824400901794, acc: 0.7345678806304932)
[2024-11-29 03:52:54,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:54,823][root][INFO] - Training Epoch: 10/10, step 195/574 completed (loss: 0.20262040197849274, acc: 0.9032257795333862)
[2024-11-29 03:52:54,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:55,093][root][INFO] - Training Epoch: 10/10, step 196/574 completed (loss: 0.016473516821861267, acc: 1.0)
[2024-11-29 03:52:55,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:55,378][root][INFO] - Training Epoch: 10/10, step 197/574 completed (loss: 0.13768509030342102, acc: 0.949999988079071)
[2024-11-29 03:52:55,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:55,720][root][INFO] - Training Epoch: 10/10, step 198/574 completed (loss: 0.17937305569648743, acc: 0.970588207244873)
[2024-11-29 03:52:55,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:56,046][root][INFO] - Training Epoch: 10/10, step 199/574 completed (loss: 0.6855091452598572, acc: 0.8235294222831726)
[2024-11-29 03:52:56,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:56,325][root][INFO] - Training Epoch: 10/10, step 200/574 completed (loss: 0.46456924080848694, acc: 0.8559321761131287)
[2024-11-29 03:52:56,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:56,609][root][INFO] - Training Epoch: 10/10, step 201/574 completed (loss: 0.37869715690612793, acc: 0.8656716346740723)
[2024-11-29 03:52:56,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:56,933][root][INFO] - Training Epoch: 10/10, step 202/574 completed (loss: 0.4628358781337738, acc: 0.8640776872634888)
[2024-11-29 03:52:57,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:57,215][root][INFO] - Training Epoch: 10/10, step 203/574 completed (loss: 0.29092881083488464, acc: 0.8730158805847168)
[2024-11-29 03:52:57,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:57,490][root][INFO] - Training Epoch: 10/10, step 204/574 completed (loss: 0.14940033853054047, acc: 0.9450549483299255)
[2024-11-29 03:52:57,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:57,782][root][INFO] - Training Epoch: 10/10, step 205/574 completed (loss: 0.18028849363327026, acc: 0.9506726264953613)
[2024-11-29 03:52:58,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:58,218][root][INFO] - Training Epoch: 10/10, step 206/574 completed (loss: 0.32527685165405273, acc: 0.8937007784843445)
[2024-11-29 03:52:58,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:58,515][root][INFO] - Training Epoch: 10/10, step 207/574 completed (loss: 0.157000333070755, acc: 0.9525862336158752)
[2024-11-29 03:52:58,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:58,856][root][INFO] - Training Epoch: 10/10, step 208/574 completed (loss: 0.25810757279396057, acc: 0.9275362491607666)
[2024-11-29 03:52:59,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:59,225][root][INFO] - Training Epoch: 10/10, step 209/574 completed (loss: 0.26201197504997253, acc: 0.9260700345039368)
[2024-11-29 03:52:59,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:59,489][root][INFO] - Training Epoch: 10/10, step 210/574 completed (loss: 0.36520567536354065, acc: 0.945652186870575)
[2024-11-29 03:52:59,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:52:59,786][root][INFO] - Training Epoch: 10/10, step 211/574 completed (loss: 0.005802889820188284, acc: 1.0)
[2024-11-29 03:52:59,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:00,113][root][INFO] - Training Epoch: 10/10, step 212/574 completed (loss: 0.0403878390789032, acc: 1.0)
[2024-11-29 03:53:00,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:00,437][root][INFO] - Training Epoch: 10/10, step 213/574 completed (loss: 0.31185075640678406, acc: 0.8723404407501221)
[2024-11-29 03:53:00,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:01,392][root][INFO] - Training Epoch: 10/10, step 214/574 completed (loss: 0.14269056916236877, acc: 0.9692307710647583)
[2024-11-29 03:53:01,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:01,714][root][INFO] - Training Epoch: 10/10, step 215/574 completed (loss: 0.015531361103057861, acc: 1.0)
[2024-11-29 03:53:01,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:02,058][root][INFO] - Training Epoch: 10/10, step 216/574 completed (loss: 0.03296376392245293, acc: 1.0)
[2024-11-29 03:53:02,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:02,776][root][INFO] - Training Epoch: 10/10, step 217/574 completed (loss: 0.1698462814092636, acc: 0.954954981803894)
[2024-11-29 03:53:03,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:03,226][root][INFO] - Training Epoch: 10/10, step 218/574 completed (loss: 0.14997784793376923, acc: 0.9444444179534912)
[2024-11-29 03:53:03,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:03,530][root][INFO] - Training Epoch: 10/10, step 219/574 completed (loss: 0.0383794866502285, acc: 1.0)
[2024-11-29 03:53:03,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:03,824][root][INFO] - Training Epoch: 10/10, step 220/574 completed (loss: 0.004995433613657951, acc: 1.0)
[2024-11-29 03:53:03,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:04,122][root][INFO] - Training Epoch: 10/10, step 221/574 completed (loss: 0.008417290635406971, acc: 1.0)
[2024-11-29 03:53:04,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:04,411][root][INFO] - Training Epoch: 10/10, step 222/574 completed (loss: 0.28949856758117676, acc: 0.9038461446762085)
[2024-11-29 03:53:05,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:05,485][root][INFO] - Training Epoch: 10/10, step 223/574 completed (loss: 0.24856455624103546, acc: 0.945652186870575)
[2024-11-29 03:53:05,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:06,209][root][INFO] - Training Epoch: 10/10, step 224/574 completed (loss: 0.490965873003006, acc: 0.8409090638160706)
[2024-11-29 03:53:06,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:06,757][root][INFO] - Training Epoch: 10/10, step 225/574 completed (loss: 0.25234925746917725, acc: 0.9468085169792175)
[2024-11-29 03:53:06,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:07,105][root][INFO] - Training Epoch: 10/10, step 226/574 completed (loss: 0.11345329880714417, acc: 0.9811320900917053)
[2024-11-29 03:53:07,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:07,427][root][INFO] - Training Epoch: 10/10, step 227/574 completed (loss: 0.14101055264472961, acc: 0.949999988079071)
[2024-11-29 03:53:07,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:07,728][root][INFO] - Training Epoch: 10/10, step 228/574 completed (loss: 0.8857192397117615, acc: 0.8372092843055725)
[2024-11-29 03:53:07,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:08,066][root][INFO] - Training Epoch: 10/10, step 229/574 completed (loss: 0.612114667892456, acc: 0.8333333134651184)
[2024-11-29 03:53:08,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:08,468][root][INFO] - Training Epoch: 10/10, step 230/574 completed (loss: 1.815618872642517, acc: 0.5263158082962036)
[2024-11-29 03:53:08,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:08,777][root][INFO] - Training Epoch: 10/10, step 231/574 completed (loss: 1.5769644975662231, acc: 0.6111111044883728)
[2024-11-29 03:53:09,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:09,291][root][INFO] - Training Epoch: 10/10, step 232/574 completed (loss: 1.472909927368164, acc: 0.6111111044883728)
[2024-11-29 03:53:09,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:09,919][root][INFO] - Training Epoch: 10/10, step 233/574 completed (loss: 1.8850215673446655, acc: 0.5183486342430115)
[2024-11-29 03:53:10,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:10,532][root][INFO] - Training Epoch: 10/10, step 234/574 completed (loss: 1.282355785369873, acc: 0.6307692527770996)
[2024-11-29 03:53:10,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:10,849][root][INFO] - Training Epoch: 10/10, step 235/574 completed (loss: 0.00784413330256939, acc: 1.0)
[2024-11-29 03:53:11,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:11,143][root][INFO] - Training Epoch: 10/10, step 236/574 completed (loss: 0.1599007546901703, acc: 0.9583333134651184)
[2024-11-29 03:53:11,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:11,409][root][INFO] - Training Epoch: 10/10, step 237/574 completed (loss: 0.06405133008956909, acc: 1.0)
[2024-11-29 03:53:11,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:11,722][root][INFO] - Training Epoch: 10/10, step 238/574 completed (loss: 0.5292525291442871, acc: 0.8148148059844971)
[2024-11-29 03:53:11,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:12,053][root][INFO] - Training Epoch: 10/10, step 239/574 completed (loss: 0.6396551132202148, acc: 0.8285714387893677)
[2024-11-29 03:53:12,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:12,411][root][INFO] - Training Epoch: 10/10, step 240/574 completed (loss: 0.4558161795139313, acc: 0.8409090638160706)
[2024-11-29 03:53:12,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:12,717][root][INFO] - Training Epoch: 10/10, step 241/574 completed (loss: 0.18568378686904907, acc: 0.9772727489471436)
[2024-11-29 03:53:13,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:13,638][root][INFO] - Training Epoch: 10/10, step 242/574 completed (loss: 0.5139511227607727, acc: 0.8225806355476379)
[2024-11-29 03:53:14,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:14,356][root][INFO] - Training Epoch: 10/10, step 243/574 completed (loss: 0.3405413329601288, acc: 0.8636363744735718)
[2024-11-29 03:53:14,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:14,656][root][INFO] - Training Epoch: 10/10, step 244/574 completed (loss: 0.005696652457118034, acc: 1.0)
[2024-11-29 03:53:14,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:14,938][root][INFO] - Training Epoch: 10/10, step 245/574 completed (loss: 0.29422667622566223, acc: 0.8846153616905212)
[2024-11-29 03:53:15,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:15,251][root][INFO] - Training Epoch: 10/10, step 246/574 completed (loss: 0.035903073847293854, acc: 1.0)
[2024-11-29 03:53:15,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:15,569][root][INFO] - Training Epoch: 10/10, step 247/574 completed (loss: 0.011767451651394367, acc: 1.0)
[2024-11-29 03:53:15,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:15,943][root][INFO] - Training Epoch: 10/10, step 248/574 completed (loss: 0.07006973773241043, acc: 1.0)
[2024-11-29 03:53:16,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:16,232][root][INFO] - Training Epoch: 10/10, step 249/574 completed (loss: 0.4762463867664337, acc: 0.8648648858070374)
[2024-11-29 03:53:16,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:16,570][root][INFO] - Training Epoch: 10/10, step 250/574 completed (loss: 0.049955133348703384, acc: 1.0)
[2024-11-29 03:53:16,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:16,891][root][INFO] - Training Epoch: 10/10, step 251/574 completed (loss: 0.15383785963058472, acc: 0.9558823704719543)
[2024-11-29 03:53:17,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:17,187][root][INFO] - Training Epoch: 10/10, step 252/574 completed (loss: 0.06232542544603348, acc: 0.9756097793579102)
[2024-11-29 03:53:17,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:17,487][root][INFO] - Training Epoch: 10/10, step 253/574 completed (loss: 0.02743501216173172, acc: 1.0)
[2024-11-29 03:53:17,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:17,786][root][INFO] - Training Epoch: 10/10, step 254/574 completed (loss: 0.019809888675808907, acc: 1.0)
[2024-11-29 03:53:17,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:18,107][root][INFO] - Training Epoch: 10/10, step 255/574 completed (loss: 0.024880485609173775, acc: 1.0)
[2024-11-29 03:53:18,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:18,424][root][INFO] - Training Epoch: 10/10, step 256/574 completed (loss: 0.09188491106033325, acc: 0.9649122953414917)
[2024-11-29 03:53:18,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:18,711][root][INFO] - Training Epoch: 10/10, step 257/574 completed (loss: 0.11216224730014801, acc: 0.9714285731315613)
[2024-11-29 03:53:18,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:19,025][root][INFO] - Training Epoch: 10/10, step 258/574 completed (loss: 0.12767398357391357, acc: 0.9605262875556946)
[2024-11-29 03:53:19,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:19,787][root][INFO] - Training Epoch: 10/10, step 259/574 completed (loss: 0.20770305395126343, acc: 0.9528301954269409)
[2024-11-29 03:53:20,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:20,571][root][INFO] - Training Epoch: 10/10, step 260/574 completed (loss: 0.24362878501415253, acc: 0.9166666865348816)
[2024-11-29 03:53:20,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:20,850][root][INFO] - Training Epoch: 10/10, step 261/574 completed (loss: 0.19804424047470093, acc: 0.9166666865348816)
[2024-11-29 03:53:21,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:21,169][root][INFO] - Training Epoch: 10/10, step 262/574 completed (loss: 0.11829419434070587, acc: 0.9677419066429138)
[2024-11-29 03:53:21,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:21,570][root][INFO] - Training Epoch: 10/10, step 263/574 completed (loss: 0.40881261229515076, acc: 0.8533333539962769)
[2024-11-29 03:53:21,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:21,891][root][INFO] - Training Epoch: 10/10, step 264/574 completed (loss: 0.33489790558815, acc: 0.8541666865348816)
[2024-11-29 03:53:22,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:23,139][root][INFO] - Training Epoch: 10/10, step 265/574 completed (loss: 0.9753519296646118, acc: 0.7039999961853027)
[2024-11-29 03:53:23,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:23,465][root][INFO] - Training Epoch: 10/10, step 266/574 completed (loss: 0.6006670594215393, acc: 0.7977527976036072)
[2024-11-29 03:53:23,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:23,846][root][INFO] - Training Epoch: 10/10, step 267/574 completed (loss: 0.4799603223800659, acc: 0.8513513803482056)
[2024-11-29 03:53:24,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:25,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:25,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:26,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:26,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:26,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:27,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:27,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:28,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:28,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:29,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:29,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:30,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:30,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:31,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:31,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:32,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:32,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:32,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:33,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:33,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:34,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:34,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:34,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:35,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:35,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:36,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:36,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:37,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:37,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:37,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:38,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:38,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:38,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:39,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:39,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:40,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:40,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:41,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:41,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:42,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:42,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:43,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:43,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:43,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:44,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:44,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:45,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:45,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:46,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:46,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:46,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:47,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:47,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:48,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:48,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:49,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:49,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:50,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:50,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:50,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:51,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:52,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:52,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:52,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:53,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:53,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:54,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:54,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:55,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:55,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:56,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:56,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:56,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:57,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:57,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:58,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:58,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:58,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:53:59,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:00,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:00,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:00,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:01,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:01,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:02,704][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.0553, device='cuda:0') eval_epoch_loss=tensor(1.1169, device='cuda:0') eval_epoch_acc=tensor(0.7636, device='cuda:0')
[2024-11-29 03:54:02,706][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:54:02,706][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:54:02,964][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_10_step_268_loss_1.1168837547302246/model.pt
[2024-11-29 03:54:03,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:03,568][root][INFO] - Training Epoch: 10/10, step 268/574 completed (loss: 0.23214516043663025, acc: 0.9655172228813171)
[2024-11-29 03:54:03,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:03,833][root][INFO] - Training Epoch: 10/10, step 269/574 completed (loss: 0.0051704030483961105, acc: 1.0)
[2024-11-29 03:54:04,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:04,160][root][INFO] - Training Epoch: 10/10, step 270/574 completed (loss: 0.009498842991888523, acc: 1.0)
[2024-11-29 03:54:04,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:04,433][root][INFO] - Training Epoch: 10/10, step 271/574 completed (loss: 0.045096952468156815, acc: 1.0)
[2024-11-29 03:54:04,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:04,756][root][INFO] - Training Epoch: 10/10, step 272/574 completed (loss: 0.0051588513888418674, acc: 1.0)
[2024-11-29 03:54:04,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:05,178][root][INFO] - Training Epoch: 10/10, step 273/574 completed (loss: 0.35766905546188354, acc: 0.9166666865348816)
[2024-11-29 03:54:05,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:05,459][root][INFO] - Training Epoch: 10/10, step 274/574 completed (loss: 0.08124275505542755, acc: 0.96875)
[2024-11-29 03:54:05,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:05,832][root][INFO] - Training Epoch: 10/10, step 275/574 completed (loss: 0.17218418419361115, acc: 0.9333333373069763)
[2024-11-29 03:54:06,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:06,156][root][INFO] - Training Epoch: 10/10, step 276/574 completed (loss: 0.10181935131549835, acc: 0.9655172228813171)
[2024-11-29 03:54:06,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:06,422][root][INFO] - Training Epoch: 10/10, step 277/574 completed (loss: 0.01696344092488289, acc: 1.0)
[2024-11-29 03:54:06,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:06,728][root][INFO] - Training Epoch: 10/10, step 278/574 completed (loss: 0.11893899738788605, acc: 0.978723406791687)
[2024-11-29 03:54:06,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:07,010][root][INFO] - Training Epoch: 10/10, step 279/574 completed (loss: 0.1605386883020401, acc: 0.9375)
[2024-11-29 03:54:07,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:07,257][root][INFO] - Training Epoch: 10/10, step 280/574 completed (loss: 0.018802843987941742, acc: 1.0)
[2024-11-29 03:54:07,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:07,745][root][INFO] - Training Epoch: 10/10, step 281/574 completed (loss: 0.6399316787719727, acc: 0.8313252925872803)
[2024-11-29 03:54:07,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:08,113][root][INFO] - Training Epoch: 10/10, step 282/574 completed (loss: 0.4112050235271454, acc: 0.8240740895271301)
[2024-11-29 03:54:08,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:08,365][root][INFO] - Training Epoch: 10/10, step 283/574 completed (loss: 0.022125424817204475, acc: 1.0)
[2024-11-29 03:54:08,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:08,659][root][INFO] - Training Epoch: 10/10, step 284/574 completed (loss: 0.07666366547346115, acc: 0.970588207244873)
[2024-11-29 03:54:08,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:08,932][root][INFO] - Training Epoch: 10/10, step 285/574 completed (loss: 0.03685054928064346, acc: 1.0)
[2024-11-29 03:54:09,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:09,211][root][INFO] - Training Epoch: 10/10, step 286/574 completed (loss: 0.2083054482936859, acc: 0.9453125)
[2024-11-29 03:54:09,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:09,534][root][INFO] - Training Epoch: 10/10, step 287/574 completed (loss: 0.3593621253967285, acc: 0.9039999842643738)
[2024-11-29 03:54:09,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:09,788][root][INFO] - Training Epoch: 10/10, step 288/574 completed (loss: 0.31355273723602295, acc: 0.8791208863258362)
[2024-11-29 03:54:09,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:10,061][root][INFO] - Training Epoch: 10/10, step 289/574 completed (loss: 0.17555058002471924, acc: 0.9503105878829956)
[2024-11-29 03:54:10,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:10,383][root][INFO] - Training Epoch: 10/10, step 290/574 completed (loss: 0.5199630856513977, acc: 0.8556700944900513)
[2024-11-29 03:54:10,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:10,685][root][INFO] - Training Epoch: 10/10, step 291/574 completed (loss: 0.05339755117893219, acc: 0.9545454382896423)
[2024-11-29 03:54:10,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:10,948][root][INFO] - Training Epoch: 10/10, step 292/574 completed (loss: 0.3438117802143097, acc: 0.9047619104385376)
[2024-11-29 03:54:11,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:11,226][root][INFO] - Training Epoch: 10/10, step 293/574 completed (loss: 0.13991308212280273, acc: 0.9482758641242981)
[2024-11-29 03:54:11,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:11,853][root][INFO] - Training Epoch: 10/10, step 294/574 completed (loss: 0.2747843265533447, acc: 0.9272727370262146)
[2024-11-29 03:54:12,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:12,570][root][INFO] - Training Epoch: 10/10, step 295/574 completed (loss: 0.7086682915687561, acc: 0.7989690899848938)
[2024-11-29 03:54:12,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:12,821][root][INFO] - Training Epoch: 10/10, step 296/574 completed (loss: 0.16418412327766418, acc: 0.9655172228813171)
[2024-11-29 03:54:12,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:13,111][root][INFO] - Training Epoch: 10/10, step 297/574 completed (loss: 0.02968411333858967, acc: 1.0)
[2024-11-29 03:54:13,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:13,396][root][INFO] - Training Epoch: 10/10, step 298/574 completed (loss: 0.3118307590484619, acc: 0.9210526347160339)
[2024-11-29 03:54:13,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:13,696][root][INFO] - Training Epoch: 10/10, step 299/574 completed (loss: 0.13090009987354279, acc: 0.9642857313156128)
[2024-11-29 03:54:13,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:13,967][root][INFO] - Training Epoch: 10/10, step 300/574 completed (loss: 0.006285837851464748, acc: 1.0)
[2024-11-29 03:54:14,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:14,242][root][INFO] - Training Epoch: 10/10, step 301/574 completed (loss: 0.1786622852087021, acc: 0.9622641801834106)
[2024-11-29 03:54:14,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:14,507][root][INFO] - Training Epoch: 10/10, step 302/574 completed (loss: 0.02332128956913948, acc: 1.0)
[2024-11-29 03:54:14,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:14,767][root][INFO] - Training Epoch: 10/10, step 303/574 completed (loss: 0.012671642005443573, acc: 1.0)
[2024-11-29 03:54:14,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:15,007][root][INFO] - Training Epoch: 10/10, step 304/574 completed (loss: 0.024309031665325165, acc: 1.0)
[2024-11-29 03:54:15,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:15,300][root][INFO] - Training Epoch: 10/10, step 305/574 completed (loss: 0.20852650701999664, acc: 0.9180327653884888)
[2024-11-29 03:54:15,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:15,554][root][INFO] - Training Epoch: 10/10, step 306/574 completed (loss: 0.03047024831175804, acc: 1.0)
[2024-11-29 03:54:15,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:15,800][root][INFO] - Training Epoch: 10/10, step 307/574 completed (loss: 0.003493314841762185, acc: 1.0)
[2024-11-29 03:54:15,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:16,079][root][INFO] - Training Epoch: 10/10, step 308/574 completed (loss: 0.1031375527381897, acc: 0.9710144996643066)
[2024-11-29 03:54:16,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:16,563][root][INFO] - Training Epoch: 10/10, step 309/574 completed (loss: 0.1989385038614273, acc: 0.9583333134651184)
[2024-11-29 03:54:16,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:16,836][root][INFO] - Training Epoch: 10/10, step 310/574 completed (loss: 0.13032935559749603, acc: 0.9879518151283264)
[2024-11-29 03:54:16,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:17,117][root][INFO] - Training Epoch: 10/10, step 311/574 completed (loss: 0.09390198439359665, acc: 0.9743589758872986)
[2024-11-29 03:54:17,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:17,474][root][INFO] - Training Epoch: 10/10, step 312/574 completed (loss: 0.11122949421405792, acc: 0.9489796161651611)
[2024-11-29 03:54:17,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:17,718][root][INFO] - Training Epoch: 10/10, step 313/574 completed (loss: 0.0523691326379776, acc: 1.0)
[2024-11-29 03:54:17,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:18,017][root][INFO] - Training Epoch: 10/10, step 314/574 completed (loss: 0.1178121492266655, acc: 0.9583333134651184)
[2024-11-29 03:54:18,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:18,275][root][INFO] - Training Epoch: 10/10, step 315/574 completed (loss: 0.12157146632671356, acc: 0.9354838728904724)
[2024-11-29 03:54:18,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:18,519][root][INFO] - Training Epoch: 10/10, step 316/574 completed (loss: 0.6991080641746521, acc: 0.7419354915618896)
[2024-11-29 03:54:18,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:18,827][root][INFO] - Training Epoch: 10/10, step 317/574 completed (loss: 0.1396799236536026, acc: 0.9701492786407471)
[2024-11-29 03:54:18,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:19,123][root][INFO] - Training Epoch: 10/10, step 318/574 completed (loss: 0.05161590129137039, acc: 0.9807692170143127)
[2024-11-29 03:54:19,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:19,379][root][INFO] - Training Epoch: 10/10, step 319/574 completed (loss: 0.03684123978018761, acc: 1.0)
[2024-11-29 03:54:19,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:19,615][root][INFO] - Training Epoch: 10/10, step 320/574 completed (loss: 0.025545265525579453, acc: 1.0)
[2024-11-29 03:54:19,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:19,889][root][INFO] - Training Epoch: 10/10, step 321/574 completed (loss: 0.013394857756793499, acc: 1.0)
[2024-11-29 03:54:20,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:20,161][root][INFO] - Training Epoch: 10/10, step 322/574 completed (loss: 0.4826604425907135, acc: 0.8888888955116272)
[2024-11-29 03:54:20,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:20,420][root][INFO] - Training Epoch: 10/10, step 323/574 completed (loss: 1.1850146055221558, acc: 0.6857143044471741)
[2024-11-29 03:54:20,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:20,669][root][INFO] - Training Epoch: 10/10, step 324/574 completed (loss: 0.8151412606239319, acc: 0.7692307829856873)
[2024-11-29 03:54:20,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:20,964][root][INFO] - Training Epoch: 10/10, step 325/574 completed (loss: 1.2752970457077026, acc: 0.6341463327407837)
[2024-11-29 03:54:21,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:21,243][root][INFO] - Training Epoch: 10/10, step 326/574 completed (loss: 0.3007689416408539, acc: 0.9473684430122375)
[2024-11-29 03:54:21,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:21,488][root][INFO] - Training Epoch: 10/10, step 327/574 completed (loss: 0.30486026406288147, acc: 0.9473684430122375)
[2024-11-29 03:54:21,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:21,738][root][INFO] - Training Epoch: 10/10, step 328/574 completed (loss: 0.0050100949592888355, acc: 1.0)
[2024-11-29 03:54:21,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:21,990][root][INFO] - Training Epoch: 10/10, step 329/574 completed (loss: 0.018153153359889984, acc: 1.0)
[2024-11-29 03:54:22,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:22,254][root][INFO] - Training Epoch: 10/10, step 330/574 completed (loss: 0.014643837697803974, acc: 1.0)
[2024-11-29 03:54:22,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:22,569][root][INFO] - Training Epoch: 10/10, step 331/574 completed (loss: 0.08402801305055618, acc: 0.9677419066429138)
[2024-11-29 03:54:22,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:22,957][root][INFO] - Training Epoch: 10/10, step 332/574 completed (loss: 0.05089174956083298, acc: 0.9824561476707458)
[2024-11-29 03:54:23,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:23,214][root][INFO] - Training Epoch: 10/10, step 333/574 completed (loss: 0.06362512707710266, acc: 0.96875)
[2024-11-29 03:54:23,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:23,502][root][INFO] - Training Epoch: 10/10, step 334/574 completed (loss: 0.013833620585501194, acc: 1.0)
[2024-11-29 03:54:23,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:23,778][root][INFO] - Training Epoch: 10/10, step 335/574 completed (loss: 0.010301074013113976, acc: 1.0)
[2024-11-29 03:54:23,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:24,086][root][INFO] - Training Epoch: 10/10, step 336/574 completed (loss: 0.3730391561985016, acc: 0.8399999737739563)
[2024-11-29 03:54:24,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:24,413][root][INFO] - Training Epoch: 10/10, step 337/574 completed (loss: 0.6849991679191589, acc: 0.7701149582862854)
[2024-11-29 03:54:24,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:24,766][root][INFO] - Training Epoch: 10/10, step 338/574 completed (loss: 0.6664656400680542, acc: 0.8297872543334961)
[2024-11-29 03:54:24,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:25,100][root][INFO] - Training Epoch: 10/10, step 339/574 completed (loss: 0.5859144926071167, acc: 0.8072289228439331)
[2024-11-29 03:54:25,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:25,367][root][INFO] - Training Epoch: 10/10, step 340/574 completed (loss: 0.005396032240241766, acc: 1.0)
[2024-11-29 03:54:25,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:25,621][root][INFO] - Training Epoch: 10/10, step 341/574 completed (loss: 0.061832230538129807, acc: 0.9743589758872986)
[2024-11-29 03:54:25,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:25,897][root][INFO] - Training Epoch: 10/10, step 342/574 completed (loss: 0.14904023706912994, acc: 0.9518072009086609)
[2024-11-29 03:54:26,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:26,156][root][INFO] - Training Epoch: 10/10, step 343/574 completed (loss: 0.5971037745475769, acc: 0.8679245114326477)
[2024-11-29 03:54:26,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:26,411][root][INFO] - Training Epoch: 10/10, step 344/574 completed (loss: 0.041210293769836426, acc: 1.0)
[2024-11-29 03:54:26,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:26,667][root][INFO] - Training Epoch: 10/10, step 345/574 completed (loss: 0.040928084403276443, acc: 0.9803921580314636)
[2024-11-29 03:54:26,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:26,921][root][INFO] - Training Epoch: 10/10, step 346/574 completed (loss: 0.16848985850811005, acc: 0.9402984976768494)
[2024-11-29 03:54:27,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:27,164][root][INFO] - Training Epoch: 10/10, step 347/574 completed (loss: 0.15473592281341553, acc: 0.949999988079071)
[2024-11-29 03:54:27,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:27,419][root][INFO] - Training Epoch: 10/10, step 348/574 completed (loss: 0.11428696662187576, acc: 0.9599999785423279)
[2024-11-29 03:54:27,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:27,858][root][INFO] - Training Epoch: 10/10, step 349/574 completed (loss: 0.3172289729118347, acc: 0.9722222089767456)
[2024-11-29 03:54:28,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:28,129][root][INFO] - Training Epoch: 10/10, step 350/574 completed (loss: 0.30357059836387634, acc: 0.9069767594337463)
[2024-11-29 03:54:28,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:28,416][root][INFO] - Training Epoch: 10/10, step 351/574 completed (loss: 0.1591922789812088, acc: 0.9487179517745972)
[2024-11-29 03:54:28,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:28,819][root][INFO] - Training Epoch: 10/10, step 352/574 completed (loss: 0.10735582560300827, acc: 0.9777777791023254)
[2024-11-29 03:54:28,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:29,063][root][INFO] - Training Epoch: 10/10, step 353/574 completed (loss: 0.004967217333614826, acc: 1.0)
[2024-11-29 03:54:29,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:29,311][root][INFO] - Training Epoch: 10/10, step 354/574 completed (loss: 0.11155491322278976, acc: 0.9615384340286255)
[2024-11-29 03:54:29,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:29,631][root][INFO] - Training Epoch: 10/10, step 355/574 completed (loss: 0.42328301072120667, acc: 0.901098906993866)
[2024-11-29 03:54:29,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:30,279][root][INFO] - Training Epoch: 10/10, step 356/574 completed (loss: 0.2969552278518677, acc: 0.8695651888847351)
[2024-11-29 03:54:30,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:30,591][root][INFO] - Training Epoch: 10/10, step 357/574 completed (loss: 0.31551820039749146, acc: 0.9239130616188049)
[2024-11-29 03:54:30,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:30,874][root][INFO] - Training Epoch: 10/10, step 358/574 completed (loss: 0.08112634718418121, acc: 0.9795918464660645)
[2024-11-29 03:54:31,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:31,119][root][INFO] - Training Epoch: 10/10, step 359/574 completed (loss: 0.003235887736082077, acc: 1.0)
[2024-11-29 03:54:31,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:31,374][root][INFO] - Training Epoch: 10/10, step 360/574 completed (loss: 0.18509837985038757, acc: 0.9230769276618958)
[2024-11-29 03:54:31,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:31,627][root][INFO] - Training Epoch: 10/10, step 361/574 completed (loss: 0.3575798273086548, acc: 0.9268292784690857)
[2024-11-29 03:54:31,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:31,885][root][INFO] - Training Epoch: 10/10, step 362/574 completed (loss: 0.24597257375717163, acc: 0.9111111164093018)
[2024-11-29 03:54:32,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:32,151][root][INFO] - Training Epoch: 10/10, step 363/574 completed (loss: 0.1537621021270752, acc: 0.9473684430122375)
[2024-11-29 03:54:32,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:32,413][root][INFO] - Training Epoch: 10/10, step 364/574 completed (loss: 0.09110677242279053, acc: 0.9756097793579102)
[2024-11-29 03:54:32,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:32,666][root][INFO] - Training Epoch: 10/10, step 365/574 completed (loss: 0.010693224146962166, acc: 1.0)
[2024-11-29 03:54:32,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:32,916][root][INFO] - Training Epoch: 10/10, step 366/574 completed (loss: 0.00736165652051568, acc: 1.0)
[2024-11-29 03:54:33,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:33,162][root][INFO] - Training Epoch: 10/10, step 367/574 completed (loss: 0.07897961884737015, acc: 0.95652174949646)
[2024-11-29 03:54:33,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:33,418][root][INFO] - Training Epoch: 10/10, step 368/574 completed (loss: 0.09712819010019302, acc: 0.9642857313156128)
[2024-11-29 03:54:33,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:33,660][root][INFO] - Training Epoch: 10/10, step 369/574 completed (loss: 0.3745900094509125, acc: 0.9375)
[2024-11-29 03:54:34,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:34,488][root][INFO] - Training Epoch: 10/10, step 370/574 completed (loss: 0.4472309350967407, acc: 0.8666666746139526)
[2024-11-29 03:54:35,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:35,704][root][INFO] - Training Epoch: 10/10, step 371/574 completed (loss: 0.24172653257846832, acc: 0.9150943160057068)
[2024-11-29 03:54:35,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:36,017][root][INFO] - Training Epoch: 10/10, step 372/574 completed (loss: 0.14670808613300323, acc: 0.9555555582046509)
[2024-11-29 03:54:36,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:36,338][root][INFO] - Training Epoch: 10/10, step 373/574 completed (loss: 0.04579883813858032, acc: 0.9821428656578064)
[2024-11-29 03:54:36,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:36,642][root][INFO] - Training Epoch: 10/10, step 374/574 completed (loss: 0.45444929599761963, acc: 0.9428571462631226)
[2024-11-29 03:54:36,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:36,952][root][INFO] - Training Epoch: 10/10, step 375/574 completed (loss: 0.011458409950137138, acc: 1.0)
[2024-11-29 03:54:37,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:37,256][root][INFO] - Training Epoch: 10/10, step 376/574 completed (loss: 0.36828964948654175, acc: 0.9130434989929199)
[2024-11-29 03:54:37,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:37,515][root][INFO] - Training Epoch: 10/10, step 377/574 completed (loss: 0.016946321353316307, acc: 1.0)
[2024-11-29 03:54:37,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:37,815][root][INFO] - Training Epoch: 10/10, step 378/574 completed (loss: 0.026837246492505074, acc: 0.9894737005233765)
[2024-11-29 03:54:38,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:38,597][root][INFO] - Training Epoch: 10/10, step 379/574 completed (loss: 0.18499039113521576, acc: 0.940119743347168)
[2024-11-29 03:54:38,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:39,063][root][INFO] - Training Epoch: 10/10, step 380/574 completed (loss: 0.16387037932872772, acc: 0.9248120188713074)
[2024-11-29 03:54:40,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:40,811][root][INFO] - Training Epoch: 10/10, step 381/574 completed (loss: 0.5095579624176025, acc: 0.8449198007583618)
[2024-11-29 03:54:41,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:41,574][root][INFO] - Training Epoch: 10/10, step 382/574 completed (loss: 0.1243232786655426, acc: 0.954954981803894)
[2024-11-29 03:54:41,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:41,823][root][INFO] - Training Epoch: 10/10, step 383/574 completed (loss: 0.08775589615106583, acc: 0.9642857313156128)
[2024-11-29 03:54:41,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:42,074][root][INFO] - Training Epoch: 10/10, step 384/574 completed (loss: 0.06526896357536316, acc: 0.9642857313156128)
[2024-11-29 03:54:42,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:42,320][root][INFO] - Training Epoch: 10/10, step 385/574 completed (loss: 0.021153273060917854, acc: 1.0)
[2024-11-29 03:54:42,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:42,555][root][INFO] - Training Epoch: 10/10, step 386/574 completed (loss: 0.008063587360084057, acc: 1.0)
[2024-11-29 03:54:42,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:42,810][root][INFO] - Training Epoch: 10/10, step 387/574 completed (loss: 0.04483804106712341, acc: 0.9736841917037964)
[2024-11-29 03:54:42,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:43,059][root][INFO] - Training Epoch: 10/10, step 388/574 completed (loss: 0.002628277987241745, acc: 1.0)
[2024-11-29 03:54:43,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:43,313][root][INFO] - Training Epoch: 10/10, step 389/574 completed (loss: 0.003181741340085864, acc: 1.0)
[2024-11-29 03:54:43,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:43,569][root][INFO] - Training Epoch: 10/10, step 390/574 completed (loss: 0.335286021232605, acc: 0.9047619104385376)
[2024-11-29 03:54:43,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:43,838][root][INFO] - Training Epoch: 10/10, step 391/574 completed (loss: 0.24581216275691986, acc: 0.9259259104728699)
[2024-11-29 03:54:44,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:44,145][root][INFO] - Training Epoch: 10/10, step 392/574 completed (loss: 0.30810022354125977, acc: 0.9029126167297363)
[2024-11-29 03:54:44,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:44,820][root][INFO] - Training Epoch: 10/10, step 393/574 completed (loss: 0.6104373335838318, acc: 0.845588207244873)
[2024-11-29 03:54:45,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:45,214][root][INFO] - Training Epoch: 10/10, step 394/574 completed (loss: 0.4643875062465668, acc: 0.8399999737739563)
[2024-11-29 03:54:45,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:45,648][root][INFO] - Training Epoch: 10/10, step 395/574 completed (loss: 0.34619665145874023, acc: 0.9097222089767456)
[2024-11-29 03:54:45,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:45,914][root][INFO] - Training Epoch: 10/10, step 396/574 completed (loss: 0.1323736608028412, acc: 0.9534883499145508)
[2024-11-29 03:54:46,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:46,169][root][INFO] - Training Epoch: 10/10, step 397/574 completed (loss: 0.012092065066099167, acc: 1.0)
[2024-11-29 03:54:46,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:46,451][root][INFO] - Training Epoch: 10/10, step 398/574 completed (loss: 0.1396719515323639, acc: 0.9767441749572754)
[2024-11-29 03:54:46,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:46,712][root][INFO] - Training Epoch: 10/10, step 399/574 completed (loss: 0.010048279538750648, acc: 1.0)
[2024-11-29 03:54:47,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:47,428][root][INFO] - Training Epoch: 10/10, step 400/574 completed (loss: 0.1392301321029663, acc: 0.9558823704719543)
[2024-11-29 03:54:47,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:47,692][root][INFO] - Training Epoch: 10/10, step 401/574 completed (loss: 0.23434920608997345, acc: 0.9466666579246521)
[2024-11-29 03:54:47,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:47,943][root][INFO] - Training Epoch: 10/10, step 402/574 completed (loss: 0.07946103066205978, acc: 0.9696969985961914)
[2024-11-29 03:54:48,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:48,192][root][INFO] - Training Epoch: 10/10, step 403/574 completed (loss: 0.08749980479478836, acc: 0.9696969985961914)
[2024-11-29 03:54:48,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:48,445][root][INFO] - Training Epoch: 10/10, step 404/574 completed (loss: 0.19952696561813354, acc: 0.9354838728904724)
[2024-11-29 03:54:48,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:48,701][root][INFO] - Training Epoch: 10/10, step 405/574 completed (loss: 0.005939951632171869, acc: 1.0)
[2024-11-29 03:54:48,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:48,978][root][INFO] - Training Epoch: 10/10, step 406/574 completed (loss: 0.021785274147987366, acc: 1.0)
[2024-11-29 03:54:49,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:49,237][root][INFO] - Training Epoch: 10/10, step 407/574 completed (loss: 0.05203980207443237, acc: 0.9722222089767456)
[2024-11-29 03:54:49,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:49,489][root][INFO] - Training Epoch: 10/10, step 408/574 completed (loss: 0.05510229244828224, acc: 0.9629629850387573)
[2024-11-29 03:54:49,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:49,738][root][INFO] - Training Epoch: 10/10, step 409/574 completed (loss: 0.03386995941400528, acc: 1.0)
[2024-11-29 03:54:49,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:49,997][root][INFO] - Training Epoch: 10/10, step 410/574 completed (loss: 0.03828796371817589, acc: 1.0)
[2024-11-29 03:54:50,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:51,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:51,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:52,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:52,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:53,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:53,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:53,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:54,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:54,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:55,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:55,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:56,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:56,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:57,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:57,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:57,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:58,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:58,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:59,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:59,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:54:59,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:00,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:00,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:01,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:01,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:02,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:02,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:03,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:03,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:04,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:04,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:05,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:05,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:06,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:06,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:06,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:07,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:07,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:08,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:08,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:09,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:09,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:09,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:10,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:10,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:10,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:11,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:11,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:12,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:12,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:13,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:13,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:13,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:14,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:14,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:15,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:15,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:15,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:16,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:16,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:17,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:18,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:18,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:18,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:19,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:19,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:20,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:20,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:21,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:21,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:22,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:22,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:22,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:23,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:23,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:23,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:24,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:24,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:25,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:25,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:25,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:26,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:26,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:27,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:27,791][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.9202, device='cuda:0') eval_epoch_loss=tensor(1.0717, device='cuda:0') eval_epoch_acc=tensor(0.7616, device='cuda:0')
[2024-11-29 03:55:27,792][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:55:27,793][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:55:28,111][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_10_step_411_loss_1.0716547966003418/model.pt
[2024-11-29 03:55:28,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:28,400][root][INFO] - Training Epoch: 10/10, step 411/574 completed (loss: 0.11156706511974335, acc: 0.9642857313156128)
[2024-11-29 03:55:28,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:28,649][root][INFO] - Training Epoch: 10/10, step 412/574 completed (loss: 0.008729079738259315, acc: 1.0)
[2024-11-29 03:55:28,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:28,905][root][INFO] - Training Epoch: 10/10, step 413/574 completed (loss: 0.014373882673680782, acc: 1.0)
[2024-11-29 03:55:29,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:29,163][root][INFO] - Training Epoch: 10/10, step 414/574 completed (loss: 0.006365722510963678, acc: 1.0)
[2024-11-29 03:55:29,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:29,448][root][INFO] - Training Epoch: 10/10, step 415/574 completed (loss: 0.27892178297042847, acc: 0.8823529481887817)
[2024-11-29 03:55:29,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:29,759][root][INFO] - Training Epoch: 10/10, step 416/574 completed (loss: 0.008391128852963448, acc: 1.0)
[2024-11-29 03:55:29,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:30,079][root][INFO] - Training Epoch: 10/10, step 417/574 completed (loss: 0.029815124347805977, acc: 1.0)
[2024-11-29 03:55:30,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:30,376][root][INFO] - Training Epoch: 10/10, step 418/574 completed (loss: 0.06214918941259384, acc: 0.9750000238418579)
[2024-11-29 03:55:30,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:30,681][root][INFO] - Training Epoch: 10/10, step 419/574 completed (loss: 0.017388787120580673, acc: 1.0)
[2024-11-29 03:55:30,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:30,986][root][INFO] - Training Epoch: 10/10, step 420/574 completed (loss: 0.1163816824555397, acc: 0.9523809552192688)
[2024-11-29 03:55:31,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:31,325][root][INFO] - Training Epoch: 10/10, step 421/574 completed (loss: 0.039087411016225815, acc: 1.0)
[2024-11-29 03:55:31,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:31,617][root][INFO] - Training Epoch: 10/10, step 422/574 completed (loss: 0.36848995089530945, acc: 0.9375)
[2024-11-29 03:55:31,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:31,938][root][INFO] - Training Epoch: 10/10, step 423/574 completed (loss: 0.05899661034345627, acc: 1.0)
[2024-11-29 03:55:32,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:32,237][root][INFO] - Training Epoch: 10/10, step 424/574 completed (loss: 0.029061174020171165, acc: 1.0)
[2024-11-29 03:55:32,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:32,504][root][INFO] - Training Epoch: 10/10, step 425/574 completed (loss: 0.023486658930778503, acc: 1.0)
[2024-11-29 03:55:32,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:32,761][root][INFO] - Training Epoch: 10/10, step 426/574 completed (loss: 0.08589658886194229, acc: 0.95652174949646)
[2024-11-29 03:55:32,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:33,029][root][INFO] - Training Epoch: 10/10, step 427/574 completed (loss: 0.13325469195842743, acc: 0.9459459185600281)
[2024-11-29 03:55:33,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:33,290][root][INFO] - Training Epoch: 10/10, step 428/574 completed (loss: 0.022384151816368103, acc: 1.0)
[2024-11-29 03:55:33,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:33,550][root][INFO] - Training Epoch: 10/10, step 429/574 completed (loss: 0.01616532728075981, acc: 1.0)
[2024-11-29 03:55:33,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:33,875][root][INFO] - Training Epoch: 10/10, step 430/574 completed (loss: 0.0033516495022922754, acc: 1.0)
[2024-11-29 03:55:34,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:34,161][root][INFO] - Training Epoch: 10/10, step 431/574 completed (loss: 0.06720585376024246, acc: 0.9629629850387573)
[2024-11-29 03:55:34,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:34,482][root][INFO] - Training Epoch: 10/10, step 432/574 completed (loss: 0.014029099605977535, acc: 1.0)
[2024-11-29 03:55:34,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:34,850][root][INFO] - Training Epoch: 10/10, step 433/574 completed (loss: 0.061338067054748535, acc: 0.9722222089767456)
[2024-11-29 03:55:35,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:35,158][root][INFO] - Training Epoch: 10/10, step 434/574 completed (loss: 0.005219243932515383, acc: 1.0)
[2024-11-29 03:55:35,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:35,492][root][INFO] - Training Epoch: 10/10, step 435/574 completed (loss: 0.30316218733787537, acc: 0.9090909361839294)
[2024-11-29 03:55:35,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:35,831][root][INFO] - Training Epoch: 10/10, step 436/574 completed (loss: 0.22276271879673004, acc: 0.9166666865348816)
[2024-11-29 03:55:36,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:36,177][root][INFO] - Training Epoch: 10/10, step 437/574 completed (loss: 0.2161518633365631, acc: 0.9545454382896423)
[2024-11-29 03:55:36,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:36,465][root][INFO] - Training Epoch: 10/10, step 438/574 completed (loss: 0.03987345099449158, acc: 0.9523809552192688)
[2024-11-29 03:55:36,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:36,806][root][INFO] - Training Epoch: 10/10, step 439/574 completed (loss: 0.1393861323595047, acc: 0.9487179517745972)
[2024-11-29 03:55:37,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:37,405][root][INFO] - Training Epoch: 10/10, step 440/574 completed (loss: 0.22468163073062897, acc: 0.9242424368858337)
[2024-11-29 03:55:37,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:38,360][root][INFO] - Training Epoch: 10/10, step 441/574 completed (loss: 0.3870527446269989, acc: 0.8880000114440918)
[2024-11-29 03:55:38,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:38,824][root][INFO] - Training Epoch: 10/10, step 442/574 completed (loss: 0.48013603687286377, acc: 0.8467742204666138)
[2024-11-29 03:55:39,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:39,728][root][INFO] - Training Epoch: 10/10, step 443/574 completed (loss: 0.4408024251461029, acc: 0.8557214140892029)
[2024-11-29 03:55:39,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:40,050][root][INFO] - Training Epoch: 10/10, step 444/574 completed (loss: 0.15144221484661102, acc: 0.9056603908538818)
[2024-11-29 03:55:40,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:40,548][root][INFO] - Training Epoch: 10/10, step 445/574 completed (loss: 0.011164046823978424, acc: 1.0)
[2024-11-29 03:55:40,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:40,799][root][INFO] - Training Epoch: 10/10, step 446/574 completed (loss: 0.5194843411445618, acc: 0.9130434989929199)
[2024-11-29 03:55:40,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:41,103][root][INFO] - Training Epoch: 10/10, step 447/574 completed (loss: 0.2664412558078766, acc: 0.9615384340286255)
[2024-11-29 03:55:41,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:41,412][root][INFO] - Training Epoch: 10/10, step 448/574 completed (loss: 0.05083291977643967, acc: 1.0)
[2024-11-29 03:55:41,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:41,739][root][INFO] - Training Epoch: 10/10, step 449/574 completed (loss: 0.05572926253080368, acc: 0.9850746393203735)
[2024-11-29 03:55:41,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:42,025][root][INFO] - Training Epoch: 10/10, step 450/574 completed (loss: 0.083183154463768, acc: 0.9861111044883728)
[2024-11-29 03:55:42,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:42,340][root][INFO] - Training Epoch: 10/10, step 451/574 completed (loss: 0.12741400301456451, acc: 0.95652174949646)
[2024-11-29 03:55:42,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:42,663][root][INFO] - Training Epoch: 10/10, step 452/574 completed (loss: 0.08347313851118088, acc: 0.9871794581413269)
[2024-11-29 03:55:42,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:42,973][root][INFO] - Training Epoch: 10/10, step 453/574 completed (loss: 0.1915261596441269, acc: 0.9078947305679321)
[2024-11-29 03:55:43,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:43,215][root][INFO] - Training Epoch: 10/10, step 454/574 completed (loss: 0.03943770378828049, acc: 1.0)
[2024-11-29 03:55:43,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:43,537][root][INFO] - Training Epoch: 10/10, step 455/574 completed (loss: 0.05258629843592644, acc: 1.0)
[2024-11-29 03:55:43,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:43,848][root][INFO] - Training Epoch: 10/10, step 456/574 completed (loss: 0.25316235423088074, acc: 0.9278350472450256)
[2024-11-29 03:55:44,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:44,196][root][INFO] - Training Epoch: 10/10, step 457/574 completed (loss: 0.03182648494839668, acc: 1.0)
[2024-11-29 03:55:44,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:44,632][root][INFO] - Training Epoch: 10/10, step 458/574 completed (loss: 0.3379250764846802, acc: 0.9011628031730652)
[2024-11-29 03:55:44,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:44,917][root][INFO] - Training Epoch: 10/10, step 459/574 completed (loss: 0.07197557389736176, acc: 1.0)
[2024-11-29 03:55:45,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:45,248][root][INFO] - Training Epoch: 10/10, step 460/574 completed (loss: 0.20128431916236877, acc: 0.9382715821266174)
[2024-11-29 03:55:45,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:45,572][root][INFO] - Training Epoch: 10/10, step 461/574 completed (loss: 0.10815034061670303, acc: 0.9722222089767456)
[2024-11-29 03:55:45,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:45,907][root][INFO] - Training Epoch: 10/10, step 462/574 completed (loss: 0.1411244422197342, acc: 0.96875)
[2024-11-29 03:55:46,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:46,223][root][INFO] - Training Epoch: 10/10, step 463/574 completed (loss: 0.06242236867547035, acc: 0.9615384340286255)
[2024-11-29 03:55:46,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:46,558][root][INFO] - Training Epoch: 10/10, step 464/574 completed (loss: 0.260052889585495, acc: 0.9347826242446899)
[2024-11-29 03:55:46,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:46,882][root][INFO] - Training Epoch: 10/10, step 465/574 completed (loss: 0.18416115641593933, acc: 0.9404761791229248)
[2024-11-29 03:55:47,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:47,213][root][INFO] - Training Epoch: 10/10, step 466/574 completed (loss: 0.7246542572975159, acc: 0.8313252925872803)
[2024-11-29 03:55:47,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:47,604][root][INFO] - Training Epoch: 10/10, step 467/574 completed (loss: 0.0700603723526001, acc: 0.9819819927215576)
[2024-11-29 03:55:47,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:47,942][root][INFO] - Training Epoch: 10/10, step 468/574 completed (loss: 0.38278305530548096, acc: 0.893203854560852)
[2024-11-29 03:55:48,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:48,241][root][INFO] - Training Epoch: 10/10, step 469/574 completed (loss: 0.4213274121284485, acc: 0.8861788511276245)
[2024-11-29 03:55:48,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:48,514][root][INFO] - Training Epoch: 10/10, step 470/574 completed (loss: 0.059766486287117004, acc: 0.9583333134651184)
[2024-11-29 03:55:48,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:48,759][root][INFO] - Training Epoch: 10/10, step 471/574 completed (loss: 0.03400129824876785, acc: 1.0)
[2024-11-29 03:55:49,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:49,237][root][INFO] - Training Epoch: 10/10, step 472/574 completed (loss: 0.45879843831062317, acc: 0.843137264251709)
[2024-11-29 03:55:49,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:49,609][root][INFO] - Training Epoch: 10/10, step 473/574 completed (loss: 0.6072847843170166, acc: 0.8253275156021118)
[2024-11-29 03:55:49,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:49,953][root][INFO] - Training Epoch: 10/10, step 474/574 completed (loss: 0.208613321185112, acc: 0.9583333134651184)
[2024-11-29 03:55:50,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:50,233][root][INFO] - Training Epoch: 10/10, step 475/574 completed (loss: 0.22890029847621918, acc: 0.9386503100395203)
[2024-11-29 03:55:50,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:50,516][root][INFO] - Training Epoch: 10/10, step 476/574 completed (loss: 0.1824008822441101, acc: 0.9496402740478516)
[2024-11-29 03:55:50,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:50,866][root][INFO] - Training Epoch: 10/10, step 477/574 completed (loss: 0.45576512813568115, acc: 0.8542713522911072)
[2024-11-29 03:55:51,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:51,162][root][INFO] - Training Epoch: 10/10, step 478/574 completed (loss: 0.06131933256983757, acc: 1.0)
[2024-11-29 03:55:51,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:51,420][root][INFO] - Training Epoch: 10/10, step 479/574 completed (loss: 0.09456586837768555, acc: 1.0)
[2024-11-29 03:55:51,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:51,719][root][INFO] - Training Epoch: 10/10, step 480/574 completed (loss: 0.32554230093955994, acc: 0.9259259104728699)
[2024-11-29 03:55:51,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:52,059][root][INFO] - Training Epoch: 10/10, step 481/574 completed (loss: 0.6553362607955933, acc: 0.8500000238418579)
[2024-11-29 03:55:52,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:52,372][root][INFO] - Training Epoch: 10/10, step 482/574 completed (loss: 0.5551956295967102, acc: 0.8500000238418579)
[2024-11-29 03:55:52,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:52,793][root][INFO] - Training Epoch: 10/10, step 483/574 completed (loss: 0.3672262728214264, acc: 0.8965517282485962)
[2024-11-29 03:55:52,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:53,066][root][INFO] - Training Epoch: 10/10, step 484/574 completed (loss: 0.026930054649710655, acc: 1.0)
[2024-11-29 03:55:53,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:53,387][root][INFO] - Training Epoch: 10/10, step 485/574 completed (loss: 0.023985665291547775, acc: 1.0)
[2024-11-29 03:55:53,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:53,672][root][INFO] - Training Epoch: 10/10, step 486/574 completed (loss: 0.08563070744276047, acc: 1.0)
[2024-11-29 03:55:53,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:53,969][root][INFO] - Training Epoch: 10/10, step 487/574 completed (loss: 0.2621900737285614, acc: 0.9047619104385376)
[2024-11-29 03:55:54,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:54,274][root][INFO] - Training Epoch: 10/10, step 488/574 completed (loss: 0.06815127283334732, acc: 1.0)
[2024-11-29 03:55:54,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:54,624][root][INFO] - Training Epoch: 10/10, step 489/574 completed (loss: 0.3202713131904602, acc: 0.9076923131942749)
[2024-11-29 03:55:54,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:54,909][root][INFO] - Training Epoch: 10/10, step 490/574 completed (loss: 0.024847762659192085, acc: 1.0)
[2024-11-29 03:55:55,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:55,173][root][INFO] - Training Epoch: 10/10, step 491/574 completed (loss: 0.04577488824725151, acc: 1.0)
[2024-11-29 03:55:55,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:55,499][root][INFO] - Training Epoch: 10/10, step 492/574 completed (loss: 0.03430117294192314, acc: 1.0)
[2024-11-29 03:55:55,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:55,781][root][INFO] - Training Epoch: 10/10, step 493/574 completed (loss: 0.1817554235458374, acc: 0.9655172228813171)
[2024-11-29 03:55:55,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:56,057][root][INFO] - Training Epoch: 10/10, step 494/574 completed (loss: 0.035088587552309036, acc: 1.0)
[2024-11-29 03:55:56,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:56,381][root][INFO] - Training Epoch: 10/10, step 495/574 completed (loss: 0.5726661682128906, acc: 0.8947368264198303)
[2024-11-29 03:55:56,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:56,706][root][INFO] - Training Epoch: 10/10, step 496/574 completed (loss: 0.4329633116722107, acc: 0.8839285969734192)
[2024-11-29 03:55:56,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:57,105][root][INFO] - Training Epoch: 10/10, step 497/574 completed (loss: 0.16521020233631134, acc: 0.9550561904907227)
[2024-11-29 03:55:57,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:57,437][root][INFO] - Training Epoch: 10/10, step 498/574 completed (loss: 0.3524118661880493, acc: 0.8764045238494873)
[2024-11-29 03:55:57,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:57,744][root][INFO] - Training Epoch: 10/10, step 499/574 completed (loss: 0.8236033916473389, acc: 0.7446808218955994)
[2024-11-29 03:55:57,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:58,052][root][INFO] - Training Epoch: 10/10, step 500/574 completed (loss: 0.3113112151622772, acc: 0.8804348111152649)
[2024-11-29 03:55:58,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:58,311][root][INFO] - Training Epoch: 10/10, step 501/574 completed (loss: 0.009398378431797028, acc: 1.0)
[2024-11-29 03:55:58,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:58,566][root][INFO] - Training Epoch: 10/10, step 502/574 completed (loss: 0.00469792727380991, acc: 1.0)
[2024-11-29 03:55:58,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:58,852][root][INFO] - Training Epoch: 10/10, step 503/574 completed (loss: 0.2042134404182434, acc: 0.9259259104728699)
[2024-11-29 03:55:59,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:59,161][root][INFO] - Training Epoch: 10/10, step 504/574 completed (loss: 0.0335509330034256, acc: 1.0)
[2024-11-29 03:55:59,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:59,482][root][INFO] - Training Epoch: 10/10, step 505/574 completed (loss: 0.4510621428489685, acc: 0.849056601524353)
[2024-11-29 03:55:59,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:55:59,802][root][INFO] - Training Epoch: 10/10, step 506/574 completed (loss: 0.751915693283081, acc: 0.7931034564971924)
[2024-11-29 03:56:00,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:00,615][root][INFO] - Training Epoch: 10/10, step 507/574 completed (loss: 0.7677165269851685, acc: 0.8108108043670654)
[2024-11-29 03:56:00,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:01,161][root][INFO] - Training Epoch: 10/10, step 508/574 completed (loss: 0.6595720052719116, acc: 0.8169013857841492)
[2024-11-29 03:56:01,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:01,460][root][INFO] - Training Epoch: 10/10, step 509/574 completed (loss: 0.0058662001974880695, acc: 1.0)
[2024-11-29 03:56:01,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:01,754][root][INFO] - Training Epoch: 10/10, step 510/574 completed (loss: 0.020784884691238403, acc: 1.0)
[2024-11-29 03:56:01,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:02,019][root][INFO] - Training Epoch: 10/10, step 511/574 completed (loss: 0.06917251646518707, acc: 1.0)
[2024-11-29 03:56:04,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:05,727][root][INFO] - Training Epoch: 10/10, step 512/574 completed (loss: 0.7992315292358398, acc: 0.7857142686843872)
[2024-11-29 03:56:06,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:06,827][root][INFO] - Training Epoch: 10/10, step 513/574 completed (loss: 0.4174024164676666, acc: 0.8888888955116272)
[2024-11-29 03:56:07,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:07,164][root][INFO] - Training Epoch: 10/10, step 514/574 completed (loss: 0.4895452857017517, acc: 0.8214285969734192)
[2024-11-29 03:56:07,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:07,484][root][INFO] - Training Epoch: 10/10, step 515/574 completed (loss: 0.1328846663236618, acc: 0.9666666388511658)
[2024-11-29 03:56:08,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:08,455][root][INFO] - Training Epoch: 10/10, step 516/574 completed (loss: 0.33048728108406067, acc: 0.9166666865348816)
[2024-11-29 03:56:08,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:08,721][root][INFO] - Training Epoch: 10/10, step 517/574 completed (loss: 0.008916053920984268, acc: 1.0)
[2024-11-29 03:56:08,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:09,034][root][INFO] - Training Epoch: 10/10, step 518/574 completed (loss: 0.008673720993101597, acc: 1.0)
[2024-11-29 03:56:09,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:09,315][root][INFO] - Training Epoch: 10/10, step 519/574 completed (loss: 0.05235893651843071, acc: 1.0)
[2024-11-29 03:56:09,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:09,670][root][INFO] - Training Epoch: 10/10, step 520/574 completed (loss: 0.13534538447856903, acc: 0.9259259104728699)
[2024-11-29 03:56:10,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:11,167][root][INFO] - Training Epoch: 10/10, step 521/574 completed (loss: 0.5634549260139465, acc: 0.8262711763381958)
[2024-11-29 03:56:11,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:11,556][root][INFO] - Training Epoch: 10/10, step 522/574 completed (loss: 0.2544718086719513, acc: 0.9328358173370361)
[2024-11-29 03:56:11,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:11,956][root][INFO] - Training Epoch: 10/10, step 523/574 completed (loss: 0.23967495560646057, acc: 0.8978102207183838)
[2024-11-29 03:56:12,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:12,693][root][INFO] - Training Epoch: 10/10, step 524/574 completed (loss: 0.49499228596687317, acc: 0.8700000047683716)
[2024-11-29 03:56:12,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:12,955][root][INFO] - Training Epoch: 10/10, step 525/574 completed (loss: 0.07688359171152115, acc: 0.9814814925193787)
[2024-11-29 03:56:13,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:13,221][root][INFO] - Training Epoch: 10/10, step 526/574 completed (loss: 0.039968714118003845, acc: 1.0)
[2024-11-29 03:56:13,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:13,488][root][INFO] - Training Epoch: 10/10, step 527/574 completed (loss: 0.014304895885288715, acc: 1.0)
[2024-11-29 03:56:13,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:13,815][root][INFO] - Training Epoch: 10/10, step 528/574 completed (loss: 0.5510677099227905, acc: 0.8852459192276001)
[2024-11-29 03:56:14,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:14,125][root][INFO] - Training Epoch: 10/10, step 529/574 completed (loss: 0.09950415045022964, acc: 0.9661017060279846)
[2024-11-29 03:56:14,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:14,408][root][INFO] - Training Epoch: 10/10, step 530/574 completed (loss: 0.8815885186195374, acc: 0.7906976938247681)
[2024-11-29 03:56:14,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:14,704][root][INFO] - Training Epoch: 10/10, step 531/574 completed (loss: 0.27470654249191284, acc: 0.8863636255264282)
[2024-11-29 03:56:14,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:15,006][root][INFO] - Training Epoch: 10/10, step 532/574 completed (loss: 0.587411642074585, acc: 0.849056601524353)
[2024-11-29 03:56:15,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:15,296][root][INFO] - Training Epoch: 10/10, step 533/574 completed (loss: 0.16202203929424286, acc: 0.9318181872367859)
[2024-11-29 03:56:15,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:15,553][root][INFO] - Training Epoch: 10/10, step 534/574 completed (loss: 0.20110952854156494, acc: 0.9200000166893005)
[2024-11-29 03:56:15,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:15,842][root][INFO] - Training Epoch: 10/10, step 535/574 completed (loss: 0.036625806242227554, acc: 1.0)
[2024-11-29 03:56:16,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:16,146][root][INFO] - Training Epoch: 10/10, step 536/574 completed (loss: 0.26455458998680115, acc: 0.9545454382896423)
[2024-11-29 03:56:16,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:16,597][root][INFO] - Training Epoch: 10/10, step 537/574 completed (loss: 0.08408353477716446, acc: 0.9846153855323792)
[2024-11-29 03:56:16,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:16,937][root][INFO] - Training Epoch: 10/10, step 538/574 completed (loss: 0.1205902248620987, acc: 0.953125)
[2024-11-29 03:56:17,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:17,380][root][INFO] - Training Epoch: 10/10, step 539/574 completed (loss: 0.23606567084789276, acc: 0.9375)
[2024-11-29 03:56:17,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:17,697][root][INFO] - Training Epoch: 10/10, step 540/574 completed (loss: 1.0432696342468262, acc: 0.6969696879386902)
[2024-11-29 03:56:17,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:17,972][root][INFO] - Training Epoch: 10/10, step 541/574 completed (loss: 0.0069286273792386055, acc: 1.0)
[2024-11-29 03:56:18,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:18,252][root][INFO] - Training Epoch: 10/10, step 542/574 completed (loss: 0.02522318623960018, acc: 1.0)
[2024-11-29 03:56:18,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:18,576][root][INFO] - Training Epoch: 10/10, step 543/574 completed (loss: 0.06210148334503174, acc: 0.95652174949646)
[2024-11-29 03:56:18,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:18,873][root][INFO] - Training Epoch: 10/10, step 544/574 completed (loss: 0.017044203355908394, acc: 1.0)
[2024-11-29 03:56:19,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:19,186][root][INFO] - Training Epoch: 10/10, step 545/574 completed (loss: 0.010996936820447445, acc: 1.0)
[2024-11-29 03:56:19,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:19,499][root][INFO] - Training Epoch: 10/10, step 546/574 completed (loss: 0.07936099916696548, acc: 0.9714285731315613)
[2024-11-29 03:56:19,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:19,829][root][INFO] - Training Epoch: 10/10, step 547/574 completed (loss: 0.010196365416049957, acc: 1.0)
[2024-11-29 03:56:20,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:20,177][root][INFO] - Training Epoch: 10/10, step 548/574 completed (loss: 0.06188799813389778, acc: 0.9677419066429138)
[2024-11-29 03:56:20,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:20,484][root][INFO] - Training Epoch: 10/10, step 549/574 completed (loss: 0.01044030673801899, acc: 1.0)
[2024-11-29 03:56:20,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:20,759][root][INFO] - Training Epoch: 10/10, step 550/574 completed (loss: 0.0337822400033474, acc: 1.0)
[2024-11-29 03:56:20,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:21,062][root][INFO] - Training Epoch: 10/10, step 551/574 completed (loss: 0.030061304569244385, acc: 1.0)
[2024-11-29 03:56:21,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:21,416][root][INFO] - Training Epoch: 10/10, step 552/574 completed (loss: 0.06958893686532974, acc: 0.9714285731315613)
[2024-11-29 03:56:21,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:21,733][root][INFO] - Training Epoch: 10/10, step 553/574 completed (loss: 0.252741277217865, acc: 0.9343065619468689)
[2024-11-29 03:56:22,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:22,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:23,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:23,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:24,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:24,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:25,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:25,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:26,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:26,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:26,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:27,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:27,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:28,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:28,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:29,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:29,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:29,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:30,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:30,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:30,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:31,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:31,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:32,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:32,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:32,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:33,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:33,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:34,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:34,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:35,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:35,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:35,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:36,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:36,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:37,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:37,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:38,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:38,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:39,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:39,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:40,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:40,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:40,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:41,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:41,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:42,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:42,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:43,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:43,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:43,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:44,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:44,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:45,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:45,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:45,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:46,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:46,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:47,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:47,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:48,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:48,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:49,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:49,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:50,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:50,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:50,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:51,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:52,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:52,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:52,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:53,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:53,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:54,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:54,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:55,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:55,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:56,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:56,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:56,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:57,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:57,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:58,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:58,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:59,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:56:59,667][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.2601, device='cuda:0') eval_epoch_loss=tensor(1.1817, device='cuda:0') eval_epoch_acc=tensor(0.7632, device='cuda:0')
[2024-11-29 03:56:59,668][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-11-29 03:56:59,669][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-29 03:57:00,073][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_freeze_llm/asr_epoch_10_step_554_loss_1.1817495822906494/model.pt
[2024-11-29 03:57:00,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:00,479][root][INFO] - Training Epoch: 10/10, step 554/574 completed (loss: 0.12629471719264984, acc: 0.951724112033844)
[2024-11-29 03:57:00,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:00,785][root][INFO] - Training Epoch: 10/10, step 555/574 completed (loss: 0.27300575375556946, acc: 0.9214285612106323)
[2024-11-29 03:57:00,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:01,108][root][INFO] - Training Epoch: 10/10, step 556/574 completed (loss: 0.25284335017204285, acc: 0.9536423683166504)
[2024-11-29 03:57:01,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:01,438][root][INFO] - Training Epoch: 10/10, step 557/574 completed (loss: 0.05696028098464012, acc: 0.9829059839248657)
[2024-11-29 03:57:01,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:01,740][root][INFO] - Training Epoch: 10/10, step 558/574 completed (loss: 0.029664723202586174, acc: 1.0)
[2024-11-29 03:57:01,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:02,064][root][INFO] - Training Epoch: 10/10, step 559/574 completed (loss: 0.08173157274723053, acc: 0.9615384340286255)
[2024-11-29 03:57:02,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:02,355][root][INFO] - Training Epoch: 10/10, step 560/574 completed (loss: 0.008713758550584316, acc: 1.0)
[2024-11-29 03:57:02,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:02,678][root][INFO] - Training Epoch: 10/10, step 561/574 completed (loss: 0.019222624599933624, acc: 1.0)
[2024-11-29 03:57:02,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:03,021][root][INFO] - Training Epoch: 10/10, step 562/574 completed (loss: 0.2859085202217102, acc: 0.9111111164093018)
[2024-11-29 03:57:03,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:03,320][root][INFO] - Training Epoch: 10/10, step 563/574 completed (loss: 0.16377098858356476, acc: 0.9740259647369385)
[2024-11-29 03:57:03,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:03,609][root][INFO] - Training Epoch: 10/10, step 564/574 completed (loss: 0.07583040744066238, acc: 0.9791666865348816)
[2024-11-29 03:57:03,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:03,927][root][INFO] - Training Epoch: 10/10, step 565/574 completed (loss: 0.2679895758628845, acc: 0.931034505367279)
[2024-11-29 03:57:04,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:04,207][root][INFO] - Training Epoch: 10/10, step 566/574 completed (loss: 0.08358053117990494, acc: 0.976190447807312)
[2024-11-29 03:57:04,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:04,517][root][INFO] - Training Epoch: 10/10, step 567/574 completed (loss: 0.01727176271378994, acc: 1.0)
[2024-11-29 03:57:04,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:04,848][root][INFO] - Training Epoch: 10/10, step 568/574 completed (loss: 0.03382887318730354, acc: 1.0)
[2024-11-29 03:57:05,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:05,264][root][INFO] - Training Epoch: 10/10, step 569/574 completed (loss: 0.22240060567855835, acc: 0.9197860956192017)
[2024-11-29 03:57:05,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:05,511][root][INFO] - Training Epoch: 10/10, step 570/574 completed (loss: 0.008628916926681995, acc: 1.0)
[2024-11-29 03:57:05,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:05,807][root][INFO] - Training Epoch: 10/10, step 571/574 completed (loss: 0.099671371281147, acc: 0.9914529919624329)
[2024-11-29 03:57:05,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:06,118][root][INFO] - Training Epoch: 10/10, step 572/574 completed (loss: 0.5904117226600647, acc: 0.8622449040412903)
[2024-11-29 03:57:06,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-29 03:57:06,464][root][INFO] - Training Epoch: 10/10, step 573/574 completed (loss: 0.22666506469249725, acc: 0.9182389974594116)
[2024-11-29 03:57:06,987][slam_llm.utils.train_utils][INFO] - Epoch 10: train_perplexity=1.3051, train_epoch_loss=0.2663, epoch time 379.3164415676147s
[2024-11-29 03:57:06,987][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-11-29 03:57:06,987][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 22 GB
[2024-11-29 03:57:06,987][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-11-29 03:57:06,987][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 20
[2024-11-29 03:57:06,988][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-29 03:57:06,991][root][INFO] - Key: avg_train_prep, Value: 4.626709461212158
[2024-11-29 03:57:06,991][root][INFO] - Key: avg_train_loss, Value: 0.8587422370910645
[2024-11-29 03:57:06,992][root][INFO] - Key: avg_train_acc, Value: 0.7973165512084961
[2024-11-29 03:57:06,992][root][INFO] - Key: avg_eval_prep, Value: 5.433770179748535
[2024-11-29 03:57:06,992][root][INFO] - Key: avg_eval_loss, Value: 1.333640217781067
[2024-11-29 03:57:06,992][root][INFO] - Key: avg_eval_acc, Value: 0.696800947189331
[2024-11-29 03:57:06,992][root][INFO] - Key: avg_epoch_time, Value: 382.134709713608
[2024-11-29 03:57:06,992][root][INFO] - Key: avg_checkpoint_time, Value: 0.3283179242629558
