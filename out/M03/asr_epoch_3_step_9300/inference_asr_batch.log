[2024-08-17 22:26:22,241][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'num_workers_dataloader': 2, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 1, 'use_peft': False, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'v_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/out/tllama-pho-20240816/M03', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True}
[2024-08-17 22:26:22,246][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': 'NO_SHARD', 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-08-17 22:26:22,254][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'tinyllama', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/models/TinyLlama-1.1B-Chat-v1.0', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'encoder_name': 'wav2p', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': False, 'encoder_type': 'finetune', 'dual_encoder': False, 'encoder2_dim': 1024}
[2024-08-17 22:32:35,782][slam_llm.utils.train_utils][INFO] - --> Module wav2p
[2024-08-17 22:32:35,792][slam_llm.utils.train_utils][INFO] - --> wav2p has 315.43872 Million params

[2024-08-17 22:32:35,803][slam_llm.utils.train_utils][INFO] - --> Module wav2p
[2024-08-17 22:32:35,817][slam_llm.utils.train_utils][INFO] - --> wav2p has 0.0 Million params

[2024-08-17 22:32:40,806][slam_llm.utils.train_utils][INFO] - --> Module tinyllama
[2024-08-17 22:32:40,812][slam_llm.utils.train_utils][INFO] - --> tinyllama has 1100.048384 Million params

[2024-08-17 22:32:40,824][slam_llm.utils.train_utils][INFO] - --> Module tinyllama
[2024-08-17 22:32:40,827][slam_llm.utils.train_utils][INFO] - --> tinyllama has 0.0 Million params

[2024-08-17 22:32:40,948][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-08-17 22:32:40,949][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2024-08-17 22:32:40,951][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/out/tllama-pho-20240816/M03/asr_epoch_3_step_9300/model.pt
[2024-08-17 22:33:10,184][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'num_workers_dataloader': 2, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 1, 'use_peft': False, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'v_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/out/tllama-pho-20240816/M03', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True}
[2024-08-17 22:33:10,184][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': 'NO_SHARD', 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-08-17 22:33:10,185][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'tinyllama', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/models/TinyLlama-1.1B-Chat-v1.0', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'encoder_name': 'wav2p', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': False, 'encoder_type': 'finetune', 'dual_encoder': False, 'encoder2_dim': 1024}
[2024-08-17 22:33:12,152][slam_llm.utils.train_utils][INFO] - --> Module wav2p
[2024-08-17 22:33:12,153][slam_llm.utils.train_utils][INFO] - --> wav2p has 315.43872 Million params

[2024-08-17 22:33:12,156][slam_llm.utils.train_utils][INFO] - --> Module wav2p
[2024-08-17 22:33:12,157][slam_llm.utils.train_utils][INFO] - --> wav2p has 0.0 Million params

[2024-08-17 22:33:17,181][slam_llm.utils.train_utils][INFO] - --> Module tinyllama
[2024-08-17 22:33:17,183][slam_llm.utils.train_utils][INFO] - --> tinyllama has 1100.048384 Million params

[2024-08-17 22:33:17,188][slam_llm.utils.train_utils][INFO] - --> Module tinyllama
[2024-08-17 22:33:17,193][slam_llm.utils.train_utils][INFO] - --> tinyllama has 0.0 Million params

[2024-08-17 22:33:17,318][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-08-17 22:33:17,318][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2024-08-17 22:33:17,328][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/out/tllama-pho-20240816/M03/asr_epoch_3_step_9300/model.pt
