[2024-12-16 01:06:14,487][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': False, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_freeze_llm', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': True, 'save_embedding': True}
[2024-12-16 01:06:14,488][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-16 01:06:14,488][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-16 01:06:14,488][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'librispeech-100_wavlm_llama32_1b_linear_freeze_llm', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-12-16_01-06-14.txt', 'log_interval': 5}
[2024-12-16 01:06:37,873][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-16 01:06:43,105][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-16 01:06:43,107][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-16 01:06:43,109][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-16 01:06:43,110][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-12-16 01:06:51,133][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-16 01:06:51,134][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-12-16 01:06:51,136][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-16 01:06:51,136][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 0.0 Million params

[2024-12-16 01:06:51,240][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-12-16 01:06:51,240][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2024-12-16 01:06:51,240][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-12-16 01:06:51,242][slam_llm.utils.train_utils][INFO] - --> asr has 14.68416 Million params

[2024-12-16 01:06:52,980][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-12-16 01:06:55,265][root][INFO] - --> Training Set Length = 28539
[2024-12-16 01:06:55,281][root][INFO] - --> Validation Set Length = 2703
[2024-12-16 01:06:55,281][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-16 01:06:55,282][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-16 01:13:01,242][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': False, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_freeze_llm', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': True, 'save_embedding': True}
[2024-12-16 01:13:01,242][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-16 01:13:01,242][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-16 01:13:01,242][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'librispeech-100_wavlm_llama32_1b_linear_freeze_llm', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-12-16_01-13-00.txt', 'log_interval': 5}
[2024-12-16 01:13:22,497][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-16 01:13:28,985][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-16 01:13:28,987][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-16 01:13:28,989][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-16 01:13:28,990][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-12-16 01:13:34,023][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-16 01:13:34,025][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-12-16 01:13:34,026][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-16 01:13:34,027][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 0.0 Million params

[2024-12-16 01:13:34,142][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-12-16 01:13:34,142][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2024-12-16 01:13:34,143][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-12-16 01:13:34,146][slam_llm.utils.train_utils][INFO] - --> asr has 14.68416 Million params

[2024-12-16 01:13:36,806][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-12-16 01:13:38,085][root][INFO] - --> Training Set Length = 28539
[2024-12-16 01:13:38,098][root][INFO] - --> Validation Set Length = 2703
[2024-12-16 01:13:38,098][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-16 01:13:38,099][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-17 01:32:46,657][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': False, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_freeze_llm', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': True, 'save_embedding': False}
[2024-12-17 01:32:46,657][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-17 01:32:46,657][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-17 01:32:46,657][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'librispeech-100_wavlm_llama32_1b_linear_freeze_llm', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-12-17_01-32-45.txt', 'log_interval': 5}
[2024-12-17 01:33:11,929][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-17 01:33:17,420][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-17 01:33:17,422][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-17 01:33:17,424][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-17 01:33:17,425][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-12-17 01:33:26,692][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-17 01:33:26,695][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-12-17 01:33:26,696][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-17 01:33:26,696][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 0.0 Million params

[2024-12-17 01:33:26,809][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-12-17 01:33:26,809][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2024-12-17 01:33:26,810][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-12-17 01:33:26,812][slam_llm.utils.train_utils][INFO] - --> asr has 14.68416 Million params

[2024-12-17 01:33:28,618][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-12-17 01:33:31,008][root][INFO] - --> Training Set Length = 28539
[2024-12-17 01:33:31,042][root][INFO] - --> Validation Set Length = 2703
[2024-12-17 01:33:31,043][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-17 01:33:31,044][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-17 01:33:33,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:36,414][numexpr.utils][INFO] - Note: NumExpr detected 28 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2024-12-17 01:33:38,583][root][INFO] - Training Epoch: 1/2, step 0/7134 completed (loss: 6.130461692810059, acc: 0.0833333358168602)
[2024-12-17 01:33:38,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:38,973][root][INFO] - Training Epoch: 1/2, step 1/7134 completed (loss: 6.48796272277832, acc: 0.07643312215805054)
[2024-12-17 01:33:39,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:39,261][root][INFO] - Training Epoch: 1/2, step 2/7134 completed (loss: 6.10561990737915, acc: 0.08522727340459824)
[2024-12-17 01:33:39,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:39,585][root][INFO] - Training Epoch: 1/2, step 3/7134 completed (loss: 6.525084018707275, acc: 0.08139535039663315)
[2024-12-17 01:33:39,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:40,034][root][INFO] - Training Epoch: 1/2, step 4/7134 completed (loss: 6.548985481262207, acc: 0.10691823810338974)
[2024-12-17 01:33:40,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:40,349][root][INFO] - Training Epoch: 1/2, step 5/7134 completed (loss: 5.783308029174805, acc: 0.11173184216022491)
[2024-12-17 01:33:40,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:40,661][root][INFO] - Training Epoch: 1/2, step 6/7134 completed (loss: 5.656893253326416, acc: 0.17605634033679962)
[2024-12-17 01:33:40,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:40,969][root][INFO] - Training Epoch: 1/2, step 7/7134 completed (loss: 6.353971004486084, acc: 0.11290322244167328)
[2024-12-17 01:33:41,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:41,330][root][INFO] - Training Epoch: 1/2, step 8/7134 completed (loss: 6.528140068054199, acc: 0.09146341681480408)
[2024-12-17 01:33:41,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:41,684][root][INFO] - Training Epoch: 1/2, step 9/7134 completed (loss: 5.776102542877197, acc: 0.16556291282176971)
[2024-12-17 01:33:41,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:42,031][root][INFO] - Training Epoch: 1/2, step 10/7134 completed (loss: 6.013820648193359, acc: 0.1834319531917572)
[2024-12-17 01:33:42,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:42,356][root][INFO] - Training Epoch: 1/2, step 11/7134 completed (loss: 6.520310878753662, acc: 0.09166666865348816)
[2024-12-17 01:33:42,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:42,703][root][INFO] - Training Epoch: 1/2, step 12/7134 completed (loss: 5.846710205078125, acc: 0.12138728052377701)
[2024-12-17 01:33:42,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:43,035][root][INFO] - Training Epoch: 1/2, step 13/7134 completed (loss: 5.5752129554748535, acc: 0.17977528274059296)
[2024-12-17 01:33:43,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:43,364][root][INFO] - Training Epoch: 1/2, step 14/7134 completed (loss: 5.683833599090576, acc: 0.10135135054588318)
[2024-12-17 01:33:43,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:43,680][root][INFO] - Training Epoch: 1/2, step 15/7134 completed (loss: 5.569918155670166, acc: 0.10869564861059189)
[2024-12-17 01:33:43,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:44,008][root][INFO] - Training Epoch: 1/2, step 16/7134 completed (loss: 5.786028861999512, acc: 0.08771929889917374)
[2024-12-17 01:33:44,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:44,302][root][INFO] - Training Epoch: 1/2, step 17/7134 completed (loss: 6.423141956329346, acc: 0.09574468433856964)
[2024-12-17 01:33:44,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:44,620][root][INFO] - Training Epoch: 1/2, step 18/7134 completed (loss: 5.262317180633545, acc: 0.16867469251155853)
[2024-12-17 01:33:44,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:44,942][root][INFO] - Training Epoch: 1/2, step 19/7134 completed (loss: 5.426244735717773, acc: 0.15606936812400818)
[2024-12-17 01:33:45,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:45,241][root][INFO] - Training Epoch: 1/2, step 20/7134 completed (loss: 5.36427116394043, acc: 0.17045454680919647)
[2024-12-17 01:33:45,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:45,600][root][INFO] - Training Epoch: 1/2, step 21/7134 completed (loss: 5.664104461669922, acc: 0.14204545319080353)
[2024-12-17 01:33:45,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:45,930][root][INFO] - Training Epoch: 1/2, step 22/7134 completed (loss: 5.002630710601807, acc: 0.14723926782608032)
[2024-12-17 01:33:46,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:46,265][root][INFO] - Training Epoch: 1/2, step 23/7134 completed (loss: 4.924371719360352, acc: 0.2542372941970825)
[2024-12-17 01:33:46,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:46,618][root][INFO] - Training Epoch: 1/2, step 24/7134 completed (loss: 5.42501974105835, acc: 0.15000000596046448)
[2024-12-17 01:33:46,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:46,979][root][INFO] - Training Epoch: 1/2, step 25/7134 completed (loss: 4.996540546417236, acc: 0.17159762978553772)
[2024-12-17 01:33:47,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:47,336][root][INFO] - Training Epoch: 1/2, step 26/7134 completed (loss: 5.334298610687256, acc: 0.19018404185771942)
[2024-12-17 01:33:47,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:47,690][root][INFO] - Training Epoch: 1/2, step 27/7134 completed (loss: 5.2244343757629395, acc: 0.13461539149284363)
[2024-12-17 01:33:47,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:48,053][root][INFO] - Training Epoch: 1/2, step 28/7134 completed (loss: 5.703401565551758, acc: 0.1675126850605011)
[2024-12-17 01:33:48,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:48,374][root][INFO] - Training Epoch: 1/2, step 29/7134 completed (loss: 5.0963826179504395, acc: 0.17751479148864746)
[2024-12-17 01:33:48,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:48,676][root][INFO] - Training Epoch: 1/2, step 30/7134 completed (loss: 5.450952529907227, acc: 0.17874395847320557)
[2024-12-17 01:33:48,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:48,950][root][INFO] - Training Epoch: 1/2, step 31/7134 completed (loss: 5.607885837554932, acc: 0.15813954174518585)
[2024-12-17 01:33:49,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:49,260][root][INFO] - Training Epoch: 1/2, step 32/7134 completed (loss: 5.3203558921813965, acc: 0.19565217196941376)
[2024-12-17 01:33:49,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:49,563][root][INFO] - Training Epoch: 1/2, step 33/7134 completed (loss: 5.2113356590271, acc: 0.1846153885126114)
[2024-12-17 01:33:49,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:49,880][root][INFO] - Training Epoch: 1/2, step 34/7134 completed (loss: 5.149074077606201, acc: 0.1666666716337204)
[2024-12-17 01:33:50,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:50,231][root][INFO] - Training Epoch: 1/2, step 35/7134 completed (loss: 5.16727876663208, acc: 0.13333334028720856)
[2024-12-17 01:33:50,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:50,581][root][INFO] - Training Epoch: 1/2, step 36/7134 completed (loss: 5.097419261932373, acc: 0.17972350120544434)
[2024-12-17 01:33:50,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:50,914][root][INFO] - Training Epoch: 1/2, step 37/7134 completed (loss: 5.601191997528076, acc: 0.19576719403266907)
[2024-12-17 01:33:51,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:51,199][root][INFO] - Training Epoch: 1/2, step 38/7134 completed (loss: 5.470434665679932, acc: 0.1949685513973236)
[2024-12-17 01:33:51,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:51,475][root][INFO] - Training Epoch: 1/2, step 39/7134 completed (loss: 5.0719709396362305, acc: 0.1871345043182373)
[2024-12-17 01:33:51,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:51,789][root][INFO] - Training Epoch: 1/2, step 40/7134 completed (loss: 5.777065753936768, acc: 0.1964285671710968)
[2024-12-17 01:33:51,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:52,129][root][INFO] - Training Epoch: 1/2, step 41/7134 completed (loss: 5.080508232116699, acc: 0.20212766528129578)
[2024-12-17 01:33:52,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:52,459][root][INFO] - Training Epoch: 1/2, step 42/7134 completed (loss: 5.236120700836182, acc: 0.15432098507881165)
[2024-12-17 01:33:52,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:52,787][root][INFO] - Training Epoch: 1/2, step 43/7134 completed (loss: 4.407670497894287, acc: 0.27374300360679626)
[2024-12-17 01:33:52,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:53,112][root][INFO] - Training Epoch: 1/2, step 44/7134 completed (loss: 4.95851993560791, acc: 0.2245989292860031)
[2024-12-17 01:33:53,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:53,448][root][INFO] - Training Epoch: 1/2, step 45/7134 completed (loss: 4.974597454071045, acc: 0.23113207519054413)
[2024-12-17 01:33:53,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:53,781][root][INFO] - Training Epoch: 1/2, step 46/7134 completed (loss: 5.785148620605469, acc: 0.14534883201122284)
[2024-12-17 01:33:53,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:54,110][root][INFO] - Training Epoch: 1/2, step 47/7134 completed (loss: 5.130068302154541, acc: 0.1731843501329422)
[2024-12-17 01:33:54,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:54,451][root][INFO] - Training Epoch: 1/2, step 48/7134 completed (loss: 4.816286563873291, acc: 0.20772947371006012)
[2024-12-17 01:33:54,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:54,754][root][INFO] - Training Epoch: 1/2, step 49/7134 completed (loss: 5.42917013168335, acc: 0.1411764770746231)
[2024-12-17 01:33:54,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:55,087][root][INFO] - Training Epoch: 1/2, step 50/7134 completed (loss: 5.239589214324951, acc: 0.22815534472465515)
[2024-12-17 01:33:55,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:55,375][root][INFO] - Training Epoch: 1/2, step 51/7134 completed (loss: 5.137554168701172, acc: 0.15816326439380646)
[2024-12-17 01:33:55,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:55,691][root][INFO] - Training Epoch: 1/2, step 52/7134 completed (loss: 4.925459384918213, acc: 0.15231788158416748)
[2024-12-17 01:33:55,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:55,991][root][INFO] - Training Epoch: 1/2, step 53/7134 completed (loss: 4.892545223236084, acc: 0.21621622145175934)
[2024-12-17 01:33:56,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:56,308][root][INFO] - Training Epoch: 1/2, step 54/7134 completed (loss: 5.101973056793213, acc: 0.18095238506793976)
[2024-12-17 01:33:56,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:56,670][root][INFO] - Training Epoch: 1/2, step 55/7134 completed (loss: 5.095073699951172, acc: 0.21739129722118378)
[2024-12-17 01:33:56,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:57,000][root][INFO] - Training Epoch: 1/2, step 56/7134 completed (loss: 5.700748920440674, acc: 0.16153846681118011)
[2024-12-17 01:33:57,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:57,343][root][INFO] - Training Epoch: 1/2, step 57/7134 completed (loss: 5.722423553466797, acc: 0.1538461595773697)
[2024-12-17 01:33:57,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:57,688][root][INFO] - Training Epoch: 1/2, step 58/7134 completed (loss: 5.393711090087891, acc: 0.15642458200454712)
[2024-12-17 01:33:57,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:57,972][root][INFO] - Training Epoch: 1/2, step 59/7134 completed (loss: 5.104480743408203, acc: 0.2139037400484085)
[2024-12-17 01:33:58,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:58,292][root][INFO] - Training Epoch: 1/2, step 60/7134 completed (loss: 5.532022476196289, acc: 0.16455696523189545)
[2024-12-17 01:33:58,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:58,621][root][INFO] - Training Epoch: 1/2, step 61/7134 completed (loss: 5.353650093078613, acc: 0.18994413316249847)
[2024-12-17 01:33:58,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:58,946][root][INFO] - Training Epoch: 1/2, step 62/7134 completed (loss: 6.027784824371338, acc: 0.13483145833015442)
[2024-12-17 01:33:59,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:59,252][root][INFO] - Training Epoch: 1/2, step 63/7134 completed (loss: 5.322324752807617, acc: 0.14835165441036224)
[2024-12-17 01:33:59,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:59,591][root][INFO] - Training Epoch: 1/2, step 64/7134 completed (loss: 5.647141933441162, acc: 0.15882353484630585)
[2024-12-17 01:33:59,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:59,926][root][INFO] - Training Epoch: 1/2, step 65/7134 completed (loss: 6.098771572113037, acc: 0.1489361673593521)
[2024-12-17 01:34:00,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:00,242][root][INFO] - Training Epoch: 1/2, step 66/7134 completed (loss: 5.856148719787598, acc: 0.1666666716337204)
[2024-12-17 01:34:00,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:00,575][root][INFO] - Training Epoch: 1/2, step 67/7134 completed (loss: 5.711585521697998, acc: 0.18965516984462738)
[2024-12-17 01:34:00,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:00,848][root][INFO] - Training Epoch: 1/2, step 68/7134 completed (loss: 5.606351852416992, acc: 0.23033708333969116)
[2024-12-17 01:34:00,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:01,135][root][INFO] - Training Epoch: 1/2, step 69/7134 completed (loss: 5.591736793518066, acc: 0.19576719403266907)
[2024-12-17 01:34:01,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:01,426][root][INFO] - Training Epoch: 1/2, step 70/7134 completed (loss: 6.181504726409912, acc: 0.1171875)
[2024-12-17 01:34:01,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:01,729][root][INFO] - Training Epoch: 1/2, step 71/7134 completed (loss: 5.008359432220459, acc: 0.20606060326099396)
[2024-12-17 01:34:01,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:02,013][root][INFO] - Training Epoch: 1/2, step 72/7134 completed (loss: 5.677216053009033, acc: 0.16568046808242798)
[2024-12-17 01:34:02,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:02,287][root][INFO] - Training Epoch: 1/2, step 73/7134 completed (loss: 5.598634719848633, acc: 0.12716762721538544)
[2024-12-17 01:34:02,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:02,635][root][INFO] - Training Epoch: 1/2, step 74/7134 completed (loss: 5.329123020172119, acc: 0.151162788271904)
[2024-12-17 01:34:02,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:02,991][root][INFO] - Training Epoch: 1/2, step 75/7134 completed (loss: 5.636896133422852, acc: 0.2142857164144516)
[2024-12-17 01:34:03,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:03,343][root][INFO] - Training Epoch: 1/2, step 76/7134 completed (loss: 5.342859745025635, acc: 0.16847826540470123)
[2024-12-17 01:34:03,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:03,713][root][INFO] - Training Epoch: 1/2, step 77/7134 completed (loss: 5.225185871124268, acc: 0.16022099554538727)
[2024-12-17 01:34:03,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:04,081][root][INFO] - Training Epoch: 1/2, step 78/7134 completed (loss: 5.521406650543213, acc: 0.21192052960395813)
[2024-12-17 01:34:04,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:04,429][root][INFO] - Training Epoch: 1/2, step 79/7134 completed (loss: 5.249176979064941, acc: 0.20666666328907013)
[2024-12-17 01:34:04,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:04,730][root][INFO] - Training Epoch: 1/2, step 80/7134 completed (loss: 4.94367790222168, acc: 0.19662921130657196)
[2024-12-17 01:34:04,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:05,072][root][INFO] - Training Epoch: 1/2, step 81/7134 completed (loss: 5.154935836791992, acc: 0.21164020895957947)
[2024-12-17 01:34:05,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:05,384][root][INFO] - Training Epoch: 1/2, step 82/7134 completed (loss: 5.156056880950928, acc: 0.1927710771560669)
[2024-12-17 01:34:05,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:05,710][root][INFO] - Training Epoch: 1/2, step 83/7134 completed (loss: 5.49354887008667, acc: 0.1595744639635086)
[2024-12-17 01:34:05,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:06,049][root][INFO] - Training Epoch: 1/2, step 84/7134 completed (loss: 4.648820877075195, acc: 0.2733812928199768)
[2024-12-17 01:34:06,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:06,320][root][INFO] - Training Epoch: 1/2, step 85/7134 completed (loss: 5.014238357543945, acc: 0.17000000178813934)
[2024-12-17 01:34:06,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:06,612][root][INFO] - Training Epoch: 1/2, step 86/7134 completed (loss: 5.067088603973389, acc: 0.1875)
[2024-12-17 01:34:06,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:06,921][root][INFO] - Training Epoch: 1/2, step 87/7134 completed (loss: 4.800407886505127, acc: 0.25974026322364807)
[2024-12-17 01:34:07,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:07,228][root][INFO] - Training Epoch: 1/2, step 88/7134 completed (loss: 5.099818706512451, acc: 0.17469879984855652)
[2024-12-17 01:34:07,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:07,582][root][INFO] - Training Epoch: 1/2, step 89/7134 completed (loss: 4.982426643371582, acc: 0.18857142329216003)
[2024-12-17 01:34:07,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:07,909][root][INFO] - Training Epoch: 1/2, step 90/7134 completed (loss: 5.152932643890381, acc: 0.1764705926179886)
[2024-12-17 01:34:08,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:08,226][root][INFO] - Training Epoch: 1/2, step 91/7134 completed (loss: 5.520190715789795, acc: 0.1900826394557953)
[2024-12-17 01:34:08,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:08,557][root][INFO] - Training Epoch: 1/2, step 92/7134 completed (loss: 4.9048614501953125, acc: 0.2532467544078827)
[2024-12-17 01:34:08,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:08,885][root][INFO] - Training Epoch: 1/2, step 93/7134 completed (loss: 4.729397773742676, acc: 0.2571428716182709)
[2024-12-17 01:34:09,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:09,145][root][INFO] - Training Epoch: 1/2, step 94/7134 completed (loss: 5.205260276794434, acc: 0.2924528419971466)
[2024-12-17 01:34:09,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:09,501][root][INFO] - Training Epoch: 1/2, step 95/7134 completed (loss: 5.016525745391846, acc: 0.2195121943950653)
[2024-12-17 01:34:09,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:09,771][root][INFO] - Training Epoch: 1/2, step 96/7134 completed (loss: 4.969360828399658, acc: 0.20560747385025024)
[2024-12-17 01:34:09,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:10,126][root][INFO] - Training Epoch: 1/2, step 97/7134 completed (loss: 6.393557071685791, acc: 0.0)
[2024-12-17 01:34:10,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:10,482][root][INFO] - Training Epoch: 1/2, step 98/7134 completed (loss: 5.084986209869385, acc: 0.21830986440181732)
[2024-12-17 01:34:10,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:10,776][root][INFO] - Training Epoch: 1/2, step 99/7134 completed (loss: 4.559183120727539, acc: 0.26153847575187683)
[2024-12-17 01:34:10,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:11,080][root][INFO] - Training Epoch: 1/2, step 100/7134 completed (loss: 4.880173683166504, acc: 0.265193372964859)
[2024-12-17 01:34:11,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:11,389][root][INFO] - Training Epoch: 1/2, step 101/7134 completed (loss: 5.452361583709717, acc: 0.1640625)
[2024-12-17 01:34:11,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:11,687][root][INFO] - Training Epoch: 1/2, step 102/7134 completed (loss: 4.8093085289001465, acc: 0.20218579471111298)
[2024-12-17 01:34:11,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:11,990][root][INFO] - Training Epoch: 1/2, step 103/7134 completed (loss: 5.326957702636719, acc: 0.17123287916183472)
[2024-12-17 01:34:12,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:12,317][root][INFO] - Training Epoch: 1/2, step 104/7134 completed (loss: 4.502094268798828, acc: 0.2199999988079071)
[2024-12-17 01:34:12,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:12,649][root][INFO] - Training Epoch: 1/2, step 105/7134 completed (loss: 4.650291919708252, acc: 0.2014925330877304)
[2024-12-17 01:34:12,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:12,975][root][INFO] - Training Epoch: 1/2, step 106/7134 completed (loss: 4.543914794921875, acc: 0.29192546010017395)
[2024-12-17 01:34:13,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:13,300][root][INFO] - Training Epoch: 1/2, step 107/7134 completed (loss: 4.80833625793457, acc: 0.2848837077617645)
[2024-12-17 01:34:13,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:13,631][root][INFO] - Training Epoch: 1/2, step 108/7134 completed (loss: 4.804619789123535, acc: 0.23783783614635468)
[2024-12-17 01:34:13,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:13,946][root][INFO] - Training Epoch: 1/2, step 109/7134 completed (loss: 4.930573463439941, acc: 0.1666666716337204)
[2024-12-17 01:34:14,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:14,239][root][INFO] - Training Epoch: 1/2, step 110/7134 completed (loss: 4.441015720367432, acc: 0.22905027866363525)
[2024-12-17 01:34:14,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:14,528][root][INFO] - Training Epoch: 1/2, step 111/7134 completed (loss: 4.342384338378906, acc: 0.25)
[2024-12-17 01:34:14,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:14,811][root][INFO] - Training Epoch: 1/2, step 112/7134 completed (loss: 4.805302143096924, acc: 0.2152777761220932)
[2024-12-17 01:34:14,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:15,087][root][INFO] - Training Epoch: 1/2, step 113/7134 completed (loss: 4.178781986236572, acc: 0.31284916400909424)
[2024-12-17 01:34:15,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:15,381][root][INFO] - Training Epoch: 1/2, step 114/7134 completed (loss: 4.705628395080566, acc: 0.24571429193019867)
[2024-12-17 01:34:15,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:15,707][root][INFO] - Training Epoch: 1/2, step 115/7134 completed (loss: 5.2842793464660645, acc: 0.20792078971862793)
[2024-12-17 01:34:15,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:16,080][root][INFO] - Training Epoch: 1/2, step 116/7134 completed (loss: 4.976648807525635, acc: 0.20114941895008087)
[2024-12-17 01:34:16,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:16,378][root][INFO] - Training Epoch: 1/2, step 117/7134 completed (loss: 4.568746566772461, acc: 0.30909091234207153)
[2024-12-17 01:34:16,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:16,690][root][INFO] - Training Epoch: 1/2, step 118/7134 completed (loss: 5.188176155090332, acc: 0.2611111104488373)
[2024-12-17 01:34:16,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:16,994][root][INFO] - Training Epoch: 1/2, step 119/7134 completed (loss: 4.9475202560424805, acc: 0.22340425848960876)
[2024-12-17 01:34:17,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:17,337][root][INFO] - Training Epoch: 1/2, step 120/7134 completed (loss: 4.55552864074707, acc: 0.2023809552192688)
[2024-12-17 01:34:17,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:17,634][root][INFO] - Training Epoch: 1/2, step 121/7134 completed (loss: 4.90941858291626, acc: 0.20670391619205475)
[2024-12-17 01:34:17,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:17,933][root][INFO] - Training Epoch: 1/2, step 122/7134 completed (loss: 4.199606895446777, acc: 0.30219781398773193)
[2024-12-17 01:34:18,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:18,215][root][INFO] - Training Epoch: 1/2, step 123/7134 completed (loss: 4.505330562591553, acc: 0.23270440101623535)
[2024-12-17 01:34:18,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:18,510][root][INFO] - Training Epoch: 1/2, step 124/7134 completed (loss: 4.542236328125, acc: 0.2638888955116272)
[2024-12-17 01:34:18,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:18,842][root][INFO] - Training Epoch: 1/2, step 125/7134 completed (loss: 4.640137672424316, acc: 0.2598039209842682)
[2024-12-17 01:34:18,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:19,151][root][INFO] - Training Epoch: 1/2, step 126/7134 completed (loss: 4.9523420333862305, acc: 0.23404255509376526)
[2024-12-17 01:34:19,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:19,421][root][INFO] - Training Epoch: 1/2, step 127/7134 completed (loss: 4.065418720245361, acc: 0.3020833432674408)
[2024-12-17 01:34:19,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:19,738][root][INFO] - Training Epoch: 1/2, step 128/7134 completed (loss: 4.693226337432861, acc: 0.2679425776004791)
[2024-12-17 01:34:19,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:20,043][root][INFO] - Training Epoch: 1/2, step 129/7134 completed (loss: 4.186040878295898, acc: 0.25139665603637695)
[2024-12-17 01:34:20,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:20,313][root][INFO] - Training Epoch: 1/2, step 130/7134 completed (loss: 4.278746128082275, acc: 0.2823529541492462)
[2024-12-17 01:34:20,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:20,591][root][INFO] - Training Epoch: 1/2, step 131/7134 completed (loss: 4.40994119644165, acc: 0.23976607620716095)
[2024-12-17 01:34:20,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:20,874][root][INFO] - Training Epoch: 1/2, step 132/7134 completed (loss: 4.458420753479004, acc: 0.23270440101623535)
[2024-12-17 01:34:20,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:21,160][root][INFO] - Training Epoch: 1/2, step 133/7134 completed (loss: 4.613499641418457, acc: 0.22058823704719543)
[2024-12-17 01:34:21,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:21,458][root][INFO] - Training Epoch: 1/2, step 134/7134 completed (loss: 4.625950813293457, acc: 0.2255639135837555)
[2024-12-17 01:34:21,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:21,773][root][INFO] - Training Epoch: 1/2, step 135/7134 completed (loss: 4.156006336212158, acc: 0.27513226866722107)
[2024-12-17 01:34:21,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:22,050][root][INFO] - Training Epoch: 1/2, step 136/7134 completed (loss: 4.8026204109191895, acc: 0.2445652186870575)
[2024-12-17 01:34:22,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:22,333][root][INFO] - Training Epoch: 1/2, step 137/7134 completed (loss: 4.367223739624023, acc: 0.26633167266845703)
[2024-12-17 01:34:22,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:22,659][root][INFO] - Training Epoch: 1/2, step 138/7134 completed (loss: 4.367482662200928, acc: 0.29032257199287415)
[2024-12-17 01:34:22,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:22,974][root][INFO] - Training Epoch: 1/2, step 139/7134 completed (loss: 4.776856899261475, acc: 0.19680851697921753)
[2024-12-17 01:34:23,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:23,262][root][INFO] - Training Epoch: 1/2, step 140/7134 completed (loss: 4.238186359405518, acc: 0.25153374671936035)
[2024-12-17 01:34:23,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:23,554][root][INFO] - Training Epoch: 1/2, step 141/7134 completed (loss: 4.431339740753174, acc: 0.25)
[2024-12-17 01:34:23,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:23,861][root][INFO] - Training Epoch: 1/2, step 142/7134 completed (loss: 4.639320373535156, acc: 0.22033898532390594)
[2024-12-17 01:34:23,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:24,154][root][INFO] - Training Epoch: 1/2, step 143/7134 completed (loss: 4.065011024475098, acc: 0.2596684992313385)
[2024-12-17 01:34:24,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:24,459][root][INFO] - Training Epoch: 1/2, step 144/7134 completed (loss: 4.914857387542725, acc: 0.22297297418117523)
[2024-12-17 01:34:24,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:24,747][root][INFO] - Training Epoch: 1/2, step 145/7134 completed (loss: 5.53659725189209, acc: 0.1865285038948059)
[2024-12-17 01:34:24,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:25,069][root][INFO] - Training Epoch: 1/2, step 146/7134 completed (loss: 4.964273929595947, acc: 0.20903955399990082)
[2024-12-17 01:34:25,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:25,377][root][INFO] - Training Epoch: 1/2, step 147/7134 completed (loss: 4.990698337554932, acc: 0.20000000298023224)
[2024-12-17 01:34:25,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:25,659][root][INFO] - Training Epoch: 1/2, step 148/7134 completed (loss: 5.411371231079102, acc: 0.22580644488334656)
[2024-12-17 01:34:25,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:25,953][root][INFO] - Training Epoch: 1/2, step 149/7134 completed (loss: 4.693171977996826, acc: 0.2588832378387451)
[2024-12-17 01:34:26,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:26,239][root][INFO] - Training Epoch: 1/2, step 150/7134 completed (loss: 5.1300129890441895, acc: 0.1884816735982895)
[2024-12-17 01:34:26,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:26,519][root][INFO] - Training Epoch: 1/2, step 151/7134 completed (loss: 4.374112129211426, acc: 0.24731183052062988)
[2024-12-17 01:34:26,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:26,850][root][INFO] - Training Epoch: 1/2, step 152/7134 completed (loss: 4.57525634765625, acc: 0.1866028755903244)
[2024-12-17 01:34:26,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:27,147][root][INFO] - Training Epoch: 1/2, step 153/7134 completed (loss: 5.056675910949707, acc: 0.19889502227306366)
[2024-12-17 01:34:27,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:27,496][root][INFO] - Training Epoch: 1/2, step 154/7134 completed (loss: 5.00639533996582, acc: 0.2222222238779068)
[2024-12-17 01:34:27,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:27,783][root][INFO] - Training Epoch: 1/2, step 155/7134 completed (loss: 4.636576175689697, acc: 0.23497267067432404)
[2024-12-17 01:34:27,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:28,071][root][INFO] - Training Epoch: 1/2, step 156/7134 completed (loss: 4.568857669830322, acc: 0.21182265877723694)
[2024-12-17 01:34:28,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:28,362][root][INFO] - Training Epoch: 1/2, step 157/7134 completed (loss: 5.285806179046631, acc: 0.17989417910575867)
[2024-12-17 01:34:28,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:28,670][root][INFO] - Training Epoch: 1/2, step 158/7134 completed (loss: 4.719198226928711, acc: 0.20467835664749146)
[2024-12-17 01:34:28,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:28,984][root][INFO] - Training Epoch: 1/2, step 159/7134 completed (loss: 4.372610569000244, acc: 0.23699422180652618)
[2024-12-17 01:34:29,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:29,245][root][INFO] - Training Epoch: 1/2, step 160/7134 completed (loss: 4.90253210067749, acc: 0.18644067645072937)
[2024-12-17 01:34:29,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:29,490][root][INFO] - Training Epoch: 1/2, step 161/7134 completed (loss: 4.144774436950684, acc: 0.3243243098258972)
[2024-12-17 01:34:29,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:29,838][root][INFO] - Training Epoch: 1/2, step 162/7134 completed (loss: 4.239957332611084, acc: 0.25925925374031067)
[2024-12-17 01:34:29,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:30,173][root][INFO] - Training Epoch: 1/2, step 163/7134 completed (loss: 4.537456512451172, acc: 0.2158273309469223)
[2024-12-17 01:34:30,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:30,431][root][INFO] - Training Epoch: 1/2, step 164/7134 completed (loss: 4.529399394989014, acc: 0.3030303120613098)
[2024-12-17 01:34:30,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:30,691][root][INFO] - Training Epoch: 1/2, step 165/7134 completed (loss: 4.132085800170898, acc: 0.27000001072883606)
[2024-12-17 01:34:30,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:30,927][root][INFO] - Training Epoch: 1/2, step 166/7134 completed (loss: 4.571220874786377, acc: 0.2631579041481018)
[2024-12-17 01:34:31,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:31,229][root][INFO] - Training Epoch: 1/2, step 167/7134 completed (loss: 5.480261325836182, acc: 0.1927710771560669)
[2024-12-17 01:34:31,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:31,456][root][INFO] - Training Epoch: 1/2, step 168/7134 completed (loss: 6.537699222564697, acc: 0.1090909093618393)
[2024-12-17 01:34:31,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:31,721][root][INFO] - Training Epoch: 1/2, step 169/7134 completed (loss: 6.484889030456543, acc: 0.1171875)
[2024-12-17 01:34:31,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:32,040][root][INFO] - Training Epoch: 1/2, step 170/7134 completed (loss: 5.412044525146484, acc: 0.2261904776096344)
[2024-12-17 01:34:32,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:32,338][root][INFO] - Training Epoch: 1/2, step 171/7134 completed (loss: 6.271981716156006, acc: 0.13861386477947235)
[2024-12-17 01:34:32,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:32,609][root][INFO] - Training Epoch: 1/2, step 172/7134 completed (loss: 5.202399730682373, acc: 0.21705426275730133)
[2024-12-17 01:34:32,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:32,873][root][INFO] - Training Epoch: 1/2, step 173/7134 completed (loss: 5.820063591003418, acc: 0.14399999380111694)
[2024-12-17 01:34:33,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:33,188][root][INFO] - Training Epoch: 1/2, step 174/7134 completed (loss: 5.543968200683594, acc: 0.17105263471603394)
[2024-12-17 01:34:33,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:33,485][root][INFO] - Training Epoch: 1/2, step 175/7134 completed (loss: 4.914776802062988, acc: 0.21854305267333984)
[2024-12-17 01:34:33,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:33,777][root][INFO] - Training Epoch: 1/2, step 176/7134 completed (loss: 4.80618953704834, acc: 0.25136610865592957)
[2024-12-17 01:34:33,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:34,049][root][INFO] - Training Epoch: 1/2, step 177/7134 completed (loss: 5.348174095153809, acc: 0.1796407252550125)
[2024-12-17 01:34:34,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:34,308][root][INFO] - Training Epoch: 1/2, step 178/7134 completed (loss: 5.1885552406311035, acc: 0.1818181872367859)
[2024-12-17 01:34:34,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:34,581][root][INFO] - Training Epoch: 1/2, step 179/7134 completed (loss: 4.3614821434021, acc: 0.2846715450286865)
[2024-12-17 01:34:34,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:34,893][root][INFO] - Training Epoch: 1/2, step 180/7134 completed (loss: 4.442814826965332, acc: 0.24832214415073395)
[2024-12-17 01:34:35,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:35,179][root][INFO] - Training Epoch: 1/2, step 181/7134 completed (loss: 4.226301193237305, acc: 0.2896551787853241)
[2024-12-17 01:34:35,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:35,514][root][INFO] - Training Epoch: 1/2, step 182/7134 completed (loss: 4.1389479637146, acc: 0.2857142984867096)
[2024-12-17 01:34:35,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:35,809][root][INFO] - Training Epoch: 1/2, step 183/7134 completed (loss: 4.293252944946289, acc: 0.2602739632129669)
[2024-12-17 01:34:35,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:36,074][root][INFO] - Training Epoch: 1/2, step 184/7134 completed (loss: 4.62506628036499, acc: 0.2734375)
[2024-12-17 01:34:36,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:36,351][root][INFO] - Training Epoch: 1/2, step 185/7134 completed (loss: 4.246069431304932, acc: 0.27210885286331177)
[2024-12-17 01:34:36,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:36,652][root][INFO] - Training Epoch: 1/2, step 186/7134 completed (loss: 4.5566558837890625, acc: 0.20895522832870483)
[2024-12-17 01:34:36,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:36,948][root][INFO] - Training Epoch: 1/2, step 187/7134 completed (loss: 3.9841160774230957, acc: 0.33986929059028625)
[2024-12-17 01:34:37,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:37,229][root][INFO] - Training Epoch: 1/2, step 188/7134 completed (loss: 4.014531135559082, acc: 0.2804878056049347)
[2024-12-17 01:34:37,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:37,495][root][INFO] - Training Epoch: 1/2, step 189/7134 completed (loss: 4.09096097946167, acc: 0.31147539615631104)
[2024-12-17 01:34:37,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:37,778][root][INFO] - Training Epoch: 1/2, step 190/7134 completed (loss: 4.421463489532471, acc: 0.2537313401699066)
[2024-12-17 01:34:37,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:38,056][root][INFO] - Training Epoch: 1/2, step 191/7134 completed (loss: 4.124779224395752, acc: 0.3173076808452606)
[2024-12-17 01:34:38,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:38,373][root][INFO] - Training Epoch: 1/2, step 192/7134 completed (loss: 3.811628580093384, acc: 0.27906978130340576)
[2024-12-17 01:34:38,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:38,647][root][INFO] - Training Epoch: 1/2, step 193/7134 completed (loss: 4.244060039520264, acc: 0.3053892254829407)
[2024-12-17 01:34:38,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:38,970][root][INFO] - Training Epoch: 1/2, step 194/7134 completed (loss: 4.630463123321533, acc: 0.28930819034576416)
[2024-12-17 01:34:39,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:39,328][root][INFO] - Training Epoch: 1/2, step 195/7134 completed (loss: 4.696376800537109, acc: 0.1875)
[2024-12-17 01:34:39,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:39,662][root][INFO] - Training Epoch: 1/2, step 196/7134 completed (loss: 4.91691780090332, acc: 0.22346368432044983)
[2024-12-17 01:34:39,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:39,964][root][INFO] - Training Epoch: 1/2, step 197/7134 completed (loss: 3.689608573913574, acc: 0.30405405163764954)
[2024-12-17 01:34:40,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:40,287][root][INFO] - Training Epoch: 1/2, step 198/7134 completed (loss: 4.106305122375488, acc: 0.24840764701366425)
[2024-12-17 01:34:40,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:40,631][root][INFO] - Training Epoch: 1/2, step 199/7134 completed (loss: 4.1436262130737305, acc: 0.3014705777168274)
[2024-12-17 01:34:40,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:40,977][root][INFO] - Training Epoch: 1/2, step 200/7134 completed (loss: 4.0667219161987305, acc: 0.2925170063972473)
[2024-12-17 01:34:41,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:41,277][root][INFO] - Training Epoch: 1/2, step 201/7134 completed (loss: 4.534595489501953, acc: 0.26241135597229004)
[2024-12-17 01:34:41,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:41,588][root][INFO] - Training Epoch: 1/2, step 202/7134 completed (loss: 4.515240669250488, acc: 0.25806450843811035)
[2024-12-17 01:34:41,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:41,898][root][INFO] - Training Epoch: 1/2, step 203/7134 completed (loss: 4.8823041915893555, acc: 0.2544378638267517)
[2024-12-17 01:34:42,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:42,214][root][INFO] - Training Epoch: 1/2, step 204/7134 completed (loss: 4.860931873321533, acc: 0.21383647620677948)
[2024-12-17 01:34:42,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:42,546][root][INFO] - Training Epoch: 1/2, step 205/7134 completed (loss: 4.926556587219238, acc: 0.1899999976158142)
[2024-12-17 01:34:42,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:42,877][root][INFO] - Training Epoch: 1/2, step 206/7134 completed (loss: 4.244848728179932, acc: 0.2708333432674408)
[2024-12-17 01:34:43,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:43,162][root][INFO] - Training Epoch: 1/2, step 207/7134 completed (loss: 4.368873596191406, acc: 0.2380952388048172)
[2024-12-17 01:34:43,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:43,455][root][INFO] - Training Epoch: 1/2, step 208/7134 completed (loss: 5.1539201736450195, acc: 0.20000000298023224)
[2024-12-17 01:34:43,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:43,760][root][INFO] - Training Epoch: 1/2, step 209/7134 completed (loss: 5.052297592163086, acc: 0.21229049563407898)
[2024-12-17 01:34:43,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:44,097][root][INFO] - Training Epoch: 1/2, step 210/7134 completed (loss: 4.591373443603516, acc: 0.21145375072956085)
[2024-12-17 01:34:44,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:44,406][root][INFO] - Training Epoch: 1/2, step 211/7134 completed (loss: 4.577057361602783, acc: 0.25)
[2024-12-17 01:34:44,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:44,725][root][INFO] - Training Epoch: 1/2, step 212/7134 completed (loss: 5.738443374633789, acc: 0.13223139941692352)
[2024-12-17 01:34:44,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:45,034][root][INFO] - Training Epoch: 1/2, step 213/7134 completed (loss: 4.682246685028076, acc: 0.25999999046325684)
[2024-12-17 01:34:45,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:45,360][root][INFO] - Training Epoch: 1/2, step 214/7134 completed (loss: 5.445012092590332, acc: 0.1683168262243271)
[2024-12-17 01:34:45,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:45,704][root][INFO] - Training Epoch: 1/2, step 215/7134 completed (loss: 4.294804573059082, acc: 0.3142857253551483)
[2024-12-17 01:34:45,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:46,013][root][INFO] - Training Epoch: 1/2, step 216/7134 completed (loss: 3.9522125720977783, acc: 0.2921348214149475)
[2024-12-17 01:34:46,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:46,367][root][INFO] - Training Epoch: 1/2, step 217/7134 completed (loss: 3.7884275913238525, acc: 0.3125)
[2024-12-17 01:34:46,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:46,696][root][INFO] - Training Epoch: 1/2, step 218/7134 completed (loss: 3.94830584526062, acc: 0.30481284856796265)
[2024-12-17 01:34:46,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:46,993][root][INFO] - Training Epoch: 1/2, step 219/7134 completed (loss: 4.954086780548096, acc: 0.19298245012760162)
[2024-12-17 01:34:47,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:47,283][root][INFO] - Training Epoch: 1/2, step 220/7134 completed (loss: 4.13606595993042, acc: 0.321739137172699)
[2024-12-17 01:34:47,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:47,612][root][INFO] - Training Epoch: 1/2, step 221/7134 completed (loss: 4.112494468688965, acc: 0.28125)
[2024-12-17 01:34:47,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:47,951][root][INFO] - Training Epoch: 1/2, step 222/7134 completed (loss: 4.319169998168945, acc: 0.3005780279636383)
[2024-12-17 01:34:48,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:48,239][root][INFO] - Training Epoch: 1/2, step 223/7134 completed (loss: 5.046486854553223, acc: 0.2108108103275299)
[2024-12-17 01:34:48,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:48,516][root][INFO] - Training Epoch: 1/2, step 224/7134 completed (loss: 5.288588523864746, acc: 0.2178770899772644)
[2024-12-17 01:34:48,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:48,824][root][INFO] - Training Epoch: 1/2, step 225/7134 completed (loss: 4.733104228973389, acc: 0.2781065106391907)
[2024-12-17 01:34:49,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:49,167][root][INFO] - Training Epoch: 1/2, step 226/7134 completed (loss: 4.786113262176514, acc: 0.24571429193019867)
[2024-12-17 01:34:49,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:49,473][root][INFO] - Training Epoch: 1/2, step 227/7134 completed (loss: 4.962795734405518, acc: 0.25531914830207825)
[2024-12-17 01:34:49,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:49,814][root][INFO] - Training Epoch: 1/2, step 228/7134 completed (loss: 4.7731170654296875, acc: 0.28143712878227234)
[2024-12-17 01:34:49,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:50,142][root][INFO] - Training Epoch: 1/2, step 229/7134 completed (loss: 5.177371025085449, acc: 0.21714285016059875)
[2024-12-17 01:34:50,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:50,491][root][INFO] - Training Epoch: 1/2, step 230/7134 completed (loss: 5.001358509063721, acc: 0.24861878156661987)
[2024-12-17 01:34:50,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:50,774][root][INFO] - Training Epoch: 1/2, step 231/7134 completed (loss: 5.044112682342529, acc: 0.19298245012760162)
[2024-12-17 01:34:50,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:51,107][root][INFO] - Training Epoch: 1/2, step 232/7134 completed (loss: 4.93754768371582, acc: 0.21678321063518524)
[2024-12-17 01:34:51,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:51,413][root][INFO] - Training Epoch: 1/2, step 233/7134 completed (loss: 4.7246994972229, acc: 0.2554744482040405)
[2024-12-17 01:34:51,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:51,741][root][INFO] - Training Epoch: 1/2, step 234/7134 completed (loss: 4.81905460357666, acc: 0.19014084339141846)
[2024-12-17 01:34:51,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:52,031][root][INFO] - Training Epoch: 1/2, step 235/7134 completed (loss: 4.633065223693848, acc: 0.27439025044441223)
[2024-12-17 01:34:52,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:52,393][root][INFO] - Training Epoch: 1/2, step 236/7134 completed (loss: 4.364920139312744, acc: 0.2715231776237488)
[2024-12-17 01:34:52,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:52,673][root][INFO] - Training Epoch: 1/2, step 237/7134 completed (loss: 5.203671455383301, acc: 0.19108280539512634)
[2024-12-17 01:34:52,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:52,976][root][INFO] - Training Epoch: 1/2, step 238/7134 completed (loss: 4.928520202636719, acc: 0.23664122819900513)
[2024-12-17 01:34:53,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:53,258][root][INFO] - Training Epoch: 1/2, step 239/7134 completed (loss: 5.280364990234375, acc: 0.1603773534297943)
[2024-12-17 01:34:53,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:53,568][root][INFO] - Training Epoch: 1/2, step 240/7134 completed (loss: 4.58713436126709, acc: 0.26213592290878296)
[2024-12-17 01:34:53,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:53,874][root][INFO] - Training Epoch: 1/2, step 241/7134 completed (loss: 4.699920654296875, acc: 0.21641790866851807)
[2024-12-17 01:34:54,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:54,200][root][INFO] - Training Epoch: 1/2, step 242/7134 completed (loss: 4.919882297515869, acc: 0.21476510167121887)
[2024-12-17 01:34:54,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:54,515][root][INFO] - Training Epoch: 1/2, step 243/7134 completed (loss: 5.189927577972412, acc: 0.24137930572032928)
[2024-12-17 01:34:54,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:54,791][root][INFO] - Training Epoch: 1/2, step 244/7134 completed (loss: 4.413365364074707, acc: 0.20863309502601624)
[2024-12-17 01:34:54,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:55,096][root][INFO] - Training Epoch: 1/2, step 245/7134 completed (loss: 4.412090301513672, acc: 0.28688523173332214)
[2024-12-17 01:34:55,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:55,430][root][INFO] - Training Epoch: 1/2, step 246/7134 completed (loss: 4.503521919250488, acc: 0.26811593770980835)
[2024-12-17 01:34:55,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:55,720][root][INFO] - Training Epoch: 1/2, step 247/7134 completed (loss: 4.220618724822998, acc: 0.2857142984867096)
[2024-12-17 01:34:55,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:56,047][root][INFO] - Training Epoch: 1/2, step 248/7134 completed (loss: 4.3901591300964355, acc: 0.28455284237861633)
[2024-12-17 01:34:56,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:56,346][root][INFO] - Training Epoch: 1/2, step 249/7134 completed (loss: 4.244283199310303, acc: 0.33695653080940247)
[2024-12-17 01:34:56,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:56,671][root][INFO] - Training Epoch: 1/2, step 250/7134 completed (loss: 4.466516494750977, acc: 0.23178808391094208)
[2024-12-17 01:34:56,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:56,970][root][INFO] - Training Epoch: 1/2, step 251/7134 completed (loss: 4.574789047241211, acc: 0.28057554364204407)
[2024-12-17 01:34:57,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:57,288][root][INFO] - Training Epoch: 1/2, step 252/7134 completed (loss: 4.136093616485596, acc: 0.30215826630592346)
[2024-12-17 01:34:57,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:57,579][root][INFO] - Training Epoch: 1/2, step 253/7134 completed (loss: 4.125279426574707, acc: 0.24799999594688416)
[2024-12-17 01:34:57,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:57,850][root][INFO] - Training Epoch: 1/2, step 254/7134 completed (loss: 4.5691304206848145, acc: 0.17543859779834747)
[2024-12-17 01:34:58,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:58,169][root][INFO] - Training Epoch: 1/2, step 255/7134 completed (loss: 4.275885581970215, acc: 0.2628205120563507)
[2024-12-17 01:34:58,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:58,429][root][INFO] - Training Epoch: 1/2, step 256/7134 completed (loss: 4.630331039428711, acc: 0.21621622145175934)
[2024-12-17 01:34:58,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:58,735][root][INFO] - Training Epoch: 1/2, step 257/7134 completed (loss: 4.725764274597168, acc: 0.26829269528388977)
[2024-12-17 01:34:58,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:59,031][root][INFO] - Training Epoch: 1/2, step 258/7134 completed (loss: 4.234517574310303, acc: 0.2661290466785431)
[2024-12-17 01:34:59,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:59,321][root][INFO] - Training Epoch: 1/2, step 259/7134 completed (loss: 4.4275126457214355, acc: 0.280303031206131)
[2024-12-17 01:34:59,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:59,607][root][INFO] - Training Epoch: 1/2, step 260/7134 completed (loss: 4.099005222320557, acc: 0.33834585547447205)
[2024-12-17 01:34:59,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:59,913][root][INFO] - Training Epoch: 1/2, step 261/7134 completed (loss: 4.597431182861328, acc: 0.23148147761821747)
[2024-12-17 01:35:00,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:00,178][root][INFO] - Training Epoch: 1/2, step 262/7134 completed (loss: 4.112724304199219, acc: 0.2926829159259796)
[2024-12-17 01:35:00,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:00,443][root][INFO] - Training Epoch: 1/2, step 263/7134 completed (loss: 4.28706693649292, acc: 0.25925925374031067)
[2024-12-17 01:35:00,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:00,719][root][INFO] - Training Epoch: 1/2, step 264/7134 completed (loss: 4.145606517791748, acc: 0.2235294133424759)
[2024-12-17 01:35:00,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:00,994][root][INFO] - Training Epoch: 1/2, step 265/7134 completed (loss: 4.465316295623779, acc: 0.26966291666030884)
[2024-12-17 01:35:01,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:01,264][root][INFO] - Training Epoch: 1/2, step 266/7134 completed (loss: 4.360881328582764, acc: 0.2395833283662796)
[2024-12-17 01:35:01,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:01,558][root][INFO] - Training Epoch: 1/2, step 267/7134 completed (loss: 4.550048351287842, acc: 0.23404255509376526)
[2024-12-17 01:35:01,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:01,910][root][INFO] - Training Epoch: 1/2, step 268/7134 completed (loss: 4.494015216827393, acc: 0.260606050491333)
[2024-12-17 01:35:02,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:02,273][root][INFO] - Training Epoch: 1/2, step 269/7134 completed (loss: 4.637425422668457, acc: 0.2083333283662796)
[2024-12-17 01:35:02,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:02,545][root][INFO] - Training Epoch: 1/2, step 270/7134 completed (loss: 4.51702880859375, acc: 0.2750000059604645)
[2024-12-17 01:35:02,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:02,873][root][INFO] - Training Epoch: 1/2, step 271/7134 completed (loss: 4.929737567901611, acc: 0.23333333432674408)
[2024-12-17 01:35:02,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:03,141][root][INFO] - Training Epoch: 1/2, step 272/7134 completed (loss: 4.586449146270752, acc: 0.29050278663635254)
[2024-12-17 01:35:03,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:03,406][root][INFO] - Training Epoch: 1/2, step 273/7134 completed (loss: 4.156732559204102, acc: 0.228723406791687)
[2024-12-17 01:35:03,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:03,700][root][INFO] - Training Epoch: 1/2, step 274/7134 completed (loss: 4.961287498474121, acc: 0.19883041083812714)
[2024-12-17 01:35:03,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:04,001][root][INFO] - Training Epoch: 1/2, step 275/7134 completed (loss: 4.289783000946045, acc: 0.2639593780040741)
[2024-12-17 01:35:04,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:04,303][root][INFO] - Training Epoch: 1/2, step 276/7134 completed (loss: 4.6606831550598145, acc: 0.22680412232875824)
[2024-12-17 01:35:04,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:04,594][root][INFO] - Training Epoch: 1/2, step 277/7134 completed (loss: 4.58966588973999, acc: 0.23783783614635468)
[2024-12-17 01:35:04,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:04,868][root][INFO] - Training Epoch: 1/2, step 278/7134 completed (loss: 4.722303867340088, acc: 0.2447916716337204)
[2024-12-17 01:35:04,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:05,145][root][INFO] - Training Epoch: 1/2, step 279/7134 completed (loss: 4.382245063781738, acc: 0.23783783614635468)
[2024-12-17 01:35:05,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:05,426][root][INFO] - Training Epoch: 1/2, step 280/7134 completed (loss: 4.85985803604126, acc: 0.25600001215934753)
[2024-12-17 01:35:05,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:05,705][root][INFO] - Training Epoch: 1/2, step 281/7134 completed (loss: 4.673032760620117, acc: 0.26271185278892517)
[2024-12-17 01:35:05,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:05,986][root][INFO] - Training Epoch: 1/2, step 282/7134 completed (loss: 4.6311163902282715, acc: 0.2531645596027374)
[2024-12-17 01:35:06,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:06,270][root][INFO] - Training Epoch: 1/2, step 283/7134 completed (loss: 4.657958507537842, acc: 0.2442748099565506)
[2024-12-17 01:35:06,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:06,573][root][INFO] - Training Epoch: 1/2, step 284/7134 completed (loss: 4.354496479034424, acc: 0.2237762212753296)
[2024-12-17 01:35:06,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:06,862][root][INFO] - Training Epoch: 1/2, step 285/7134 completed (loss: 4.681727409362793, acc: 0.2666666805744171)
[2024-12-17 01:35:06,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:07,122][root][INFO] - Training Epoch: 1/2, step 286/7134 completed (loss: 4.995890140533447, acc: 0.1805555522441864)
[2024-12-17 01:35:07,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:07,404][root][INFO] - Training Epoch: 1/2, step 287/7134 completed (loss: 4.43413782119751, acc: 0.281879186630249)
[2024-12-17 01:35:07,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:07,744][root][INFO] - Training Epoch: 1/2, step 288/7134 completed (loss: 4.572799205780029, acc: 0.25196850299835205)
[2024-12-17 01:35:07,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:08,045][root][INFO] - Training Epoch: 1/2, step 289/7134 completed (loss: 4.534332275390625, acc: 0.24031007289886475)
[2024-12-17 01:35:08,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:08,325][root][INFO] - Training Epoch: 1/2, step 290/7134 completed (loss: 4.35997200012207, acc: 0.27272728085517883)
[2024-12-17 01:35:08,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:08,634][root][INFO] - Training Epoch: 1/2, step 291/7134 completed (loss: 4.23138952255249, acc: 0.2857142984867096)
[2024-12-17 01:35:08,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:08,916][root][INFO] - Training Epoch: 1/2, step 292/7134 completed (loss: 5.007525444030762, acc: 0.1975308656692505)
[2024-12-17 01:35:09,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:09,202][root][INFO] - Training Epoch: 1/2, step 293/7134 completed (loss: 4.652795314788818, acc: 0.2743362784385681)
[2024-12-17 01:35:09,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:09,504][root][INFO] - Training Epoch: 1/2, step 294/7134 completed (loss: 5.22858190536499, acc: 0.18644067645072937)
[2024-12-17 01:35:09,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:09,822][root][INFO] - Training Epoch: 1/2, step 295/7134 completed (loss: 4.390669345855713, acc: 0.29487180709838867)
[2024-12-17 01:35:09,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:10,147][root][INFO] - Training Epoch: 1/2, step 296/7134 completed (loss: 4.262690544128418, acc: 0.3030303120613098)
[2024-12-17 01:35:10,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:10,437][root][INFO] - Training Epoch: 1/2, step 297/7134 completed (loss: 4.31320858001709, acc: 0.23140496015548706)
[2024-12-17 01:35:10,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:10,763][root][INFO] - Training Epoch: 1/2, step 298/7134 completed (loss: 4.657580375671387, acc: 0.26153847575187683)
[2024-12-17 01:35:10,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:11,094][root][INFO] - Training Epoch: 1/2, step 299/7134 completed (loss: 4.4264702796936035, acc: 0.22627736628055573)
[2024-12-17 01:35:11,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:11,388][root][INFO] - Training Epoch: 1/2, step 300/7134 completed (loss: 3.8635449409484863, acc: 0.3115941882133484)
[2024-12-17 01:35:11,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:11,684][root][INFO] - Training Epoch: 1/2, step 301/7134 completed (loss: 4.407243251800537, acc: 0.279720276594162)
[2024-12-17 01:35:11,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:11,959][root][INFO] - Training Epoch: 1/2, step 302/7134 completed (loss: 4.346255302429199, acc: 0.2871287167072296)
[2024-12-17 01:35:12,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:12,260][root][INFO] - Training Epoch: 1/2, step 303/7134 completed (loss: 5.016112327575684, acc: 0.2432432472705841)
[2024-12-17 01:35:12,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:12,574][root][INFO] - Training Epoch: 1/2, step 304/7134 completed (loss: 4.761547565460205, acc: 0.1782178282737732)
[2024-12-17 01:35:12,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:12,852][root][INFO] - Training Epoch: 1/2, step 305/7134 completed (loss: 4.3105950355529785, acc: 0.1875)
[2024-12-17 01:35:12,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:13,156][root][INFO] - Training Epoch: 1/2, step 306/7134 completed (loss: 4.541603088378906, acc: 0.24347825348377228)
[2024-12-17 01:35:13,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:13,464][root][INFO] - Training Epoch: 1/2, step 307/7134 completed (loss: 4.53182315826416, acc: 0.2710280418395996)
[2024-12-17 01:35:13,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:13,737][root][INFO] - Training Epoch: 1/2, step 308/7134 completed (loss: 4.322512149810791, acc: 0.24409449100494385)
[2024-12-17 01:35:13,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:14,043][root][INFO] - Training Epoch: 1/2, step 309/7134 completed (loss: 4.834989547729492, acc: 0.17699114978313446)
[2024-12-17 01:35:14,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:14,355][root][INFO] - Training Epoch: 1/2, step 310/7134 completed (loss: 4.093850612640381, acc: 0.302325576543808)
[2024-12-17 01:35:14,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:14,625][root][INFO] - Training Epoch: 1/2, step 311/7134 completed (loss: 4.278841495513916, acc: 0.25563910603523254)
[2024-12-17 01:35:14,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:14,931][root][INFO] - Training Epoch: 1/2, step 312/7134 completed (loss: 4.0677313804626465, acc: 0.28688523173332214)
[2024-12-17 01:35:15,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:15,214][root][INFO] - Training Epoch: 1/2, step 313/7134 completed (loss: 4.276822566986084, acc: 0.2639999985694885)
[2024-12-17 01:35:15,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:15,505][root][INFO] - Training Epoch: 1/2, step 314/7134 completed (loss: 4.505061626434326, acc: 0.2888889014720917)
[2024-12-17 01:35:15,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:15,794][root][INFO] - Training Epoch: 1/2, step 315/7134 completed (loss: 4.4278154373168945, acc: 0.3083333373069763)
[2024-12-17 01:35:15,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:16,056][root][INFO] - Training Epoch: 1/2, step 316/7134 completed (loss: 4.144899845123291, acc: 0.30630630254745483)
[2024-12-17 01:35:16,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:16,358][root][INFO] - Training Epoch: 1/2, step 317/7134 completed (loss: 4.253196716308594, acc: 0.18987341225147247)
[2024-12-17 01:35:16,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:16,671][root][INFO] - Training Epoch: 1/2, step 318/7134 completed (loss: 4.644237518310547, acc: 0.24193547666072845)
[2024-12-17 01:35:16,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:16,938][root][INFO] - Training Epoch: 1/2, step 319/7134 completed (loss: 4.633376121520996, acc: 0.23602484166622162)
[2024-12-17 01:35:17,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:17,242][root][INFO] - Training Epoch: 1/2, step 320/7134 completed (loss: 4.288087844848633, acc: 0.2916666567325592)
[2024-12-17 01:35:17,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:17,536][root][INFO] - Training Epoch: 1/2, step 321/7134 completed (loss: 4.457909107208252, acc: 0.2816092073917389)
[2024-12-17 01:35:17,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:17,830][root][INFO] - Training Epoch: 1/2, step 322/7134 completed (loss: 4.408745765686035, acc: 0.24183006584644318)
[2024-12-17 01:35:17,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:18,119][root][INFO] - Training Epoch: 1/2, step 323/7134 completed (loss: 4.712362289428711, acc: 0.2551020383834839)
[2024-12-17 01:35:18,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:18,397][root][INFO] - Training Epoch: 1/2, step 324/7134 completed (loss: 4.166325092315674, acc: 0.28703704476356506)
[2024-12-17 01:35:18,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:18,704][root][INFO] - Training Epoch: 1/2, step 325/7134 completed (loss: 4.194278240203857, acc: 0.27840909361839294)
[2024-12-17 01:35:18,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:18,981][root][INFO] - Training Epoch: 1/2, step 326/7134 completed (loss: 4.222375869750977, acc: 0.26404494047164917)
[2024-12-17 01:35:19,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:19,266][root][INFO] - Training Epoch: 1/2, step 327/7134 completed (loss: 4.1524338722229, acc: 0.2626262605190277)
[2024-12-17 01:35:19,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:19,589][root][INFO] - Training Epoch: 1/2, step 328/7134 completed (loss: 4.2897539138793945, acc: 0.25)
[2024-12-17 01:35:19,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:19,873][root][INFO] - Training Epoch: 1/2, step 329/7134 completed (loss: 4.158792972564697, acc: 0.27860695123672485)
[2024-12-17 01:35:19,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:20,153][root][INFO] - Training Epoch: 1/2, step 330/7134 completed (loss: 3.7588436603546143, acc: 0.3114035129547119)
[2024-12-17 01:35:20,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:20,441][root][INFO] - Training Epoch: 1/2, step 331/7134 completed (loss: 4.160834312438965, acc: 0.265625)
[2024-12-17 01:35:20,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:20,720][root][INFO] - Training Epoch: 1/2, step 332/7134 completed (loss: 3.8875300884246826, acc: 0.2636815905570984)
[2024-12-17 01:35:20,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:21,011][root][INFO] - Training Epoch: 1/2, step 333/7134 completed (loss: 4.571284294128418, acc: 0.22580644488334656)
[2024-12-17 01:35:21,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:21,338][root][INFO] - Training Epoch: 1/2, step 334/7134 completed (loss: 4.498784065246582, acc: 0.23626373708248138)
[2024-12-17 01:35:21,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:21,615][root][INFO] - Training Epoch: 1/2, step 335/7134 completed (loss: 4.133631706237793, acc: 0.2635135054588318)
[2024-12-17 01:35:21,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:21,893][root][INFO] - Training Epoch: 1/2, step 336/7134 completed (loss: 4.172900676727295, acc: 0.2331606149673462)
[2024-12-17 01:35:21,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:22,162][root][INFO] - Training Epoch: 1/2, step 337/7134 completed (loss: 4.330909729003906, acc: 0.24223601818084717)
[2024-12-17 01:35:22,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:22,432][root][INFO] - Training Epoch: 1/2, step 338/7134 completed (loss: 4.6116943359375, acc: 0.24607330560684204)
[2024-12-17 01:35:22,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:22,701][root][INFO] - Training Epoch: 1/2, step 339/7134 completed (loss: 4.367860317230225, acc: 0.2513369023799896)
[2024-12-17 01:35:22,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:22,982][root][INFO] - Training Epoch: 1/2, step 340/7134 completed (loss: 3.922982931137085, acc: 0.31313130259513855)
[2024-12-17 01:35:23,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:23,300][root][INFO] - Training Epoch: 1/2, step 341/7134 completed (loss: 4.222159385681152, acc: 0.2806122303009033)
[2024-12-17 01:35:23,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:23,587][root][INFO] - Training Epoch: 1/2, step 342/7134 completed (loss: 4.225696563720703, acc: 0.24528302252292633)
[2024-12-17 01:35:23,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:23,902][root][INFO] - Training Epoch: 1/2, step 343/7134 completed (loss: 4.272619724273682, acc: 0.2230769246816635)
[2024-12-17 01:35:24,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:24,172][root][INFO] - Training Epoch: 1/2, step 344/7134 completed (loss: 4.70454216003418, acc: 0.22480620443820953)
[2024-12-17 01:35:24,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:24,444][root][INFO] - Training Epoch: 1/2, step 345/7134 completed (loss: 4.777402400970459, acc: 0.21276596188545227)
[2024-12-17 01:35:24,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:24,743][root][INFO] - Training Epoch: 1/2, step 346/7134 completed (loss: 4.762603282928467, acc: 0.18421052396297455)
[2024-12-17 01:35:24,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:25,025][root][INFO] - Training Epoch: 1/2, step 347/7134 completed (loss: 4.253294944763184, acc: 0.26875001192092896)
[2024-12-17 01:35:25,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:25,310][root][INFO] - Training Epoch: 1/2, step 348/7134 completed (loss: 3.9683830738067627, acc: 0.30177515745162964)
[2024-12-17 01:35:25,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:25,613][root][INFO] - Training Epoch: 1/2, step 349/7134 completed (loss: 4.335825443267822, acc: 0.28994083404541016)
[2024-12-17 01:35:25,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:25,969][root][INFO] - Training Epoch: 1/2, step 350/7134 completed (loss: 4.617768287658691, acc: 0.2210526317358017)
[2024-12-17 01:35:26,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:26,302][root][INFO] - Training Epoch: 1/2, step 351/7134 completed (loss: 4.5158915519714355, acc: 0.2663043439388275)
[2024-12-17 01:35:26,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:26,605][root][INFO] - Training Epoch: 1/2, step 352/7134 completed (loss: 4.159482479095459, acc: 0.2982456088066101)
[2024-12-17 01:35:26,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:26,949][root][INFO] - Training Epoch: 1/2, step 353/7134 completed (loss: 4.380708694458008, acc: 0.25153374671936035)
[2024-12-17 01:35:27,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:27,257][root][INFO] - Training Epoch: 1/2, step 354/7134 completed (loss: 4.24615478515625, acc: 0.2763819098472595)
[2024-12-17 01:35:27,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:27,603][root][INFO] - Training Epoch: 1/2, step 355/7134 completed (loss: 4.272572040557861, acc: 0.2958579957485199)
[2024-12-17 01:35:27,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:27,943][root][INFO] - Training Epoch: 1/2, step 356/7134 completed (loss: 3.9147024154663086, acc: 0.31736525893211365)
[2024-12-17 01:35:28,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:28,265][root][INFO] - Training Epoch: 1/2, step 357/7134 completed (loss: 4.180464267730713, acc: 0.22674418985843658)
[2024-12-17 01:35:28,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:28,567][root][INFO] - Training Epoch: 1/2, step 358/7134 completed (loss: 3.6067044734954834, acc: 0.27840909361839294)
[2024-12-17 01:35:28,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:28,886][root][INFO] - Training Epoch: 1/2, step 359/7134 completed (loss: 4.043554306030273, acc: 0.2764706015586853)
[2024-12-17 01:35:29,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:29,174][root][INFO] - Training Epoch: 1/2, step 360/7134 completed (loss: 3.9937589168548584, acc: 0.27450981736183167)
[2024-12-17 01:35:29,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:29,460][root][INFO] - Training Epoch: 1/2, step 361/7134 completed (loss: 3.729574203491211, acc: 0.2269938588142395)
[2024-12-17 01:35:29,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:29,772][root][INFO] - Training Epoch: 1/2, step 362/7134 completed (loss: 4.18414831161499, acc: 0.2594936788082123)
[2024-12-17 01:35:29,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:30,066][root][INFO] - Training Epoch: 1/2, step 363/7134 completed (loss: 4.364128112792969, acc: 0.18579235672950745)
[2024-12-17 01:35:30,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:30,368][root][INFO] - Training Epoch: 1/2, step 364/7134 completed (loss: 4.408316612243652, acc: 0.223300963640213)
[2024-12-17 01:35:30,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:30,695][root][INFO] - Training Epoch: 1/2, step 365/7134 completed (loss: 3.8829221725463867, acc: 0.3037974536418915)
[2024-12-17 01:35:30,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:31,031][root][INFO] - Training Epoch: 1/2, step 366/7134 completed (loss: 3.9332563877105713, acc: 0.2611464858055115)
[2024-12-17 01:35:31,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:31,364][root][INFO] - Training Epoch: 1/2, step 367/7134 completed (loss: 3.866553544998169, acc: 0.2989690601825714)
[2024-12-17 01:35:31,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:31,640][root][INFO] - Training Epoch: 1/2, step 368/7134 completed (loss: 3.6686227321624756, acc: 0.24852071702480316)
[2024-12-17 01:35:31,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:31,918][root][INFO] - Training Epoch: 1/2, step 369/7134 completed (loss: 4.364059925079346, acc: 0.19631901383399963)
[2024-12-17 01:35:32,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:32,241][root][INFO] - Training Epoch: 1/2, step 370/7134 completed (loss: 4.443175315856934, acc: 0.20253165066242218)
[2024-12-17 01:35:32,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:32,569][root][INFO] - Training Epoch: 1/2, step 371/7134 completed (loss: 4.16195011138916, acc: 0.26708075404167175)
[2024-12-17 01:35:32,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:32,865][root][INFO] - Training Epoch: 1/2, step 372/7134 completed (loss: 4.402811527252197, acc: 0.24528302252292633)
[2024-12-17 01:35:33,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:33,182][root][INFO] - Training Epoch: 1/2, step 373/7134 completed (loss: 4.030412673950195, acc: 0.27450981736183167)
[2024-12-17 01:35:33,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:33,459][root][INFO] - Training Epoch: 1/2, step 374/7134 completed (loss: 3.6489295959472656, acc: 0.27702704071998596)
[2024-12-17 01:35:33,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:33,782][root][INFO] - Training Epoch: 1/2, step 375/7134 completed (loss: 3.8153038024902344, acc: 0.3191489279270172)
[2024-12-17 01:35:33,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:34,076][root][INFO] - Training Epoch: 1/2, step 376/7134 completed (loss: 4.369708061218262, acc: 0.2611111104488373)
[2024-12-17 01:35:34,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:34,397][root][INFO] - Training Epoch: 1/2, step 377/7134 completed (loss: 4.110811233520508, acc: 0.2569832503795624)
[2024-12-17 01:35:34,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:34,697][root][INFO] - Training Epoch: 1/2, step 378/7134 completed (loss: 4.558599472045898, acc: 0.26553672552108765)
[2024-12-17 01:35:34,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:35,012][root][INFO] - Training Epoch: 1/2, step 379/7134 completed (loss: 3.5229177474975586, acc: 0.28431373834609985)
[2024-12-17 01:35:35,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:35,339][root][INFO] - Training Epoch: 1/2, step 380/7134 completed (loss: 4.588809490203857, acc: 0.26288658380508423)
[2024-12-17 01:35:35,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:35,621][root][INFO] - Training Epoch: 1/2, step 381/7134 completed (loss: 4.341879844665527, acc: 0.2631579041481018)
[2024-12-17 01:35:35,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:35,940][root][INFO] - Training Epoch: 1/2, step 382/7134 completed (loss: 3.754321336746216, acc: 0.3333333432674408)
[2024-12-17 01:35:36,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:36,219][root][INFO] - Training Epoch: 1/2, step 383/7134 completed (loss: 3.97357177734375, acc: 0.26356589794158936)
[2024-12-17 01:35:36,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:36,538][root][INFO] - Training Epoch: 1/2, step 384/7134 completed (loss: 3.6792349815368652, acc: 0.32044199109077454)
[2024-12-17 01:35:36,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:36,860][root][INFO] - Training Epoch: 1/2, step 385/7134 completed (loss: 3.6609182357788086, acc: 0.33986929059028625)
[2024-12-17 01:35:37,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:37,146][root][INFO] - Training Epoch: 1/2, step 386/7134 completed (loss: 4.156231880187988, acc: 0.2702702581882477)
[2024-12-17 01:35:37,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:37,485][root][INFO] - Training Epoch: 1/2, step 387/7134 completed (loss: 4.40996789932251, acc: 0.21301774680614471)
[2024-12-17 01:35:37,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:37,770][root][INFO] - Training Epoch: 1/2, step 388/7134 completed (loss: 3.7410149574279785, acc: 0.3253588378429413)
[2024-12-17 01:35:37,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:38,052][root][INFO] - Training Epoch: 1/2, step 389/7134 completed (loss: 4.145864009857178, acc: 0.2914285659790039)
[2024-12-17 01:35:38,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:38,385][root][INFO] - Training Epoch: 1/2, step 390/7134 completed (loss: 3.9697604179382324, acc: 0.29054054617881775)
[2024-12-17 01:35:38,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:38,668][root][INFO] - Training Epoch: 1/2, step 391/7134 completed (loss: 3.6863489151000977, acc: 0.3199999928474426)
[2024-12-17 01:35:38,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:39,005][root][INFO] - Training Epoch: 1/2, step 392/7134 completed (loss: 3.595912456512451, acc: 0.3255814015865326)
[2024-12-17 01:35:39,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:39,329][root][INFO] - Training Epoch: 1/2, step 393/7134 completed (loss: 3.689915180206299, acc: 0.32620319724082947)
[2024-12-17 01:35:39,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:39,650][root][INFO] - Training Epoch: 1/2, step 394/7134 completed (loss: 4.137040138244629, acc: 0.2671755850315094)
[2024-12-17 01:35:39,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:39,955][root][INFO] - Training Epoch: 1/2, step 395/7134 completed (loss: 3.639653205871582, acc: 0.2978723347187042)
[2024-12-17 01:35:40,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:40,233][root][INFO] - Training Epoch: 1/2, step 396/7134 completed (loss: 4.295275688171387, acc: 0.26724138855934143)
[2024-12-17 01:35:40,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:40,574][root][INFO] - Training Epoch: 1/2, step 397/7134 completed (loss: 4.220364570617676, acc: 0.28260868787765503)
[2024-12-17 01:35:40,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:40,861][root][INFO] - Training Epoch: 1/2, step 398/7134 completed (loss: 3.8816468715667725, acc: 0.3585858643054962)
[2024-12-17 01:35:41,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:41,164][root][INFO] - Training Epoch: 1/2, step 399/7134 completed (loss: 3.9483940601348877, acc: 0.29113924503326416)
[2024-12-17 01:35:41,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:41,455][root][INFO] - Training Epoch: 1/2, step 400/7134 completed (loss: 4.249748706817627, acc: 0.297468364238739)
[2024-12-17 01:35:41,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:41,764][root][INFO] - Training Epoch: 1/2, step 401/7134 completed (loss: 3.976902723312378, acc: 0.27941176295280457)
[2024-12-17 01:35:41,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:42,090][root][INFO] - Training Epoch: 1/2, step 402/7134 completed (loss: 4.294175624847412, acc: 0.19597989320755005)
[2024-12-17 01:35:42,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:42,447][root][INFO] - Training Epoch: 1/2, step 403/7134 completed (loss: 3.7443079948425293, acc: 0.3056768476963043)
[2024-12-17 01:35:42,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:42,717][root][INFO] - Training Epoch: 1/2, step 404/7134 completed (loss: 3.8599202632904053, acc: 0.301075279712677)
[2024-12-17 01:35:42,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:43,035][root][INFO] - Training Epoch: 1/2, step 405/7134 completed (loss: 4.027692794799805, acc: 0.302325576543808)
[2024-12-17 01:35:43,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:43,333][root][INFO] - Training Epoch: 1/2, step 406/7134 completed (loss: 3.8498363494873047, acc: 0.2594594657421112)
[2024-12-17 01:35:43,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:43,600][root][INFO] - Training Epoch: 1/2, step 407/7134 completed (loss: 3.960942506790161, acc: 0.29936304688453674)
[2024-12-17 01:35:43,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:43,914][root][INFO] - Training Epoch: 1/2, step 408/7134 completed (loss: 3.5272979736328125, acc: 0.3072625696659088)
[2024-12-17 01:35:44,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:44,188][root][INFO] - Training Epoch: 1/2, step 409/7134 completed (loss: 4.035499095916748, acc: 0.28421053290367126)
[2024-12-17 01:35:44,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:44,496][root][INFO] - Training Epoch: 1/2, step 410/7134 completed (loss: 3.7483036518096924, acc: 0.3030303120613098)
[2024-12-17 01:35:44,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:44,800][root][INFO] - Training Epoch: 1/2, step 411/7134 completed (loss: 3.9464714527130127, acc: 0.28378379344940186)
[2024-12-17 01:35:44,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:45,083][root][INFO] - Training Epoch: 1/2, step 412/7134 completed (loss: 3.9081945419311523, acc: 0.26457399129867554)
[2024-12-17 01:35:45,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:45,366][root][INFO] - Training Epoch: 1/2, step 413/7134 completed (loss: 4.343397617340088, acc: 0.2565445005893707)
[2024-12-17 01:35:45,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:45,665][root][INFO] - Training Epoch: 1/2, step 414/7134 completed (loss: 4.388288497924805, acc: 0.2774566411972046)
[2024-12-17 01:35:45,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:45,957][root][INFO] - Training Epoch: 1/2, step 415/7134 completed (loss: 4.071957588195801, acc: 0.25238096714019775)
[2024-12-17 01:35:46,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:46,268][root][INFO] - Training Epoch: 1/2, step 416/7134 completed (loss: 3.7270636558532715, acc: 0.26923078298568726)
[2024-12-17 01:35:46,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:46,606][root][INFO] - Training Epoch: 1/2, step 417/7134 completed (loss: 4.175768852233887, acc: 0.2967033088207245)
[2024-12-17 01:35:46,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:46,938][root][INFO] - Training Epoch: 1/2, step 418/7134 completed (loss: 4.108889579772949, acc: 0.3285024166107178)
[2024-12-17 01:35:47,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:47,251][root][INFO] - Training Epoch: 1/2, step 419/7134 completed (loss: 3.9648427963256836, acc: 0.30693069100379944)
[2024-12-17 01:35:47,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:47,583][root][INFO] - Training Epoch: 1/2, step 420/7134 completed (loss: 4.389254093170166, acc: 0.24285714328289032)
[2024-12-17 01:35:47,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:47,912][root][INFO] - Training Epoch: 1/2, step 421/7134 completed (loss: 3.651115655899048, acc: 0.29559749364852905)
[2024-12-17 01:35:48,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:48,217][root][INFO] - Training Epoch: 1/2, step 422/7134 completed (loss: 4.385964870452881, acc: 0.23668639361858368)
[2024-12-17 01:35:48,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:48,525][root][INFO] - Training Epoch: 1/2, step 423/7134 completed (loss: 3.4545881748199463, acc: 0.26966291666030884)
[2024-12-17 01:35:48,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:48,810][root][INFO] - Training Epoch: 1/2, step 424/7134 completed (loss: 3.7522785663604736, acc: 0.2716049253940582)
[2024-12-17 01:35:48,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:49,155][root][INFO] - Training Epoch: 1/2, step 425/7134 completed (loss: 3.5529558658599854, acc: 0.3011363744735718)
[2024-12-17 01:35:49,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:49,450][root][INFO] - Training Epoch: 1/2, step 426/7134 completed (loss: 3.643333911895752, acc: 0.28823530673980713)
[2024-12-17 01:35:49,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:49,726][root][INFO] - Training Epoch: 1/2, step 427/7134 completed (loss: 3.7468109130859375, acc: 0.3396226465702057)
[2024-12-17 01:35:49,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:50,056][root][INFO] - Training Epoch: 1/2, step 428/7134 completed (loss: 4.031910419464111, acc: 0.2514970004558563)
[2024-12-17 01:35:50,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:50,355][root][INFO] - Training Epoch: 1/2, step 429/7134 completed (loss: 4.306624889373779, acc: 0.2565789520740509)
[2024-12-17 01:35:50,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:50,667][root][INFO] - Training Epoch: 1/2, step 430/7134 completed (loss: 4.350250720977783, acc: 0.24117647111415863)
[2024-12-17 01:35:50,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:50,958][root][INFO] - Training Epoch: 1/2, step 431/7134 completed (loss: 3.9410359859466553, acc: 0.2840236723423004)
[2024-12-17 01:35:51,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:51,256][root][INFO] - Training Epoch: 1/2, step 432/7134 completed (loss: 4.444448947906494, acc: 0.2348484843969345)
[2024-12-17 01:35:51,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:51,614][root][INFO] - Training Epoch: 1/2, step 433/7134 completed (loss: 3.5056312084198, acc: 0.3723404109477997)
[2024-12-17 01:35:51,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:51,931][root][INFO] - Training Epoch: 1/2, step 434/7134 completed (loss: 3.912306070327759, acc: 0.29012346267700195)
[2024-12-17 01:35:52,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:52,223][root][INFO] - Training Epoch: 1/2, step 435/7134 completed (loss: 3.948319911956787, acc: 0.2666666805744171)
[2024-12-17 01:35:52,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:52,500][root][INFO] - Training Epoch: 1/2, step 436/7134 completed (loss: 3.9686992168426514, acc: 0.3263888955116272)
[2024-12-17 01:35:52,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:52,777][root][INFO] - Training Epoch: 1/2, step 437/7134 completed (loss: 4.292227745056152, acc: 0.19718310236930847)
[2024-12-17 01:35:52,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:53,053][root][INFO] - Training Epoch: 1/2, step 438/7134 completed (loss: 4.016214847564697, acc: 0.25984251499176025)
[2024-12-17 01:35:53,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:53,378][root][INFO] - Training Epoch: 1/2, step 439/7134 completed (loss: 3.801304578781128, acc: 0.33908045291900635)
[2024-12-17 01:35:53,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:53,701][root][INFO] - Training Epoch: 1/2, step 440/7134 completed (loss: 4.102662086486816, acc: 0.2846153974533081)
[2024-12-17 01:35:53,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:54,018][root][INFO] - Training Epoch: 1/2, step 441/7134 completed (loss: 3.6673223972320557, acc: 0.2876712381839752)
[2024-12-17 01:35:54,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:54,342][root][INFO] - Training Epoch: 1/2, step 442/7134 completed (loss: 3.3889455795288086, acc: 0.2945736348628998)
[2024-12-17 01:35:54,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:54,627][root][INFO] - Training Epoch: 1/2, step 443/7134 completed (loss: 3.3694064617156982, acc: 0.3265306055545807)
[2024-12-17 01:35:54,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:54,971][root][INFO] - Training Epoch: 1/2, step 444/7134 completed (loss: 3.339704990386963, acc: 0.3333333432674408)
[2024-12-17 01:35:55,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:55,252][root][INFO] - Training Epoch: 1/2, step 445/7134 completed (loss: 3.898787498474121, acc: 0.2578616440296173)
[2024-12-17 01:35:55,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:55,556][root][INFO] - Training Epoch: 1/2, step 446/7134 completed (loss: 3.7931737899780273, acc: 0.27218934893608093)
[2024-12-17 01:35:55,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:55,873][root][INFO] - Training Epoch: 1/2, step 447/7134 completed (loss: 3.9086947441101074, acc: 0.2638036906719208)
[2024-12-17 01:35:56,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:56,161][root][INFO] - Training Epoch: 1/2, step 448/7134 completed (loss: 4.018277168273926, acc: 0.23280423879623413)
[2024-12-17 01:35:56,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:56,458][root][INFO] - Training Epoch: 1/2, step 449/7134 completed (loss: 4.116354465484619, acc: 0.28723403811454773)
[2024-12-17 01:35:56,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:56,745][root][INFO] - Training Epoch: 1/2, step 450/7134 completed (loss: 4.096071720123291, acc: 0.30188679695129395)
[2024-12-17 01:35:56,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:57,048][root][INFO] - Training Epoch: 1/2, step 451/7134 completed (loss: 4.094218730926514, acc: 0.31779661774635315)
[2024-12-17 01:35:57,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:57,342][root][INFO] - Training Epoch: 1/2, step 452/7134 completed (loss: 4.2324748039245605, acc: 0.2921348214149475)
[2024-12-17 01:35:57,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:57,655][root][INFO] - Training Epoch: 1/2, step 453/7134 completed (loss: 3.974684238433838, acc: 0.3404255211353302)
[2024-12-17 01:35:57,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:57,950][root][INFO] - Training Epoch: 1/2, step 454/7134 completed (loss: 3.846306085586548, acc: 0.27848100662231445)
[2024-12-17 01:35:58,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:58,241][root][INFO] - Training Epoch: 1/2, step 455/7134 completed (loss: 4.237701416015625, acc: 0.3384615480899811)
[2024-12-17 01:35:58,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:58,546][root][INFO] - Training Epoch: 1/2, step 456/7134 completed (loss: 4.178972244262695, acc: 0.24539877474308014)
[2024-12-17 01:35:58,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:58,841][root][INFO] - Training Epoch: 1/2, step 457/7134 completed (loss: 4.054615020751953, acc: 0.22068965435028076)
[2024-12-17 01:35:59,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:59,160][root][INFO] - Training Epoch: 1/2, step 458/7134 completed (loss: 4.186132907867432, acc: 0.27419355511665344)
[2024-12-17 01:35:59,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:59,456][root][INFO] - Training Epoch: 1/2, step 459/7134 completed (loss: 3.987683057785034, acc: 0.3132530152797699)
[2024-12-17 01:35:59,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:59,745][root][INFO] - Training Epoch: 1/2, step 460/7134 completed (loss: 4.177140712738037, acc: 0.25333333015441895)
[2024-12-17 01:35:59,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:00,023][root][INFO] - Training Epoch: 1/2, step 461/7134 completed (loss: 4.477004528045654, acc: 0.2294117659330368)
[2024-12-17 01:36:00,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:00,330][root][INFO] - Training Epoch: 1/2, step 462/7134 completed (loss: 4.057037353515625, acc: 0.25925925374031067)
[2024-12-17 01:36:00,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:00,663][root][INFO] - Training Epoch: 1/2, step 463/7134 completed (loss: 4.313653469085693, acc: 0.2985074520111084)
[2024-12-17 01:36:00,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:01,030][root][INFO] - Training Epoch: 1/2, step 464/7134 completed (loss: 3.8299567699432373, acc: 0.3011363744735718)
[2024-12-17 01:36:01,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:01,337][root][INFO] - Training Epoch: 1/2, step 465/7134 completed (loss: 3.7974298000335693, acc: 0.2849161922931671)
[2024-12-17 01:36:01,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:01,649][root][INFO] - Training Epoch: 1/2, step 466/7134 completed (loss: 4.195049285888672, acc: 0.28654971718788147)
[2024-12-17 01:36:01,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:01,958][root][INFO] - Training Epoch: 1/2, step 467/7134 completed (loss: 4.126471519470215, acc: 0.3333333432674408)
[2024-12-17 01:36:02,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:02,247][root][INFO] - Training Epoch: 1/2, step 468/7134 completed (loss: 4.0286078453063965, acc: 0.3266666531562805)
[2024-12-17 01:36:02,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:02,516][root][INFO] - Training Epoch: 1/2, step 469/7134 completed (loss: 4.105073928833008, acc: 0.375)
[2024-12-17 01:36:02,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:02,788][root][INFO] - Training Epoch: 1/2, step 470/7134 completed (loss: 4.022531032562256, acc: 0.36486485600471497)
[2024-12-17 01:36:02,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:03,061][root][INFO] - Training Epoch: 1/2, step 471/7134 completed (loss: 4.103088855743408, acc: 0.32967033982276917)
[2024-12-17 01:36:03,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:03,358][root][INFO] - Training Epoch: 1/2, step 472/7134 completed (loss: 4.242710590362549, acc: 0.2866666615009308)
[2024-12-17 01:36:03,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:03,689][root][INFO] - Training Epoch: 1/2, step 473/7134 completed (loss: 3.978475332260132, acc: 0.25757575035095215)
[2024-12-17 01:36:03,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:03,989][root][INFO] - Training Epoch: 1/2, step 474/7134 completed (loss: 4.476747989654541, acc: 0.27272728085517883)
[2024-12-17 01:36:04,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:04,295][root][INFO] - Training Epoch: 1/2, step 475/7134 completed (loss: 3.908074140548706, acc: 0.3636363744735718)
[2024-12-17 01:36:04,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:04,603][root][INFO] - Training Epoch: 1/2, step 476/7134 completed (loss: 4.479240894317627, acc: 0.23125000298023224)
[2024-12-17 01:36:04,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:04,904][root][INFO] - Training Epoch: 1/2, step 477/7134 completed (loss: 3.9382686614990234, acc: 0.26737967133522034)
[2024-12-17 01:36:05,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:05,221][root][INFO] - Training Epoch: 1/2, step 478/7134 completed (loss: 3.968421697616577, acc: 0.269565224647522)
[2024-12-17 01:36:05,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:05,496][root][INFO] - Training Epoch: 1/2, step 479/7134 completed (loss: 4.412919044494629, acc: 0.33112582564353943)
[2024-12-17 01:36:05,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:05,775][root][INFO] - Training Epoch: 1/2, step 480/7134 completed (loss: 4.310903549194336, acc: 0.28125)
[2024-12-17 01:36:05,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:06,060][root][INFO] - Training Epoch: 1/2, step 481/7134 completed (loss: 4.265535354614258, acc: 0.2857142984867096)
[2024-12-17 01:36:06,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:06,375][root][INFO] - Training Epoch: 1/2, step 482/7134 completed (loss: 4.073597431182861, acc: 0.31446540355682373)
[2024-12-17 01:36:06,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:06,663][root][INFO] - Training Epoch: 1/2, step 483/7134 completed (loss: 4.0630645751953125, acc: 0.24725274741649628)
[2024-12-17 01:36:06,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:06,948][root][INFO] - Training Epoch: 1/2, step 484/7134 completed (loss: 4.68564510345459, acc: 0.22959183156490326)
[2024-12-17 01:36:07,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:07,227][root][INFO] - Training Epoch: 1/2, step 485/7134 completed (loss: 4.696112632751465, acc: 0.23602484166622162)
[2024-12-17 01:36:07,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:07,509][root][INFO] - Training Epoch: 1/2, step 486/7134 completed (loss: 4.742569923400879, acc: 0.21935483813285828)
[2024-12-17 01:36:07,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:07,841][root][INFO] - Training Epoch: 1/2, step 487/7134 completed (loss: 4.404272556304932, acc: 0.1975308656692505)
[2024-12-17 01:36:07,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:08,133][root][INFO] - Training Epoch: 1/2, step 488/7134 completed (loss: 4.6969380378723145, acc: 0.23880596458911896)
[2024-12-17 01:36:08,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:08,465][root][INFO] - Training Epoch: 1/2, step 489/7134 completed (loss: 4.400071620941162, acc: 0.28057554364204407)
[2024-12-17 01:36:08,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:08,744][root][INFO] - Training Epoch: 1/2, step 490/7134 completed (loss: 3.869027853012085, acc: 0.3417721390724182)
[2024-12-17 01:36:08,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:09,017][root][INFO] - Training Epoch: 1/2, step 491/7134 completed (loss: 4.05128288269043, acc: 0.3194444477558136)
[2024-12-17 01:36:09,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:09,292][root][INFO] - Training Epoch: 1/2, step 492/7134 completed (loss: 4.036185264587402, acc: 0.2774193584918976)
[2024-12-17 01:36:09,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:09,628][root][INFO] - Training Epoch: 1/2, step 493/7134 completed (loss: 4.588113307952881, acc: 0.2248520702123642)
[2024-12-17 01:36:09,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:09,917][root][INFO] - Training Epoch: 1/2, step 494/7134 completed (loss: 4.653038501739502, acc: 0.23333333432674408)
[2024-12-17 01:36:10,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:10,224][root][INFO] - Training Epoch: 1/2, step 495/7134 completed (loss: 3.2796733379364014, acc: 0.3140496015548706)
[2024-12-17 01:36:10,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:10,526][root][INFO] - Training Epoch: 1/2, step 496/7134 completed (loss: 4.426732540130615, acc: 0.2631579041481018)
[2024-12-17 01:36:10,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:10,841][root][INFO] - Training Epoch: 1/2, step 497/7134 completed (loss: 3.720250368118286, acc: 0.3461538553237915)
[2024-12-17 01:36:11,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:11,177][root][INFO] - Training Epoch: 1/2, step 498/7134 completed (loss: 3.8078927993774414, acc: 0.3221476376056671)
[2024-12-17 01:36:11,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:11,492][root][INFO] - Training Epoch: 1/2, step 499/7134 completed (loss: 3.3590612411499023, acc: 0.38235294818878174)
[2024-12-17 01:36:11,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:11,787][root][INFO] - Training Epoch: 1/2, step 500/7134 completed (loss: 3.9564290046691895, acc: 0.302325576543808)
[2024-12-17 01:36:11,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:12,122][root][INFO] - Training Epoch: 1/2, step 501/7134 completed (loss: 3.9158921241760254, acc: 0.2774566411972046)
[2024-12-17 01:36:12,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:12,423][root][INFO] - Training Epoch: 1/2, step 502/7134 completed (loss: 3.154573678970337, acc: 0.38311687111854553)
[2024-12-17 01:36:12,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:12,698][root][INFO] - Training Epoch: 1/2, step 503/7134 completed (loss: 3.779921531677246, acc: 0.2954545319080353)
[2024-12-17 01:36:12,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:13,002][root][INFO] - Training Epoch: 1/2, step 504/7134 completed (loss: 3.8710269927978516, acc: 0.2981366515159607)
[2024-12-17 01:36:13,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:13,303][root][INFO] - Training Epoch: 1/2, step 505/7134 completed (loss: 4.315577507019043, acc: 0.2738095223903656)
[2024-12-17 01:36:13,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:13,635][root][INFO] - Training Epoch: 1/2, step 506/7134 completed (loss: 3.624563694000244, acc: 0.27272728085517883)
[2024-12-17 01:36:13,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:13,947][root][INFO] - Training Epoch: 1/2, step 507/7134 completed (loss: 3.7144200801849365, acc: 0.33879780769348145)
[2024-12-17 01:36:14,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:14,286][root][INFO] - Training Epoch: 1/2, step 508/7134 completed (loss: 3.990182399749756, acc: 0.25882354378700256)
[2024-12-17 01:36:14,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:14,633][root][INFO] - Training Epoch: 1/2, step 509/7134 completed (loss: 4.8609938621521, acc: 0.22297297418117523)
[2024-12-17 01:36:14,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:14,947][root][INFO] - Training Epoch: 1/2, step 510/7134 completed (loss: 5.313319683074951, acc: 0.17886178195476532)
[2024-12-17 01:36:15,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:15,257][root][INFO] - Training Epoch: 1/2, step 511/7134 completed (loss: 4.702049732208252, acc: 0.20952381193637848)
[2024-12-17 01:36:15,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:15,548][root][INFO] - Training Epoch: 1/2, step 512/7134 completed (loss: 4.981097221374512, acc: 0.19083969295024872)
[2024-12-17 01:36:15,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:15,852][root][INFO] - Training Epoch: 1/2, step 513/7134 completed (loss: 4.564150810241699, acc: 0.268456369638443)
[2024-12-17 01:36:16,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:16,146][root][INFO] - Training Epoch: 1/2, step 514/7134 completed (loss: 5.040902137756348, acc: 0.12037037312984467)
[2024-12-17 01:36:16,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:16,439][root][INFO] - Training Epoch: 1/2, step 515/7134 completed (loss: 4.758578300476074, acc: 0.1726190447807312)
[2024-12-17 01:36:16,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:16,707][root][INFO] - Training Epoch: 1/2, step 516/7134 completed (loss: 4.678493022918701, acc: 0.23728813230991364)
[2024-12-17 01:36:16,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:16,989][root][INFO] - Training Epoch: 1/2, step 517/7134 completed (loss: 5.305086135864258, acc: 0.21014492213726044)
[2024-12-17 01:36:17,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:17,274][root][INFO] - Training Epoch: 1/2, step 518/7134 completed (loss: 4.401751518249512, acc: 0.251655638217926)
[2024-12-17 01:36:17,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:17,566][root][INFO] - Training Epoch: 1/2, step 519/7134 completed (loss: 4.557679653167725, acc: 0.208695650100708)
[2024-12-17 01:36:17,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:17,856][root][INFO] - Training Epoch: 1/2, step 520/7134 completed (loss: 4.064539909362793, acc: 0.2697368562221527)
[2024-12-17 01:36:18,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:18,143][root][INFO] - Training Epoch: 1/2, step 521/7134 completed (loss: 4.44340705871582, acc: 0.24561403691768646)
[2024-12-17 01:36:18,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:18,468][root][INFO] - Training Epoch: 1/2, step 522/7134 completed (loss: 4.432563304901123, acc: 0.2078651636838913)
[2024-12-17 01:36:18,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:18,760][root][INFO] - Training Epoch: 1/2, step 523/7134 completed (loss: 3.7905373573303223, acc: 0.3139534890651703)
[2024-12-17 01:36:18,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:19,048][root][INFO] - Training Epoch: 1/2, step 524/7134 completed (loss: 4.131436824798584, acc: 0.24858756363391876)
[2024-12-17 01:36:19,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:19,342][root][INFO] - Training Epoch: 1/2, step 525/7134 completed (loss: 3.964298963546753, acc: 0.3128834366798401)
[2024-12-17 01:36:19,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:19,627][root][INFO] - Training Epoch: 1/2, step 526/7134 completed (loss: 4.2502641677856445, acc: 0.2670454680919647)
[2024-12-17 01:36:19,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:19,901][root][INFO] - Training Epoch: 1/2, step 527/7134 completed (loss: 4.497387409210205, acc: 0.2109375)
[2024-12-17 01:36:20,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:20,192][root][INFO] - Training Epoch: 1/2, step 528/7134 completed (loss: 4.453364372253418, acc: 0.26724138855934143)
[2024-12-17 01:36:20,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:20,532][root][INFO] - Training Epoch: 1/2, step 529/7134 completed (loss: 4.639138221740723, acc: 0.2611464858055115)
[2024-12-17 01:36:20,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:20,813][root][INFO] - Training Epoch: 1/2, step 530/7134 completed (loss: 4.740813255310059, acc: 0.2538461685180664)
[2024-12-17 01:36:20,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:21,099][root][INFO] - Training Epoch: 1/2, step 531/7134 completed (loss: 4.4153337478637695, acc: 0.2054794579744339)
[2024-12-17 01:36:21,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:21,384][root][INFO] - Training Epoch: 1/2, step 532/7134 completed (loss: 4.427271842956543, acc: 0.22123894095420837)
[2024-12-17 01:36:21,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:21,713][root][INFO] - Training Epoch: 1/2, step 533/7134 completed (loss: 4.6643548011779785, acc: 0.2380952388048172)
[2024-12-17 01:36:21,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:22,002][root][INFO] - Training Epoch: 1/2, step 534/7134 completed (loss: 4.743931770324707, acc: 0.17365269362926483)
[2024-12-17 01:36:22,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:22,337][root][INFO] - Training Epoch: 1/2, step 535/7134 completed (loss: 4.36857271194458, acc: 0.24087591469287872)
[2024-12-17 01:36:22,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:22,623][root][INFO] - Training Epoch: 1/2, step 536/7134 completed (loss: 4.581656455993652, acc: 0.2195121943950653)
[2024-12-17 01:36:22,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:22,908][root][INFO] - Training Epoch: 1/2, step 537/7134 completed (loss: 4.480020046234131, acc: 0.2658959627151489)
[2024-12-17 01:36:23,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:23,229][root][INFO] - Training Epoch: 1/2, step 538/7134 completed (loss: 4.4805498123168945, acc: 0.23493975400924683)
[2024-12-17 01:36:23,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:23,527][root][INFO] - Training Epoch: 1/2, step 539/7134 completed (loss: 4.517862319946289, acc: 0.3129771053791046)
[2024-12-17 01:36:23,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:23,803][root][INFO] - Training Epoch: 1/2, step 540/7134 completed (loss: 4.613072872161865, acc: 0.24528302252292633)
[2024-12-17 01:36:23,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:24,161][root][INFO] - Training Epoch: 1/2, step 541/7134 completed (loss: 4.334907054901123, acc: 0.25)
[2024-12-17 01:36:24,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:24,498][root][INFO] - Training Epoch: 1/2, step 542/7134 completed (loss: 5.013947486877441, acc: 0.23000000417232513)
[2024-12-17 01:36:24,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:24,831][root][INFO] - Training Epoch: 1/2, step 543/7134 completed (loss: 4.090242385864258, acc: 0.32894736528396606)
[2024-12-17 01:36:24,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:25,140][root][INFO] - Training Epoch: 1/2, step 544/7134 completed (loss: 4.551453113555908, acc: 0.2857142984867096)
[2024-12-17 01:36:25,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:25,486][root][INFO] - Training Epoch: 1/2, step 545/7134 completed (loss: 4.522519111633301, acc: 0.29323309659957886)
[2024-12-17 01:36:25,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:25,783][root][INFO] - Training Epoch: 1/2, step 546/7134 completed (loss: 4.095400333404541, acc: 0.31481480598449707)
[2024-12-17 01:36:25,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:26,079][root][INFO] - Training Epoch: 1/2, step 547/7134 completed (loss: 4.236297607421875, acc: 0.2847682237625122)
[2024-12-17 01:36:26,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:26,372][root][INFO] - Training Epoch: 1/2, step 548/7134 completed (loss: 4.422105312347412, acc: 0.28947368264198303)
[2024-12-17 01:36:26,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:26,659][root][INFO] - Training Epoch: 1/2, step 549/7134 completed (loss: 4.871778964996338, acc: 0.2928571403026581)
[2024-12-17 01:36:26,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:26,947][root][INFO] - Training Epoch: 1/2, step 550/7134 completed (loss: 4.73317289352417, acc: 0.24409449100494385)
[2024-12-17 01:36:27,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:27,213][root][INFO] - Training Epoch: 1/2, step 551/7134 completed (loss: 4.484887599945068, acc: 0.3046875)
[2024-12-17 01:36:27,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:27,500][root][INFO] - Training Epoch: 1/2, step 552/7134 completed (loss: 4.183078289031982, acc: 0.3401360511779785)
[2024-12-17 01:36:27,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:27,799][root][INFO] - Training Epoch: 1/2, step 553/7134 completed (loss: 4.510952472686768, acc: 0.31578946113586426)
[2024-12-17 01:36:27,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:28,115][root][INFO] - Training Epoch: 1/2, step 554/7134 completed (loss: 4.50521183013916, acc: 0.2802547812461853)
[2024-12-17 01:36:28,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:28,394][root][INFO] - Training Epoch: 1/2, step 555/7134 completed (loss: 4.436069488525391, acc: 0.2792207896709442)
[2024-12-17 01:36:28,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:28,683][root][INFO] - Training Epoch: 1/2, step 556/7134 completed (loss: 3.7387473583221436, acc: 0.36250001192092896)
[2024-12-17 01:36:28,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:28,976][root][INFO] - Training Epoch: 1/2, step 557/7134 completed (loss: 4.348371982574463, acc: 0.3120567500591278)
[2024-12-17 01:36:29,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:29,295][root][INFO] - Training Epoch: 1/2, step 558/7134 completed (loss: 4.331733226776123, acc: 0.3076923191547394)
[2024-12-17 01:36:29,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:29,569][root][INFO] - Training Epoch: 1/2, step 559/7134 completed (loss: 4.084840297698975, acc: 0.29530200362205505)
[2024-12-17 01:36:29,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:29,856][root][INFO] - Training Epoch: 1/2, step 560/7134 completed (loss: 4.705397129058838, acc: 0.22764228284358978)
[2024-12-17 01:36:30,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:30,201][root][INFO] - Training Epoch: 1/2, step 561/7134 completed (loss: 3.947362184524536, acc: 0.34375)
[2024-12-17 01:36:30,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:30,468][root][INFO] - Training Epoch: 1/2, step 562/7134 completed (loss: 4.213995456695557, acc: 0.30519479513168335)
[2024-12-17 01:36:30,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:30,752][root][INFO] - Training Epoch: 1/2, step 563/7134 completed (loss: 4.985687732696533, acc: 0.24475523829460144)
[2024-12-17 01:36:30,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:31,093][root][INFO] - Training Epoch: 1/2, step 564/7134 completed (loss: 4.044521808624268, acc: 0.3333333432674408)
[2024-12-17 01:36:31,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:31,410][root][INFO] - Training Epoch: 1/2, step 565/7134 completed (loss: 4.168484210968018, acc: 0.3385826647281647)
[2024-12-17 01:36:31,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:31,682][root][INFO] - Training Epoch: 1/2, step 566/7134 completed (loss: 4.3459086418151855, acc: 0.2432432472705841)
[2024-12-17 01:36:31,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:31,987][root][INFO] - Training Epoch: 1/2, step 567/7134 completed (loss: 4.614759922027588, acc: 0.2514970004558563)
[2024-12-17 01:36:32,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:32,261][root][INFO] - Training Epoch: 1/2, step 568/7134 completed (loss: 3.9059736728668213, acc: 0.3210526406764984)
[2024-12-17 01:36:32,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:32,560][root][INFO] - Training Epoch: 1/2, step 569/7134 completed (loss: 4.291144371032715, acc: 0.29608938097953796)
[2024-12-17 01:36:32,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:32,857][root][INFO] - Training Epoch: 1/2, step 570/7134 completed (loss: 4.225658893585205, acc: 0.3383084535598755)
[2024-12-17 01:36:32,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:33,140][root][INFO] - Training Epoch: 1/2, step 571/7134 completed (loss: 4.3945536613464355, acc: 0.24175824224948883)
[2024-12-17 01:36:33,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:33,404][root][INFO] - Training Epoch: 1/2, step 572/7134 completed (loss: 3.993870258331299, acc: 0.35428571701049805)
[2024-12-17 01:36:33,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:33,680][root][INFO] - Training Epoch: 1/2, step 573/7134 completed (loss: 4.286540985107422, acc: 0.2666666805744171)
[2024-12-17 01:36:33,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:33,945][root][INFO] - Training Epoch: 1/2, step 574/7134 completed (loss: 4.259321212768555, acc: 0.2544378638267517)
[2024-12-17 01:36:34,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:34,282][root][INFO] - Training Epoch: 1/2, step 575/7134 completed (loss: 4.275036334991455, acc: 0.27485379576683044)
[2024-12-17 01:36:34,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:34,568][root][INFO] - Training Epoch: 1/2, step 576/7134 completed (loss: 4.355378150939941, acc: 0.2634408473968506)
[2024-12-17 01:36:34,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:34,843][root][INFO] - Training Epoch: 1/2, step 577/7134 completed (loss: 4.6732563972473145, acc: 0.2181818187236786)
[2024-12-17 01:36:34,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:35,174][root][INFO] - Training Epoch: 1/2, step 578/7134 completed (loss: 4.040635585784912, acc: 0.31840795278549194)
[2024-12-17 01:36:35,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:35,453][root][INFO] - Training Epoch: 1/2, step 579/7134 completed (loss: 3.9510958194732666, acc: 0.35483869910240173)
[2024-12-17 01:36:35,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:35,784][root][INFO] - Training Epoch: 1/2, step 580/7134 completed (loss: 4.695462226867676, acc: 0.27222222089767456)
[2024-12-17 01:36:35,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:36,041][root][INFO] - Training Epoch: 1/2, step 581/7134 completed (loss: 4.240555763244629, acc: 0.2565789520740509)
[2024-12-17 01:36:36,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:36,325][root][INFO] - Training Epoch: 1/2, step 582/7134 completed (loss: 4.2654523849487305, acc: 0.2771739065647125)
[2024-12-17 01:36:36,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:36,617][root][INFO] - Training Epoch: 1/2, step 583/7134 completed (loss: 4.6191487312316895, acc: 0.257485032081604)
[2024-12-17 01:36:36,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:36,938][root][INFO] - Training Epoch: 1/2, step 584/7134 completed (loss: 3.8969273567199707, acc: 0.26229506731033325)
[2024-12-17 01:36:37,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:37,214][root][INFO] - Training Epoch: 1/2, step 585/7134 completed (loss: 3.978902578353882, acc: 0.2918919026851654)
[2024-12-17 01:36:37,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:37,492][root][INFO] - Training Epoch: 1/2, step 586/7134 completed (loss: 3.963141918182373, acc: 0.2978723347187042)
[2024-12-17 01:36:37,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:37,796][root][INFO] - Training Epoch: 1/2, step 587/7134 completed (loss: 4.222538471221924, acc: 0.31491711735725403)
[2024-12-17 01:36:37,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:38,079][root][INFO] - Training Epoch: 1/2, step 588/7134 completed (loss: 4.169773101806641, acc: 0.2567567527294159)
[2024-12-17 01:36:38,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:38,363][root][INFO] - Training Epoch: 1/2, step 589/7134 completed (loss: 4.598511695861816, acc: 0.21472392976284027)
[2024-12-17 01:36:38,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:38,646][root][INFO] - Training Epoch: 1/2, step 590/7134 completed (loss: 4.141364097595215, acc: 0.2781457006931305)
[2024-12-17 01:36:38,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:38,919][root][INFO] - Training Epoch: 1/2, step 591/7134 completed (loss: 4.005525588989258, acc: 0.24858756363391876)
[2024-12-17 01:36:39,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:39,216][root][INFO] - Training Epoch: 1/2, step 592/7134 completed (loss: 3.9455983638763428, acc: 0.2556818127632141)
[2024-12-17 01:36:39,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:39,494][root][INFO] - Training Epoch: 1/2, step 593/7134 completed (loss: 3.9552595615386963, acc: 0.28070175647735596)
[2024-12-17 01:36:39,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:39,779][root][INFO] - Training Epoch: 1/2, step 594/7134 completed (loss: 4.014658451080322, acc: 0.23353293538093567)
[2024-12-17 01:36:39,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:40,075][root][INFO] - Training Epoch: 1/2, step 595/7134 completed (loss: 3.7209010124206543, acc: 0.3494623601436615)
[2024-12-17 01:36:40,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:40,383][root][INFO] - Training Epoch: 1/2, step 596/7134 completed (loss: 4.169107913970947, acc: 0.30000001192092896)
[2024-12-17 01:36:40,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:40,670][root][INFO] - Training Epoch: 1/2, step 597/7134 completed (loss: 4.035433769226074, acc: 0.25139665603637695)
[2024-12-17 01:36:40,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:40,948][root][INFO] - Training Epoch: 1/2, step 598/7134 completed (loss: 4.486448764801025, acc: 0.2771739065647125)
[2024-12-17 01:36:41,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:41,268][root][INFO] - Training Epoch: 1/2, step 599/7134 completed (loss: 3.8263888359069824, acc: 0.29032257199287415)
[2024-12-17 01:36:41,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:41,547][root][INFO] - Training Epoch: 1/2, step 600/7134 completed (loss: 4.301900386810303, acc: 0.30054643750190735)
[2024-12-17 01:36:41,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:41,859][root][INFO] - Training Epoch: 1/2, step 601/7134 completed (loss: 4.394749641418457, acc: 0.3011363744735718)
[2024-12-17 01:36:41,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:42,134][root][INFO] - Training Epoch: 1/2, step 602/7134 completed (loss: 3.9132533073425293, acc: 0.31351351737976074)
[2024-12-17 01:36:42,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:42,414][root][INFO] - Training Epoch: 1/2, step 603/7134 completed (loss: 4.351617336273193, acc: 0.28042328357696533)
[2024-12-17 01:36:42,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:42,691][root][INFO] - Training Epoch: 1/2, step 604/7134 completed (loss: 4.224445343017578, acc: 0.290909081697464)
[2024-12-17 01:36:42,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:43,037][root][INFO] - Training Epoch: 1/2, step 605/7134 completed (loss: 4.073996543884277, acc: 0.2513369023799896)
[2024-12-17 01:36:43,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:43,315][root][INFO] - Training Epoch: 1/2, step 606/7134 completed (loss: 4.215432167053223, acc: 0.26499998569488525)
[2024-12-17 01:36:43,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:43,595][root][INFO] - Training Epoch: 1/2, step 607/7134 completed (loss: 3.73832368850708, acc: 0.29885056614875793)
[2024-12-17 01:36:43,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:43,946][root][INFO] - Training Epoch: 1/2, step 608/7134 completed (loss: 4.624691963195801, acc: 0.2432432472705841)
[2024-12-17 01:36:44,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:44,237][root][INFO] - Training Epoch: 1/2, step 609/7134 completed (loss: 4.172555923461914, acc: 0.3282051384449005)
[2024-12-17 01:36:44,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:44,518][root][INFO] - Training Epoch: 1/2, step 610/7134 completed (loss: 4.246294021606445, acc: 0.27586206793785095)
[2024-12-17 01:36:44,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:44,811][root][INFO] - Training Epoch: 1/2, step 611/7134 completed (loss: 4.251058578491211, acc: 0.3163841664791107)
[2024-12-17 01:36:44,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:45,134][root][INFO] - Training Epoch: 1/2, step 612/7134 completed (loss: 4.222979545593262, acc: 0.31521740555763245)
[2024-12-17 01:36:45,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:45,432][root][INFO] - Training Epoch: 1/2, step 613/7134 completed (loss: 4.473731994628906, acc: 0.28787878155708313)
[2024-12-17 01:36:45,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:45,705][root][INFO] - Training Epoch: 1/2, step 614/7134 completed (loss: 4.267845153808594, acc: 0.239130437374115)
[2024-12-17 01:36:45,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:45,988][root][INFO] - Training Epoch: 1/2, step 615/7134 completed (loss: 3.757112503051758, acc: 0.3210526406764984)
[2024-12-17 01:36:46,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:46,273][root][INFO] - Training Epoch: 1/2, step 616/7134 completed (loss: 4.40918493270874, acc: 0.28110599517822266)
[2024-12-17 01:36:46,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:46,549][root][INFO] - Training Epoch: 1/2, step 617/7134 completed (loss: 4.199954986572266, acc: 0.2918660342693329)
[2024-12-17 01:36:46,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:46,815][root][INFO] - Training Epoch: 1/2, step 618/7134 completed (loss: 4.357671737670898, acc: 0.22994652390480042)
[2024-12-17 01:36:46,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:47,088][root][INFO] - Training Epoch: 1/2, step 619/7134 completed (loss: 4.871264934539795, acc: 0.22131147980690002)
[2024-12-17 01:36:47,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:47,378][root][INFO] - Training Epoch: 1/2, step 620/7134 completed (loss: 4.383541107177734, acc: 0.267123281955719)
[2024-12-17 01:36:47,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:47,662][root][INFO] - Training Epoch: 1/2, step 621/7134 completed (loss: 3.885161876678467, acc: 0.36666667461395264)
[2024-12-17 01:36:47,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:47,940][root][INFO] - Training Epoch: 1/2, step 622/7134 completed (loss: 3.9999828338623047, acc: 0.30921053886413574)
[2024-12-17 01:36:48,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:48,272][root][INFO] - Training Epoch: 1/2, step 623/7134 completed (loss: 3.7395009994506836, acc: 0.3093525171279907)
[2024-12-17 01:36:48,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:48,549][root][INFO] - Training Epoch: 1/2, step 624/7134 completed (loss: 4.014217853546143, acc: 0.30656933784484863)
[2024-12-17 01:36:48,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:48,830][root][INFO] - Training Epoch: 1/2, step 625/7134 completed (loss: 3.735539197921753, acc: 0.3187499940395355)
[2024-12-17 01:36:48,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:49,130][root][INFO] - Training Epoch: 1/2, step 626/7134 completed (loss: 4.102991104125977, acc: 0.30399999022483826)
[2024-12-17 01:36:49,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:49,409][root][INFO] - Training Epoch: 1/2, step 627/7134 completed (loss: 3.931182622909546, acc: 0.2857142984867096)
[2024-12-17 01:36:49,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:49,676][root][INFO] - Training Epoch: 1/2, step 628/7134 completed (loss: 4.171445369720459, acc: 0.25850340723991394)
[2024-12-17 01:36:49,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:49,952][root][INFO] - Training Epoch: 1/2, step 629/7134 completed (loss: 3.9929890632629395, acc: 0.3617021143436432)
[2024-12-17 01:36:50,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:50,263][root][INFO] - Training Epoch: 1/2, step 630/7134 completed (loss: 4.193820953369141, acc: 0.3248407542705536)
[2024-12-17 01:36:50,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:50,565][root][INFO] - Training Epoch: 1/2, step 631/7134 completed (loss: 4.266610622406006, acc: 0.2467532455921173)
[2024-12-17 01:36:50,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:50,855][root][INFO] - Training Epoch: 1/2, step 632/7134 completed (loss: 4.004004955291748, acc: 0.28169015049934387)
[2024-12-17 01:36:50,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:51,152][root][INFO] - Training Epoch: 1/2, step 633/7134 completed (loss: 4.251517295837402, acc: 0.28125)
[2024-12-17 01:36:51,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:51,488][root][INFO] - Training Epoch: 1/2, step 634/7134 completed (loss: 3.8610129356384277, acc: 0.350649356842041)
[2024-12-17 01:36:51,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:51,775][root][INFO] - Training Epoch: 1/2, step 635/7134 completed (loss: 4.042141437530518, acc: 0.3246753215789795)
[2024-12-17 01:36:51,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:52,053][root][INFO] - Training Epoch: 1/2, step 636/7134 completed (loss: 4.108728408813477, acc: 0.2934131622314453)
[2024-12-17 01:36:52,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:52,324][root][INFO] - Training Epoch: 1/2, step 637/7134 completed (loss: 3.815641403198242, acc: 0.28776979446411133)
[2024-12-17 01:36:52,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:52,619][root][INFO] - Training Epoch: 1/2, step 638/7134 completed (loss: 4.311111927032471, acc: 0.24161073565483093)
[2024-12-17 01:36:52,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:52,895][root][INFO] - Training Epoch: 1/2, step 639/7134 completed (loss: 4.006084442138672, acc: 0.33571428060531616)
[2024-12-17 01:36:53,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:53,161][root][INFO] - Training Epoch: 1/2, step 640/7134 completed (loss: 4.1656341552734375, acc: 0.24637681245803833)
[2024-12-17 01:36:53,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:53,419][root][INFO] - Training Epoch: 1/2, step 641/7134 completed (loss: 4.089202404022217, acc: 0.26811593770980835)
[2024-12-17 01:36:53,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:53,710][root][INFO] - Training Epoch: 1/2, step 642/7134 completed (loss: 4.087864875793457, acc: 0.30882352590560913)
[2024-12-17 01:36:53,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:53,994][root][INFO] - Training Epoch: 1/2, step 643/7134 completed (loss: 3.6201412677764893, acc: 0.3314606845378876)
[2024-12-17 01:36:54,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:54,319][root][INFO] - Training Epoch: 1/2, step 644/7134 completed (loss: 3.9749367237091064, acc: 0.2890625)
[2024-12-17 01:36:54,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:54,593][root][INFO] - Training Epoch: 1/2, step 645/7134 completed (loss: 3.8787951469421387, acc: 0.3448275923728943)
[2024-12-17 01:36:54,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:54,889][root][INFO] - Training Epoch: 1/2, step 646/7134 completed (loss: 3.961527109146118, acc: 0.2278480976819992)
[2024-12-17 01:36:55,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:55,197][root][INFO] - Training Epoch: 1/2, step 647/7134 completed (loss: 4.241234302520752, acc: 0.27407407760620117)
[2024-12-17 01:36:55,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:55,496][root][INFO] - Training Epoch: 1/2, step 648/7134 completed (loss: 5.062545299530029, acc: 0.23846153914928436)
[2024-12-17 01:36:55,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:55,808][root][INFO] - Training Epoch: 1/2, step 649/7134 completed (loss: 4.597182273864746, acc: 0.26486486196517944)
[2024-12-17 01:36:55,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:56,082][root][INFO] - Training Epoch: 1/2, step 650/7134 completed (loss: 4.993349075317383, acc: 0.21917808055877686)
[2024-12-17 01:36:56,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:56,361][root][INFO] - Training Epoch: 1/2, step 651/7134 completed (loss: 4.907560348510742, acc: 0.23376622796058655)
[2024-12-17 01:36:56,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:56,641][root][INFO] - Training Epoch: 1/2, step 652/7134 completed (loss: 4.876181125640869, acc: 0.2112676054239273)
[2024-12-17 01:36:56,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:56,913][root][INFO] - Training Epoch: 1/2, step 653/7134 completed (loss: 4.437090873718262, acc: 0.2242424190044403)
[2024-12-17 01:36:57,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:57,213][root][INFO] - Training Epoch: 1/2, step 654/7134 completed (loss: 4.032927513122559, acc: 0.308270663022995)
[2024-12-17 01:36:57,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:57,562][root][INFO] - Training Epoch: 1/2, step 655/7134 completed (loss: 5.173319339752197, acc: 0.16379310190677643)
[2024-12-17 01:36:57,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:57,855][root][INFO] - Training Epoch: 1/2, step 656/7134 completed (loss: 4.797652244567871, acc: 0.2222222238779068)
[2024-12-17 01:36:57,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:58,133][root][INFO] - Training Epoch: 1/2, step 657/7134 completed (loss: 5.197968006134033, acc: 0.19718310236930847)
[2024-12-17 01:36:58,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:58,411][root][INFO] - Training Epoch: 1/2, step 658/7134 completed (loss: 4.04831075668335, acc: 0.26553672552108765)
[2024-12-17 01:36:58,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:58,690][root][INFO] - Training Epoch: 1/2, step 659/7134 completed (loss: 3.6814403533935547, acc: 0.28742516040802)
[2024-12-17 01:36:58,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:58,970][root][INFO] - Training Epoch: 1/2, step 660/7134 completed (loss: 4.123387336730957, acc: 0.2647058963775635)
[2024-12-17 01:36:59,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:59,256][root][INFO] - Training Epoch: 1/2, step 661/7134 completed (loss: 3.7784440517425537, acc: 0.2711864411830902)
[2024-12-17 01:36:59,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:59,558][root][INFO] - Training Epoch: 1/2, step 662/7134 completed (loss: 3.8786706924438477, acc: 0.25)
[2024-12-17 01:36:59,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:59,883][root][INFO] - Training Epoch: 1/2, step 663/7134 completed (loss: 4.470844268798828, acc: 0.24271844327449799)
[2024-12-17 01:36:59,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:00,156][root][INFO] - Training Epoch: 1/2, step 664/7134 completed (loss: 4.437105178833008, acc: 0.279720276594162)
[2024-12-17 01:37:00,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:00,421][root][INFO] - Training Epoch: 1/2, step 665/7134 completed (loss: 4.076709747314453, acc: 0.28961747884750366)
[2024-12-17 01:37:00,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:00,708][root][INFO] - Training Epoch: 1/2, step 666/7134 completed (loss: 4.5777788162231445, acc: 0.20571428537368774)
[2024-12-17 01:37:00,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:00,994][root][INFO] - Training Epoch: 1/2, step 667/7134 completed (loss: 4.56893253326416, acc: 0.20359280705451965)
[2024-12-17 01:37:01,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:01,261][root][INFO] - Training Epoch: 1/2, step 668/7134 completed (loss: 3.9942963123321533, acc: 0.2568306028842926)
[2024-12-17 01:37:01,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:01,546][root][INFO] - Training Epoch: 1/2, step 669/7134 completed (loss: 3.95805287361145, acc: 0.2849161922931671)
[2024-12-17 01:37:01,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:01,840][root][INFO] - Training Epoch: 1/2, step 670/7134 completed (loss: 4.0316386222839355, acc: 0.29680365324020386)
[2024-12-17 01:37:01,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:02,133][root][INFO] - Training Epoch: 1/2, step 671/7134 completed (loss: 4.234315872192383, acc: 0.2850678861141205)
[2024-12-17 01:37:02,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:02,407][root][INFO] - Training Epoch: 1/2, step 672/7134 completed (loss: 4.140000343322754, acc: 0.22499999403953552)
[2024-12-17 01:37:02,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:02,692][root][INFO] - Training Epoch: 1/2, step 673/7134 completed (loss: 4.359990119934082, acc: 0.23383083939552307)
[2024-12-17 01:37:02,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:02,970][root][INFO] - Training Epoch: 1/2, step 674/7134 completed (loss: 3.5889475345611572, acc: 0.3109756112098694)
[2024-12-17 01:37:03,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:03,249][root][INFO] - Training Epoch: 1/2, step 675/7134 completed (loss: 3.7707087993621826, acc: 0.3535911738872528)
[2024-12-17 01:37:03,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:03,526][root][INFO] - Training Epoch: 1/2, step 676/7134 completed (loss: 4.194619655609131, acc: 0.239130437374115)
[2024-12-17 01:37:03,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:03,811][root][INFO] - Training Epoch: 1/2, step 677/7134 completed (loss: 3.7456154823303223, acc: 0.32275131344795227)
[2024-12-17 01:37:03,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:04,095][root][INFO] - Training Epoch: 1/2, step 678/7134 completed (loss: 3.8443775177001953, acc: 0.25)
[2024-12-17 01:37:04,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:04,358][root][INFO] - Training Epoch: 1/2, step 679/7134 completed (loss: 3.9963438510894775, acc: 0.31578946113586426)
[2024-12-17 01:37:04,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:04,641][root][INFO] - Training Epoch: 1/2, step 680/7134 completed (loss: 3.952585220336914, acc: 0.28140702843666077)
[2024-12-17 01:37:04,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:04,947][root][INFO] - Training Epoch: 1/2, step 681/7134 completed (loss: 3.6363580226898193, acc: 0.34210526943206787)
[2024-12-17 01:37:05,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:05,238][root][INFO] - Training Epoch: 1/2, step 682/7134 completed (loss: 3.6644446849823, acc: 0.3333333432674408)
[2024-12-17 01:37:05,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:05,555][root][INFO] - Training Epoch: 1/2, step 683/7134 completed (loss: 4.069681167602539, acc: 0.2594594657421112)
[2024-12-17 01:37:05,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:05,912][root][INFO] - Training Epoch: 1/2, step 684/7134 completed (loss: 4.0140604972839355, acc: 0.3611111044883728)
[2024-12-17 01:37:06,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:06,193][root][INFO] - Training Epoch: 1/2, step 685/7134 completed (loss: 4.033010005950928, acc: 0.31658291816711426)
[2024-12-17 01:37:06,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:06,475][root][INFO] - Training Epoch: 1/2, step 686/7134 completed (loss: 3.684659719467163, acc: 0.3224043846130371)
[2024-12-17 01:37:06,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:06,761][root][INFO] - Training Epoch: 1/2, step 687/7134 completed (loss: 4.440501689910889, acc: 0.26771652698516846)
[2024-12-17 01:37:06,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:07,093][root][INFO] - Training Epoch: 1/2, step 688/7134 completed (loss: 3.6616764068603516, acc: 0.2848101258277893)
[2024-12-17 01:37:07,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:07,393][root][INFO] - Training Epoch: 1/2, step 689/7134 completed (loss: 4.302978038787842, acc: 0.27407407760620117)
[2024-12-17 01:37:07,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:07,744][root][INFO] - Training Epoch: 1/2, step 690/7134 completed (loss: 3.8309035301208496, acc: 0.3290322721004486)
[2024-12-17 01:37:07,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:08,056][root][INFO] - Training Epoch: 1/2, step 691/7134 completed (loss: 4.9165873527526855, acc: 0.22727273404598236)
[2024-12-17 01:37:08,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:08,361][root][INFO] - Training Epoch: 1/2, step 692/7134 completed (loss: 4.074245929718018, acc: 0.2588832378387451)
[2024-12-17 01:37:08,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:08,683][root][INFO] - Training Epoch: 1/2, step 693/7134 completed (loss: 4.301057815551758, acc: 0.25531914830207825)
[2024-12-17 01:37:08,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:08,992][root][INFO] - Training Epoch: 1/2, step 694/7134 completed (loss: 4.447648525238037, acc: 0.2545454502105713)
[2024-12-17 01:37:09,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:09,326][root][INFO] - Training Epoch: 1/2, step 695/7134 completed (loss: 4.813479423522949, acc: 0.2761194109916687)
[2024-12-17 01:37:09,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:09,672][root][INFO] - Training Epoch: 1/2, step 696/7134 completed (loss: 4.648046493530273, acc: 0.30188679695129395)
[2024-12-17 01:37:09,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:09,971][root][INFO] - Training Epoch: 1/2, step 697/7134 completed (loss: 3.9863884449005127, acc: 0.32608696818351746)
[2024-12-17 01:37:10,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:10,283][root][INFO] - Training Epoch: 1/2, step 698/7134 completed (loss: 4.409409999847412, acc: 0.21969696879386902)
[2024-12-17 01:37:10,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:10,599][root][INFO] - Training Epoch: 1/2, step 699/7134 completed (loss: 4.412783145904541, acc: 0.25342464447021484)
[2024-12-17 01:37:10,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:10,895][root][INFO] - Training Epoch: 1/2, step 700/7134 completed (loss: 4.332146644592285, acc: 0.2879999876022339)
[2024-12-17 01:37:11,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:11,173][root][INFO] - Training Epoch: 1/2, step 701/7134 completed (loss: 4.93927001953125, acc: 0.22608695924282074)
[2024-12-17 01:37:11,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:11,528][root][INFO] - Training Epoch: 1/2, step 702/7134 completed (loss: 4.6078104972839355, acc: 0.26490065455436707)
[2024-12-17 01:37:11,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:11,821][root][INFO] - Training Epoch: 1/2, step 703/7134 completed (loss: 4.98563814163208, acc: 0.25)
[2024-12-17 01:37:11,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:12,104][root][INFO] - Training Epoch: 1/2, step 704/7134 completed (loss: 4.234520435333252, acc: 0.26623377203941345)
[2024-12-17 01:37:12,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:12,464][root][INFO] - Training Epoch: 1/2, step 705/7134 completed (loss: 3.8049561977386475, acc: 0.33944955468177795)
[2024-12-17 01:37:12,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:12,749][root][INFO] - Training Epoch: 1/2, step 706/7134 completed (loss: 3.8851962089538574, acc: 0.3207547068595886)
[2024-12-17 01:37:12,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:13,032][root][INFO] - Training Epoch: 1/2, step 707/7134 completed (loss: 4.105090141296387, acc: 0.26237624883651733)
[2024-12-17 01:37:13,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:13,321][root][INFO] - Training Epoch: 1/2, step 708/7134 completed (loss: 4.355936527252197, acc: 0.2584269642829895)
[2024-12-17 01:37:13,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:13,600][root][INFO] - Training Epoch: 1/2, step 709/7134 completed (loss: 3.7623183727264404, acc: 0.33714285492897034)
[2024-12-17 01:37:13,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:13,895][root][INFO] - Training Epoch: 1/2, step 710/7134 completed (loss: 4.108224868774414, acc: 0.2864583432674408)
[2024-12-17 01:37:14,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:14,178][root][INFO] - Training Epoch: 1/2, step 711/7134 completed (loss: 4.041086673736572, acc: 0.2450980395078659)
[2024-12-17 01:37:14,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:14,450][root][INFO] - Training Epoch: 1/2, step 712/7134 completed (loss: 3.8018739223480225, acc: 0.3229166567325592)
[2024-12-17 01:37:14,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:14,733][root][INFO] - Training Epoch: 1/2, step 713/7134 completed (loss: 3.824293375015259, acc: 0.2964824140071869)
[2024-12-17 01:37:14,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:15,011][root][INFO] - Training Epoch: 1/2, step 714/7134 completed (loss: 4.335023880004883, acc: 0.27000001072883606)
[2024-12-17 01:37:15,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:15,309][root][INFO] - Training Epoch: 1/2, step 715/7134 completed (loss: 3.6917121410369873, acc: 0.28804346919059753)
[2024-12-17 01:37:15,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:15,603][root][INFO] - Training Epoch: 1/2, step 716/7134 completed (loss: 3.529137134552002, acc: 0.3186274468898773)
[2024-12-17 01:37:15,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:15,876][root][INFO] - Training Epoch: 1/2, step 717/7134 completed (loss: 3.809077024459839, acc: 0.32085561752319336)
[2024-12-17 01:37:16,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:16,168][root][INFO] - Training Epoch: 1/2, step 718/7134 completed (loss: 3.9850451946258545, acc: 0.26455026865005493)
[2024-12-17 01:37:16,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:16,435][root][INFO] - Training Epoch: 1/2, step 719/7134 completed (loss: 3.4614808559417725, acc: 0.3120567500591278)
[2024-12-17 01:37:16,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:16,728][root][INFO] - Training Epoch: 1/2, step 720/7134 completed (loss: 3.7372848987579346, acc: 0.2918919026851654)
[2024-12-17 01:37:16,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:17,013][root][INFO] - Training Epoch: 1/2, step 721/7134 completed (loss: 3.7397985458374023, acc: 0.27368420362472534)
[2024-12-17 01:37:17,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:17,346][root][INFO] - Training Epoch: 1/2, step 722/7134 completed (loss: 4.065582752227783, acc: 0.25757575035095215)
[2024-12-17 01:37:17,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:17,625][root][INFO] - Training Epoch: 1/2, step 723/7134 completed (loss: 3.7971913814544678, acc: 0.30978259444236755)
[2024-12-17 01:37:17,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:17,929][root][INFO] - Training Epoch: 1/2, step 724/7134 completed (loss: 4.201539516448975, acc: 0.23270440101623535)
[2024-12-17 01:37:18,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:18,213][root][INFO] - Training Epoch: 1/2, step 725/7134 completed (loss: 3.5018539428710938, acc: 0.3095238208770752)
[2024-12-17 01:37:18,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:18,498][root][INFO] - Training Epoch: 1/2, step 726/7134 completed (loss: 3.1070566177368164, acc: 0.33519554138183594)
[2024-12-17 01:37:18,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:18,784][root][INFO] - Training Epoch: 1/2, step 727/7134 completed (loss: 3.4827094078063965, acc: 0.27167630195617676)
[2024-12-17 01:37:18,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:19,097][root][INFO] - Training Epoch: 1/2, step 728/7134 completed (loss: 3.807278633117676, acc: 0.2742857038974762)
[2024-12-17 01:37:19,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:19,410][root][INFO] - Training Epoch: 1/2, step 729/7134 completed (loss: 3.4291837215423584, acc: 0.33544304966926575)
[2024-12-17 01:37:19,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:19,739][root][INFO] - Training Epoch: 1/2, step 730/7134 completed (loss: 3.221313714981079, acc: 0.31382977962493896)
[2024-12-17 01:37:19,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:20,021][root][INFO] - Training Epoch: 1/2, step 731/7134 completed (loss: 3.216557264328003, acc: 0.33898305892944336)
[2024-12-17 01:37:20,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:20,306][root][INFO] - Training Epoch: 1/2, step 732/7134 completed (loss: 3.9857842922210693, acc: 0.32786884903907776)
[2024-12-17 01:37:20,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:20,612][root][INFO] - Training Epoch: 1/2, step 733/7134 completed (loss: 4.339397430419922, acc: 0.23076923191547394)
[2024-12-17 01:37:20,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:20,899][root][INFO] - Training Epoch: 1/2, step 734/7134 completed (loss: 4.248515605926514, acc: 0.29032257199287415)
[2024-12-17 01:37:21,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:21,190][root][INFO] - Training Epoch: 1/2, step 735/7134 completed (loss: 4.1555867195129395, acc: 0.27464789152145386)
[2024-12-17 01:37:21,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:21,471][root][INFO] - Training Epoch: 1/2, step 736/7134 completed (loss: 4.239302158355713, acc: 0.30693069100379944)
[2024-12-17 01:37:21,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:21,759][root][INFO] - Training Epoch: 1/2, step 737/7134 completed (loss: 3.9160890579223633, acc: 0.33898305892944336)
[2024-12-17 01:37:21,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:22,036][root][INFO] - Training Epoch: 1/2, step 738/7134 completed (loss: 4.728183269500732, acc: 0.19811320304870605)
[2024-12-17 01:37:22,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:22,324][root][INFO] - Training Epoch: 1/2, step 739/7134 completed (loss: 4.629096984863281, acc: 0.208695650100708)
[2024-12-17 01:37:22,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:22,588][root][INFO] - Training Epoch: 1/2, step 740/7134 completed (loss: 3.858275890350342, acc: 0.3983739912509918)
[2024-12-17 01:37:22,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:22,879][root][INFO] - Training Epoch: 1/2, step 741/7134 completed (loss: 3.965282678604126, acc: 0.2666666805744171)
[2024-12-17 01:37:23,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:23,146][root][INFO] - Training Epoch: 1/2, step 742/7134 completed (loss: 4.251732349395752, acc: 0.28421053290367126)
[2024-12-17 01:37:23,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:23,469][root][INFO] - Training Epoch: 1/2, step 743/7134 completed (loss: 3.9719130992889404, acc: 0.2789115607738495)
[2024-12-17 01:37:23,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:23,755][root][INFO] - Training Epoch: 1/2, step 744/7134 completed (loss: 4.154210090637207, acc: 0.25999999046325684)
[2024-12-17 01:37:23,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:24,083][root][INFO] - Training Epoch: 1/2, step 745/7134 completed (loss: 3.627155303955078, acc: 0.2720588147640228)
[2024-12-17 01:37:24,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:24,410][root][INFO] - Training Epoch: 1/2, step 746/7134 completed (loss: 4.29039192199707, acc: 0.28244274854660034)
[2024-12-17 01:37:24,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:24,720][root][INFO] - Training Epoch: 1/2, step 747/7134 completed (loss: 4.1025495529174805, acc: 0.32283464074134827)
[2024-12-17 01:37:24,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:25,023][root][INFO] - Training Epoch: 1/2, step 748/7134 completed (loss: 4.0127973556518555, acc: 0.31343284249305725)
[2024-12-17 01:37:25,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:25,317][root][INFO] - Training Epoch: 1/2, step 749/7134 completed (loss: 3.7540392875671387, acc: 0.3214285671710968)
[2024-12-17 01:37:25,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:25,660][root][INFO] - Training Epoch: 1/2, step 750/7134 completed (loss: 4.350711345672607, acc: 0.28925618529319763)
[2024-12-17 01:37:25,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:25,934][root][INFO] - Training Epoch: 1/2, step 751/7134 completed (loss: 4.820291996002197, acc: 0.24799999594688416)
[2024-12-17 01:37:26,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:26,201][root][INFO] - Training Epoch: 1/2, step 752/7134 completed (loss: 4.442368507385254, acc: 0.3243243098258972)
[2024-12-17 01:37:26,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:26,475][root][INFO] - Training Epoch: 1/2, step 753/7134 completed (loss: 4.128832817077637, acc: 0.2890625)
[2024-12-17 01:37:26,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:26,763][root][INFO] - Training Epoch: 1/2, step 754/7134 completed (loss: 3.551347255706787, acc: 0.41304346919059753)
[2024-12-17 01:37:26,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:27,094][root][INFO] - Training Epoch: 1/2, step 755/7134 completed (loss: 4.262503623962402, acc: 0.2879999876022339)
[2024-12-17 01:37:27,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:27,378][root][INFO] - Training Epoch: 1/2, step 756/7134 completed (loss: 4.4987077713012695, acc: 0.2410714328289032)
[2024-12-17 01:37:27,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:27,669][root][INFO] - Training Epoch: 1/2, step 757/7134 completed (loss: 4.563887119293213, acc: 0.17307692766189575)
[2024-12-17 01:37:27,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:27,947][root][INFO] - Training Epoch: 1/2, step 758/7134 completed (loss: 4.02117395401001, acc: 0.28828829526901245)
[2024-12-17 01:37:28,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:28,210][root][INFO] - Training Epoch: 1/2, step 759/7134 completed (loss: 4.430403232574463, acc: 0.2522522509098053)
[2024-12-17 01:37:28,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:28,473][root][INFO] - Training Epoch: 1/2, step 760/7134 completed (loss: 4.076292037963867, acc: 0.3484848439693451)
[2024-12-17 01:37:28,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:28,746][root][INFO] - Training Epoch: 1/2, step 761/7134 completed (loss: 3.724391460418701, acc: 0.31736525893211365)
[2024-12-17 01:37:28,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:29,011][root][INFO] - Training Epoch: 1/2, step 762/7134 completed (loss: 4.315991401672363, acc: 0.2971014380455017)
[2024-12-17 01:37:29,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:29,289][root][INFO] - Training Epoch: 1/2, step 763/7134 completed (loss: 4.209317207336426, acc: 0.30263158679008484)
[2024-12-17 01:37:29,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:29,585][root][INFO] - Training Epoch: 1/2, step 764/7134 completed (loss: 4.065744400024414, acc: 0.2781065106391907)
[2024-12-17 01:37:29,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:29,888][root][INFO] - Training Epoch: 1/2, step 765/7134 completed (loss: 3.7849676609039307, acc: 0.30188679695129395)
[2024-12-17 01:37:30,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:30,172][root][INFO] - Training Epoch: 1/2, step 766/7134 completed (loss: 3.813063383102417, acc: 0.26249998807907104)
[2024-12-17 01:37:30,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:30,447][root][INFO] - Training Epoch: 1/2, step 767/7134 completed (loss: 3.551687717437744, acc: 0.3333333432674408)
[2024-12-17 01:37:30,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:30,730][root][INFO] - Training Epoch: 1/2, step 768/7134 completed (loss: 3.6871588230133057, acc: 0.3060109317302704)
[2024-12-17 01:37:30,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:31,020][root][INFO] - Training Epoch: 1/2, step 769/7134 completed (loss: 4.075713634490967, acc: 0.25465837121009827)
[2024-12-17 01:37:31,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:31,294][root][INFO] - Training Epoch: 1/2, step 770/7134 completed (loss: 3.8302195072174072, acc: 0.31481480598449707)
[2024-12-17 01:37:31,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:31,606][root][INFO] - Training Epoch: 1/2, step 771/7134 completed (loss: 3.777034044265747, acc: 0.30656933784484863)
[2024-12-17 01:37:31,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:31,874][root][INFO] - Training Epoch: 1/2, step 772/7134 completed (loss: 3.6911425590515137, acc: 0.2857142984867096)
[2024-12-17 01:37:32,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:32,174][root][INFO] - Training Epoch: 1/2, step 773/7134 completed (loss: 3.7227516174316406, acc: 0.2947368323802948)
[2024-12-17 01:37:32,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:32,523][root][INFO] - Training Epoch: 1/2, step 774/7134 completed (loss: 4.4999918937683105, acc: 0.246478870511055)
[2024-12-17 01:37:32,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:32,837][root][INFO] - Training Epoch: 1/2, step 775/7134 completed (loss: 3.7188475131988525, acc: 0.30319148302078247)
[2024-12-17 01:37:32,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:33,151][root][INFO] - Training Epoch: 1/2, step 776/7134 completed (loss: 3.736481189727783, acc: 0.31847134232521057)
[2024-12-17 01:37:33,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:33,467][root][INFO] - Training Epoch: 1/2, step 777/7134 completed (loss: 3.6482133865356445, acc: 0.30666667222976685)
[2024-12-17 01:37:33,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:33,764][root][INFO] - Training Epoch: 1/2, step 778/7134 completed (loss: 4.256281852722168, acc: 0.276729553937912)
[2024-12-17 01:37:33,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:34,046][root][INFO] - Training Epoch: 1/2, step 779/7134 completed (loss: 3.8620662689208984, acc: 0.2923976480960846)
[2024-12-17 01:37:34,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:34,321][root][INFO] - Training Epoch: 1/2, step 780/7134 completed (loss: 4.037336349487305, acc: 0.3027026951313019)
[2024-12-17 01:37:34,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:34,621][root][INFO] - Training Epoch: 1/2, step 781/7134 completed (loss: 3.8810906410217285, acc: 0.28921568393707275)
[2024-12-17 01:37:34,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:34,916][root][INFO] - Training Epoch: 1/2, step 782/7134 completed (loss: 4.252452373504639, acc: 0.24683544039726257)
[2024-12-17 01:37:35,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:35,209][root][INFO] - Training Epoch: 1/2, step 783/7134 completed (loss: 3.944917678833008, acc: 0.25233644247055054)
[2024-12-17 01:37:35,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:35,507][root][INFO] - Training Epoch: 1/2, step 784/7134 completed (loss: 3.3882389068603516, acc: 0.3631840944290161)
[2024-12-17 01:37:35,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:35,798][root][INFO] - Training Epoch: 1/2, step 785/7134 completed (loss: 4.364872932434082, acc: 0.25999999046325684)
[2024-12-17 01:37:35,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:36,117][root][INFO] - Training Epoch: 1/2, step 786/7134 completed (loss: 4.2464752197265625, acc: 0.24626865983009338)
[2024-12-17 01:37:36,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:36,401][root][INFO] - Training Epoch: 1/2, step 787/7134 completed (loss: 3.892077922821045, acc: 0.29323309659957886)
[2024-12-17 01:37:36,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:36,679][root][INFO] - Training Epoch: 1/2, step 788/7134 completed (loss: 3.951502561569214, acc: 0.27374300360679626)
[2024-12-17 01:37:36,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:36,951][root][INFO] - Training Epoch: 1/2, step 789/7134 completed (loss: 4.338521480560303, acc: 0.19871795177459717)
[2024-12-17 01:37:37,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:37,226][root][INFO] - Training Epoch: 1/2, step 790/7134 completed (loss: 4.5500593185424805, acc: 0.1689189225435257)
[2024-12-17 01:37:37,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:37,555][root][INFO] - Training Epoch: 1/2, step 791/7134 completed (loss: 4.214141368865967, acc: 0.2601625919342041)
[2024-12-17 01:37:37,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:37,833][root][INFO] - Training Epoch: 1/2, step 792/7134 completed (loss: 4.047924041748047, acc: 0.3417721390724182)
[2024-12-17 01:37:37,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:38,145][root][INFO] - Training Epoch: 1/2, step 793/7134 completed (loss: 4.353135108947754, acc: 0.23125000298023224)
[2024-12-17 01:37:38,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:38,445][root][INFO] - Training Epoch: 1/2, step 794/7134 completed (loss: 4.247066497802734, acc: 0.23275862634181976)
[2024-12-17 01:37:38,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:38,740][root][INFO] - Training Epoch: 1/2, step 795/7134 completed (loss: 4.411538600921631, acc: 0.26582279801368713)
[2024-12-17 01:37:38,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:39,061][root][INFO] - Training Epoch: 1/2, step 796/7134 completed (loss: 4.371129989624023, acc: 0.24761904776096344)
[2024-12-17 01:37:39,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:39,336][root][INFO] - Training Epoch: 1/2, step 797/7134 completed (loss: 4.590806007385254, acc: 0.22834645211696625)
[2024-12-17 01:37:39,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:39,620][root][INFO] - Training Epoch: 1/2, step 798/7134 completed (loss: 4.432622909545898, acc: 0.2222222238779068)
[2024-12-17 01:37:39,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:39,906][root][INFO] - Training Epoch: 1/2, step 799/7134 completed (loss: 4.45845365524292, acc: 0.27272728085517883)
[2024-12-17 01:37:40,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:40,187][root][INFO] - Training Epoch: 1/2, step 800/7134 completed (loss: 4.087920188903809, acc: 0.27407407760620117)
[2024-12-17 01:37:40,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:40,476][root][INFO] - Training Epoch: 1/2, step 801/7134 completed (loss: 4.743298053741455, acc: 0.19354838132858276)
[2024-12-17 01:37:40,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:40,755][root][INFO] - Training Epoch: 1/2, step 802/7134 completed (loss: 4.368887424468994, acc: 0.26950353384017944)
[2024-12-17 01:37:40,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:41,029][root][INFO] - Training Epoch: 1/2, step 803/7134 completed (loss: 4.1942138671875, acc: 0.23188406229019165)
[2024-12-17 01:37:41,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:41,331][root][INFO] - Training Epoch: 1/2, step 804/7134 completed (loss: 4.161407947540283, acc: 0.27906978130340576)
[2024-12-17 01:37:41,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:41,609][root][INFO] - Training Epoch: 1/2, step 805/7134 completed (loss: 4.409234523773193, acc: 0.3076923191547394)
[2024-12-17 01:37:41,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:41,905][root][INFO] - Training Epoch: 1/2, step 806/7134 completed (loss: 3.540722608566284, acc: 0.32098764181137085)
[2024-12-17 01:37:42,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:42,274][root][INFO] - Training Epoch: 1/2, step 807/7134 completed (loss: 4.011443614959717, acc: 0.29499998688697815)
[2024-12-17 01:37:42,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:42,544][root][INFO] - Training Epoch: 1/2, step 808/7134 completed (loss: 3.8665175437927246, acc: 0.29441624879837036)
[2024-12-17 01:37:42,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:42,825][root][INFO] - Training Epoch: 1/2, step 809/7134 completed (loss: 3.9804117679595947, acc: 0.273333340883255)
[2024-12-17 01:37:42,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:43,108][root][INFO] - Training Epoch: 1/2, step 810/7134 completed (loss: 3.8088185787200928, acc: 0.2857142984867096)
[2024-12-17 01:37:43,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:43,381][root][INFO] - Training Epoch: 1/2, step 811/7134 completed (loss: 3.797898769378662, acc: 0.35862070322036743)
[2024-12-17 01:37:43,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:43,650][root][INFO] - Training Epoch: 1/2, step 812/7134 completed (loss: 4.077139854431152, acc: 0.33157894015312195)
[2024-12-17 01:37:43,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:43,981][root][INFO] - Training Epoch: 1/2, step 813/7134 completed (loss: 3.8178858757019043, acc: 0.30000001192092896)
[2024-12-17 01:37:44,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:44,331][root][INFO] - Training Epoch: 1/2, step 814/7134 completed (loss: 4.0642008781433105, acc: 0.2711864411830902)
[2024-12-17 01:37:44,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:44,629][root][INFO] - Training Epoch: 1/2, step 815/7134 completed (loss: 3.967012882232666, acc: 0.3461538553237915)
[2024-12-17 01:37:44,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:44,937][root][INFO] - Training Epoch: 1/2, step 816/7134 completed (loss: 4.593269348144531, acc: 0.1843971610069275)
[2024-12-17 01:37:45,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:45,247][root][INFO] - Training Epoch: 1/2, step 817/7134 completed (loss: 4.593469619750977, acc: 0.2589927911758423)
[2024-12-17 01:37:45,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:45,586][root][INFO] - Training Epoch: 1/2, step 818/7134 completed (loss: 4.251431465148926, acc: 0.26143792271614075)
[2024-12-17 01:37:45,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:45,856][root][INFO] - Training Epoch: 1/2, step 819/7134 completed (loss: 4.016348838806152, acc: 0.28082191944122314)
[2024-12-17 01:37:46,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:46,194][root][INFO] - Training Epoch: 1/2, step 820/7134 completed (loss: 3.736344814300537, acc: 0.34415584802627563)
[2024-12-17 01:37:46,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:46,513][root][INFO] - Training Epoch: 1/2, step 821/7134 completed (loss: 3.6772823333740234, acc: 0.3352601230144501)
[2024-12-17 01:37:46,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:46,785][root][INFO] - Training Epoch: 1/2, step 822/7134 completed (loss: 3.4122817516326904, acc: 0.3417721390724182)
[2024-12-17 01:37:46,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:47,058][root][INFO] - Training Epoch: 1/2, step 823/7134 completed (loss: 3.780982494354248, acc: 0.3008130192756653)
[2024-12-17 01:37:47,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:47,337][root][INFO] - Training Epoch: 1/2, step 824/7134 completed (loss: 4.033416748046875, acc: 0.2651515007019043)
[2024-12-17 01:37:47,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:47,669][root][INFO] - Training Epoch: 1/2, step 825/7134 completed (loss: 3.821108102798462, acc: 0.3579545319080353)
[2024-12-17 01:37:47,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:47,985][root][INFO] - Training Epoch: 1/2, step 826/7134 completed (loss: 3.594041585922241, acc: 0.31578946113586426)
[2024-12-17 01:37:48,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:48,263][root][INFO] - Training Epoch: 1/2, step 827/7134 completed (loss: 3.8031530380249023, acc: 0.3333333432674408)
[2024-12-17 01:37:48,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:48,525][root][INFO] - Training Epoch: 1/2, step 828/7134 completed (loss: 3.623377799987793, acc: 0.3311688303947449)
[2024-12-17 01:37:48,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:48,807][root][INFO] - Training Epoch: 1/2, step 829/7134 completed (loss: 4.194543838500977, acc: 0.21153846383094788)
[2024-12-17 01:37:48,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:49,106][root][INFO] - Training Epoch: 1/2, step 830/7134 completed (loss: 3.426044464111328, acc: 0.316546767950058)
[2024-12-17 01:37:49,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:49,402][root][INFO] - Training Epoch: 1/2, step 831/7134 completed (loss: 3.836799383163452, acc: 0.29518070816993713)
[2024-12-17 01:37:49,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:49,686][root][INFO] - Training Epoch: 1/2, step 832/7134 completed (loss: 4.12054443359375, acc: 0.2857142984867096)
[2024-12-17 01:37:49,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:49,972][root][INFO] - Training Epoch: 1/2, step 833/7134 completed (loss: 4.398435115814209, acc: 0.2023809552192688)
[2024-12-17 01:37:50,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:50,279][root][INFO] - Training Epoch: 1/2, step 834/7134 completed (loss: 3.590740919113159, acc: 0.3588235378265381)
[2024-12-17 01:37:50,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:50,588][root][INFO] - Training Epoch: 1/2, step 835/7134 completed (loss: 3.955631971359253, acc: 0.31578946113586426)
[2024-12-17 01:37:50,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:50,948][root][INFO] - Training Epoch: 1/2, step 836/7134 completed (loss: 3.6786651611328125, acc: 0.2893401086330414)
[2024-12-17 01:37:51,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:51,250][root][INFO] - Training Epoch: 1/2, step 837/7134 completed (loss: 4.048621654510498, acc: 0.2881355881690979)
[2024-12-17 01:37:51,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:51,529][root][INFO] - Training Epoch: 1/2, step 838/7134 completed (loss: 4.296998500823975, acc: 0.2875817120075226)
[2024-12-17 01:37:51,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:51,814][root][INFO] - Training Epoch: 1/2, step 839/7134 completed (loss: 3.978347063064575, acc: 0.2772277295589447)
[2024-12-17 01:37:51,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:52,095][root][INFO] - Training Epoch: 1/2, step 840/7134 completed (loss: 3.4005894660949707, acc: 0.35329341888427734)
[2024-12-17 01:37:52,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:52,382][root][INFO] - Training Epoch: 1/2, step 841/7134 completed (loss: 4.09705114364624, acc: 0.3040935695171356)
[2024-12-17 01:37:52,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:52,694][root][INFO] - Training Epoch: 1/2, step 842/7134 completed (loss: 3.671565532684326, acc: 0.29411765933036804)
[2024-12-17 01:37:52,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:52,978][root][INFO] - Training Epoch: 1/2, step 843/7134 completed (loss: 3.553922176361084, acc: 0.3274853825569153)
[2024-12-17 01:37:53,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:53,265][root][INFO] - Training Epoch: 1/2, step 844/7134 completed (loss: 3.3113763332366943, acc: 0.4178082048892975)
[2024-12-17 01:37:53,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:53,553][root][INFO] - Training Epoch: 1/2, step 845/7134 completed (loss: 3.9669477939605713, acc: 0.32592591643333435)
[2024-12-17 01:37:53,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:53,837][root][INFO] - Training Epoch: 1/2, step 846/7134 completed (loss: 3.425527811050415, acc: 0.39726027846336365)
[2024-12-17 01:37:53,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:54,109][root][INFO] - Training Epoch: 1/2, step 847/7134 completed (loss: 3.8911921977996826, acc: 0.3652694523334503)
[2024-12-17 01:37:54,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:54,385][root][INFO] - Training Epoch: 1/2, step 848/7134 completed (loss: 4.405826091766357, acc: 0.24561403691768646)
[2024-12-17 01:37:54,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:54,719][root][INFO] - Training Epoch: 1/2, step 849/7134 completed (loss: 3.8855655193328857, acc: 0.27439025044441223)
[2024-12-17 01:37:54,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:55,033][root][INFO] - Training Epoch: 1/2, step 850/7134 completed (loss: 3.3420042991638184, acc: 0.34899330139160156)
[2024-12-17 01:37:55,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:55,346][root][INFO] - Training Epoch: 1/2, step 851/7134 completed (loss: 3.9083943367004395, acc: 0.3139534890651703)
[2024-12-17 01:37:55,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:55,622][root][INFO] - Training Epoch: 1/2, step 852/7134 completed (loss: 3.6746113300323486, acc: 0.32460734248161316)
[2024-12-17 01:37:55,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:55,915][root][INFO] - Training Epoch: 1/2, step 853/7134 completed (loss: 3.941145896911621, acc: 0.30890053510665894)
[2024-12-17 01:37:56,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:56,214][root][INFO] - Training Epoch: 1/2, step 854/7134 completed (loss: 3.509037971496582, acc: 0.3109756112098694)
[2024-12-17 01:37:56,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:56,503][root][INFO] - Training Epoch: 1/2, step 855/7134 completed (loss: 3.6935617923736572, acc: 0.3179190754890442)
[2024-12-17 01:37:56,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:56,778][root][INFO] - Training Epoch: 1/2, step 856/7134 completed (loss: 3.7237398624420166, acc: 0.3606557250022888)
[2024-12-17 01:37:56,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:57,067][root][INFO] - Training Epoch: 1/2, step 857/7134 completed (loss: 3.946756362915039, acc: 0.2785714268684387)
[2024-12-17 01:37:57,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:57,356][root][INFO] - Training Epoch: 1/2, step 858/7134 completed (loss: 4.0474653244018555, acc: 0.3333333432674408)
[2024-12-17 01:37:57,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:57,640][root][INFO] - Training Epoch: 1/2, step 859/7134 completed (loss: 4.003275394439697, acc: 0.2768361568450928)
[2024-12-17 01:37:57,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:57,924][root][INFO] - Training Epoch: 1/2, step 860/7134 completed (loss: 4.633437633514404, acc: 0.29801324009895325)
[2024-12-17 01:37:58,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:58,256][root][INFO] - Training Epoch: 1/2, step 861/7134 completed (loss: 3.7037949562072754, acc: 0.32258063554763794)
[2024-12-17 01:37:58,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:58,532][root][INFO] - Training Epoch: 1/2, step 862/7134 completed (loss: 4.455921649932861, acc: 0.2685714364051819)
[2024-12-17 01:37:58,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:58,813][root][INFO] - Training Epoch: 1/2, step 863/7134 completed (loss: 4.241353511810303, acc: 0.3224043846130371)
[2024-12-17 01:37:58,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:59,093][root][INFO] - Training Epoch: 1/2, step 864/7134 completed (loss: 4.111209392547607, acc: 0.2857142984867096)
[2024-12-17 01:37:59,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:59,377][root][INFO] - Training Epoch: 1/2, step 865/7134 completed (loss: 4.16591739654541, acc: 0.25581395626068115)
[2024-12-17 01:37:59,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:59,666][root][INFO] - Training Epoch: 1/2, step 866/7134 completed (loss: 4.184704780578613, acc: 0.26428571343421936)
[2024-12-17 01:37:59,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:59,969][root][INFO] - Training Epoch: 1/2, step 867/7134 completed (loss: 4.295880317687988, acc: 0.2750000059604645)
[2024-12-17 01:38:00,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:00,253][root][INFO] - Training Epoch: 1/2, step 868/7134 completed (loss: 4.265684604644775, acc: 0.26744186878204346)
[2024-12-17 01:38:00,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:00,529][root][INFO] - Training Epoch: 1/2, step 869/7134 completed (loss: 5.329690456390381, acc: 0.15662650763988495)
[2024-12-17 01:38:00,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:00,813][root][INFO] - Training Epoch: 1/2, step 870/7134 completed (loss: 4.158191204071045, acc: 0.3274853825569153)
[2024-12-17 01:38:00,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:01,089][root][INFO] - Training Epoch: 1/2, step 871/7134 completed (loss: 4.454155921936035, acc: 0.2602739632129669)
[2024-12-17 01:38:01,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:01,359][root][INFO] - Training Epoch: 1/2, step 872/7134 completed (loss: 3.90081524848938, acc: 0.2847222089767456)
[2024-12-17 01:38:01,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:01,636][root][INFO] - Training Epoch: 1/2, step 873/7134 completed (loss: 4.078873157501221, acc: 0.2969697117805481)
[2024-12-17 01:38:01,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:01,922][root][INFO] - Training Epoch: 1/2, step 874/7134 completed (loss: 4.641679286956787, acc: 0.2083333283662796)
[2024-12-17 01:38:02,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:02,218][root][INFO] - Training Epoch: 1/2, step 875/7134 completed (loss: 4.0136847496032715, acc: 0.24460431933403015)
[2024-12-17 01:38:02,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:02,543][root][INFO] - Training Epoch: 1/2, step 876/7134 completed (loss: 4.0021772384643555, acc: 0.25)
[2024-12-17 01:38:02,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:02,835][root][INFO] - Training Epoch: 1/2, step 877/7134 completed (loss: 3.9437689781188965, acc: 0.25153374671936035)
[2024-12-17 01:38:02,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:03,114][root][INFO] - Training Epoch: 1/2, step 878/7134 completed (loss: 4.222126007080078, acc: 0.26249998807907104)
[2024-12-17 01:38:03,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:03,389][root][INFO] - Training Epoch: 1/2, step 879/7134 completed (loss: 4.36084508895874, acc: 0.2802547812461853)
[2024-12-17 01:38:03,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:03,710][root][INFO] - Training Epoch: 1/2, step 880/7134 completed (loss: 4.147939682006836, acc: 0.25766870379447937)
[2024-12-17 01:38:03,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:03,975][root][INFO] - Training Epoch: 1/2, step 881/7134 completed (loss: 4.286046028137207, acc: 0.22764228284358978)
[2024-12-17 01:38:04,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:04,248][root][INFO] - Training Epoch: 1/2, step 882/7134 completed (loss: 3.760624408721924, acc: 0.25806450843811035)
[2024-12-17 01:38:04,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:04,538][root][INFO] - Training Epoch: 1/2, step 883/7134 completed (loss: 4.299324035644531, acc: 0.32236841320991516)
[2024-12-17 01:38:04,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:04,820][root][INFO] - Training Epoch: 1/2, step 884/7134 completed (loss: 4.0917558670043945, acc: 0.2934131622314453)
[2024-12-17 01:38:04,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:05,144][root][INFO] - Training Epoch: 1/2, step 885/7134 completed (loss: 3.683051109313965, acc: 0.3353658616542816)
[2024-12-17 01:38:05,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:05,421][root][INFO] - Training Epoch: 1/2, step 886/7134 completed (loss: 3.8576767444610596, acc: 0.24369747936725616)
[2024-12-17 01:38:05,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:05,734][root][INFO] - Training Epoch: 1/2, step 887/7134 completed (loss: 4.007002830505371, acc: 0.2238806039094925)
[2024-12-17 01:38:05,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:06,013][root][INFO] - Training Epoch: 1/2, step 888/7134 completed (loss: 4.115087509155273, acc: 0.24161073565483093)
[2024-12-17 01:38:06,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:06,311][root][INFO] - Training Epoch: 1/2, step 889/7134 completed (loss: 4.318864345550537, acc: 0.32673266530036926)
[2024-12-17 01:38:06,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:06,590][root][INFO] - Training Epoch: 1/2, step 890/7134 completed (loss: 4.13092565536499, acc: 0.281879186630249)
[2024-12-17 01:38:06,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:06,869][root][INFO] - Training Epoch: 1/2, step 891/7134 completed (loss: 3.658799171447754, acc: 0.3072625696659088)
[2024-12-17 01:38:07,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:07,170][root][INFO] - Training Epoch: 1/2, step 892/7134 completed (loss: 3.7267589569091797, acc: 0.2738095223903656)
[2024-12-17 01:38:07,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:07,454][root][INFO] - Training Epoch: 1/2, step 893/7134 completed (loss: 3.8357253074645996, acc: 0.32679739594459534)
[2024-12-17 01:38:07,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:07,740][root][INFO] - Training Epoch: 1/2, step 894/7134 completed (loss: 3.4656829833984375, acc: 0.3502824902534485)
[2024-12-17 01:38:07,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:08,029][root][INFO] - Training Epoch: 1/2, step 895/7134 completed (loss: 3.573176145553589, acc: 0.34246575832366943)
[2024-12-17 01:38:08,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:08,307][root][INFO] - Training Epoch: 1/2, step 896/7134 completed (loss: 3.6632909774780273, acc: 0.34645670652389526)
[2024-12-17 01:38:08,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:08,629][root][INFO] - Training Epoch: 1/2, step 897/7134 completed (loss: 3.59386944770813, acc: 0.29608938097953796)
[2024-12-17 01:38:08,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:08,929][root][INFO] - Training Epoch: 1/2, step 898/7134 completed (loss: 3.939316511154175, acc: 0.27272728085517883)
[2024-12-17 01:38:09,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:09,202][root][INFO] - Training Epoch: 1/2, step 899/7134 completed (loss: 3.7657084465026855, acc: 0.31550800800323486)
[2024-12-17 01:38:09,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:09,517][root][INFO] - Training Epoch: 1/2, step 900/7134 completed (loss: 3.62605357170105, acc: 0.3048780560493469)
[2024-12-17 01:38:09,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:09,830][root][INFO] - Training Epoch: 1/2, step 901/7134 completed (loss: 3.8347480297088623, acc: 0.3452380895614624)
[2024-12-17 01:38:09,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:10,130][root][INFO] - Training Epoch: 1/2, step 902/7134 completed (loss: 3.9890904426574707, acc: 0.2792207896709442)
[2024-12-17 01:38:10,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:10,404][root][INFO] - Training Epoch: 1/2, step 903/7134 completed (loss: 3.651620864868164, acc: 0.2832369804382324)
[2024-12-17 01:38:10,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:10,692][root][INFO] - Training Epoch: 1/2, step 904/7134 completed (loss: 3.72078013420105, acc: 0.299435019493103)
[2024-12-17 01:38:10,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:10,984][root][INFO] - Training Epoch: 1/2, step 905/7134 completed (loss: 3.7023322582244873, acc: 0.32758620381355286)
[2024-12-17 01:38:11,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:11,268][root][INFO] - Training Epoch: 1/2, step 906/7134 completed (loss: 3.920858383178711, acc: 0.2928176820278168)
[2024-12-17 01:38:11,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:11,545][root][INFO] - Training Epoch: 1/2, step 907/7134 completed (loss: 3.8657312393188477, acc: 0.29032257199287415)
[2024-12-17 01:38:11,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:11,812][root][INFO] - Training Epoch: 1/2, step 908/7134 completed (loss: 3.461885690689087, acc: 0.3611111044883728)
[2024-12-17 01:38:11,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:12,075][root][INFO] - Training Epoch: 1/2, step 909/7134 completed (loss: 3.2726495265960693, acc: 0.3881579041481018)
[2024-12-17 01:38:12,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:12,369][root][INFO] - Training Epoch: 1/2, step 910/7134 completed (loss: 4.358081817626953, acc: 0.26249998807907104)
[2024-12-17 01:38:12,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:12,639][root][INFO] - Training Epoch: 1/2, step 911/7134 completed (loss: 4.2678728103637695, acc: 0.3096774220466614)
[2024-12-17 01:38:12,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:12,922][root][INFO] - Training Epoch: 1/2, step 912/7134 completed (loss: 3.8042027950286865, acc: 0.3105263113975525)
[2024-12-17 01:38:13,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:13,219][root][INFO] - Training Epoch: 1/2, step 913/7134 completed (loss: 3.9093470573425293, acc: 0.29120880365371704)
[2024-12-17 01:38:13,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:13,498][root][INFO] - Training Epoch: 1/2, step 914/7134 completed (loss: 4.073370456695557, acc: 0.2545454502105713)
[2024-12-17 01:38:13,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:13,814][root][INFO] - Training Epoch: 1/2, step 915/7134 completed (loss: 4.051710605621338, acc: 0.2785714268684387)
[2024-12-17 01:38:13,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:14,100][root][INFO] - Training Epoch: 1/2, step 916/7134 completed (loss: 3.871697187423706, acc: 0.3100775182247162)
[2024-12-17 01:38:14,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:14,366][root][INFO] - Training Epoch: 1/2, step 917/7134 completed (loss: 4.363649368286133, acc: 0.2792207896709442)
[2024-12-17 01:38:14,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:14,658][root][INFO] - Training Epoch: 1/2, step 918/7134 completed (loss: 3.668442964553833, acc: 0.3576158881187439)
[2024-12-17 01:38:14,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:14,926][root][INFO] - Training Epoch: 1/2, step 919/7134 completed (loss: 3.6275079250335693, acc: 0.3246753215789795)
[2024-12-17 01:38:15,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:15,201][root][INFO] - Training Epoch: 1/2, step 920/7134 completed (loss: 3.834103584289551, acc: 0.29651162028312683)
[2024-12-17 01:38:15,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:15,540][root][INFO] - Training Epoch: 1/2, step 921/7134 completed (loss: 4.124511241912842, acc: 0.23391813039779663)
[2024-12-17 01:38:15,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:15,843][root][INFO] - Training Epoch: 1/2, step 922/7134 completed (loss: 3.727473497390747, acc: 0.26119402050971985)
[2024-12-17 01:38:15,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:16,128][root][INFO] - Training Epoch: 1/2, step 923/7134 completed (loss: 3.4132559299468994, acc: 0.3333333432674408)
[2024-12-17 01:38:16,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:16,487][root][INFO] - Training Epoch: 1/2, step 924/7134 completed (loss: 3.507297992706299, acc: 0.2542372941970825)
[2024-12-17 01:38:16,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:16,793][root][INFO] - Training Epoch: 1/2, step 925/7134 completed (loss: 4.002045154571533, acc: 0.31612902879714966)
[2024-12-17 01:38:16,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:17,097][root][INFO] - Training Epoch: 1/2, step 926/7134 completed (loss: 3.4532954692840576, acc: 0.2944444417953491)
[2024-12-17 01:38:17,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:17,391][root][INFO] - Training Epoch: 1/2, step 927/7134 completed (loss: 3.5323331356048584, acc: 0.3093525171279907)
[2024-12-17 01:38:17,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:17,690][root][INFO] - Training Epoch: 1/2, step 928/7134 completed (loss: 3.725592613220215, acc: 0.3211009204387665)
[2024-12-17 01:38:17,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:17,986][root][INFO] - Training Epoch: 1/2, step 929/7134 completed (loss: 3.890268087387085, acc: 0.30263158679008484)
[2024-12-17 01:38:18,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:18,239][root][INFO] - Training Epoch: 1/2, step 930/7134 completed (loss: 3.7038705348968506, acc: 0.3467741906642914)
[2024-12-17 01:38:18,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:18,532][root][INFO] - Training Epoch: 1/2, step 931/7134 completed (loss: 3.747436285018921, acc: 0.31617647409439087)
[2024-12-17 01:38:18,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:18,847][root][INFO] - Training Epoch: 1/2, step 932/7134 completed (loss: 3.548546552658081, acc: 0.3154761791229248)
[2024-12-17 01:38:18,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:19,129][root][INFO] - Training Epoch: 1/2, step 933/7134 completed (loss: 4.292914867401123, acc: 0.269461065530777)
[2024-12-17 01:38:19,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:19,431][root][INFO] - Training Epoch: 1/2, step 934/7134 completed (loss: 4.028736114501953, acc: 0.24418604373931885)
[2024-12-17 01:38:19,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:19,704][root][INFO] - Training Epoch: 1/2, step 935/7134 completed (loss: 3.5929501056671143, acc: 0.3178294599056244)
[2024-12-17 01:38:19,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:19,981][root][INFO] - Training Epoch: 1/2, step 936/7134 completed (loss: 4.072859287261963, acc: 0.25196850299835205)
[2024-12-17 01:38:20,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:20,262][root][INFO] - Training Epoch: 1/2, step 937/7134 completed (loss: 4.355745792388916, acc: 0.24390244483947754)
[2024-12-17 01:38:20,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:20,593][root][INFO] - Training Epoch: 1/2, step 938/7134 completed (loss: 3.895069122314453, acc: 0.2628205120563507)
[2024-12-17 01:38:20,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:20,878][root][INFO] - Training Epoch: 1/2, step 939/7134 completed (loss: 3.972440004348755, acc: 0.2804878056049347)
[2024-12-17 01:38:21,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:21,170][root][INFO] - Training Epoch: 1/2, step 940/7134 completed (loss: 4.0153584480285645, acc: 0.2543352544307709)
[2024-12-17 01:38:21,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:21,459][root][INFO] - Training Epoch: 1/2, step 941/7134 completed (loss: 3.6268796920776367, acc: 0.30337077379226685)
[2024-12-17 01:38:21,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:21,752][root][INFO] - Training Epoch: 1/2, step 942/7134 completed (loss: 3.8569793701171875, acc: 0.302325576543808)
[2024-12-17 01:38:21,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:22,042][root][INFO] - Training Epoch: 1/2, step 943/7134 completed (loss: 3.867145538330078, acc: 0.24539877474308014)
[2024-12-17 01:38:22,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:22,330][root][INFO] - Training Epoch: 1/2, step 944/7134 completed (loss: 3.751358985900879, acc: 0.2738853394985199)
[2024-12-17 01:38:22,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:22,596][root][INFO] - Training Epoch: 1/2, step 945/7134 completed (loss: 3.863696336746216, acc: 0.3245033025741577)
[2024-12-17 01:38:22,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:22,888][root][INFO] - Training Epoch: 1/2, step 946/7134 completed (loss: 4.197877883911133, acc: 0.25242719054222107)
[2024-12-17 01:38:23,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:23,184][root][INFO] - Training Epoch: 1/2, step 947/7134 completed (loss: 4.092926502227783, acc: 0.25)
[2024-12-17 01:38:23,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:23,474][root][INFO] - Training Epoch: 1/2, step 948/7134 completed (loss: 3.690080404281616, acc: 0.3012048304080963)
[2024-12-17 01:38:23,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:23,806][root][INFO] - Training Epoch: 1/2, step 949/7134 completed (loss: 3.90008282661438, acc: 0.32499998807907104)
[2024-12-17 01:38:23,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:24,098][root][INFO] - Training Epoch: 1/2, step 950/7134 completed (loss: 3.647078514099121, acc: 0.3311688303947449)
[2024-12-17 01:38:24,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:24,392][root][INFO] - Training Epoch: 1/2, step 951/7134 completed (loss: 3.847398042678833, acc: 0.28244274854660034)
[2024-12-17 01:38:24,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:24,688][root][INFO] - Training Epoch: 1/2, step 952/7134 completed (loss: 3.340271234512329, acc: 0.38235294818878174)
[2024-12-17 01:38:24,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:24,981][root][INFO] - Training Epoch: 1/2, step 953/7134 completed (loss: 4.137733459472656, acc: 0.24390244483947754)
[2024-12-17 01:38:25,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:25,288][root][INFO] - Training Epoch: 1/2, step 954/7134 completed (loss: 3.8479487895965576, acc: 0.32413792610168457)
[2024-12-17 01:38:25,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:25,590][root][INFO] - Training Epoch: 1/2, step 955/7134 completed (loss: 3.9727542400360107, acc: 0.2881355881690979)
[2024-12-17 01:38:25,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:25,881][root][INFO] - Training Epoch: 1/2, step 956/7134 completed (loss: 3.674673557281494, acc: 0.30434781312942505)
[2024-12-17 01:38:26,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:26,176][root][INFO] - Training Epoch: 1/2, step 957/7134 completed (loss: 3.5632169246673584, acc: 0.28921568393707275)
[2024-12-17 01:38:26,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:26,543][root][INFO] - Training Epoch: 1/2, step 958/7134 completed (loss: 4.0326972007751465, acc: 0.31343284249305725)
[2024-12-17 01:38:26,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:26,849][root][INFO] - Training Epoch: 1/2, step 959/7134 completed (loss: 4.211998462677002, acc: 0.3298968970775604)
[2024-12-17 01:38:26,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:27,127][root][INFO] - Training Epoch: 1/2, step 960/7134 completed (loss: 4.354974269866943, acc: 0.2985074520111084)
[2024-12-17 01:38:27,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:27,406][root][INFO] - Training Epoch: 1/2, step 961/7134 completed (loss: 4.247184753417969, acc: 0.29120880365371704)
[2024-12-17 01:38:27,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:27,683][root][INFO] - Training Epoch: 1/2, step 962/7134 completed (loss: 4.278763294219971, acc: 0.2631579041481018)
[2024-12-17 01:38:27,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:27,999][root][INFO] - Training Epoch: 1/2, step 963/7134 completed (loss: 3.6873059272766113, acc: 0.27906978130340576)
[2024-12-17 01:38:28,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:28,270][root][INFO] - Training Epoch: 1/2, step 964/7134 completed (loss: 4.463052272796631, acc: 0.23780487477779388)
[2024-12-17 01:38:28,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:28,558][root][INFO] - Training Epoch: 1/2, step 965/7134 completed (loss: 4.003961563110352, acc: 0.26203209161758423)
[2024-12-17 01:38:28,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:28,835][root][INFO] - Training Epoch: 1/2, step 966/7134 completed (loss: 4.018952369689941, acc: 0.28834354877471924)
[2024-12-17 01:38:28,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:29,114][root][INFO] - Training Epoch: 1/2, step 967/7134 completed (loss: 4.070207595825195, acc: 0.27659574151039124)
[2024-12-17 01:38:29,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:29,446][root][INFO] - Training Epoch: 1/2, step 968/7134 completed (loss: 4.690648555755615, acc: 0.27819550037384033)
[2024-12-17 01:38:29,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:29,701][root][INFO] - Training Epoch: 1/2, step 969/7134 completed (loss: 4.248586654663086, acc: 0.2742857038974762)
[2024-12-17 01:38:29,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:29,986][root][INFO] - Training Epoch: 1/2, step 970/7134 completed (loss: 4.351546287536621, acc: 0.2867647111415863)
[2024-12-17 01:38:30,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:30,273][root][INFO] - Training Epoch: 1/2, step 971/7134 completed (loss: 3.4693264961242676, acc: 0.3412322402000427)
[2024-12-17 01:38:30,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:30,564][root][INFO] - Training Epoch: 1/2, step 972/7134 completed (loss: 4.209923267364502, acc: 0.2153846174478531)
[2024-12-17 01:38:30,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:30,886][root][INFO] - Training Epoch: 1/2, step 973/7134 completed (loss: 4.032217502593994, acc: 0.3461538553237915)
[2024-12-17 01:38:31,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:31,184][root][INFO] - Training Epoch: 1/2, step 974/7134 completed (loss: 4.173379421234131, acc: 0.27227723598480225)
[2024-12-17 01:38:31,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:31,457][root][INFO] - Training Epoch: 1/2, step 975/7134 completed (loss: 4.430433750152588, acc: 0.25)
[2024-12-17 01:38:31,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:31,744][root][INFO] - Training Epoch: 1/2, step 976/7134 completed (loss: 3.7351903915405273, acc: 0.29801324009895325)
[2024-12-17 01:38:31,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:32,026][root][INFO] - Training Epoch: 1/2, step 977/7134 completed (loss: 4.1443867683410645, acc: 0.32022473216056824)
[2024-12-17 01:38:32,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:32,313][root][INFO] - Training Epoch: 1/2, step 978/7134 completed (loss: 3.8014278411865234, acc: 0.3195876181125641)
[2024-12-17 01:38:32,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:32,593][root][INFO] - Training Epoch: 1/2, step 979/7134 completed (loss: 3.8514411449432373, acc: 0.36216217279434204)
[2024-12-17 01:38:32,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:32,875][root][INFO] - Training Epoch: 1/2, step 980/7134 completed (loss: 4.081952095031738, acc: 0.2910798192024231)
[2024-12-17 01:38:33,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:33,168][root][INFO] - Training Epoch: 1/2, step 981/7134 completed (loss: 4.398325443267822, acc: 0.2830188572406769)
[2024-12-17 01:38:33,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:33,445][root][INFO] - Training Epoch: 1/2, step 982/7134 completed (loss: 4.179734706878662, acc: 0.3028571307659149)
[2024-12-17 01:38:33,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:33,732][root][INFO] - Training Epoch: 1/2, step 983/7134 completed (loss: 4.155557632446289, acc: 0.2631579041481018)
[2024-12-17 01:38:33,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:34,018][root][INFO] - Training Epoch: 1/2, step 984/7134 completed (loss: 3.9324474334716797, acc: 0.326241135597229)
[2024-12-17 01:38:34,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:34,306][root][INFO] - Training Epoch: 1/2, step 985/7134 completed (loss: 3.702702760696411, acc: 0.30000001192092896)
[2024-12-17 01:38:34,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:34,593][root][INFO] - Training Epoch: 1/2, step 986/7134 completed (loss: 3.6906542778015137, acc: 0.29050278663635254)
[2024-12-17 01:38:34,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:34,892][root][INFO] - Training Epoch: 1/2, step 987/7134 completed (loss: 3.5569262504577637, acc: 0.34899330139160156)
[2024-12-17 01:38:35,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:35,175][root][INFO] - Training Epoch: 1/2, step 988/7134 completed (loss: 4.283511638641357, acc: 0.31073445081710815)
[2024-12-17 01:38:35,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:35,461][root][INFO] - Training Epoch: 1/2, step 989/7134 completed (loss: 4.116720676422119, acc: 0.2822085916996002)
[2024-12-17 01:38:35,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:35,744][root][INFO] - Training Epoch: 1/2, step 990/7134 completed (loss: 4.0960001945495605, acc: 0.2527472674846649)
[2024-12-17 01:38:35,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:36,023][root][INFO] - Training Epoch: 1/2, step 991/7134 completed (loss: 4.264188289642334, acc: 0.3396226465702057)
[2024-12-17 01:38:36,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:36,311][root][INFO] - Training Epoch: 1/2, step 992/7134 completed (loss: 3.880551815032959, acc: 0.30635836720466614)
[2024-12-17 01:38:36,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:36,606][root][INFO] - Training Epoch: 1/2, step 993/7134 completed (loss: 4.4535441398620605, acc: 0.28057554364204407)
[2024-12-17 01:38:36,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:36,948][root][INFO] - Training Epoch: 1/2, step 994/7134 completed (loss: 3.4911961555480957, acc: 0.38349515199661255)
[2024-12-17 01:38:37,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:37,245][root][INFO] - Training Epoch: 1/2, step 995/7134 completed (loss: 4.233910083770752, acc: 0.21768707036972046)
[2024-12-17 01:38:37,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:37,527][root][INFO] - Training Epoch: 1/2, step 996/7134 completed (loss: 3.875410318374634, acc: 0.302325576543808)
[2024-12-17 01:38:37,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:37,806][root][INFO] - Training Epoch: 1/2, step 997/7134 completed (loss: 3.703307628631592, acc: 0.33529412746429443)
[2024-12-17 01:38:37,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:38,087][root][INFO] - Training Epoch: 1/2, step 998/7134 completed (loss: 3.8632147312164307, acc: 0.2934131622314453)
[2024-12-17 01:38:38,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:38,371][root][INFO] - Training Epoch: 1/2, step 999/7134 completed (loss: 4.153914928436279, acc: 0.2461538463830948)
[2024-12-17 01:38:38,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:38,650][root][INFO] - Training Epoch: 1/2, step 1000/7134 completed (loss: 4.075283050537109, acc: 0.24264705181121826)
[2024-12-17 01:38:38,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:38,973][root][INFO] - Training Epoch: 1/2, step 1001/7134 completed (loss: 3.885535717010498, acc: 0.3272727131843567)
[2024-12-17 01:38:39,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:39,255][root][INFO] - Training Epoch: 1/2, step 1002/7134 completed (loss: 4.257813930511475, acc: 0.2641509473323822)
[2024-12-17 01:38:39,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:39,529][root][INFO] - Training Epoch: 1/2, step 1003/7134 completed (loss: 3.6923108100891113, acc: 0.3263888955116272)
[2024-12-17 01:38:39,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:39,796][root][INFO] - Training Epoch: 1/2, step 1004/7134 completed (loss: 4.185247421264648, acc: 0.32743361592292786)
[2024-12-17 01:38:39,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:40,079][root][INFO] - Training Epoch: 1/2, step 1005/7134 completed (loss: 3.9694581031799316, acc: 0.3120567500591278)
[2024-12-17 01:38:40,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:40,342][root][INFO] - Training Epoch: 1/2, step 1006/7134 completed (loss: 4.593683242797852, acc: 0.19745223224163055)
[2024-12-17 01:38:40,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:40,614][root][INFO] - Training Epoch: 1/2, step 1007/7134 completed (loss: 4.3599138259887695, acc: 0.23943662643432617)
[2024-12-17 01:38:40,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:40,892][root][INFO] - Training Epoch: 1/2, step 1008/7134 completed (loss: 4.247343063354492, acc: 0.2839506268501282)
[2024-12-17 01:38:41,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:41,165][root][INFO] - Training Epoch: 1/2, step 1009/7134 completed (loss: 3.709226131439209, acc: 0.27131783962249756)
[2024-12-17 01:38:41,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:41,429][root][INFO] - Training Epoch: 1/2, step 1010/7134 completed (loss: 3.6349194049835205, acc: 0.3333333432674408)
[2024-12-17 01:38:41,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:41,709][root][INFO] - Training Epoch: 1/2, step 1011/7134 completed (loss: 4.057470321655273, acc: 0.30817610025405884)
[2024-12-17 01:38:41,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:41,991][root][INFO] - Training Epoch: 1/2, step 1012/7134 completed (loss: 3.8889317512512207, acc: 0.375)
[2024-12-17 01:38:42,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:42,273][root][INFO] - Training Epoch: 1/2, step 1013/7134 completed (loss: 4.262138843536377, acc: 0.2650602459907532)
[2024-12-17 01:38:42,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:42,551][root][INFO] - Training Epoch: 1/2, step 1014/7134 completed (loss: 4.178483486175537, acc: 0.283687949180603)
[2024-12-17 01:38:42,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:42,832][root][INFO] - Training Epoch: 1/2, step 1015/7134 completed (loss: 3.95794677734375, acc: 0.3245033025741577)
[2024-12-17 01:38:42,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:43,136][root][INFO] - Training Epoch: 1/2, step 1016/7134 completed (loss: 4.4000139236450195, acc: 0.26050421595573425)
[2024-12-17 01:38:43,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:43,426][root][INFO] - Training Epoch: 1/2, step 1017/7134 completed (loss: 3.8509671688079834, acc: 0.3142857253551483)
[2024-12-17 01:38:43,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:43,732][root][INFO] - Training Epoch: 1/2, step 1018/7134 completed (loss: 4.340439796447754, acc: 0.30434781312942505)
[2024-12-17 01:38:43,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:44,014][root][INFO] - Training Epoch: 1/2, step 1019/7134 completed (loss: 4.421789169311523, acc: 0.20779220759868622)
[2024-12-17 01:38:44,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:44,320][root][INFO] - Training Epoch: 1/2, step 1020/7134 completed (loss: 4.387497901916504, acc: 0.2675159275531769)
[2024-12-17 01:38:44,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:44,595][root][INFO] - Training Epoch: 1/2, step 1021/7134 completed (loss: 3.5975043773651123, acc: 0.3333333432674408)
[2024-12-17 01:38:44,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:44,876][root][INFO] - Training Epoch: 1/2, step 1022/7134 completed (loss: 3.4931440353393555, acc: 0.323699414730072)
[2024-12-17 01:38:44,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:45,158][root][INFO] - Training Epoch: 1/2, step 1023/7134 completed (loss: 4.109509468078613, acc: 0.24581006169319153)
[2024-12-17 01:38:45,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:45,458][root][INFO] - Training Epoch: 1/2, step 1024/7134 completed (loss: 4.144619464874268, acc: 0.31343284249305725)
[2024-12-17 01:38:45,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:45,759][root][INFO] - Training Epoch: 1/2, step 1025/7134 completed (loss: 3.6974170207977295, acc: 0.3120567500591278)
[2024-12-17 01:38:45,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:46,048][root][INFO] - Training Epoch: 1/2, step 1026/7134 completed (loss: 3.9734346866607666, acc: 0.2743362784385681)
[2024-12-17 01:38:46,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:46,355][root][INFO] - Training Epoch: 1/2, step 1027/7134 completed (loss: 3.859813690185547, acc: 0.2823529541492462)
[2024-12-17 01:38:46,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:46,656][root][INFO] - Training Epoch: 1/2, step 1028/7134 completed (loss: 3.6873459815979004, acc: 0.2578616440296173)
[2024-12-17 01:38:46,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:46,945][root][INFO] - Training Epoch: 1/2, step 1029/7134 completed (loss: 3.609663486480713, acc: 0.29012346267700195)
[2024-12-17 01:38:47,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:47,231][root][INFO] - Training Epoch: 1/2, step 1030/7134 completed (loss: 3.8549246788024902, acc: 0.26436781883239746)
[2024-12-17 01:38:47,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:47,519][root][INFO] - Training Epoch: 1/2, step 1031/7134 completed (loss: 4.82343053817749, acc: 0.1801242232322693)
[2024-12-17 01:38:47,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:47,805][root][INFO] - Training Epoch: 1/2, step 1032/7134 completed (loss: 3.7120561599731445, acc: 0.3510638177394867)
[2024-12-17 01:38:47,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:48,103][root][INFO] - Training Epoch: 1/2, step 1033/7134 completed (loss: 3.9090447425842285, acc: 0.30136987566947937)
[2024-12-17 01:38:48,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:48,377][root][INFO] - Training Epoch: 1/2, step 1034/7134 completed (loss: 4.237124919891357, acc: 0.34415584802627563)
[2024-12-17 01:38:48,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:48,676][root][INFO] - Training Epoch: 1/2, step 1035/7134 completed (loss: 4.906045913696289, acc: 0.22297297418117523)
[2024-12-17 01:38:48,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:48,965][root][INFO] - Training Epoch: 1/2, step 1036/7134 completed (loss: 5.015241622924805, acc: 0.2542372941970825)
[2024-12-17 01:38:49,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:49,247][root][INFO] - Training Epoch: 1/2, step 1037/7134 completed (loss: 3.4155993461608887, acc: 0.36702126264572144)
[2024-12-17 01:38:49,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:49,526][root][INFO] - Training Epoch: 1/2, step 1038/7134 completed (loss: 3.8593881130218506, acc: 0.3440000116825104)
[2024-12-17 01:38:49,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:49,796][root][INFO] - Training Epoch: 1/2, step 1039/7134 completed (loss: 3.8066024780273438, acc: 0.26605504751205444)
[2024-12-17 01:38:49,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:50,118][root][INFO] - Training Epoch: 1/2, step 1040/7134 completed (loss: 4.193948268890381, acc: 0.2246376872062683)
[2024-12-17 01:38:50,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:50,426][root][INFO] - Training Epoch: 1/2, step 1041/7134 completed (loss: 3.6388533115386963, acc: 0.3154362440109253)
[2024-12-17 01:38:50,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:50,758][root][INFO] - Training Epoch: 1/2, step 1042/7134 completed (loss: 3.6703195571899414, acc: 0.35754188895225525)
[2024-12-17 01:38:50,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:51,038][root][INFO] - Training Epoch: 1/2, step 1043/7134 completed (loss: 3.850696325302124, acc: 0.29207921028137207)
[2024-12-17 01:38:51,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:51,329][root][INFO] - Training Epoch: 1/2, step 1044/7134 completed (loss: 2.9561715126037598, acc: 0.4409937858581543)
[2024-12-17 01:38:51,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:51,601][root][INFO] - Training Epoch: 1/2, step 1045/7134 completed (loss: 4.852597236633301, acc: 0.19875776767730713)
[2024-12-17 01:38:51,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:51,880][root][INFO] - Training Epoch: 1/2, step 1046/7134 completed (loss: 4.314523220062256, acc: 0.2631579041481018)
[2024-12-17 01:38:52,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:52,169][root][INFO] - Training Epoch: 1/2, step 1047/7134 completed (loss: 4.192737579345703, acc: 0.3085714280605316)
[2024-12-17 01:38:52,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:52,546][root][INFO] - Training Epoch: 1/2, step 1048/7134 completed (loss: 4.019003868103027, acc: 0.31847134232521057)
[2024-12-17 01:38:52,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:52,822][root][INFO] - Training Epoch: 1/2, step 1049/7134 completed (loss: 4.358674049377441, acc: 0.2697368562221527)
[2024-12-17 01:38:52,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:53,113][root][INFO] - Training Epoch: 1/2, step 1050/7134 completed (loss: 4.446821212768555, acc: 0.2760416567325592)
[2024-12-17 01:38:53,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:53,393][root][INFO] - Training Epoch: 1/2, step 1051/7134 completed (loss: 3.9259328842163086, acc: 0.3199999928474426)
[2024-12-17 01:38:53,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:53,673][root][INFO] - Training Epoch: 1/2, step 1052/7134 completed (loss: 4.042764186859131, acc: 0.3614457845687866)
[2024-12-17 01:38:53,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:53,950][root][INFO] - Training Epoch: 1/2, step 1053/7134 completed (loss: 4.159366130828857, acc: 0.31736525893211365)
[2024-12-17 01:38:54,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:54,230][root][INFO] - Training Epoch: 1/2, step 1054/7134 completed (loss: 3.8012144565582275, acc: 0.2864583432674408)
[2024-12-17 01:38:54,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:54,509][root][INFO] - Training Epoch: 1/2, step 1055/7134 completed (loss: 4.37015438079834, acc: 0.25190839171409607)
[2024-12-17 01:38:54,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:54,790][root][INFO] - Training Epoch: 1/2, step 1056/7134 completed (loss: 4.07969856262207, acc: 0.2906976640224457)
[2024-12-17 01:38:54,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:55,078][root][INFO] - Training Epoch: 1/2, step 1057/7134 completed (loss: 3.7477357387542725, acc: 0.3056994676589966)
[2024-12-17 01:38:55,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:55,370][root][INFO] - Training Epoch: 1/2, step 1058/7134 completed (loss: 3.990079641342163, acc: 0.2631579041481018)
[2024-12-17 01:38:55,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:55,679][root][INFO] - Training Epoch: 1/2, step 1059/7134 completed (loss: 4.006484508514404, acc: 0.2985782027244568)
[2024-12-17 01:38:55,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:55,956][root][INFO] - Training Epoch: 1/2, step 1060/7134 completed (loss: 3.7623815536499023, acc: 0.33974358439445496)
[2024-12-17 01:38:56,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:56,277][root][INFO] - Training Epoch: 1/2, step 1061/7134 completed (loss: 3.8555870056152344, acc: 0.3041236996650696)
[2024-12-17 01:38:56,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:56,549][root][INFO] - Training Epoch: 1/2, step 1062/7134 completed (loss: 4.171470642089844, acc: 0.27108433842658997)
[2024-12-17 01:38:56,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:56,827][root][INFO] - Training Epoch: 1/2, step 1063/7134 completed (loss: 3.771336793899536, acc: 0.33529412746429443)
[2024-12-17 01:38:56,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:57,115][root][INFO] - Training Epoch: 1/2, step 1064/7134 completed (loss: 3.654686450958252, acc: 0.3027026951313019)
[2024-12-17 01:38:57,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:57,400][root][INFO] - Training Epoch: 1/2, step 1065/7134 completed (loss: 3.9217896461486816, acc: 0.2928176820278168)
[2024-12-17 01:38:57,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:57,682][root][INFO] - Training Epoch: 1/2, step 1066/7134 completed (loss: 4.254472732543945, acc: 0.28244274854660034)
[2024-12-17 01:38:57,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:57,969][root][INFO] - Training Epoch: 1/2, step 1067/7134 completed (loss: 4.152576446533203, acc: 0.3137255012989044)
[2024-12-17 01:38:58,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:58,279][root][INFO] - Training Epoch: 1/2, step 1068/7134 completed (loss: 4.334239482879639, acc: 0.2890625)
[2024-12-17 01:38:58,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:58,553][root][INFO] - Training Epoch: 1/2, step 1069/7134 completed (loss: 4.137997627258301, acc: 0.2986111044883728)
[2024-12-17 01:38:58,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:58,838][root][INFO] - Training Epoch: 1/2, step 1070/7134 completed (loss: 4.086198806762695, acc: 0.232876718044281)
[2024-12-17 01:38:59,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:59,169][root][INFO] - Training Epoch: 1/2, step 1071/7134 completed (loss: 4.007751941680908, acc: 0.26875001192092896)
[2024-12-17 01:38:59,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:59,453][root][INFO] - Training Epoch: 1/2, step 1072/7134 completed (loss: 3.520209789276123, acc: 0.29878050088882446)
[2024-12-17 01:38:59,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:59,737][root][INFO] - Training Epoch: 1/2, step 1073/7134 completed (loss: 3.736278772354126, acc: 0.23602484166622162)
[2024-12-17 01:38:59,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:00,015][root][INFO] - Training Epoch: 1/2, step 1074/7134 completed (loss: 4.018790245056152, acc: 0.304964542388916)
[2024-12-17 01:39:00,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:00,301][root][INFO] - Training Epoch: 1/2, step 1075/7134 completed (loss: 4.290119647979736, acc: 0.277372270822525)
[2024-12-17 01:39:00,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:00,577][root][INFO] - Training Epoch: 1/2, step 1076/7134 completed (loss: 4.167651653289795, acc: 0.31382977962493896)
[2024-12-17 01:39:00,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:00,849][root][INFO] - Training Epoch: 1/2, step 1077/7134 completed (loss: 4.353453159332275, acc: 0.3008849620819092)
[2024-12-17 01:39:00,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:01,133][root][INFO] - Training Epoch: 1/2, step 1078/7134 completed (loss: 4.846314430236816, acc: 0.2515723407268524)
[2024-12-17 01:39:01,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:01,417][root][INFO] - Training Epoch: 1/2, step 1079/7134 completed (loss: 4.2985758781433105, acc: 0.23963133990764618)
[2024-12-17 01:39:01,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:01,737][root][INFO] - Training Epoch: 1/2, step 1080/7134 completed (loss: 4.237266540527344, acc: 0.302325576543808)
[2024-12-17 01:39:01,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:02,007][root][INFO] - Training Epoch: 1/2, step 1081/7134 completed (loss: 3.7962613105773926, acc: 0.29518070816993713)
[2024-12-17 01:39:02,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:02,342][root][INFO] - Training Epoch: 1/2, step 1082/7134 completed (loss: 3.0261881351470947, acc: 0.43497759103775024)
[2024-12-17 01:39:02,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:02,644][root][INFO] - Training Epoch: 1/2, step 1083/7134 completed (loss: 4.2255330085754395, acc: 0.2588832378387451)
[2024-12-17 01:39:02,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:02,932][root][INFO] - Training Epoch: 1/2, step 1084/7134 completed (loss: 3.3659884929656982, acc: 0.3510638177394867)
[2024-12-17 01:39:03,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:03,212][root][INFO] - Training Epoch: 1/2, step 1085/7134 completed (loss: 3.9596400260925293, acc: 0.3207547068595886)
[2024-12-17 01:39:03,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:03,481][root][INFO] - Training Epoch: 1/2, step 1086/7134 completed (loss: 4.384987831115723, acc: 0.32258063554763794)
[2024-12-17 01:39:03,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:03,777][root][INFO] - Training Epoch: 1/2, step 1087/7134 completed (loss: 3.7422685623168945, acc: 0.3172042965888977)
[2024-12-17 01:39:03,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:04,085][root][INFO] - Training Epoch: 1/2, step 1088/7134 completed (loss: 3.647686004638672, acc: 0.3068181872367859)
[2024-12-17 01:39:04,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:04,371][root][INFO] - Training Epoch: 1/2, step 1089/7134 completed (loss: 4.027551174163818, acc: 0.33742332458496094)
[2024-12-17 01:39:04,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:04,682][root][INFO] - Training Epoch: 1/2, step 1090/7134 completed (loss: 3.7472996711730957, acc: 0.375)
[2024-12-17 01:39:04,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:04,980][root][INFO] - Training Epoch: 1/2, step 1091/7134 completed (loss: 3.7417216300964355, acc: 0.35403725504875183)
[2024-12-17 01:39:05,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:05,260][root][INFO] - Training Epoch: 1/2, step 1092/7134 completed (loss: 3.7597925662994385, acc: 0.3053892254829407)
[2024-12-17 01:39:05,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:05,544][root][INFO] - Training Epoch: 1/2, step 1093/7134 completed (loss: 3.6524081230163574, acc: 0.3877550959587097)
[2024-12-17 01:39:05,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:05,832][root][INFO] - Training Epoch: 1/2, step 1094/7134 completed (loss: 4.124917030334473, acc: 0.308270663022995)
[2024-12-17 01:39:06,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:06,206][root][INFO] - Training Epoch: 1/2, step 1095/7134 completed (loss: 3.9646379947662354, acc: 0.3174603283405304)
[2024-12-17 01:39:06,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:06,494][root][INFO] - Training Epoch: 1/2, step 1096/7134 completed (loss: 3.996026039123535, acc: 0.2634408473968506)
[2024-12-17 01:39:06,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:06,791][root][INFO] - Training Epoch: 1/2, step 1097/7134 completed (loss: 4.424931049346924, acc: 0.24043716490268707)
[2024-12-17 01:39:06,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:07,091][root][INFO] - Training Epoch: 1/2, step 1098/7134 completed (loss: 4.347788333892822, acc: 0.24444444477558136)
[2024-12-17 01:39:07,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:07,379][root][INFO] - Training Epoch: 1/2, step 1099/7134 completed (loss: 3.7918694019317627, acc: 0.3229166567325592)
[2024-12-17 01:39:07,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:07,708][root][INFO] - Training Epoch: 1/2, step 1100/7134 completed (loss: 4.124005317687988, acc: 0.30994153022766113)
[2024-12-17 01:39:07,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:07,997][root][INFO] - Training Epoch: 1/2, step 1101/7134 completed (loss: 3.891892910003662, acc: 0.3076923191547394)
[2024-12-17 01:39:08,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:08,283][root][INFO] - Training Epoch: 1/2, step 1102/7134 completed (loss: 4.020488739013672, acc: 0.2847222089767456)
[2024-12-17 01:39:08,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:08,591][root][INFO] - Training Epoch: 1/2, step 1103/7134 completed (loss: 4.225749492645264, acc: 0.3154761791229248)
[2024-12-17 01:39:08,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:08,873][root][INFO] - Training Epoch: 1/2, step 1104/7134 completed (loss: 4.177637100219727, acc: 0.30666667222976685)
[2024-12-17 01:39:09,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:09,185][root][INFO] - Training Epoch: 1/2, step 1105/7134 completed (loss: 4.04107666015625, acc: 0.2530864179134369)
[2024-12-17 01:39:09,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:09,531][root][INFO] - Training Epoch: 1/2, step 1106/7134 completed (loss: 3.960777521133423, acc: 0.25827813148498535)
[2024-12-17 01:39:09,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:09,824][root][INFO] - Training Epoch: 1/2, step 1107/7134 completed (loss: 3.8583600521087646, acc: 0.25)
[2024-12-17 01:39:09,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:10,103][root][INFO] - Training Epoch: 1/2, step 1108/7134 completed (loss: 3.539724588394165, acc: 0.3491124212741852)
[2024-12-17 01:39:10,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:10,432][root][INFO] - Training Epoch: 1/2, step 1109/7134 completed (loss: 3.8217837810516357, acc: 0.31213873624801636)
[2024-12-17 01:39:10,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:10,728][root][INFO] - Training Epoch: 1/2, step 1110/7134 completed (loss: 3.9591169357299805, acc: 0.2795698940753937)
[2024-12-17 01:39:10,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:11,022][root][INFO] - Training Epoch: 1/2, step 1111/7134 completed (loss: 4.006427764892578, acc: 0.3062500059604645)
[2024-12-17 01:39:11,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:11,320][root][INFO] - Training Epoch: 1/2, step 1112/7134 completed (loss: 3.8354909420013428, acc: 0.3216783106327057)
[2024-12-17 01:39:11,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:11,625][root][INFO] - Training Epoch: 1/2, step 1113/7134 completed (loss: 4.270031452178955, acc: 0.276729553937912)
[2024-12-17 01:39:11,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:11,954][root][INFO] - Training Epoch: 1/2, step 1114/7134 completed (loss: 4.107006549835205, acc: 0.30687829852104187)
[2024-12-17 01:39:12,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:12,234][root][INFO] - Training Epoch: 1/2, step 1115/7134 completed (loss: 4.340484142303467, acc: 0.25806450843811035)
[2024-12-17 01:39:12,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:12,506][root][INFO] - Training Epoch: 1/2, step 1116/7134 completed (loss: 3.891697406768799, acc: 0.26829269528388977)
[2024-12-17 01:39:12,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:12,786][root][INFO] - Training Epoch: 1/2, step 1117/7134 completed (loss: 3.223060131072998, acc: 0.4013157784938812)
[2024-12-17 01:39:12,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:13,054][root][INFO] - Training Epoch: 1/2, step 1118/7134 completed (loss: 3.8980672359466553, acc: 0.21374045312404633)
[2024-12-17 01:39:13,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:13,371][root][INFO] - Training Epoch: 1/2, step 1119/7134 completed (loss: 3.3817484378814697, acc: 0.29655173420906067)
[2024-12-17 01:39:13,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:13,664][root][INFO] - Training Epoch: 1/2, step 1120/7134 completed (loss: 4.317587852478027, acc: 0.22900763154029846)
[2024-12-17 01:39:13,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:13,963][root][INFO] - Training Epoch: 1/2, step 1121/7134 completed (loss: 3.4868884086608887, acc: 0.34193548560142517)
[2024-12-17 01:39:14,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:14,232][root][INFO] - Training Epoch: 1/2, step 1122/7134 completed (loss: 3.2868523597717285, acc: 0.32307693362236023)
[2024-12-17 01:39:14,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:14,554][root][INFO] - Training Epoch: 1/2, step 1123/7134 completed (loss: 3.9728152751922607, acc: 0.2896551787853241)
[2024-12-17 01:39:14,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:14,849][root][INFO] - Training Epoch: 1/2, step 1124/7134 completed (loss: 4.141322135925293, acc: 0.2567567527294159)
[2024-12-17 01:39:14,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:15,133][root][INFO] - Training Epoch: 1/2, step 1125/7134 completed (loss: 3.913905143737793, acc: 0.2142857164144516)
[2024-12-17 01:39:15,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:15,432][root][INFO] - Training Epoch: 1/2, step 1126/7134 completed (loss: 3.6233792304992676, acc: 0.3314606845378876)
[2024-12-17 01:39:15,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:15,717][root][INFO] - Training Epoch: 1/2, step 1127/7134 completed (loss: 4.248748302459717, acc: 0.23529411852359772)
[2024-12-17 01:39:15,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:15,998][root][INFO] - Training Epoch: 1/2, step 1128/7134 completed (loss: 4.243132591247559, acc: 0.2671755850315094)
[2024-12-17 01:39:16,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:16,278][root][INFO] - Training Epoch: 1/2, step 1129/7134 completed (loss: 4.019713401794434, acc: 0.2916666567325592)
[2024-12-17 01:39:16,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:16,552][root][INFO] - Training Epoch: 1/2, step 1130/7134 completed (loss: 3.650319814682007, acc: 0.3381294906139374)
[2024-12-17 01:39:16,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:16,850][root][INFO] - Training Epoch: 1/2, step 1131/7134 completed (loss: 3.547914981842041, acc: 0.3232323229312897)
[2024-12-17 01:39:16,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:17,124][root][INFO] - Training Epoch: 1/2, step 1132/7134 completed (loss: 4.4947381019592285, acc: 0.28859061002731323)
[2024-12-17 01:39:17,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:17,420][root][INFO] - Training Epoch: 1/2, step 1133/7134 completed (loss: 4.1731276512146, acc: 0.27167630195617676)
[2024-12-17 01:39:17,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:17,703][root][INFO] - Training Epoch: 1/2, step 1134/7134 completed (loss: 4.232275009155273, acc: 0.2527472674846649)
[2024-12-17 01:39:17,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:18,053][root][INFO] - Training Epoch: 1/2, step 1135/7134 completed (loss: 4.172329425811768, acc: 0.23489932715892792)
[2024-12-17 01:39:18,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:18,379][root][INFO] - Training Epoch: 1/2, step 1136/7134 completed (loss: 4.281824111938477, acc: 0.30612245202064514)
[2024-12-17 01:39:18,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:18,641][root][INFO] - Training Epoch: 1/2, step 1137/7134 completed (loss: 4.676966190338135, acc: 0.22641509771347046)
[2024-12-17 01:39:18,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:18,978][root][INFO] - Training Epoch: 1/2, step 1138/7134 completed (loss: 4.147775173187256, acc: 0.2549999952316284)
[2024-12-17 01:39:19,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:19,273][root][INFO] - Training Epoch: 1/2, step 1139/7134 completed (loss: 4.453452110290527, acc: 0.2637362778186798)
[2024-12-17 01:39:19,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:19,584][root][INFO] - Training Epoch: 1/2, step 1140/7134 completed (loss: 3.902250051498413, acc: 0.23157894611358643)
[2024-12-17 01:39:19,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:19,868][root][INFO] - Training Epoch: 1/2, step 1141/7134 completed (loss: 3.898223876953125, acc: 0.290909081697464)
[2024-12-17 01:39:19,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:20,155][root][INFO] - Training Epoch: 1/2, step 1142/7134 completed (loss: 3.6599762439727783, acc: 0.3055555522441864)
[2024-12-17 01:39:20,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:20,459][root][INFO] - Training Epoch: 1/2, step 1143/7134 completed (loss: 4.076125621795654, acc: 0.3132530152797699)
[2024-12-17 01:39:20,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:20,737][root][INFO] - Training Epoch: 1/2, step 1144/7134 completed (loss: 4.2129693031311035, acc: 0.3154761791229248)
[2024-12-17 01:39:20,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:21,036][root][INFO] - Training Epoch: 1/2, step 1145/7134 completed (loss: 4.082377910614014, acc: 0.2849161922931671)
[2024-12-17 01:39:21,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:21,320][root][INFO] - Training Epoch: 1/2, step 1146/7134 completed (loss: 3.5374269485473633, acc: 0.34090909361839294)
[2024-12-17 01:39:21,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:21,621][root][INFO] - Training Epoch: 1/2, step 1147/7134 completed (loss: 3.7765204906463623, acc: 0.3027026951313019)
[2024-12-17 01:39:21,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:21,909][root][INFO] - Training Epoch: 1/2, step 1148/7134 completed (loss: 3.63045334815979, acc: 0.316546767950058)
[2024-12-17 01:39:22,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:22,203][root][INFO] - Training Epoch: 1/2, step 1149/7134 completed (loss: 4.120601177215576, acc: 0.3194444477558136)
[2024-12-17 01:39:22,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:22,496][root][INFO] - Training Epoch: 1/2, step 1150/7134 completed (loss: 4.191971302032471, acc: 0.30718955397605896)
[2024-12-17 01:39:22,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:22,823][root][INFO] - Training Epoch: 1/2, step 1151/7134 completed (loss: 4.060210704803467, acc: 0.31092438101768494)
[2024-12-17 01:39:22,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:23,112][root][INFO] - Training Epoch: 1/2, step 1152/7134 completed (loss: 4.060495853424072, acc: 0.2822580635547638)
[2024-12-17 01:39:23,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:23,391][root][INFO] - Training Epoch: 1/2, step 1153/7134 completed (loss: 4.282299995422363, acc: 0.24183006584644318)
[2024-12-17 01:39:23,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:23,686][root][INFO] - Training Epoch: 1/2, step 1154/7134 completed (loss: 3.8262622356414795, acc: 0.3515625)
[2024-12-17 01:39:23,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:23,962][root][INFO] - Training Epoch: 1/2, step 1155/7134 completed (loss: 4.332688331604004, acc: 0.28205129504203796)
[2024-12-17 01:39:24,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:24,238][root][INFO] - Training Epoch: 1/2, step 1156/7134 completed (loss: 4.30139684677124, acc: 0.27272728085517883)
[2024-12-17 01:39:24,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:24,522][root][INFO] - Training Epoch: 1/2, step 1157/7134 completed (loss: 3.916682720184326, acc: 0.29655173420906067)
[2024-12-17 01:39:24,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:24,826][root][INFO] - Training Epoch: 1/2, step 1158/7134 completed (loss: 4.258807182312012, acc: 0.24347825348377228)
[2024-12-17 01:39:24,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:25,128][root][INFO] - Training Epoch: 1/2, step 1159/7134 completed (loss: 4.066572666168213, acc: 0.24550898373126984)
[2024-12-17 01:39:25,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:25,434][root][INFO] - Training Epoch: 1/2, step 1160/7134 completed (loss: 3.5772769451141357, acc: 0.3333333432674408)
[2024-12-17 01:39:25,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:25,733][root][INFO] - Training Epoch: 1/2, step 1161/7134 completed (loss: 3.75451397895813, acc: 0.3333333432674408)
[2024-12-17 01:39:25,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:26,041][root][INFO] - Training Epoch: 1/2, step 1162/7134 completed (loss: 3.941660165786743, acc: 0.297468364238739)
[2024-12-17 01:39:26,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:26,330][root][INFO] - Training Epoch: 1/2, step 1163/7134 completed (loss: 3.5972609519958496, acc: 0.317241370677948)
[2024-12-17 01:39:26,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:26,639][root][INFO] - Training Epoch: 1/2, step 1164/7134 completed (loss: 3.5068814754486084, acc: 0.31491711735725403)
[2024-12-17 01:39:26,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:26,952][root][INFO] - Training Epoch: 1/2, step 1165/7134 completed (loss: 3.621838331222534, acc: 0.2974359095096588)
[2024-12-17 01:39:27,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:27,231][root][INFO] - Training Epoch: 1/2, step 1166/7134 completed (loss: 3.6788647174835205, acc: 0.3085106313228607)
[2024-12-17 01:39:27,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:27,512][root][INFO] - Training Epoch: 1/2, step 1167/7134 completed (loss: 4.265740394592285, acc: 0.20000000298023224)
[2024-12-17 01:39:27,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:27,863][root][INFO] - Training Epoch: 1/2, step 1168/7134 completed (loss: 3.8424673080444336, acc: 0.2539682686328888)
[2024-12-17 01:39:27,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:28,152][root][INFO] - Training Epoch: 1/2, step 1169/7134 completed (loss: 4.019518852233887, acc: 0.3191489279270172)
[2024-12-17 01:39:28,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:28,469][root][INFO] - Training Epoch: 1/2, step 1170/7134 completed (loss: 4.004044055938721, acc: 0.2542372941970825)
[2024-12-17 01:39:28,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:28,761][root][INFO] - Training Epoch: 1/2, step 1171/7134 completed (loss: 4.562910079956055, acc: 0.2866666615009308)
[2024-12-17 01:39:28,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:29,043][root][INFO] - Training Epoch: 1/2, step 1172/7134 completed (loss: 4.053301811218262, acc: 0.255952388048172)
[2024-12-17 01:39:29,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:29,328][root][INFO] - Training Epoch: 1/2, step 1173/7134 completed (loss: 4.059906959533691, acc: 0.23280423879623413)
[2024-12-17 01:39:29,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:29,636][root][INFO] - Training Epoch: 1/2, step 1174/7134 completed (loss: 3.648956537246704, acc: 0.2760736048221588)
[2024-12-17 01:39:29,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:29,955][root][INFO] - Training Epoch: 1/2, step 1175/7134 completed (loss: 4.2369608879089355, acc: 0.2647058963775635)
[2024-12-17 01:39:30,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:30,234][root][INFO] - Training Epoch: 1/2, step 1176/7134 completed (loss: 3.9584858417510986, acc: 0.2569444477558136)
[2024-12-17 01:39:30,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:30,505][root][INFO] - Training Epoch: 1/2, step 1177/7134 completed (loss: 3.833026885986328, acc: 0.26153847575187683)
[2024-12-17 01:39:30,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:30,800][root][INFO] - Training Epoch: 1/2, step 1178/7134 completed (loss: 4.165773391723633, acc: 0.21153846383094788)
[2024-12-17 01:39:30,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:31,081][root][INFO] - Training Epoch: 1/2, step 1179/7134 completed (loss: 4.276904106140137, acc: 0.24193547666072845)
[2024-12-17 01:39:31,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:31,379][root][INFO] - Training Epoch: 1/2, step 1180/7134 completed (loss: 3.900240182876587, acc: 0.25)
[2024-12-17 01:39:31,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:31,657][root][INFO] - Training Epoch: 1/2, step 1181/7134 completed (loss: 3.8880934715270996, acc: 0.26923078298568726)
[2024-12-17 01:39:31,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:31,915][root][INFO] - Training Epoch: 1/2, step 1182/7134 completed (loss: 4.208083152770996, acc: 0.25850340723991394)
[2024-12-17 01:39:32,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:32,198][root][INFO] - Training Epoch: 1/2, step 1183/7134 completed (loss: 3.83711838722229, acc: 0.2543352544307709)
[2024-12-17 01:39:32,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:32,482][root][INFO] - Training Epoch: 1/2, step 1184/7134 completed (loss: 3.7627851963043213, acc: 0.2543352544307709)
[2024-12-17 01:39:32,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:32,800][root][INFO] - Training Epoch: 1/2, step 1185/7134 completed (loss: 3.7175421714782715, acc: 0.27272728085517883)
[2024-12-17 01:39:32,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:33,078][root][INFO] - Training Epoch: 1/2, step 1186/7134 completed (loss: 3.5240204334259033, acc: 0.29347825050354004)
[2024-12-17 01:39:33,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:33,364][root][INFO] - Training Epoch: 1/2, step 1187/7134 completed (loss: 3.9743449687957764, acc: 0.25)
[2024-12-17 01:39:33,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:33,640][root][INFO] - Training Epoch: 1/2, step 1188/7134 completed (loss: 3.9235289096832275, acc: 0.2634408473968506)
[2024-12-17 01:39:33,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:33,916][root][INFO] - Training Epoch: 1/2, step 1189/7134 completed (loss: 3.6495656967163086, acc: 0.3195266127586365)
[2024-12-17 01:39:34,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:34,225][root][INFO] - Training Epoch: 1/2, step 1190/7134 completed (loss: 3.943171977996826, acc: 0.3222222328186035)
[2024-12-17 01:39:34,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:34,533][root][INFO] - Training Epoch: 1/2, step 1191/7134 completed (loss: 3.586747884750366, acc: 0.3265306055545807)
[2024-12-17 01:39:34,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:34,846][root][INFO] - Training Epoch: 1/2, step 1192/7134 completed (loss: 4.270730972290039, acc: 0.23308271169662476)
[2024-12-17 01:39:34,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:35,128][root][INFO] - Training Epoch: 1/2, step 1193/7134 completed (loss: 4.467152118682861, acc: 0.22834645211696625)
[2024-12-17 01:39:35,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:35,409][root][INFO] - Training Epoch: 1/2, step 1194/7134 completed (loss: 3.731943130493164, acc: 0.30201342701911926)
[2024-12-17 01:39:35,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:35,692][root][INFO] - Training Epoch: 1/2, step 1195/7134 completed (loss: 4.166441917419434, acc: 0.33076924085617065)
[2024-12-17 01:39:35,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:35,981][root][INFO] - Training Epoch: 1/2, step 1196/7134 completed (loss: 3.73274302482605, acc: 0.3191489279270172)
[2024-12-17 01:39:36,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:36,258][root][INFO] - Training Epoch: 1/2, step 1197/7134 completed (loss: 3.608936071395874, acc: 0.3219178020954132)
[2024-12-17 01:39:36,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:36,532][root][INFO] - Training Epoch: 1/2, step 1198/7134 completed (loss: 3.633227825164795, acc: 0.33125001192092896)
[2024-12-17 01:39:36,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:36,861][root][INFO] - Training Epoch: 1/2, step 1199/7134 completed (loss: 3.4184110164642334, acc: 0.37662336230278015)
[2024-12-17 01:39:36,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:37,157][root][INFO] - Training Epoch: 1/2, step 1200/7134 completed (loss: 3.5699706077575684, acc: 0.38317757844924927)
[2024-12-17 01:39:37,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:37,455][root][INFO] - Training Epoch: 1/2, step 1201/7134 completed (loss: 4.235982418060303, acc: 0.30817610025405884)
[2024-12-17 01:39:37,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:37,755][root][INFO] - Training Epoch: 1/2, step 1202/7134 completed (loss: 4.129342555999756, acc: 0.34239131212234497)
[2024-12-17 01:39:37,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:38,020][root][INFO] - Training Epoch: 1/2, step 1203/7134 completed (loss: 4.6347856521606445, acc: 0.20666666328907013)
[2024-12-17 01:39:38,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:38,293][root][INFO] - Training Epoch: 1/2, step 1204/7134 completed (loss: 4.1585283279418945, acc: 0.25)
[2024-12-17 01:39:38,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:38,588][root][INFO] - Training Epoch: 1/2, step 1205/7134 completed (loss: 4.163575172424316, acc: 0.2816092073917389)
[2024-12-17 01:39:38,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:38,877][root][INFO] - Training Epoch: 1/2, step 1206/7134 completed (loss: 4.269384860992432, acc: 0.2613065242767334)
[2024-12-17 01:39:39,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:39,167][root][INFO] - Training Epoch: 1/2, step 1207/7134 completed (loss: 4.10390567779541, acc: 0.30645161867141724)
[2024-12-17 01:39:39,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:39,475][root][INFO] - Training Epoch: 1/2, step 1208/7134 completed (loss: 4.547548294067383, acc: 0.2442748099565506)
[2024-12-17 01:39:39,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:39,757][root][INFO] - Training Epoch: 1/2, step 1209/7134 completed (loss: 4.363848686218262, acc: 0.28688523173332214)
[2024-12-17 01:39:39,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:40,045][root][INFO] - Training Epoch: 1/2, step 1210/7134 completed (loss: 4.429139614105225, acc: 0.35333332419395447)
[2024-12-17 01:39:40,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:40,335][root][INFO] - Training Epoch: 1/2, step 1211/7134 completed (loss: 4.452486038208008, acc: 0.3381294906139374)
[2024-12-17 01:39:40,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:40,611][root][INFO] - Training Epoch: 1/2, step 1212/7134 completed (loss: 4.919613361358643, acc: 0.32846716046333313)
[2024-12-17 01:39:40,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:40,894][root][INFO] - Training Epoch: 1/2, step 1213/7134 completed (loss: 4.208431720733643, acc: 0.28994083404541016)
[2024-12-17 01:39:41,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:41,170][root][INFO] - Training Epoch: 1/2, step 1214/7134 completed (loss: 4.64763069152832, acc: 0.23333333432674408)
[2024-12-17 01:39:41,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:41,451][root][INFO] - Training Epoch: 1/2, step 1215/7134 completed (loss: 4.542788982391357, acc: 0.2764706015586853)
[2024-12-17 01:39:41,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:41,728][root][INFO] - Training Epoch: 1/2, step 1216/7134 completed (loss: 4.303901195526123, acc: 0.29139071702957153)
[2024-12-17 01:39:41,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:42,033][root][INFO] - Training Epoch: 1/2, step 1217/7134 completed (loss: 4.101349830627441, acc: 0.25)
[2024-12-17 01:39:42,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:42,323][root][INFO] - Training Epoch: 1/2, step 1218/7134 completed (loss: 4.251528739929199, acc: 0.25)
[2024-12-17 01:39:42,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:42,613][root][INFO] - Training Epoch: 1/2, step 1219/7134 completed (loss: 4.546655178070068, acc: 0.2666666805744171)
[2024-12-17 01:39:42,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:42,909][root][INFO] - Training Epoch: 1/2, step 1220/7134 completed (loss: 4.4669189453125, acc: 0.2319587618112564)
[2024-12-17 01:39:43,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:43,198][root][INFO] - Training Epoch: 1/2, step 1221/7134 completed (loss: 4.596591472625732, acc: 0.24886877834796906)
[2024-12-17 01:39:43,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:43,477][root][INFO] - Training Epoch: 1/2, step 1222/7134 completed (loss: 4.698989391326904, acc: 0.27184465527534485)
[2024-12-17 01:39:43,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:43,775][root][INFO] - Training Epoch: 1/2, step 1223/7134 completed (loss: 5.109991073608398, acc: 0.14772726595401764)
[2024-12-17 01:39:43,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:44,070][root][INFO] - Training Epoch: 1/2, step 1224/7134 completed (loss: 4.542159557342529, acc: 0.12264151126146317)
[2024-12-17 01:39:44,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:44,366][root][INFO] - Training Epoch: 1/2, step 1225/7134 completed (loss: 4.1384406089782715, acc: 0.27397260069847107)
[2024-12-17 01:39:44,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:44,650][root][INFO] - Training Epoch: 1/2, step 1226/7134 completed (loss: 4.647188663482666, acc: 0.2142857164144516)
[2024-12-17 01:39:44,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:44,924][root][INFO] - Training Epoch: 1/2, step 1227/7134 completed (loss: 4.654021739959717, acc: 0.2886597812175751)
[2024-12-17 01:39:45,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:45,199][root][INFO] - Training Epoch: 1/2, step 1228/7134 completed (loss: 4.603287696838379, acc: 0.20930232107639313)
[2024-12-17 01:39:45,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:45,493][root][INFO] - Training Epoch: 1/2, step 1229/7134 completed (loss: 4.590879917144775, acc: 0.2772277295589447)
[2024-12-17 01:39:45,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:45,783][root][INFO] - Training Epoch: 1/2, step 1230/7134 completed (loss: 4.41626501083374, acc: 0.25)
[2024-12-17 01:39:45,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:46,132][root][INFO] - Training Epoch: 1/2, step 1231/7134 completed (loss: 4.6217875480651855, acc: 0.21551723778247833)
[2024-12-17 01:39:46,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:46,433][root][INFO] - Training Epoch: 1/2, step 1232/7134 completed (loss: 4.390995502471924, acc: 0.25112107396125793)
[2024-12-17 01:39:46,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:46,724][root][INFO] - Training Epoch: 1/2, step 1233/7134 completed (loss: 4.232083797454834, acc: 0.3031674325466156)
[2024-12-17 01:39:46,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:47,053][root][INFO] - Training Epoch: 1/2, step 1234/7134 completed (loss: 4.587735176086426, acc: 0.24358974397182465)
[2024-12-17 01:39:47,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:47,339][root][INFO] - Training Epoch: 1/2, step 1235/7134 completed (loss: 4.393148422241211, acc: 0.26530611515045166)
[2024-12-17 01:39:47,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:47,613][root][INFO] - Training Epoch: 1/2, step 1236/7134 completed (loss: 4.760371685028076, acc: 0.2294117659330368)
[2024-12-17 01:39:47,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:47,894][root][INFO] - Training Epoch: 1/2, step 1237/7134 completed (loss: 3.911250352859497, acc: 0.251655638217926)
[2024-12-17 01:39:48,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:48,176][root][INFO] - Training Epoch: 1/2, step 1238/7134 completed (loss: 4.4525346755981445, acc: 0.33023256063461304)
[2024-12-17 01:39:48,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:48,466][root][INFO] - Training Epoch: 1/2, step 1239/7134 completed (loss: 4.414961814880371, acc: 0.26829269528388977)
[2024-12-17 01:39:48,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:48,750][root][INFO] - Training Epoch: 1/2, step 1240/7134 completed (loss: 4.592511177062988, acc: 0.24418604373931885)
[2024-12-17 01:39:48,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:49,026][root][INFO] - Training Epoch: 1/2, step 1241/7134 completed (loss: 5.295055389404297, acc: 0.2295081913471222)
[2024-12-17 01:39:49,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:49,325][root][INFO] - Training Epoch: 1/2, step 1242/7134 completed (loss: 4.549835681915283, acc: 0.2565445005893707)
[2024-12-17 01:39:49,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:49,640][root][INFO] - Training Epoch: 1/2, step 1243/7134 completed (loss: 4.342301845550537, acc: 0.26754385232925415)
[2024-12-17 01:39:49,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:49,945][root][INFO] - Training Epoch: 1/2, step 1244/7134 completed (loss: 5.06174373626709, acc: 0.21830986440181732)
[2024-12-17 01:39:50,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:50,233][root][INFO] - Training Epoch: 1/2, step 1245/7134 completed (loss: 4.6023149490356445, acc: 0.22727273404598236)
[2024-12-17 01:39:50,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:50,535][root][INFO] - Training Epoch: 1/2, step 1246/7134 completed (loss: 4.664756774902344, acc: 0.24210526049137115)
[2024-12-17 01:39:50,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:50,837][root][INFO] - Training Epoch: 1/2, step 1247/7134 completed (loss: 4.43621826171875, acc: 0.27710843086242676)
[2024-12-17 01:39:50,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:51,119][root][INFO] - Training Epoch: 1/2, step 1248/7134 completed (loss: 4.657764434814453, acc: 0.28999999165534973)
[2024-12-17 01:39:51,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:51,425][root][INFO] - Training Epoch: 1/2, step 1249/7134 completed (loss: 4.246323108673096, acc: 0.27586206793785095)
[2024-12-17 01:39:51,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:51,697][root][INFO] - Training Epoch: 1/2, step 1250/7134 completed (loss: 3.837939977645874, acc: 0.2866666615009308)
[2024-12-17 01:39:51,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:51,998][root][INFO] - Training Epoch: 1/2, step 1251/7134 completed (loss: 4.186753749847412, acc: 0.290909081697464)
[2024-12-17 01:39:52,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:52,280][root][INFO] - Training Epoch: 1/2, step 1252/7134 completed (loss: 4.613035202026367, acc: 0.24409449100494385)
[2024-12-17 01:39:52,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:52,588][root][INFO] - Training Epoch: 1/2, step 1253/7134 completed (loss: 4.109577178955078, acc: 0.36752137541770935)
[2024-12-17 01:39:52,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:52,885][root][INFO] - Training Epoch: 1/2, step 1254/7134 completed (loss: 4.076858043670654, acc: 0.36666667461395264)
[2024-12-17 01:39:53,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:53,181][root][INFO] - Training Epoch: 1/2, step 1255/7134 completed (loss: 4.154661655426025, acc: 0.2896551787853241)
[2024-12-17 01:39:53,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:53,476][root][INFO] - Training Epoch: 1/2, step 1256/7134 completed (loss: 4.148715496063232, acc: 0.28244274854660034)
[2024-12-17 01:39:53,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:53,764][root][INFO] - Training Epoch: 1/2, step 1257/7134 completed (loss: 3.9803578853607178, acc: 0.2977099120616913)
[2024-12-17 01:39:53,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:54,061][root][INFO] - Training Epoch: 1/2, step 1258/7134 completed (loss: 3.4526431560516357, acc: 0.3571428656578064)
[2024-12-17 01:39:54,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:54,367][root][INFO] - Training Epoch: 1/2, step 1259/7134 completed (loss: 3.948681354522705, acc: 0.3076923191547394)
[2024-12-17 01:39:54,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:54,654][root][INFO] - Training Epoch: 1/2, step 1260/7134 completed (loss: 4.092597484588623, acc: 0.28859061002731323)
[2024-12-17 01:39:54,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:54,976][root][INFO] - Training Epoch: 1/2, step 1261/7134 completed (loss: 4.040656089782715, acc: 0.2567567527294159)
[2024-12-17 01:39:55,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:55,256][root][INFO] - Training Epoch: 1/2, step 1262/7134 completed (loss: 3.756993532180786, acc: 0.22480620443820953)
[2024-12-17 01:39:55,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:55,546][root][INFO] - Training Epoch: 1/2, step 1263/7134 completed (loss: 3.570486545562744, acc: 0.32258063554763794)
[2024-12-17 01:39:55,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:55,873][root][INFO] - Training Epoch: 1/2, step 1264/7134 completed (loss: 4.237664699554443, acc: 0.25925925374031067)
[2024-12-17 01:39:56,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:56,186][root][INFO] - Training Epoch: 1/2, step 1265/7134 completed (loss: 3.5879404544830322, acc: 0.3142857253551483)
[2024-12-17 01:39:56,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:56,499][root][INFO] - Training Epoch: 1/2, step 1266/7134 completed (loss: 3.2237656116485596, acc: 0.3893129825592041)
[2024-12-17 01:39:56,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:56,791][root][INFO] - Training Epoch: 1/2, step 1267/7134 completed (loss: 3.8942182064056396, acc: 0.31168830394744873)
[2024-12-17 01:39:56,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:57,096][root][INFO] - Training Epoch: 1/2, step 1268/7134 completed (loss: 4.277909278869629, acc: 0.29629629850387573)
[2024-12-17 01:39:57,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:57,400][root][INFO] - Training Epoch: 1/2, step 1269/7134 completed (loss: 3.902303457260132, acc: 0.3181818127632141)
[2024-12-17 01:39:57,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:57,669][root][INFO] - Training Epoch: 1/2, step 1270/7134 completed (loss: 4.128690242767334, acc: 0.2876712381839752)
[2024-12-17 01:39:57,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:57,976][root][INFO] - Training Epoch: 1/2, step 1271/7134 completed (loss: 3.8229756355285645, acc: 0.32499998807907104)
[2024-12-17 01:39:58,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:58,321][root][INFO] - Training Epoch: 1/2, step 1272/7134 completed (loss: 3.7993624210357666, acc: 0.31446540355682373)
[2024-12-17 01:39:58,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:58,597][root][INFO] - Training Epoch: 1/2, step 1273/7134 completed (loss: 4.318982124328613, acc: 0.2666666805744171)
[2024-12-17 01:39:58,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:58,867][root][INFO] - Training Epoch: 1/2, step 1274/7134 completed (loss: 3.8382511138916016, acc: 0.3140496015548706)
[2024-12-17 01:39:58,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:59,136][root][INFO] - Training Epoch: 1/2, step 1275/7134 completed (loss: 3.8929593563079834, acc: 0.2956521809101105)
[2024-12-17 01:39:59,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:59,396][root][INFO] - Training Epoch: 1/2, step 1276/7134 completed (loss: 3.765324354171753, acc: 0.2651515007019043)
[2024-12-17 01:39:59,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:59,662][root][INFO] - Training Epoch: 1/2, step 1277/7134 completed (loss: 3.964468002319336, acc: 0.2887323796749115)
[2024-12-17 01:39:59,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:00,001][root][INFO] - Training Epoch: 1/2, step 1278/7134 completed (loss: 4.240276336669922, acc: 0.2874999940395355)
[2024-12-17 01:40:00,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:00,276][root][INFO] - Training Epoch: 1/2, step 1279/7134 completed (loss: 3.774217128753662, acc: 0.29891303181648254)
[2024-12-17 01:40:00,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:00,551][root][INFO] - Training Epoch: 1/2, step 1280/7134 completed (loss: 3.9001612663269043, acc: 0.28342247009277344)
[2024-12-17 01:40:00,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:00,841][root][INFO] - Training Epoch: 1/2, step 1281/7134 completed (loss: 4.245307445526123, acc: 0.280303031206131)
[2024-12-17 01:40:00,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:01,138][root][INFO] - Training Epoch: 1/2, step 1282/7134 completed (loss: 4.051219940185547, acc: 0.2950819730758667)
[2024-12-17 01:40:01,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:01,432][root][INFO] - Training Epoch: 1/2, step 1283/7134 completed (loss: 4.0972900390625, acc: 0.302325576543808)
[2024-12-17 01:40:01,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:01,723][root][INFO] - Training Epoch: 1/2, step 1284/7134 completed (loss: 4.205558776855469, acc: 0.23952095210552216)
[2024-12-17 01:40:01,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:02,021][root][INFO] - Training Epoch: 1/2, step 1285/7134 completed (loss: 4.1276984214782715, acc: 0.21875)
[2024-12-17 01:40:02,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:02,306][root][INFO] - Training Epoch: 1/2, step 1286/7134 completed (loss: 3.86289644241333, acc: 0.35975611209869385)
[2024-12-17 01:40:02,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:02,589][root][INFO] - Training Epoch: 1/2, step 1287/7134 completed (loss: 4.239753723144531, acc: 0.32592591643333435)
[2024-12-17 01:40:02,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:02,858][root][INFO] - Training Epoch: 1/2, step 1288/7134 completed (loss: 3.9926400184631348, acc: 0.2849740982055664)
[2024-12-17 01:40:02,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:03,133][root][INFO] - Training Epoch: 1/2, step 1289/7134 completed (loss: 3.986769199371338, acc: 0.29655173420906067)
[2024-12-17 01:40:03,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:03,407][root][INFO] - Training Epoch: 1/2, step 1290/7134 completed (loss: 3.8024230003356934, acc: 0.28143712878227234)
[2024-12-17 01:40:03,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:03,764][root][INFO] - Training Epoch: 1/2, step 1291/7134 completed (loss: 3.630000591278076, acc: 0.3235294222831726)
[2024-12-17 01:40:03,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:04,061][root][INFO] - Training Epoch: 1/2, step 1292/7134 completed (loss: 3.9978694915771484, acc: 0.3241758346557617)
[2024-12-17 01:40:04,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:04,343][root][INFO] - Training Epoch: 1/2, step 1293/7134 completed (loss: 4.513522148132324, acc: 0.2153846174478531)
[2024-12-17 01:40:04,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:04,627][root][INFO] - Training Epoch: 1/2, step 1294/7134 completed (loss: 4.134249210357666, acc: 0.2568306028842926)
[2024-12-17 01:40:04,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:04,914][root][INFO] - Training Epoch: 1/2, step 1295/7134 completed (loss: 4.318212509155273, acc: 0.2537313401699066)
[2024-12-17 01:40:05,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:05,216][root][INFO] - Training Epoch: 1/2, step 1296/7134 completed (loss: 4.279240131378174, acc: 0.2211538404226303)
[2024-12-17 01:40:05,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:05,541][root][INFO] - Training Epoch: 1/2, step 1297/7134 completed (loss: 4.559353351593018, acc: 0.25)
[2024-12-17 01:40:05,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:05,823][root][INFO] - Training Epoch: 1/2, step 1298/7134 completed (loss: 4.335789203643799, acc: 0.23140496015548706)
[2024-12-17 01:40:05,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:06,108][root][INFO] - Training Epoch: 1/2, step 1299/7134 completed (loss: 4.126669406890869, acc: 0.3012048304080963)
[2024-12-17 01:40:06,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:06,447][root][INFO] - Training Epoch: 1/2, step 1300/7134 completed (loss: 4.007154941558838, acc: 0.2326732724905014)
[2024-12-17 01:40:06,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:06,721][root][INFO] - Training Epoch: 1/2, step 1301/7134 completed (loss: 4.035073280334473, acc: 0.25)
[2024-12-17 01:40:06,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:07,007][root][INFO] - Training Epoch: 1/2, step 1302/7134 completed (loss: 3.53981614112854, acc: 0.3316831588745117)
[2024-12-17 01:40:07,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:07,291][root][INFO] - Training Epoch: 1/2, step 1303/7134 completed (loss: 3.9655768871307373, acc: 0.30000001192092896)
[2024-12-17 01:40:07,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:07,578][root][INFO] - Training Epoch: 1/2, step 1304/7134 completed (loss: 3.9489617347717285, acc: 0.2259887009859085)
[2024-12-17 01:40:07,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:07,876][root][INFO] - Training Epoch: 1/2, step 1305/7134 completed (loss: 4.066793918609619, acc: 0.2680412232875824)
[2024-12-17 01:40:08,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:08,225][root][INFO] - Training Epoch: 1/2, step 1306/7134 completed (loss: 4.204238414764404, acc: 0.31578946113586426)
[2024-12-17 01:40:08,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:08,528][root][INFO] - Training Epoch: 1/2, step 1307/7134 completed (loss: 3.924278974533081, acc: 0.28776979446411133)
[2024-12-17 01:40:08,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:08,822][root][INFO] - Training Epoch: 1/2, step 1308/7134 completed (loss: 4.1607794761657715, acc: 0.2451612949371338)
[2024-12-17 01:40:08,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:09,117][root][INFO] - Training Epoch: 1/2, step 1309/7134 completed (loss: 4.085546016693115, acc: 0.2995169162750244)
[2024-12-17 01:40:09,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:09,422][root][INFO] - Training Epoch: 1/2, step 1310/7134 completed (loss: 3.9671685695648193, acc: 0.3425414264202118)
[2024-12-17 01:40:09,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:09,734][root][INFO] - Training Epoch: 1/2, step 1311/7134 completed (loss: 4.025964736938477, acc: 0.26923078298568726)
[2024-12-17 01:40:09,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:10,038][root][INFO] - Training Epoch: 1/2, step 1312/7134 completed (loss: 4.089147567749023, acc: 0.2981366515159607)
[2024-12-17 01:40:10,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:10,342][root][INFO] - Training Epoch: 1/2, step 1313/7134 completed (loss: 3.8850111961364746, acc: 0.31481480598449707)
[2024-12-17 01:40:10,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:10,634][root][INFO] - Training Epoch: 1/2, step 1314/7134 completed (loss: 3.850447416305542, acc: 0.30434781312942505)
[2024-12-17 01:40:10,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:10,920][root][INFO] - Training Epoch: 1/2, step 1315/7134 completed (loss: 4.008518695831299, acc: 0.32972973585128784)
[2024-12-17 01:40:11,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:11,216][root][INFO] - Training Epoch: 1/2, step 1316/7134 completed (loss: 4.214206695556641, acc: 0.24390244483947754)
[2024-12-17 01:40:11,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:11,527][root][INFO] - Training Epoch: 1/2, step 1317/7134 completed (loss: 4.262510776519775, acc: 0.28358209133148193)
[2024-12-17 01:40:11,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:11,826][root][INFO] - Training Epoch: 1/2, step 1318/7134 completed (loss: 4.128586769104004, acc: 0.2857142984867096)
[2024-12-17 01:40:11,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:12,101][root][INFO] - Training Epoch: 1/2, step 1319/7134 completed (loss: 4.2167744636535645, acc: 0.290909081697464)
[2024-12-17 01:40:12,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:12,396][root][INFO] - Training Epoch: 1/2, step 1320/7134 completed (loss: 4.138493537902832, acc: 0.3245033025741577)
[2024-12-17 01:40:12,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:12,695][root][INFO] - Training Epoch: 1/2, step 1321/7134 completed (loss: 4.035253047943115, acc: 0.2953367829322815)
[2024-12-17 01:40:12,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:12,982][root][INFO] - Training Epoch: 1/2, step 1322/7134 completed (loss: 4.023583889007568, acc: 0.3333333432674408)
[2024-12-17 01:40:13,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:13,254][root][INFO] - Training Epoch: 1/2, step 1323/7134 completed (loss: 4.19489860534668, acc: 0.21830986440181732)
[2024-12-17 01:40:13,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:13,540][root][INFO] - Training Epoch: 1/2, step 1324/7134 completed (loss: 3.6023192405700684, acc: 0.30718955397605896)
[2024-12-17 01:40:13,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:13,829][root][INFO] - Training Epoch: 1/2, step 1325/7134 completed (loss: 4.314178943634033, acc: 0.25242719054222107)
[2024-12-17 01:40:13,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:14,125][root][INFO] - Training Epoch: 1/2, step 1326/7134 completed (loss: 3.6341733932495117, acc: 0.35159817337989807)
[2024-12-17 01:40:14,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:14,407][root][INFO] - Training Epoch: 1/2, step 1327/7134 completed (loss: 3.7014925479888916, acc: 0.2958579957485199)
[2024-12-17 01:40:14,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:14,692][root][INFO] - Training Epoch: 1/2, step 1328/7134 completed (loss: 4.497099876403809, acc: 0.21782177686691284)
[2024-12-17 01:40:14,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:14,973][root][INFO] - Training Epoch: 1/2, step 1329/7134 completed (loss: 4.033718109130859, acc: 0.3100000023841858)
[2024-12-17 01:40:15,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:15,246][root][INFO] - Training Epoch: 1/2, step 1330/7134 completed (loss: 3.9276504516601562, acc: 0.30215826630592346)
[2024-12-17 01:40:15,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:15,551][root][INFO] - Training Epoch: 1/2, step 1331/7134 completed (loss: 3.654794692993164, acc: 0.35211268067359924)
[2024-12-17 01:40:15,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:15,804][root][INFO] - Training Epoch: 1/2, step 1332/7134 completed (loss: 3.8678994178771973, acc: 0.28947368264198303)
[2024-12-17 01:40:15,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:16,091][root][INFO] - Training Epoch: 1/2, step 1333/7134 completed (loss: 4.370244026184082, acc: 0.25)
[2024-12-17 01:40:16,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:16,378][root][INFO] - Training Epoch: 1/2, step 1334/7134 completed (loss: 4.801428318023682, acc: 0.21604938805103302)
[2024-12-17 01:40:16,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:16,656][root][INFO] - Training Epoch: 1/2, step 1335/7134 completed (loss: 3.826172113418579, acc: 0.3298429250717163)
[2024-12-17 01:40:16,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:16,929][root][INFO] - Training Epoch: 1/2, step 1336/7134 completed (loss: 4.006141185760498, acc: 0.24064171314239502)
[2024-12-17 01:40:17,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:17,223][root][INFO] - Training Epoch: 1/2, step 1337/7134 completed (loss: 3.908783435821533, acc: 0.32258063554763794)
[2024-12-17 01:40:17,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:17,514][root][INFO] - Training Epoch: 1/2, step 1338/7134 completed (loss: 4.181127071380615, acc: 0.265625)
[2024-12-17 01:40:17,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:17,792][root][INFO] - Training Epoch: 1/2, step 1339/7134 completed (loss: 3.9621517658233643, acc: 0.3877550959587097)
[2024-12-17 01:40:17,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:18,055][root][INFO] - Training Epoch: 1/2, step 1340/7134 completed (loss: 4.5811944007873535, acc: 0.26623377203941345)
[2024-12-17 01:40:18,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:18,365][root][INFO] - Training Epoch: 1/2, step 1341/7134 completed (loss: 4.091132164001465, acc: 0.24175824224948883)
[2024-12-17 01:40:18,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:18,690][root][INFO] - Training Epoch: 1/2, step 1342/7134 completed (loss: 3.7394282817840576, acc: 0.29801324009895325)
[2024-12-17 01:40:18,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:18,981][root][INFO] - Training Epoch: 1/2, step 1343/7134 completed (loss: 4.4104228019714355, acc: 0.29411765933036804)
[2024-12-17 01:40:19,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:19,255][root][INFO] - Training Epoch: 1/2, step 1344/7134 completed (loss: 4.101454734802246, acc: 0.26605504751205444)
[2024-12-17 01:40:19,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:19,520][root][INFO] - Training Epoch: 1/2, step 1345/7134 completed (loss: 4.611056327819824, acc: 0.29032257199287415)
[2024-12-17 01:40:19,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:19,856][root][INFO] - Training Epoch: 1/2, step 1346/7134 completed (loss: 3.977569103240967, acc: 0.284153014421463)
[2024-12-17 01:40:19,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:20,130][root][INFO] - Training Epoch: 1/2, step 1347/7134 completed (loss: 3.940566062927246, acc: 0.2638888955116272)
[2024-12-17 01:40:20,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:20,421][root][INFO] - Training Epoch: 1/2, step 1348/7134 completed (loss: 3.6698901653289795, acc: 0.33701658248901367)
[2024-12-17 01:40:20,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:20,690][root][INFO] - Training Epoch: 1/2, step 1349/7134 completed (loss: 3.6476190090179443, acc: 0.3333333432674408)
[2024-12-17 01:40:20,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:20,953][root][INFO] - Training Epoch: 1/2, step 1350/7134 completed (loss: 3.6240110397338867, acc: 0.2514970004558563)
[2024-12-17 01:40:21,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:21,218][root][INFO] - Training Epoch: 1/2, step 1351/7134 completed (loss: 3.7053565979003906, acc: 0.3333333432674408)
[2024-12-17 01:40:21,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:21,489][root][INFO] - Training Epoch: 1/2, step 1352/7134 completed (loss: 3.8119704723358154, acc: 0.25)
[2024-12-17 01:40:21,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:21,782][root][INFO] - Training Epoch: 1/2, step 1353/7134 completed (loss: 3.620972156524658, acc: 0.32499998807907104)
[2024-12-17 01:40:21,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:22,065][root][INFO] - Training Epoch: 1/2, step 1354/7134 completed (loss: 3.627242088317871, acc: 0.2933333218097687)
[2024-12-17 01:40:22,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:22,322][root][INFO] - Training Epoch: 1/2, step 1355/7134 completed (loss: 3.310528039932251, acc: 0.35483869910240173)
[2024-12-17 01:40:22,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:22,615][root][INFO] - Training Epoch: 1/2, step 1356/7134 completed (loss: 3.409309148788452, acc: 0.31976744532585144)
[2024-12-17 01:40:22,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:22,898][root][INFO] - Training Epoch: 1/2, step 1357/7134 completed (loss: 3.5106608867645264, acc: 0.3174603283405304)
[2024-12-17 01:40:23,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:23,234][root][INFO] - Training Epoch: 1/2, step 1358/7134 completed (loss: 3.8371756076812744, acc: 0.23863635957241058)
[2024-12-17 01:40:23,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:23,515][root][INFO] - Training Epoch: 1/2, step 1359/7134 completed (loss: 3.3430612087249756, acc: 0.3471074402332306)
[2024-12-17 01:40:23,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:23,794][root][INFO] - Training Epoch: 1/2, step 1360/7134 completed (loss: 3.7394466400146484, acc: 0.261904776096344)
[2024-12-17 01:40:23,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:24,119][root][INFO] - Training Epoch: 1/2, step 1361/7134 completed (loss: 4.083076000213623, acc: 0.23076923191547394)
[2024-12-17 01:40:24,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:24,409][root][INFO] - Training Epoch: 1/2, step 1362/7134 completed (loss: 4.149165153503418, acc: 0.2786885201931)
[2024-12-17 01:40:24,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:24,728][root][INFO] - Training Epoch: 1/2, step 1363/7134 completed (loss: 3.836613893508911, acc: 0.2816092073917389)
[2024-12-17 01:40:24,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:25,015][root][INFO] - Training Epoch: 1/2, step 1364/7134 completed (loss: 3.827728748321533, acc: 0.24705882370471954)
[2024-12-17 01:40:25,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:25,292][root][INFO] - Training Epoch: 1/2, step 1365/7134 completed (loss: 3.7233097553253174, acc: 0.2888889014720917)
[2024-12-17 01:40:25,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:25,588][root][INFO] - Training Epoch: 1/2, step 1366/7134 completed (loss: 3.916196823120117, acc: 0.24390244483947754)
[2024-12-17 01:40:25,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:25,867][root][INFO] - Training Epoch: 1/2, step 1367/7134 completed (loss: 3.9204819202423096, acc: 0.2647058963775635)
[2024-12-17 01:40:25,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:26,158][root][INFO] - Training Epoch: 1/2, step 1368/7134 completed (loss: 3.90432071685791, acc: 0.3045977056026459)
[2024-12-17 01:40:26,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:26,438][root][INFO] - Training Epoch: 1/2, step 1369/7134 completed (loss: 3.6412911415100098, acc: 0.32846716046333313)
[2024-12-17 01:40:26,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:26,718][root][INFO] - Training Epoch: 1/2, step 1370/7134 completed (loss: 3.6663761138916016, acc: 0.30612245202064514)
[2024-12-17 01:40:26,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:27,008][root][INFO] - Training Epoch: 1/2, step 1371/7134 completed (loss: 3.4694108963012695, acc: 0.3086419701576233)
[2024-12-17 01:40:27,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:27,293][root][INFO] - Training Epoch: 1/2, step 1372/7134 completed (loss: 4.00881290435791, acc: 0.3030303120613098)
[2024-12-17 01:40:27,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:27,571][root][INFO] - Training Epoch: 1/2, step 1373/7134 completed (loss: 4.0472412109375, acc: 0.24806201457977295)
[2024-12-17 01:40:27,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:27,881][root][INFO] - Training Epoch: 1/2, step 1374/7134 completed (loss: 4.44439172744751, acc: 0.30000001192092896)
[2024-12-17 01:40:28,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:28,151][root][INFO] - Training Epoch: 1/2, step 1375/7134 completed (loss: 3.7760560512542725, acc: 0.29411765933036804)
[2024-12-17 01:40:28,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:28,454][root][INFO] - Training Epoch: 1/2, step 1376/7134 completed (loss: 4.690718650817871, acc: 0.2232142835855484)
[2024-12-17 01:40:28,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:28,745][root][INFO] - Training Epoch: 1/2, step 1377/7134 completed (loss: 4.404679775238037, acc: 0.28431373834609985)
[2024-12-17 01:40:28,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:29,001][root][INFO] - Training Epoch: 1/2, step 1378/7134 completed (loss: 4.646832466125488, acc: 0.26923078298568726)
[2024-12-17 01:40:29,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:29,292][root][INFO] - Training Epoch: 1/2, step 1379/7134 completed (loss: 4.432319641113281, acc: 0.2871287167072296)
[2024-12-17 01:40:29,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:29,591][root][INFO] - Training Epoch: 1/2, step 1380/7134 completed (loss: 4.46381950378418, acc: 0.29629629850387573)
[2024-12-17 01:40:29,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:29,908][root][INFO] - Training Epoch: 1/2, step 1381/7134 completed (loss: 4.381107807159424, acc: 0.21739129722118378)
[2024-12-17 01:40:30,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:30,174][root][INFO] - Training Epoch: 1/2, step 1382/7134 completed (loss: 4.545776844024658, acc: 0.26923078298568726)
[2024-12-17 01:40:30,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:30,464][root][INFO] - Training Epoch: 1/2, step 1383/7134 completed (loss: 4.439840793609619, acc: 0.29411765933036804)
[2024-12-17 01:40:30,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:30,789][root][INFO] - Training Epoch: 1/2, step 1384/7134 completed (loss: 4.7277631759643555, acc: 0.22695034742355347)
[2024-12-17 01:40:30,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:31,071][root][INFO] - Training Epoch: 1/2, step 1385/7134 completed (loss: 5.200990200042725, acc: 0.20800000429153442)
[2024-12-17 01:40:31,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:31,358][root][INFO] - Training Epoch: 1/2, step 1386/7134 completed (loss: 4.337717533111572, acc: 0.30985915660858154)
[2024-12-17 01:40:31,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:31,644][root][INFO] - Training Epoch: 1/2, step 1387/7134 completed (loss: 4.318302154541016, acc: 0.279720276594162)
[2024-12-17 01:40:31,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:31,918][root][INFO] - Training Epoch: 1/2, step 1388/7134 completed (loss: 4.868080139160156, acc: 0.2160000056028366)
[2024-12-17 01:40:32,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:32,190][root][INFO] - Training Epoch: 1/2, step 1389/7134 completed (loss: 4.796648979187012, acc: 0.23880596458911896)
[2024-12-17 01:40:32,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:32,485][root][INFO] - Training Epoch: 1/2, step 1390/7134 completed (loss: 4.989965438842773, acc: 0.22627736628055573)
[2024-12-17 01:40:32,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:32,800][root][INFO] - Training Epoch: 1/2, step 1391/7134 completed (loss: 4.42838191986084, acc: 0.25)
[2024-12-17 01:40:32,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:33,117][root][INFO] - Training Epoch: 1/2, step 1392/7134 completed (loss: 4.830929756164551, acc: 0.24390244483947754)
[2024-12-17 01:40:33,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:33,411][root][INFO] - Training Epoch: 1/2, step 1393/7134 completed (loss: 4.578017711639404, acc: 0.2604166567325592)
[2024-12-17 01:40:33,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:33,711][root][INFO] - Training Epoch: 1/2, step 1394/7134 completed (loss: 4.897108554840088, acc: 0.2641509473323822)
[2024-12-17 01:40:33,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:33,990][root][INFO] - Training Epoch: 1/2, step 1395/7134 completed (loss: 4.366703510284424, acc: 0.28125)
[2024-12-17 01:40:34,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:34,279][root][INFO] - Training Epoch: 1/2, step 1396/7134 completed (loss: 3.8436625003814697, acc: 0.3199999928474426)
[2024-12-17 01:40:34,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:34,557][root][INFO] - Training Epoch: 1/2, step 1397/7134 completed (loss: 4.623228073120117, acc: 0.2702702581882477)
[2024-12-17 01:40:34,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:34,826][root][INFO] - Training Epoch: 1/2, step 1398/7134 completed (loss: 4.2267351150512695, acc: 0.31683167815208435)
[2024-12-17 01:40:34,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:35,114][root][INFO] - Training Epoch: 1/2, step 1399/7134 completed (loss: 4.400806903839111, acc: 0.22302158176898956)
[2024-12-17 01:40:35,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:35,405][root][INFO] - Training Epoch: 1/2, step 1400/7134 completed (loss: 4.2325358390808105, acc: 0.28260868787765503)
[2024-12-17 01:40:35,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:35,687][root][INFO] - Training Epoch: 1/2, step 1401/7134 completed (loss: 4.154584884643555, acc: 0.2666666805744171)
[2024-12-17 01:40:35,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:35,965][root][INFO] - Training Epoch: 1/2, step 1402/7134 completed (loss: 4.158276081085205, acc: 0.26865673065185547)
[2024-12-17 01:40:36,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:36,262][root][INFO] - Training Epoch: 1/2, step 1403/7134 completed (loss: 3.864415168762207, acc: 0.24260355532169342)
[2024-12-17 01:40:36,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:36,549][root][INFO] - Training Epoch: 1/2, step 1404/7134 completed (loss: 3.7557783126831055, acc: 0.2916666567325592)
[2024-12-17 01:40:36,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:36,879][root][INFO] - Training Epoch: 1/2, step 1405/7134 completed (loss: 3.594351291656494, acc: 0.3392857015132904)
[2024-12-17 01:40:37,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:37,164][root][INFO] - Training Epoch: 1/2, step 1406/7134 completed (loss: 3.7196924686431885, acc: 0.30434781312942505)
[2024-12-17 01:40:37,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:37,444][root][INFO] - Training Epoch: 1/2, step 1407/7134 completed (loss: 4.204455852508545, acc: 0.26744186878204346)
[2024-12-17 01:40:37,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:37,736][root][INFO] - Training Epoch: 1/2, step 1408/7134 completed (loss: 4.151083469390869, acc: 0.24827586114406586)
[2024-12-17 01:40:37,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:38,019][root][INFO] - Training Epoch: 1/2, step 1409/7134 completed (loss: 3.791356086730957, acc: 0.30817610025405884)
[2024-12-17 01:40:38,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:38,297][root][INFO] - Training Epoch: 1/2, step 1410/7134 completed (loss: 3.948476791381836, acc: 0.2707182466983795)
[2024-12-17 01:40:38,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:38,590][root][INFO] - Training Epoch: 1/2, step 1411/7134 completed (loss: 3.9129436016082764, acc: 0.2571428716182709)
[2024-12-17 01:40:38,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:38,875][root][INFO] - Training Epoch: 1/2, step 1412/7134 completed (loss: 3.6997320652008057, acc: 0.34736841917037964)
[2024-12-17 01:40:39,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:39,157][root][INFO] - Training Epoch: 1/2, step 1413/7134 completed (loss: 3.9016847610473633, acc: 0.2634730637073517)
[2024-12-17 01:40:39,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:39,433][root][INFO] - Training Epoch: 1/2, step 1414/7134 completed (loss: 3.823188543319702, acc: 0.29801324009895325)
[2024-12-17 01:40:39,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:39,712][root][INFO] - Training Epoch: 1/2, step 1415/7134 completed (loss: 3.9467318058013916, acc: 0.2700729966163635)
[2024-12-17 01:40:39,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:40,030][root][INFO] - Training Epoch: 1/2, step 1416/7134 completed (loss: 3.465954065322876, acc: 0.29378530383110046)
[2024-12-17 01:40:40,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:40,338][root][INFO] - Training Epoch: 1/2, step 1417/7134 completed (loss: 3.5812225341796875, acc: 0.2916666567325592)
[2024-12-17 01:40:40,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:40,634][root][INFO] - Training Epoch: 1/2, step 1418/7134 completed (loss: 3.5680291652679443, acc: 0.3178294599056244)
[2024-12-17 01:40:40,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:40,945][root][INFO] - Training Epoch: 1/2, step 1419/7134 completed (loss: 3.4304680824279785, acc: 0.3125)
[2024-12-17 01:40:41,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:41,255][root][INFO] - Training Epoch: 1/2, step 1420/7134 completed (loss: 3.3657805919647217, acc: 0.3263157904148102)
[2024-12-17 01:40:41,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:41,537][root][INFO] - Training Epoch: 1/2, step 1421/7134 completed (loss: 3.231189727783203, acc: 0.3557046949863434)
[2024-12-17 01:40:41,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:41,823][root][INFO] - Training Epoch: 1/2, step 1422/7134 completed (loss: 3.9853076934814453, acc: 0.3072289228439331)
[2024-12-17 01:40:41,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:42,145][root][INFO] - Training Epoch: 1/2, step 1423/7134 completed (loss: 4.195162773132324, acc: 0.30534350872039795)
[2024-12-17 01:40:42,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:42,423][root][INFO] - Training Epoch: 1/2, step 1424/7134 completed (loss: 4.55045747756958, acc: 0.2601625919342041)
[2024-12-17 01:40:42,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:42,711][root][INFO] - Training Epoch: 1/2, step 1425/7134 completed (loss: 4.1298418045043945, acc: 0.2196531742811203)
[2024-12-17 01:40:42,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:43,038][root][INFO] - Training Epoch: 1/2, step 1426/7134 completed (loss: 3.7065699100494385, acc: 0.35567009449005127)
[2024-12-17 01:40:43,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:43,326][root][INFO] - Training Epoch: 1/2, step 1427/7134 completed (loss: 4.318319797515869, acc: 0.28248587250709534)
[2024-12-17 01:40:43,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:43,630][root][INFO] - Training Epoch: 1/2, step 1428/7134 completed (loss: 3.991248369216919, acc: 0.35483869910240173)
[2024-12-17 01:40:43,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:43,914][root][INFO] - Training Epoch: 1/2, step 1429/7134 completed (loss: 4.093264102935791, acc: 0.24074074625968933)
[2024-12-17 01:40:44,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:44,205][root][INFO] - Training Epoch: 1/2, step 1430/7134 completed (loss: 3.1952016353607178, acc: 0.41726619005203247)
[2024-12-17 01:40:44,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:44,490][root][INFO] - Training Epoch: 1/2, step 1431/7134 completed (loss: 3.542724847793579, acc: 0.35483869910240173)
[2024-12-17 01:40:44,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:44,801][root][INFO] - Training Epoch: 1/2, step 1432/7134 completed (loss: 3.734884738922119, acc: 0.28140702843666077)
[2024-12-17 01:40:44,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:45,087][root][INFO] - Training Epoch: 1/2, step 1433/7134 completed (loss: 3.7704527378082275, acc: 0.2598039209842682)
[2024-12-17 01:40:45,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:45,366][root][INFO] - Training Epoch: 1/2, step 1434/7134 completed (loss: 3.3848581314086914, acc: 0.3333333432674408)
[2024-12-17 01:40:45,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:45,657][root][INFO] - Training Epoch: 1/2, step 1435/7134 completed (loss: 3.798793077468872, acc: 0.30645161867141724)
[2024-12-17 01:40:45,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:45,959][root][INFO] - Training Epoch: 1/2, step 1436/7134 completed (loss: 3.925830364227295, acc: 0.28703704476356506)
[2024-12-17 01:40:46,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:46,233][root][INFO] - Training Epoch: 1/2, step 1437/7134 completed (loss: 3.419405698776245, acc: 0.36021506786346436)
[2024-12-17 01:40:46,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:46,521][root][INFO] - Training Epoch: 1/2, step 1438/7134 completed (loss: 3.793876886367798, acc: 0.2969697117805481)
[2024-12-17 01:40:46,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:46,805][root][INFO] - Training Epoch: 1/2, step 1439/7134 completed (loss: 3.8720290660858154, acc: 0.2518518567085266)
[2024-12-17 01:40:46,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:47,073][root][INFO] - Training Epoch: 1/2, step 1440/7134 completed (loss: 4.11328649520874, acc: 0.3105590045452118)
[2024-12-17 01:40:47,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:47,351][root][INFO] - Training Epoch: 1/2, step 1441/7134 completed (loss: 3.439201593399048, acc: 0.33908045291900635)
[2024-12-17 01:40:47,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:47,635][root][INFO] - Training Epoch: 1/2, step 1442/7134 completed (loss: 3.6598777770996094, acc: 0.3839285671710968)
[2024-12-17 01:40:47,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:47,917][root][INFO] - Training Epoch: 1/2, step 1443/7134 completed (loss: 3.373910903930664, acc: 0.34567901492118835)
[2024-12-17 01:40:48,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:48,200][root][INFO] - Training Epoch: 1/2, step 1444/7134 completed (loss: 3.876673460006714, acc: 0.2847222089767456)
[2024-12-17 01:40:48,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:48,488][root][INFO] - Training Epoch: 1/2, step 1445/7134 completed (loss: 3.6510508060455322, acc: 0.31847134232521057)
[2024-12-17 01:40:48,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:48,761][root][INFO] - Training Epoch: 1/2, step 1446/7134 completed (loss: 3.6119322776794434, acc: 0.3181818127632141)
[2024-12-17 01:40:48,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:49,040][root][INFO] - Training Epoch: 1/2, step 1447/7134 completed (loss: 4.078114032745361, acc: 0.2795698940753937)
[2024-12-17 01:40:49,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:49,316][root][INFO] - Training Epoch: 1/2, step 1448/7134 completed (loss: 4.348149299621582, acc: 0.305970162153244)
[2024-12-17 01:40:49,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:49,605][root][INFO] - Training Epoch: 1/2, step 1449/7134 completed (loss: 3.8454809188842773, acc: 0.3442623019218445)
[2024-12-17 01:40:49,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:49,870][root][INFO] - Training Epoch: 1/2, step 1450/7134 completed (loss: 3.315498113632202, acc: 0.3475935757160187)
[2024-12-17 01:40:50,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:50,158][root][INFO] - Training Epoch: 1/2, step 1451/7134 completed (loss: 2.9612743854522705, acc: 0.41361257433891296)
[2024-12-17 01:40:50,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:50,463][root][INFO] - Training Epoch: 1/2, step 1452/7134 completed (loss: 3.6212069988250732, acc: 0.3680555522441864)
[2024-12-17 01:40:50,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:50,745][root][INFO] - Training Epoch: 1/2, step 1453/7134 completed (loss: 3.838165044784546, acc: 0.3604651093482971)
[2024-12-17 01:40:50,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:51,030][root][INFO] - Training Epoch: 1/2, step 1454/7134 completed (loss: 3.6181256771087646, acc: 0.3697916567325592)
[2024-12-17 01:40:51,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:51,320][root][INFO] - Training Epoch: 1/2, step 1455/7134 completed (loss: 3.6031131744384766, acc: 0.35172414779663086)
[2024-12-17 01:40:51,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:51,634][root][INFO] - Training Epoch: 1/2, step 1456/7134 completed (loss: 3.6452276706695557, acc: 0.3471074402332306)
[2024-12-17 01:40:51,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:51,906][root][INFO] - Training Epoch: 1/2, step 1457/7134 completed (loss: 3.790111541748047, acc: 0.31677019596099854)
[2024-12-17 01:40:52,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:52,183][root][INFO] - Training Epoch: 1/2, step 1458/7134 completed (loss: 3.8256402015686035, acc: 0.3136094808578491)
[2024-12-17 01:40:52,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:52,458][root][INFO] - Training Epoch: 1/2, step 1459/7134 completed (loss: 4.083718299865723, acc: 0.2370370328426361)
[2024-12-17 01:40:52,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:52,749][root][INFO] - Training Epoch: 1/2, step 1460/7134 completed (loss: 4.49547815322876, acc: 0.24852071702480316)
[2024-12-17 01:40:52,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:53,014][root][INFO] - Training Epoch: 1/2, step 1461/7134 completed (loss: 4.620166301727295, acc: 0.25827813148498535)
[2024-12-17 01:40:53,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:53,298][root][INFO] - Training Epoch: 1/2, step 1462/7134 completed (loss: 3.571211099624634, acc: 0.3731343150138855)
[2024-12-17 01:40:53,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:53,577][root][INFO] - Training Epoch: 1/2, step 1463/7134 completed (loss: 4.451801300048828, acc: 0.3006536066532135)
[2024-12-17 01:40:53,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:53,876][root][INFO] - Training Epoch: 1/2, step 1464/7134 completed (loss: 4.578490257263184, acc: 0.1867469847202301)
[2024-12-17 01:40:53,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:54,160][root][INFO] - Training Epoch: 1/2, step 1465/7134 completed (loss: 4.1105756759643555, acc: 0.2884615361690521)
[2024-12-17 01:40:54,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:54,451][root][INFO] - Training Epoch: 1/2, step 1466/7134 completed (loss: 3.8100976943969727, acc: 0.2569832503795624)
[2024-12-17 01:40:54,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:54,736][root][INFO] - Training Epoch: 1/2, step 1467/7134 completed (loss: 4.228075981140137, acc: 0.17575757205486298)
[2024-12-17 01:40:54,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:55,039][root][INFO] - Training Epoch: 1/2, step 1468/7134 completed (loss: 4.614711284637451, acc: 0.17977528274059296)
[2024-12-17 01:40:55,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:55,327][root][INFO] - Training Epoch: 1/2, step 1469/7134 completed (loss: 3.9918227195739746, acc: 0.2556818127632141)
[2024-12-17 01:40:55,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:55,594][root][INFO] - Training Epoch: 1/2, step 1470/7134 completed (loss: 4.1493144035339355, acc: 0.2866241931915283)
[2024-12-17 01:40:55,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:55,865][root][INFO] - Training Epoch: 1/2, step 1471/7134 completed (loss: 4.1739182472229, acc: 0.32307693362236023)
[2024-12-17 01:40:55,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:56,144][root][INFO] - Training Epoch: 1/2, step 1472/7134 completed (loss: 3.5927212238311768, acc: 0.32163742184638977)
[2024-12-17 01:40:56,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:56,427][root][INFO] - Training Epoch: 1/2, step 1473/7134 completed (loss: 3.603128433227539, acc: 0.2545454502105713)
[2024-12-17 01:40:56,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:56,695][root][INFO] - Training Epoch: 1/2, step 1474/7134 completed (loss: 3.7776119709014893, acc: 0.3103448152542114)
[2024-12-17 01:40:56,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:56,971][root][INFO] - Training Epoch: 1/2, step 1475/7134 completed (loss: 4.109076976776123, acc: 0.32121211290359497)
[2024-12-17 01:40:57,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:57,253][root][INFO] - Training Epoch: 1/2, step 1476/7134 completed (loss: 4.733757972717285, acc: 0.2800000011920929)
[2024-12-17 01:40:57,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:57,558][root][INFO] - Training Epoch: 1/2, step 1477/7134 completed (loss: 3.918518543243408, acc: 0.2689655125141144)
[2024-12-17 01:40:57,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:57,847][root][INFO] - Training Epoch: 1/2, step 1478/7134 completed (loss: 4.21884822845459, acc: 0.25)
[2024-12-17 01:40:57,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:58,133][root][INFO] - Training Epoch: 1/2, step 1479/7134 completed (loss: 4.045752048492432, acc: 0.28735631704330444)
[2024-12-17 01:40:58,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:58,420][root][INFO] - Training Epoch: 1/2, step 1480/7134 completed (loss: 4.2259721755981445, acc: 0.23204420506954193)
[2024-12-17 01:40:58,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:58,712][root][INFO] - Training Epoch: 1/2, step 1481/7134 completed (loss: 3.713081121444702, acc: 0.32777777314186096)
[2024-12-17 01:40:58,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:59,000][root][INFO] - Training Epoch: 1/2, step 1482/7134 completed (loss: 4.041922569274902, acc: 0.3254437744617462)
[2024-12-17 01:40:59,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:59,270][root][INFO] - Training Epoch: 1/2, step 1483/7134 completed (loss: 4.654421806335449, acc: 0.2442748099565506)
[2024-12-17 01:40:59,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:59,564][root][INFO] - Training Epoch: 1/2, step 1484/7134 completed (loss: 4.039696216583252, acc: 0.28313252329826355)
[2024-12-17 01:40:59,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:59,845][root][INFO] - Training Epoch: 1/2, step 1485/7134 completed (loss: 4.369171619415283, acc: 0.19883041083812714)
[2024-12-17 01:40:59,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:00,114][root][INFO] - Training Epoch: 1/2, step 1486/7134 completed (loss: 4.13073205947876, acc: 0.276729553937912)
[2024-12-17 01:41:00,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:00,390][root][INFO] - Training Epoch: 1/2, step 1487/7134 completed (loss: 3.618170738220215, acc: 0.3513513505458832)
[2024-12-17 01:41:00,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:00,685][root][INFO] - Training Epoch: 1/2, step 1488/7134 completed (loss: 4.170200347900391, acc: 0.24651162326335907)
[2024-12-17 01:41:00,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:00,954][root][INFO] - Training Epoch: 1/2, step 1489/7134 completed (loss: 4.338064193725586, acc: 0.25)
[2024-12-17 01:41:01,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:01,244][root][INFO] - Training Epoch: 1/2, step 1490/7134 completed (loss: 4.291768550872803, acc: 0.29646018147468567)
[2024-12-17 01:41:01,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:01,539][root][INFO] - Training Epoch: 1/2, step 1491/7134 completed (loss: 3.974825859069824, acc: 0.29523810744285583)
[2024-12-17 01:41:01,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:01,834][root][INFO] - Training Epoch: 1/2, step 1492/7134 completed (loss: 3.860665798187256, acc: 0.29383885860443115)
[2024-12-17 01:41:01,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:02,132][root][INFO] - Training Epoch: 1/2, step 1493/7134 completed (loss: 3.8644585609436035, acc: 0.2289719581604004)
[2024-12-17 01:41:02,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:02,440][root][INFO] - Training Epoch: 1/2, step 1494/7134 completed (loss: 4.2250447273254395, acc: 0.20725388824939728)
[2024-12-17 01:41:02,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:02,731][root][INFO] - Training Epoch: 1/2, step 1495/7134 completed (loss: 4.401984214782715, acc: 0.23902438580989838)
[2024-12-17 01:41:02,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:03,011][root][INFO] - Training Epoch: 1/2, step 1496/7134 completed (loss: 4.5085039138793945, acc: 0.19374999403953552)
[2024-12-17 01:41:03,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:03,319][root][INFO] - Training Epoch: 1/2, step 1497/7134 completed (loss: 3.672584295272827, acc: 0.31481480598449707)
[2024-12-17 01:41:03,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:03,579][root][INFO] - Training Epoch: 1/2, step 1498/7134 completed (loss: 4.702534198760986, acc: 0.20540539920330048)
[2024-12-17 01:41:03,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:03,874][root][INFO] - Training Epoch: 1/2, step 1499/7134 completed (loss: 4.076976299285889, acc: 0.2837209403514862)
[2024-12-17 01:41:03,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:04,146][root][INFO] - Training Epoch: 1/2, step 1500/7134 completed (loss: 4.7761945724487305, acc: 0.21232876181602478)
[2024-12-17 01:41:04,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:04,434][root][INFO] - Training Epoch: 1/2, step 1501/7134 completed (loss: 4.818248271942139, acc: 0.20710058510303497)
[2024-12-17 01:41:04,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:04,713][root][INFO] - Training Epoch: 1/2, step 1502/7134 completed (loss: 4.068380832672119, acc: 0.34090909361839294)
[2024-12-17 01:41:04,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:04,977][root][INFO] - Training Epoch: 1/2, step 1503/7134 completed (loss: 4.798994541168213, acc: 0.23999999463558197)
[2024-12-17 01:41:05,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:05,247][root][INFO] - Training Epoch: 1/2, step 1504/7134 completed (loss: 4.465144634246826, acc: 0.21693122386932373)
[2024-12-17 01:41:05,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:05,526][root][INFO] - Training Epoch: 1/2, step 1505/7134 completed (loss: 4.935818672180176, acc: 0.18987341225147247)
[2024-12-17 01:41:05,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:05,805][root][INFO] - Training Epoch: 1/2, step 1506/7134 completed (loss: 4.452880859375, acc: 0.29559749364852905)
[2024-12-17 01:41:05,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:06,127][root][INFO] - Training Epoch: 1/2, step 1507/7134 completed (loss: 4.6533379554748535, acc: 0.265625)
[2024-12-17 01:41:06,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:06,420][root][INFO] - Training Epoch: 1/2, step 1508/7134 completed (loss: 3.960628032684326, acc: 0.3177570104598999)
[2024-12-17 01:41:06,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:06,698][root][INFO] - Training Epoch: 1/2, step 1509/7134 completed (loss: 4.086950778961182, acc: 0.2666666805744171)
[2024-12-17 01:41:06,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:06,984][root][INFO] - Training Epoch: 1/2, step 1510/7134 completed (loss: 4.474181652069092, acc: 0.23225806653499603)
[2024-12-17 01:41:07,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:07,270][root][INFO] - Training Epoch: 1/2, step 1511/7134 completed (loss: 4.471266746520996, acc: 0.3016759753227234)
[2024-12-17 01:41:07,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:07,552][root][INFO] - Training Epoch: 1/2, step 1512/7134 completed (loss: 3.9054129123687744, acc: 0.2800000011920929)
[2024-12-17 01:41:07,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:07,831][root][INFO] - Training Epoch: 1/2, step 1513/7134 completed (loss: 4.15741491317749, acc: 0.2541436553001404)
[2024-12-17 01:41:07,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:08,107][root][INFO] - Training Epoch: 1/2, step 1514/7134 completed (loss: 4.416141510009766, acc: 0.19170984625816345)
[2024-12-17 01:41:08,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:08,387][root][INFO] - Training Epoch: 1/2, step 1515/7134 completed (loss: 4.128345489501953, acc: 0.2522522509098053)
[2024-12-17 01:41:08,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:08,640][root][INFO] - Training Epoch: 1/2, step 1516/7134 completed (loss: 4.490800380706787, acc: 0.23749999701976776)
[2024-12-17 01:41:08,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:08,930][root][INFO] - Training Epoch: 1/2, step 1517/7134 completed (loss: 4.654149532318115, acc: 0.2410714328289032)
[2024-12-17 01:41:09,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:09,208][root][INFO] - Training Epoch: 1/2, step 1518/7134 completed (loss: 4.125307083129883, acc: 0.3298968970775604)
[2024-12-17 01:41:09,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:09,502][root][INFO] - Training Epoch: 1/2, step 1519/7134 completed (loss: 4.201995849609375, acc: 0.19417475163936615)
[2024-12-17 01:41:09,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:09,807][root][INFO] - Training Epoch: 1/2, step 1520/7134 completed (loss: 4.168219566345215, acc: 0.30656933784484863)
[2024-12-17 01:41:09,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:10,103][root][INFO] - Training Epoch: 1/2, step 1521/7134 completed (loss: 4.152809143066406, acc: 0.2720588147640228)
[2024-12-17 01:41:10,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:10,378][root][INFO] - Training Epoch: 1/2, step 1522/7134 completed (loss: 4.354794502258301, acc: 0.30158731341362)
[2024-12-17 01:41:10,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:10,672][root][INFO] - Training Epoch: 1/2, step 1523/7134 completed (loss: 5.320688724517822, acc: 0.21710526943206787)
[2024-12-17 01:41:10,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:10,980][root][INFO] - Training Epoch: 1/2, step 1524/7134 completed (loss: 4.874716758728027, acc: 0.19178082048892975)
[2024-12-17 01:41:11,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:11,258][root][INFO] - Training Epoch: 1/2, step 1525/7134 completed (loss: 4.509544372558594, acc: 0.25999999046325684)
[2024-12-17 01:41:11,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:11,566][root][INFO] - Training Epoch: 1/2, step 1526/7134 completed (loss: 4.853963375091553, acc: 0.27210885286331177)
[2024-12-17 01:41:11,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:11,858][root][INFO] - Training Epoch: 1/2, step 1527/7134 completed (loss: 4.484889984130859, acc: 0.3185840845108032)
[2024-12-17 01:41:11,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:12,156][root][INFO] - Training Epoch: 1/2, step 1528/7134 completed (loss: 4.505417823791504, acc: 0.24637681245803833)
[2024-12-17 01:41:12,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:12,429][root][INFO] - Training Epoch: 1/2, step 1529/7134 completed (loss: 4.019146919250488, acc: 0.271276593208313)
[2024-12-17 01:41:12,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:12,694][root][INFO] - Training Epoch: 1/2, step 1530/7134 completed (loss: 4.530129432678223, acc: 0.2767857015132904)
[2024-12-17 01:41:12,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:12,960][root][INFO] - Training Epoch: 1/2, step 1531/7134 completed (loss: 4.801331043243408, acc: 0.2348484843969345)
[2024-12-17 01:41:13,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:13,303][root][INFO] - Training Epoch: 1/2, step 1532/7134 completed (loss: 3.7037110328674316, acc: 0.31794872879981995)
[2024-12-17 01:41:13,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:13,569][root][INFO] - Training Epoch: 1/2, step 1533/7134 completed (loss: 4.327615737915039, acc: 0.2590361535549164)
[2024-12-17 01:41:13,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:13,863][root][INFO] - Training Epoch: 1/2, step 1534/7134 completed (loss: 4.6462721824646, acc: 0.22302158176898956)
[2024-12-17 01:41:14,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:14,204][root][INFO] - Training Epoch: 1/2, step 1535/7134 completed (loss: 3.76631498336792, acc: 0.34857141971588135)
[2024-12-17 01:41:14,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:14,480][root][INFO] - Training Epoch: 1/2, step 1536/7134 completed (loss: 4.058472633361816, acc: 0.32098764181137085)
[2024-12-17 01:41:14,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:14,776][root][INFO] - Training Epoch: 1/2, step 1537/7134 completed (loss: 4.143942832946777, acc: 0.3274853825569153)
[2024-12-17 01:41:14,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:15,053][root][INFO] - Training Epoch: 1/2, step 1538/7134 completed (loss: 4.315745830535889, acc: 0.261904776096344)
[2024-12-17 01:41:15,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:15,327][root][INFO] - Training Epoch: 1/2, step 1539/7134 completed (loss: 4.221736431121826, acc: 0.260606050491333)
[2024-12-17 01:41:15,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:15,606][root][INFO] - Training Epoch: 1/2, step 1540/7134 completed (loss: 4.317934513092041, acc: 0.2151898741722107)
[2024-12-17 01:41:15,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:15,884][root][INFO] - Training Epoch: 1/2, step 1541/7134 completed (loss: 4.207634449005127, acc: 0.21052631735801697)
[2024-12-17 01:41:16,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:16,177][root][INFO] - Training Epoch: 1/2, step 1542/7134 completed (loss: 3.8211452960968018, acc: 0.24719101190567017)
[2024-12-17 01:41:16,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:16,458][root][INFO] - Training Epoch: 1/2, step 1543/7134 completed (loss: 4.135800361633301, acc: 0.25238096714019775)
[2024-12-17 01:41:16,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:16,750][root][INFO] - Training Epoch: 1/2, step 1544/7134 completed (loss: 4.039877414703369, acc: 0.25)
[2024-12-17 01:41:16,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:17,010][root][INFO] - Training Epoch: 1/2, step 1545/7134 completed (loss: 4.01874303817749, acc: 0.2916666567325592)
[2024-12-17 01:41:17,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:17,310][root][INFO] - Training Epoch: 1/2, step 1546/7134 completed (loss: 4.561354637145996, acc: 0.30000001192092896)
[2024-12-17 01:41:17,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:17,596][root][INFO] - Training Epoch: 1/2, step 1547/7134 completed (loss: 4.615938186645508, acc: 0.22839505970478058)
[2024-12-17 01:41:17,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:17,886][root][INFO] - Training Epoch: 1/2, step 1548/7134 completed (loss: 4.490103244781494, acc: 0.2789473831653595)
[2024-12-17 01:41:18,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:18,167][root][INFO] - Training Epoch: 1/2, step 1549/7134 completed (loss: 3.764150381088257, acc: 0.3085714280605316)
[2024-12-17 01:41:18,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:18,451][root][INFO] - Training Epoch: 1/2, step 1550/7134 completed (loss: 3.9759910106658936, acc: 0.3117647171020508)
[2024-12-17 01:41:18,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:18,718][root][INFO] - Training Epoch: 1/2, step 1551/7134 completed (loss: 4.056722640991211, acc: 0.3178808093070984)
[2024-12-17 01:41:18,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:18,997][root][INFO] - Training Epoch: 1/2, step 1552/7134 completed (loss: 3.6527302265167236, acc: 0.30102041363716125)
[2024-12-17 01:41:19,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:19,275][root][INFO] - Training Epoch: 1/2, step 1553/7134 completed (loss: 4.475731372833252, acc: 0.2857142984867096)
[2024-12-17 01:41:19,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:19,562][root][INFO] - Training Epoch: 1/2, step 1554/7134 completed (loss: 4.0920209884643555, acc: 0.30635836720466614)
[2024-12-17 01:41:19,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:19,836][root][INFO] - Training Epoch: 1/2, step 1555/7134 completed (loss: 4.1699018478393555, acc: 0.2562499940395355)
[2024-12-17 01:41:19,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:20,122][root][INFO] - Training Epoch: 1/2, step 1556/7134 completed (loss: 4.211705207824707, acc: 0.2881355881690979)
[2024-12-17 01:41:20,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:20,406][root][INFO] - Training Epoch: 1/2, step 1557/7134 completed (loss: 4.026124000549316, acc: 0.30000001192092896)
[2024-12-17 01:41:20,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:20,686][root][INFO] - Training Epoch: 1/2, step 1558/7134 completed (loss: 4.273329734802246, acc: 0.2397260218858719)
[2024-12-17 01:41:20,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:20,958][root][INFO] - Training Epoch: 1/2, step 1559/7134 completed (loss: 4.0161333084106445, acc: 0.2857142984867096)
[2024-12-17 01:41:21,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:21,229][root][INFO] - Training Epoch: 1/2, step 1560/7134 completed (loss: 3.1086812019348145, acc: 0.3502538204193115)
[2024-12-17 01:41:21,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:21,523][root][INFO] - Training Epoch: 1/2, step 1561/7134 completed (loss: 4.056056499481201, acc: 0.2586206793785095)
[2024-12-17 01:41:21,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:21,838][root][INFO] - Training Epoch: 1/2, step 1562/7134 completed (loss: 3.8394839763641357, acc: 0.28994083404541016)
[2024-12-17 01:41:21,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:22,115][root][INFO] - Training Epoch: 1/2, step 1563/7134 completed (loss: 4.256724834442139, acc: 0.2598039209842682)
[2024-12-17 01:41:22,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:22,398][root][INFO] - Training Epoch: 1/2, step 1564/7134 completed (loss: 4.333468437194824, acc: 0.21782177686691284)
[2024-12-17 01:41:22,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:22,660][root][INFO] - Training Epoch: 1/2, step 1565/7134 completed (loss: 4.465793609619141, acc: 0.23899370431900024)
[2024-12-17 01:41:22,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:22,928][root][INFO] - Training Epoch: 1/2, step 1566/7134 completed (loss: 4.057501316070557, acc: 0.2983425557613373)
[2024-12-17 01:41:23,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:23,230][root][INFO] - Training Epoch: 1/2, step 1567/7134 completed (loss: 4.208316802978516, acc: 0.2780487835407257)
[2024-12-17 01:41:23,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:23,531][root][INFO] - Training Epoch: 1/2, step 1568/7134 completed (loss: 4.068542957305908, acc: 0.24519230425357819)
[2024-12-17 01:41:23,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:23,811][root][INFO] - Training Epoch: 1/2, step 1569/7134 completed (loss: 4.061474323272705, acc: 0.24848484992980957)
[2024-12-17 01:41:23,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:24,104][root][INFO] - Training Epoch: 1/2, step 1570/7134 completed (loss: 4.2299346923828125, acc: 0.2582159638404846)
[2024-12-17 01:41:24,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:24,376][root][INFO] - Training Epoch: 1/2, step 1571/7134 completed (loss: 3.699686288833618, acc: 0.3041474521160126)
[2024-12-17 01:41:24,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:24,664][root][INFO] - Training Epoch: 1/2, step 1572/7134 completed (loss: 3.376676559448242, acc: 0.3333333432674408)
[2024-12-17 01:41:24,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:24,943][root][INFO] - Training Epoch: 1/2, step 1573/7134 completed (loss: 3.6503055095672607, acc: 0.2934131622314453)
[2024-12-17 01:41:25,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:25,227][root][INFO] - Training Epoch: 1/2, step 1574/7134 completed (loss: 3.548950433731079, acc: 0.3228699564933777)
[2024-12-17 01:41:25,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:25,501][root][INFO] - Training Epoch: 1/2, step 1575/7134 completed (loss: 3.820601224899292, acc: 0.2818181812763214)
[2024-12-17 01:41:25,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:25,779][root][INFO] - Training Epoch: 1/2, step 1576/7134 completed (loss: 3.1793453693389893, acc: 0.35211268067359924)
[2024-12-17 01:41:25,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:26,092][root][INFO] - Training Epoch: 1/2, step 1577/7134 completed (loss: 3.542736291885376, acc: 0.28985506296157837)
[2024-12-17 01:41:26,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:26,367][root][INFO] - Training Epoch: 1/2, step 1578/7134 completed (loss: 4.285051345825195, acc: 0.2670454680919647)
[2024-12-17 01:41:26,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:26,679][root][INFO] - Training Epoch: 1/2, step 1579/7134 completed (loss: 3.8808882236480713, acc: 0.32692307233810425)
[2024-12-17 01:41:26,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:26,957][root][INFO] - Training Epoch: 1/2, step 1580/7134 completed (loss: 4.570021629333496, acc: 0.23671497404575348)
[2024-12-17 01:41:27,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:27,246][root][INFO] - Training Epoch: 1/2, step 1581/7134 completed (loss: 4.283786773681641, acc: 0.3154761791229248)
[2024-12-17 01:41:27,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:27,521][root][INFO] - Training Epoch: 1/2, step 1582/7134 completed (loss: 4.3336639404296875, acc: 0.2866666615009308)
[2024-12-17 01:41:27,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:27,794][root][INFO] - Training Epoch: 1/2, step 1583/7134 completed (loss: 4.435718536376953, acc: 0.3028571307659149)
[2024-12-17 01:41:27,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:28,099][root][INFO] - Training Epoch: 1/2, step 1584/7134 completed (loss: 4.037357330322266, acc: 0.31081080436706543)
[2024-12-17 01:41:28,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:28,381][root][INFO] - Training Epoch: 1/2, step 1585/7134 completed (loss: 3.8250973224639893, acc: 0.28155338764190674)
[2024-12-17 01:41:28,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:28,688][root][INFO] - Training Epoch: 1/2, step 1586/7134 completed (loss: 3.9098610877990723, acc: 0.3478260934352875)
[2024-12-17 01:41:28,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:28,962][root][INFO] - Training Epoch: 1/2, step 1587/7134 completed (loss: 4.568822860717773, acc: 0.23566879332065582)
[2024-12-17 01:41:29,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:29,240][root][INFO] - Training Epoch: 1/2, step 1588/7134 completed (loss: 3.637338161468506, acc: 0.30573248863220215)
[2024-12-17 01:41:29,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:29,515][root][INFO] - Training Epoch: 1/2, step 1589/7134 completed (loss: 4.056647300720215, acc: 0.21341463923454285)
[2024-12-17 01:41:29,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:29,786][root][INFO] - Training Epoch: 1/2, step 1590/7134 completed (loss: 3.930514097213745, acc: 0.30714285373687744)
[2024-12-17 01:41:29,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:30,059][root][INFO] - Training Epoch: 1/2, step 1591/7134 completed (loss: 3.767073631286621, acc: 0.3333333432674408)
[2024-12-17 01:41:30,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:30,345][root][INFO] - Training Epoch: 1/2, step 1592/7134 completed (loss: 3.863152027130127, acc: 0.2922077775001526)
[2024-12-17 01:41:30,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:30,628][root][INFO] - Training Epoch: 1/2, step 1593/7134 completed (loss: 4.002767086029053, acc: 0.27807486057281494)
[2024-12-17 01:41:30,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:30,903][root][INFO] - Training Epoch: 1/2, step 1594/7134 completed (loss: 4.025479793548584, acc: 0.2421875)
[2024-12-17 01:41:30,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:31,180][root][INFO] - Training Epoch: 1/2, step 1595/7134 completed (loss: 3.5541651248931885, acc: 0.29411765933036804)
[2024-12-17 01:41:31,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:31,453][root][INFO] - Training Epoch: 1/2, step 1596/7134 completed (loss: 3.7997653484344482, acc: 0.2986111044883728)
[2024-12-17 01:41:31,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:31,737][root][INFO] - Training Epoch: 1/2, step 1597/7134 completed (loss: 4.12653923034668, acc: 0.2781457006931305)
[2024-12-17 01:41:31,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:31,999][root][INFO] - Training Epoch: 1/2, step 1598/7134 completed (loss: 3.8624114990234375, acc: 0.3583333194255829)
[2024-12-17 01:41:32,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:32,276][root][INFO] - Training Epoch: 1/2, step 1599/7134 completed (loss: 3.905855894088745, acc: 0.317241370677948)
[2024-12-17 01:41:32,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:32,564][root][INFO] - Training Epoch: 1/2, step 1600/7134 completed (loss: 3.332557439804077, acc: 0.3520408272743225)
[2024-12-17 01:41:32,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:32,847][root][INFO] - Training Epoch: 1/2, step 1601/7134 completed (loss: 3.36137056350708, acc: 0.38787877559661865)
[2024-12-17 01:41:32,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:33,136][root][INFO] - Training Epoch: 1/2, step 1602/7134 completed (loss: 3.44808030128479, acc: 0.36538460850715637)
[2024-12-17 01:41:33,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:33,405][root][INFO] - Training Epoch: 1/2, step 1603/7134 completed (loss: 4.229411602020264, acc: 0.2530120611190796)
[2024-12-17 01:41:33,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:33,682][root][INFO] - Training Epoch: 1/2, step 1604/7134 completed (loss: 3.6893208026885986, acc: 0.3696969747543335)
[2024-12-17 01:41:33,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:33,967][root][INFO] - Training Epoch: 1/2, step 1605/7134 completed (loss: 4.0156331062316895, acc: 0.34705883264541626)
[2024-12-17 01:41:34,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:34,227][root][INFO] - Training Epoch: 1/2, step 1606/7134 completed (loss: 3.477029800415039, acc: 0.3401360511779785)
[2024-12-17 01:41:34,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:34,490][root][INFO] - Training Epoch: 1/2, step 1607/7134 completed (loss: 3.24830961227417, acc: 0.37272727489471436)
[2024-12-17 01:41:34,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:34,769][root][INFO] - Training Epoch: 1/2, step 1608/7134 completed (loss: 3.4270174503326416, acc: 0.35433071851730347)
[2024-12-17 01:41:34,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:35,050][root][INFO] - Training Epoch: 1/2, step 1609/7134 completed (loss: 3.769392251968384, acc: 0.3541666567325592)
[2024-12-17 01:41:35,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:35,320][root][INFO] - Training Epoch: 1/2, step 1610/7134 completed (loss: 3.5479624271392822, acc: 0.3664122223854065)
[2024-12-17 01:41:35,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:35,583][root][INFO] - Training Epoch: 1/2, step 1611/7134 completed (loss: 3.9286653995513916, acc: 0.24074074625968933)
[2024-12-17 01:41:35,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:35,846][root][INFO] - Training Epoch: 1/2, step 1612/7134 completed (loss: 3.66593337059021, acc: 0.3734939694404602)
[2024-12-17 01:41:35,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:36,123][root][INFO] - Training Epoch: 1/2, step 1613/7134 completed (loss: 3.979288339614868, acc: 0.2484472095966339)
[2024-12-17 01:41:36,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:36,403][root][INFO] - Training Epoch: 1/2, step 1614/7134 completed (loss: 4.013123989105225, acc: 0.2368421107530594)
[2024-12-17 01:41:36,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:36,700][root][INFO] - Training Epoch: 1/2, step 1615/7134 completed (loss: 3.4469611644744873, acc: 0.3313252925872803)
[2024-12-17 01:41:36,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:36,970][root][INFO] - Training Epoch: 1/2, step 1616/7134 completed (loss: 3.692643165588379, acc: 0.3032258152961731)
[2024-12-17 01:41:37,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:37,267][root][INFO] - Training Epoch: 1/2, step 1617/7134 completed (loss: 3.6061487197875977, acc: 0.2949640154838562)
[2024-12-17 01:41:37,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:37,556][root][INFO] - Training Epoch: 1/2, step 1618/7134 completed (loss: 4.015359401702881, acc: 0.28244274854660034)
[2024-12-17 01:41:37,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:37,835][root][INFO] - Training Epoch: 1/2, step 1619/7134 completed (loss: 4.120045185089111, acc: 0.353658527135849)
[2024-12-17 01:41:37,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:38,138][root][INFO] - Training Epoch: 1/2, step 1620/7134 completed (loss: 3.825206756591797, acc: 0.37012988328933716)
[2024-12-17 01:41:38,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:38,434][root][INFO] - Training Epoch: 1/2, step 1621/7134 completed (loss: 4.342067241668701, acc: 0.30718955397605896)
[2024-12-17 01:41:38,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:38,708][root][INFO] - Training Epoch: 1/2, step 1622/7134 completed (loss: 4.481177806854248, acc: 0.27450981736183167)
[2024-12-17 01:41:38,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:39,001][root][INFO] - Training Epoch: 1/2, step 1623/7134 completed (loss: 4.494764804840088, acc: 0.19871795177459717)
[2024-12-17 01:41:39,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:39,291][root][INFO] - Training Epoch: 1/2, step 1624/7134 completed (loss: 4.246595859527588, acc: 0.27272728085517883)
[2024-12-17 01:41:39,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:39,569][root][INFO] - Training Epoch: 1/2, step 1625/7134 completed (loss: 4.15449857711792, acc: 0.2750000059604645)
[2024-12-17 01:41:39,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:39,846][root][INFO] - Training Epoch: 1/2, step 1626/7134 completed (loss: 4.730644226074219, acc: 0.1855670064687729)
[2024-12-17 01:41:39,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:40,120][root][INFO] - Training Epoch: 1/2, step 1627/7134 completed (loss: 4.609302043914795, acc: 0.2520325183868408)
[2024-12-17 01:41:40,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:40,396][root][INFO] - Training Epoch: 1/2, step 1628/7134 completed (loss: 3.971864700317383, acc: 0.31481480598449707)
[2024-12-17 01:41:40,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:40,662][root][INFO] - Training Epoch: 1/2, step 1629/7134 completed (loss: 4.292135238647461, acc: 0.2348484843969345)
[2024-12-17 01:41:40,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:40,943][root][INFO] - Training Epoch: 1/2, step 1630/7134 completed (loss: 4.532287120819092, acc: 0.25531914830207825)
[2024-12-17 01:41:41,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:41,232][root][INFO] - Training Epoch: 1/2, step 1631/7134 completed (loss: 4.713044166564941, acc: 0.2158273309469223)
[2024-12-17 01:41:41,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:41,500][root][INFO] - Training Epoch: 1/2, step 1632/7134 completed (loss: 4.448925018310547, acc: 0.305970162153244)
[2024-12-17 01:41:41,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:41,785][root][INFO] - Training Epoch: 1/2, step 1633/7134 completed (loss: 4.566647052764893, acc: 0.2857142984867096)
[2024-12-17 01:41:41,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:42,082][root][INFO] - Training Epoch: 1/2, step 1634/7134 completed (loss: 3.9867050647735596, acc: 0.2578616440296173)
[2024-12-17 01:41:42,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:42,366][root][INFO] - Training Epoch: 1/2, step 1635/7134 completed (loss: 4.413488388061523, acc: 0.2777777910232544)
[2024-12-17 01:41:42,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:42,660][root][INFO] - Training Epoch: 1/2, step 1636/7134 completed (loss: 5.2686543464660645, acc: 0.19266055524349213)
[2024-12-17 01:41:42,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:42,948][root][INFO] - Training Epoch: 1/2, step 1637/7134 completed (loss: 4.125406265258789, acc: 0.2732919156551361)
[2024-12-17 01:41:43,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:43,237][root][INFO] - Training Epoch: 1/2, step 1638/7134 completed (loss: 4.176365852355957, acc: 0.3385826647281647)
[2024-12-17 01:41:43,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:43,518][root][INFO] - Training Epoch: 1/2, step 1639/7134 completed (loss: 4.431713581085205, acc: 0.30434781312942505)
[2024-12-17 01:41:43,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:43,802][root][INFO] - Training Epoch: 1/2, step 1640/7134 completed (loss: 3.5945065021514893, acc: 0.3840579688549042)
[2024-12-17 01:41:43,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:44,080][root][INFO] - Training Epoch: 1/2, step 1641/7134 completed (loss: 3.1599783897399902, acc: 0.40789473056793213)
[2024-12-17 01:41:44,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:44,359][root][INFO] - Training Epoch: 1/2, step 1642/7134 completed (loss: 4.270529747009277, acc: 0.30817610025405884)
[2024-12-17 01:41:44,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:44,623][root][INFO] - Training Epoch: 1/2, step 1643/7134 completed (loss: 4.7777628898620605, acc: 0.2454545497894287)
[2024-12-17 01:41:44,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:44,908][root][INFO] - Training Epoch: 1/2, step 1644/7134 completed (loss: 4.114231109619141, acc: 0.3522012531757355)
[2024-12-17 01:41:45,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:45,190][root][INFO] - Training Epoch: 1/2, step 1645/7134 completed (loss: 4.352503776550293, acc: 0.2689655125141144)
[2024-12-17 01:41:45,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:45,472][root][INFO] - Training Epoch: 1/2, step 1646/7134 completed (loss: 3.987539768218994, acc: 0.3677419424057007)
[2024-12-17 01:41:45,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:45,751][root][INFO] - Training Epoch: 1/2, step 1647/7134 completed (loss: 3.572340726852417, acc: 0.3708920180797577)
[2024-12-17 01:41:45,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:46,033][root][INFO] - Training Epoch: 1/2, step 1648/7134 completed (loss: 4.239709854125977, acc: 0.24875621497631073)
[2024-12-17 01:41:46,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:46,310][root][INFO] - Training Epoch: 1/2, step 1649/7134 completed (loss: 3.8084146976470947, acc: 0.3053097426891327)
[2024-12-17 01:41:46,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:46,588][root][INFO] - Training Epoch: 1/2, step 1650/7134 completed (loss: 4.227600574493408, acc: 0.26633167266845703)
[2024-12-17 01:41:46,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:46,863][root][INFO] - Training Epoch: 1/2, step 1651/7134 completed (loss: 4.078948020935059, acc: 0.26363635063171387)
[2024-12-17 01:41:46,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:47,176][root][INFO] - Training Epoch: 1/2, step 1652/7134 completed (loss: 4.214559555053711, acc: 0.2777777910232544)
[2024-12-17 01:41:47,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:47,452][root][INFO] - Training Epoch: 1/2, step 1653/7134 completed (loss: 4.533447742462158, acc: 0.24043716490268707)
[2024-12-17 01:41:47,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:47,754][root][INFO] - Training Epoch: 1/2, step 1654/7134 completed (loss: 3.9868662357330322, acc: 0.29184550046920776)
[2024-12-17 01:41:47,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:48,045][root][INFO] - Training Epoch: 1/2, step 1655/7134 completed (loss: 4.3192138671875, acc: 0.26530611515045166)
[2024-12-17 01:41:48,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:48,317][root][INFO] - Training Epoch: 1/2, step 1656/7134 completed (loss: 3.9195539951324463, acc: 0.2959641218185425)
[2024-12-17 01:41:48,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:48,612][root][INFO] - Training Epoch: 1/2, step 1657/7134 completed (loss: 3.725863456726074, acc: 0.302325576543808)
[2024-12-17 01:41:48,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:48,887][root][INFO] - Training Epoch: 1/2, step 1658/7134 completed (loss: 3.766371488571167, acc: 0.2697095572948456)
[2024-12-17 01:41:48,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:49,163][root][INFO] - Training Epoch: 1/2, step 1659/7134 completed (loss: 4.022530555725098, acc: 0.2720000147819519)
[2024-12-17 01:41:49,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:49,448][root][INFO] - Training Epoch: 1/2, step 1660/7134 completed (loss: 3.98348069190979, acc: 0.2836538553237915)
[2024-12-17 01:41:49,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:49,731][root][INFO] - Training Epoch: 1/2, step 1661/7134 completed (loss: 3.885535478591919, acc: 0.29004329442977905)
[2024-12-17 01:41:49,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:50,005][root][INFO] - Training Epoch: 1/2, step 1662/7134 completed (loss: 3.491488456726074, acc: 0.3222748935222626)
[2024-12-17 01:41:50,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:50,288][root][INFO] - Training Epoch: 1/2, step 1663/7134 completed (loss: 3.969839334487915, acc: 0.2680850923061371)
[2024-12-17 01:41:50,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:50,561][root][INFO] - Training Epoch: 1/2, step 1664/7134 completed (loss: 4.0189032554626465, acc: 0.2750000059604645)
[2024-12-17 01:41:50,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:50,850][root][INFO] - Training Epoch: 1/2, step 1665/7134 completed (loss: 3.546578884124756, acc: 0.3128834366798401)
[2024-12-17 01:41:50,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:51,218][root][INFO] - Training Epoch: 1/2, step 1666/7134 completed (loss: 3.725315809249878, acc: 0.2689075767993927)
[2024-12-17 01:41:51,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:51,504][root][INFO] - Training Epoch: 1/2, step 1667/7134 completed (loss: 3.6661510467529297, acc: 0.2626262605190277)
[2024-12-17 01:41:51,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:51,782][root][INFO] - Training Epoch: 1/2, step 1668/7134 completed (loss: 3.5531904697418213, acc: 0.30493274331092834)
[2024-12-17 01:41:51,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:52,085][root][INFO] - Training Epoch: 1/2, step 1669/7134 completed (loss: 3.5478293895721436, acc: 0.3206106722354889)
[2024-12-17 01:41:52,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:52,381][root][INFO] - Training Epoch: 1/2, step 1670/7134 completed (loss: 3.4031617641448975, acc: 0.3460076153278351)
[2024-12-17 01:41:52,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:52,660][root][INFO] - Training Epoch: 1/2, step 1671/7134 completed (loss: 3.489570379257202, acc: 0.3571428656578064)
[2024-12-17 01:41:52,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:52,949][root][INFO] - Training Epoch: 1/2, step 1672/7134 completed (loss: 3.845571756362915, acc: 0.30994153022766113)
[2024-12-17 01:41:53,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:53,232][root][INFO] - Training Epoch: 1/2, step 1673/7134 completed (loss: 3.8747475147247314, acc: 0.26708075404167175)
[2024-12-17 01:41:53,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:53,500][root][INFO] - Training Epoch: 1/2, step 1674/7134 completed (loss: 4.129823684692383, acc: 0.32894736528396606)
[2024-12-17 01:41:53,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:53,783][root][INFO] - Training Epoch: 1/2, step 1675/7134 completed (loss: 4.2591352462768555, acc: 0.30136987566947937)
[2024-12-17 01:41:53,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:54,061][root][INFO] - Training Epoch: 1/2, step 1676/7134 completed (loss: 3.9138219356536865, acc: 0.31410256028175354)
[2024-12-17 01:41:54,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:54,326][root][INFO] - Training Epoch: 1/2, step 1677/7134 completed (loss: 4.0287089347839355, acc: 0.3404255211353302)
[2024-12-17 01:41:54,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:54,614][root][INFO] - Training Epoch: 1/2, step 1678/7134 completed (loss: 3.9269678592681885, acc: 0.2934131622314453)
[2024-12-17 01:41:54,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:54,889][root][INFO] - Training Epoch: 1/2, step 1679/7134 completed (loss: 4.0909528732299805, acc: 0.2926829159259796)
[2024-12-17 01:41:54,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:55,174][root][INFO] - Training Epoch: 1/2, step 1680/7134 completed (loss: 3.863619804382324, acc: 0.30000001192092896)
[2024-12-17 01:41:55,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:55,445][root][INFO] - Training Epoch: 1/2, step 1681/7134 completed (loss: 4.240788459777832, acc: 0.28930819034576416)
[2024-12-17 01:41:55,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:55,723][root][INFO] - Training Epoch: 1/2, step 1682/7134 completed (loss: 4.41519021987915, acc: 0.2602739632129669)
[2024-12-17 01:41:55,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:56,021][root][INFO] - Training Epoch: 1/2, step 1683/7134 completed (loss: 3.506850242614746, acc: 0.35172414779663086)
[2024-12-17 01:41:56,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:56,303][root][INFO] - Training Epoch: 1/2, step 1684/7134 completed (loss: 3.8449325561523438, acc: 0.347517728805542)
[2024-12-17 01:41:56,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:56,589][root][INFO] - Training Epoch: 1/2, step 1685/7134 completed (loss: 3.8042736053466797, acc: 0.30909091234207153)
[2024-12-17 01:41:56,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:56,872][root][INFO] - Training Epoch: 1/2, step 1686/7134 completed (loss: 4.155917167663574, acc: 0.25563910603523254)
[2024-12-17 01:41:57,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:57,208][root][INFO] - Training Epoch: 1/2, step 1687/7134 completed (loss: 3.856207847595215, acc: 0.36283186078071594)
[2024-12-17 01:41:57,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:57,465][root][INFO] - Training Epoch: 1/2, step 1688/7134 completed (loss: 3.838656187057495, acc: 0.3287671208381653)
[2024-12-17 01:41:57,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:57,739][root][INFO] - Training Epoch: 1/2, step 1689/7134 completed (loss: 3.9676241874694824, acc: 0.3096774220466614)
[2024-12-17 01:41:57,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:58,017][root][INFO] - Training Epoch: 1/2, step 1690/7134 completed (loss: 4.222322463989258, acc: 0.2300885021686554)
[2024-12-17 01:41:58,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:58,293][root][INFO] - Training Epoch: 1/2, step 1691/7134 completed (loss: 4.3627729415893555, acc: 0.19858156144618988)
[2024-12-17 01:41:58,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:58,614][root][INFO] - Training Epoch: 1/2, step 1692/7134 completed (loss: 4.627601623535156, acc: 0.23577235639095306)
[2024-12-17 01:41:58,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:58,912][root][INFO] - Training Epoch: 1/2, step 1693/7134 completed (loss: 3.773371934890747, acc: 0.3469387888908386)
[2024-12-17 01:41:59,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:59,206][root][INFO] - Training Epoch: 1/2, step 1694/7134 completed (loss: 4.008593559265137, acc: 0.2689655125141144)
[2024-12-17 01:41:59,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:59,498][root][INFO] - Training Epoch: 1/2, step 1695/7134 completed (loss: 4.0502095222473145, acc: 0.26050421595573425)
[2024-12-17 01:41:59,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:59,769][root][INFO] - Training Epoch: 1/2, step 1696/7134 completed (loss: 4.190178394317627, acc: 0.27067670226097107)
[2024-12-17 01:41:59,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:00,035][root][INFO] - Training Epoch: 1/2, step 1697/7134 completed (loss: 3.8524348735809326, acc: 0.279720276594162)
[2024-12-17 01:42:00,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:00,317][root][INFO] - Training Epoch: 1/2, step 1698/7134 completed (loss: 4.021171569824219, acc: 0.2377622425556183)
[2024-12-17 01:42:00,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:00,597][root][INFO] - Training Epoch: 1/2, step 1699/7134 completed (loss: 3.894270181655884, acc: 0.29104477167129517)
[2024-12-17 01:42:00,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:00,880][root][INFO] - Training Epoch: 1/2, step 1700/7134 completed (loss: 4.262760639190674, acc: 0.28358209133148193)
[2024-12-17 01:42:00,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:01,148][root][INFO] - Training Epoch: 1/2, step 1701/7134 completed (loss: 3.817652702331543, acc: 0.36666667461395264)
[2024-12-17 01:42:01,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:01,425][root][INFO] - Training Epoch: 1/2, step 1702/7134 completed (loss: 4.115225791931152, acc: 0.3053892254829407)
[2024-12-17 01:42:01,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:01,710][root][INFO] - Training Epoch: 1/2, step 1703/7134 completed (loss: 4.411149501800537, acc: 0.2715231776237488)
[2024-12-17 01:42:01,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:01,998][root][INFO] - Training Epoch: 1/2, step 1704/7134 completed (loss: 4.3184075355529785, acc: 0.3109756112098694)
[2024-12-17 01:42:02,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:02,320][root][INFO] - Training Epoch: 1/2, step 1705/7134 completed (loss: 4.299574375152588, acc: 0.2800000011920929)
[2024-12-17 01:42:02,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:02,527][root][INFO] - Training Epoch: 1/2, step 1706/7134 completed (loss: 3.968778371810913, acc: 0.30000001192092896)
[2024-12-17 01:42:02,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:02,806][root][INFO] - Training Epoch: 1/2, step 1707/7134 completed (loss: 4.12081241607666, acc: 0.27586206793785095)
[2024-12-17 01:42:02,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:03,080][root][INFO] - Training Epoch: 1/2, step 1708/7134 completed (loss: 4.017434120178223, acc: 0.25925925374031067)
[2024-12-17 01:42:03,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:03,339][root][INFO] - Training Epoch: 1/2, step 1709/7134 completed (loss: 4.546986103057861, acc: 0.23999999463558197)
[2024-12-17 01:42:03,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:03,641][root][INFO] - Training Epoch: 1/2, step 1710/7134 completed (loss: 4.113162517547607, acc: 0.3175675570964813)
[2024-12-17 01:42:03,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:03,900][root][INFO] - Training Epoch: 1/2, step 1711/7134 completed (loss: 4.170597076416016, acc: 0.2338709682226181)
[2024-12-17 01:42:04,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:04,172][root][INFO] - Training Epoch: 1/2, step 1712/7134 completed (loss: 3.702956438064575, acc: 0.3333333432674408)
[2024-12-17 01:42:04,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:04,438][root][INFO] - Training Epoch: 1/2, step 1713/7134 completed (loss: 4.653034210205078, acc: 0.2571428716182709)
[2024-12-17 01:42:04,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:04,722][root][INFO] - Training Epoch: 1/2, step 1714/7134 completed (loss: 4.185948848724365, acc: 0.27659574151039124)
[2024-12-17 01:42:04,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:04,992][root][INFO] - Training Epoch: 1/2, step 1715/7134 completed (loss: 4.611913204193115, acc: 0.25471699237823486)
[2024-12-17 01:42:05,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:05,250][root][INFO] - Training Epoch: 1/2, step 1716/7134 completed (loss: 4.3415069580078125, acc: 0.31578946113586426)
[2024-12-17 01:42:05,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:05,497][root][INFO] - Training Epoch: 1/2, step 1717/7134 completed (loss: 4.491231918334961, acc: 0.27131783962249756)
[2024-12-17 01:42:05,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:05,803][root][INFO] - Training Epoch: 1/2, step 1718/7134 completed (loss: 4.470179557800293, acc: 0.25641027092933655)
[2024-12-17 01:42:05,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:06,099][root][INFO] - Training Epoch: 1/2, step 1719/7134 completed (loss: 4.564128398895264, acc: 0.2781065106391907)
[2024-12-17 01:42:06,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:06,388][root][INFO] - Training Epoch: 1/2, step 1720/7134 completed (loss: 4.783310890197754, acc: 0.2153846174478531)
[2024-12-17 01:42:06,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:06,666][root][INFO] - Training Epoch: 1/2, step 1721/7134 completed (loss: 4.247099876403809, acc: 0.265625)
[2024-12-17 01:42:06,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:06,937][root][INFO] - Training Epoch: 1/2, step 1722/7134 completed (loss: 4.182334899902344, acc: 0.24242424964904785)
[2024-12-17 01:42:07,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:07,207][root][INFO] - Training Epoch: 1/2, step 1723/7134 completed (loss: 4.358792304992676, acc: 0.32098764181137085)
[2024-12-17 01:42:07,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:07,506][root][INFO] - Training Epoch: 1/2, step 1724/7134 completed (loss: 4.122957229614258, acc: 0.25)
[2024-12-17 01:42:07,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:07,759][root][INFO] - Training Epoch: 1/2, step 1725/7134 completed (loss: 4.32429313659668, acc: 0.26865673065185547)
[2024-12-17 01:42:07,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:08,017][root][INFO] - Training Epoch: 1/2, step 1726/7134 completed (loss: 3.7210450172424316, acc: 0.34408602118492126)
[2024-12-17 01:42:08,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:08,277][root][INFO] - Training Epoch: 1/2, step 1727/7134 completed (loss: 4.4885382652282715, acc: 0.2654867172241211)
[2024-12-17 01:42:08,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:08,554][root][INFO] - Training Epoch: 1/2, step 1728/7134 completed (loss: 3.9660696983337402, acc: 0.29230770468711853)
[2024-12-17 01:42:08,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:08,804][root][INFO] - Training Epoch: 1/2, step 1729/7134 completed (loss: 4.239169120788574, acc: 0.2522522509098053)
[2024-12-17 01:42:08,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:09,082][root][INFO] - Training Epoch: 1/2, step 1730/7134 completed (loss: 4.281778812408447, acc: 0.28037384152412415)
[2024-12-17 01:42:09,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:09,325][root][INFO] - Training Epoch: 1/2, step 1731/7134 completed (loss: 4.205682277679443, acc: 0.3132530152797699)
[2024-12-17 01:42:09,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:09,573][root][INFO] - Training Epoch: 1/2, step 1732/7134 completed (loss: 4.055777072906494, acc: 0.3333333432674408)
[2024-12-17 01:42:09,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:09,824][root][INFO] - Training Epoch: 1/2, step 1733/7134 completed (loss: 4.202756881713867, acc: 0.302752286195755)
[2024-12-17 01:42:09,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:10,107][root][INFO] - Training Epoch: 1/2, step 1734/7134 completed (loss: 4.038647651672363, acc: 0.3313252925872803)
[2024-12-17 01:42:10,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:10,380][root][INFO] - Training Epoch: 1/2, step 1735/7134 completed (loss: 3.984921932220459, acc: 0.2384105920791626)
[2024-12-17 01:42:10,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:10,657][root][INFO] - Training Epoch: 1/2, step 1736/7134 completed (loss: 4.400092124938965, acc: 0.29113924503326416)
[2024-12-17 01:42:10,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:10,934][root][INFO] - Training Epoch: 1/2, step 1737/7134 completed (loss: 4.030270099639893, acc: 0.3400000035762787)
[2024-12-17 01:42:11,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:11,210][root][INFO] - Training Epoch: 1/2, step 1738/7134 completed (loss: 4.334660053253174, acc: 0.24581006169319153)
[2024-12-17 01:42:11,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:11,484][root][INFO] - Training Epoch: 1/2, step 1739/7134 completed (loss: 4.225249767303467, acc: 0.29323309659957886)
[2024-12-17 01:42:11,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:11,760][root][INFO] - Training Epoch: 1/2, step 1740/7134 completed (loss: 4.023359298706055, acc: 0.30405405163764954)
[2024-12-17 01:42:11,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:12,056][root][INFO] - Training Epoch: 1/2, step 1741/7134 completed (loss: 4.163137912750244, acc: 0.25465837121009827)
[2024-12-17 01:42:12,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:12,331][root][INFO] - Training Epoch: 1/2, step 1742/7134 completed (loss: 4.216954708099365, acc: 0.3178808093070984)
[2024-12-17 01:42:12,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:12,624][root][INFO] - Training Epoch: 1/2, step 1743/7134 completed (loss: 4.287742614746094, acc: 0.27210885286331177)
[2024-12-17 01:42:12,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:12,908][root][INFO] - Training Epoch: 1/2, step 1744/7134 completed (loss: 3.908407688140869, acc: 0.27819550037384033)
[2024-12-17 01:42:13,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:13,194][root][INFO] - Training Epoch: 1/2, step 1745/7134 completed (loss: 4.311399936676025, acc: 0.30000001192092896)
[2024-12-17 01:42:13,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:13,473][root][INFO] - Training Epoch: 1/2, step 1746/7134 completed (loss: 3.8389527797698975, acc: 0.326241135597229)
[2024-12-17 01:42:13,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:13,779][root][INFO] - Training Epoch: 1/2, step 1747/7134 completed (loss: 4.2920403480529785, acc: 0.2804878056049347)
[2024-12-17 01:42:13,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:14,090][root][INFO] - Training Epoch: 1/2, step 1748/7134 completed (loss: 4.1294379234313965, acc: 0.29411765933036804)
[2024-12-17 01:42:14,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:14,423][root][INFO] - Training Epoch: 1/2, step 1749/7134 completed (loss: 3.9245152473449707, acc: 0.3036649227142334)
[2024-12-17 01:42:14,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:14,756][root][INFO] - Training Epoch: 1/2, step 1750/7134 completed (loss: 3.819582939147949, acc: 0.3254437744617462)
[2024-12-17 01:42:14,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:15,035][root][INFO] - Training Epoch: 1/2, step 1751/7134 completed (loss: 3.9938838481903076, acc: 0.3333333432674408)
[2024-12-17 01:42:15,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:15,319][root][INFO] - Training Epoch: 1/2, step 1752/7134 completed (loss: 4.219364166259766, acc: 0.2666666805744171)
[2024-12-17 01:42:15,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:15,590][root][INFO] - Training Epoch: 1/2, step 1753/7134 completed (loss: 3.8957948684692383, acc: 0.29801324009895325)
[2024-12-17 01:42:15,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:15,858][root][INFO] - Training Epoch: 1/2, step 1754/7134 completed (loss: 4.093653678894043, acc: 0.3137255012989044)
[2024-12-17 01:42:15,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:16,141][root][INFO] - Training Epoch: 1/2, step 1755/7134 completed (loss: 4.208203315734863, acc: 0.24183006584644318)
[2024-12-17 01:42:16,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:16,427][root][INFO] - Training Epoch: 1/2, step 1756/7134 completed (loss: 4.193049907684326, acc: 0.2800000011920929)
[2024-12-17 01:42:16,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:16,705][root][INFO] - Training Epoch: 1/2, step 1757/7134 completed (loss: 4.194669246673584, acc: 0.23966942727565765)
[2024-12-17 01:42:16,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:16,996][root][INFO] - Training Epoch: 1/2, step 1758/7134 completed (loss: 3.8408641815185547, acc: 0.3117647171020508)
[2024-12-17 01:42:17,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:17,278][root][INFO] - Training Epoch: 1/2, step 1759/7134 completed (loss: 4.2704758644104, acc: 0.2565789520740509)
[2024-12-17 01:42:17,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:17,550][root][INFO] - Training Epoch: 1/2, step 1760/7134 completed (loss: 3.9708304405212402, acc: 0.2950819730758667)
[2024-12-17 01:42:17,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:17,806][root][INFO] - Training Epoch: 1/2, step 1761/7134 completed (loss: 4.458892822265625, acc: 0.30000001192092896)
[2024-12-17 01:42:17,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:18,099][root][INFO] - Training Epoch: 1/2, step 1762/7134 completed (loss: 4.123579978942871, acc: 0.3203883469104767)
[2024-12-17 01:42:18,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:18,384][root][INFO] - Training Epoch: 1/2, step 1763/7134 completed (loss: 3.2036869525909424, acc: 0.4726027250289917)
[2024-12-17 01:42:18,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:18,665][root][INFO] - Training Epoch: 1/2, step 1764/7134 completed (loss: 3.550340175628662, acc: 0.33870968222618103)
[2024-12-17 01:42:18,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:18,945][root][INFO] - Training Epoch: 1/2, step 1765/7134 completed (loss: 3.5990169048309326, acc: 0.33986929059028625)
[2024-12-17 01:42:19,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:19,222][root][INFO] - Training Epoch: 1/2, step 1766/7134 completed (loss: 3.960559844970703, acc: 0.31168830394744873)
[2024-12-17 01:42:19,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:19,510][root][INFO] - Training Epoch: 1/2, step 1767/7134 completed (loss: 4.004124641418457, acc: 0.2768361568450928)
[2024-12-17 01:42:19,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:19,790][root][INFO] - Training Epoch: 1/2, step 1768/7134 completed (loss: 3.7263646125793457, acc: 0.3214285671710968)
[2024-12-17 01:42:19,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:20,120][root][INFO] - Training Epoch: 1/2, step 1769/7134 completed (loss: 3.951446056365967, acc: 0.31333333253860474)
[2024-12-17 01:42:20,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:20,391][root][INFO] - Training Epoch: 1/2, step 1770/7134 completed (loss: 3.834127426147461, acc: 0.33561643958091736)
[2024-12-17 01:42:20,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:20,667][root][INFO] - Training Epoch: 1/2, step 1771/7134 completed (loss: 4.380633354187012, acc: 0.25974026322364807)
[2024-12-17 01:42:20,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:20,983][root][INFO] - Training Epoch: 1/2, step 1772/7134 completed (loss: 4.1276068687438965, acc: 0.2857142984867096)
[2024-12-17 01:42:21,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:21,263][root][INFO] - Training Epoch: 1/2, step 1773/7134 completed (loss: 3.795020580291748, acc: 0.3617021143436432)
[2024-12-17 01:42:21,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:21,565][root][INFO] - Training Epoch: 1/2, step 1774/7134 completed (loss: 3.801546096801758, acc: 0.32575756311416626)
[2024-12-17 01:42:21,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:21,831][root][INFO] - Training Epoch: 1/2, step 1775/7134 completed (loss: 3.5191640853881836, acc: 0.30136987566947937)
[2024-12-17 01:42:21,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:22,101][root][INFO] - Training Epoch: 1/2, step 1776/7134 completed (loss: 3.7723541259765625, acc: 0.27586206793785095)
[2024-12-17 01:42:22,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:22,392][root][INFO] - Training Epoch: 1/2, step 1777/7134 completed (loss: 3.21830677986145, acc: 0.337579607963562)
[2024-12-17 01:42:22,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:22,663][root][INFO] - Training Epoch: 1/2, step 1778/7134 completed (loss: 3.9163026809692383, acc: 0.3270440399646759)
[2024-12-17 01:42:22,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:22,936][root][INFO] - Training Epoch: 1/2, step 1779/7134 completed (loss: 3.5232338905334473, acc: 0.37168142199516296)
[2024-12-17 01:42:23,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:23,286][root][INFO] - Training Epoch: 1/2, step 1780/7134 completed (loss: 3.6550683975219727, acc: 0.299401193857193)
[2024-12-17 01:42:23,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:23,555][root][INFO] - Training Epoch: 1/2, step 1781/7134 completed (loss: 4.017095565795898, acc: 0.24832214415073395)
[2024-12-17 01:42:23,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:23,834][root][INFO] - Training Epoch: 1/2, step 1782/7134 completed (loss: 3.8461968898773193, acc: 0.30128204822540283)
[2024-12-17 01:42:27,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:29,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:29,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:29,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:30,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:30,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:30,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:31,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:32,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:32,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:32,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:34,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:34,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:34,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:34,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:35,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:35,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:35,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:36,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:36,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:36,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:36,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:37,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:37,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:37,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:38,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:38,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:38,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:39,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:39,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:40,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:40,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:40,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:41,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:41,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:41,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:41,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:42,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:42,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:42,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:43,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:43,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:43,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:44,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:44,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:44,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:45,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:45,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:45,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:46,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:46,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:46,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:47,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:47,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:47,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:48,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:48,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:48,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:49,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:49,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:49,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:49,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:50,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:50,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:51,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:51,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:51,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:51,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:52,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:52,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:52,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:52,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:53,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:53,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:53,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:54,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:54,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:54,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:54,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:55,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:55,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:55,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:55,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:56,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:56,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:56,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:57,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:57,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:57,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:58,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:58,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:58,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:58,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:59,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:59,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:59,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:00,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:00,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:00,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:00,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:01,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:01,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:01,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:02,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:02,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:02,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:02,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:03,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:03,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:03,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:04,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:04,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:04,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:04,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:05,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:05,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:05,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:06,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:06,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:06,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:07,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:07,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:07,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:07,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:08,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:08,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:08,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:09,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:09,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:09,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:10,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:10,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:10,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:11,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:11,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:11,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:12,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:12,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:12,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:13,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:13,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:13,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:14,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:14,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:14,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:14,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:15,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:15,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:16,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:16,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:16,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:17,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:17,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:17,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:18,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:18,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:18,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:18,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:19,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:19,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:19,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:20,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:20,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:21,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:21,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:21,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:22,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:22,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:22,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:23,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:23,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:23,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:23,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:24,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:24,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:24,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:24,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:25,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:25,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:25,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:26,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:26,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:26,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:27,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:27,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:27,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:28,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:28,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:28,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:29,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:29,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:29,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:29,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:30,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:30,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:30,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:31,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:31,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:31,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:32,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:32,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:32,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:33,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:33,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:33,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:34,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:34,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:34,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:34,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:35,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:35,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:35,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:36,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:36,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:36,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:37,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:37,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:37,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:38,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:38,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:38,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:39,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:39,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:39,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:39,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:40,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:40,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:40,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:40,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:41,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:41,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:41,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:41,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:42,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:42,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:42,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:43,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:43,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:43,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:44,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:44,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:44,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:45,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:45,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:46,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:46,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:46,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:47,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:47,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:47,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:48,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:48,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:48,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:48,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:49,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:49,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:49,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:49,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:50,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:50,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:50,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:51,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:51,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:51,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:52,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:52,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:52,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:53,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:53,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:53,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:54,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:54,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:55,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:55,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:55,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:56,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:56,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:56,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:57,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:57,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:57,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:58,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:58,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:58,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:59,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:59,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:59,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:00,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:00,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:01,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:01,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:01,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:02,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:02,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:02,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:03,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:03,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:04,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:04,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:04,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:05,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:05,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:05,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:05,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:06,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:06,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:06,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:07,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:07,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:07,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:08,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:08,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:08,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:08,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:09,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:09,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:09,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:10,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:10,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:10,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:11,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:11,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:11,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:11,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:12,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:12,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:13,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:13,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:13,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:14,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:14,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:14,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:14,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:15,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:15,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:15,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:16,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:16,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:17,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:17,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:17,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:17,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:18,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:18,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:19,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:19,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:19,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:20,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:20,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:20,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:21,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:21,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:21,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:22,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:22,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:23,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:23,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:23,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:23,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:24,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:24,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:25,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:25,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:26,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:26,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:27,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:27,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:27,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:28,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:28,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:28,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:28,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:29,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:29,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:29,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:30,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:30,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:30,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:31,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:31,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:31,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:32,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:32,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:32,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:33,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:33,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:33,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:34,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:34,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:34,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:34,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:35,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:35,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:35,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:36,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:36,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:36,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:37,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:37,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:37,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:37,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:38,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:38,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:38,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:39,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:39,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:39,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:39,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:40,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:40,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:40,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:40,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:41,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:41,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:41,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:42,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:42,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:42,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:43,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:43,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:43,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:44,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:44,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:44,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:44,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:45,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:45,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:45,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:46,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:46,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:46,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:47,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:47,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:47,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:48,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:48,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:48,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:48,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:49,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:49,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:49,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:50,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:50,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:50,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:51,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:51,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:51,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:51,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:52,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:52,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:52,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:53,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:53,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:53,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:54,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:54,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:54,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:54,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:55,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:55,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:55,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:56,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:56,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:56,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:57,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:57,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:57,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:58,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:58,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:58,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:58,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:59,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:59,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:59,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:00,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:00,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:00,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:01,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:01,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:01,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:02,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:02,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:03,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:03,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:03,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:04,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:04,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:04,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:04,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:05,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:05,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:05,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:06,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:06,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:06,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:07,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:07,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:07,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:08,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:08,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:08,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:09,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:09,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:09,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:10,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:10,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:10,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:10,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:11,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:11,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:11,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:12,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:12,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:12,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:13,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:13,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:13,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:14,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:14,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:14,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:15,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:15,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:15,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:16,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:16,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:16,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:17,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:17,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:17,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:18,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:18,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:18,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:19,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:19,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:19,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:20,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:20,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:20,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:20,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:21,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:21,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:21,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:21,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:22,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:22,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:22,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:23,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:23,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:23,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:24,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:24,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:24,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:25,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:25,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:25,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:26,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:26,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:26,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:26,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:27,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:27,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:27,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:28,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:28,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:28,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:29,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:29,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:29,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:30,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:30,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:30,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:30,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:31,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:31,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:31,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:32,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:32,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:32,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:33,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:33,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:34,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:34,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:34,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:35,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:35,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:35,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:36,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:36,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:37,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:37,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:37,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:37,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:38,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:38,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:38,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:39,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:39,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:39,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:39,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:40,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:40,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:40,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:40,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:41,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:41,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:41,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:42,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:42,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:42,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:43,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:43,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:43,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:44,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:44,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:44,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:44,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:45,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:45,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:45,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:46,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:46,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:46,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:46,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:47,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:47,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:48,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:48,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:49,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:49,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:49,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:50,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:50,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:50,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:51,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:51,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:52,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:52,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:53,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:53,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:53,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:54,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:54,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:54,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:54,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:55,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:55,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:55,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:56,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:56,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:56,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:57,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:57,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:57,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:57,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:58,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:58,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:58,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:59,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:59,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:59,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:59,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:00,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:00,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:00,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:00,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:01,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:01,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:01,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:02,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:02,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:02,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:03,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:03,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:03,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:04,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:04,834][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(56.1883, device='cuda:0') eval_epoch_loss=tensor(4.0287, device='cuda:0') eval_epoch_acc=tensor(0.2968, device='cuda:0')
[2024-12-17 01:46:04,836][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-12-17 01:46:04,836][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 01:46:05,041][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_1_step_1783_loss_4.0287089347839355/model.pt
[2024-12-17 01:46:05,050][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 4.0287089347839355
[2024-12-17 01:46:05,051][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.2967861592769623
[2024-12-17 01:46:05,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:05,368][root][INFO] - Training Epoch: 1/2, step 1783/7134 completed (loss: 3.8697702884674072, acc: 0.2947976887226105)
[2024-12-17 01:46:05,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:05,644][root][INFO] - Training Epoch: 1/2, step 1784/7134 completed (loss: 3.70563006401062, acc: 0.3205128312110901)
[2024-12-17 01:46:05,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:05,923][root][INFO] - Training Epoch: 1/2, step 1785/7134 completed (loss: 3.979539632797241, acc: 0.28915661573410034)
[2024-12-17 01:46:06,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:06,192][root][INFO] - Training Epoch: 1/2, step 1786/7134 completed (loss: 3.942678928375244, acc: 0.2967741787433624)
[2024-12-17 01:46:06,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:06,477][root][INFO] - Training Epoch: 1/2, step 1787/7134 completed (loss: 4.324655055999756, acc: 0.26865673065185547)
[2024-12-17 01:46:06,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:06,758][root][INFO] - Training Epoch: 1/2, step 1788/7134 completed (loss: 3.9392662048339844, acc: 0.25517240166664124)
[2024-12-17 01:46:06,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:07,046][root][INFO] - Training Epoch: 1/2, step 1789/7134 completed (loss: 4.190528392791748, acc: 0.2565789520740509)
[2024-12-17 01:46:07,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:07,431][root][INFO] - Training Epoch: 1/2, step 1790/7134 completed (loss: 3.5866026878356934, acc: 0.3290322721004486)
[2024-12-17 01:46:07,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:07,709][root][INFO] - Training Epoch: 1/2, step 1791/7134 completed (loss: 4.405677318572998, acc: 0.33128833770751953)
[2024-12-17 01:46:07,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:07,990][root][INFO] - Training Epoch: 1/2, step 1792/7134 completed (loss: 4.1598944664001465, acc: 0.2793295979499817)
[2024-12-17 01:46:08,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:08,273][root][INFO] - Training Epoch: 1/2, step 1793/7134 completed (loss: 4.313592433929443, acc: 0.3076923191547394)
[2024-12-17 01:46:08,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:08,565][root][INFO] - Training Epoch: 1/2, step 1794/7134 completed (loss: 4.3219523429870605, acc: 0.2565789520740509)
[2024-12-17 01:46:08,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:08,860][root][INFO] - Training Epoch: 1/2, step 1795/7134 completed (loss: 4.447664737701416, acc: 0.28125)
[2024-12-17 01:46:08,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:09,141][root][INFO] - Training Epoch: 1/2, step 1796/7134 completed (loss: 3.9877071380615234, acc: 0.3050847351551056)
[2024-12-17 01:46:09,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:09,421][root][INFO] - Training Epoch: 1/2, step 1797/7134 completed (loss: 4.35164213180542, acc: 0.2857142984867096)
[2024-12-17 01:46:09,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:09,703][root][INFO] - Training Epoch: 1/2, step 1798/7134 completed (loss: 4.490704536437988, acc: 0.26356589794158936)
[2024-12-17 01:46:09,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:09,985][root][INFO] - Training Epoch: 1/2, step 1799/7134 completed (loss: 4.171689510345459, acc: 0.3333333432674408)
[2024-12-17 01:46:10,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:10,264][root][INFO] - Training Epoch: 1/2, step 1800/7134 completed (loss: 4.448085784912109, acc: 0.3142857253551483)
[2024-12-17 01:46:10,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:10,539][root][INFO] - Training Epoch: 1/2, step 1801/7134 completed (loss: 4.365932941436768, acc: 0.27927929162979126)
[2024-12-17 01:46:10,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:10,811][root][INFO] - Training Epoch: 1/2, step 1802/7134 completed (loss: 4.084831237792969, acc: 0.28723403811454773)
[2024-12-17 01:46:10,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:11,082][root][INFO] - Training Epoch: 1/2, step 1803/7134 completed (loss: 4.233857154846191, acc: 0.3048780560493469)
[2024-12-17 01:46:11,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:11,346][root][INFO] - Training Epoch: 1/2, step 1804/7134 completed (loss: 3.933264970779419, acc: 0.29629629850387573)
[2024-12-17 01:46:11,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:11,616][root][INFO] - Training Epoch: 1/2, step 1805/7134 completed (loss: 3.706831455230713, acc: 0.28654971718788147)
[2024-12-17 01:46:11,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:11,911][root][INFO] - Training Epoch: 1/2, step 1806/7134 completed (loss: 3.9759602546691895, acc: 0.2950819730758667)
[2024-12-17 01:46:12,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:12,187][root][INFO] - Training Epoch: 1/2, step 1807/7134 completed (loss: 4.377192497253418, acc: 0.2409638613462448)
[2024-12-17 01:46:12,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:12,452][root][INFO] - Training Epoch: 1/2, step 1808/7134 completed (loss: 4.126077651977539, acc: 0.26553672552108765)
[2024-12-17 01:46:12,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:12,735][root][INFO] - Training Epoch: 1/2, step 1809/7134 completed (loss: 4.1324872970581055, acc: 0.2774566411972046)
[2024-12-17 01:46:12,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:13,019][root][INFO] - Training Epoch: 1/2, step 1810/7134 completed (loss: 3.9193782806396484, acc: 0.30219781398773193)
[2024-12-17 01:46:13,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:13,296][root][INFO] - Training Epoch: 1/2, step 1811/7134 completed (loss: 4.089592933654785, acc: 0.2819148898124695)
[2024-12-17 01:46:13,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:13,570][root][INFO] - Training Epoch: 1/2, step 1812/7134 completed (loss: 3.941458225250244, acc: 0.31073445081710815)
[2024-12-17 01:46:13,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:13,855][root][INFO] - Training Epoch: 1/2, step 1813/7134 completed (loss: 4.269706726074219, acc: 0.32596686482429504)
[2024-12-17 01:46:13,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:14,131][root][INFO] - Training Epoch: 1/2, step 1814/7134 completed (loss: 3.931778907775879, acc: 0.31491711735725403)
[2024-12-17 01:46:14,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:14,399][root][INFO] - Training Epoch: 1/2, step 1815/7134 completed (loss: 4.183183670043945, acc: 0.35668790340423584)
[2024-12-17 01:46:14,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:14,668][root][INFO] - Training Epoch: 1/2, step 1816/7134 completed (loss: 4.589627265930176, acc: 0.2777777910232544)
[2024-12-17 01:46:14,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:14,948][root][INFO] - Training Epoch: 1/2, step 1817/7134 completed (loss: 4.189591407775879, acc: 0.296875)
[2024-12-17 01:46:15,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:15,233][root][INFO] - Training Epoch: 1/2, step 1818/7134 completed (loss: 4.077662944793701, acc: 0.2879581153392792)
[2024-12-17 01:46:15,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:15,508][root][INFO] - Training Epoch: 1/2, step 1819/7134 completed (loss: 3.918438196182251, acc: 0.3372093141078949)
[2024-12-17 01:46:15,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:16,676][root][INFO] - Training Epoch: 1/2, step 1820/7134 completed (loss: 4.376464366912842, acc: 0.25471699237823486)
[2024-12-17 01:46:16,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:16,959][root][INFO] - Training Epoch: 1/2, step 1821/7134 completed (loss: 3.7211625576019287, acc: 0.3037383258342743)
[2024-12-17 01:46:17,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:17,219][root][INFO] - Training Epoch: 1/2, step 1822/7134 completed (loss: 3.9794042110443115, acc: 0.31578946113586426)
[2024-12-17 01:46:17,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:17,492][root][INFO] - Training Epoch: 1/2, step 1823/7134 completed (loss: 3.8743436336517334, acc: 0.302325576543808)
[2024-12-17 01:46:17,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:17,767][root][INFO] - Training Epoch: 1/2, step 1824/7134 completed (loss: 4.019784450531006, acc: 0.30054643750190735)
[2024-12-17 01:46:17,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:18,049][root][INFO] - Training Epoch: 1/2, step 1825/7134 completed (loss: 3.983452081680298, acc: 0.2710280418395996)
[2024-12-17 01:46:18,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:18,323][root][INFO] - Training Epoch: 1/2, step 1826/7134 completed (loss: 4.107702732086182, acc: 0.2163742631673813)
[2024-12-17 01:46:18,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:18,595][root][INFO] - Training Epoch: 1/2, step 1827/7134 completed (loss: 3.655640125274658, acc: 0.31753554940223694)
[2024-12-17 01:46:18,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:18,866][root][INFO] - Training Epoch: 1/2, step 1828/7134 completed (loss: 3.87166166305542, acc: 0.35555556416511536)
[2024-12-17 01:46:18,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:19,143][root][INFO] - Training Epoch: 1/2, step 1829/7134 completed (loss: 4.378960132598877, acc: 0.24731183052062988)
[2024-12-17 01:46:19,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:19,425][root][INFO] - Training Epoch: 1/2, step 1830/7134 completed (loss: 4.333707809448242, acc: 0.2331606149673462)
[2024-12-17 01:46:19,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:19,678][root][INFO] - Training Epoch: 1/2, step 1831/7134 completed (loss: 4.436801910400391, acc: 0.24242424964904785)
[2024-12-17 01:46:19,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:19,941][root][INFO] - Training Epoch: 1/2, step 1832/7134 completed (loss: 3.897949457168579, acc: 0.341085284948349)
[2024-12-17 01:46:20,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:20,220][root][INFO] - Training Epoch: 1/2, step 1833/7134 completed (loss: 4.240697860717773, acc: 0.27642276883125305)
[2024-12-17 01:46:20,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:20,503][root][INFO] - Training Epoch: 1/2, step 1834/7134 completed (loss: 3.5006701946258545, acc: 0.35256409645080566)
[2024-12-17 01:46:20,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:20,777][root][INFO] - Training Epoch: 1/2, step 1835/7134 completed (loss: 4.127239227294922, acc: 0.26623377203941345)
[2024-12-17 01:46:20,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:21,060][root][INFO] - Training Epoch: 1/2, step 1836/7134 completed (loss: 3.8544774055480957, acc: 0.31550800800323486)
[2024-12-17 01:46:21,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:21,336][root][INFO] - Training Epoch: 1/2, step 1837/7134 completed (loss: 4.249361038208008, acc: 0.2857142984867096)
[2024-12-17 01:46:21,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:21,565][root][INFO] - Training Epoch: 1/2, step 1838/7134 completed (loss: 4.069783687591553, acc: 0.29357796907424927)
[2024-12-17 01:46:21,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:21,847][root][INFO] - Training Epoch: 1/2, step 1839/7134 completed (loss: 3.7441718578338623, acc: 0.34065935015678406)
[2024-12-17 01:46:21,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:22,130][root][INFO] - Training Epoch: 1/2, step 1840/7134 completed (loss: 4.212584495544434, acc: 0.2721518874168396)
[2024-12-17 01:46:22,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:22,413][root][INFO] - Training Epoch: 1/2, step 1841/7134 completed (loss: 3.921659469604492, acc: 0.34545454382896423)
[2024-12-17 01:46:22,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:22,695][root][INFO] - Training Epoch: 1/2, step 1842/7134 completed (loss: 3.6916258335113525, acc: 0.3109756112098694)
[2024-12-17 01:46:22,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:22,965][root][INFO] - Training Epoch: 1/2, step 1843/7134 completed (loss: 3.9851443767547607, acc: 0.2976190447807312)
[2024-12-17 01:46:23,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:23,246][root][INFO] - Training Epoch: 1/2, step 1844/7134 completed (loss: 3.0816802978515625, acc: 0.3617021143436432)
[2024-12-17 01:46:23,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:23,531][root][INFO] - Training Epoch: 1/2, step 1845/7134 completed (loss: 3.936048984527588, acc: 0.31521740555763245)
[2024-12-17 01:46:23,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:23,803][root][INFO] - Training Epoch: 1/2, step 1846/7134 completed (loss: 3.505546808242798, acc: 0.3333333432674408)
[2024-12-17 01:46:23,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:24,086][root][INFO] - Training Epoch: 1/2, step 1847/7134 completed (loss: 4.03700590133667, acc: 0.2954545319080353)
[2024-12-17 01:46:24,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:24,374][root][INFO] - Training Epoch: 1/2, step 1848/7134 completed (loss: 4.256661891937256, acc: 0.24468085169792175)
[2024-12-17 01:46:24,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:24,647][root][INFO] - Training Epoch: 1/2, step 1849/7134 completed (loss: 4.261343479156494, acc: 0.26056337356567383)
[2024-12-17 01:46:24,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:24,930][root][INFO] - Training Epoch: 1/2, step 1850/7134 completed (loss: 4.124403953552246, acc: 0.32474225759506226)
[2024-12-17 01:46:25,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:25,211][root][INFO] - Training Epoch: 1/2, step 1851/7134 completed (loss: 4.052094459533691, acc: 0.2974359095096588)
[2024-12-17 01:46:25,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:25,478][root][INFO] - Training Epoch: 1/2, step 1852/7134 completed (loss: 4.552050590515137, acc: 0.2562499940395355)
[2024-12-17 01:46:25,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:25,753][root][INFO] - Training Epoch: 1/2, step 1853/7134 completed (loss: 3.8650290966033936, acc: 0.3467336595058441)
[2024-12-17 01:46:25,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:26,029][root][INFO] - Training Epoch: 1/2, step 1854/7134 completed (loss: 3.5338454246520996, acc: 0.3936651647090912)
[2024-12-17 01:46:26,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:26,310][root][INFO] - Training Epoch: 1/2, step 1855/7134 completed (loss: 3.9730663299560547, acc: 0.3364928960800171)
[2024-12-17 01:46:26,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:26,589][root][INFO] - Training Epoch: 1/2, step 1856/7134 completed (loss: 3.798459053039551, acc: 0.3520408272743225)
[2024-12-17 01:46:26,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:26,942][root][INFO] - Training Epoch: 1/2, step 1857/7134 completed (loss: 4.178381443023682, acc: 0.27941176295280457)
[2024-12-17 01:46:27,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:27,228][root][INFO] - Training Epoch: 1/2, step 1858/7134 completed (loss: 3.6207797527313232, acc: 0.3265306055545807)
[2024-12-17 01:46:27,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:27,530][root][INFO] - Training Epoch: 1/2, step 1859/7134 completed (loss: 3.6657047271728516, acc: 0.330143541097641)
[2024-12-17 01:46:27,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:27,803][root][INFO] - Training Epoch: 1/2, step 1860/7134 completed (loss: 3.681786298751831, acc: 0.284153014421463)
[2024-12-17 01:46:27,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:28,073][root][INFO] - Training Epoch: 1/2, step 1861/7134 completed (loss: 3.5952072143554688, acc: 0.3141361176967621)
[2024-12-17 01:46:28,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:28,365][root][INFO] - Training Epoch: 1/2, step 1862/7134 completed (loss: 3.796806573867798, acc: 0.29100528359413147)
[2024-12-17 01:46:28,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:28,662][root][INFO] - Training Epoch: 1/2, step 1863/7134 completed (loss: 3.2399168014526367, acc: 0.3645320236682892)
[2024-12-17 01:46:28,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:28,964][root][INFO] - Training Epoch: 1/2, step 1864/7134 completed (loss: 3.8395261764526367, acc: 0.2791878283023834)
[2024-12-17 01:46:29,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:29,231][root][INFO] - Training Epoch: 1/2, step 1865/7134 completed (loss: 4.034560680389404, acc: 0.30201342701911926)
[2024-12-17 01:46:29,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:29,498][root][INFO] - Training Epoch: 1/2, step 1866/7134 completed (loss: 3.442530393600464, acc: 0.30588236451148987)
[2024-12-17 01:46:29,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:29,781][root][INFO] - Training Epoch: 1/2, step 1867/7134 completed (loss: 3.6776673793792725, acc: 0.34090909361839294)
[2024-12-17 01:46:29,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:30,099][root][INFO] - Training Epoch: 1/2, step 1868/7134 completed (loss: 3.9697470664978027, acc: 0.2638036906719208)
[2024-12-17 01:46:30,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:30,370][root][INFO] - Training Epoch: 1/2, step 1869/7134 completed (loss: 3.391777992248535, acc: 0.3767123222351074)
[2024-12-17 01:46:30,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:30,634][root][INFO] - Training Epoch: 1/2, step 1870/7134 completed (loss: 3.5378897190093994, acc: 0.36216217279434204)
[2024-12-17 01:46:30,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:30,916][root][INFO] - Training Epoch: 1/2, step 1871/7134 completed (loss: 3.8724443912506104, acc: 0.28387096524238586)
[2024-12-17 01:46:31,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:31,187][root][INFO] - Training Epoch: 1/2, step 1872/7134 completed (loss: 6.027386665344238, acc: 0.15942029654979706)
[2024-12-17 01:46:31,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:31,477][root][INFO] - Training Epoch: 1/2, step 1873/7134 completed (loss: 4.988914489746094, acc: 0.20661157369613647)
[2024-12-17 01:46:31,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:31,752][root][INFO] - Training Epoch: 1/2, step 1874/7134 completed (loss: 4.196418762207031, acc: 0.25287356972694397)
[2024-12-17 01:46:31,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:32,023][root][INFO] - Training Epoch: 1/2, step 1875/7134 completed (loss: 3.6805760860443115, acc: 0.2946428656578064)
[2024-12-17 01:46:32,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:32,316][root][INFO] - Training Epoch: 1/2, step 1876/7134 completed (loss: 4.158530235290527, acc: 0.2628571391105652)
[2024-12-17 01:46:32,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:32,597][root][INFO] - Training Epoch: 1/2, step 1877/7134 completed (loss: 3.827444553375244, acc: 0.33898305892944336)
[2024-12-17 01:46:32,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:32,864][root][INFO] - Training Epoch: 1/2, step 1878/7134 completed (loss: 3.7935280799865723, acc: 0.37254902720451355)
[2024-12-17 01:46:32,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:33,138][root][INFO] - Training Epoch: 1/2, step 1879/7134 completed (loss: 4.077786922454834, acc: 0.32098764181137085)
[2024-12-17 01:46:33,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:33,418][root][INFO] - Training Epoch: 1/2, step 1880/7134 completed (loss: 4.631308555603027, acc: 0.30894309282302856)
[2024-12-17 01:46:33,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:33,697][root][INFO] - Training Epoch: 1/2, step 1881/7134 completed (loss: 4.342746257781982, acc: 0.26056337356567383)
[2024-12-17 01:46:33,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:33,952][root][INFO] - Training Epoch: 1/2, step 1882/7134 completed (loss: 4.755528926849365, acc: 0.260869562625885)
[2024-12-17 01:46:34,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:34,277][root][INFO] - Training Epoch: 1/2, step 1883/7134 completed (loss: 4.198113441467285, acc: 0.302325576543808)
[2024-12-17 01:46:34,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:34,558][root][INFO] - Training Epoch: 1/2, step 1884/7134 completed (loss: 4.563503265380859, acc: 0.2702702581882477)
[2024-12-17 01:46:34,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:34,838][root][INFO] - Training Epoch: 1/2, step 1885/7134 completed (loss: 4.538589954376221, acc: 0.26056337356567383)
[2024-12-17 01:46:34,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:35,119][root][INFO] - Training Epoch: 1/2, step 1886/7134 completed (loss: 4.416756629943848, acc: 0.30158731341362)
[2024-12-17 01:46:35,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:35,401][root][INFO] - Training Epoch: 1/2, step 1887/7134 completed (loss: 4.175085544586182, acc: 0.3112582862377167)
[2024-12-17 01:46:35,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:35,695][root][INFO] - Training Epoch: 1/2, step 1888/7134 completed (loss: 4.680384159088135, acc: 0.29914531111717224)
[2024-12-17 01:46:35,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:35,983][root][INFO] - Training Epoch: 1/2, step 1889/7134 completed (loss: 3.932262420654297, acc: 0.3274853825569153)
[2024-12-17 01:46:36,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:36,269][root][INFO] - Training Epoch: 1/2, step 1890/7134 completed (loss: 3.4271647930145264, acc: 0.3112582862377167)
[2024-12-17 01:46:36,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:36,547][root][INFO] - Training Epoch: 1/2, step 1891/7134 completed (loss: 4.222714424133301, acc: 0.31976744532585144)
[2024-12-17 01:46:36,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:36,831][root][INFO] - Training Epoch: 1/2, step 1892/7134 completed (loss: 4.787250518798828, acc: 0.299401193857193)
[2024-12-17 01:46:36,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:37,094][root][INFO] - Training Epoch: 1/2, step 1893/7134 completed (loss: 4.048858165740967, acc: 0.34567901492118835)
[2024-12-17 01:46:37,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:37,387][root][INFO] - Training Epoch: 1/2, step 1894/7134 completed (loss: 4.741074562072754, acc: 0.25)
[2024-12-17 01:46:37,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:37,673][root][INFO] - Training Epoch: 1/2, step 1895/7134 completed (loss: 4.843046188354492, acc: 0.2584269642829895)
[2024-12-17 01:46:37,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:37,957][root][INFO] - Training Epoch: 1/2, step 1896/7134 completed (loss: 4.605984687805176, acc: 0.2181818187236786)
[2024-12-17 01:46:38,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:38,238][root][INFO] - Training Epoch: 1/2, step 1897/7134 completed (loss: 4.30117130279541, acc: 0.2887323796749115)
[2024-12-17 01:46:38,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:38,508][root][INFO] - Training Epoch: 1/2, step 1898/7134 completed (loss: 4.090969085693359, acc: 0.30344828963279724)
[2024-12-17 01:46:38,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:38,803][root][INFO] - Training Epoch: 1/2, step 1899/7134 completed (loss: 4.699179172515869, acc: 0.25757575035095215)
[2024-12-17 01:46:38,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:39,076][root][INFO] - Training Epoch: 1/2, step 1900/7134 completed (loss: 4.284509658813477, acc: 0.3014705777168274)
[2024-12-17 01:46:39,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:39,358][root][INFO] - Training Epoch: 1/2, step 1901/7134 completed (loss: 4.436779022216797, acc: 0.316546767950058)
[2024-12-17 01:46:39,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:39,617][root][INFO] - Training Epoch: 1/2, step 1902/7134 completed (loss: 4.057361602783203, acc: 0.30215826630592346)
[2024-12-17 01:46:39,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:39,898][root][INFO] - Training Epoch: 1/2, step 1903/7134 completed (loss: 4.275774955749512, acc: 0.24836601316928864)
[2024-12-17 01:46:39,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:40,154][root][INFO] - Training Epoch: 1/2, step 1904/7134 completed (loss: 4.345409870147705, acc: 0.29523810744285583)
[2024-12-17 01:46:40,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:40,414][root][INFO] - Training Epoch: 1/2, step 1905/7134 completed (loss: 4.255992889404297, acc: 0.283687949180603)
[2024-12-17 01:46:40,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:40,697][root][INFO] - Training Epoch: 1/2, step 1906/7134 completed (loss: 3.649541139602661, acc: 0.35036495327949524)
[2024-12-17 01:46:40,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:40,955][root][INFO] - Training Epoch: 1/2, step 1907/7134 completed (loss: 4.084155559539795, acc: 0.2925170063972473)
[2024-12-17 01:46:41,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:41,219][root][INFO] - Training Epoch: 1/2, step 1908/7134 completed (loss: 3.734157085418701, acc: 0.3177570104598999)
[2024-12-17 01:46:41,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:41,515][root][INFO] - Training Epoch: 1/2, step 1909/7134 completed (loss: 4.112252235412598, acc: 0.22448979318141937)
[2024-12-17 01:46:41,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:41,805][root][INFO] - Training Epoch: 1/2, step 1910/7134 completed (loss: 3.9124715328216553, acc: 0.26511627435684204)
[2024-12-17 01:46:41,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:42,076][root][INFO] - Training Epoch: 1/2, step 1911/7134 completed (loss: 3.5285191535949707, acc: 0.31979694962501526)
[2024-12-17 01:46:42,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:42,349][root][INFO] - Training Epoch: 1/2, step 1912/7134 completed (loss: 3.639066219329834, acc: 0.30909091234207153)
[2024-12-17 01:46:42,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:42,600][root][INFO] - Training Epoch: 1/2, step 1913/7134 completed (loss: 3.9738519191741943, acc: 0.29133859276771545)
[2024-12-17 01:46:42,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:42,897][root][INFO] - Training Epoch: 1/2, step 1914/7134 completed (loss: 3.6971495151519775, acc: 0.36612021923065186)
[2024-12-17 01:46:43,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:43,160][root][INFO] - Training Epoch: 1/2, step 1915/7134 completed (loss: 3.589681625366211, acc: 0.28671327233314514)
[2024-12-17 01:46:43,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:43,429][root][INFO] - Training Epoch: 1/2, step 1916/7134 completed (loss: 4.156951427459717, acc: 0.24725274741649628)
[2024-12-17 01:46:43,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:43,707][root][INFO] - Training Epoch: 1/2, step 1917/7134 completed (loss: 3.841554641723633, acc: 0.24242424964904785)
[2024-12-17 01:46:43,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:43,955][root][INFO] - Training Epoch: 1/2, step 1918/7134 completed (loss: 3.97025203704834, acc: 0.251655638217926)
[2024-12-17 01:46:44,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:44,248][root][INFO] - Training Epoch: 1/2, step 1919/7134 completed (loss: 3.6810874938964844, acc: 0.31707316637039185)
[2024-12-17 01:46:44,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:44,511][root][INFO] - Training Epoch: 1/2, step 1920/7134 completed (loss: 4.097414493560791, acc: 0.26530611515045166)
[2024-12-17 01:46:44,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:44,767][root][INFO] - Training Epoch: 1/2, step 1921/7134 completed (loss: 4.134155750274658, acc: 0.28070175647735596)
[2024-12-17 01:46:44,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:45,049][root][INFO] - Training Epoch: 1/2, step 1922/7134 completed (loss: 3.215961456298828, acc: 0.3647541105747223)
[2024-12-17 01:46:45,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:45,316][root][INFO] - Training Epoch: 1/2, step 1923/7134 completed (loss: 3.5149943828582764, acc: 0.3216783106327057)
[2024-12-17 01:46:45,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:45,586][root][INFO] - Training Epoch: 1/2, step 1924/7134 completed (loss: 3.342320442199707, acc: 0.390625)
[2024-12-17 01:46:45,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:45,875][root][INFO] - Training Epoch: 1/2, step 1925/7134 completed (loss: 3.4653267860412598, acc: 0.34309622645378113)
[2024-12-17 01:46:45,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:46,153][root][INFO] - Training Epoch: 1/2, step 1926/7134 completed (loss: 3.6181657314300537, acc: 0.2946428656578064)
[2024-12-17 01:46:46,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:46,433][root][INFO] - Training Epoch: 1/2, step 1927/7134 completed (loss: 3.7526535987854004, acc: 0.25471699237823486)
[2024-12-17 01:46:46,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:46,720][root][INFO] - Training Epoch: 1/2, step 1928/7134 completed (loss: 4.0290350914001465, acc: 0.3035714328289032)
[2024-12-17 01:46:46,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:47,038][root][INFO] - Training Epoch: 1/2, step 1929/7134 completed (loss: 3.93495774269104, acc: 0.24581006169319153)
[2024-12-17 01:46:47,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:47,319][root][INFO] - Training Epoch: 1/2, step 1930/7134 completed (loss: 4.070184230804443, acc: 0.30434781312942505)
[2024-12-17 01:46:47,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:47,596][root][INFO] - Training Epoch: 1/2, step 1931/7134 completed (loss: 3.8537755012512207, acc: 0.31018519401550293)
[2024-12-17 01:46:47,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:47,860][root][INFO] - Training Epoch: 1/2, step 1932/7134 completed (loss: 4.114223480224609, acc: 0.25139665603637695)
[2024-12-17 01:46:47,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:48,137][root][INFO] - Training Epoch: 1/2, step 1933/7134 completed (loss: 4.17601203918457, acc: 0.2964824140071869)
[2024-12-17 01:46:48,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:48,423][root][INFO] - Training Epoch: 1/2, step 1934/7134 completed (loss: 4.200804710388184, acc: 0.2857142984867096)
[2024-12-17 01:46:48,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:48,712][root][INFO] - Training Epoch: 1/2, step 1935/7134 completed (loss: 4.336625099182129, acc: 0.18902438879013062)
[2024-12-17 01:46:48,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:48,992][root][INFO] - Training Epoch: 1/2, step 1936/7134 completed (loss: 4.245936870574951, acc: 0.24836601316928864)
[2024-12-17 01:46:49,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:49,253][root][INFO] - Training Epoch: 1/2, step 1937/7134 completed (loss: 3.972682237625122, acc: 0.28658536076545715)
[2024-12-17 01:46:49,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:49,531][root][INFO] - Training Epoch: 1/2, step 1938/7134 completed (loss: 4.365235328674316, acc: 0.25)
[2024-12-17 01:46:49,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:49,799][root][INFO] - Training Epoch: 1/2, step 1939/7134 completed (loss: 4.011810779571533, acc: 0.27586206793785095)
[2024-12-17 01:46:49,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:50,068][root][INFO] - Training Epoch: 1/2, step 1940/7134 completed (loss: 3.8377630710601807, acc: 0.341317355632782)
[2024-12-17 01:46:50,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:50,345][root][INFO] - Training Epoch: 1/2, step 1941/7134 completed (loss: 3.8634068965911865, acc: 0.3136094808578491)
[2024-12-17 01:46:50,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:50,635][root][INFO] - Training Epoch: 1/2, step 1942/7134 completed (loss: 4.222127914428711, acc: 0.29629629850387573)
[2024-12-17 01:46:50,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:50,915][root][INFO] - Training Epoch: 1/2, step 1943/7134 completed (loss: 3.9390711784362793, acc: 0.28421053290367126)
[2024-12-17 01:46:51,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:51,186][root][INFO] - Training Epoch: 1/2, step 1944/7134 completed (loss: 3.9445841312408447, acc: 0.26229506731033325)
[2024-12-17 01:46:51,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:51,449][root][INFO] - Training Epoch: 1/2, step 1945/7134 completed (loss: 4.16470193862915, acc: 0.2983871102333069)
[2024-12-17 01:46:51,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:51,729][root][INFO] - Training Epoch: 1/2, step 1946/7134 completed (loss: 4.01416540145874, acc: 0.3142857253551483)
[2024-12-17 01:46:51,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:52,003][root][INFO] - Training Epoch: 1/2, step 1947/7134 completed (loss: 3.9858176708221436, acc: 0.30635836720466614)
[2024-12-17 01:46:52,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:52,283][root][INFO] - Training Epoch: 1/2, step 1948/7134 completed (loss: 3.448530912399292, acc: 0.4000000059604645)
[2024-12-17 01:46:52,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:52,559][root][INFO] - Training Epoch: 1/2, step 1949/7134 completed (loss: 3.921975612640381, acc: 0.29870128631591797)
[2024-12-17 01:46:52,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:52,839][root][INFO] - Training Epoch: 1/2, step 1950/7134 completed (loss: 3.7555103302001953, acc: 0.30434781312942505)
[2024-12-17 01:46:52,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:53,169][root][INFO] - Training Epoch: 1/2, step 1951/7134 completed (loss: 4.171921730041504, acc: 0.2631579041481018)
[2024-12-17 01:46:53,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:53,448][root][INFO] - Training Epoch: 1/2, step 1952/7134 completed (loss: 4.030910968780518, acc: 0.3192771077156067)
[2024-12-17 01:46:53,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:53,726][root][INFO] - Training Epoch: 1/2, step 1953/7134 completed (loss: 4.100485801696777, acc: 0.29113924503326416)
[2024-12-17 01:46:53,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:53,984][root][INFO] - Training Epoch: 1/2, step 1954/7134 completed (loss: 3.7726309299468994, acc: 0.3235294222831726)
[2024-12-17 01:46:54,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:54,250][root][INFO] - Training Epoch: 1/2, step 1955/7134 completed (loss: 4.164385795593262, acc: 0.3208955228328705)
[2024-12-17 01:46:54,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:54,482][root][INFO] - Training Epoch: 1/2, step 1956/7134 completed (loss: 4.079460144042969, acc: 0.25)
[2024-12-17 01:46:54,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:54,744][root][INFO] - Training Epoch: 1/2, step 1957/7134 completed (loss: 4.152345180511475, acc: 0.19548872113227844)
[2024-12-17 01:46:54,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:54,943][root][INFO] - Training Epoch: 1/2, step 1958/7134 completed (loss: 4.225664138793945, acc: 0.25555557012557983)
[2024-12-17 01:46:55,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:55,216][root][INFO] - Training Epoch: 1/2, step 1959/7134 completed (loss: 4.1957926750183105, acc: 0.2232142835855484)
[2024-12-17 01:46:55,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:55,480][root][INFO] - Training Epoch: 1/2, step 1960/7134 completed (loss: 3.9109699726104736, acc: 0.3499999940395355)
[2024-12-17 01:46:55,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:55,740][root][INFO] - Training Epoch: 1/2, step 1961/7134 completed (loss: 4.272621154785156, acc: 0.3164556920528412)
[2024-12-17 01:46:55,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:56,018][root][INFO] - Training Epoch: 1/2, step 1962/7134 completed (loss: 4.121077060699463, acc: 0.25287356972694397)
[2024-12-17 01:46:56,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:56,299][root][INFO] - Training Epoch: 1/2, step 1963/7134 completed (loss: 4.1072869300842285, acc: 0.3112582862377167)
[2024-12-17 01:46:56,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:56,583][root][INFO] - Training Epoch: 1/2, step 1964/7134 completed (loss: 3.7828383445739746, acc: 0.3181818127632141)
[2024-12-17 01:46:56,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:56,901][root][INFO] - Training Epoch: 1/2, step 1965/7134 completed (loss: 3.902082920074463, acc: 0.3595505654811859)
[2024-12-17 01:46:57,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:57,186][root][INFO] - Training Epoch: 1/2, step 1966/7134 completed (loss: 4.1079254150390625, acc: 0.36942675709724426)
[2024-12-17 01:46:57,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:57,471][root][INFO] - Training Epoch: 1/2, step 1967/7134 completed (loss: 3.9132893085479736, acc: 0.33157894015312195)
[2024-12-17 01:46:57,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:57,750][root][INFO] - Training Epoch: 1/2, step 1968/7134 completed (loss: 3.865523338317871, acc: 0.30319148302078247)
[2024-12-17 01:46:57,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:58,019][root][INFO] - Training Epoch: 1/2, step 1969/7134 completed (loss: 3.7355384826660156, acc: 0.37288135290145874)
[2024-12-17 01:46:58,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:58,302][root][INFO] - Training Epoch: 1/2, step 1970/7134 completed (loss: 3.507561206817627, acc: 0.3668639063835144)
[2024-12-17 01:46:58,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:58,586][root][INFO] - Training Epoch: 1/2, step 1971/7134 completed (loss: 3.7990095615386963, acc: 0.3036649227142334)
[2024-12-17 01:46:58,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:58,860][root][INFO] - Training Epoch: 1/2, step 1972/7134 completed (loss: 4.5460524559021, acc: 0.25438597798347473)
[2024-12-17 01:46:58,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:59,126][root][INFO] - Training Epoch: 1/2, step 1973/7134 completed (loss: 4.704471111297607, acc: 0.2083333283662796)
[2024-12-17 01:46:59,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:59,411][root][INFO] - Training Epoch: 1/2, step 1974/7134 completed (loss: 3.5723226070404053, acc: 0.36082473397254944)
[2024-12-17 01:46:59,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:59,680][root][INFO] - Training Epoch: 1/2, step 1975/7134 completed (loss: 3.806117296218872, acc: 0.3062500059604645)
[2024-12-17 01:46:59,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:59,963][root][INFO] - Training Epoch: 1/2, step 1976/7134 completed (loss: 4.141009330749512, acc: 0.2788461446762085)
[2024-12-17 01:47:00,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:00,243][root][INFO] - Training Epoch: 1/2, step 1977/7134 completed (loss: 4.281521797180176, acc: 0.28742516040802)
[2024-12-17 01:47:00,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:00,514][root][INFO] - Training Epoch: 1/2, step 1978/7134 completed (loss: 3.2557780742645264, acc: 0.3372093141078949)
[2024-12-17 01:47:00,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:00,801][root][INFO] - Training Epoch: 1/2, step 1979/7134 completed (loss: 3.7563979625701904, acc: 0.30219781398773193)
[2024-12-17 01:47:00,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:01,092][root][INFO] - Training Epoch: 1/2, step 1980/7134 completed (loss: 3.456209897994995, acc: 0.3036649227142334)
[2024-12-17 01:47:01,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:01,378][root][INFO] - Training Epoch: 1/2, step 1981/7134 completed (loss: 3.7206900119781494, acc: 0.30219781398773193)
[2024-12-17 01:47:01,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:01,663][root][INFO] - Training Epoch: 1/2, step 1982/7134 completed (loss: 3.5941054821014404, acc: 0.28717949986457825)
[2024-12-17 01:47:01,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:01,943][root][INFO] - Training Epoch: 1/2, step 1983/7134 completed (loss: 3.5653367042541504, acc: 0.2956989109516144)
[2024-12-17 01:47:02,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:02,219][root][INFO] - Training Epoch: 1/2, step 1984/7134 completed (loss: 3.6957457065582275, acc: 0.2732558250427246)
[2024-12-17 01:47:02,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:02,485][root][INFO] - Training Epoch: 1/2, step 1985/7134 completed (loss: 3.6298389434814453, acc: 0.35403725504875183)
[2024-12-17 01:47:02,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:02,757][root][INFO] - Training Epoch: 1/2, step 1986/7134 completed (loss: 3.5484395027160645, acc: 0.31843575835227966)
[2024-12-17 01:47:02,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:03,035][root][INFO] - Training Epoch: 1/2, step 1987/7134 completed (loss: 3.911458969116211, acc: 0.2977527976036072)
[2024-12-17 01:47:03,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:03,304][root][INFO] - Training Epoch: 1/2, step 1988/7134 completed (loss: 3.683746576309204, acc: 0.3393939435482025)
[2024-12-17 01:47:03,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:03,561][root][INFO] - Training Epoch: 1/2, step 1989/7134 completed (loss: 3.880995273590088, acc: 0.3219178020954132)
[2024-12-17 01:47:03,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:03,849][root][INFO] - Training Epoch: 1/2, step 1990/7134 completed (loss: 3.6416473388671875, acc: 0.3038673996925354)
[2024-12-17 01:47:03,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:04,145][root][INFO] - Training Epoch: 1/2, step 1991/7134 completed (loss: 4.177973747253418, acc: 0.2661290466785431)
[2024-12-17 01:47:04,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:04,432][root][INFO] - Training Epoch: 1/2, step 1992/7134 completed (loss: 4.680067539215088, acc: 0.24637681245803833)
[2024-12-17 01:47:04,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:04,707][root][INFO] - Training Epoch: 1/2, step 1993/7134 completed (loss: 4.933934688568115, acc: 0.208695650100708)
[2024-12-17 01:47:04,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:04,984][root][INFO] - Training Epoch: 1/2, step 1994/7134 completed (loss: 4.173713684082031, acc: 0.26356589794158936)
[2024-12-17 01:47:05,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:05,262][root][INFO] - Training Epoch: 1/2, step 1995/7134 completed (loss: 3.7076497077941895, acc: 0.29655173420906067)
[2024-12-17 01:47:05,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:05,537][root][INFO] - Training Epoch: 1/2, step 1996/7134 completed (loss: 4.477967262268066, acc: 0.29197078943252563)
[2024-12-17 01:47:05,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:05,808][root][INFO] - Training Epoch: 1/2, step 1997/7134 completed (loss: 4.043295860290527, acc: 0.30000001192092896)
[2024-12-17 01:47:05,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:06,079][root][INFO] - Training Epoch: 1/2, step 1998/7134 completed (loss: 3.9303481578826904, acc: 0.30281689763069153)
[2024-12-17 01:47:06,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:06,355][root][INFO] - Training Epoch: 1/2, step 1999/7134 completed (loss: 4.262938499450684, acc: 0.279720276594162)
[2024-12-17 01:47:06,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:06,630][root][INFO] - Training Epoch: 1/2, step 2000/7134 completed (loss: 4.211262226104736, acc: 0.2916666567325592)
[2024-12-17 01:47:06,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:06,885][root][INFO] - Training Epoch: 1/2, step 2001/7134 completed (loss: 3.966846227645874, acc: 0.2620689570903778)
[2024-12-17 01:47:06,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:07,155][root][INFO] - Training Epoch: 1/2, step 2002/7134 completed (loss: 4.67734956741333, acc: 0.23308271169662476)
[2024-12-17 01:47:07,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:07,425][root][INFO] - Training Epoch: 1/2, step 2003/7134 completed (loss: 3.8196308612823486, acc: 0.3684210479259491)
[2024-12-17 01:47:07,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:07,706][root][INFO] - Training Epoch: 1/2, step 2004/7134 completed (loss: 4.708284854888916, acc: 0.2704918086528778)
[2024-12-17 01:47:07,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:08,047][root][INFO] - Training Epoch: 1/2, step 2005/7134 completed (loss: 4.121302127838135, acc: 0.2448979616165161)
[2024-12-17 01:47:08,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:08,324][root][INFO] - Training Epoch: 1/2, step 2006/7134 completed (loss: 4.460517406463623, acc: 0.3488371968269348)
[2024-12-17 01:47:08,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:08,611][root][INFO] - Training Epoch: 1/2, step 2007/7134 completed (loss: 3.8512260913848877, acc: 0.3193277418613434)
[2024-12-17 01:47:08,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:08,893][root][INFO] - Training Epoch: 1/2, step 2008/7134 completed (loss: 4.761967658996582, acc: 0.22602739930152893)
[2024-12-17 01:47:08,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:09,175][root][INFO] - Training Epoch: 1/2, step 2009/7134 completed (loss: 4.292757511138916, acc: 0.28148147463798523)
[2024-12-17 01:47:09,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:09,461][root][INFO] - Training Epoch: 1/2, step 2010/7134 completed (loss: 4.38936185836792, acc: 0.23357664048671722)
[2024-12-17 01:47:09,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:09,763][root][INFO] - Training Epoch: 1/2, step 2011/7134 completed (loss: 4.471689701080322, acc: 0.230158731341362)
[2024-12-17 01:47:09,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:10,032][root][INFO] - Training Epoch: 1/2, step 2012/7134 completed (loss: 4.6684064865112305, acc: 0.24576270580291748)
[2024-12-17 01:47:10,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:10,315][root][INFO] - Training Epoch: 1/2, step 2013/7134 completed (loss: 4.50307559967041, acc: 0.23770491778850555)
[2024-12-17 01:47:10,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:10,597][root][INFO] - Training Epoch: 1/2, step 2014/7134 completed (loss: 4.087873458862305, acc: 0.2839506268501282)
[2024-12-17 01:47:10,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:10,874][root][INFO] - Training Epoch: 1/2, step 2015/7134 completed (loss: 4.214159965515137, acc: 0.28125)
[2024-12-17 01:47:10,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:11,153][root][INFO] - Training Epoch: 1/2, step 2016/7134 completed (loss: 3.640019655227661, acc: 0.35374149680137634)
[2024-12-17 01:47:11,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:11,427][root][INFO] - Training Epoch: 1/2, step 2017/7134 completed (loss: 4.142597675323486, acc: 0.3112582862377167)
[2024-12-17 01:47:11,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:11,697][root][INFO] - Training Epoch: 1/2, step 2018/7134 completed (loss: 3.956296682357788, acc: 0.3287671208381653)
[2024-12-17 01:47:11,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:11,962][root][INFO] - Training Epoch: 1/2, step 2019/7134 completed (loss: 3.922168493270874, acc: 0.37748345732688904)
[2024-12-17 01:47:12,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:12,239][root][INFO] - Training Epoch: 1/2, step 2020/7134 completed (loss: 4.215550422668457, acc: 0.3305785059928894)
[2024-12-17 01:47:12,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:12,524][root][INFO] - Training Epoch: 1/2, step 2021/7134 completed (loss: 3.982194185256958, acc: 0.318918913602829)
[2024-12-17 01:47:12,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:12,780][root][INFO] - Training Epoch: 1/2, step 2022/7134 completed (loss: 4.154355049133301, acc: 0.3208955228328705)
[2024-12-17 01:47:12,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:13,056][root][INFO] - Training Epoch: 1/2, step 2023/7134 completed (loss: 3.6763076782226562, acc: 0.3128834366798401)
[2024-12-17 01:47:13,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:13,343][root][INFO] - Training Epoch: 1/2, step 2024/7134 completed (loss: 4.063292026519775, acc: 0.2616279125213623)
[2024-12-17 01:47:13,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:13,638][root][INFO] - Training Epoch: 1/2, step 2025/7134 completed (loss: 3.9384257793426514, acc: 0.23976607620716095)
[2024-12-17 01:47:13,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:13,923][root][INFO] - Training Epoch: 1/2, step 2026/7134 completed (loss: 3.9902665615081787, acc: 0.3040935695171356)
[2024-12-17 01:47:14,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:14,191][root][INFO] - Training Epoch: 1/2, step 2027/7134 completed (loss: 4.76569128036499, acc: 0.2255639135837555)
[2024-12-17 01:47:14,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:14,466][root][INFO] - Training Epoch: 1/2, step 2028/7134 completed (loss: 3.989743947982788, acc: 0.30061349272727966)
[2024-12-17 01:47:14,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:14,741][root][INFO] - Training Epoch: 1/2, step 2029/7134 completed (loss: 3.9583370685577393, acc: 0.2764706015586853)
[2024-12-17 01:47:14,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:15,009][root][INFO] - Training Epoch: 1/2, step 2030/7134 completed (loss: 3.902195692062378, acc: 0.3072289228439331)
[2024-12-17 01:47:15,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:15,289][root][INFO] - Training Epoch: 1/2, step 2031/7134 completed (loss: 3.681062698364258, acc: 0.31491711735725403)
[2024-12-17 01:47:15,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:15,562][root][INFO] - Training Epoch: 1/2, step 2032/7134 completed (loss: 4.150571823120117, acc: 0.28070175647735596)
[2024-12-17 01:47:15,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:15,858][root][INFO] - Training Epoch: 1/2, step 2033/7134 completed (loss: 3.9406533241271973, acc: 0.3129771053791046)
[2024-12-17 01:47:15,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:16,127][root][INFO] - Training Epoch: 1/2, step 2034/7134 completed (loss: 4.094481945037842, acc: 0.268456369638443)
[2024-12-17 01:47:16,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:16,411][root][INFO] - Training Epoch: 1/2, step 2035/7134 completed (loss: 3.9346539974212646, acc: 0.3333333432674408)
[2024-12-17 01:47:16,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:16,668][root][INFO] - Training Epoch: 1/2, step 2036/7134 completed (loss: 4.234402656555176, acc: 0.2748091518878937)
[2024-12-17 01:47:16,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:16,945][root][INFO] - Training Epoch: 1/2, step 2037/7134 completed (loss: 3.8163647651672363, acc: 0.29447853565216064)
[2024-12-17 01:47:17,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:17,221][root][INFO] - Training Epoch: 1/2, step 2038/7134 completed (loss: 4.1488189697265625, acc: 0.2857142984867096)
[2024-12-17 01:47:17,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:17,496][root][INFO] - Training Epoch: 1/2, step 2039/7134 completed (loss: 4.305628299713135, acc: 0.18978102505207062)
[2024-12-17 01:47:17,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:17,749][root][INFO] - Training Epoch: 1/2, step 2040/7134 completed (loss: 3.972376585006714, acc: 0.26724138855934143)
[2024-12-17 01:47:17,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:18,016][root][INFO] - Training Epoch: 1/2, step 2041/7134 completed (loss: 4.688056945800781, acc: 0.2181818187236786)
[2024-12-17 01:47:18,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:18,317][root][INFO] - Training Epoch: 1/2, step 2042/7134 completed (loss: 4.073369026184082, acc: 0.2542372941970825)
[2024-12-17 01:47:18,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:18,578][root][INFO] - Training Epoch: 1/2, step 2043/7134 completed (loss: 3.9618189334869385, acc: 0.2751677930355072)
[2024-12-17 01:47:18,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:18,870][root][INFO] - Training Epoch: 1/2, step 2044/7134 completed (loss: 4.120544910430908, acc: 0.2160000056028366)
[2024-12-17 01:47:18,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:19,135][root][INFO] - Training Epoch: 1/2, step 2045/7134 completed (loss: 4.164523124694824, acc: 0.3083333373069763)
[2024-12-17 01:47:19,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:19,398][root][INFO] - Training Epoch: 1/2, step 2046/7134 completed (loss: 4.194360256195068, acc: 0.2857142984867096)
[2024-12-17 01:47:19,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:19,692][root][INFO] - Training Epoch: 1/2, step 2047/7134 completed (loss: 4.178479194641113, acc: 0.2689655125141144)
[2024-12-17 01:47:19,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:19,976][root][INFO] - Training Epoch: 1/2, step 2048/7134 completed (loss: 4.085875511169434, acc: 0.3392857015132904)
[2024-12-17 01:47:20,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:20,253][root][INFO] - Training Epoch: 1/2, step 2049/7134 completed (loss: 3.8777894973754883, acc: 0.26363635063171387)
[2024-12-17 01:47:20,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:20,505][root][INFO] - Training Epoch: 1/2, step 2050/7134 completed (loss: 3.793769359588623, acc: 0.33561643958091736)
[2024-12-17 01:47:20,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:20,796][root][INFO] - Training Epoch: 1/2, step 2051/7134 completed (loss: 4.316960334777832, acc: 0.3008849620819092)
[2024-12-17 01:47:20,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:21,086][root][INFO] - Training Epoch: 1/2, step 2052/7134 completed (loss: 4.076766014099121, acc: 0.3333333432674408)
[2024-12-17 01:47:21,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:21,387][root][INFO] - Training Epoch: 1/2, step 2053/7134 completed (loss: 4.403367519378662, acc: 0.221374049782753)
[2024-12-17 01:47:21,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:21,670][root][INFO] - Training Epoch: 1/2, step 2054/7134 completed (loss: 4.305238246917725, acc: 0.2756410241127014)
[2024-12-17 01:47:21,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:21,954][root][INFO] - Training Epoch: 1/2, step 2055/7134 completed (loss: 4.456341743469238, acc: 0.2945205569267273)
[2024-12-17 01:47:22,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:22,294][root][INFO] - Training Epoch: 1/2, step 2056/7134 completed (loss: 4.689189434051514, acc: 0.28248587250709534)
[2024-12-17 01:47:22,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:22,572][root][INFO] - Training Epoch: 1/2, step 2057/7134 completed (loss: 4.2954277992248535, acc: 0.32022473216056824)
[2024-12-17 01:47:22,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:22,864][root][INFO] - Training Epoch: 1/2, step 2058/7134 completed (loss: 4.540084362030029, acc: 0.2543352544307709)
[2024-12-17 01:47:23,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:23,152][root][INFO] - Training Epoch: 1/2, step 2059/7134 completed (loss: 4.402268409729004, acc: 0.27659574151039124)
[2024-12-17 01:47:23,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:23,441][root][INFO] - Training Epoch: 1/2, step 2060/7134 completed (loss: 4.364473342895508, acc: 0.2675159275531769)
[2024-12-17 01:47:23,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:23,730][root][INFO] - Training Epoch: 1/2, step 2061/7134 completed (loss: 4.652754306793213, acc: 0.2738095223903656)
[2024-12-17 01:47:23,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:24,018][root][INFO] - Training Epoch: 1/2, step 2062/7134 completed (loss: 4.582237720489502, acc: 0.3203125)
[2024-12-17 01:47:24,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:24,281][root][INFO] - Training Epoch: 1/2, step 2063/7134 completed (loss: 3.8671720027923584, acc: 0.2978723347187042)
[2024-12-17 01:47:24,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:24,561][root][INFO] - Training Epoch: 1/2, step 2064/7134 completed (loss: 3.6885766983032227, acc: 0.29411765933036804)
[2024-12-17 01:47:24,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:24,851][root][INFO] - Training Epoch: 1/2, step 2065/7134 completed (loss: 4.000124454498291, acc: 0.26428571343421936)
[2024-12-17 01:47:24,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:25,123][root][INFO] - Training Epoch: 1/2, step 2066/7134 completed (loss: 3.8690898418426514, acc: 0.3008130192756653)
[2024-12-17 01:47:25,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:25,398][root][INFO] - Training Epoch: 1/2, step 2067/7134 completed (loss: 4.427456378936768, acc: 0.3083333373069763)
[2024-12-17 01:47:25,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:25,664][root][INFO] - Training Epoch: 1/2, step 2068/7134 completed (loss: 3.918438196182251, acc: 0.30392158031463623)
[2024-12-17 01:47:25,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:25,971][root][INFO] - Training Epoch: 1/2, step 2069/7134 completed (loss: 4.034590721130371, acc: 0.268456369638443)
[2024-12-17 01:47:26,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:26,239][root][INFO] - Training Epoch: 1/2, step 2070/7134 completed (loss: 4.131448745727539, acc: 0.26724138855934143)
[2024-12-17 01:47:26,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:26,515][root][INFO] - Training Epoch: 1/2, step 2071/7134 completed (loss: 3.905748128890991, acc: 0.3009708821773529)
[2024-12-17 01:47:26,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:26,773][root][INFO] - Training Epoch: 1/2, step 2072/7134 completed (loss: 3.801321029663086, acc: 0.3137255012989044)
[2024-12-17 01:47:26,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:27,038][root][INFO] - Training Epoch: 1/2, step 2073/7134 completed (loss: 4.118401050567627, acc: 0.28925618529319763)
[2024-12-17 01:47:27,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:27,331][root][INFO] - Training Epoch: 1/2, step 2074/7134 completed (loss: 3.8586058616638184, acc: 0.26178011298179626)
[2024-12-17 01:47:27,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:27,616][root][INFO] - Training Epoch: 1/2, step 2075/7134 completed (loss: 3.967376232147217, acc: 0.3270440399646759)
[2024-12-17 01:47:27,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:27,893][root][INFO] - Training Epoch: 1/2, step 2076/7134 completed (loss: 3.903142213821411, acc: 0.25850340723991394)
[2024-12-17 01:47:27,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:28,166][root][INFO] - Training Epoch: 1/2, step 2077/7134 completed (loss: 4.010457992553711, acc: 0.23728813230991364)
[2024-12-17 01:47:28,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:28,459][root][INFO] - Training Epoch: 1/2, step 2078/7134 completed (loss: 3.5566632747650146, acc: 0.34517765045166016)
[2024-12-17 01:47:28,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:28,741][root][INFO] - Training Epoch: 1/2, step 2079/7134 completed (loss: 3.9293665885925293, acc: 0.27710843086242676)
[2024-12-17 01:47:28,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:29,008][root][INFO] - Training Epoch: 1/2, step 2080/7134 completed (loss: 4.189857006072998, acc: 0.22875817120075226)
[2024-12-17 01:47:29,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:29,290][root][INFO] - Training Epoch: 1/2, step 2081/7134 completed (loss: 4.0279541015625, acc: 0.23566879332065582)
[2024-12-17 01:47:29,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:29,584][root][INFO] - Training Epoch: 1/2, step 2082/7134 completed (loss: 4.017881870269775, acc: 0.2881355881690979)
[2024-12-17 01:47:29,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:29,834][root][INFO] - Training Epoch: 1/2, step 2083/7134 completed (loss: 3.673729658126831, acc: 0.24031007289886475)
[2024-12-17 01:47:29,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:30,101][root][INFO] - Training Epoch: 1/2, step 2084/7134 completed (loss: 4.192614555358887, acc: 0.2800000011920929)
[2024-12-17 01:47:30,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:30,378][root][INFO] - Training Epoch: 1/2, step 2085/7134 completed (loss: 3.758852481842041, acc: 0.3008130192756653)
[2024-12-17 01:47:30,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:30,653][root][INFO] - Training Epoch: 1/2, step 2086/7134 completed (loss: 4.364585876464844, acc: 0.3137255012989044)
[2024-12-17 01:47:30,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:30,939][root][INFO] - Training Epoch: 1/2, step 2087/7134 completed (loss: 4.085305213928223, acc: 0.2738095223903656)
[2024-12-17 01:47:31,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:31,208][root][INFO] - Training Epoch: 1/2, step 2088/7134 completed (loss: 3.8803558349609375, acc: 0.3254437744617462)
[2024-12-17 01:47:31,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:31,494][root][INFO] - Training Epoch: 1/2, step 2089/7134 completed (loss: 4.169858932495117, acc: 0.3095238208770752)
[2024-12-17 01:47:31,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:31,756][root][INFO] - Training Epoch: 1/2, step 2090/7134 completed (loss: 3.803828239440918, acc: 0.26143792271614075)
[2024-12-17 01:47:31,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:32,019][root][INFO] - Training Epoch: 1/2, step 2091/7134 completed (loss: 3.253209114074707, acc: 0.37931033968925476)
[2024-12-17 01:47:32,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:32,301][root][INFO] - Training Epoch: 1/2, step 2092/7134 completed (loss: 3.2290377616882324, acc: 0.3576158881187439)
[2024-12-17 01:47:32,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:32,608][root][INFO] - Training Epoch: 1/2, step 2093/7134 completed (loss: 3.67877459526062, acc: 0.36315789818763733)
[2024-12-17 01:47:32,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:32,871][root][INFO] - Training Epoch: 1/2, step 2094/7134 completed (loss: 3.9165499210357666, acc: 0.36567163467407227)
[2024-12-17 01:47:32,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:33,170][root][INFO] - Training Epoch: 1/2, step 2095/7134 completed (loss: 3.8320138454437256, acc: 0.3383084535598755)
[2024-12-17 01:47:33,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:33,432][root][INFO] - Training Epoch: 1/2, step 2096/7134 completed (loss: 4.052915096282959, acc: 0.27272728085517883)
[2024-12-17 01:47:33,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:33,703][root][INFO] - Training Epoch: 1/2, step 2097/7134 completed (loss: 3.410529375076294, acc: 0.35542169213294983)
[2024-12-17 01:47:33,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:33,969][root][INFO] - Training Epoch: 1/2, step 2098/7134 completed (loss: 3.6229469776153564, acc: 0.32236841320991516)
[2024-12-17 01:47:34,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:34,235][root][INFO] - Training Epoch: 1/2, step 2099/7134 completed (loss: 4.099536418914795, acc: 0.3125)
[2024-12-17 01:47:34,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:34,509][root][INFO] - Training Epoch: 1/2, step 2100/7134 completed (loss: 3.9256341457366943, acc: 0.33714285492897034)
[2024-12-17 01:47:34,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:34,786][root][INFO] - Training Epoch: 1/2, step 2101/7134 completed (loss: 4.84700870513916, acc: 0.2142857164144516)
[2024-12-17 01:47:34,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:35,075][root][INFO] - Training Epoch: 1/2, step 2102/7134 completed (loss: 3.5687787532806396, acc: 0.2756756842136383)
[2024-12-17 01:47:35,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:35,348][root][INFO] - Training Epoch: 1/2, step 2103/7134 completed (loss: 4.114069938659668, acc: 0.2750000059604645)
[2024-12-17 01:47:35,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:35,629][root][INFO] - Training Epoch: 1/2, step 2104/7134 completed (loss: 3.928619623184204, acc: 0.3085714280605316)
[2024-12-17 01:47:35,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:35,896][root][INFO] - Training Epoch: 1/2, step 2105/7134 completed (loss: 4.159494400024414, acc: 0.26241135597229004)
[2024-12-17 01:47:35,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:36,149][root][INFO] - Training Epoch: 1/2, step 2106/7134 completed (loss: 3.969649076461792, acc: 0.29605263471603394)
[2024-12-17 01:47:36,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:36,425][root][INFO] - Training Epoch: 1/2, step 2107/7134 completed (loss: 4.134739875793457, acc: 0.2209944725036621)
[2024-12-17 01:47:36,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:36,705][root][INFO] - Training Epoch: 1/2, step 2108/7134 completed (loss: 3.901524066925049, acc: 0.3354037404060364)
[2024-12-17 01:47:36,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:36,968][root][INFO] - Training Epoch: 1/2, step 2109/7134 completed (loss: 4.235480308532715, acc: 0.239130437374115)
[2024-12-17 01:47:37,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:37,260][root][INFO] - Training Epoch: 1/2, step 2110/7134 completed (loss: 4.447009563446045, acc: 0.2634730637073517)
[2024-12-17 01:47:37,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:37,534][root][INFO] - Training Epoch: 1/2, step 2111/7134 completed (loss: 4.29644250869751, acc: 0.22797927260398865)
[2024-12-17 01:47:37,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:37,784][root][INFO] - Training Epoch: 1/2, step 2112/7134 completed (loss: 3.7211573123931885, acc: 0.2800000011920929)
[2024-12-17 01:47:37,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:38,056][root][INFO] - Training Epoch: 1/2, step 2113/7134 completed (loss: 3.911033868789673, acc: 0.3199999928474426)
[2024-12-17 01:47:38,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:38,337][root][INFO] - Training Epoch: 1/2, step 2114/7134 completed (loss: 4.461900234222412, acc: 0.2781065106391907)
[2024-12-17 01:47:38,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:38,617][root][INFO] - Training Epoch: 1/2, step 2115/7134 completed (loss: 4.206768035888672, acc: 0.31609195470809937)
[2024-12-17 01:47:38,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:38,883][root][INFO] - Training Epoch: 1/2, step 2116/7134 completed (loss: 4.789205551147461, acc: 0.30612245202064514)
[2024-12-17 01:47:38,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:39,150][root][INFO] - Training Epoch: 1/2, step 2117/7134 completed (loss: 4.737818717956543, acc: 0.2711864411830902)
[2024-12-17 01:47:39,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:39,433][root][INFO] - Training Epoch: 1/2, step 2118/7134 completed (loss: 4.189566135406494, acc: 0.27218934893608093)
[2024-12-17 01:47:39,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:39,709][root][INFO] - Training Epoch: 1/2, step 2119/7134 completed (loss: 3.8698604106903076, acc: 0.3005780279636383)
[2024-12-17 01:47:39,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:39,992][root][INFO] - Training Epoch: 1/2, step 2120/7134 completed (loss: 4.3198771476745605, acc: 0.22839505970478058)
[2024-12-17 01:47:40,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:40,256][root][INFO] - Training Epoch: 1/2, step 2121/7134 completed (loss: 4.2381720542907715, acc: 0.25503355264663696)
[2024-12-17 01:47:40,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:40,536][root][INFO] - Training Epoch: 1/2, step 2122/7134 completed (loss: 4.043113708496094, acc: 0.3446327745914459)
[2024-12-17 01:47:40,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:40,801][root][INFO] - Training Epoch: 1/2, step 2123/7134 completed (loss: 4.567227840423584, acc: 0.25)
[2024-12-17 01:47:40,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:41,064][root][INFO] - Training Epoch: 1/2, step 2124/7134 completed (loss: 4.352431297302246, acc: 0.25)
[2024-12-17 01:47:41,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:41,332][root][INFO] - Training Epoch: 1/2, step 2125/7134 completed (loss: 3.836427688598633, acc: 0.31736525893211365)
[2024-12-17 01:47:41,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:41,652][root][INFO] - Training Epoch: 1/2, step 2126/7134 completed (loss: 4.146004676818848, acc: 0.24113474786281586)
[2024-12-17 01:47:41,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:41,942][root][INFO] - Training Epoch: 1/2, step 2127/7134 completed (loss: 4.195291996002197, acc: 0.2469879537820816)
[2024-12-17 01:47:42,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:42,219][root][INFO] - Training Epoch: 1/2, step 2128/7134 completed (loss: 3.92868709564209, acc: 0.2666666805744171)
[2024-12-17 01:47:42,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:42,498][root][INFO] - Training Epoch: 1/2, step 2129/7134 completed (loss: 4.262895584106445, acc: 0.23668639361858368)
[2024-12-17 01:47:42,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:42,757][root][INFO] - Training Epoch: 1/2, step 2130/7134 completed (loss: 4.122280120849609, acc: 0.29729729890823364)
[2024-12-17 01:47:42,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:43,012][root][INFO] - Training Epoch: 1/2, step 2131/7134 completed (loss: 4.147446155548096, acc: 0.23312883079051971)
[2024-12-17 01:47:43,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:43,279][root][INFO] - Training Epoch: 1/2, step 2132/7134 completed (loss: 3.67588472366333, acc: 0.2926829159259796)
[2024-12-17 01:47:43,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:43,552][root][INFO] - Training Epoch: 1/2, step 2133/7134 completed (loss: 3.7107462882995605, acc: 0.3333333432674408)
[2024-12-17 01:47:43,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:43,846][root][INFO] - Training Epoch: 1/2, step 2134/7134 completed (loss: 4.021323204040527, acc: 0.3333333432674408)
[2024-12-17 01:47:43,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:44,110][root][INFO] - Training Epoch: 1/2, step 2135/7134 completed (loss: 3.9800515174865723, acc: 0.25827813148498535)
[2024-12-17 01:47:44,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:44,389][root][INFO] - Training Epoch: 1/2, step 2136/7134 completed (loss: 3.6156461238861084, acc: 0.3076923191547394)
[2024-12-17 01:47:44,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:44,689][root][INFO] - Training Epoch: 1/2, step 2137/7134 completed (loss: 4.131911277770996, acc: 0.31382977962493896)
[2024-12-17 01:47:44,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:44,965][root][INFO] - Training Epoch: 1/2, step 2138/7134 completed (loss: 3.954833984375, acc: 0.2934131622314453)
[2024-12-17 01:47:45,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:45,243][root][INFO] - Training Epoch: 1/2, step 2139/7134 completed (loss: 4.048587799072266, acc: 0.24418604373931885)
[2024-12-17 01:47:45,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:45,535][root][INFO] - Training Epoch: 1/2, step 2140/7134 completed (loss: 4.319186687469482, acc: 0.2542372941970825)
[2024-12-17 01:47:45,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:45,756][root][INFO] - Training Epoch: 1/2, step 2141/7134 completed (loss: 4.967857360839844, acc: 0.20212766528129578)
[2024-12-17 01:47:45,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:46,039][root][INFO] - Training Epoch: 1/2, step 2142/7134 completed (loss: 4.683956146240234, acc: 0.1977401077747345)
[2024-12-17 01:47:46,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:46,318][root][INFO] - Training Epoch: 1/2, step 2143/7134 completed (loss: 4.19010066986084, acc: 0.2896551787853241)
[2024-12-17 01:47:46,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:46,606][root][INFO] - Training Epoch: 1/2, step 2144/7134 completed (loss: 3.9956512451171875, acc: 0.2613636255264282)
[2024-12-17 01:47:46,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:46,888][root][INFO] - Training Epoch: 1/2, step 2145/7134 completed (loss: 4.817041397094727, acc: 0.25)
[2024-12-17 01:47:47,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:47,170][root][INFO] - Training Epoch: 1/2, step 2146/7134 completed (loss: 3.8151040077209473, acc: 0.3243243098258972)
[2024-12-17 01:47:47,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:47,457][root][INFO] - Training Epoch: 1/2, step 2147/7134 completed (loss: 4.44400691986084, acc: 0.24747474491596222)
[2024-12-17 01:47:47,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:47,740][root][INFO] - Training Epoch: 1/2, step 2148/7134 completed (loss: 3.8993544578552246, acc: 0.33522728085517883)
[2024-12-17 01:47:47,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:48,012][root][INFO] - Training Epoch: 1/2, step 2149/7134 completed (loss: 4.163254261016846, acc: 0.28070175647735596)
[2024-12-17 01:47:48,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:48,275][root][INFO] - Training Epoch: 1/2, step 2150/7134 completed (loss: 4.02670431137085, acc: 0.2711864411830902)
[2024-12-17 01:47:48,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:48,553][root][INFO] - Training Epoch: 1/2, step 2151/7134 completed (loss: 4.212458610534668, acc: 0.27108433842658997)
[2024-12-17 01:47:48,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:48,839][root][INFO] - Training Epoch: 1/2, step 2152/7134 completed (loss: 4.316656112670898, acc: 0.2774193584918976)
[2024-12-17 01:47:48,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:49,138][root][INFO] - Training Epoch: 1/2, step 2153/7134 completed (loss: 4.266045570373535, acc: 0.2696078419685364)
[2024-12-17 01:47:49,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:49,425][root][INFO] - Training Epoch: 1/2, step 2154/7134 completed (loss: 4.610904693603516, acc: 0.24137930572032928)
[2024-12-17 01:47:49,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:49,676][root][INFO] - Training Epoch: 1/2, step 2155/7134 completed (loss: 4.409298896789551, acc: 0.24358974397182465)
[2024-12-17 01:47:49,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:49,934][root][INFO] - Training Epoch: 1/2, step 2156/7134 completed (loss: 3.808234691619873, acc: 0.2720588147640228)
[2024-12-17 01:47:50,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:50,213][root][INFO] - Training Epoch: 1/2, step 2157/7134 completed (loss: 4.1613311767578125, acc: 0.2777777910232544)
[2024-12-17 01:47:50,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:50,492][root][INFO] - Training Epoch: 1/2, step 2158/7134 completed (loss: 4.310529708862305, acc: 0.21134020388126373)
[2024-12-17 01:47:50,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:50,768][root][INFO] - Training Epoch: 1/2, step 2159/7134 completed (loss: 4.006722927093506, acc: 0.2678571343421936)
[2024-12-17 01:47:50,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:51,039][root][INFO] - Training Epoch: 1/2, step 2160/7134 completed (loss: 3.9689364433288574, acc: 0.3048780560493469)
[2024-12-17 01:47:51,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:51,307][root][INFO] - Training Epoch: 1/2, step 2161/7134 completed (loss: 3.750938892364502, acc: 0.3055555522441864)
[2024-12-17 01:47:51,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:51,575][root][INFO] - Training Epoch: 1/2, step 2162/7134 completed (loss: 4.147494792938232, acc: 0.23870967328548431)
[2024-12-17 01:47:51,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:51,861][root][INFO] - Training Epoch: 1/2, step 2163/7134 completed (loss: 4.371215343475342, acc: 0.2199999988079071)
[2024-12-17 01:47:51,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:52,110][root][INFO] - Training Epoch: 1/2, step 2164/7134 completed (loss: 4.276003837585449, acc: 0.24242424964904785)
[2024-12-17 01:47:52,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:52,393][root][INFO] - Training Epoch: 1/2, step 2165/7134 completed (loss: 3.686495780944824, acc: 0.28658536076545715)
[2024-12-17 01:47:52,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:52,665][root][INFO] - Training Epoch: 1/2, step 2166/7134 completed (loss: 3.7638063430786133, acc: 0.33898305892944336)
[2024-12-17 01:47:52,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:52,979][root][INFO] - Training Epoch: 1/2, step 2167/7134 completed (loss: 4.04973840713501, acc: 0.3009708821773529)
[2024-12-17 01:47:53,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:53,261][root][INFO] - Training Epoch: 1/2, step 2168/7134 completed (loss: 4.096993923187256, acc: 0.2733812928199768)
[2024-12-17 01:47:53,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:53,542][root][INFO] - Training Epoch: 1/2, step 2169/7134 completed (loss: 3.3757526874542236, acc: 0.3819095492362976)
[2024-12-17 01:47:53,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:53,809][root][INFO] - Training Epoch: 1/2, step 2170/7134 completed (loss: 4.113822937011719, acc: 0.2875817120075226)
[2024-12-17 01:47:53,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:54,093][root][INFO] - Training Epoch: 1/2, step 2171/7134 completed (loss: 4.1698317527771, acc: 0.2432432472705841)
[2024-12-17 01:47:54,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:54,365][root][INFO] - Training Epoch: 1/2, step 2172/7134 completed (loss: 3.967541217803955, acc: 0.28436020016670227)
[2024-12-17 01:47:54,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:54,638][root][INFO] - Training Epoch: 1/2, step 2173/7134 completed (loss: 4.406382083892822, acc: 0.24657534062862396)
[2024-12-17 01:47:54,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:54,911][root][INFO] - Training Epoch: 1/2, step 2174/7134 completed (loss: 3.7918500900268555, acc: 0.3353293538093567)
[2024-12-17 01:47:55,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:55,186][root][INFO] - Training Epoch: 1/2, step 2175/7134 completed (loss: 3.92438006401062, acc: 0.3272727131843567)
[2024-12-17 01:47:55,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:55,478][root][INFO] - Training Epoch: 1/2, step 2176/7134 completed (loss: 3.9772467613220215, acc: 0.30434781312942505)
[2024-12-17 01:47:55,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:55,798][root][INFO] - Training Epoch: 1/2, step 2177/7134 completed (loss: 3.8512215614318848, acc: 0.28961747884750366)
[2024-12-17 01:47:55,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:56,066][root][INFO] - Training Epoch: 1/2, step 2178/7134 completed (loss: 3.90899920463562, acc: 0.2864583432674408)
[2024-12-17 01:47:56,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:56,345][root][INFO] - Training Epoch: 1/2, step 2179/7134 completed (loss: 3.646374464035034, acc: 0.3333333432674408)
[2024-12-17 01:47:56,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:56,621][root][INFO] - Training Epoch: 1/2, step 2180/7134 completed (loss: 4.182108402252197, acc: 0.2252747267484665)
[2024-12-17 01:47:56,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:56,938][root][INFO] - Training Epoch: 1/2, step 2181/7134 completed (loss: 3.727681875228882, acc: 0.3229813575744629)
[2024-12-17 01:47:57,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:57,220][root][INFO] - Training Epoch: 1/2, step 2182/7134 completed (loss: 4.100275039672852, acc: 0.3282051384449005)
[2024-12-17 01:47:57,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:57,526][root][INFO] - Training Epoch: 1/2, step 2183/7134 completed (loss: 3.9375531673431396, acc: 0.2928176820278168)
[2024-12-17 01:47:57,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:57,820][root][INFO] - Training Epoch: 1/2, step 2184/7134 completed (loss: 3.987727642059326, acc: 0.2957746386528015)
[2024-12-17 01:47:57,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:58,095][root][INFO] - Training Epoch: 1/2, step 2185/7134 completed (loss: 4.199743270874023, acc: 0.2704402506351471)
[2024-12-17 01:47:58,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:58,382][root][INFO] - Training Epoch: 1/2, step 2186/7134 completed (loss: 3.8364062309265137, acc: 0.3400000035762787)
[2024-12-17 01:47:58,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:58,676][root][INFO] - Training Epoch: 1/2, step 2187/7134 completed (loss: 4.189985275268555, acc: 0.3093525171279907)
[2024-12-17 01:47:58,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:59,003][root][INFO] - Training Epoch: 1/2, step 2188/7134 completed (loss: 3.4155373573303223, acc: 0.38181817531585693)
[2024-12-17 01:47:59,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:59,275][root][INFO] - Training Epoch: 1/2, step 2189/7134 completed (loss: 4.015563011169434, acc: 0.3181818127632141)
[2024-12-17 01:47:59,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:59,562][root][INFO] - Training Epoch: 1/2, step 2190/7134 completed (loss: 3.6271862983703613, acc: 0.34078213572502136)
[2024-12-17 01:47:59,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:59,827][root][INFO] - Training Epoch: 1/2, step 2191/7134 completed (loss: 4.3295769691467285, acc: 0.3263157904148102)
[2024-12-17 01:47:59,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:00,101][root][INFO] - Training Epoch: 1/2, step 2192/7134 completed (loss: 4.018192768096924, acc: 0.24444444477558136)
[2024-12-17 01:48:00,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:00,383][root][INFO] - Training Epoch: 1/2, step 2193/7134 completed (loss: 3.8999857902526855, acc: 0.284153014421463)
[2024-12-17 01:48:00,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:00,660][root][INFO] - Training Epoch: 1/2, step 2194/7134 completed (loss: 4.256842136383057, acc: 0.23026315867900848)
[2024-12-17 01:48:00,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:00,950][root][INFO] - Training Epoch: 1/2, step 2195/7134 completed (loss: 3.6763482093811035, acc: 0.32098764181137085)
[2024-12-17 01:48:01,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:01,236][root][INFO] - Training Epoch: 1/2, step 2196/7134 completed (loss: 4.118388652801514, acc: 0.20879121124744415)
[2024-12-17 01:48:01,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:01,498][root][INFO] - Training Epoch: 1/2, step 2197/7134 completed (loss: 3.992542266845703, acc: 0.28346458077430725)
[2024-12-17 01:48:01,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:01,775][root][INFO] - Training Epoch: 1/2, step 2198/7134 completed (loss: 3.803440570831299, acc: 0.3218390941619873)
[2024-12-17 01:48:01,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:02,049][root][INFO] - Training Epoch: 1/2, step 2199/7134 completed (loss: 3.766554355621338, acc: 0.29113924503326416)
[2024-12-17 01:48:02,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:02,329][root][INFO] - Training Epoch: 1/2, step 2200/7134 completed (loss: 4.033461570739746, acc: 0.26771652698516846)
[2024-12-17 01:48:02,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:02,609][root][INFO] - Training Epoch: 1/2, step 2201/7134 completed (loss: 3.9856104850769043, acc: 0.31081080436706543)
[2024-12-17 01:48:02,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:02,910][root][INFO] - Training Epoch: 1/2, step 2202/7134 completed (loss: 4.203812599182129, acc: 0.29197078943252563)
[2024-12-17 01:48:03,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:03,204][root][INFO] - Training Epoch: 1/2, step 2203/7134 completed (loss: 3.8663363456726074, acc: 0.31137725710868835)
[2024-12-17 01:48:03,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:03,479][root][INFO] - Training Epoch: 1/2, step 2204/7134 completed (loss: 3.9045305252075195, acc: 0.27586206793785095)
[2024-12-17 01:48:03,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:03,758][root][INFO] - Training Epoch: 1/2, step 2205/7134 completed (loss: 3.787311553955078, acc: 0.2978723347187042)
[2024-12-17 01:48:03,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:04,042][root][INFO] - Training Epoch: 1/2, step 2206/7134 completed (loss: 4.153278827667236, acc: 0.26174497604370117)
[2024-12-17 01:48:04,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:04,325][root][INFO] - Training Epoch: 1/2, step 2207/7134 completed (loss: 3.8281469345092773, acc: 0.21768707036972046)
[2024-12-17 01:48:04,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:04,600][root][INFO] - Training Epoch: 1/2, step 2208/7134 completed (loss: 4.414938926696777, acc: 0.25806450843811035)
[2024-12-17 01:48:04,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:04,880][root][INFO] - Training Epoch: 1/2, step 2209/7134 completed (loss: 3.9538309574127197, acc: 0.29878050088882446)
[2024-12-17 01:48:05,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:05,162][root][INFO] - Training Epoch: 1/2, step 2210/7134 completed (loss: 3.8844006061553955, acc: 0.31707316637039185)
[2024-12-17 01:48:05,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:05,441][root][INFO] - Training Epoch: 1/2, step 2211/7134 completed (loss: 3.944830894470215, acc: 0.28313252329826355)
[2024-12-17 01:48:05,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:05,726][root][INFO] - Training Epoch: 1/2, step 2212/7134 completed (loss: 4.065912246704102, acc: 0.23999999463558197)
[2024-12-17 01:48:05,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:06,004][root][INFO] - Training Epoch: 1/2, step 2213/7134 completed (loss: 4.144583702087402, acc: 0.25294119119644165)
[2024-12-17 01:48:06,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:06,268][root][INFO] - Training Epoch: 1/2, step 2214/7134 completed (loss: 3.6406729221343994, acc: 0.3310810923576355)
[2024-12-17 01:48:06,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:06,535][root][INFO] - Training Epoch: 1/2, step 2215/7134 completed (loss: 4.080635070800781, acc: 0.31012657284736633)
[2024-12-17 01:48:06,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:06,805][root][INFO] - Training Epoch: 1/2, step 2216/7134 completed (loss: 3.9168975353240967, acc: 0.24561403691768646)
[2024-12-17 01:48:06,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:07,071][root][INFO] - Training Epoch: 1/2, step 2217/7134 completed (loss: 3.9345550537109375, acc: 0.23952095210552216)
[2024-12-17 01:48:07,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:07,333][root][INFO] - Training Epoch: 1/2, step 2218/7134 completed (loss: 4.45710563659668, acc: 0.2469135820865631)
[2024-12-17 01:48:07,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:07,595][root][INFO] - Training Epoch: 1/2, step 2219/7134 completed (loss: 3.9423248767852783, acc: 0.30714285373687744)
[2024-12-17 01:48:07,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:07,858][root][INFO] - Training Epoch: 1/2, step 2220/7134 completed (loss: 4.144076824188232, acc: 0.29629629850387573)
[2024-12-17 01:48:07,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:08,148][root][INFO] - Training Epoch: 1/2, step 2221/7134 completed (loss: 4.403149604797363, acc: 0.25465837121009827)
[2024-12-17 01:48:08,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:08,415][root][INFO] - Training Epoch: 1/2, step 2222/7134 completed (loss: 4.51949405670166, acc: 0.24657534062862396)
[2024-12-17 01:48:08,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:08,690][root][INFO] - Training Epoch: 1/2, step 2223/7134 completed (loss: 4.206804275512695, acc: 0.2281879186630249)
[2024-12-17 01:48:08,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:09,004][root][INFO] - Training Epoch: 1/2, step 2224/7134 completed (loss: 3.7972686290740967, acc: 0.34810125827789307)
[2024-12-17 01:48:09,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:09,289][root][INFO] - Training Epoch: 1/2, step 2225/7134 completed (loss: 4.551462173461914, acc: 0.2380952388048172)
[2024-12-17 01:48:09,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:09,566][root][INFO] - Training Epoch: 1/2, step 2226/7134 completed (loss: 4.022686004638672, acc: 0.24161073565483093)
[2024-12-17 01:48:09,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:09,840][root][INFO] - Training Epoch: 1/2, step 2227/7134 completed (loss: 4.237329483032227, acc: 0.26623377203941345)
[2024-12-17 01:48:09,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:10,099][root][INFO] - Training Epoch: 1/2, step 2228/7134 completed (loss: 4.168750762939453, acc: 0.2868216931819916)
[2024-12-17 01:48:10,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:10,368][root][INFO] - Training Epoch: 1/2, step 2229/7134 completed (loss: 3.854846239089966, acc: 0.3106796145439148)
[2024-12-17 01:48:10,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:10,618][root][INFO] - Training Epoch: 1/2, step 2230/7134 completed (loss: 3.7500317096710205, acc: 0.3093525171279907)
[2024-12-17 01:48:10,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:10,883][root][INFO] - Training Epoch: 1/2, step 2231/7134 completed (loss: 4.339305877685547, acc: 0.2857142984867096)
[2024-12-17 01:48:10,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:11,157][root][INFO] - Training Epoch: 1/2, step 2232/7134 completed (loss: 3.7870707511901855, acc: 0.35057470202445984)
[2024-12-17 01:48:11,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:11,436][root][INFO] - Training Epoch: 1/2, step 2233/7134 completed (loss: 3.976999521255493, acc: 0.2756410241127014)
[2024-12-17 01:48:11,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:11,739][root][INFO] - Training Epoch: 1/2, step 2234/7134 completed (loss: 4.195960998535156, acc: 0.2792207896709442)
[2024-12-17 01:48:11,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:12,016][root][INFO] - Training Epoch: 1/2, step 2235/7134 completed (loss: 4.272801399230957, acc: 0.24475523829460144)
[2024-12-17 01:48:12,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:12,278][root][INFO] - Training Epoch: 1/2, step 2236/7134 completed (loss: 4.020445346832275, acc: 0.30000001192092896)
[2024-12-17 01:48:12,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:12,572][root][INFO] - Training Epoch: 1/2, step 2237/7134 completed (loss: 4.1018218994140625, acc: 0.20000000298023224)
[2024-12-17 01:48:12,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:12,852][root][INFO] - Training Epoch: 1/2, step 2238/7134 completed (loss: 4.086076259613037, acc: 0.29629629850387573)
[2024-12-17 01:48:12,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:13,130][root][INFO] - Training Epoch: 1/2, step 2239/7134 completed (loss: 4.363487243652344, acc: 0.28877004981040955)
[2024-12-17 01:48:13,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:13,427][root][INFO] - Training Epoch: 1/2, step 2240/7134 completed (loss: 4.570062160491943, acc: 0.22727273404598236)
[2024-12-17 01:48:13,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:13,697][root][INFO] - Training Epoch: 1/2, step 2241/7134 completed (loss: 4.267834186553955, acc: 0.2916666567325592)
[2024-12-17 01:48:13,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:13,950][root][INFO] - Training Epoch: 1/2, step 2242/7134 completed (loss: 4.406628131866455, acc: 0.3055555522441864)
[2024-12-17 01:48:14,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:14,267][root][INFO] - Training Epoch: 1/2, step 2243/7134 completed (loss: 4.247755527496338, acc: 0.3612903356552124)
[2024-12-17 01:48:14,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:14,551][root][INFO] - Training Epoch: 1/2, step 2244/7134 completed (loss: 4.876044750213623, acc: 0.2602739632129669)
[2024-12-17 01:48:14,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:14,817][root][INFO] - Training Epoch: 1/2, step 2245/7134 completed (loss: 4.32168436050415, acc: 0.3006536066532135)
[2024-12-17 01:48:14,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:15,102][root][INFO] - Training Epoch: 1/2, step 2246/7134 completed (loss: 5.244765758514404, acc: 0.284153014421463)
[2024-12-17 01:48:15,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:15,381][root][INFO] - Training Epoch: 1/2, step 2247/7134 completed (loss: 5.192033767700195, acc: 0.24277456104755402)
[2024-12-17 01:48:15,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:15,653][root][INFO] - Training Epoch: 1/2, step 2248/7134 completed (loss: 5.014214992523193, acc: 0.2601155936717987)
[2024-12-17 01:48:15,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:15,929][root][INFO] - Training Epoch: 1/2, step 2249/7134 completed (loss: 4.469850540161133, acc: 0.2707182466983795)
[2024-12-17 01:48:16,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:16,237][root][INFO] - Training Epoch: 1/2, step 2250/7134 completed (loss: 4.428947925567627, acc: 0.31382977962493896)
[2024-12-17 01:48:16,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:16,501][root][INFO] - Training Epoch: 1/2, step 2251/7134 completed (loss: 4.041841506958008, acc: 0.2540983557701111)
[2024-12-17 01:48:16,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:16,771][root][INFO] - Training Epoch: 1/2, step 2252/7134 completed (loss: 4.143795013427734, acc: 0.2445652186870575)
[2024-12-17 01:48:16,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:17,076][root][INFO] - Training Epoch: 1/2, step 2253/7134 completed (loss: 4.300611972808838, acc: 0.2165605127811432)
[2024-12-17 01:48:17,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:17,335][root][INFO] - Training Epoch: 1/2, step 2254/7134 completed (loss: 4.369027137756348, acc: 0.30645161867141724)
[2024-12-17 01:48:17,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:17,615][root][INFO] - Training Epoch: 1/2, step 2255/7134 completed (loss: 3.922133684158325, acc: 0.2641509473323822)
[2024-12-17 01:48:17,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:17,859][root][INFO] - Training Epoch: 1/2, step 2256/7134 completed (loss: 4.772701263427734, acc: 0.2520325183868408)
[2024-12-17 01:48:17,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:18,143][root][INFO] - Training Epoch: 1/2, step 2257/7134 completed (loss: 4.027460098266602, acc: 0.29012346267700195)
[2024-12-17 01:48:18,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:18,442][root][INFO] - Training Epoch: 1/2, step 2258/7134 completed (loss: 4.396554946899414, acc: 0.27906978130340576)
[2024-12-17 01:48:18,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:18,730][root][INFO] - Training Epoch: 1/2, step 2259/7134 completed (loss: 4.042415618896484, acc: 0.3333333432674408)
[2024-12-17 01:48:18,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:19,021][root][INFO] - Training Epoch: 1/2, step 2260/7134 completed (loss: 4.113708972930908, acc: 0.2792207896709442)
[2024-12-17 01:48:19,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:19,313][root][INFO] - Training Epoch: 1/2, step 2261/7134 completed (loss: 4.0115180015563965, acc: 0.29629629850387573)
[2024-12-17 01:48:19,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:19,587][root][INFO] - Training Epoch: 1/2, step 2262/7134 completed (loss: 4.636757850646973, acc: 0.27819550037384033)
[2024-12-17 01:48:19,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:19,879][root][INFO] - Training Epoch: 1/2, step 2263/7134 completed (loss: 4.195688247680664, acc: 0.33834585547447205)
[2024-12-17 01:48:20,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:20,170][root][INFO] - Training Epoch: 1/2, step 2264/7134 completed (loss: 4.000561237335205, acc: 0.3351351320743561)
[2024-12-17 01:48:20,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:20,478][root][INFO] - Training Epoch: 1/2, step 2265/7134 completed (loss: 4.451142311096191, acc: 0.2467532455921173)
[2024-12-17 01:48:20,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:20,773][root][INFO] - Training Epoch: 1/2, step 2266/7134 completed (loss: 4.1215901374816895, acc: 0.31491711735725403)
[2024-12-17 01:48:20,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:21,059][root][INFO] - Training Epoch: 1/2, step 2267/7134 completed (loss: 3.8091518878936768, acc: 0.28455284237861633)
[2024-12-17 01:48:21,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:21,364][root][INFO] - Training Epoch: 1/2, step 2268/7134 completed (loss: 4.593164443969727, acc: 0.24657534062862396)
[2024-12-17 01:48:21,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:21,666][root][INFO] - Training Epoch: 1/2, step 2269/7134 completed (loss: 4.281210899353027, acc: 0.29050278663635254)
[2024-12-17 01:48:21,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:21,952][root][INFO] - Training Epoch: 1/2, step 2270/7134 completed (loss: 4.277122974395752, acc: 0.296875)
[2024-12-17 01:48:22,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:22,254][root][INFO] - Training Epoch: 1/2, step 2271/7134 completed (loss: 4.297832489013672, acc: 0.31351351737976074)
[2024-12-17 01:48:22,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:22,550][root][INFO] - Training Epoch: 1/2, step 2272/7134 completed (loss: 3.8597357273101807, acc: 0.36021506786346436)
[2024-12-17 01:48:22,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:22,844][root][INFO] - Training Epoch: 1/2, step 2273/7134 completed (loss: 4.0665364265441895, acc: 0.25)
[2024-12-17 01:48:22,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:23,150][root][INFO] - Training Epoch: 1/2, step 2274/7134 completed (loss: 4.8523640632629395, acc: 0.22564102709293365)
[2024-12-17 01:48:23,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:23,445][root][INFO] - Training Epoch: 1/2, step 2275/7134 completed (loss: 3.620091199874878, acc: 0.3284313678741455)
[2024-12-17 01:48:23,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:23,761][root][INFO] - Training Epoch: 1/2, step 2276/7134 completed (loss: 4.055484294891357, acc: 0.29629629850387573)
[2024-12-17 01:48:23,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:24,063][root][INFO] - Training Epoch: 1/2, step 2277/7134 completed (loss: 4.358879089355469, acc: 0.25128206610679626)
[2024-12-17 01:48:24,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:24,368][root][INFO] - Training Epoch: 1/2, step 2278/7134 completed (loss: 4.575412273406982, acc: 0.29032257199287415)
[2024-12-17 01:48:24,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:24,665][root][INFO] - Training Epoch: 1/2, step 2279/7134 completed (loss: 4.044999122619629, acc: 0.2791878283023834)
[2024-12-17 01:48:24,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:24,964][root][INFO] - Training Epoch: 1/2, step 2280/7134 completed (loss: 3.7637157440185547, acc: 0.31192660331726074)
[2024-12-17 01:48:25,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:25,251][root][INFO] - Training Epoch: 1/2, step 2281/7134 completed (loss: 4.095578193664551, acc: 0.3297872245311737)
[2024-12-17 01:48:25,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:25,550][root][INFO] - Training Epoch: 1/2, step 2282/7134 completed (loss: 3.7843172550201416, acc: 0.28421053290367126)
[2024-12-17 01:48:25,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:25,851][root][INFO] - Training Epoch: 1/2, step 2283/7134 completed (loss: 3.9622488021850586, acc: 0.26442307233810425)
[2024-12-17 01:48:25,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:26,141][root][INFO] - Training Epoch: 1/2, step 2284/7134 completed (loss: 4.083532333374023, acc: 0.32258063554763794)
[2024-12-17 01:48:26,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:26,449][root][INFO] - Training Epoch: 1/2, step 2285/7134 completed (loss: 3.852048635482788, acc: 0.33000001311302185)
[2024-12-17 01:48:26,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:26,748][root][INFO] - Training Epoch: 1/2, step 2286/7134 completed (loss: 4.510199546813965, acc: 0.2586206793785095)
[2024-12-17 01:48:26,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:27,058][root][INFO] - Training Epoch: 1/2, step 2287/7134 completed (loss: 4.4389801025390625, acc: 0.30674847960472107)
[2024-12-17 01:48:27,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:27,365][root][INFO] - Training Epoch: 1/2, step 2288/7134 completed (loss: 3.99888014793396, acc: 0.2527472674846649)
[2024-12-17 01:48:27,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:27,653][root][INFO] - Training Epoch: 1/2, step 2289/7134 completed (loss: 3.8715734481811523, acc: 0.29411765933036804)
[2024-12-17 01:48:27,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:27,937][root][INFO] - Training Epoch: 1/2, step 2290/7134 completed (loss: 4.097086429595947, acc: 0.2956989109516144)
[2024-12-17 01:48:28,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:28,234][root][INFO] - Training Epoch: 1/2, step 2291/7134 completed (loss: 4.354756832122803, acc: 0.2596684992313385)
[2024-12-17 01:48:28,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:28,523][root][INFO] - Training Epoch: 1/2, step 2292/7134 completed (loss: 4.103947639465332, acc: 0.2929292917251587)
[2024-12-17 01:48:28,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:28,827][root][INFO] - Training Epoch: 1/2, step 2293/7134 completed (loss: 3.644597053527832, acc: 0.29680365324020386)
[2024-12-17 01:48:28,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:29,117][root][INFO] - Training Epoch: 1/2, step 2294/7134 completed (loss: 3.8353826999664307, acc: 0.330143541097641)
[2024-12-17 01:48:29,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:29,429][root][INFO] - Training Epoch: 1/2, step 2295/7134 completed (loss: 3.7813541889190674, acc: 0.3125)
[2024-12-17 01:48:29,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:29,724][root][INFO] - Training Epoch: 1/2, step 2296/7134 completed (loss: 3.6790990829467773, acc: 0.2884615361690521)
[2024-12-17 01:48:29,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:30,019][root][INFO] - Training Epoch: 1/2, step 2297/7134 completed (loss: 3.6886179447174072, acc: 0.31603774428367615)
[2024-12-17 01:48:30,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:30,312][root][INFO] - Training Epoch: 1/2, step 2298/7134 completed (loss: 3.9048688411712646, acc: 0.30000001192092896)
[2024-12-17 01:48:30,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:30,618][root][INFO] - Training Epoch: 1/2, step 2299/7134 completed (loss: 4.280570030212402, acc: 0.2634408473968506)
[2024-12-17 01:48:30,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:30,913][root][INFO] - Training Epoch: 1/2, step 2300/7134 completed (loss: 3.599789619445801, acc: 0.32828283309936523)
[2024-12-17 01:48:31,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:31,200][root][INFO] - Training Epoch: 1/2, step 2301/7134 completed (loss: 3.835371971130371, acc: 0.32608696818351746)
[2024-12-17 01:48:31,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:31,480][root][INFO] - Training Epoch: 1/2, step 2302/7134 completed (loss: 4.1556572914123535, acc: 0.25128206610679626)
[2024-12-17 01:48:31,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:31,735][root][INFO] - Training Epoch: 1/2, step 2303/7134 completed (loss: 3.7355079650878906, acc: 0.3502304255962372)
[2024-12-17 01:48:31,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:32,016][root][INFO] - Training Epoch: 1/2, step 2304/7134 completed (loss: 4.276715278625488, acc: 0.303964763879776)
[2024-12-17 01:48:32,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:32,301][root][INFO] - Training Epoch: 1/2, step 2305/7134 completed (loss: 4.242081165313721, acc: 0.28773584961891174)
[2024-12-17 01:48:32,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:32,581][root][INFO] - Training Epoch: 1/2, step 2306/7134 completed (loss: 3.657423496246338, acc: 0.3348837196826935)
[2024-12-17 01:48:32,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:32,850][root][INFO] - Training Epoch: 1/2, step 2307/7134 completed (loss: 3.660184383392334, acc: 0.32203391194343567)
[2024-12-17 01:48:32,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:33,130][root][INFO] - Training Epoch: 1/2, step 2308/7134 completed (loss: 4.148054122924805, acc: 0.2907488942146301)
[2024-12-17 01:48:33,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:33,394][root][INFO] - Training Epoch: 1/2, step 2309/7134 completed (loss: 3.660895347595215, acc: 0.33862432837486267)
[2024-12-17 01:48:33,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:33,666][root][INFO] - Training Epoch: 1/2, step 2310/7134 completed (loss: 3.644510269165039, acc: 0.34761905670166016)
[2024-12-17 01:48:33,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:33,931][root][INFO] - Training Epoch: 1/2, step 2311/7134 completed (loss: 3.6826531887054443, acc: 0.2807881832122803)
[2024-12-17 01:48:34,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:34,217][root][INFO] - Training Epoch: 1/2, step 2312/7134 completed (loss: 3.878386974334717, acc: 0.31924882531166077)
[2024-12-17 01:48:34,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:34,488][root][INFO] - Training Epoch: 1/2, step 2313/7134 completed (loss: 4.387148857116699, acc: 0.30288460850715637)
[2024-12-17 01:48:34,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:34,786][root][INFO] - Training Epoch: 1/2, step 2314/7134 completed (loss: 4.108684062957764, acc: 0.2568807303905487)
[2024-12-17 01:48:34,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:35,079][root][INFO] - Training Epoch: 1/2, step 2315/7134 completed (loss: 3.9358954429626465, acc: 0.302325576543808)
[2024-12-17 01:48:35,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:35,367][root][INFO] - Training Epoch: 1/2, step 2316/7134 completed (loss: 3.947824239730835, acc: 0.32275131344795227)
[2024-12-17 01:48:35,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:35,664][root][INFO] - Training Epoch: 1/2, step 2317/7134 completed (loss: 3.748054265975952, acc: 0.2689075767993927)
[2024-12-17 01:48:35,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:35,959][root][INFO] - Training Epoch: 1/2, step 2318/7134 completed (loss: 3.5741755962371826, acc: 0.34934496879577637)
[2024-12-17 01:48:36,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:36,236][root][INFO] - Training Epoch: 1/2, step 2319/7134 completed (loss: 3.4413962364196777, acc: 0.3333333432674408)
[2024-12-17 01:48:36,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:36,513][root][INFO] - Training Epoch: 1/2, step 2320/7134 completed (loss: 3.6573359966278076, acc: 0.2974359095096588)
[2024-12-17 01:48:36,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:36,790][root][INFO] - Training Epoch: 1/2, step 2321/7134 completed (loss: 3.7135303020477295, acc: 0.3176470696926117)
[2024-12-17 01:48:36,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:37,072][root][INFO] - Training Epoch: 1/2, step 2322/7134 completed (loss: 3.9145965576171875, acc: 0.30674847960472107)
[2024-12-17 01:48:37,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:37,343][root][INFO] - Training Epoch: 1/2, step 2323/7134 completed (loss: 4.4660444259643555, acc: 0.21019108593463898)
[2024-12-17 01:48:37,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:37,624][root][INFO] - Training Epoch: 1/2, step 2324/7134 completed (loss: 4.425069808959961, acc: 0.27108433842658997)
[2024-12-17 01:48:37,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:37,913][root][INFO] - Training Epoch: 1/2, step 2325/7134 completed (loss: 4.458532333374023, acc: 0.24285714328289032)
[2024-12-17 01:48:38,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:38,173][root][INFO] - Training Epoch: 1/2, step 2326/7134 completed (loss: 3.876786708831787, acc: 0.30000001192092896)
[2024-12-17 01:48:38,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:38,438][root][INFO] - Training Epoch: 1/2, step 2327/7134 completed (loss: 4.625311374664307, acc: 0.28859061002731323)
[2024-12-17 01:48:38,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:38,723][root][INFO] - Training Epoch: 1/2, step 2328/7134 completed (loss: 4.739200592041016, acc: 0.25503355264663696)
[2024-12-17 01:48:38,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:39,002][root][INFO] - Training Epoch: 1/2, step 2329/7134 completed (loss: 3.77945613861084, acc: 0.32679739594459534)
[2024-12-17 01:48:39,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:39,269][root][INFO] - Training Epoch: 1/2, step 2330/7134 completed (loss: 4.365434169769287, acc: 0.3030303120613098)
[2024-12-17 01:48:39,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:39,543][root][INFO] - Training Epoch: 1/2, step 2331/7134 completed (loss: 3.813866376876831, acc: 0.2967741787433624)
[2024-12-17 01:48:39,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:39,825][root][INFO] - Training Epoch: 1/2, step 2332/7134 completed (loss: 3.901454448699951, acc: 0.28484848141670227)
[2024-12-17 01:48:39,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:40,100][root][INFO] - Training Epoch: 1/2, step 2333/7134 completed (loss: 3.693263053894043, acc: 0.3353658616542816)
[2024-12-17 01:48:40,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:40,380][root][INFO] - Training Epoch: 1/2, step 2334/7134 completed (loss: 4.088499546051025, acc: 0.337579607963562)
[2024-12-17 01:48:40,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:40,681][root][INFO] - Training Epoch: 1/2, step 2335/7134 completed (loss: 4.086018085479736, acc: 0.297468364238739)
[2024-12-17 01:48:40,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:40,946][root][INFO] - Training Epoch: 1/2, step 2336/7134 completed (loss: 4.184924602508545, acc: 0.268456369638443)
[2024-12-17 01:48:41,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:41,224][root][INFO] - Training Epoch: 1/2, step 2337/7134 completed (loss: 4.290307998657227, acc: 0.2083333283662796)
[2024-12-17 01:48:41,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:41,507][root][INFO] - Training Epoch: 1/2, step 2338/7134 completed (loss: 4.426848411560059, acc: 0.22727273404598236)
[2024-12-17 01:48:41,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:41,785][root][INFO] - Training Epoch: 1/2, step 2339/7134 completed (loss: 4.313746452331543, acc: 0.2884615361690521)
[2024-12-17 01:48:41,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:42,062][root][INFO] - Training Epoch: 1/2, step 2340/7134 completed (loss: 4.086825847625732, acc: 0.2792207896709442)
[2024-12-17 01:48:42,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:42,337][root][INFO] - Training Epoch: 1/2, step 2341/7134 completed (loss: 3.9218802452087402, acc: 0.3057851195335388)
[2024-12-17 01:48:42,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:42,599][root][INFO] - Training Epoch: 1/2, step 2342/7134 completed (loss: 3.7533459663391113, acc: 0.369047611951828)
[2024-12-17 01:48:42,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:42,874][root][INFO] - Training Epoch: 1/2, step 2343/7134 completed (loss: 4.112431049346924, acc: 0.3187499940395355)
[2024-12-17 01:48:42,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:43,156][root][INFO] - Training Epoch: 1/2, step 2344/7134 completed (loss: 4.652575492858887, acc: 0.2777777910232544)
[2024-12-17 01:48:43,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:43,430][root][INFO] - Training Epoch: 1/2, step 2345/7134 completed (loss: 4.507484436035156, acc: 0.25287356972694397)
[2024-12-17 01:48:43,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:43,732][root][INFO] - Training Epoch: 1/2, step 2346/7134 completed (loss: 3.899637222290039, acc: 0.33701658248901367)
[2024-12-17 01:48:43,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:44,028][root][INFO] - Training Epoch: 1/2, step 2347/7134 completed (loss: 3.6417691707611084, acc: 0.35915493965148926)
[2024-12-17 01:48:44,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:44,325][root][INFO] - Training Epoch: 1/2, step 2348/7134 completed (loss: 4.1364545822143555, acc: 0.30927833914756775)
[2024-12-17 01:48:44,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:44,623][root][INFO] - Training Epoch: 1/2, step 2349/7134 completed (loss: 4.864311695098877, acc: 0.25)
[2024-12-17 01:48:44,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:44,948][root][INFO] - Training Epoch: 1/2, step 2350/7134 completed (loss: 4.932365894317627, acc: 0.22151899337768555)
[2024-12-17 01:48:45,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:45,259][root][INFO] - Training Epoch: 1/2, step 2351/7134 completed (loss: 3.9428224563598633, acc: 0.3442623019218445)
[2024-12-17 01:48:45,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:45,550][root][INFO] - Training Epoch: 1/2, step 2352/7134 completed (loss: 4.88205099105835, acc: 0.2451612949371338)
[2024-12-17 01:48:45,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:45,855][root][INFO] - Training Epoch: 1/2, step 2353/7134 completed (loss: 4.070804595947266, acc: 0.31612902879714966)
[2024-12-17 01:48:45,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:46,127][root][INFO] - Training Epoch: 1/2, step 2354/7134 completed (loss: 3.8678946495056152, acc: 0.3224043846130371)
[2024-12-17 01:48:46,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:46,403][root][INFO] - Training Epoch: 1/2, step 2355/7134 completed (loss: 4.577182292938232, acc: 0.3093922734260559)
[2024-12-17 01:48:46,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:46,671][root][INFO] - Training Epoch: 1/2, step 2356/7134 completed (loss: 5.080789566040039, acc: 0.2246376872062683)
[2024-12-17 01:48:46,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:46,932][root][INFO] - Training Epoch: 1/2, step 2357/7134 completed (loss: 4.471896648406982, acc: 0.2380952388048172)
[2024-12-17 01:48:47,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:47,213][root][INFO] - Training Epoch: 1/2, step 2358/7134 completed (loss: 4.142098903656006, acc: 0.27551019191741943)
[2024-12-17 01:48:47,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:47,487][root][INFO] - Training Epoch: 1/2, step 2359/7134 completed (loss: 3.8634414672851562, acc: 0.375)
[2024-12-17 01:48:47,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:47,772][root][INFO] - Training Epoch: 1/2, step 2360/7134 completed (loss: 3.916127920150757, acc: 0.3291139304637909)
[2024-12-17 01:48:47,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:48,051][root][INFO] - Training Epoch: 1/2, step 2361/7134 completed (loss: 4.035682201385498, acc: 0.255952388048172)
[2024-12-17 01:48:48,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:48,312][root][INFO] - Training Epoch: 1/2, step 2362/7134 completed (loss: 4.1743855476379395, acc: 0.27927929162979126)
[2024-12-17 01:48:48,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:48,620][root][INFO] - Training Epoch: 1/2, step 2363/7134 completed (loss: 4.132192134857178, acc: 0.3036649227142334)
[2024-12-17 01:48:48,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:48,887][root][INFO] - Training Epoch: 1/2, step 2364/7134 completed (loss: 3.986574172973633, acc: 0.2810457646846771)
[2024-12-17 01:48:48,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:49,154][root][INFO] - Training Epoch: 1/2, step 2365/7134 completed (loss: 3.9033682346343994, acc: 0.2732558250427246)
[2024-12-17 01:48:49,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:49,431][root][INFO] - Training Epoch: 1/2, step 2366/7134 completed (loss: 3.580471992492676, acc: 0.3282051384449005)
[2024-12-17 01:48:49,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:49,717][root][INFO] - Training Epoch: 1/2, step 2367/7134 completed (loss: 3.5605881214141846, acc: 0.34343433380126953)
[2024-12-17 01:48:49,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:50,001][root][INFO] - Training Epoch: 1/2, step 2368/7134 completed (loss: 3.898176431655884, acc: 0.2613065242767334)
[2024-12-17 01:48:50,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:50,283][root][INFO] - Training Epoch: 1/2, step 2369/7134 completed (loss: 3.65411376953125, acc: 0.3113207519054413)
[2024-12-17 01:48:50,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:50,524][root][INFO] - Training Epoch: 1/2, step 2370/7134 completed (loss: 3.929170846939087, acc: 0.3199999928474426)
[2024-12-17 01:48:50,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:50,806][root][INFO] - Training Epoch: 1/2, step 2371/7134 completed (loss: 3.9407875537872314, acc: 0.2732919156551361)
[2024-12-17 01:48:50,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:51,079][root][INFO] - Training Epoch: 1/2, step 2372/7134 completed (loss: 3.3658275604248047, acc: 0.3100000023841858)
[2024-12-17 01:48:51,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:51,356][root][INFO] - Training Epoch: 1/2, step 2373/7134 completed (loss: 3.4170587062835693, acc: 0.3108808398246765)
[2024-12-17 01:48:51,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:51,630][root][INFO] - Training Epoch: 1/2, step 2374/7134 completed (loss: 3.8329012393951416, acc: 0.28729280829429626)
[2024-12-17 01:48:51,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:51,913][root][INFO] - Training Epoch: 1/2, step 2375/7134 completed (loss: 4.268259048461914, acc: 0.30909091234207153)
[2024-12-17 01:48:52,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:52,192][root][INFO] - Training Epoch: 1/2, step 2376/7134 completed (loss: 4.491415023803711, acc: 0.22875817120075226)
[2024-12-17 01:48:52,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:52,478][root][INFO] - Training Epoch: 1/2, step 2377/7134 completed (loss: 5.040585041046143, acc: 0.18691588938236237)
[2024-12-17 01:48:52,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:52,761][root][INFO] - Training Epoch: 1/2, step 2378/7134 completed (loss: 4.892661094665527, acc: 0.20792078971862793)
[2024-12-17 01:48:52,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:53,050][root][INFO] - Training Epoch: 1/2, step 2379/7134 completed (loss: 5.095680236816406, acc: 0.1734693944454193)
[2024-12-17 01:48:53,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:53,335][root][INFO] - Training Epoch: 1/2, step 2380/7134 completed (loss: 5.611517906188965, acc: 0.14130434393882751)
[2024-12-17 01:48:53,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:53,585][root][INFO] - Training Epoch: 1/2, step 2381/7134 completed (loss: 5.344679832458496, acc: 0.20496894419193268)
[2024-12-17 01:48:53,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:53,850][root][INFO] - Training Epoch: 1/2, step 2382/7134 completed (loss: 4.6357245445251465, acc: 0.1913580298423767)
[2024-12-17 01:48:53,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:54,115][root][INFO] - Training Epoch: 1/2, step 2383/7134 completed (loss: 4.648240566253662, acc: 0.22404371201992035)
[2024-12-17 01:48:54,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:54,389][root][INFO] - Training Epoch: 1/2, step 2384/7134 completed (loss: 5.401356220245361, acc: 0.16091954708099365)
[2024-12-17 01:48:54,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:54,668][root][INFO] - Training Epoch: 1/2, step 2385/7134 completed (loss: 4.762094020843506, acc: 0.21978022158145905)
[2024-12-17 01:48:54,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:54,938][root][INFO] - Training Epoch: 1/2, step 2386/7134 completed (loss: 4.861115455627441, acc: 0.24867725372314453)
[2024-12-17 01:48:55,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:55,225][root][INFO] - Training Epoch: 1/2, step 2387/7134 completed (loss: 4.836743354797363, acc: 0.19523809850215912)
[2024-12-17 01:48:55,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:55,503][root][INFO] - Training Epoch: 1/2, step 2388/7134 completed (loss: 4.576244831085205, acc: 0.23076923191547394)
[2024-12-17 01:48:55,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:55,830][root][INFO] - Training Epoch: 1/2, step 2389/7134 completed (loss: 4.834323406219482, acc: 0.1990521401166916)
[2024-12-17 01:48:55,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:56,115][root][INFO] - Training Epoch: 1/2, step 2390/7134 completed (loss: 5.030208587646484, acc: 0.20853079855442047)
[2024-12-17 01:48:56,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:56,380][root][INFO] - Training Epoch: 1/2, step 2391/7134 completed (loss: 5.1341776847839355, acc: 0.16756756603717804)
[2024-12-17 01:48:56,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:56,654][root][INFO] - Training Epoch: 1/2, step 2392/7134 completed (loss: 4.887787342071533, acc: 0.2295081913471222)
[2024-12-17 01:48:56,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:56,925][root][INFO] - Training Epoch: 1/2, step 2393/7134 completed (loss: 4.858433246612549, acc: 0.2227979302406311)
[2024-12-17 01:48:57,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:57,211][root][INFO] - Training Epoch: 1/2, step 2394/7134 completed (loss: 5.002974033355713, acc: 0.19387754797935486)
[2024-12-17 01:48:57,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:57,490][root][INFO] - Training Epoch: 1/2, step 2395/7134 completed (loss: 4.825660705566406, acc: 0.20571428537368774)
[2024-12-17 01:48:57,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:57,788][root][INFO] - Training Epoch: 1/2, step 2396/7134 completed (loss: 5.173661231994629, acc: 0.2070707082748413)
[2024-12-17 01:48:57,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:58,066][root][INFO] - Training Epoch: 1/2, step 2397/7134 completed (loss: 4.999917030334473, acc: 0.2195121943950653)
[2024-12-17 01:48:58,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:58,360][root][INFO] - Training Epoch: 1/2, step 2398/7134 completed (loss: 4.589768886566162, acc: 0.22162161767482758)
[2024-12-17 01:48:58,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:58,651][root][INFO] - Training Epoch: 1/2, step 2399/7134 completed (loss: 5.142868995666504, acc: 0.20725388824939728)
[2024-12-17 01:48:58,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:58,968][root][INFO] - Training Epoch: 1/2, step 2400/7134 completed (loss: 4.887746334075928, acc: 0.2010050266981125)
[2024-12-17 01:48:59,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:59,271][root][INFO] - Training Epoch: 1/2, step 2401/7134 completed (loss: 5.572738170623779, acc: 0.18269230425357819)
[2024-12-17 01:48:59,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:59,575][root][INFO] - Training Epoch: 1/2, step 2402/7134 completed (loss: 5.3856964111328125, acc: 0.15458936989307404)
[2024-12-17 01:48:59,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:59,873][root][INFO] - Training Epoch: 1/2, step 2403/7134 completed (loss: 4.683376789093018, acc: 0.19760479032993317)
[2024-12-17 01:48:59,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:00,169][root][INFO] - Training Epoch: 1/2, step 2404/7134 completed (loss: 4.275996208190918, acc: 0.28289473056793213)
[2024-12-17 01:49:00,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:00,429][root][INFO] - Training Epoch: 1/2, step 2405/7134 completed (loss: 4.285217761993408, acc: 0.2802547812461853)
[2024-12-17 01:49:00,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:00,702][root][INFO] - Training Epoch: 1/2, step 2406/7134 completed (loss: 4.216711044311523, acc: 0.2248520702123642)
[2024-12-17 01:49:00,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:00,977][root][INFO] - Training Epoch: 1/2, step 2407/7134 completed (loss: 4.109485149383545, acc: 0.3202614486217499)
[2024-12-17 01:49:01,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:01,251][root][INFO] - Training Epoch: 1/2, step 2408/7134 completed (loss: 3.764899969100952, acc: 0.28729280829429626)
[2024-12-17 01:49:01,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:01,519][root][INFO] - Training Epoch: 1/2, step 2409/7134 completed (loss: 4.331016540527344, acc: 0.2874999940395355)
[2024-12-17 01:49:01,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:01,778][root][INFO] - Training Epoch: 1/2, step 2410/7134 completed (loss: 4.721179962158203, acc: 0.22535210847854614)
[2024-12-17 01:49:01,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:02,048][root][INFO] - Training Epoch: 1/2, step 2411/7134 completed (loss: 4.049122333526611, acc: 0.23204420506954193)
[2024-12-17 01:49:02,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:02,315][root][INFO] - Training Epoch: 1/2, step 2412/7134 completed (loss: 4.067959308624268, acc: 0.28977271914482117)
[2024-12-17 01:49:02,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:02,587][root][INFO] - Training Epoch: 1/2, step 2413/7134 completed (loss: 4.464705944061279, acc: 0.27272728085517883)
[2024-12-17 01:49:02,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:02,866][root][INFO] - Training Epoch: 1/2, step 2414/7134 completed (loss: 4.216722011566162, acc: 0.2677595615386963)
[2024-12-17 01:49:02,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:03,150][root][INFO] - Training Epoch: 1/2, step 2415/7134 completed (loss: 4.892439365386963, acc: 0.22560974955558777)
[2024-12-17 01:49:03,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:03,419][root][INFO] - Training Epoch: 1/2, step 2416/7134 completed (loss: 4.723402500152588, acc: 0.23270440101623535)
[2024-12-17 01:49:03,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:03,716][root][INFO] - Training Epoch: 1/2, step 2417/7134 completed (loss: 3.9901881217956543, acc: 0.3365853726863861)
[2024-12-17 01:49:03,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:03,969][root][INFO] - Training Epoch: 1/2, step 2418/7134 completed (loss: 4.652174949645996, acc: 0.21678321063518524)
[2024-12-17 01:49:04,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:04,236][root][INFO] - Training Epoch: 1/2, step 2419/7134 completed (loss: 4.479259014129639, acc: 0.20245398581027985)
[2024-12-17 01:49:04,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:04,532][root][INFO] - Training Epoch: 1/2, step 2420/7134 completed (loss: 3.9775381088256836, acc: 0.2777777910232544)
[2024-12-17 01:49:04,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:04,825][root][INFO] - Training Epoch: 1/2, step 2421/7134 completed (loss: 4.067034721374512, acc: 0.3405405282974243)
[2024-12-17 01:49:04,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:05,145][root][INFO] - Training Epoch: 1/2, step 2422/7134 completed (loss: 4.269987106323242, acc: 0.20000000298023224)
[2024-12-17 01:49:05,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:05,408][root][INFO] - Training Epoch: 1/2, step 2423/7134 completed (loss: 3.578437328338623, acc: 0.3452380895614624)
[2024-12-17 01:49:05,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:05,682][root][INFO] - Training Epoch: 1/2, step 2424/7134 completed (loss: 4.171616554260254, acc: 0.2670454680919647)
[2024-12-17 01:49:05,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:05,960][root][INFO] - Training Epoch: 1/2, step 2425/7134 completed (loss: 3.974714994430542, acc: 0.33707866072654724)
[2024-12-17 01:49:06,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:06,250][root][INFO] - Training Epoch: 1/2, step 2426/7134 completed (loss: 4.239278793334961, acc: 0.2586206793785095)
[2024-12-17 01:49:06,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:06,525][root][INFO] - Training Epoch: 1/2, step 2427/7134 completed (loss: 3.583430051803589, acc: 0.359375)
[2024-12-17 01:49:06,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:06,819][root][INFO] - Training Epoch: 1/2, step 2428/7134 completed (loss: 3.86218523979187, acc: 0.2947368323802948)
[2024-12-17 01:49:06,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:07,096][root][INFO] - Training Epoch: 1/2, step 2429/7134 completed (loss: 4.009673118591309, acc: 0.2848101258277893)
[2024-12-17 01:49:07,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:07,361][root][INFO] - Training Epoch: 1/2, step 2430/7134 completed (loss: 3.8280484676361084, acc: 0.273333340883255)
[2024-12-17 01:49:07,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:07,635][root][INFO] - Training Epoch: 1/2, step 2431/7134 completed (loss: 3.6160969734191895, acc: 0.3636363744735718)
[2024-12-17 01:49:07,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:07,908][root][INFO] - Training Epoch: 1/2, step 2432/7134 completed (loss: 4.092592239379883, acc: 0.28099173307418823)
[2024-12-17 01:49:08,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:08,182][root][INFO] - Training Epoch: 1/2, step 2433/7134 completed (loss: 3.940828323364258, acc: 0.2733812928199768)
[2024-12-17 01:49:08,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:08,445][root][INFO] - Training Epoch: 1/2, step 2434/7134 completed (loss: 3.994692325592041, acc: 0.3288590610027313)
[2024-12-17 01:49:08,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:08,726][root][INFO] - Training Epoch: 1/2, step 2435/7134 completed (loss: 4.047745704650879, acc: 0.33774834871292114)
[2024-12-17 01:49:08,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:08,993][root][INFO] - Training Epoch: 1/2, step 2436/7134 completed (loss: 3.3223555088043213, acc: 0.39086294174194336)
[2024-12-17 01:49:09,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:09,257][root][INFO] - Training Epoch: 1/2, step 2437/7134 completed (loss: 3.705559015274048, acc: 0.38732394576072693)
[2024-12-17 01:49:09,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:09,533][root][INFO] - Training Epoch: 1/2, step 2438/7134 completed (loss: 3.6284518241882324, acc: 0.35185185074806213)
[2024-12-17 01:49:09,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:09,808][root][INFO] - Training Epoch: 1/2, step 2439/7134 completed (loss: 3.758892297744751, acc: 0.33155080676078796)
[2024-12-17 01:49:09,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:10,064][root][INFO] - Training Epoch: 1/2, step 2440/7134 completed (loss: 4.57411527633667, acc: 0.25)
[2024-12-17 01:49:10,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:10,322][root][INFO] - Training Epoch: 1/2, step 2441/7134 completed (loss: 4.560347557067871, acc: 0.30399999022483826)
[2024-12-17 01:49:10,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:10,591][root][INFO] - Training Epoch: 1/2, step 2442/7134 completed (loss: 3.9091832637786865, acc: 0.3550295829772949)
[2024-12-17 01:49:10,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:10,861][root][INFO] - Training Epoch: 1/2, step 2443/7134 completed (loss: 4.20667028427124, acc: 0.25153374671936035)
[2024-12-17 01:49:10,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:11,130][root][INFO] - Training Epoch: 1/2, step 2444/7134 completed (loss: 3.7722222805023193, acc: 0.3488371968269348)
[2024-12-17 01:49:11,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:11,404][root][INFO] - Training Epoch: 1/2, step 2445/7134 completed (loss: 4.086948871612549, acc: 0.2866241931915283)
[2024-12-17 01:49:11,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:11,696][root][INFO] - Training Epoch: 1/2, step 2446/7134 completed (loss: 4.2744669914245605, acc: 0.25974026322364807)
[2024-12-17 01:49:11,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:11,979][root][INFO] - Training Epoch: 1/2, step 2447/7134 completed (loss: 4.119593143463135, acc: 0.25280898809432983)
[2024-12-17 01:49:12,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:12,248][root][INFO] - Training Epoch: 1/2, step 2448/7134 completed (loss: 3.735826015472412, acc: 0.3691275119781494)
[2024-12-17 01:49:12,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:12,505][root][INFO] - Training Epoch: 1/2, step 2449/7134 completed (loss: 4.2931647300720215, acc: 0.302325576543808)
[2024-12-17 01:49:12,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:12,787][root][INFO] - Training Epoch: 1/2, step 2450/7134 completed (loss: 3.9768457412719727, acc: 0.3117647171020508)
[2024-12-17 01:49:12,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:13,062][root][INFO] - Training Epoch: 1/2, step 2451/7134 completed (loss: 3.9822142124176025, acc: 0.26737967133522034)
[2024-12-17 01:49:13,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:13,341][root][INFO] - Training Epoch: 1/2, step 2452/7134 completed (loss: 4.133186340332031, acc: 0.2688172161579132)
[2024-12-17 01:49:13,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:13,635][root][INFO] - Training Epoch: 1/2, step 2453/7134 completed (loss: 4.108863353729248, acc: 0.29015544056892395)
[2024-12-17 01:49:13,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:13,908][root][INFO] - Training Epoch: 1/2, step 2454/7134 completed (loss: 4.334113597869873, acc: 0.21985815465450287)
[2024-12-17 01:49:14,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:14,204][root][INFO] - Training Epoch: 1/2, step 2455/7134 completed (loss: 4.254192352294922, acc: 0.2699386477470398)
[2024-12-17 01:49:14,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:14,467][root][INFO] - Training Epoch: 1/2, step 2456/7134 completed (loss: 3.9058263301849365, acc: 0.2694300413131714)
[2024-12-17 01:49:14,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:14,756][root][INFO] - Training Epoch: 1/2, step 2457/7134 completed (loss: 4.077047348022461, acc: 0.2549019753932953)
[2024-12-17 01:49:14,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:15,032][root][INFO] - Training Epoch: 1/2, step 2458/7134 completed (loss: 4.440925598144531, acc: 0.23125000298023224)
[2024-12-17 01:49:15,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:15,316][root][INFO] - Training Epoch: 1/2, step 2459/7134 completed (loss: 4.14695405960083, acc: 0.2573099434375763)
[2024-12-17 01:49:15,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:15,603][root][INFO] - Training Epoch: 1/2, step 2460/7134 completed (loss: 3.651270627975464, acc: 0.34065935015678406)
[2024-12-17 01:49:15,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:15,891][root][INFO] - Training Epoch: 1/2, step 2461/7134 completed (loss: 3.6390111446380615, acc: 0.30817610025405884)
[2024-12-17 01:49:16,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:16,186][root][INFO] - Training Epoch: 1/2, step 2462/7134 completed (loss: 3.83864164352417, acc: 0.31515151262283325)
[2024-12-17 01:49:16,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:16,489][root][INFO] - Training Epoch: 1/2, step 2463/7134 completed (loss: 3.420830249786377, acc: 0.3187499940395355)
[2024-12-17 01:49:16,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:16,778][root][INFO] - Training Epoch: 1/2, step 2464/7134 completed (loss: 3.9997713565826416, acc: 0.30000001192092896)
[2024-12-17 01:49:16,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:17,078][root][INFO] - Training Epoch: 1/2, step 2465/7134 completed (loss: 3.838160753250122, acc: 0.3016759753227234)
[2024-12-17 01:49:17,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:17,382][root][INFO] - Training Epoch: 1/2, step 2466/7134 completed (loss: 4.073400974273682, acc: 0.2514970004558563)
[2024-12-17 01:49:17,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:17,682][root][INFO] - Training Epoch: 1/2, step 2467/7134 completed (loss: 4.279934883117676, acc: 0.28651684522628784)
[2024-12-17 01:49:17,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:17,980][root][INFO] - Training Epoch: 1/2, step 2468/7134 completed (loss: 3.697923183441162, acc: 0.26744186878204346)
[2024-12-17 01:49:18,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:18,282][root][INFO] - Training Epoch: 1/2, step 2469/7134 completed (loss: 3.586866855621338, acc: 0.33139535784721375)
[2024-12-17 01:49:18,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:18,560][root][INFO] - Training Epoch: 1/2, step 2470/7134 completed (loss: 3.87274432182312, acc: 0.2978723347187042)
[2024-12-17 01:49:18,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:18,829][root][INFO] - Training Epoch: 1/2, step 2471/7134 completed (loss: 3.7866556644439697, acc: 0.29078012704849243)
[2024-12-17 01:49:18,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:19,089][root][INFO] - Training Epoch: 1/2, step 2472/7134 completed (loss: 3.624215602874756, acc: 0.31081080436706543)
[2024-12-17 01:49:19,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:19,365][root][INFO] - Training Epoch: 1/2, step 2473/7134 completed (loss: 4.265037536621094, acc: 0.2897196114063263)
[2024-12-17 01:49:19,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:19,642][root][INFO] - Training Epoch: 1/2, step 2474/7134 completed (loss: 3.8666012287139893, acc: 0.260606050491333)
[2024-12-17 01:49:19,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:19,897][root][INFO] - Training Epoch: 1/2, step 2475/7134 completed (loss: 3.521028995513916, acc: 0.3360655605792999)
[2024-12-17 01:49:20,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:20,181][root][INFO] - Training Epoch: 1/2, step 2476/7134 completed (loss: 4.081407070159912, acc: 0.2514619827270508)
[2024-12-17 01:49:20,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:20,452][root][INFO] - Training Epoch: 1/2, step 2477/7134 completed (loss: 3.450815200805664, acc: 0.31481480598449707)
[2024-12-17 01:49:20,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:20,721][root][INFO] - Training Epoch: 1/2, step 2478/7134 completed (loss: 3.6193723678588867, acc: 0.30201342701911926)
[2024-12-17 01:49:20,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:21,016][root][INFO] - Training Epoch: 1/2, step 2479/7134 completed (loss: 4.363723278045654, acc: 0.30612245202064514)
[2024-12-17 01:49:21,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:21,278][root][INFO] - Training Epoch: 1/2, step 2480/7134 completed (loss: 3.244567632675171, acc: 0.38461539149284363)
[2024-12-17 01:49:21,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:21,553][root][INFO] - Training Epoch: 1/2, step 2481/7134 completed (loss: 3.7178306579589844, acc: 0.3076923191547394)
[2024-12-17 01:49:21,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:21,831][root][INFO] - Training Epoch: 1/2, step 2482/7134 completed (loss: 4.027562618255615, acc: 0.27272728085517883)
[2024-12-17 01:49:21,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:22,113][root][INFO] - Training Epoch: 1/2, step 2483/7134 completed (loss: 3.6038193702697754, acc: 0.2934131622314453)
[2024-12-17 01:49:22,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:22,389][root][INFO] - Training Epoch: 1/2, step 2484/7134 completed (loss: 3.6753334999084473, acc: 0.3192771077156067)
[2024-12-17 01:49:22,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:22,659][root][INFO] - Training Epoch: 1/2, step 2485/7134 completed (loss: 3.470561981201172, acc: 0.3333333432674408)
[2024-12-17 01:49:22,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:22,934][root][INFO] - Training Epoch: 1/2, step 2486/7134 completed (loss: 3.8101413249969482, acc: 0.2602739632129669)
[2024-12-17 01:49:23,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:23,194][root][INFO] - Training Epoch: 1/2, step 2487/7134 completed (loss: 3.894543170928955, acc: 0.3263888955116272)
[2024-12-17 01:49:23,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:23,467][root][INFO] - Training Epoch: 1/2, step 2488/7134 completed (loss: 4.011333465576172, acc: 0.2666666805744171)
[2024-12-17 01:49:23,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:23,733][root][INFO] - Training Epoch: 1/2, step 2489/7134 completed (loss: 3.450139045715332, acc: 0.30177515745162964)
[2024-12-17 01:49:23,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:24,008][root][INFO] - Training Epoch: 1/2, step 2490/7134 completed (loss: 3.9808766841888428, acc: 0.29870128631591797)
[2024-12-17 01:49:24,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:24,268][root][INFO] - Training Epoch: 1/2, step 2491/7134 completed (loss: 3.574476718902588, acc: 0.38805970549583435)
[2024-12-17 01:49:24,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:24,523][root][INFO] - Training Epoch: 1/2, step 2492/7134 completed (loss: 3.490910768508911, acc: 0.36477985978126526)
[2024-12-17 01:49:24,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:24,800][root][INFO] - Training Epoch: 1/2, step 2493/7134 completed (loss: 4.036510467529297, acc: 0.3035714328289032)
[2024-12-17 01:49:24,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:25,088][root][INFO] - Training Epoch: 1/2, step 2494/7134 completed (loss: 3.7036261558532715, acc: 0.29012346267700195)
[2024-12-17 01:49:25,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:25,372][root][INFO] - Training Epoch: 1/2, step 2495/7134 completed (loss: 3.817356586456299, acc: 0.364705890417099)
[2024-12-17 01:49:25,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:25,645][root][INFO] - Training Epoch: 1/2, step 2496/7134 completed (loss: 3.843768835067749, acc: 0.297468364238739)
[2024-12-17 01:49:25,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:25,920][root][INFO] - Training Epoch: 1/2, step 2497/7134 completed (loss: 3.788893699645996, acc: 0.3103448152542114)
[2024-12-17 01:49:26,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:26,204][root][INFO] - Training Epoch: 1/2, step 2498/7134 completed (loss: 3.857468605041504, acc: 0.2971428632736206)
[2024-12-17 01:49:26,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:26,482][root][INFO] - Training Epoch: 1/2, step 2499/7134 completed (loss: 3.758674383163452, acc: 0.3734939694404602)
[2024-12-17 01:49:26,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:26,752][root][INFO] - Training Epoch: 1/2, step 2500/7134 completed (loss: 3.884289264678955, acc: 0.2702702581882477)
[2024-12-17 01:49:26,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:27,023][root][INFO] - Training Epoch: 1/2, step 2501/7134 completed (loss: 4.0253496170043945, acc: 0.30337077379226685)
[2024-12-17 01:49:27,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:27,337][root][INFO] - Training Epoch: 1/2, step 2502/7134 completed (loss: 3.455817699432373, acc: 0.38461539149284363)
[2024-12-17 01:49:27,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:27,628][root][INFO] - Training Epoch: 1/2, step 2503/7134 completed (loss: 3.7276062965393066, acc: 0.3333333432674408)
[2024-12-17 01:49:27,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:27,923][root][INFO] - Training Epoch: 1/2, step 2504/7134 completed (loss: 3.6891796588897705, acc: 0.3670886158943176)
[2024-12-17 01:49:28,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:28,218][root][INFO] - Training Epoch: 1/2, step 2505/7134 completed (loss: 3.7819314002990723, acc: 0.29651162028312683)
[2024-12-17 01:49:28,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:28,529][root][INFO] - Training Epoch: 1/2, step 2506/7134 completed (loss: 4.084626197814941, acc: 0.3196721374988556)
[2024-12-17 01:49:28,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:28,818][root][INFO] - Training Epoch: 1/2, step 2507/7134 completed (loss: 2.934281826019287, acc: 0.4000000059604645)
[2024-12-17 01:49:28,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:29,103][root][INFO] - Training Epoch: 1/2, step 2508/7134 completed (loss: 3.4129157066345215, acc: 0.3672316372394562)
[2024-12-17 01:49:29,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:29,371][root][INFO] - Training Epoch: 1/2, step 2509/7134 completed (loss: 3.2341811656951904, acc: 0.4000000059604645)
[2024-12-17 01:49:29,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:29,644][root][INFO] - Training Epoch: 1/2, step 2510/7134 completed (loss: 2.9826769828796387, acc: 0.44285714626312256)
[2024-12-17 01:49:29,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:29,916][root][INFO] - Training Epoch: 1/2, step 2511/7134 completed (loss: 3.6950106620788574, acc: 0.3606557250022888)
[2024-12-17 01:49:30,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:30,188][root][INFO] - Training Epoch: 1/2, step 2512/7134 completed (loss: 3.7205440998077393, acc: 0.29411765933036804)
[2024-12-17 01:49:30,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:30,469][root][INFO] - Training Epoch: 1/2, step 2513/7134 completed (loss: 3.2362420558929443, acc: 0.3817204236984253)
[2024-12-17 01:49:30,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:30,788][root][INFO] - Training Epoch: 1/2, step 2514/7134 completed (loss: 3.4601476192474365, acc: 0.3949044644832611)
[2024-12-17 01:49:30,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:31,071][root][INFO] - Training Epoch: 1/2, step 2515/7134 completed (loss: 3.5450539588928223, acc: 0.33766233921051025)
[2024-12-17 01:49:31,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:31,387][root][INFO] - Training Epoch: 1/2, step 2516/7134 completed (loss: 3.4437060356140137, acc: 0.35754188895225525)
[2024-12-17 01:49:31,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:31,670][root][INFO] - Training Epoch: 1/2, step 2517/7134 completed (loss: 3.167891502380371, acc: 0.4277777671813965)
[2024-12-17 01:49:31,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:31,957][root][INFO] - Training Epoch: 1/2, step 2518/7134 completed (loss: 3.8617441654205322, acc: 0.3137255012989044)
[2024-12-17 01:49:32,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:32,244][root][INFO] - Training Epoch: 1/2, step 2519/7134 completed (loss: 3.631251096725464, acc: 0.3032258152961731)
[2024-12-17 01:49:32,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:32,524][root][INFO] - Training Epoch: 1/2, step 2520/7134 completed (loss: 4.403221607208252, acc: 0.2368421107530594)
[2024-12-17 01:49:32,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:32,823][root][INFO] - Training Epoch: 1/2, step 2521/7134 completed (loss: 3.853466272354126, acc: 0.35164836049079895)
[2024-12-17 01:49:32,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:33,133][root][INFO] - Training Epoch: 1/2, step 2522/7134 completed (loss: 4.179819583892822, acc: 0.24827586114406586)
[2024-12-17 01:49:33,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:33,435][root][INFO] - Training Epoch: 1/2, step 2523/7134 completed (loss: 3.9652717113494873, acc: 0.2760736048221588)
[2024-12-17 01:49:33,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:33,728][root][INFO] - Training Epoch: 1/2, step 2524/7134 completed (loss: 4.095304489135742, acc: 0.29878050088882446)
[2024-12-17 01:49:33,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:34,022][root][INFO] - Training Epoch: 1/2, step 2525/7134 completed (loss: 4.245737552642822, acc: 0.232876718044281)
[2024-12-17 01:49:34,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:34,301][root][INFO] - Training Epoch: 1/2, step 2526/7134 completed (loss: 3.857631206512451, acc: 0.24242424964904785)
[2024-12-17 01:49:34,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:34,587][root][INFO] - Training Epoch: 1/2, step 2527/7134 completed (loss: 3.999600887298584, acc: 0.3169398903846741)
[2024-12-17 01:49:34,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:34,870][root][INFO] - Training Epoch: 1/2, step 2528/7134 completed (loss: 3.92724347114563, acc: 0.28915661573410034)
[2024-12-17 01:49:34,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:35,159][root][INFO] - Training Epoch: 1/2, step 2529/7134 completed (loss: 4.054746627807617, acc: 0.2202380895614624)
[2024-12-17 01:49:35,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:35,448][root][INFO] - Training Epoch: 1/2, step 2530/7134 completed (loss: 3.8231029510498047, acc: 0.2808988690376282)
[2024-12-17 01:49:35,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:35,719][root][INFO] - Training Epoch: 1/2, step 2531/7134 completed (loss: 3.913736343383789, acc: 0.28313252329826355)
[2024-12-17 01:49:35,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:35,990][root][INFO] - Training Epoch: 1/2, step 2532/7134 completed (loss: 4.05743932723999, acc: 0.25333333015441895)
[2024-12-17 01:49:36,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:36,262][root][INFO] - Training Epoch: 1/2, step 2533/7134 completed (loss: 4.489365577697754, acc: 0.29487180709838867)
[2024-12-17 01:49:36,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:36,537][root][INFO] - Training Epoch: 1/2, step 2534/7134 completed (loss: 3.631699800491333, acc: 0.25139665603637695)
[2024-12-17 01:49:36,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:36,817][root][INFO] - Training Epoch: 1/2, step 2535/7134 completed (loss: 3.6684412956237793, acc: 0.32203391194343567)
[2024-12-17 01:49:36,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:37,103][root][INFO] - Training Epoch: 1/2, step 2536/7134 completed (loss: 3.8151912689208984, acc: 0.3056994676589966)
[2024-12-17 01:49:37,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:37,370][root][INFO] - Training Epoch: 1/2, step 2537/7134 completed (loss: 4.216355323791504, acc: 0.25342464447021484)
[2024-12-17 01:49:37,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:37,672][root][INFO] - Training Epoch: 1/2, step 2538/7134 completed (loss: 4.190044403076172, acc: 0.3103448152542114)
[2024-12-17 01:49:37,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:37,976][root][INFO] - Training Epoch: 1/2, step 2539/7134 completed (loss: 4.009578704833984, acc: 0.27819550037384033)
[2024-12-17 01:49:38,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:38,277][root][INFO] - Training Epoch: 1/2, step 2540/7134 completed (loss: 4.059567928314209, acc: 0.2450331151485443)
[2024-12-17 01:49:38,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:38,565][root][INFO] - Training Epoch: 1/2, step 2541/7134 completed (loss: 4.163716793060303, acc: 0.33088234066963196)
[2024-12-17 01:49:38,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:38,831][root][INFO] - Training Epoch: 1/2, step 2542/7134 completed (loss: 3.777278423309326, acc: 0.28125)
[2024-12-17 01:49:38,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:39,145][root][INFO] - Training Epoch: 1/2, step 2543/7134 completed (loss: 4.498837947845459, acc: 0.22641509771347046)
[2024-12-17 01:49:39,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:39,425][root][INFO] - Training Epoch: 1/2, step 2544/7134 completed (loss: 3.982464075088501, acc: 0.3214285671710968)
[2024-12-17 01:49:39,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:39,712][root][INFO] - Training Epoch: 1/2, step 2545/7134 completed (loss: 3.9892704486846924, acc: 0.2537313401699066)
[2024-12-17 01:49:39,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:40,034][root][INFO] - Training Epoch: 1/2, step 2546/7134 completed (loss: 3.9089794158935547, acc: 0.2806122303009033)
[2024-12-17 01:49:40,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:40,310][root][INFO] - Training Epoch: 1/2, step 2547/7134 completed (loss: 3.7009763717651367, acc: 0.36690646409988403)
[2024-12-17 01:49:40,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:40,574][root][INFO] - Training Epoch: 1/2, step 2548/7134 completed (loss: 3.479203462600708, acc: 0.29203540086746216)
[2024-12-17 01:49:40,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:40,841][root][INFO] - Training Epoch: 1/2, step 2549/7134 completed (loss: 3.5405259132385254, acc: 0.30894309282302856)
[2024-12-17 01:49:40,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:41,127][root][INFO] - Training Epoch: 1/2, step 2550/7134 completed (loss: 3.4711341857910156, acc: 0.30821916460990906)
[2024-12-17 01:49:41,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:41,409][root][INFO] - Training Epoch: 1/2, step 2551/7134 completed (loss: 3.8439042568206787, acc: 0.3333333432674408)
[2024-12-17 01:49:41,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:41,688][root][INFO] - Training Epoch: 1/2, step 2552/7134 completed (loss: 3.417689085006714, acc: 0.3544303774833679)
[2024-12-17 01:49:41,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:41,962][root][INFO] - Training Epoch: 1/2, step 2553/7134 completed (loss: 4.083101749420166, acc: 0.2368421107530594)
[2024-12-17 01:49:42,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:42,252][root][INFO] - Training Epoch: 1/2, step 2554/7134 completed (loss: 4.028384208679199, acc: 0.30708661675453186)
[2024-12-17 01:49:42,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:42,528][root][INFO] - Training Epoch: 1/2, step 2555/7134 completed (loss: 4.04233980178833, acc: 0.2702702581882477)
[2024-12-17 01:49:42,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:42,811][root][INFO] - Training Epoch: 1/2, step 2556/7134 completed (loss: 3.88295316696167, acc: 0.27000001072883606)
[2024-12-17 01:49:42,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:43,102][root][INFO] - Training Epoch: 1/2, step 2557/7134 completed (loss: 3.8189427852630615, acc: 0.26530611515045166)
[2024-12-17 01:49:43,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:43,371][root][INFO] - Training Epoch: 1/2, step 2558/7134 completed (loss: 3.760101079940796, acc: 0.2846715450286865)
[2024-12-17 01:49:43,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:43,657][root][INFO] - Training Epoch: 1/2, step 2559/7134 completed (loss: 3.8619697093963623, acc: 0.25)
[2024-12-17 01:49:43,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:43,949][root][INFO] - Training Epoch: 1/2, step 2560/7134 completed (loss: 3.7513129711151123, acc: 0.27702704071998596)
[2024-12-17 01:49:44,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:44,221][root][INFO] - Training Epoch: 1/2, step 2561/7134 completed (loss: 4.04186487197876, acc: 0.2083333283662796)
[2024-12-17 01:49:44,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:44,505][root][INFO] - Training Epoch: 1/2, step 2562/7134 completed (loss: 3.712221145629883, acc: 0.2639999985694885)
[2024-12-17 01:49:44,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:44,790][root][INFO] - Training Epoch: 1/2, step 2563/7134 completed (loss: 3.7066032886505127, acc: 0.26035502552986145)
[2024-12-17 01:49:44,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:45,070][root][INFO] - Training Epoch: 1/2, step 2564/7134 completed (loss: 3.6447412967681885, acc: 0.28057554364204407)
[2024-12-17 01:49:45,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:45,361][root][INFO] - Training Epoch: 1/2, step 2565/7134 completed (loss: 3.962045907974243, acc: 0.30215826630592346)
[2024-12-17 01:49:45,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:45,669][root][INFO] - Training Epoch: 1/2, step 2566/7134 completed (loss: 3.8130710124969482, acc: 0.28915661573410034)
[2024-12-17 01:49:45,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:45,923][root][INFO] - Training Epoch: 1/2, step 2567/7134 completed (loss: 3.880824565887451, acc: 0.25563910603523254)
[2024-12-17 01:49:46,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:46,193][root][INFO] - Training Epoch: 1/2, step 2568/7134 completed (loss: 3.887261390686035, acc: 0.31410256028175354)
[2024-12-17 01:49:46,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:46,476][root][INFO] - Training Epoch: 1/2, step 2569/7134 completed (loss: 3.9260435104370117, acc: 0.28169015049934387)
[2024-12-17 01:49:46,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:46,754][root][INFO] - Training Epoch: 1/2, step 2570/7134 completed (loss: 3.687278985977173, acc: 0.3642384111881256)
[2024-12-17 01:49:46,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:47,019][root][INFO] - Training Epoch: 1/2, step 2571/7134 completed (loss: 4.018341541290283, acc: 0.24590164422988892)
[2024-12-17 01:49:47,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:47,301][root][INFO] - Training Epoch: 1/2, step 2572/7134 completed (loss: 3.762709379196167, acc: 0.31972789764404297)
[2024-12-17 01:49:47,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:47,582][root][INFO] - Training Epoch: 1/2, step 2573/7134 completed (loss: 3.43143892288208, acc: 0.32374101877212524)
[2024-12-17 01:49:47,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:47,835][root][INFO] - Training Epoch: 1/2, step 2574/7134 completed (loss: 3.844851016998291, acc: 0.1818181872367859)
[2024-12-17 01:49:47,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:48,098][root][INFO] - Training Epoch: 1/2, step 2575/7134 completed (loss: 3.819166898727417, acc: 0.2950819730758667)
[2024-12-17 01:49:48,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:48,374][root][INFO] - Training Epoch: 1/2, step 2576/7134 completed (loss: 3.803274393081665, acc: 0.31707316637039185)
[2024-12-17 01:49:48,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:48,647][root][INFO] - Training Epoch: 1/2, step 2577/7134 completed (loss: 4.092491149902344, acc: 0.29133859276771545)
[2024-12-17 01:49:48,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:48,945][root][INFO] - Training Epoch: 1/2, step 2578/7134 completed (loss: 4.423058032989502, acc: 0.2810457646846771)
[2024-12-17 01:49:49,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:49,225][root][INFO] - Training Epoch: 1/2, step 2579/7134 completed (loss: 4.43124532699585, acc: 0.2628205120563507)
[2024-12-17 01:49:49,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:49,509][root][INFO] - Training Epoch: 1/2, step 2580/7134 completed (loss: 4.528079032897949, acc: 0.2543352544307709)
[2024-12-17 01:49:49,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:49,779][root][INFO] - Training Epoch: 1/2, step 2581/7134 completed (loss: 4.48980188369751, acc: 0.3050847351551056)
[2024-12-17 01:49:49,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:50,064][root][INFO] - Training Epoch: 1/2, step 2582/7134 completed (loss: 4.3092756271362305, acc: 0.3050847351551056)
[2024-12-17 01:49:50,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:50,330][root][INFO] - Training Epoch: 1/2, step 2583/7134 completed (loss: 4.697266578674316, acc: 0.24137930572032928)
[2024-12-17 01:49:50,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:50,580][root][INFO] - Training Epoch: 1/2, step 2584/7134 completed (loss: 4.347257137298584, acc: 0.26950353384017944)
[2024-12-17 01:49:50,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:50,866][root][INFO] - Training Epoch: 1/2, step 2585/7134 completed (loss: 4.269405364990234, acc: 0.2781457006931305)
[2024-12-17 01:49:50,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:51,140][root][INFO] - Training Epoch: 1/2, step 2586/7134 completed (loss: 3.9970755577087402, acc: 0.2846153974533081)
[2024-12-17 01:49:51,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:51,417][root][INFO] - Training Epoch: 1/2, step 2587/7134 completed (loss: 4.233532428741455, acc: 0.3062500059604645)
[2024-12-17 01:49:51,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:51,711][root][INFO] - Training Epoch: 1/2, step 2588/7134 completed (loss: 4.045148849487305, acc: 0.25850340723991394)
[2024-12-17 01:49:51,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:51,994][root][INFO] - Training Epoch: 1/2, step 2589/7134 completed (loss: 4.563987731933594, acc: 0.2539682686328888)
[2024-12-17 01:49:52,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:52,282][root][INFO] - Training Epoch: 1/2, step 2590/7134 completed (loss: 4.308017253875732, acc: 0.27407407760620117)
[2024-12-17 01:49:52,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:52,577][root][INFO] - Training Epoch: 1/2, step 2591/7134 completed (loss: 4.824392318725586, acc: 0.30994153022766113)
[2024-12-17 01:49:52,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:52,888][root][INFO] - Training Epoch: 1/2, step 2592/7134 completed (loss: 4.477828025817871, acc: 0.29608938097953796)
[2024-12-17 01:49:53,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:53,172][root][INFO] - Training Epoch: 1/2, step 2593/7134 completed (loss: 4.238929271697998, acc: 0.3231707215309143)
[2024-12-17 01:49:53,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:53,449][root][INFO] - Training Epoch: 1/2, step 2594/7134 completed (loss: 4.543509483337402, acc: 0.3464052379131317)
[2024-12-17 01:49:53,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:53,733][root][INFO] - Training Epoch: 1/2, step 2595/7134 completed (loss: 4.15047025680542, acc: 0.2804878056049347)
[2024-12-17 01:49:53,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:54,026][root][INFO] - Training Epoch: 1/2, step 2596/7134 completed (loss: 4.388264179229736, acc: 0.2705882489681244)
[2024-12-17 01:49:54,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:54,315][root][INFO] - Training Epoch: 1/2, step 2597/7134 completed (loss: 4.2490973472595215, acc: 0.33898305892944336)
[2024-12-17 01:49:54,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:54,593][root][INFO] - Training Epoch: 1/2, step 2598/7134 completed (loss: 4.010624885559082, acc: 0.3178808093070984)
[2024-12-17 01:49:54,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:54,858][root][INFO] - Training Epoch: 1/2, step 2599/7134 completed (loss: 4.107595443725586, acc: 0.24528302252292633)
[2024-12-17 01:49:54,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:55,159][root][INFO] - Training Epoch: 1/2, step 2600/7134 completed (loss: 3.478121280670166, acc: 0.3764044940471649)
[2024-12-17 01:49:55,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:55,444][root][INFO] - Training Epoch: 1/2, step 2601/7134 completed (loss: 4.3080573081970215, acc: 0.31612902879714966)
[2024-12-17 01:49:55,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:55,724][root][INFO] - Training Epoch: 1/2, step 2602/7134 completed (loss: 4.132065773010254, acc: 0.3214285671710968)
[2024-12-17 01:49:55,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:56,018][root][INFO] - Training Epoch: 1/2, step 2603/7134 completed (loss: 4.0867600440979, acc: 0.27450981736183167)
[2024-12-17 01:49:56,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:56,301][root][INFO] - Training Epoch: 1/2, step 2604/7134 completed (loss: 4.172553062438965, acc: 0.2698412835597992)
[2024-12-17 01:49:56,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:56,568][root][INFO] - Training Epoch: 1/2, step 2605/7134 completed (loss: 3.947206735610962, acc: 0.29203540086746216)
[2024-12-17 01:49:56,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:56,857][root][INFO] - Training Epoch: 1/2, step 2606/7134 completed (loss: 4.128724098205566, acc: 0.25999999046325684)
[2024-12-17 01:49:56,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:57,145][root][INFO] - Training Epoch: 1/2, step 2607/7134 completed (loss: 3.6405551433563232, acc: 0.3483146131038666)
[2024-12-17 01:49:57,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:57,424][root][INFO] - Training Epoch: 1/2, step 2608/7134 completed (loss: 4.030118465423584, acc: 0.35449734330177307)
[2024-12-17 01:49:57,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:57,695][root][INFO] - Training Epoch: 1/2, step 2609/7134 completed (loss: 4.251924991607666, acc: 0.2810457646846771)
[2024-12-17 01:49:57,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:57,959][root][INFO] - Training Epoch: 1/2, step 2610/7134 completed (loss: 4.611171245574951, acc: 0.28057554364204407)
[2024-12-17 01:49:58,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:58,244][root][INFO] - Training Epoch: 1/2, step 2611/7134 completed (loss: 4.274532794952393, acc: 0.2793295979499817)
[2024-12-17 01:49:58,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:58,531][root][INFO] - Training Epoch: 1/2, step 2612/7134 completed (loss: 4.308102607727051, acc: 0.27000001072883606)
[2024-12-17 01:49:58,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:58,834][root][INFO] - Training Epoch: 1/2, step 2613/7134 completed (loss: 4.039750099182129, acc: 0.2916666567325592)
[2024-12-17 01:49:58,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:59,119][root][INFO] - Training Epoch: 1/2, step 2614/7134 completed (loss: 4.675512790679932, acc: 0.26595744490623474)
[2024-12-17 01:49:59,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:59,398][root][INFO] - Training Epoch: 1/2, step 2615/7134 completed (loss: 4.1202569007873535, acc: 0.3258427083492279)
[2024-12-17 01:49:59,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:59,680][root][INFO] - Training Epoch: 1/2, step 2616/7134 completed (loss: 4.2276129722595215, acc: 0.2857142984867096)
[2024-12-17 01:49:59,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:59,972][root][INFO] - Training Epoch: 1/2, step 2617/7134 completed (loss: 4.609920501708984, acc: 0.2690355181694031)
[2024-12-17 01:50:00,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:00,223][root][INFO] - Training Epoch: 1/2, step 2618/7134 completed (loss: 4.226008892059326, acc: 0.2735042870044708)
[2024-12-17 01:50:00,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:00,491][root][INFO] - Training Epoch: 1/2, step 2619/7134 completed (loss: 3.8066608905792236, acc: 0.3478260934352875)
[2024-12-17 01:50:00,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:00,768][root][INFO] - Training Epoch: 1/2, step 2620/7134 completed (loss: 3.8738021850585938, acc: 0.31216931343078613)
[2024-12-17 01:50:00,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:01,049][root][INFO] - Training Epoch: 1/2, step 2621/7134 completed (loss: 4.159081935882568, acc: 0.3582887649536133)
[2024-12-17 01:50:01,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:01,338][root][INFO] - Training Epoch: 1/2, step 2622/7134 completed (loss: 4.204695701599121, acc: 0.3219178020954132)
[2024-12-17 01:50:01,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:01,626][root][INFO] - Training Epoch: 1/2, step 2623/7134 completed (loss: 3.823725461959839, acc: 0.34403669834136963)
[2024-12-17 01:50:01,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:01,914][root][INFO] - Training Epoch: 1/2, step 2624/7134 completed (loss: 4.265988826751709, acc: 0.3047619163990021)
[2024-12-17 01:50:02,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:02,208][root][INFO] - Training Epoch: 1/2, step 2625/7134 completed (loss: 4.571268558502197, acc: 0.255952388048172)
[2024-12-17 01:50:02,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:02,498][root][INFO] - Training Epoch: 1/2, step 2626/7134 completed (loss: 4.466078281402588, acc: 0.20114941895008087)
[2024-12-17 01:50:02,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:02,787][root][INFO] - Training Epoch: 1/2, step 2627/7134 completed (loss: 4.365234375, acc: 0.29447853565216064)
[2024-12-17 01:50:02,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:03,062][root][INFO] - Training Epoch: 1/2, step 2628/7134 completed (loss: 4.080218315124512, acc: 0.3055555522441864)
[2024-12-17 01:50:03,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:03,419][root][INFO] - Training Epoch: 1/2, step 2629/7134 completed (loss: 4.085284233093262, acc: 0.32335329055786133)
[2024-12-17 01:50:03,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:03,694][root][INFO] - Training Epoch: 1/2, step 2630/7134 completed (loss: 4.560146808624268, acc: 0.2753623127937317)
[2024-12-17 01:50:03,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:03,972][root][INFO] - Training Epoch: 1/2, step 2631/7134 completed (loss: 3.8936827182769775, acc: 0.3401015102863312)
[2024-12-17 01:50:04,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:04,253][root][INFO] - Training Epoch: 1/2, step 2632/7134 completed (loss: 4.523897647857666, acc: 0.260869562625885)
[2024-12-17 01:50:04,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:04,539][root][INFO] - Training Epoch: 1/2, step 2633/7134 completed (loss: 4.457412242889404, acc: 0.25824177265167236)
[2024-12-17 01:50:04,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:04,820][root][INFO] - Training Epoch: 1/2, step 2634/7134 completed (loss: 3.6619396209716797, acc: 0.30177515745162964)
[2024-12-17 01:50:04,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:05,115][root][INFO] - Training Epoch: 1/2, step 2635/7134 completed (loss: 4.528548717498779, acc: 0.27222222089767456)
[2024-12-17 01:50:05,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:05,426][root][INFO] - Training Epoch: 1/2, step 2636/7134 completed (loss: 4.348278999328613, acc: 0.2681564390659332)
[2024-12-17 01:50:05,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:05,716][root][INFO] - Training Epoch: 1/2, step 2637/7134 completed (loss: 4.299158096313477, acc: 0.28834354877471924)
[2024-12-17 01:50:05,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:06,019][root][INFO] - Training Epoch: 1/2, step 2638/7134 completed (loss: 4.574082851409912, acc: 0.23880596458911896)
[2024-12-17 01:50:06,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:06,294][root][INFO] - Training Epoch: 1/2, step 2639/7134 completed (loss: 4.328734874725342, acc: 0.31578946113586426)
[2024-12-17 01:50:06,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:06,577][root][INFO] - Training Epoch: 1/2, step 2640/7134 completed (loss: 4.237618446350098, acc: 0.3034825921058655)
[2024-12-17 01:50:06,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:06,858][root][INFO] - Training Epoch: 1/2, step 2641/7134 completed (loss: 4.414407730102539, acc: 0.2514285743236542)
[2024-12-17 01:50:06,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:07,127][root][INFO] - Training Epoch: 1/2, step 2642/7134 completed (loss: 5.29773473739624, acc: 0.2023809552192688)
[2024-12-17 01:50:07,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:07,416][root][INFO] - Training Epoch: 1/2, step 2643/7134 completed (loss: 4.6469221115112305, acc: 0.23255814611911774)
[2024-12-17 01:50:07,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:07,734][root][INFO] - Training Epoch: 1/2, step 2644/7134 completed (loss: 4.2115654945373535, acc: 0.30687829852104187)
[2024-12-17 01:50:07,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:08,023][root][INFO] - Training Epoch: 1/2, step 2645/7134 completed (loss: 4.207764148712158, acc: 0.24571429193019867)
[2024-12-17 01:50:08,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:08,300][root][INFO] - Training Epoch: 1/2, step 2646/7134 completed (loss: 4.540367603302002, acc: 0.260869562625885)
[2024-12-17 01:50:08,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:08,589][root][INFO] - Training Epoch: 1/2, step 2647/7134 completed (loss: 4.055896759033203, acc: 0.29347825050354004)
[2024-12-17 01:50:08,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:08,872][root][INFO] - Training Epoch: 1/2, step 2648/7134 completed (loss: 4.2163615226745605, acc: 0.2970297038555145)
[2024-12-17 01:50:09,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:09,165][root][INFO] - Training Epoch: 1/2, step 2649/7134 completed (loss: 4.648531913757324, acc: 0.24864864349365234)
[2024-12-17 01:50:09,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:09,435][root][INFO] - Training Epoch: 1/2, step 2650/7134 completed (loss: 4.9432573318481445, acc: 0.19411765038967133)
[2024-12-17 01:50:09,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:09,719][root][INFO] - Training Epoch: 1/2, step 2651/7134 completed (loss: 4.198789596557617, acc: 0.2634146213531494)
[2024-12-17 01:50:09,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:10,016][root][INFO] - Training Epoch: 1/2, step 2652/7134 completed (loss: 4.19968318939209, acc: 0.31460675597190857)
[2024-12-17 01:50:10,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:10,295][root][INFO] - Training Epoch: 1/2, step 2653/7134 completed (loss: 4.537069797515869, acc: 0.19607843458652496)
[2024-12-17 01:50:10,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:10,595][root][INFO] - Training Epoch: 1/2, step 2654/7134 completed (loss: 4.781114101409912, acc: 0.16428571939468384)
[2024-12-17 01:50:10,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:10,870][root][INFO] - Training Epoch: 1/2, step 2655/7134 completed (loss: 4.2459211349487305, acc: 0.24223601818084717)
[2024-12-17 01:50:10,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:11,148][root][INFO] - Training Epoch: 1/2, step 2656/7134 completed (loss: 4.498325347900391, acc: 0.22093023359775543)
[2024-12-17 01:50:11,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:11,441][root][INFO] - Training Epoch: 1/2, step 2657/7134 completed (loss: 4.263558387756348, acc: 0.2405063360929489)
[2024-12-17 01:50:11,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:11,720][root][INFO] - Training Epoch: 1/2, step 2658/7134 completed (loss: 3.98830246925354, acc: 0.3181818127632141)
[2024-12-17 01:50:11,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:11,995][root][INFO] - Training Epoch: 1/2, step 2659/7134 completed (loss: 4.045041561126709, acc: 0.24626865983009338)
[2024-12-17 01:50:12,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:12,293][root][INFO] - Training Epoch: 1/2, step 2660/7134 completed (loss: 4.790189266204834, acc: 0.25641027092933655)
[2024-12-17 01:50:12,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:12,573][root][INFO] - Training Epoch: 1/2, step 2661/7134 completed (loss: 3.790908098220825, acc: 0.27218934893608093)
[2024-12-17 01:50:12,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:12,856][root][INFO] - Training Epoch: 1/2, step 2662/7134 completed (loss: 4.214521408081055, acc: 0.20370370149612427)
[2024-12-17 01:50:12,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:13,148][root][INFO] - Training Epoch: 1/2, step 2663/7134 completed (loss: 4.025567054748535, acc: 0.33678755164146423)
[2024-12-17 01:50:13,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:13,429][root][INFO] - Training Epoch: 1/2, step 2664/7134 completed (loss: 4.586346626281738, acc: 0.29651162028312683)
[2024-12-17 01:50:13,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:13,728][root][INFO] - Training Epoch: 1/2, step 2665/7134 completed (loss: 4.069357395172119, acc: 0.2650602459907532)
[2024-12-17 01:50:13,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:14,024][root][INFO] - Training Epoch: 1/2, step 2666/7134 completed (loss: 4.046535491943359, acc: 0.2383720874786377)
[2024-12-17 01:50:14,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:14,303][root][INFO] - Training Epoch: 1/2, step 2667/7134 completed (loss: 3.88515043258667, acc: 0.2721518874168396)
[2024-12-17 01:50:14,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:14,580][root][INFO] - Training Epoch: 1/2, step 2668/7134 completed (loss: 3.3967061042785645, acc: 0.35428571701049805)
[2024-12-17 01:50:14,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:14,861][root][INFO] - Training Epoch: 1/2, step 2669/7134 completed (loss: 3.318622589111328, acc: 0.31840795278549194)
[2024-12-17 01:50:14,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:15,146][root][INFO] - Training Epoch: 1/2, step 2670/7134 completed (loss: 4.17366886138916, acc: 0.35428571701049805)
[2024-12-17 01:50:15,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:15,431][root][INFO] - Training Epoch: 1/2, step 2671/7134 completed (loss: 4.1949357986450195, acc: 0.24571429193019867)
[2024-12-17 01:50:15,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:15,714][root][INFO] - Training Epoch: 1/2, step 2672/7134 completed (loss: 3.6288552284240723, acc: 0.28915661573410034)
[2024-12-17 01:50:15,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:16,002][root][INFO] - Training Epoch: 1/2, step 2673/7134 completed (loss: 4.043493270874023, acc: 0.265193372964859)
[2024-12-17 01:50:16,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:16,271][root][INFO] - Training Epoch: 1/2, step 2674/7134 completed (loss: 4.436522483825684, acc: 0.2222222238779068)
[2024-12-17 01:50:16,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:16,578][root][INFO] - Training Epoch: 1/2, step 2675/7134 completed (loss: 3.7356908321380615, acc: 0.3030303120613098)
[2024-12-17 01:50:16,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:16,846][root][INFO] - Training Epoch: 1/2, step 2676/7134 completed (loss: 3.7654807567596436, acc: 0.3181818127632141)
[2024-12-17 01:50:16,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:17,131][root][INFO] - Training Epoch: 1/2, step 2677/7134 completed (loss: 3.5031988620758057, acc: 0.30061349272727966)
[2024-12-17 01:50:17,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:17,419][root][INFO] - Training Epoch: 1/2, step 2678/7134 completed (loss: 3.5480594635009766, acc: 0.32768362760543823)
[2024-12-17 01:50:17,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:17,704][root][INFO] - Training Epoch: 1/2, step 2679/7134 completed (loss: 3.5703680515289307, acc: 0.28787878155708313)
[2024-12-17 01:50:17,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:17,979][root][INFO] - Training Epoch: 1/2, step 2680/7134 completed (loss: 3.978543758392334, acc: 0.3131868243217468)
[2024-12-17 01:50:18,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:18,238][root][INFO] - Training Epoch: 1/2, step 2681/7134 completed (loss: 3.3741517066955566, acc: 0.39240506291389465)
[2024-12-17 01:50:18,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:18,485][root][INFO] - Training Epoch: 1/2, step 2682/7134 completed (loss: 3.796070098876953, acc: 0.29530200362205505)
[2024-12-17 01:50:18,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:18,735][root][INFO] - Training Epoch: 1/2, step 2683/7134 completed (loss: 3.9332804679870605, acc: 0.3245033025741577)
[2024-12-17 01:50:18,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:18,993][root][INFO] - Training Epoch: 1/2, step 2684/7134 completed (loss: 4.12094259262085, acc: 0.296875)
[2024-12-17 01:50:19,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:19,273][root][INFO] - Training Epoch: 1/2, step 2685/7134 completed (loss: 4.130875110626221, acc: 0.2958579957485199)
[2024-12-17 01:50:19,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:19,561][root][INFO] - Training Epoch: 1/2, step 2686/7134 completed (loss: 3.6766202449798584, acc: 0.3400000035762787)
[2024-12-17 01:50:19,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:19,818][root][INFO] - Training Epoch: 1/2, step 2687/7134 completed (loss: 3.822592258453369, acc: 0.36974790692329407)
[2024-12-17 01:50:19,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:20,082][root][INFO] - Training Epoch: 1/2, step 2688/7134 completed (loss: 4.478981018066406, acc: 0.27067670226097107)
[2024-12-17 01:50:20,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:20,305][root][INFO] - Training Epoch: 1/2, step 2689/7134 completed (loss: 3.7618401050567627, acc: 0.3414634168148041)
[2024-12-17 01:50:20,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:20,567][root][INFO] - Training Epoch: 1/2, step 2690/7134 completed (loss: 3.914249897003174, acc: 0.28776979446411133)
[2024-12-17 01:50:20,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:20,817][root][INFO] - Training Epoch: 1/2, step 2691/7134 completed (loss: 4.092062473297119, acc: 0.2743362784385681)
[2024-12-17 01:50:20,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:21,084][root][INFO] - Training Epoch: 1/2, step 2692/7134 completed (loss: 4.086968898773193, acc: 0.27272728085517883)
[2024-12-17 01:50:21,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:21,329][root][INFO] - Training Epoch: 1/2, step 2693/7134 completed (loss: 3.8282535076141357, acc: 0.3539822995662689)
[2024-12-17 01:50:21,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:21,580][root][INFO] - Training Epoch: 1/2, step 2694/7134 completed (loss: 3.8545420169830322, acc: 0.3576158881187439)
[2024-12-17 01:50:21,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:21,863][root][INFO] - Training Epoch: 1/2, step 2695/7134 completed (loss: 3.4197487831115723, acc: 0.34074074029922485)
[2024-12-17 01:50:21,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:22,134][root][INFO] - Training Epoch: 1/2, step 2696/7134 completed (loss: 3.912942409515381, acc: 0.27142858505249023)
[2024-12-17 01:50:22,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:22,392][root][INFO] - Training Epoch: 1/2, step 2697/7134 completed (loss: 4.307905673980713, acc: 0.22727273404598236)
[2024-12-17 01:50:22,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:22,671][root][INFO] - Training Epoch: 1/2, step 2698/7134 completed (loss: 3.867154598236084, acc: 0.31972789764404297)
[2024-12-17 01:50:22,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:22,949][root][INFO] - Training Epoch: 1/2, step 2699/7134 completed (loss: 4.094462871551514, acc: 0.3017241358757019)
[2024-12-17 01:50:23,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:23,171][root][INFO] - Training Epoch: 1/2, step 2700/7134 completed (loss: 4.513956069946289, acc: 0.30000001192092896)
[2024-12-17 01:50:23,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:23,416][root][INFO] - Training Epoch: 1/2, step 2701/7134 completed (loss: 4.04862117767334, acc: 0.27067670226097107)
[2024-12-17 01:50:23,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:23,612][root][INFO] - Training Epoch: 1/2, step 2702/7134 completed (loss: 3.849020481109619, acc: 0.31481480598449707)
[2024-12-17 01:50:23,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:23,885][root][INFO] - Training Epoch: 1/2, step 2703/7134 completed (loss: 3.674410820007324, acc: 0.3466666638851166)
[2024-12-17 01:50:24,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:24,163][root][INFO] - Training Epoch: 1/2, step 2704/7134 completed (loss: 3.9209413528442383, acc: 0.2797619104385376)
[2024-12-17 01:50:24,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:24,444][root][INFO] - Training Epoch: 1/2, step 2705/7134 completed (loss: 4.448394298553467, acc: 0.23239436745643616)
[2024-12-17 01:50:24,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:24,729][root][INFO] - Training Epoch: 1/2, step 2706/7134 completed (loss: 4.113687038421631, acc: 0.2945205569267273)
[2024-12-17 01:50:24,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:25,000][root][INFO] - Training Epoch: 1/2, step 2707/7134 completed (loss: 4.0867533683776855, acc: 0.2916666567325592)
[2024-12-17 01:50:25,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:25,284][root][INFO] - Training Epoch: 1/2, step 2708/7134 completed (loss: 4.490676403045654, acc: 0.23428571224212646)
[2024-12-17 01:50:25,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:25,565][root][INFO] - Training Epoch: 1/2, step 2709/7134 completed (loss: 3.782989025115967, acc: 0.2887323796749115)
[2024-12-17 01:50:25,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:25,827][root][INFO] - Training Epoch: 1/2, step 2710/7134 completed (loss: 3.7770743370056152, acc: 0.3499999940395355)
[2024-12-17 01:50:25,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:26,097][root][INFO] - Training Epoch: 1/2, step 2711/7134 completed (loss: 3.8424203395843506, acc: 0.2680412232875824)
[2024-12-17 01:50:26,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:26,374][root][INFO] - Training Epoch: 1/2, step 2712/7134 completed (loss: 4.140082836151123, acc: 0.24468085169792175)
[2024-12-17 01:50:26,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:26,655][root][INFO] - Training Epoch: 1/2, step 2713/7134 completed (loss: 3.9168190956115723, acc: 0.30000001192092896)
[2024-12-17 01:50:26,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:26,921][root][INFO] - Training Epoch: 1/2, step 2714/7134 completed (loss: 3.900636672973633, acc: 0.29411765933036804)
[2024-12-17 01:50:27,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:27,190][root][INFO] - Training Epoch: 1/2, step 2715/7134 completed (loss: 4.180500507354736, acc: 0.3103448152542114)
[2024-12-17 01:50:27,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:27,462][root][INFO] - Training Epoch: 1/2, step 2716/7134 completed (loss: 3.8079850673675537, acc: 0.29651162028312683)
[2024-12-17 01:50:27,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:27,731][root][INFO] - Training Epoch: 1/2, step 2717/7134 completed (loss: 4.563077449798584, acc: 0.2735042870044708)
[2024-12-17 01:50:27,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:28,005][root][INFO] - Training Epoch: 1/2, step 2718/7134 completed (loss: 3.873950958251953, acc: 0.3055555522441864)
[2024-12-17 01:50:28,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:28,278][root][INFO] - Training Epoch: 1/2, step 2719/7134 completed (loss: 4.059717178344727, acc: 0.316546767950058)
[2024-12-17 01:50:28,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:28,545][root][INFO] - Training Epoch: 1/2, step 2720/7134 completed (loss: 4.428772449493408, acc: 0.2846715450286865)
[2024-12-17 01:50:28,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:28,769][root][INFO] - Training Epoch: 1/2, step 2721/7134 completed (loss: 3.7950572967529297, acc: 0.3112582862377167)
[2024-12-17 01:50:28,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:28,983][root][INFO] - Training Epoch: 1/2, step 2722/7134 completed (loss: 4.554694175720215, acc: 0.26595744490623474)
[2024-12-17 01:50:29,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:29,242][root][INFO] - Training Epoch: 1/2, step 2723/7134 completed (loss: 4.151619911193848, acc: 0.23952095210552216)
[2024-12-17 01:50:29,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:29,514][root][INFO] - Training Epoch: 1/2, step 2724/7134 completed (loss: 3.657252788543701, acc: 0.28248587250709534)
[2024-12-17 01:50:29,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:29,784][root][INFO] - Training Epoch: 1/2, step 2725/7134 completed (loss: 4.071098327636719, acc: 0.305970162153244)
[2024-12-17 01:50:29,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:30,051][root][INFO] - Training Epoch: 1/2, step 2726/7134 completed (loss: 4.189080238342285, acc: 0.22764228284358978)
[2024-12-17 01:50:30,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:30,345][root][INFO] - Training Epoch: 1/2, step 2727/7134 completed (loss: 4.3628830909729, acc: 0.31578946113586426)
[2024-12-17 01:50:30,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:30,622][root][INFO] - Training Epoch: 1/2, step 2728/7134 completed (loss: 4.200717926025391, acc: 0.3629629611968994)
[2024-12-17 01:50:30,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:30,900][root][INFO] - Training Epoch: 1/2, step 2729/7134 completed (loss: 4.075915336608887, acc: 0.3214285671710968)
[2024-12-17 01:50:30,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:31,167][root][INFO] - Training Epoch: 1/2, step 2730/7134 completed (loss: 4.274231910705566, acc: 0.29203540086746216)
[2024-12-17 01:50:31,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:31,415][root][INFO] - Training Epoch: 1/2, step 2731/7134 completed (loss: 3.7830519676208496, acc: 0.33980581164360046)
[2024-12-17 01:50:31,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:31,687][root][INFO] - Training Epoch: 1/2, step 2732/7134 completed (loss: 3.9539713859558105, acc: 0.3333333432674408)
[2024-12-17 01:50:31,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:31,970][root][INFO] - Training Epoch: 1/2, step 2733/7134 completed (loss: 3.6810522079467773, acc: 0.38333332538604736)
[2024-12-17 01:50:32,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:32,228][root][INFO] - Training Epoch: 1/2, step 2734/7134 completed (loss: 4.861522197723389, acc: 0.22314049303531647)
[2024-12-17 01:50:32,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:32,532][root][INFO] - Training Epoch: 1/2, step 2735/7134 completed (loss: 3.920473098754883, acc: 0.31707316637039185)
[2024-12-17 01:50:32,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:32,803][root][INFO] - Training Epoch: 1/2, step 2736/7134 completed (loss: 4.099554061889648, acc: 0.3522012531757355)
[2024-12-17 01:50:32,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:33,070][root][INFO] - Training Epoch: 1/2, step 2737/7134 completed (loss: 3.7198128700256348, acc: 0.37142857909202576)
[2024-12-17 01:50:33,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:33,340][root][INFO] - Training Epoch: 1/2, step 2738/7134 completed (loss: 3.8475561141967773, acc: 0.359281450510025)
[2024-12-17 01:50:33,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:33,605][root][INFO] - Training Epoch: 1/2, step 2739/7134 completed (loss: 4.199208736419678, acc: 0.2971014380455017)
[2024-12-17 01:50:33,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:33,874][root][INFO] - Training Epoch: 1/2, step 2740/7134 completed (loss: 3.7167000770568848, acc: 0.40816327929496765)
[2024-12-17 01:50:33,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:34,125][root][INFO] - Training Epoch: 1/2, step 2741/7134 completed (loss: 3.0944859981536865, acc: 0.3965517282485962)
[2024-12-17 01:50:34,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:34,402][root][INFO] - Training Epoch: 1/2, step 2742/7134 completed (loss: 3.414114236831665, acc: 0.3949579894542694)
[2024-12-17 01:50:34,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:34,656][root][INFO] - Training Epoch: 1/2, step 2743/7134 completed (loss: 3.1548571586608887, acc: 0.3510638177394867)
[2024-12-17 01:50:34,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:34,855][root][INFO] - Training Epoch: 1/2, step 2744/7134 completed (loss: 3.2756223678588867, acc: 0.4193548262119293)
[2024-12-17 01:50:34,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:35,107][root][INFO] - Training Epoch: 1/2, step 2745/7134 completed (loss: 3.8669822216033936, acc: 0.3214285671710968)
[2024-12-17 01:50:35,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:35,355][root][INFO] - Training Epoch: 1/2, step 2746/7134 completed (loss: 4.247558116912842, acc: 0.35227271914482117)
[2024-12-17 01:50:35,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:35,635][root][INFO] - Training Epoch: 1/2, step 2747/7134 completed (loss: 3.4287352561950684, acc: 0.3888888955116272)
[2024-12-17 01:50:35,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:35,943][root][INFO] - Training Epoch: 1/2, step 2748/7134 completed (loss: 3.3151533603668213, acc: 0.3636363744735718)
[2024-12-17 01:50:36,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:36,221][root][INFO] - Training Epoch: 1/2, step 2749/7134 completed (loss: 3.4458558559417725, acc: 0.34020617604255676)
[2024-12-17 01:50:36,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:36,507][root][INFO] - Training Epoch: 1/2, step 2750/7134 completed (loss: 3.170680046081543, acc: 0.379518061876297)
[2024-12-17 01:50:36,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:36,782][root][INFO] - Training Epoch: 1/2, step 2751/7134 completed (loss: 2.8260269165039062, acc: 0.46846845746040344)
[2024-12-17 01:50:36,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:37,065][root][INFO] - Training Epoch: 1/2, step 2752/7134 completed (loss: 4.213748455047607, acc: 0.29927006363868713)
[2024-12-17 01:50:37,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:37,354][root][INFO] - Training Epoch: 1/2, step 2753/7134 completed (loss: 3.8296096324920654, acc: 0.3781512677669525)
[2024-12-17 01:50:37,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:37,650][root][INFO] - Training Epoch: 1/2, step 2754/7134 completed (loss: 3.7924325466156006, acc: 0.3583333194255829)
[2024-12-17 01:50:37,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:37,929][root][INFO] - Training Epoch: 1/2, step 2755/7134 completed (loss: 3.125797748565674, acc: 0.359375)
[2024-12-17 01:50:38,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:38,213][root][INFO] - Training Epoch: 1/2, step 2756/7134 completed (loss: 3.1500041484832764, acc: 0.4054054021835327)
[2024-12-17 01:50:38,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:38,436][root][INFO] - Training Epoch: 1/2, step 2757/7134 completed (loss: 3.521801233291626, acc: 0.43478259444236755)
[2024-12-17 01:50:38,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:38,726][root][INFO] - Training Epoch: 1/2, step 2758/7134 completed (loss: 3.905862331390381, acc: 0.3606557250022888)
[2024-12-17 01:50:38,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:39,047][root][INFO] - Training Epoch: 1/2, step 2759/7134 completed (loss: 3.8613617420196533, acc: 0.37142857909202576)
[2024-12-17 01:50:39,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:39,336][root][INFO] - Training Epoch: 1/2, step 2760/7134 completed (loss: 3.267648935317993, acc: 0.41111111640930176)
[2024-12-17 01:50:39,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:39,628][root][INFO] - Training Epoch: 1/2, step 2761/7134 completed (loss: 4.779110908508301, acc: 0.23157894611358643)
[2024-12-17 01:50:39,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:39,934][root][INFO] - Training Epoch: 1/2, step 2762/7134 completed (loss: 3.9310035705566406, acc: 0.3103448152542114)
[2024-12-17 01:50:40,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:40,239][root][INFO] - Training Epoch: 1/2, step 2763/7134 completed (loss: 4.302910327911377, acc: 0.3224043846130371)
[2024-12-17 01:50:40,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:40,541][root][INFO] - Training Epoch: 1/2, step 2764/7134 completed (loss: 3.607001543045044, acc: 0.328125)
[2024-12-17 01:50:40,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:40,848][root][INFO] - Training Epoch: 1/2, step 2765/7134 completed (loss: 3.97031569480896, acc: 0.3117647171020508)
[2024-12-17 01:50:40,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:41,160][root][INFO] - Training Epoch: 1/2, step 2766/7134 completed (loss: 4.026775360107422, acc: 0.2866241931915283)
[2024-12-17 01:50:41,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:41,455][root][INFO] - Training Epoch: 1/2, step 2767/7134 completed (loss: 3.9611976146698, acc: 0.36000001430511475)
[2024-12-17 01:50:41,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:41,741][root][INFO] - Training Epoch: 1/2, step 2768/7134 completed (loss: 3.9665005207061768, acc: 0.3072289228439331)
[2024-12-17 01:50:41,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:42,035][root][INFO] - Training Epoch: 1/2, step 2769/7134 completed (loss: 3.6560871601104736, acc: 0.3105263113975525)
[2024-12-17 01:50:42,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:42,335][root][INFO] - Training Epoch: 1/2, step 2770/7134 completed (loss: 3.4769229888916016, acc: 0.32098764181137085)
[2024-12-17 01:50:42,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:42,652][root][INFO] - Training Epoch: 1/2, step 2771/7134 completed (loss: 3.3911592960357666, acc: 0.3601895868778229)
[2024-12-17 01:50:42,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:42,956][root][INFO] - Training Epoch: 1/2, step 2772/7134 completed (loss: 3.422757625579834, acc: 0.39500001072883606)
[2024-12-17 01:50:43,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:43,261][root][INFO] - Training Epoch: 1/2, step 2773/7134 completed (loss: 3.5450589656829834, acc: 0.3366834223270416)
[2024-12-17 01:50:43,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:43,544][root][INFO] - Training Epoch: 1/2, step 2774/7134 completed (loss: 3.683838367462158, acc: 0.36097562313079834)
[2024-12-17 01:50:43,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:43,816][root][INFO] - Training Epoch: 1/2, step 2775/7134 completed (loss: 3.7998337745666504, acc: 0.34972676634788513)
[2024-12-17 01:50:43,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:44,119][root][INFO] - Training Epoch: 1/2, step 2776/7134 completed (loss: 3.15917706489563, acc: 0.38528138399124146)
[2024-12-17 01:50:44,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:44,395][root][INFO] - Training Epoch: 1/2, step 2777/7134 completed (loss: 3.4227356910705566, acc: 0.33714285492897034)
[2024-12-17 01:50:44,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:44,684][root][INFO] - Training Epoch: 1/2, step 2778/7134 completed (loss: 3.4073879718780518, acc: 0.38383838534355164)
[2024-12-17 01:50:44,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:44,964][root][INFO] - Training Epoch: 1/2, step 2779/7134 completed (loss: 3.462780475616455, acc: 0.37899544835090637)
[2024-12-17 01:50:45,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:45,246][root][INFO] - Training Epoch: 1/2, step 2780/7134 completed (loss: 4.05507755279541, acc: 0.29203540086746216)
[2024-12-17 01:50:45,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:45,534][root][INFO] - Training Epoch: 1/2, step 2781/7134 completed (loss: 4.074342727661133, acc: 0.28260868787765503)
[2024-12-17 01:50:45,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:45,814][root][INFO] - Training Epoch: 1/2, step 2782/7134 completed (loss: 3.5515644550323486, acc: 0.3303571343421936)
[2024-12-17 01:50:45,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:46,092][root][INFO] - Training Epoch: 1/2, step 2783/7134 completed (loss: 3.876277208328247, acc: 0.30612245202064514)
[2024-12-17 01:50:46,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:46,371][root][INFO] - Training Epoch: 1/2, step 2784/7134 completed (loss: 3.4597208499908447, acc: 0.3285024166107178)
[2024-12-17 01:50:46,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:46,665][root][INFO] - Training Epoch: 1/2, step 2785/7134 completed (loss: 3.5063254833221436, acc: 0.3349514603614807)
[2024-12-17 01:50:46,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:46,945][root][INFO] - Training Epoch: 1/2, step 2786/7134 completed (loss: 3.605036973953247, acc: 0.3733333349227905)
[2024-12-17 01:50:47,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:47,235][root][INFO] - Training Epoch: 1/2, step 2787/7134 completed (loss: 3.4243195056915283, acc: 0.39306357502937317)
[2024-12-17 01:50:47,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:47,509][root][INFO] - Training Epoch: 1/2, step 2788/7134 completed (loss: 4.665587425231934, acc: 0.2292993664741516)
[2024-12-17 01:50:47,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:47,783][root][INFO] - Training Epoch: 1/2, step 2789/7134 completed (loss: 5.283997535705566, acc: 0.2857142984867096)
[2024-12-17 01:50:47,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:48,066][root][INFO] - Training Epoch: 1/2, step 2790/7134 completed (loss: 4.779073715209961, acc: 0.2750000059604645)
[2024-12-17 01:50:48,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:48,344][root][INFO] - Training Epoch: 1/2, step 2791/7134 completed (loss: 4.413729190826416, acc: 0.2384105920791626)
[2024-12-17 01:50:48,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:48,631][root][INFO] - Training Epoch: 1/2, step 2792/7134 completed (loss: 4.1370625495910645, acc: 0.26744186878204346)
[2024-12-17 01:50:48,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:48,916][root][INFO] - Training Epoch: 1/2, step 2793/7134 completed (loss: 4.210825443267822, acc: 0.28143712878227234)
[2024-12-17 01:50:49,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:49,171][root][INFO] - Training Epoch: 1/2, step 2794/7134 completed (loss: 3.771362781524658, acc: 0.21212121844291687)
[2024-12-17 01:50:49,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:49,445][root][INFO] - Training Epoch: 1/2, step 2795/7134 completed (loss: 4.015279769897461, acc: 0.25925925374031067)
[2024-12-17 01:50:49,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:49,703][root][INFO] - Training Epoch: 1/2, step 2796/7134 completed (loss: 3.8411366939544678, acc: 0.2601625919342041)
[2024-12-17 01:50:49,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:49,926][root][INFO] - Training Epoch: 1/2, step 2797/7134 completed (loss: 4.508803367614746, acc: 0.26829269528388977)
[2024-12-17 01:50:50,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:50,204][root][INFO] - Training Epoch: 1/2, step 2798/7134 completed (loss: 3.981964111328125, acc: 0.21666666865348816)
[2024-12-17 01:50:50,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:50,465][root][INFO] - Training Epoch: 1/2, step 2799/7134 completed (loss: 4.080393314361572, acc: 0.28125)
[2024-12-17 01:50:50,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:50,700][root][INFO] - Training Epoch: 1/2, step 2800/7134 completed (loss: 4.07497501373291, acc: 0.29927006363868713)
[2024-12-17 01:50:50,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:50,986][root][INFO] - Training Epoch: 1/2, step 2801/7134 completed (loss: 4.198062896728516, acc: 0.2950819730758667)
[2024-12-17 01:50:51,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:51,267][root][INFO] - Training Epoch: 1/2, step 2802/7134 completed (loss: 4.439169883728027, acc: 0.31658291816711426)
[2024-12-17 01:50:51,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:51,542][root][INFO] - Training Epoch: 1/2, step 2803/7134 completed (loss: 4.084417343139648, acc: 0.2839506268501282)
[2024-12-17 01:50:51,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:51,835][root][INFO] - Training Epoch: 1/2, step 2804/7134 completed (loss: 4.750010013580322, acc: 0.20809248089790344)
[2024-12-17 01:50:51,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:52,114][root][INFO] - Training Epoch: 1/2, step 2805/7134 completed (loss: 4.8010053634643555, acc: 0.20930232107639313)
[2024-12-17 01:50:52,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:52,389][root][INFO] - Training Epoch: 1/2, step 2806/7134 completed (loss: 4.016824722290039, acc: 0.34558823704719543)
[2024-12-17 01:50:52,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:52,654][root][INFO] - Training Epoch: 1/2, step 2807/7134 completed (loss: 3.5884923934936523, acc: 0.33980581164360046)
[2024-12-17 01:50:52,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:52,928][root][INFO] - Training Epoch: 1/2, step 2808/7134 completed (loss: 3.7477052211761475, acc: 0.32663315534591675)
[2024-12-17 01:50:53,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:53,202][root][INFO] - Training Epoch: 1/2, step 2809/7134 completed (loss: 4.269142150878906, acc: 0.28346458077430725)
[2024-12-17 01:50:53,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:53,500][root][INFO] - Training Epoch: 1/2, step 2810/7134 completed (loss: 3.7419257164001465, acc: 0.2786885201931)
[2024-12-17 01:50:53,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:53,770][root][INFO] - Training Epoch: 1/2, step 2811/7134 completed (loss: 3.845597982406616, acc: 0.2983425557613373)
[2024-12-17 01:50:53,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:54,040][root][INFO] - Training Epoch: 1/2, step 2812/7134 completed (loss: 3.3905458450317383, acc: 0.4039735198020935)
[2024-12-17 01:50:54,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:54,320][root][INFO] - Training Epoch: 1/2, step 2813/7134 completed (loss: 3.701193332672119, acc: 0.32758620381355286)
[2024-12-17 01:50:54,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:54,586][root][INFO] - Training Epoch: 1/2, step 2814/7134 completed (loss: 3.8019371032714844, acc: 0.30813953280448914)
[2024-12-17 01:50:54,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:54,858][root][INFO] - Training Epoch: 1/2, step 2815/7134 completed (loss: 3.709749937057495, acc: 0.35164836049079895)
[2024-12-17 01:50:54,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:55,146][root][INFO] - Training Epoch: 1/2, step 2816/7134 completed (loss: 3.848327159881592, acc: 0.3202614486217499)
[2024-12-17 01:50:55,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:55,435][root][INFO] - Training Epoch: 1/2, step 2817/7134 completed (loss: 3.669459342956543, acc: 0.3502538204193115)
[2024-12-17 01:50:55,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:55,712][root][INFO] - Training Epoch: 1/2, step 2818/7134 completed (loss: 3.948744058609009, acc: 0.3297872245311737)
[2024-12-17 01:50:55,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:55,974][root][INFO] - Training Epoch: 1/2, step 2819/7134 completed (loss: 3.57593035697937, acc: 0.31506848335266113)
[2024-12-17 01:50:56,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:56,237][root][INFO] - Training Epoch: 1/2, step 2820/7134 completed (loss: 3.5369532108306885, acc: 0.3190183937549591)
[2024-12-17 01:50:56,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:56,507][root][INFO] - Training Epoch: 1/2, step 2821/7134 completed (loss: 3.806974172592163, acc: 0.3471502661705017)
[2024-12-17 01:50:56,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:56,786][root][INFO] - Training Epoch: 1/2, step 2822/7134 completed (loss: 3.89605450630188, acc: 0.3243243098258972)
[2024-12-17 01:50:56,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:57,142][root][INFO] - Training Epoch: 1/2, step 2823/7134 completed (loss: 4.092284679412842, acc: 0.3229813575744629)
[2024-12-17 01:50:57,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:57,431][root][INFO] - Training Epoch: 1/2, step 2824/7134 completed (loss: 4.826013565063477, acc: 0.2578616440296173)
[2024-12-17 01:50:57,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:57,705][root][INFO] - Training Epoch: 1/2, step 2825/7134 completed (loss: 4.020362854003906, acc: 0.2611111104488373)
[2024-12-17 01:50:57,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:57,984][root][INFO] - Training Epoch: 1/2, step 2826/7134 completed (loss: 3.9443016052246094, acc: 0.3103448152542114)
[2024-12-17 01:50:58,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:58,268][root][INFO] - Training Epoch: 1/2, step 2827/7134 completed (loss: 3.756462812423706, acc: 0.2631579041481018)
[2024-12-17 01:50:58,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:58,549][root][INFO] - Training Epoch: 1/2, step 2828/7134 completed (loss: 4.49352502822876, acc: 0.23417721688747406)
[2024-12-17 01:50:58,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:58,834][root][INFO] - Training Epoch: 1/2, step 2829/7134 completed (loss: 3.8492722511291504, acc: 0.2916666567325592)
[2024-12-17 01:50:58,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:59,114][root][INFO] - Training Epoch: 1/2, step 2830/7134 completed (loss: 3.6060683727264404, acc: 0.26865673065185547)
[2024-12-17 01:50:59,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:59,390][root][INFO] - Training Epoch: 1/2, step 2831/7134 completed (loss: 3.7769482135772705, acc: 0.28378379344940186)
[2024-12-17 01:50:59,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:59,672][root][INFO] - Training Epoch: 1/2, step 2832/7134 completed (loss: 3.643744468688965, acc: 0.3279569745063782)
[2024-12-17 01:50:59,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:59,960][root][INFO] - Training Epoch: 1/2, step 2833/7134 completed (loss: 3.7901458740234375, acc: 0.32804232835769653)
[2024-12-17 01:51:00,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:00,236][root][INFO] - Training Epoch: 1/2, step 2834/7134 completed (loss: 4.211454391479492, acc: 0.3222222328186035)
[2024-12-17 01:51:00,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:00,519][root][INFO] - Training Epoch: 1/2, step 2835/7134 completed (loss: 3.7862319946289062, acc: 0.2368421107530594)
[2024-12-17 01:51:00,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:00,790][root][INFO] - Training Epoch: 1/2, step 2836/7134 completed (loss: 3.969161033630371, acc: 0.28999999165534973)
[2024-12-17 01:51:00,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:01,084][root][INFO] - Training Epoch: 1/2, step 2837/7134 completed (loss: 3.9823079109191895, acc: 0.2631579041481018)
[2024-12-17 01:51:01,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:01,394][root][INFO] - Training Epoch: 1/2, step 2838/7134 completed (loss: 3.850320816040039, acc: 0.32019704580307007)
[2024-12-17 01:51:01,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:01,655][root][INFO] - Training Epoch: 1/2, step 2839/7134 completed (loss: 4.242082595825195, acc: 0.28358209133148193)
[2024-12-17 01:51:01,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:01,951][root][INFO] - Training Epoch: 1/2, step 2840/7134 completed (loss: 3.555971384048462, acc: 0.3294117748737335)
[2024-12-17 01:51:02,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:02,227][root][INFO] - Training Epoch: 1/2, step 2841/7134 completed (loss: 4.398865222930908, acc: 0.2075471729040146)
[2024-12-17 01:51:02,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:02,522][root][INFO] - Training Epoch: 1/2, step 2842/7134 completed (loss: 3.903818130493164, acc: 0.2604166567325592)
[2024-12-17 01:51:02,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:02,793][root][INFO] - Training Epoch: 1/2, step 2843/7134 completed (loss: 4.478353977203369, acc: 0.276729553937912)
[2024-12-17 01:51:02,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:03,074][root][INFO] - Training Epoch: 1/2, step 2844/7134 completed (loss: 4.147258758544922, acc: 0.31521740555763245)
[2024-12-17 01:51:03,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:03,337][root][INFO] - Training Epoch: 1/2, step 2845/7134 completed (loss: 4.001082420349121, acc: 0.29054054617881775)
[2024-12-17 01:51:03,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:03,613][root][INFO] - Training Epoch: 1/2, step 2846/7134 completed (loss: 4.406432628631592, acc: 0.2679738700389862)
[2024-12-17 01:51:03,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:03,948][root][INFO] - Training Epoch: 1/2, step 2847/7134 completed (loss: 4.749669075012207, acc: 0.19108280539512634)
[2024-12-17 01:51:04,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:04,260][root][INFO] - Training Epoch: 1/2, step 2848/7134 completed (loss: 4.715646743774414, acc: 0.2844036817550659)
[2024-12-17 01:51:04,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:04,551][root][INFO] - Training Epoch: 1/2, step 2849/7134 completed (loss: 3.708648443222046, acc: 0.3142857253551483)
[2024-12-17 01:51:04,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:04,849][root][INFO] - Training Epoch: 1/2, step 2850/7134 completed (loss: 3.950925588607788, acc: 0.23931623995304108)
[2024-12-17 01:51:04,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:05,150][root][INFO] - Training Epoch: 1/2, step 2851/7134 completed (loss: 3.7900195121765137, acc: 0.3333333432674408)
[2024-12-17 01:51:05,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:05,445][root][INFO] - Training Epoch: 1/2, step 2852/7134 completed (loss: 4.172962188720703, acc: 0.28455284237861633)
[2024-12-17 01:51:05,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:05,746][root][INFO] - Training Epoch: 1/2, step 2853/7134 completed (loss: 3.715101480484009, acc: 0.3877550959587097)
[2024-12-17 01:51:05,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:06,051][root][INFO] - Training Epoch: 1/2, step 2854/7134 completed (loss: 3.965555429458618, acc: 0.31292515993118286)
[2024-12-17 01:51:06,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:06,329][root][INFO] - Training Epoch: 1/2, step 2855/7134 completed (loss: 3.828695774078369, acc: 0.3175675570964813)
[2024-12-17 01:51:06,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:06,647][root][INFO] - Training Epoch: 1/2, step 2856/7134 completed (loss: 3.8361709117889404, acc: 0.2857142984867096)
[2024-12-17 01:51:06,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:06,936][root][INFO] - Training Epoch: 1/2, step 2857/7134 completed (loss: 3.9137682914733887, acc: 0.28742516040802)
[2024-12-17 01:51:07,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:07,209][root][INFO] - Training Epoch: 1/2, step 2858/7134 completed (loss: 4.121026515960693, acc: 0.2954545319080353)
[2024-12-17 01:51:07,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:07,494][root][INFO] - Training Epoch: 1/2, step 2859/7134 completed (loss: 3.8268072605133057, acc: 0.3214285671710968)
[2024-12-17 01:51:07,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:07,764][root][INFO] - Training Epoch: 1/2, step 2860/7134 completed (loss: 4.126021862030029, acc: 0.3203125)
[2024-12-17 01:51:07,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:08,037][root][INFO] - Training Epoch: 1/2, step 2861/7134 completed (loss: 4.219905376434326, acc: 0.2857142984867096)
[2024-12-17 01:51:08,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:08,310][root][INFO] - Training Epoch: 1/2, step 2862/7134 completed (loss: 4.548882484436035, acc: 0.2631579041481018)
[2024-12-17 01:51:08,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:08,613][root][INFO] - Training Epoch: 1/2, step 2863/7134 completed (loss: 3.897334098815918, acc: 0.2928176820278168)
[2024-12-17 01:51:08,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:08,873][root][INFO] - Training Epoch: 1/2, step 2864/7134 completed (loss: 3.71726393699646, acc: 0.35789474844932556)
[2024-12-17 01:51:09,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:09,161][root][INFO] - Training Epoch: 1/2, step 2865/7134 completed (loss: 3.4588770866394043, acc: 0.35652172565460205)
[2024-12-17 01:51:09,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:09,457][root][INFO] - Training Epoch: 1/2, step 2866/7134 completed (loss: 3.7511723041534424, acc: 0.31612902879714966)
[2024-12-17 01:51:09,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:09,735][root][INFO] - Training Epoch: 1/2, step 2867/7134 completed (loss: 3.9942972660064697, acc: 0.2222222238779068)
[2024-12-17 01:51:09,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:09,994][root][INFO] - Training Epoch: 1/2, step 2868/7134 completed (loss: 3.6151938438415527, acc: 0.3176470696926117)
[2024-12-17 01:51:10,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:10,267][root][INFO] - Training Epoch: 1/2, step 2869/7134 completed (loss: 3.7895069122314453, acc: 0.30344828963279724)
[2024-12-17 01:51:10,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:10,554][root][INFO] - Training Epoch: 1/2, step 2870/7134 completed (loss: 3.7608237266540527, acc: 0.30000001192092896)
[2024-12-17 01:51:10,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:10,826][root][INFO] - Training Epoch: 1/2, step 2871/7134 completed (loss: 4.014195442199707, acc: 0.24137930572032928)
[2024-12-17 01:51:10,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:11,102][root][INFO] - Training Epoch: 1/2, step 2872/7134 completed (loss: 3.807758331298828, acc: 0.3008849620819092)
[2024-12-17 01:51:11,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:11,377][root][INFO] - Training Epoch: 1/2, step 2873/7134 completed (loss: 3.848676919937134, acc: 0.3178294599056244)
[2024-12-17 01:51:11,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:11,661][root][INFO] - Training Epoch: 1/2, step 2874/7134 completed (loss: 3.6637115478515625, acc: 0.3611111044883728)
[2024-12-17 01:51:11,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:11,959][root][INFO] - Training Epoch: 1/2, step 2875/7134 completed (loss: 3.6695563793182373, acc: 0.3511904776096344)
[2024-12-17 01:51:12,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:12,228][root][INFO] - Training Epoch: 1/2, step 2876/7134 completed (loss: 3.9980859756469727, acc: 0.30188679695129395)
[2024-12-17 01:51:12,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:12,504][root][INFO] - Training Epoch: 1/2, step 2877/7134 completed (loss: 3.639392137527466, acc: 0.34188035130500793)
[2024-12-17 01:51:12,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:12,774][root][INFO] - Training Epoch: 1/2, step 2878/7134 completed (loss: 3.8716232776641846, acc: 0.2982456088066101)
[2024-12-17 01:51:12,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:13,041][root][INFO] - Training Epoch: 1/2, step 2879/7134 completed (loss: 4.048074722290039, acc: 0.2789115607738495)
[2024-12-17 01:51:13,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:13,331][root][INFO] - Training Epoch: 1/2, step 2880/7134 completed (loss: 3.8395535945892334, acc: 0.28082191944122314)
[2024-12-17 01:51:13,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:13,600][root][INFO] - Training Epoch: 1/2, step 2881/7134 completed (loss: 3.983299732208252, acc: 0.3095238208770752)
[2024-12-17 01:51:13,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:13,885][root][INFO] - Training Epoch: 1/2, step 2882/7134 completed (loss: 3.8619544506073, acc: 0.32947975397109985)
[2024-12-17 01:51:13,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:14,183][root][INFO] - Training Epoch: 1/2, step 2883/7134 completed (loss: 4.545996189117432, acc: 0.2634730637073517)
[2024-12-17 01:51:14,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:14,477][root][INFO] - Training Epoch: 1/2, step 2884/7134 completed (loss: 4.563676834106445, acc: 0.24242424964904785)
[2024-12-17 01:51:14,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:14,754][root][INFO] - Training Epoch: 1/2, step 2885/7134 completed (loss: 5.385132789611816, acc: 0.145454540848732)
[2024-12-17 01:51:14,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:15,023][root][INFO] - Training Epoch: 1/2, step 2886/7134 completed (loss: 4.333755016326904, acc: 0.25882354378700256)
[2024-12-17 01:51:15,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:15,324][root][INFO] - Training Epoch: 1/2, step 2887/7134 completed (loss: 4.159719467163086, acc: 0.235807865858078)
[2024-12-17 01:51:15,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:15,613][root][INFO] - Training Epoch: 1/2, step 2888/7134 completed (loss: 4.13699197769165, acc: 0.2368421107530594)
[2024-12-17 01:51:15,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:15,894][root][INFO] - Training Epoch: 1/2, step 2889/7134 completed (loss: 4.614352226257324, acc: 0.20111732184886932)
[2024-12-17 01:51:16,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:16,179][root][INFO] - Training Epoch: 1/2, step 2890/7134 completed (loss: 3.924170970916748, acc: 0.25128206610679626)
[2024-12-17 01:51:16,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:16,458][root][INFO] - Training Epoch: 1/2, step 2891/7134 completed (loss: 4.255438327789307, acc: 0.2666666805744171)
[2024-12-17 01:51:16,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:16,761][root][INFO] - Training Epoch: 1/2, step 2892/7134 completed (loss: 4.093730449676514, acc: 0.2840236723423004)
[2024-12-17 01:51:16,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:17,042][root][INFO] - Training Epoch: 1/2, step 2893/7134 completed (loss: 4.134947299957275, acc: 0.28961747884750366)
[2024-12-17 01:51:17,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:17,317][root][INFO] - Training Epoch: 1/2, step 2894/7134 completed (loss: 4.459136486053467, acc: 0.2518518567085266)
[2024-12-17 01:51:17,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:17,583][root][INFO] - Training Epoch: 1/2, step 2895/7134 completed (loss: 4.242519855499268, acc: 0.2711864411830902)
[2024-12-17 01:51:17,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:17,866][root][INFO] - Training Epoch: 1/2, step 2896/7134 completed (loss: 4.550034523010254, acc: 0.227544903755188)
[2024-12-17 01:51:18,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:18,162][root][INFO] - Training Epoch: 1/2, step 2897/7134 completed (loss: 4.656526565551758, acc: 0.27067670226097107)
[2024-12-17 01:51:18,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:18,440][root][INFO] - Training Epoch: 1/2, step 2898/7134 completed (loss: 3.6977503299713135, acc: 0.2663043439388275)
[2024-12-17 01:51:18,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:18,716][root][INFO] - Training Epoch: 1/2, step 2899/7134 completed (loss: 4.035635948181152, acc: 0.3053892254829407)
[2024-12-17 01:51:18,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:19,008][root][INFO] - Training Epoch: 1/2, step 2900/7134 completed (loss: 3.814659833908081, acc: 0.3085106313228607)
[2024-12-17 01:51:19,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:19,289][root][INFO] - Training Epoch: 1/2, step 2901/7134 completed (loss: 3.96728515625, acc: 0.23648647964000702)
[2024-12-17 01:51:19,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:19,584][root][INFO] - Training Epoch: 1/2, step 2902/7134 completed (loss: 4.128104209899902, acc: 0.28205129504203796)
[2024-12-17 01:51:19,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:19,865][root][INFO] - Training Epoch: 1/2, step 2903/7134 completed (loss: 3.9348487854003906, acc: 0.2921348214149475)
[2024-12-17 01:51:19,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:20,141][root][INFO] - Training Epoch: 1/2, step 2904/7134 completed (loss: 3.717440605163574, acc: 0.28108108043670654)
[2024-12-17 01:51:20,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:20,422][root][INFO] - Training Epoch: 1/2, step 2905/7134 completed (loss: 4.1519598960876465, acc: 0.2032085508108139)
[2024-12-17 01:51:20,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:20,713][root][INFO] - Training Epoch: 1/2, step 2906/7134 completed (loss: 4.266952991485596, acc: 0.2408376932144165)
[2024-12-17 01:51:20,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:21,001][root][INFO] - Training Epoch: 1/2, step 2907/7134 completed (loss: 4.32222843170166, acc: 0.2634730637073517)
[2024-12-17 01:51:21,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:21,279][root][INFO] - Training Epoch: 1/2, step 2908/7134 completed (loss: 3.9056506156921387, acc: 0.26436781883239746)
[2024-12-17 01:51:21,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:21,561][root][INFO] - Training Epoch: 1/2, step 2909/7134 completed (loss: 3.857661247253418, acc: 0.2568306028842926)
[2024-12-17 01:51:21,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:21,834][root][INFO] - Training Epoch: 1/2, step 2910/7134 completed (loss: 4.152607440948486, acc: 0.28342247009277344)
[2024-12-17 01:51:21,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:22,126][root][INFO] - Training Epoch: 1/2, step 2911/7134 completed (loss: 3.8440887928009033, acc: 0.30069929361343384)
[2024-12-17 01:51:22,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:22,420][root][INFO] - Training Epoch: 1/2, step 2912/7134 completed (loss: 3.8020713329315186, acc: 0.30821916460990906)
[2024-12-17 01:51:22,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:22,701][root][INFO] - Training Epoch: 1/2, step 2913/7134 completed (loss: 3.9961416721343994, acc: 0.316546767950058)
[2024-12-17 01:51:22,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:22,991][root][INFO] - Training Epoch: 1/2, step 2914/7134 completed (loss: 3.9397501945495605, acc: 0.3757575750350952)
[2024-12-17 01:51:23,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:23,288][root][INFO] - Training Epoch: 1/2, step 2915/7134 completed (loss: 4.28436279296875, acc: 0.25517240166664124)
[2024-12-17 01:51:23,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:23,553][root][INFO] - Training Epoch: 1/2, step 2916/7134 completed (loss: 3.8927385807037354, acc: 0.2719298303127289)
[2024-12-17 01:51:23,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:23,827][root][INFO] - Training Epoch: 1/2, step 2917/7134 completed (loss: 3.7472169399261475, acc: 0.3333333432674408)
[2024-12-17 01:51:23,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:24,097][root][INFO] - Training Epoch: 1/2, step 2918/7134 completed (loss: 3.5365092754364014, acc: 0.3684210479259491)
[2024-12-17 01:51:24,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:24,399][root][INFO] - Training Epoch: 1/2, step 2919/7134 completed (loss: 3.6882271766662598, acc: 0.34939759969711304)
[2024-12-17 01:51:24,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:24,698][root][INFO] - Training Epoch: 1/2, step 2920/7134 completed (loss: 3.7819409370422363, acc: 0.2830188572406769)
[2024-12-17 01:51:24,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:24,972][root][INFO] - Training Epoch: 1/2, step 2921/7134 completed (loss: 4.241717338562012, acc: 0.26428571343421936)
[2024-12-17 01:51:25,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:25,248][root][INFO] - Training Epoch: 1/2, step 2922/7134 completed (loss: 4.410181522369385, acc: 0.29447853565216064)
[2024-12-17 01:51:25,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:25,525][root][INFO] - Training Epoch: 1/2, step 2923/7134 completed (loss: 4.062721252441406, acc: 0.2887323796749115)
[2024-12-17 01:51:25,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:25,788][root][INFO] - Training Epoch: 1/2, step 2924/7134 completed (loss: 4.057149410247803, acc: 0.3109756112098694)
[2024-12-17 01:51:25,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:26,093][root][INFO] - Training Epoch: 1/2, step 2925/7134 completed (loss: 3.6487531661987305, acc: 0.38823530077934265)
[2024-12-17 01:51:26,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:26,395][root][INFO] - Training Epoch: 1/2, step 2926/7134 completed (loss: 3.7445194721221924, acc: 0.311557799577713)
[2024-12-17 01:51:26,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:26,677][root][INFO] - Training Epoch: 1/2, step 2927/7134 completed (loss: 4.156815052032471, acc: 0.27167630195617676)
[2024-12-17 01:51:26,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:26,973][root][INFO] - Training Epoch: 1/2, step 2928/7134 completed (loss: 3.88909912109375, acc: 0.3333333432674408)
[2024-12-17 01:51:27,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:27,325][root][INFO] - Training Epoch: 1/2, step 2929/7134 completed (loss: 3.9288218021392822, acc: 0.3333333432674408)
[2024-12-17 01:51:27,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:27,628][root][INFO] - Training Epoch: 1/2, step 2930/7134 completed (loss: 3.768272876739502, acc: 0.31292515993118286)
[2024-12-17 01:51:27,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:27,933][root][INFO] - Training Epoch: 1/2, step 2931/7134 completed (loss: 3.9714372158050537, acc: 0.30128204822540283)
[2024-12-17 01:51:28,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:28,204][root][INFO] - Training Epoch: 1/2, step 2932/7134 completed (loss: 3.874913215637207, acc: 0.29411765933036804)
[2024-12-17 01:51:28,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:28,488][root][INFO] - Training Epoch: 1/2, step 2933/7134 completed (loss: 4.316004276275635, acc: 0.2554744482040405)
[2024-12-17 01:51:28,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:28,787][root][INFO] - Training Epoch: 1/2, step 2934/7134 completed (loss: 3.7881839275360107, acc: 0.33571428060531616)
[2024-12-17 01:51:28,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:29,062][root][INFO] - Training Epoch: 1/2, step 2935/7134 completed (loss: 4.072342872619629, acc: 0.2857142984867096)
[2024-12-17 01:51:29,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:29,364][root][INFO] - Training Epoch: 1/2, step 2936/7134 completed (loss: 3.834057331085205, acc: 0.3407079577445984)
[2024-12-17 01:51:29,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:29,637][root][INFO] - Training Epoch: 1/2, step 2937/7134 completed (loss: 4.401188373565674, acc: 0.30882352590560913)
[2024-12-17 01:51:29,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:29,937][root][INFO] - Training Epoch: 1/2, step 2938/7134 completed (loss: 4.1731133460998535, acc: 0.26229506731033325)
[2024-12-17 01:51:30,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:30,224][root][INFO] - Training Epoch: 1/2, step 2939/7134 completed (loss: 4.4038262367248535, acc: 0.23178808391094208)
[2024-12-17 01:51:30,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:30,509][root][INFO] - Training Epoch: 1/2, step 2940/7134 completed (loss: 4.340312480926514, acc: 0.23497267067432404)
[2024-12-17 01:51:30,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:30,783][root][INFO] - Training Epoch: 1/2, step 2941/7134 completed (loss: 4.371917724609375, acc: 0.2415730357170105)
[2024-12-17 01:51:30,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:31,075][root][INFO] - Training Epoch: 1/2, step 2942/7134 completed (loss: 4.46221923828125, acc: 0.260606050491333)
[2024-12-17 01:51:31,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:31,343][root][INFO] - Training Epoch: 1/2, step 2943/7134 completed (loss: 4.387052536010742, acc: 0.2567567527294159)
[2024-12-17 01:51:31,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:31,624][root][INFO] - Training Epoch: 1/2, step 2944/7134 completed (loss: 4.058373928070068, acc: 0.3132530152797699)
[2024-12-17 01:51:31,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:31,928][root][INFO] - Training Epoch: 1/2, step 2945/7134 completed (loss: 3.9743263721466064, acc: 0.3288590610027313)
[2024-12-17 01:51:32,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:32,201][root][INFO] - Training Epoch: 1/2, step 2946/7134 completed (loss: 4.03027868270874, acc: 0.29629629850387573)
[2024-12-17 01:51:32,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:32,497][root][INFO] - Training Epoch: 1/2, step 2947/7134 completed (loss: 4.2420654296875, acc: 0.26249998807907104)
[2024-12-17 01:51:32,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:32,801][root][INFO] - Training Epoch: 1/2, step 2948/7134 completed (loss: 4.0322113037109375, acc: 0.3194444477558136)
[2024-12-17 01:51:32,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:33,120][root][INFO] - Training Epoch: 1/2, step 2949/7134 completed (loss: 3.886467456817627, acc: 0.27450981736183167)
[2024-12-17 01:51:33,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:33,399][root][INFO] - Training Epoch: 1/2, step 2950/7134 completed (loss: 3.79780650138855, acc: 0.2849161922931671)
[2024-12-17 01:51:33,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:33,676][root][INFO] - Training Epoch: 1/2, step 2951/7134 completed (loss: 3.763988733291626, acc: 0.32919254899024963)
[2024-12-17 01:51:33,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:33,951][root][INFO] - Training Epoch: 1/2, step 2952/7134 completed (loss: 4.2970499992370605, acc: 0.24203822016716003)
[2024-12-17 01:51:34,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:34,237][root][INFO] - Training Epoch: 1/2, step 2953/7134 completed (loss: 4.212284564971924, acc: 0.27210885286331177)
[2024-12-17 01:51:34,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:34,526][root][INFO] - Training Epoch: 1/2, step 2954/7134 completed (loss: 3.850889205932617, acc: 0.32474225759506226)
[2024-12-17 01:51:34,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:34,798][root][INFO] - Training Epoch: 1/2, step 2955/7134 completed (loss: 4.006424427032471, acc: 0.2666666805744171)
[2024-12-17 01:51:34,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:35,108][root][INFO] - Training Epoch: 1/2, step 2956/7134 completed (loss: 3.9338557720184326, acc: 0.30674847960472107)
[2024-12-17 01:51:35,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:35,416][root][INFO] - Training Epoch: 1/2, step 2957/7134 completed (loss: 4.17933464050293, acc: 0.27586206793785095)
[2024-12-17 01:51:35,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:35,691][root][INFO] - Training Epoch: 1/2, step 2958/7134 completed (loss: 3.8016819953918457, acc: 0.2986111044883728)
[2024-12-17 01:51:35,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:35,955][root][INFO] - Training Epoch: 1/2, step 2959/7134 completed (loss: 4.087564945220947, acc: 0.2405063360929489)
[2024-12-17 01:51:36,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:36,242][root][INFO] - Training Epoch: 1/2, step 2960/7134 completed (loss: 3.9299283027648926, acc: 0.2967033088207245)
[2024-12-17 01:51:36,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:36,545][root][INFO] - Training Epoch: 1/2, step 2961/7134 completed (loss: 3.621495008468628, acc: 0.3353293538093567)
[2024-12-17 01:51:36,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:36,826][root][INFO] - Training Epoch: 1/2, step 2962/7134 completed (loss: 3.7457828521728516, acc: 0.3214285671710968)
[2024-12-17 01:51:36,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:37,114][root][INFO] - Training Epoch: 1/2, step 2963/7134 completed (loss: 3.7798373699188232, acc: 0.2681564390659332)
[2024-12-17 01:51:37,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:37,407][root][INFO] - Training Epoch: 1/2, step 2964/7134 completed (loss: 3.934347629547119, acc: 0.30666667222976685)
[2024-12-17 01:51:37,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:37,701][root][INFO] - Training Epoch: 1/2, step 2965/7134 completed (loss: 4.203213691711426, acc: 0.3011363744735718)
[2024-12-17 01:51:37,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:37,995][root][INFO] - Training Epoch: 1/2, step 2966/7134 completed (loss: 3.8603687286376953, acc: 0.3162393271923065)
[2024-12-17 01:51:38,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:38,298][root][INFO] - Training Epoch: 1/2, step 2967/7134 completed (loss: 4.249817371368408, acc: 0.284153014421463)
[2024-12-17 01:51:38,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:38,615][root][INFO] - Training Epoch: 1/2, step 2968/7134 completed (loss: 4.961700439453125, acc: 0.23749999701976776)
[2024-12-17 01:51:38,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:38,892][root][INFO] - Training Epoch: 1/2, step 2969/7134 completed (loss: 4.991836071014404, acc: 0.1553398072719574)
[2024-12-17 01:51:39,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:39,175][root][INFO] - Training Epoch: 1/2, step 2970/7134 completed (loss: 5.187362194061279, acc: 0.23880596458911896)
[2024-12-17 01:51:39,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:39,453][root][INFO] - Training Epoch: 1/2, step 2971/7134 completed (loss: 3.961306095123291, acc: 0.36464089155197144)
[2024-12-17 01:51:39,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:39,728][root][INFO] - Training Epoch: 1/2, step 2972/7134 completed (loss: 4.568800926208496, acc: 0.2866666615009308)
[2024-12-17 01:51:39,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:40,006][root][INFO] - Training Epoch: 1/2, step 2973/7134 completed (loss: 4.1863603591918945, acc: 0.290909081697464)
[2024-12-17 01:51:40,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:40,290][root][INFO] - Training Epoch: 1/2, step 2974/7134 completed (loss: 4.049932956695557, acc: 0.3801169693470001)
[2024-12-17 01:51:40,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:40,571][root][INFO] - Training Epoch: 1/2, step 2975/7134 completed (loss: 4.080596446990967, acc: 0.26744186878204346)
[2024-12-17 01:51:40,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:40,865][root][INFO] - Training Epoch: 1/2, step 2976/7134 completed (loss: 3.7033932209014893, acc: 0.3679245412349701)
[2024-12-17 01:51:41,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:41,169][root][INFO] - Training Epoch: 1/2, step 2977/7134 completed (loss: 4.159900188446045, acc: 0.2620689570903778)
[2024-12-17 01:51:41,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:41,450][root][INFO] - Training Epoch: 1/2, step 2978/7134 completed (loss: 3.937953233718872, acc: 0.3072289228439331)
[2024-12-17 01:51:41,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:41,737][root][INFO] - Training Epoch: 1/2, step 2979/7134 completed (loss: 3.946425437927246, acc: 0.3724137842655182)
[2024-12-17 01:51:41,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:42,026][root][INFO] - Training Epoch: 1/2, step 2980/7134 completed (loss: 4.44508695602417, acc: 0.2800000011920929)
[2024-12-17 01:51:42,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:42,328][root][INFO] - Training Epoch: 1/2, step 2981/7134 completed (loss: 4.113526344299316, acc: 0.28735631704330444)
[2024-12-17 01:51:42,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:42,625][root][INFO] - Training Epoch: 1/2, step 2982/7134 completed (loss: 4.367372035980225, acc: 0.3076923191547394)
[2024-12-17 01:51:42,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:42,913][root][INFO] - Training Epoch: 1/2, step 2983/7134 completed (loss: 4.305528163909912, acc: 0.2638036906719208)
[2024-12-17 01:51:43,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:43,250][root][INFO] - Training Epoch: 1/2, step 2984/7134 completed (loss: 3.954204559326172, acc: 0.3351648449897766)
[2024-12-17 01:51:43,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:43,537][root][INFO] - Training Epoch: 1/2, step 2985/7134 completed (loss: 3.595844268798828, acc: 0.2926829159259796)
[2024-12-17 01:51:43,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:43,831][root][INFO] - Training Epoch: 1/2, step 2986/7134 completed (loss: 4.176172256469727, acc: 0.2525773048400879)
[2024-12-17 01:51:43,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:44,114][root][INFO] - Training Epoch: 1/2, step 2987/7134 completed (loss: 3.8280112743377686, acc: 0.32065218687057495)
[2024-12-17 01:51:44,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:44,400][root][INFO] - Training Epoch: 1/2, step 2988/7134 completed (loss: 4.160143852233887, acc: 0.24864864349365234)
[2024-12-17 01:51:44,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:44,692][root][INFO] - Training Epoch: 1/2, step 2989/7134 completed (loss: 4.270267963409424, acc: 0.28143712878227234)
[2024-12-17 01:51:44,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:44,967][root][INFO] - Training Epoch: 1/2, step 2990/7134 completed (loss: 4.347081184387207, acc: 0.2635135054588318)
[2024-12-17 01:51:45,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:45,245][root][INFO] - Training Epoch: 1/2, step 2991/7134 completed (loss: 4.919553279876709, acc: 0.2447916716337204)
[2024-12-17 01:51:45,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:45,508][root][INFO] - Training Epoch: 1/2, step 2992/7134 completed (loss: 4.4015398025512695, acc: 0.2641509473323822)
[2024-12-17 01:51:45,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:45,797][root][INFO] - Training Epoch: 1/2, step 2993/7134 completed (loss: 3.688525915145874, acc: 0.29145729541778564)
[2024-12-17 01:51:45,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:46,069][root][INFO] - Training Epoch: 1/2, step 2994/7134 completed (loss: 4.139652729034424, acc: 0.30158731341362)
[2024-12-17 01:51:46,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:46,375][root][INFO] - Training Epoch: 1/2, step 2995/7134 completed (loss: 3.9720139503479004, acc: 0.29611650109291077)
[2024-12-17 01:51:46,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:46,640][root][INFO] - Training Epoch: 1/2, step 2996/7134 completed (loss: 3.9517810344696045, acc: 0.26288658380508423)
[2024-12-17 01:51:46,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:46,920][root][INFO] - Training Epoch: 1/2, step 2997/7134 completed (loss: 3.8568193912506104, acc: 0.2924528419971466)
[2024-12-17 01:51:47,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:47,179][root][INFO] - Training Epoch: 1/2, step 2998/7134 completed (loss: 3.8813352584838867, acc: 0.3154761791229248)
[2024-12-17 01:51:47,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:47,485][root][INFO] - Training Epoch: 1/2, step 2999/7134 completed (loss: 4.0124640464782715, acc: 0.3187499940395355)
[2024-12-17 01:51:47,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:47,796][root][INFO] - Training Epoch: 1/2, step 3000/7134 completed (loss: 4.0305585861206055, acc: 0.34259259700775146)
[2024-12-17 01:51:47,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:48,080][root][INFO] - Training Epoch: 1/2, step 3001/7134 completed (loss: 3.855048418045044, acc: 0.3299492299556732)
[2024-12-17 01:51:48,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:48,359][root][INFO] - Training Epoch: 1/2, step 3002/7134 completed (loss: 3.874389886856079, acc: 0.3410138189792633)
[2024-12-17 01:51:48,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:48,643][root][INFO] - Training Epoch: 1/2, step 3003/7134 completed (loss: 3.752129316329956, acc: 0.29949238896369934)
[2024-12-17 01:51:48,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:48,921][root][INFO] - Training Epoch: 1/2, step 3004/7134 completed (loss: 3.7666118144989014, acc: 0.3118811845779419)
[2024-12-17 01:51:49,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:49,233][root][INFO] - Training Epoch: 1/2, step 3005/7134 completed (loss: 4.05192756652832, acc: 0.2849740982055664)
[2024-12-17 01:51:49,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:49,521][root][INFO] - Training Epoch: 1/2, step 3006/7134 completed (loss: 3.4861323833465576, acc: 0.3257142901420593)
[2024-12-17 01:51:49,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:49,792][root][INFO] - Training Epoch: 1/2, step 3007/7134 completed (loss: 4.111863136291504, acc: 0.25581395626068115)
[2024-12-17 01:51:49,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:50,060][root][INFO] - Training Epoch: 1/2, step 3008/7134 completed (loss: 4.308694839477539, acc: 0.3333333432674408)
[2024-12-17 01:51:50,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:50,334][root][INFO] - Training Epoch: 1/2, step 3009/7134 completed (loss: 3.941216230392456, acc: 0.3452380895614624)
[2024-12-17 01:51:50,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:50,616][root][INFO] - Training Epoch: 1/2, step 3010/7134 completed (loss: 3.836988687515259, acc: 0.34285715222358704)
[2024-12-17 01:51:50,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:50,897][root][INFO] - Training Epoch: 1/2, step 3011/7134 completed (loss: 4.034639358520508, acc: 0.38787877559661865)
[2024-12-17 01:51:51,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:51,179][root][INFO] - Training Epoch: 1/2, step 3012/7134 completed (loss: 4.253652572631836, acc: 0.3309352397918701)
[2024-12-17 01:51:51,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:51,472][root][INFO] - Training Epoch: 1/2, step 3013/7134 completed (loss: 3.998075008392334, acc: 0.33139535784721375)
[2024-12-17 01:51:51,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:51,755][root][INFO] - Training Epoch: 1/2, step 3014/7134 completed (loss: 4.022990703582764, acc: 0.32278481125831604)
[2024-12-17 01:51:51,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:52,013][root][INFO] - Training Epoch: 1/2, step 3015/7134 completed (loss: 4.467719078063965, acc: 0.30985915660858154)
[2024-12-17 01:51:52,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:52,298][root][INFO] - Training Epoch: 1/2, step 3016/7134 completed (loss: 4.214658737182617, acc: 0.267123281955719)
[2024-12-17 01:51:52,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:52,568][root][INFO] - Training Epoch: 1/2, step 3017/7134 completed (loss: 3.8963217735290527, acc: 0.3471074402332306)
[2024-12-17 01:51:52,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:52,841][root][INFO] - Training Epoch: 1/2, step 3018/7134 completed (loss: 3.9411280155181885, acc: 0.2748091518878937)
[2024-12-17 01:51:52,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:53,126][root][INFO] - Training Epoch: 1/2, step 3019/7134 completed (loss: 3.709169387817383, acc: 0.30882352590560913)
[2024-12-17 01:51:53,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:53,401][root][INFO] - Training Epoch: 1/2, step 3020/7134 completed (loss: 4.010368347167969, acc: 0.316546767950058)
[2024-12-17 01:51:53,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:53,710][root][INFO] - Training Epoch: 1/2, step 3021/7134 completed (loss: 3.415132999420166, acc: 0.3484848439693451)
[2024-12-17 01:51:53,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:54,021][root][INFO] - Training Epoch: 1/2, step 3022/7134 completed (loss: 3.682528018951416, acc: 0.2857142984867096)
[2024-12-17 01:51:54,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:54,317][root][INFO] - Training Epoch: 1/2, step 3023/7134 completed (loss: 3.6316025257110596, acc: 0.35384616255760193)
[2024-12-17 01:51:54,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:54,610][root][INFO] - Training Epoch: 1/2, step 3024/7134 completed (loss: 3.723339796066284, acc: 0.2750000059604645)
[2024-12-17 01:51:54,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:54,888][root][INFO] - Training Epoch: 1/2, step 3025/7134 completed (loss: 4.161413669586182, acc: 0.26153847575187683)
[2024-12-17 01:51:55,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:55,171][root][INFO] - Training Epoch: 1/2, step 3026/7134 completed (loss: 3.7280924320220947, acc: 0.31147539615631104)
[2024-12-17 01:51:55,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:55,451][root][INFO] - Training Epoch: 1/2, step 3027/7134 completed (loss: 4.317867755889893, acc: 0.3125)
[2024-12-17 01:51:55,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:55,694][root][INFO] - Training Epoch: 1/2, step 3028/7134 completed (loss: 3.621304512023926, acc: 0.2680412232875824)
[2024-12-17 01:51:55,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:55,959][root][INFO] - Training Epoch: 1/2, step 3029/7134 completed (loss: 3.693267345428467, acc: 0.31506848335266113)
[2024-12-17 01:51:56,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:56,257][root][INFO] - Training Epoch: 1/2, step 3030/7134 completed (loss: 3.8742637634277344, acc: 0.29054054617881775)
[2024-12-17 01:51:56,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:56,521][root][INFO] - Training Epoch: 1/2, step 3031/7134 completed (loss: 4.141242027282715, acc: 0.28282827138900757)
[2024-12-17 01:51:56,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:56,805][root][INFO] - Training Epoch: 1/2, step 3032/7134 completed (loss: 3.7951457500457764, acc: 0.3306451737880707)
[2024-12-17 01:51:56,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:57,083][root][INFO] - Training Epoch: 1/2, step 3033/7134 completed (loss: 4.164309978485107, acc: 0.265625)
[2024-12-17 01:51:57,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:57,370][root][INFO] - Training Epoch: 1/2, step 3034/7134 completed (loss: 4.455774784088135, acc: 0.2432432472705841)
[2024-12-17 01:51:57,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:57,630][root][INFO] - Training Epoch: 1/2, step 3035/7134 completed (loss: 3.953998565673828, acc: 0.2789115607738495)
[2024-12-17 01:51:57,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:57,898][root][INFO] - Training Epoch: 1/2, step 3036/7134 completed (loss: 4.587207794189453, acc: 0.31200000643730164)
[2024-12-17 01:51:58,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:58,186][root][INFO] - Training Epoch: 1/2, step 3037/7134 completed (loss: 4.080109596252441, acc: 0.3221476376056671)
[2024-12-17 01:51:58,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:58,472][root][INFO] - Training Epoch: 1/2, step 3038/7134 completed (loss: 4.303959369659424, acc: 0.26865673065185547)
[2024-12-17 01:51:58,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:58,756][root][INFO] - Training Epoch: 1/2, step 3039/7134 completed (loss: 3.8807380199432373, acc: 0.27702704071998596)
[2024-12-17 01:51:58,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:59,057][root][INFO] - Training Epoch: 1/2, step 3040/7134 completed (loss: 3.7065138816833496, acc: 0.3255814015865326)
[2024-12-17 01:51:59,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:59,339][root][INFO] - Training Epoch: 1/2, step 3041/7134 completed (loss: 3.5904316902160645, acc: 0.3642857074737549)
[2024-12-17 01:51:59,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:59,617][root][INFO] - Training Epoch: 1/2, step 3042/7134 completed (loss: 4.17926549911499, acc: 0.2628205120563507)
[2024-12-17 01:51:59,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:59,891][root][INFO] - Training Epoch: 1/2, step 3043/7134 completed (loss: 4.532043933868408, acc: 0.2321428507566452)
[2024-12-17 01:52:00,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:00,162][root][INFO] - Training Epoch: 1/2, step 3044/7134 completed (loss: 4.258441925048828, acc: 0.2631579041481018)
[2024-12-17 01:52:00,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:00,435][root][INFO] - Training Epoch: 1/2, step 3045/7134 completed (loss: 3.6596157550811768, acc: 0.27906978130340576)
[2024-12-17 01:52:00,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:00,722][root][INFO] - Training Epoch: 1/2, step 3046/7134 completed (loss: 4.024319648742676, acc: 0.24852071702480316)
[2024-12-17 01:52:00,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:01,016][root][INFO] - Training Epoch: 1/2, step 3047/7134 completed (loss: 3.966308355331421, acc: 0.299435019493103)
[2024-12-17 01:52:01,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:01,376][root][INFO] - Training Epoch: 1/2, step 3048/7134 completed (loss: 3.8913636207580566, acc: 0.2947368323802948)
[2024-12-17 01:52:01,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:01,662][root][INFO] - Training Epoch: 1/2, step 3049/7134 completed (loss: 4.316274166107178, acc: 0.23125000298023224)
[2024-12-17 01:52:01,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:01,964][root][INFO] - Training Epoch: 1/2, step 3050/7134 completed (loss: 3.8473317623138428, acc: 0.32487308979034424)
[2024-12-17 01:52:02,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:02,239][root][INFO] - Training Epoch: 1/2, step 3051/7134 completed (loss: 4.540704250335693, acc: 0.25)
[2024-12-17 01:52:02,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:02,520][root][INFO] - Training Epoch: 1/2, step 3052/7134 completed (loss: 3.873209238052368, acc: 0.3405405282974243)
[2024-12-17 01:52:02,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:02,798][root][INFO] - Training Epoch: 1/2, step 3053/7134 completed (loss: 3.518470525741577, acc: 0.30845770239830017)
[2024-12-17 01:52:02,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:03,078][root][INFO] - Training Epoch: 1/2, step 3054/7134 completed (loss: 3.4005520343780518, acc: 0.33510637283325195)
[2024-12-17 01:52:03,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:03,361][root][INFO] - Training Epoch: 1/2, step 3055/7134 completed (loss: 3.6510331630706787, acc: 0.3378378450870514)
[2024-12-17 01:52:03,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:03,661][root][INFO] - Training Epoch: 1/2, step 3056/7134 completed (loss: 4.118430137634277, acc: 0.3081081211566925)
[2024-12-17 01:52:03,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:03,952][root][INFO] - Training Epoch: 1/2, step 3057/7134 completed (loss: 3.735917806625366, acc: 0.28834354877471924)
[2024-12-17 01:52:04,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:04,227][root][INFO] - Training Epoch: 1/2, step 3058/7134 completed (loss: 3.592144250869751, acc: 0.3210526406764984)
[2024-12-17 01:52:04,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:04,499][root][INFO] - Training Epoch: 1/2, step 3059/7134 completed (loss: 3.4664011001586914, acc: 0.2742857038974762)
[2024-12-17 01:52:04,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:04,780][root][INFO] - Training Epoch: 1/2, step 3060/7134 completed (loss: 3.876474142074585, acc: 0.24607330560684204)
[2024-12-17 01:52:04,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:05,076][root][INFO] - Training Epoch: 1/2, step 3061/7134 completed (loss: 4.188689231872559, acc: 0.2874999940395355)
[2024-12-17 01:52:05,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:05,353][root][INFO] - Training Epoch: 1/2, step 3062/7134 completed (loss: 3.613436698913574, acc: 0.29559749364852905)
[2024-12-17 01:52:05,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:05,628][root][INFO] - Training Epoch: 1/2, step 3063/7134 completed (loss: 3.9695487022399902, acc: 0.3295454680919647)
[2024-12-17 01:52:05,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:05,910][root][INFO] - Training Epoch: 1/2, step 3064/7134 completed (loss: 3.721595525741577, acc: 0.3550295829772949)
[2024-12-17 01:52:06,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:06,200][root][INFO] - Training Epoch: 1/2, step 3065/7134 completed (loss: 3.369664192199707, acc: 0.33707866072654724)
[2024-12-17 01:52:06,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:06,487][root][INFO] - Training Epoch: 1/2, step 3066/7134 completed (loss: 3.866861343383789, acc: 0.2781457006931305)
[2024-12-17 01:52:06,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:06,793][root][INFO] - Training Epoch: 1/2, step 3067/7134 completed (loss: 3.5656094551086426, acc: 0.30882352590560913)
[2024-12-17 01:52:06,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:07,089][root][INFO] - Training Epoch: 1/2, step 3068/7134 completed (loss: 3.4974942207336426, acc: 0.31284916400909424)
[2024-12-17 01:52:07,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:07,365][root][INFO] - Training Epoch: 1/2, step 3069/7134 completed (loss: 3.4731180667877197, acc: 0.2908163368701935)
[2024-12-17 01:52:07,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:07,657][root][INFO] - Training Epoch: 1/2, step 3070/7134 completed (loss: 3.4782755374908447, acc: 0.330143541097641)
[2024-12-17 01:52:07,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:07,941][root][INFO] - Training Epoch: 1/2, step 3071/7134 completed (loss: 3.5778005123138428, acc: 0.32777777314186096)
[2024-12-17 01:52:08,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:08,221][root][INFO] - Training Epoch: 1/2, step 3072/7134 completed (loss: 3.3095245361328125, acc: 0.35680750012397766)
[2024-12-17 01:52:08,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:08,490][root][INFO] - Training Epoch: 1/2, step 3073/7134 completed (loss: 3.909550666809082, acc: 0.28248587250709534)
[2024-12-17 01:52:08,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:08,788][root][INFO] - Training Epoch: 1/2, step 3074/7134 completed (loss: 3.490540027618408, acc: 0.3245033025741577)
[2024-12-17 01:52:08,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:09,068][root][INFO] - Training Epoch: 1/2, step 3075/7134 completed (loss: 3.2895495891571045, acc: 0.37654322385787964)
[2024-12-17 01:52:09,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:09,356][root][INFO] - Training Epoch: 1/2, step 3076/7134 completed (loss: 3.5859944820404053, acc: 0.35483869910240173)
[2024-12-17 01:52:09,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:09,662][root][INFO] - Training Epoch: 1/2, step 3077/7134 completed (loss: 3.4773025512695312, acc: 0.3821989595890045)
[2024-12-17 01:52:09,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:09,944][root][INFO] - Training Epoch: 1/2, step 3078/7134 completed (loss: 3.861588478088379, acc: 0.3177083432674408)
[2024-12-17 01:52:10,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:10,228][root][INFO] - Training Epoch: 1/2, step 3079/7134 completed (loss: 3.5334861278533936, acc: 0.33862432837486267)
[2024-12-17 01:52:10,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:10,516][root][INFO] - Training Epoch: 1/2, step 3080/7134 completed (loss: 3.851370334625244, acc: 0.34259259700775146)
[2024-12-17 01:52:10,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:10,803][root][INFO] - Training Epoch: 1/2, step 3081/7134 completed (loss: 4.5453200340271, acc: 0.19801980257034302)
[2024-12-17 01:52:10,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:11,080][root][INFO] - Training Epoch: 1/2, step 3082/7134 completed (loss: 4.192201614379883, acc: 0.3034825921058655)
[2024-12-17 01:52:11,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:11,362][root][INFO] - Training Epoch: 1/2, step 3083/7134 completed (loss: 3.8681156635284424, acc: 0.28108108043670654)
[2024-12-17 01:52:11,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:11,635][root][INFO] - Training Epoch: 1/2, step 3084/7134 completed (loss: 4.24275541305542, acc: 0.30890053510665894)
[2024-12-17 01:52:11,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:11,962][root][INFO] - Training Epoch: 1/2, step 3085/7134 completed (loss: 4.360900402069092, acc: 0.2709677517414093)
[2024-12-17 01:52:12,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:12,260][root][INFO] - Training Epoch: 1/2, step 3086/7134 completed (loss: 3.974881649017334, acc: 0.34246575832366943)
[2024-12-17 01:52:12,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:12,547][root][INFO] - Training Epoch: 1/2, step 3087/7134 completed (loss: 3.878006935119629, acc: 0.2958579957485199)
[2024-12-17 01:52:12,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:12,833][root][INFO] - Training Epoch: 1/2, step 3088/7134 completed (loss: 4.098865509033203, acc: 0.26635512709617615)
[2024-12-17 01:52:12,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:13,125][root][INFO] - Training Epoch: 1/2, step 3089/7134 completed (loss: 3.9010438919067383, acc: 0.31162789463996887)
[2024-12-17 01:52:13,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:13,408][root][INFO] - Training Epoch: 1/2, step 3090/7134 completed (loss: 4.452964782714844, acc: 0.23163841664791107)
[2024-12-17 01:52:13,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:13,708][root][INFO] - Training Epoch: 1/2, step 3091/7134 completed (loss: 4.485228061676025, acc: 0.2360514998435974)
[2024-12-17 01:52:13,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:13,983][root][INFO] - Training Epoch: 1/2, step 3092/7134 completed (loss: 4.479687690734863, acc: 0.28244274854660034)
[2024-12-17 01:52:14,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:14,264][root][INFO] - Training Epoch: 1/2, step 3093/7134 completed (loss: 4.081949710845947, acc: 0.27699530124664307)
[2024-12-17 01:52:14,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:14,553][root][INFO] - Training Epoch: 1/2, step 3094/7134 completed (loss: 4.19337797164917, acc: 0.24277456104755402)
[2024-12-17 01:52:14,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:14,828][root][INFO] - Training Epoch: 1/2, step 3095/7134 completed (loss: 3.7639248371124268, acc: 0.30000001192092896)
[2024-12-17 01:52:14,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:15,109][root][INFO] - Training Epoch: 1/2, step 3096/7134 completed (loss: 4.3653740882873535, acc: 0.2931937277317047)
[2024-12-17 01:52:15,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:15,419][root][INFO] - Training Epoch: 1/2, step 3097/7134 completed (loss: 4.215681076049805, acc: 0.2804878056049347)
[2024-12-17 01:52:15,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:15,711][root][INFO] - Training Epoch: 1/2, step 3098/7134 completed (loss: 4.508893013000488, acc: 0.26143792271614075)
[2024-12-17 01:52:15,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:15,979][root][INFO] - Training Epoch: 1/2, step 3099/7134 completed (loss: 4.536272048950195, acc: 0.21897810697555542)
[2024-12-17 01:52:16,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:16,270][root][INFO] - Training Epoch: 1/2, step 3100/7134 completed (loss: 3.8361358642578125, acc: 0.3228699564933777)
[2024-12-17 01:52:16,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:16,558][root][INFO] - Training Epoch: 1/2, step 3101/7134 completed (loss: 4.196720123291016, acc: 0.2893401086330414)
[2024-12-17 01:52:16,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:16,851][root][INFO] - Training Epoch: 1/2, step 3102/7134 completed (loss: 3.694392204284668, acc: 0.3680981695652008)
[2024-12-17 01:52:16,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:17,138][root][INFO] - Training Epoch: 1/2, step 3103/7134 completed (loss: 3.9547083377838135, acc: 0.27586206793785095)
[2024-12-17 01:52:17,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:17,395][root][INFO] - Training Epoch: 1/2, step 3104/7134 completed (loss: 3.6881847381591797, acc: 0.3255814015865326)
[2024-12-17 01:52:17,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:17,660][root][INFO] - Training Epoch: 1/2, step 3105/7134 completed (loss: 4.01872444152832, acc: 0.27826085686683655)
[2024-12-17 01:52:17,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:17,958][root][INFO] - Training Epoch: 1/2, step 3106/7134 completed (loss: 3.951312780380249, acc: 0.2281879186630249)
[2024-12-17 01:52:18,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:18,255][root][INFO] - Training Epoch: 1/2, step 3107/7134 completed (loss: 3.8089215755462646, acc: 0.33139535784721375)
[2024-12-17 01:52:18,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:18,556][root][INFO] - Training Epoch: 1/2, step 3108/7134 completed (loss: 3.8338735103607178, acc: 0.2789115607738495)
[2024-12-17 01:52:18,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:18,858][root][INFO] - Training Epoch: 1/2, step 3109/7134 completed (loss: 4.710157871246338, acc: 0.2538461685180664)
[2024-12-17 01:52:18,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:19,140][root][INFO] - Training Epoch: 1/2, step 3110/7134 completed (loss: 4.0725555419921875, acc: 0.223300963640213)
[2024-12-17 01:52:19,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:19,426][root][INFO] - Training Epoch: 1/2, step 3111/7134 completed (loss: 5.048604488372803, acc: 0.25362318754196167)
[2024-12-17 01:52:19,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:19,692][root][INFO] - Training Epoch: 1/2, step 3112/7134 completed (loss: 5.0588202476501465, acc: 0.22627736628055573)
[2024-12-17 01:52:19,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:20,011][root][INFO] - Training Epoch: 1/2, step 3113/7134 completed (loss: 4.753187656402588, acc: 0.3109756112098694)
[2024-12-17 01:52:20,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:20,288][root][INFO] - Training Epoch: 1/2, step 3114/7134 completed (loss: 4.406426906585693, acc: 0.21052631735801697)
[2024-12-17 01:52:20,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:20,584][root][INFO] - Training Epoch: 1/2, step 3115/7134 completed (loss: 4.369393825531006, acc: 0.29605263471603394)
[2024-12-17 01:52:20,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:20,873][root][INFO] - Training Epoch: 1/2, step 3116/7134 completed (loss: 4.696151256561279, acc: 0.2768361568450928)
[2024-12-17 01:52:20,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:21,152][root][INFO] - Training Epoch: 1/2, step 3117/7134 completed (loss: 4.566310405731201, acc: 0.25280898809432983)
[2024-12-17 01:52:21,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:21,422][root][INFO] - Training Epoch: 1/2, step 3118/7134 completed (loss: 4.766489028930664, acc: 0.23756906390190125)
[2024-12-17 01:52:21,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:21,710][root][INFO] - Training Epoch: 1/2, step 3119/7134 completed (loss: 4.250950813293457, acc: 0.35449734330177307)
[2024-12-17 01:52:21,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:22,008][root][INFO] - Training Epoch: 1/2, step 3120/7134 completed (loss: 4.233656883239746, acc: 0.2839506268501282)
[2024-12-17 01:52:22,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:22,288][root][INFO] - Training Epoch: 1/2, step 3121/7134 completed (loss: 4.518810749053955, acc: 0.28409090638160706)
[2024-12-17 01:52:22,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:22,580][root][INFO] - Training Epoch: 1/2, step 3122/7134 completed (loss: 4.424320220947266, acc: 0.28421053290367126)
[2024-12-17 01:52:22,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:22,868][root][INFO] - Training Epoch: 1/2, step 3123/7134 completed (loss: 4.503234386444092, acc: 0.23243242502212524)
[2024-12-17 01:52:22,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:23,136][root][INFO] - Training Epoch: 1/2, step 3124/7134 completed (loss: 4.61558723449707, acc: 0.2666666805744171)
[2024-12-17 01:52:23,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:23,411][root][INFO] - Training Epoch: 1/2, step 3125/7134 completed (loss: 4.431693077087402, acc: 0.2380952388048172)
[2024-12-17 01:52:23,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:23,734][root][INFO] - Training Epoch: 1/2, step 3126/7134 completed (loss: 4.494879722595215, acc: 0.22346368432044983)
[2024-12-17 01:52:23,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:24,034][root][INFO] - Training Epoch: 1/2, step 3127/7134 completed (loss: 4.040369033813477, acc: 0.27230048179626465)
[2024-12-17 01:52:24,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:24,320][root][INFO] - Training Epoch: 1/2, step 3128/7134 completed (loss: 4.208820819854736, acc: 0.29946523904800415)
[2024-12-17 01:52:24,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:24,609][root][INFO] - Training Epoch: 1/2, step 3129/7134 completed (loss: 4.886917591094971, acc: 0.22727273404598236)
[2024-12-17 01:52:24,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:24,930][root][INFO] - Training Epoch: 1/2, step 3130/7134 completed (loss: 4.280375003814697, acc: 0.2690355181694031)
[2024-12-17 01:52:25,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:25,225][root][INFO] - Training Epoch: 1/2, step 3131/7134 completed (loss: 4.2439751625061035, acc: 0.24858756363391876)
[2024-12-17 01:52:25,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:25,533][root][INFO] - Training Epoch: 1/2, step 3132/7134 completed (loss: 4.2072319984436035, acc: 0.2566371560096741)
[2024-12-17 01:52:25,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:25,831][root][INFO] - Training Epoch: 1/2, step 3133/7134 completed (loss: 4.193227291107178, acc: 0.28409090638160706)
[2024-12-17 01:52:25,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:26,117][root][INFO] - Training Epoch: 1/2, step 3134/7134 completed (loss: 3.648336887359619, acc: 0.375)
[2024-12-17 01:52:26,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:26,371][root][INFO] - Training Epoch: 1/2, step 3135/7134 completed (loss: 3.8128104209899902, acc: 0.34020617604255676)
[2024-12-17 01:52:26,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:26,650][root][INFO] - Training Epoch: 1/2, step 3136/7134 completed (loss: 4.174223899841309, acc: 0.25190839171409607)
[2024-12-17 01:52:26,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:26,954][root][INFO] - Training Epoch: 1/2, step 3137/7134 completed (loss: 4.049947738647461, acc: 0.3191489279270172)
[2024-12-17 01:52:27,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:27,226][root][INFO] - Training Epoch: 1/2, step 3138/7134 completed (loss: 3.9400346279144287, acc: 0.2777777910232544)
[2024-12-17 01:52:27,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:27,481][root][INFO] - Training Epoch: 1/2, step 3139/7134 completed (loss: 4.286890506744385, acc: 0.23021583259105682)
[2024-12-17 01:52:27,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:27,748][root][INFO] - Training Epoch: 1/2, step 3140/7134 completed (loss: 3.552090883255005, acc: 0.34246575832366943)
[2024-12-17 01:52:27,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:28,022][root][INFO] - Training Epoch: 1/2, step 3141/7134 completed (loss: 4.269810676574707, acc: 0.25)
[2024-12-17 01:52:28,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:28,289][root][INFO] - Training Epoch: 1/2, step 3142/7134 completed (loss: 4.17077112197876, acc: 0.257485032081604)
[2024-12-17 01:52:28,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:28,579][root][INFO] - Training Epoch: 1/2, step 3143/7134 completed (loss: 3.950324773788452, acc: 0.2709677517414093)
[2024-12-17 01:52:28,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:28,872][root][INFO] - Training Epoch: 1/2, step 3144/7134 completed (loss: 4.179927825927734, acc: 0.26923078298568726)
[2024-12-17 01:52:28,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:29,149][root][INFO] - Training Epoch: 1/2, step 3145/7134 completed (loss: 4.001286506652832, acc: 0.28828829526901245)
[2024-12-17 01:52:29,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:29,421][root][INFO] - Training Epoch: 1/2, step 3146/7134 completed (loss: 3.4745872020721436, acc: 0.38383838534355164)
[2024-12-17 01:52:29,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:29,691][root][INFO] - Training Epoch: 1/2, step 3147/7134 completed (loss: 3.719555616378784, acc: 0.33561643958091736)
[2024-12-17 01:52:29,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:29,969][root][INFO] - Training Epoch: 1/2, step 3148/7134 completed (loss: 3.8950400352478027, acc: 0.3072625696659088)
[2024-12-17 01:52:30,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:30,245][root][INFO] - Training Epoch: 1/2, step 3149/7134 completed (loss: 4.022671699523926, acc: 0.2709677517414093)
[2024-12-17 01:52:30,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:30,525][root][INFO] - Training Epoch: 1/2, step 3150/7134 completed (loss: 4.500157356262207, acc: 0.2928571403026581)
[2024-12-17 01:52:30,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:30,792][root][INFO] - Training Epoch: 1/2, step 3151/7134 completed (loss: 4.623484134674072, acc: 0.3129771053791046)
[2024-12-17 01:52:30,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:31,048][root][INFO] - Training Epoch: 1/2, step 3152/7134 completed (loss: 4.593647003173828, acc: 0.2535211145877838)
[2024-12-17 01:52:31,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:31,323][root][INFO] - Training Epoch: 1/2, step 3153/7134 completed (loss: 4.103616237640381, acc: 0.3483146131038666)
[2024-12-17 01:52:31,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:31,598][root][INFO] - Training Epoch: 1/2, step 3154/7134 completed (loss: 4.138160705566406, acc: 0.29323309659957886)
[2024-12-17 01:52:31,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:31,865][root][INFO] - Training Epoch: 1/2, step 3155/7134 completed (loss: 3.7946743965148926, acc: 0.308270663022995)
[2024-12-17 01:52:31,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:32,154][root][INFO] - Training Epoch: 1/2, step 3156/7134 completed (loss: 4.515352249145508, acc: 0.3139534890651703)
[2024-12-17 01:52:32,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:32,418][root][INFO] - Training Epoch: 1/2, step 3157/7134 completed (loss: 4.166927337646484, acc: 0.2956521809101105)
[2024-12-17 01:52:32,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:32,693][root][INFO] - Training Epoch: 1/2, step 3158/7134 completed (loss: 3.5495259761810303, acc: 0.39716312289237976)
[2024-12-17 01:52:32,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:32,972][root][INFO] - Training Epoch: 1/2, step 3159/7134 completed (loss: 4.275218963623047, acc: 0.30927833914756775)
[2024-12-17 01:52:33,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:33,260][root][INFO] - Training Epoch: 1/2, step 3160/7134 completed (loss: 4.280325412750244, acc: 0.25641027092933655)
[2024-12-17 01:52:33,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:33,550][root][INFO] - Training Epoch: 1/2, step 3161/7134 completed (loss: 4.147858142852783, acc: 0.331210196018219)
[2024-12-17 01:52:33,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:33,835][root][INFO] - Training Epoch: 1/2, step 3162/7134 completed (loss: 3.8878273963928223, acc: 0.33561643958091736)
[2024-12-17 01:52:33,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:34,110][root][INFO] - Training Epoch: 1/2, step 3163/7134 completed (loss: 3.954261064529419, acc: 0.2786885201931)
[2024-12-17 01:52:34,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:34,386][root][INFO] - Training Epoch: 1/2, step 3164/7134 completed (loss: 4.499357223510742, acc: 0.23188406229019165)
[2024-12-17 01:52:34,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:34,675][root][INFO] - Training Epoch: 1/2, step 3165/7134 completed (loss: 4.3957743644714355, acc: 0.28671327233314514)
[2024-12-17 01:52:34,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:34,955][root][INFO] - Training Epoch: 1/2, step 3166/7134 completed (loss: 4.342254638671875, acc: 0.32278481125831604)
[2024-12-17 01:52:35,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:35,251][root][INFO] - Training Epoch: 1/2, step 3167/7134 completed (loss: 4.901440620422363, acc: 0.20370370149612427)
[2024-12-17 01:52:35,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:35,527][root][INFO] - Training Epoch: 1/2, step 3168/7134 completed (loss: 4.446829795837402, acc: 0.29411765933036804)
[2024-12-17 01:52:35,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:35,800][root][INFO] - Training Epoch: 1/2, step 3169/7134 completed (loss: 4.205746650695801, acc: 0.35245901346206665)
[2024-12-17 01:52:35,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:36,085][root][INFO] - Training Epoch: 1/2, step 3170/7134 completed (loss: 3.953167200088501, acc: 0.34558823704719543)
[2024-12-17 01:52:36,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:36,363][root][INFO] - Training Epoch: 1/2, step 3171/7134 completed (loss: 3.9713244438171387, acc: 0.34065935015678406)
[2024-12-17 01:52:36,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:36,636][root][INFO] - Training Epoch: 1/2, step 3172/7134 completed (loss: 3.7641072273254395, acc: 0.2857142984867096)
[2024-12-17 01:52:36,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:36,957][root][INFO] - Training Epoch: 1/2, step 3173/7134 completed (loss: 4.591433048248291, acc: 0.2525252401828766)
[2024-12-17 01:52:37,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:37,261][root][INFO] - Training Epoch: 1/2, step 3174/7134 completed (loss: 3.7694778442382812, acc: 0.35542169213294983)
[2024-12-17 01:52:37,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:37,554][root][INFO] - Training Epoch: 1/2, step 3175/7134 completed (loss: 3.8717243671417236, acc: 0.3139534890651703)
[2024-12-17 01:52:37,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:37,846][root][INFO] - Training Epoch: 1/2, step 3176/7134 completed (loss: 4.470131874084473, acc: 0.25)
[2024-12-17 01:52:37,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:38,137][root][INFO] - Training Epoch: 1/2, step 3177/7134 completed (loss: 4.493703365325928, acc: 0.22839505970478058)
[2024-12-17 01:52:38,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:38,424][root][INFO] - Training Epoch: 1/2, step 3178/7134 completed (loss: 3.827565908432007, acc: 0.30666667222976685)
[2024-12-17 01:52:38,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:38,721][root][INFO] - Training Epoch: 1/2, step 3179/7134 completed (loss: 4.12708854675293, acc: 0.2738095223903656)
[2024-12-17 01:52:38,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:38,990][root][INFO] - Training Epoch: 1/2, step 3180/7134 completed (loss: 4.091405391693115, acc: 0.2716049253940582)
[2024-12-17 01:52:39,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:39,281][root][INFO] - Training Epoch: 1/2, step 3181/7134 completed (loss: 4.5887837409973145, acc: 0.265193372964859)
[2024-12-17 01:52:39,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:39,565][root][INFO] - Training Epoch: 1/2, step 3182/7134 completed (loss: 3.6927714347839355, acc: 0.3414634168148041)
[2024-12-17 01:52:39,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:39,829][root][INFO] - Training Epoch: 1/2, step 3183/7134 completed (loss: 4.625945091247559, acc: 0.24817518889904022)
[2024-12-17 01:52:39,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:40,119][root][INFO] - Training Epoch: 1/2, step 3184/7134 completed (loss: 4.185035228729248, acc: 0.32499998807907104)
[2024-12-17 01:52:40,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:40,403][root][INFO] - Training Epoch: 1/2, step 3185/7134 completed (loss: 4.112443923950195, acc: 0.2578616440296173)
[2024-12-17 01:52:40,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:40,706][root][INFO] - Training Epoch: 1/2, step 3186/7134 completed (loss: 3.4099669456481934, acc: 0.3717948794364929)
[2024-12-17 01:52:40,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:40,973][root][INFO] - Training Epoch: 1/2, step 3187/7134 completed (loss: 3.8612945079803467, acc: 0.34285715222358704)
[2024-12-17 01:52:41,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:41,248][root][INFO] - Training Epoch: 1/2, step 3188/7134 completed (loss: 3.5332655906677246, acc: 0.3463687002658844)
[2024-12-17 01:52:41,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:41,525][root][INFO] - Training Epoch: 1/2, step 3189/7134 completed (loss: 3.7771477699279785, acc: 0.3395061790943146)
[2024-12-17 01:52:41,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:41,813][root][INFO] - Training Epoch: 1/2, step 3190/7134 completed (loss: 4.088257789611816, acc: 0.2750000059604645)
[2024-12-17 01:52:41,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:42,081][root][INFO] - Training Epoch: 1/2, step 3191/7134 completed (loss: 3.836888551712036, acc: 0.29192546010017395)
[2024-12-17 01:52:42,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:42,356][root][INFO] - Training Epoch: 1/2, step 3192/7134 completed (loss: 4.121727466583252, acc: 0.29927006363868713)
[2024-12-17 01:52:42,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:42,636][root][INFO] - Training Epoch: 1/2, step 3193/7134 completed (loss: 3.6155173778533936, acc: 0.3513513505458832)
[2024-12-17 01:52:42,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:42,926][root][INFO] - Training Epoch: 1/2, step 3194/7134 completed (loss: 4.345138072967529, acc: 0.27272728085517883)
[2024-12-17 01:52:43,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:43,199][root][INFO] - Training Epoch: 1/2, step 3195/7134 completed (loss: 4.388364791870117, acc: 0.26708075404167175)
[2024-12-17 01:52:43,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:43,470][root][INFO] - Training Epoch: 1/2, step 3196/7134 completed (loss: 3.7570574283599854, acc: 0.3550724685192108)
[2024-12-17 01:52:43,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:43,757][root][INFO] - Training Epoch: 1/2, step 3197/7134 completed (loss: 3.884901523590088, acc: 0.27544909715652466)
[2024-12-17 01:52:43,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:44,036][root][INFO] - Training Epoch: 1/2, step 3198/7134 completed (loss: 4.261574745178223, acc: 0.3062500059604645)
[2024-12-17 01:52:44,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:44,291][root][INFO] - Training Epoch: 1/2, step 3199/7134 completed (loss: 3.5669867992401123, acc: 0.3255814015865326)
[2024-12-17 01:52:44,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:44,542][root][INFO] - Training Epoch: 1/2, step 3200/7134 completed (loss: 3.909764051437378, acc: 0.3120567500591278)
[2024-12-17 01:52:44,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:44,827][root][INFO] - Training Epoch: 1/2, step 3201/7134 completed (loss: 4.753253936767578, acc: 0.25984251499176025)
[2024-12-17 01:52:44,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:45,110][root][INFO] - Training Epoch: 1/2, step 3202/7134 completed (loss: 4.304427146911621, acc: 0.25280898809432983)
[2024-12-17 01:52:45,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:45,379][root][INFO] - Training Epoch: 1/2, step 3203/7134 completed (loss: 3.9952011108398438, acc: 0.3125)
[2024-12-17 01:52:45,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:45,698][root][INFO] - Training Epoch: 1/2, step 3204/7134 completed (loss: 3.9010026454925537, acc: 0.2945205569267273)
[2024-12-17 01:52:45,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:45,990][root][INFO] - Training Epoch: 1/2, step 3205/7134 completed (loss: 3.8369452953338623, acc: 0.3333333432674408)
[2024-12-17 01:52:46,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:46,292][root][INFO] - Training Epoch: 1/2, step 3206/7134 completed (loss: 3.7397727966308594, acc: 0.2969697117805481)
[2024-12-17 01:52:46,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:46,582][root][INFO] - Training Epoch: 1/2, step 3207/7134 completed (loss: 3.3291447162628174, acc: 0.349693238735199)
[2024-12-17 01:52:46,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:46,890][root][INFO] - Training Epoch: 1/2, step 3208/7134 completed (loss: 3.968829870223999, acc: 0.2949640154838562)
[2024-12-17 01:52:47,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:47,190][root][INFO] - Training Epoch: 1/2, step 3209/7134 completed (loss: 3.750011920928955, acc: 0.36250001192092896)
[2024-12-17 01:52:47,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:47,491][root][INFO] - Training Epoch: 1/2, step 3210/7134 completed (loss: 3.8855016231536865, acc: 0.32258063554763794)
[2024-12-17 01:52:47,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:47,784][root][INFO] - Training Epoch: 1/2, step 3211/7134 completed (loss: 3.6051926612854004, acc: 0.29411765933036804)
[2024-12-17 01:52:47,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:48,087][root][INFO] - Training Epoch: 1/2, step 3212/7134 completed (loss: 3.602966547012329, acc: 0.3333333432674408)
[2024-12-17 01:52:48,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:48,395][root][INFO] - Training Epoch: 1/2, step 3213/7134 completed (loss: 3.9980640411376953, acc: 0.2976190447807312)
[2024-12-17 01:52:48,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:48,701][root][INFO] - Training Epoch: 1/2, step 3214/7134 completed (loss: 3.757956027984619, acc: 0.35672515630722046)
[2024-12-17 01:52:48,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:49,007][root][INFO] - Training Epoch: 1/2, step 3215/7134 completed (loss: 3.7695565223693848, acc: 0.3254437744617462)
[2024-12-17 01:52:49,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:49,319][root][INFO] - Training Epoch: 1/2, step 3216/7134 completed (loss: 3.716019630432129, acc: 0.2777777910232544)
[2024-12-17 01:52:49,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:49,631][root][INFO] - Training Epoch: 1/2, step 3217/7134 completed (loss: 3.584261894226074, acc: 0.3595505654811859)
[2024-12-17 01:52:49,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:49,923][root][INFO] - Training Epoch: 1/2, step 3218/7134 completed (loss: 3.611628293991089, acc: 0.3290322721004486)
[2024-12-17 01:52:50,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:50,197][root][INFO] - Training Epoch: 1/2, step 3219/7134 completed (loss: 3.755748987197876, acc: 0.3035714328289032)
[2024-12-17 01:52:50,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:50,490][root][INFO] - Training Epoch: 1/2, step 3220/7134 completed (loss: 3.9138214588165283, acc: 0.29378530383110046)
[2024-12-17 01:52:50,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:50,776][root][INFO] - Training Epoch: 1/2, step 3221/7134 completed (loss: 3.4978203773498535, acc: 0.27419355511665344)
[2024-12-17 01:52:50,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:51,047][root][INFO] - Training Epoch: 1/2, step 3222/7134 completed (loss: 3.949143171310425, acc: 0.31840795278549194)
[2024-12-17 01:52:51,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:51,322][root][INFO] - Training Epoch: 1/2, step 3223/7134 completed (loss: 3.5754013061523438, acc: 0.3558282256126404)
[2024-12-17 01:52:51,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:51,610][root][INFO] - Training Epoch: 1/2, step 3224/7134 completed (loss: 3.99861216545105, acc: 0.3352601230144501)
[2024-12-17 01:52:51,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:51,896][root][INFO] - Training Epoch: 1/2, step 3225/7134 completed (loss: 3.851560354232788, acc: 0.25999999046325684)
[2024-12-17 01:52:52,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:52,162][root][INFO] - Training Epoch: 1/2, step 3226/7134 completed (loss: 4.678735256195068, acc: 0.20529800653457642)
[2024-12-17 01:52:52,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:52,465][root][INFO] - Training Epoch: 1/2, step 3227/7134 completed (loss: 4.11946439743042, acc: 0.20987653732299805)
[2024-12-17 01:52:52,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:52,758][root][INFO] - Training Epoch: 1/2, step 3228/7134 completed (loss: 4.133195400238037, acc: 0.2525252401828766)
[2024-12-17 01:52:52,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:53,041][root][INFO] - Training Epoch: 1/2, step 3229/7134 completed (loss: 3.774906873703003, acc: 0.3232323229312897)
[2024-12-17 01:52:53,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:53,321][root][INFO] - Training Epoch: 1/2, step 3230/7134 completed (loss: 3.8901703357696533, acc: 0.3375000059604645)
[2024-12-17 01:52:53,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:53,594][root][INFO] - Training Epoch: 1/2, step 3231/7134 completed (loss: 3.963095188140869, acc: 0.3131868243217468)
[2024-12-17 01:52:53,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:53,877][root][INFO] - Training Epoch: 1/2, step 3232/7134 completed (loss: 3.6162562370300293, acc: 0.26851850748062134)
[2024-12-17 01:52:54,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:54,158][root][INFO] - Training Epoch: 1/2, step 3233/7134 completed (loss: 3.9284651279449463, acc: 0.29921260476112366)
[2024-12-17 01:52:54,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:54,429][root][INFO] - Training Epoch: 1/2, step 3234/7134 completed (loss: 4.201087951660156, acc: 0.29559749364852905)
[2024-12-17 01:52:54,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:54,710][root][INFO] - Training Epoch: 1/2, step 3235/7134 completed (loss: 3.7309203147888184, acc: 0.27659574151039124)
[2024-12-17 01:52:54,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:54,975][root][INFO] - Training Epoch: 1/2, step 3236/7134 completed (loss: 4.058122158050537, acc: 0.2881355881690979)
[2024-12-17 01:52:55,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:55,254][root][INFO] - Training Epoch: 1/2, step 3237/7134 completed (loss: 4.442000389099121, acc: 0.18831168115139008)
[2024-12-17 01:52:55,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:55,534][root][INFO] - Training Epoch: 1/2, step 3238/7134 completed (loss: 3.6771697998046875, acc: 0.3499999940395355)
[2024-12-17 01:52:55,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:55,824][root][INFO] - Training Epoch: 1/2, step 3239/7134 completed (loss: 3.9273507595062256, acc: 0.25609755516052246)
[2024-12-17 01:52:55,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:56,114][root][INFO] - Training Epoch: 1/2, step 3240/7134 completed (loss: 3.642070770263672, acc: 0.33519554138183594)
[2024-12-17 01:52:56,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:56,387][root][INFO] - Training Epoch: 1/2, step 3241/7134 completed (loss: 3.994241237640381, acc: 0.28823530673980713)
[2024-12-17 01:52:56,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:56,655][root][INFO] - Training Epoch: 1/2, step 3242/7134 completed (loss: 3.9513156414031982, acc: 0.31168830394744873)
[2024-12-17 01:52:56,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:56,964][root][INFO] - Training Epoch: 1/2, step 3243/7134 completed (loss: 3.649322986602783, acc: 0.3475935757160187)
[2024-12-17 01:52:57,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:57,261][root][INFO] - Training Epoch: 1/2, step 3244/7134 completed (loss: 3.9703738689422607, acc: 0.2601155936717987)
[2024-12-17 01:52:57,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:57,556][root][INFO] - Training Epoch: 1/2, step 3245/7134 completed (loss: 3.9587433338165283, acc: 0.32307693362236023)
[2024-12-17 01:52:57,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:57,837][root][INFO] - Training Epoch: 1/2, step 3246/7134 completed (loss: 4.261464595794678, acc: 0.2410256415605545)
[2024-12-17 01:52:57,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:58,114][root][INFO] - Training Epoch: 1/2, step 3247/7134 completed (loss: 3.9031293392181396, acc: 0.22435897588729858)
[2024-12-17 01:52:58,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:58,384][root][INFO] - Training Epoch: 1/2, step 3248/7134 completed (loss: 3.8026106357574463, acc: 0.32116788625717163)
[2024-12-17 01:52:58,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:58,660][root][INFO] - Training Epoch: 1/2, step 3249/7134 completed (loss: 3.549116373062134, acc: 0.3372780978679657)
[2024-12-17 01:52:58,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:58,939][root][INFO] - Training Epoch: 1/2, step 3250/7134 completed (loss: 3.3419833183288574, acc: 0.371257483959198)
[2024-12-17 01:52:59,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:59,219][root][INFO] - Training Epoch: 1/2, step 3251/7134 completed (loss: 3.690415143966675, acc: 0.3461538553237915)
[2024-12-17 01:52:59,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:59,506][root][INFO] - Training Epoch: 1/2, step 3252/7134 completed (loss: 3.84657883644104, acc: 0.3313252925872803)
[2024-12-17 01:52:59,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:59,788][root][INFO] - Training Epoch: 1/2, step 3253/7134 completed (loss: 3.4695446491241455, acc: 0.34210526943206787)
[2024-12-17 01:52:59,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:00,076][root][INFO] - Training Epoch: 1/2, step 3254/7134 completed (loss: 3.451467990875244, acc: 0.350649356842041)
[2024-12-17 01:53:00,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:00,349][root][INFO] - Training Epoch: 1/2, step 3255/7134 completed (loss: 3.418271780014038, acc: 0.3920454680919647)
[2024-12-17 01:53:00,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:00,634][root][INFO] - Training Epoch: 1/2, step 3256/7134 completed (loss: 3.6772968769073486, acc: 0.27950310707092285)
[2024-12-17 01:53:00,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:00,920][root][INFO] - Training Epoch: 1/2, step 3257/7134 completed (loss: 3.8603408336639404, acc: 0.32121211290359497)
[2024-12-17 01:53:01,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:01,220][root][INFO] - Training Epoch: 1/2, step 3258/7134 completed (loss: 4.538945198059082, acc: 0.3008130192756653)
[2024-12-17 01:53:01,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:01,501][root][INFO] - Training Epoch: 1/2, step 3259/7134 completed (loss: 3.602792263031006, acc: 0.3354037404060364)
[2024-12-17 01:53:01,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:01,811][root][INFO] - Training Epoch: 1/2, step 3260/7134 completed (loss: 4.076146125793457, acc: 0.35862070322036743)
[2024-12-17 01:53:01,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:02,103][root][INFO] - Training Epoch: 1/2, step 3261/7134 completed (loss: 4.300796031951904, acc: 0.35766422748565674)
[2024-12-17 01:53:02,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:02,390][root][INFO] - Training Epoch: 1/2, step 3262/7134 completed (loss: 4.165424346923828, acc: 0.26543208956718445)
[2024-12-17 01:53:02,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:02,668][root][INFO] - Training Epoch: 1/2, step 3263/7134 completed (loss: 4.123497009277344, acc: 0.2958579957485199)
[2024-12-17 01:53:02,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:02,935][root][INFO] - Training Epoch: 1/2, step 3264/7134 completed (loss: 3.9586732387542725, acc: 0.28658536076545715)
[2024-12-17 01:53:03,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:03,223][root][INFO] - Training Epoch: 1/2, step 3265/7134 completed (loss: 4.247490882873535, acc: 0.2802547812461853)
[2024-12-17 01:53:03,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:03,503][root][INFO] - Training Epoch: 1/2, step 3266/7134 completed (loss: 4.260558128356934, acc: 0.32413792610168457)
[2024-12-17 01:53:03,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:03,790][root][INFO] - Training Epoch: 1/2, step 3267/7134 completed (loss: 4.088625431060791, acc: 0.3030303120613098)
[2024-12-17 01:53:03,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:04,052][root][INFO] - Training Epoch: 1/2, step 3268/7134 completed (loss: 3.027320623397827, acc: 0.3561643958091736)
[2024-12-17 01:53:04,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:04,334][root][INFO] - Training Epoch: 1/2, step 3269/7134 completed (loss: 3.4106714725494385, acc: 0.35638296604156494)
[2024-12-17 01:53:04,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:04,615][root][INFO] - Training Epoch: 1/2, step 3270/7134 completed (loss: 3.6642937660217285, acc: 0.3243243098258972)
[2024-12-17 01:53:04,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:04,852][root][INFO] - Training Epoch: 1/2, step 3271/7134 completed (loss: 3.9061360359191895, acc: 0.3239436745643616)
[2024-12-17 01:53:04,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:05,127][root][INFO] - Training Epoch: 1/2, step 3272/7134 completed (loss: 3.967648983001709, acc: 0.2800000011920929)
[2024-12-17 01:53:05,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:05,416][root][INFO] - Training Epoch: 1/2, step 3273/7134 completed (loss: 3.7140939235687256, acc: 0.34857141971588135)
[2024-12-17 01:53:05,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:05,717][root][INFO] - Training Epoch: 1/2, step 3274/7134 completed (loss: 3.7966084480285645, acc: 0.2981366515159607)
[2024-12-17 01:53:05,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:06,024][root][INFO] - Training Epoch: 1/2, step 3275/7134 completed (loss: 4.362786293029785, acc: 0.23952095210552216)
[2024-12-17 01:53:06,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:06,330][root][INFO] - Training Epoch: 1/2, step 3276/7134 completed (loss: 4.039352893829346, acc: 0.30718955397605896)
[2024-12-17 01:53:06,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:06,615][root][INFO] - Training Epoch: 1/2, step 3277/7134 completed (loss: 4.08490514755249, acc: 0.3093525171279907)
[2024-12-17 01:53:06,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:06,881][root][INFO] - Training Epoch: 1/2, step 3278/7134 completed (loss: 3.9496302604675293, acc: 0.3306451737880707)
[2024-12-17 01:53:07,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:07,168][root][INFO] - Training Epoch: 1/2, step 3279/7134 completed (loss: 3.916834592819214, acc: 0.3235294222831726)
[2024-12-17 01:53:07,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:07,471][root][INFO] - Training Epoch: 1/2, step 3280/7134 completed (loss: 4.486147880554199, acc: 0.25)
[2024-12-17 01:53:07,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:07,761][root][INFO] - Training Epoch: 1/2, step 3281/7134 completed (loss: 4.009606838226318, acc: 0.3401360511779785)
[2024-12-17 01:53:07,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:08,044][root][INFO] - Training Epoch: 1/2, step 3282/7134 completed (loss: 3.6543474197387695, acc: 0.35114502906799316)
[2024-12-17 01:53:08,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:08,321][root][INFO] - Training Epoch: 1/2, step 3283/7134 completed (loss: 4.222601890563965, acc: 0.2450980395078659)
[2024-12-17 01:53:08,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:08,593][root][INFO] - Training Epoch: 1/2, step 3284/7134 completed (loss: 3.65380597114563, acc: 0.3379310369491577)
[2024-12-17 01:53:08,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:08,865][root][INFO] - Training Epoch: 1/2, step 3285/7134 completed (loss: 4.242269039154053, acc: 0.2720588147640228)
[2024-12-17 01:53:08,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:09,137][root][INFO] - Training Epoch: 1/2, step 3286/7134 completed (loss: 3.938042163848877, acc: 0.2846153974533081)
[2024-12-17 01:53:09,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:09,408][root][INFO] - Training Epoch: 1/2, step 3287/7134 completed (loss: 4.112114906311035, acc: 0.27407407760620117)
[2024-12-17 01:53:09,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:09,691][root][INFO] - Training Epoch: 1/2, step 3288/7134 completed (loss: 3.923607349395752, acc: 0.3309352397918701)
[2024-12-17 01:53:09,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:09,944][root][INFO] - Training Epoch: 1/2, step 3289/7134 completed (loss: 4.5941901206970215, acc: 0.31617647409439087)
[2024-12-17 01:53:10,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:10,207][root][INFO] - Training Epoch: 1/2, step 3290/7134 completed (loss: 4.304812431335449, acc: 0.2521008551120758)
[2024-12-17 01:53:10,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:10,480][root][INFO] - Training Epoch: 1/2, step 3291/7134 completed (loss: 4.487906455993652, acc: 0.2673267424106598)
[2024-12-17 01:53:10,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:10,747][root][INFO] - Training Epoch: 1/2, step 3292/7134 completed (loss: 4.1414618492126465, acc: 0.27731093764305115)
[2024-12-17 01:53:10,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:11,044][root][INFO] - Training Epoch: 1/2, step 3293/7134 completed (loss: 4.252567768096924, acc: 0.2651515007019043)
[2024-12-17 01:53:11,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:11,323][root][INFO] - Training Epoch: 1/2, step 3294/7134 completed (loss: 4.263241291046143, acc: 0.3181818127632141)
[2024-12-17 01:53:11,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:11,581][root][INFO] - Training Epoch: 1/2, step 3295/7134 completed (loss: 3.9211809635162354, acc: 0.25806450843811035)
[2024-12-17 01:53:11,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:11,840][root][INFO] - Training Epoch: 1/2, step 3296/7134 completed (loss: 4.011138439178467, acc: 0.3461538553237915)
[2024-12-17 01:53:11,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:12,090][root][INFO] - Training Epoch: 1/2, step 3297/7134 completed (loss: 4.535280227661133, acc: 0.24528302252292633)
[2024-12-17 01:53:12,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:12,354][root][INFO] - Training Epoch: 1/2, step 3298/7134 completed (loss: 4.12821626663208, acc: 0.29323309659957886)
[2024-12-17 01:53:12,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:12,638][root][INFO] - Training Epoch: 1/2, step 3299/7134 completed (loss: 4.19625997543335, acc: 0.27559053897857666)
[2024-12-17 01:53:12,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:12,908][root][INFO] - Training Epoch: 1/2, step 3300/7134 completed (loss: 3.8111541271209717, acc: 0.3684210479259491)
[2024-12-17 01:53:13,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:13,160][root][INFO] - Training Epoch: 1/2, step 3301/7134 completed (loss: 3.78896164894104, acc: 0.3203883469104767)
[2024-12-17 01:53:13,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:13,419][root][INFO] - Training Epoch: 1/2, step 3302/7134 completed (loss: 3.5294344425201416, acc: 0.279720276594162)
[2024-12-17 01:53:13,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:13,653][root][INFO] - Training Epoch: 1/2, step 3303/7134 completed (loss: 3.8389406204223633, acc: 0.32673266530036926)
[2024-12-17 01:53:13,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:13,935][root][INFO] - Training Epoch: 1/2, step 3304/7134 completed (loss: 3.5764412879943848, acc: 0.32568806409835815)
[2024-12-17 01:53:14,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:14,208][root][INFO] - Training Epoch: 1/2, step 3305/7134 completed (loss: 3.5655925273895264, acc: 0.3270440399646759)
[2024-12-17 01:53:14,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:14,502][root][INFO] - Training Epoch: 1/2, step 3306/7134 completed (loss: 3.818295955657959, acc: 0.3218390941619873)
[2024-12-17 01:53:14,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:14,762][root][INFO] - Training Epoch: 1/2, step 3307/7134 completed (loss: 3.6840622425079346, acc: 0.31111112236976624)
[2024-12-17 01:53:14,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:15,024][root][INFO] - Training Epoch: 1/2, step 3308/7134 completed (loss: 3.8992297649383545, acc: 0.30588236451148987)
[2024-12-17 01:53:15,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:15,274][root][INFO] - Training Epoch: 1/2, step 3309/7134 completed (loss: 4.185984134674072, acc: 0.26923078298568726)
[2024-12-17 01:53:15,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:15,550][root][INFO] - Training Epoch: 1/2, step 3310/7134 completed (loss: 3.7544050216674805, acc: 0.33636364340782166)
[2024-12-17 01:53:15,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:15,766][root][INFO] - Training Epoch: 1/2, step 3311/7134 completed (loss: 3.9940924644470215, acc: 0.3762376308441162)
[2024-12-17 01:53:15,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:16,028][root][INFO] - Training Epoch: 1/2, step 3312/7134 completed (loss: 3.6976683139801025, acc: 0.29323309659957886)
[2024-12-17 01:53:16,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:16,304][root][INFO] - Training Epoch: 1/2, step 3313/7134 completed (loss: 4.981712341308594, acc: 0.19387754797935486)
[2024-12-17 01:53:16,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:16,565][root][INFO] - Training Epoch: 1/2, step 3314/7134 completed (loss: 4.508565425872803, acc: 0.26605504751205444)
[2024-12-17 01:53:16,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:16,846][root][INFO] - Training Epoch: 1/2, step 3315/7134 completed (loss: 4.22680139541626, acc: 0.23668639361858368)
[2024-12-17 01:53:16,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:17,121][root][INFO] - Training Epoch: 1/2, step 3316/7134 completed (loss: 4.151316165924072, acc: 0.305970162153244)
[2024-12-17 01:53:17,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:17,396][root][INFO] - Training Epoch: 1/2, step 3317/7134 completed (loss: 3.4713432788848877, acc: 0.35537189245224)
[2024-12-17 01:53:17,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:17,604][root][INFO] - Training Epoch: 1/2, step 3318/7134 completed (loss: 3.92710542678833, acc: 0.2881355881690979)
[2024-12-17 01:53:17,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:17,882][root][INFO] - Training Epoch: 1/2, step 3319/7134 completed (loss: 3.921659231185913, acc: 0.2971014380455017)
[2024-12-17 01:53:17,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:18,161][root][INFO] - Training Epoch: 1/2, step 3320/7134 completed (loss: 3.527482271194458, acc: 0.3615819215774536)
[2024-12-17 01:53:18,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:18,442][root][INFO] - Training Epoch: 1/2, step 3321/7134 completed (loss: 4.031441688537598, acc: 0.3214285671710968)
[2024-12-17 01:53:18,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:18,731][root][INFO] - Training Epoch: 1/2, step 3322/7134 completed (loss: 4.066589832305908, acc: 0.30263158679008484)
[2024-12-17 01:53:18,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:19,008][root][INFO] - Training Epoch: 1/2, step 3323/7134 completed (loss: 4.151650428771973, acc: 0.2982456088066101)
[2024-12-17 01:53:19,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:19,300][root][INFO] - Training Epoch: 1/2, step 3324/7134 completed (loss: 4.278962135314941, acc: 0.2849740982055664)
[2024-12-17 01:53:19,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:19,591][root][INFO] - Training Epoch: 1/2, step 3325/7134 completed (loss: 4.001805782318115, acc: 0.329341322183609)
[2024-12-17 01:53:19,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:19,864][root][INFO] - Training Epoch: 1/2, step 3326/7134 completed (loss: 3.5788843631744385, acc: 0.35151514410972595)
[2024-12-17 01:53:19,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:20,132][root][INFO] - Training Epoch: 1/2, step 3327/7134 completed (loss: 3.5362420082092285, acc: 0.3591160178184509)
[2024-12-17 01:53:20,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:20,418][root][INFO] - Training Epoch: 1/2, step 3328/7134 completed (loss: 3.531287431716919, acc: 0.3723404109477997)
[2024-12-17 01:53:20,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:20,686][root][INFO] - Training Epoch: 1/2, step 3329/7134 completed (loss: 4.0941667556762695, acc: 0.3020833432674408)
[2024-12-17 01:53:20,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:20,965][root][INFO] - Training Epoch: 1/2, step 3330/7134 completed (loss: 3.7306551933288574, acc: 0.3076923191547394)
[2024-12-17 01:53:21,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:21,233][root][INFO] - Training Epoch: 1/2, step 3331/7134 completed (loss: 4.1572041511535645, acc: 0.34319525957107544)
[2024-12-17 01:53:21,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:21,513][root][INFO] - Training Epoch: 1/2, step 3332/7134 completed (loss: 4.122962951660156, acc: 0.2866666615009308)
[2024-12-17 01:53:21,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:21,770][root][INFO] - Training Epoch: 1/2, step 3333/7134 completed (loss: 4.483424663543701, acc: 0.260869562625885)
[2024-12-17 01:53:21,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:22,042][root][INFO] - Training Epoch: 1/2, step 3334/7134 completed (loss: 4.1236796379089355, acc: 0.29891303181648254)
[2024-12-17 01:53:22,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:22,327][root][INFO] - Training Epoch: 1/2, step 3335/7134 completed (loss: 3.384488582611084, acc: 0.30000001192092896)
[2024-12-17 01:53:22,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:22,599][root][INFO] - Training Epoch: 1/2, step 3336/7134 completed (loss: 3.2596049308776855, acc: 0.3772455155849457)
[2024-12-17 01:53:22,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:22,870][root][INFO] - Training Epoch: 1/2, step 3337/7134 completed (loss: 3.238755226135254, acc: 0.3613445460796356)
[2024-12-17 01:53:22,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:23,144][root][INFO] - Training Epoch: 1/2, step 3338/7134 completed (loss: 3.1806318759918213, acc: 0.3471502661705017)
[2024-12-17 01:53:23,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:23,425][root][INFO] - Training Epoch: 1/2, step 3339/7134 completed (loss: 3.28983998298645, acc: 0.37681159377098083)
[2024-12-17 01:53:23,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:23,697][root][INFO] - Training Epoch: 1/2, step 3340/7134 completed (loss: 4.32465934753418, acc: 0.244047611951828)
[2024-12-17 01:53:23,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:23,977][root][INFO] - Training Epoch: 1/2, step 3341/7134 completed (loss: 3.9189293384552, acc: 0.34730538725852966)
[2024-12-17 01:53:24,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:24,249][root][INFO] - Training Epoch: 1/2, step 3342/7134 completed (loss: 3.7870445251464844, acc: 0.3493150770664215)
[2024-12-17 01:53:24,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:24,543][root][INFO] - Training Epoch: 1/2, step 3343/7134 completed (loss: 4.01078462600708, acc: 0.31896552443504333)
[2024-12-17 01:53:24,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:24,818][root][INFO] - Training Epoch: 1/2, step 3344/7134 completed (loss: 3.5268003940582275, acc: 0.33088234066963196)
[2024-12-17 01:53:24,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:25,117][root][INFO] - Training Epoch: 1/2, step 3345/7134 completed (loss: 3.72186017036438, acc: 0.3426573574542999)
[2024-12-17 01:53:25,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:25,405][root][INFO] - Training Epoch: 1/2, step 3346/7134 completed (loss: 3.787031888961792, acc: 0.3414634168148041)
[2024-12-17 01:53:25,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:25,724][root][INFO] - Training Epoch: 1/2, step 3347/7134 completed (loss: 4.207772731781006, acc: 0.27450981736183167)
[2024-12-17 01:53:25,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:26,018][root][INFO] - Training Epoch: 1/2, step 3348/7134 completed (loss: 4.108273983001709, acc: 0.27848100662231445)
[2024-12-17 01:53:26,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:26,286][root][INFO] - Training Epoch: 1/2, step 3349/7134 completed (loss: 3.9114811420440674, acc: 0.3178294599056244)
[2024-12-17 01:53:26,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:26,565][root][INFO] - Training Epoch: 1/2, step 3350/7134 completed (loss: 3.5004141330718994, acc: 0.32231405377388)
[2024-12-17 01:53:26,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:26,842][root][INFO] - Training Epoch: 1/2, step 3351/7134 completed (loss: 4.207389831542969, acc: 0.3085106313228607)
[2024-12-17 01:53:26,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:27,116][root][INFO] - Training Epoch: 1/2, step 3352/7134 completed (loss: 3.9021847248077393, acc: 0.3185185194015503)
[2024-12-17 01:53:27,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:27,386][root][INFO] - Training Epoch: 1/2, step 3353/7134 completed (loss: 3.4499571323394775, acc: 0.3252032399177551)
[2024-12-17 01:53:27,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:27,660][root][INFO] - Training Epoch: 1/2, step 3354/7134 completed (loss: 3.647737503051758, acc: 0.297468364238739)
[2024-12-17 01:53:27,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:27,943][root][INFO] - Training Epoch: 1/2, step 3355/7134 completed (loss: 3.4413135051727295, acc: 0.37195122241973877)
[2024-12-17 01:53:28,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:28,224][root][INFO] - Training Epoch: 1/2, step 3356/7134 completed (loss: 3.6585843563079834, acc: 0.29629629850387573)
[2024-12-17 01:53:28,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:28,505][root][INFO] - Training Epoch: 1/2, step 3357/7134 completed (loss: 3.5214715003967285, acc: 0.371257483959198)
[2024-12-17 01:53:28,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:28,780][root][INFO] - Training Epoch: 1/2, step 3358/7134 completed (loss: 4.755804538726807, acc: 0.23529411852359772)
[2024-12-17 01:53:28,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:29,060][root][INFO] - Training Epoch: 1/2, step 3359/7134 completed (loss: 3.746526002883911, acc: 0.3493150770664215)
[2024-12-17 01:53:29,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:29,339][root][INFO] - Training Epoch: 1/2, step 3360/7134 completed (loss: 3.8244850635528564, acc: 0.321739137172699)
[2024-12-17 01:53:29,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:29,615][root][INFO] - Training Epoch: 1/2, step 3361/7134 completed (loss: 4.066497325897217, acc: 0.3392857015132904)
[2024-12-17 01:53:29,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:29,894][root][INFO] - Training Epoch: 1/2, step 3362/7134 completed (loss: 4.1580939292907715, acc: 0.30000001192092896)
[2024-12-17 01:53:30,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:30,158][root][INFO] - Training Epoch: 1/2, step 3363/7134 completed (loss: 3.957078218460083, acc: 0.2897196114063263)
[2024-12-17 01:53:30,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:30,452][root][INFO] - Training Epoch: 1/2, step 3364/7134 completed (loss: 4.313067436218262, acc: 0.30718955397605896)
[2024-12-17 01:53:30,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:30,727][root][INFO] - Training Epoch: 1/2, step 3365/7134 completed (loss: 3.8393216133117676, acc: 0.3185840845108032)
[2024-12-17 01:53:30,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:31,000][root][INFO] - Training Epoch: 1/2, step 3366/7134 completed (loss: 3.8476643562316895, acc: 0.31481480598449707)
[2024-12-17 01:53:31,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:31,295][root][INFO] - Training Epoch: 1/2, step 3367/7134 completed (loss: 3.7273623943328857, acc: 0.32085561752319336)
[2024-12-17 01:53:31,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:31,583][root][INFO] - Training Epoch: 1/2, step 3368/7134 completed (loss: 3.8712782859802246, acc: 0.2981366515159607)
[2024-12-17 01:53:31,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:31,876][root][INFO] - Training Epoch: 1/2, step 3369/7134 completed (loss: 3.8833935260772705, acc: 0.3351351320743561)
[2024-12-17 01:53:31,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:32,163][root][INFO] - Training Epoch: 1/2, step 3370/7134 completed (loss: 3.642247200012207, acc: 0.38650307059288025)
[2024-12-17 01:53:32,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:32,447][root][INFO] - Training Epoch: 1/2, step 3371/7134 completed (loss: 3.2937350273132324, acc: 0.4305555522441864)
[2024-12-17 01:53:32,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:32,732][root][INFO] - Training Epoch: 1/2, step 3372/7134 completed (loss: 4.086892604827881, acc: 0.25850340723991394)
[2024-12-17 01:53:32,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:33,003][root][INFO] - Training Epoch: 1/2, step 3373/7134 completed (loss: 3.7271955013275146, acc: 0.38562092185020447)
[2024-12-17 01:53:33,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:33,296][root][INFO] - Training Epoch: 1/2, step 3374/7134 completed (loss: 3.7783586978912354, acc: 0.35428571701049805)
[2024-12-17 01:53:33,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:33,582][root][INFO] - Training Epoch: 1/2, step 3375/7134 completed (loss: 3.9731643199920654, acc: 0.3053892254829407)
[2024-12-17 01:53:33,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:33,865][root][INFO] - Training Epoch: 1/2, step 3376/7134 completed (loss: 3.1962943077087402, acc: 0.37566137313842773)
[2024-12-17 01:53:33,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:34,165][root][INFO] - Training Epoch: 1/2, step 3377/7134 completed (loss: 3.3685410022735596, acc: 0.3316583037376404)
[2024-12-17 01:53:34,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:34,455][root][INFO] - Training Epoch: 1/2, step 3378/7134 completed (loss: 2.8233790397644043, acc: 0.46052631735801697)
[2024-12-17 01:53:34,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:34,751][root][INFO] - Training Epoch: 1/2, step 3379/7134 completed (loss: 3.638418674468994, acc: 0.3310810923576355)
[2024-12-17 01:53:34,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:35,042][root][INFO] - Training Epoch: 1/2, step 3380/7134 completed (loss: 3.4450392723083496, acc: 0.3550724685192108)
[2024-12-17 01:53:35,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:35,361][root][INFO] - Training Epoch: 1/2, step 3381/7134 completed (loss: 3.4407811164855957, acc: 0.3231707215309143)
[2024-12-17 01:53:35,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:35,661][root][INFO] - Training Epoch: 1/2, step 3382/7134 completed (loss: 3.273423910140991, acc: 0.359375)
[2024-12-17 01:53:35,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:35,978][root][INFO] - Training Epoch: 1/2, step 3383/7134 completed (loss: 3.667057514190674, acc: 0.37062937021255493)
[2024-12-17 01:53:36,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:36,256][root][INFO] - Training Epoch: 1/2, step 3384/7134 completed (loss: 3.709502935409546, acc: 0.35766422748565674)
[2024-12-17 01:53:36,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:36,535][root][INFO] - Training Epoch: 1/2, step 3385/7134 completed (loss: 2.9314992427825928, acc: 0.4583333432674408)
[2024-12-17 01:53:36,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:36,814][root][INFO] - Training Epoch: 1/2, step 3386/7134 completed (loss: 3.5633349418640137, acc: 0.39053255319595337)
[2024-12-17 01:53:36,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:37,090][root][INFO] - Training Epoch: 1/2, step 3387/7134 completed (loss: 3.8280608654022217, acc: 0.2906976640224457)
[2024-12-17 01:53:37,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:37,370][root][INFO] - Training Epoch: 1/2, step 3388/7134 completed (loss: 3.847290277481079, acc: 0.3504273593425751)
[2024-12-17 01:53:37,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:37,646][root][INFO] - Training Epoch: 1/2, step 3389/7134 completed (loss: 3.295793294906616, acc: 0.35519126057624817)
[2024-12-17 01:53:37,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:37,924][root][INFO] - Training Epoch: 1/2, step 3390/7134 completed (loss: 3.9883155822753906, acc: 0.28977271914482117)
[2024-12-17 01:53:38,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:38,187][root][INFO] - Training Epoch: 1/2, step 3391/7134 completed (loss: 3.8696579933166504, acc: 0.32926830649375916)
[2024-12-17 01:53:38,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:38,469][root][INFO] - Training Epoch: 1/2, step 3392/7134 completed (loss: 3.62589693069458, acc: 0.3435114622116089)
[2024-12-17 01:53:38,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:38,736][root][INFO] - Training Epoch: 1/2, step 3393/7134 completed (loss: 3.9825055599212646, acc: 0.3496503531932831)
[2024-12-17 01:53:38,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:39,019][root][INFO] - Training Epoch: 1/2, step 3394/7134 completed (loss: 4.510101795196533, acc: 0.27142858505249023)
[2024-12-17 01:53:39,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:39,290][root][INFO] - Training Epoch: 1/2, step 3395/7134 completed (loss: 4.085165977478027, acc: 0.3552631437778473)
[2024-12-17 01:53:39,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:39,567][root][INFO] - Training Epoch: 1/2, step 3396/7134 completed (loss: 3.5701990127563477, acc: 0.32692307233810425)
[2024-12-17 01:53:39,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:39,853][root][INFO] - Training Epoch: 1/2, step 3397/7134 completed (loss: 3.684044361114502, acc: 0.31840795278549194)
[2024-12-17 01:53:39,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:40,136][root][INFO] - Training Epoch: 1/2, step 3398/7134 completed (loss: 3.8496646881103516, acc: 0.260869562625885)
[2024-12-17 01:53:40,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:40,414][root][INFO] - Training Epoch: 1/2, step 3399/7134 completed (loss: 4.086093902587891, acc: 0.2777777910232544)
[2024-12-17 01:53:40,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:40,693][root][INFO] - Training Epoch: 1/2, step 3400/7134 completed (loss: 3.9538707733154297, acc: 0.29133859276771545)
[2024-12-17 01:53:40,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:40,972][root][INFO] - Training Epoch: 1/2, step 3401/7134 completed (loss: 3.665010929107666, acc: 0.35374149680137634)
[2024-12-17 01:53:41,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:41,276][root][INFO] - Training Epoch: 1/2, step 3402/7134 completed (loss: 3.8903942108154297, acc: 0.29946523904800415)
[2024-12-17 01:53:41,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:41,626][root][INFO] - Training Epoch: 1/2, step 3403/7134 completed (loss: 3.973597288131714, acc: 0.3080808222293854)
[2024-12-17 01:53:41,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:41,915][root][INFO] - Training Epoch: 1/2, step 3404/7134 completed (loss: 3.8554887771606445, acc: 0.31446540355682373)
[2024-12-17 01:53:42,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:42,202][root][INFO] - Training Epoch: 1/2, step 3405/7134 completed (loss: 3.945322275161743, acc: 0.3529411852359772)
[2024-12-17 01:53:42,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:42,486][root][INFO] - Training Epoch: 1/2, step 3406/7134 completed (loss: 4.12190580368042, acc: 0.33000001311302185)
[2024-12-17 01:53:42,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:42,751][root][INFO] - Training Epoch: 1/2, step 3407/7134 completed (loss: 3.5207369327545166, acc: 0.3680981695652008)
[2024-12-17 01:53:42,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:43,015][root][INFO] - Training Epoch: 1/2, step 3408/7134 completed (loss: 3.6441266536712646, acc: 0.4150943458080292)
[2024-12-17 01:53:43,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:43,305][root][INFO] - Training Epoch: 1/2, step 3409/7134 completed (loss: 3.824155330657959, acc: 0.3218390941619873)
[2024-12-17 01:53:43,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:43,586][root][INFO] - Training Epoch: 1/2, step 3410/7134 completed (loss: 4.04046106338501, acc: 0.34756097197532654)
[2024-12-17 01:53:43,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:43,869][root][INFO] - Training Epoch: 1/2, step 3411/7134 completed (loss: 3.402240753173828, acc: 0.3351648449897766)
[2024-12-17 01:53:43,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:44,141][root][INFO] - Training Epoch: 1/2, step 3412/7134 completed (loss: 3.9665017127990723, acc: 0.375)
[2024-12-17 01:53:44,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:44,429][root][INFO] - Training Epoch: 1/2, step 3413/7134 completed (loss: 3.497089147567749, acc: 0.4017094075679779)
[2024-12-17 01:53:44,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:44,715][root][INFO] - Training Epoch: 1/2, step 3414/7134 completed (loss: 3.4318623542785645, acc: 0.3402777910232544)
[2024-12-17 01:53:44,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:45,001][root][INFO] - Training Epoch: 1/2, step 3415/7134 completed (loss: 3.5450448989868164, acc: 0.3928571343421936)
[2024-12-17 01:53:45,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:45,297][root][INFO] - Training Epoch: 1/2, step 3416/7134 completed (loss: 3.759551763534546, acc: 0.3224043846130371)
[2024-12-17 01:53:45,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:45,583][root][INFO] - Training Epoch: 1/2, step 3417/7134 completed (loss: 3.5878846645355225, acc: 0.34730538725852966)
[2024-12-17 01:53:45,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:45,863][root][INFO] - Training Epoch: 1/2, step 3418/7134 completed (loss: 3.758573055267334, acc: 0.3251533806324005)
[2024-12-17 01:53:45,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:46,133][root][INFO] - Training Epoch: 1/2, step 3419/7134 completed (loss: 3.5794873237609863, acc: 0.3132530152797699)
[2024-12-17 01:53:46,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:46,417][root][INFO] - Training Epoch: 1/2, step 3420/7134 completed (loss: 3.53464412689209, acc: 0.3509933650493622)
[2024-12-17 01:53:46,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:46,704][root][INFO] - Training Epoch: 1/2, step 3421/7134 completed (loss: 3.6975574493408203, acc: 0.3717948794364929)
[2024-12-17 01:53:46,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:46,982][root][INFO] - Training Epoch: 1/2, step 3422/7134 completed (loss: 3.3676598072052, acc: 0.3382352888584137)
[2024-12-17 01:53:47,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:47,270][root][INFO] - Training Epoch: 1/2, step 3423/7134 completed (loss: 3.0719377994537354, acc: 0.44078946113586426)
[2024-12-17 01:53:47,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:47,568][root][INFO] - Training Epoch: 1/2, step 3424/7134 completed (loss: 3.430513620376587, acc: 0.41333332657814026)
[2024-12-17 01:53:47,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:47,841][root][INFO] - Training Epoch: 1/2, step 3425/7134 completed (loss: 3.6023881435394287, acc: 0.378947377204895)
[2024-12-17 01:53:47,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:48,119][root][INFO] - Training Epoch: 1/2, step 3426/7134 completed (loss: 3.1312742233276367, acc: 0.369047611951828)
[2024-12-17 01:53:48,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:48,400][root][INFO] - Training Epoch: 1/2, step 3427/7134 completed (loss: 3.1194605827331543, acc: 0.44155845046043396)
[2024-12-17 01:53:48,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:48,679][root][INFO] - Training Epoch: 1/2, step 3428/7134 completed (loss: 2.9542248249053955, acc: 0.3764705955982208)
[2024-12-17 01:53:48,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:48,973][root][INFO] - Training Epoch: 1/2, step 3429/7134 completed (loss: 3.55924129486084, acc: 0.3802816867828369)
[2024-12-17 01:53:49,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:49,254][root][INFO] - Training Epoch: 1/2, step 3430/7134 completed (loss: 3.350750684738159, acc: 0.4041095972061157)
[2024-12-17 01:53:49,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:49,525][root][INFO] - Training Epoch: 1/2, step 3431/7134 completed (loss: 3.3709874153137207, acc: 0.3478260934352875)
[2024-12-17 01:53:49,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:49,809][root][INFO] - Training Epoch: 1/2, step 3432/7134 completed (loss: 3.023496150970459, acc: 0.44171780347824097)
[2024-12-17 01:53:49,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:50,105][root][INFO] - Training Epoch: 1/2, step 3433/7134 completed (loss: 3.6526873111724854, acc: 0.34558823704719543)
[2024-12-17 01:53:50,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:50,388][root][INFO] - Training Epoch: 1/2, step 3434/7134 completed (loss: 3.167712688446045, acc: 0.37857142090797424)
[2024-12-17 01:53:50,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:50,674][root][INFO] - Training Epoch: 1/2, step 3435/7134 completed (loss: 3.854599952697754, acc: 0.3103448152542114)
[2024-12-17 01:53:50,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:50,962][root][INFO] - Training Epoch: 1/2, step 3436/7134 completed (loss: 3.829359531402588, acc: 0.32116788625717163)
[2024-12-17 01:53:51,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:51,246][root][INFO] - Training Epoch: 1/2, step 3437/7134 completed (loss: 3.997466564178467, acc: 0.3140496015548706)
[2024-12-17 01:53:51,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:51,534][root][INFO] - Training Epoch: 1/2, step 3438/7134 completed (loss: 3.8052759170532227, acc: 0.359649121761322)
[2024-12-17 01:53:51,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:51,787][root][INFO] - Training Epoch: 1/2, step 3439/7134 completed (loss: 3.943875789642334, acc: 0.4365079402923584)
[2024-12-17 01:53:51,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:52,098][root][INFO] - Training Epoch: 1/2, step 3440/7134 completed (loss: 3.573652744293213, acc: 0.43103447556495667)
[2024-12-17 01:53:52,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:52,399][root][INFO] - Training Epoch: 1/2, step 3441/7134 completed (loss: 3.372042179107666, acc: 0.4651162922382355)
[2024-12-17 01:53:52,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:52,696][root][INFO] - Training Epoch: 1/2, step 3442/7134 completed (loss: 3.1159210205078125, acc: 0.39716312289237976)
[2024-12-17 01:53:52,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:52,980][root][INFO] - Training Epoch: 1/2, step 3443/7134 completed (loss: 3.4322447776794434, acc: 0.40449437499046326)
[2024-12-17 01:53:53,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:53,284][root][INFO] - Training Epoch: 1/2, step 3444/7134 completed (loss: 3.2295949459075928, acc: 0.36942675709724426)
[2024-12-17 01:53:53,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:53,571][root][INFO] - Training Epoch: 1/2, step 3445/7134 completed (loss: 3.2804055213928223, acc: 0.37593984603881836)
[2024-12-17 01:53:53,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:53,879][root][INFO] - Training Epoch: 1/2, step 3446/7134 completed (loss: 3.403867244720459, acc: 0.4266666769981384)
[2024-12-17 01:53:53,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:54,186][root][INFO] - Training Epoch: 1/2, step 3447/7134 completed (loss: 3.5630221366882324, acc: 0.3580246865749359)
[2024-12-17 01:53:54,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:54,475][root][INFO] - Training Epoch: 1/2, step 3448/7134 completed (loss: 3.2262468338012695, acc: 0.4219653308391571)
[2024-12-17 01:53:54,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:54,751][root][INFO] - Training Epoch: 1/2, step 3449/7134 completed (loss: 3.380946397781372, acc: 0.42574256658554077)
[2024-12-17 01:53:54,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:55,031][root][INFO] - Training Epoch: 1/2, step 3450/7134 completed (loss: 3.963322162628174, acc: 0.3529411852359772)
[2024-12-17 01:53:55,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:55,303][root][INFO] - Training Epoch: 1/2, step 3451/7134 completed (loss: 3.8592545986175537, acc: 0.326241135597229)
[2024-12-17 01:53:55,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:55,581][root][INFO] - Training Epoch: 1/2, step 3452/7134 completed (loss: 4.272227764129639, acc: 0.30894309282302856)
[2024-12-17 01:53:55,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:55,841][root][INFO] - Training Epoch: 1/2, step 3453/7134 completed (loss: 3.0042223930358887, acc: 0.4583333432674408)
[2024-12-17 01:53:55,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:56,126][root][INFO] - Training Epoch: 1/2, step 3454/7134 completed (loss: 3.3071701526641846, acc: 0.42168673872947693)
[2024-12-17 01:53:56,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:56,401][root][INFO] - Training Epoch: 1/2, step 3455/7134 completed (loss: 2.413405656814575, acc: 0.4906832277774811)
[2024-12-17 01:53:56,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:56,678][root][INFO] - Training Epoch: 1/2, step 3456/7134 completed (loss: 2.314913272857666, acc: 0.5075376629829407)
[2024-12-17 01:53:56,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:56,969][root][INFO] - Training Epoch: 1/2, step 3457/7134 completed (loss: 2.4707672595977783, acc: 0.48591548204421997)
[2024-12-17 01:53:57,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:57,262][root][INFO] - Training Epoch: 1/2, step 3458/7134 completed (loss: 2.460223436355591, acc: 0.5274725556373596)
[2024-12-17 01:53:57,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:57,526][root][INFO] - Training Epoch: 1/2, step 3459/7134 completed (loss: 2.793724298477173, acc: 0.43396225571632385)
[2024-12-17 01:53:57,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:57,781][root][INFO] - Training Epoch: 1/2, step 3460/7134 completed (loss: 3.2852182388305664, acc: 0.4848484992980957)
[2024-12-17 01:53:57,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:58,002][root][INFO] - Training Epoch: 1/2, step 3461/7134 completed (loss: 3.7613892555236816, acc: 0.4000000059604645)
[2024-12-17 01:53:58,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:58,269][root][INFO] - Training Epoch: 1/2, step 3462/7134 completed (loss: 2.610905885696411, acc: 0.4853801131248474)
[2024-12-17 01:53:58,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:58,554][root][INFO] - Training Epoch: 1/2, step 3463/7134 completed (loss: 2.4296586513519287, acc: 0.5123456716537476)
[2024-12-17 01:53:58,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:58,839][root][INFO] - Training Epoch: 1/2, step 3464/7134 completed (loss: 3.0252997875213623, acc: 0.466292142868042)
[2024-12-17 01:53:58,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:59,097][root][INFO] - Training Epoch: 1/2, step 3465/7134 completed (loss: 2.2286877632141113, acc: 0.5925925970077515)
[2024-12-17 01:53:59,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:59,363][root][INFO] - Training Epoch: 1/2, step 3466/7134 completed (loss: 2.635239839553833, acc: 0.5123456716537476)
[2024-12-17 01:53:59,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:59,637][root][INFO] - Training Epoch: 1/2, step 3467/7134 completed (loss: 1.9311836957931519, acc: 0.6440678238868713)
[2024-12-17 01:53:59,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:59,911][root][INFO] - Training Epoch: 1/2, step 3468/7134 completed (loss: 2.188699722290039, acc: 0.5065789222717285)
[2024-12-17 01:54:00,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:00,188][root][INFO] - Training Epoch: 1/2, step 3469/7134 completed (loss: 2.7720839977264404, acc: 0.5112782120704651)
[2024-12-17 01:54:00,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:00,450][root][INFO] - Training Epoch: 1/2, step 3470/7134 completed (loss: 1.7879172563552856, acc: 0.5740740895271301)
[2024-12-17 01:54:00,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:00,717][root][INFO] - Training Epoch: 1/2, step 3471/7134 completed (loss: 1.8318066596984863, acc: 0.644444465637207)
[2024-12-17 01:54:00,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:01,000][root][INFO] - Training Epoch: 1/2, step 3472/7134 completed (loss: 1.9905352592468262, acc: 0.6114649772644043)
[2024-12-17 01:54:01,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:01,319][root][INFO] - Training Epoch: 1/2, step 3473/7134 completed (loss: 1.8722020387649536, acc: 0.6118420958518982)
[2024-12-17 01:54:01,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:01,582][root][INFO] - Training Epoch: 1/2, step 3474/7134 completed (loss: 1.6413449048995972, acc: 0.7028985619544983)
[2024-12-17 01:54:01,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:01,844][root][INFO] - Training Epoch: 1/2, step 3475/7134 completed (loss: 1.6271452903747559, acc: 0.6515151262283325)
[2024-12-17 01:54:01,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:02,120][root][INFO] - Training Epoch: 1/2, step 3476/7134 completed (loss: 1.7902566194534302, acc: 0.6369863152503967)
[2024-12-17 01:54:02,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:02,387][root][INFO] - Training Epoch: 1/2, step 3477/7134 completed (loss: 1.5541410446166992, acc: 0.6554054021835327)
[2024-12-17 01:54:02,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:02,653][root][INFO] - Training Epoch: 1/2, step 3478/7134 completed (loss: 1.1448653936386108, acc: 0.71257483959198)
[2024-12-17 01:54:02,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:02,920][root][INFO] - Training Epoch: 1/2, step 3479/7134 completed (loss: 1.2894090414047241, acc: 0.7307692170143127)
[2024-12-17 01:54:03,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:03,199][root][INFO] - Training Epoch: 1/2, step 3480/7134 completed (loss: 1.665758728981018, acc: 0.6153846383094788)
[2024-12-17 01:54:03,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:03,469][root][INFO] - Training Epoch: 1/2, step 3481/7134 completed (loss: 0.8641610145568848, acc: 0.7819548845291138)
[2024-12-17 01:54:03,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:03,732][root][INFO] - Training Epoch: 1/2, step 3482/7134 completed (loss: 0.7554479837417603, acc: 0.796875)
[2024-12-17 01:54:03,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:04,012][root][INFO] - Training Epoch: 1/2, step 3483/7134 completed (loss: 0.9575442671775818, acc: 0.774193525314331)
[2024-12-17 01:54:04,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:04,270][root][INFO] - Training Epoch: 1/2, step 3484/7134 completed (loss: 1.0769037008285522, acc: 0.7559523582458496)
[2024-12-17 01:54:04,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:04,515][root][INFO] - Training Epoch: 1/2, step 3485/7134 completed (loss: 1.732525110244751, acc: 0.6848484873771667)
[2024-12-17 01:54:04,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:04,786][root][INFO] - Training Epoch: 1/2, step 3486/7134 completed (loss: 2.90366792678833, acc: 0.4188034236431122)
[2024-12-17 01:54:04,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:05,062][root][INFO] - Training Epoch: 1/2, step 3487/7134 completed (loss: 2.023698091506958, acc: 0.5542168617248535)
[2024-12-17 01:54:05,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:05,340][root][INFO] - Training Epoch: 1/2, step 3488/7134 completed (loss: 1.8709276914596558, acc: 0.5857142806053162)
[2024-12-17 01:54:05,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:05,603][root][INFO] - Training Epoch: 1/2, step 3489/7134 completed (loss: 2.5726869106292725, acc: 0.5407407283782959)
[2024-12-17 01:54:05,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:05,893][root][INFO] - Training Epoch: 1/2, step 3490/7134 completed (loss: 2.139606475830078, acc: 0.6573426723480225)
[2024-12-17 01:54:05,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:06,167][root][INFO] - Training Epoch: 1/2, step 3491/7134 completed (loss: 1.574896216392517, acc: 0.662420392036438)
[2024-12-17 01:54:06,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:06,425][root][INFO] - Training Epoch: 1/2, step 3492/7134 completed (loss: 1.3915544748306274, acc: 0.7247706651687622)
[2024-12-17 01:54:06,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:06,721][root][INFO] - Training Epoch: 1/2, step 3493/7134 completed (loss: 1.6115485429763794, acc: 0.654321014881134)
[2024-12-17 01:54:06,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:06,985][root][INFO] - Training Epoch: 1/2, step 3494/7134 completed (loss: 1.3261586427688599, acc: 0.7162162065505981)
[2024-12-17 01:54:07,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:07,258][root][INFO] - Training Epoch: 1/2, step 3495/7134 completed (loss: 1.5780048370361328, acc: 0.6597937941551208)
[2024-12-17 01:54:07,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:07,528][root][INFO] - Training Epoch: 1/2, step 3496/7134 completed (loss: 1.1080230474472046, acc: 0.8235294222831726)
[2024-12-17 01:54:07,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:07,812][root][INFO] - Training Epoch: 1/2, step 3497/7134 completed (loss: 1.1691516637802124, acc: 0.7088607549667358)
[2024-12-17 01:54:07,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:08,107][root][INFO] - Training Epoch: 1/2, step 3498/7134 completed (loss: 1.546999454498291, acc: 0.6835442781448364)
[2024-12-17 01:54:08,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:08,397][root][INFO] - Training Epoch: 1/2, step 3499/7134 completed (loss: 1.4307010173797607, acc: 0.6797385811805725)
[2024-12-17 01:54:08,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:08,682][root][INFO] - Training Epoch: 1/2, step 3500/7134 completed (loss: 1.5143554210662842, acc: 0.6842105388641357)
[2024-12-17 01:54:08,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:08,960][root][INFO] - Training Epoch: 1/2, step 3501/7134 completed (loss: 1.4318856000900269, acc: 0.689393937587738)
[2024-12-17 01:54:09,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:09,227][root][INFO] - Training Epoch: 1/2, step 3502/7134 completed (loss: 1.6009176969528198, acc: 0.7027027010917664)
[2024-12-17 01:54:09,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:09,510][root][INFO] - Training Epoch: 1/2, step 3503/7134 completed (loss: 1.7571485042572021, acc: 0.597122311592102)
[2024-12-17 01:54:09,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:09,784][root][INFO] - Training Epoch: 1/2, step 3504/7134 completed (loss: 0.8808106780052185, acc: 0.8066666722297668)
[2024-12-17 01:54:09,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:10,056][root][INFO] - Training Epoch: 1/2, step 3505/7134 completed (loss: 1.0318118333816528, acc: 0.8015872836112976)
[2024-12-17 01:54:10,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:10,326][root][INFO] - Training Epoch: 1/2, step 3506/7134 completed (loss: 0.9510051608085632, acc: 0.7906976938247681)
[2024-12-17 01:54:10,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:10,607][root][INFO] - Training Epoch: 1/2, step 3507/7134 completed (loss: 0.896682620048523, acc: 0.8055555820465088)
[2024-12-17 01:54:10,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:10,886][root][INFO] - Training Epoch: 1/2, step 3508/7134 completed (loss: 1.0678443908691406, acc: 0.7549669146537781)
[2024-12-17 01:54:10,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:11,170][root][INFO] - Training Epoch: 1/2, step 3509/7134 completed (loss: 1.4581100940704346, acc: 0.6380367875099182)
[2024-12-17 01:54:11,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:11,465][root][INFO] - Training Epoch: 1/2, step 3510/7134 completed (loss: 1.372402310371399, acc: 0.6917293071746826)
[2024-12-17 01:54:11,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:11,768][root][INFO] - Training Epoch: 1/2, step 3511/7134 completed (loss: 0.6000251770019531, acc: 0.8676470518112183)
[2024-12-17 01:54:11,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:12,046][root][INFO] - Training Epoch: 1/2, step 3512/7134 completed (loss: 1.3266725540161133, acc: 0.7179487347602844)
[2024-12-17 01:54:12,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:12,329][root][INFO] - Training Epoch: 1/2, step 3513/7134 completed (loss: 1.0114880800247192, acc: 0.7681159377098083)
[2024-12-17 01:54:12,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:12,607][root][INFO] - Training Epoch: 1/2, step 3514/7134 completed (loss: 0.9659242033958435, acc: 0.760765552520752)
[2024-12-17 01:54:12,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:12,876][root][INFO] - Training Epoch: 1/2, step 3515/7134 completed (loss: 0.7342257499694824, acc: 0.8135592937469482)
[2024-12-17 01:54:12,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:13,163][root][INFO] - Training Epoch: 1/2, step 3516/7134 completed (loss: 0.6575278043746948, acc: 0.8508771657943726)
[2024-12-17 01:54:13,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:13,442][root][INFO] - Training Epoch: 1/2, step 3517/7134 completed (loss: 0.8234894871711731, acc: 0.808080792427063)
[2024-12-17 01:54:13,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:13,722][root][INFO] - Training Epoch: 1/2, step 3518/7134 completed (loss: 0.9632822871208191, acc: 0.8074073791503906)
[2024-12-17 01:54:13,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:14,002][root][INFO] - Training Epoch: 1/2, step 3519/7134 completed (loss: 0.914006769657135, acc: 0.8222222328186035)
[2024-12-17 01:54:14,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:14,290][root][INFO] - Training Epoch: 1/2, step 3520/7134 completed (loss: 1.1197293996810913, acc: 0.7575757503509521)
[2024-12-17 01:54:14,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:14,572][root][INFO] - Training Epoch: 1/2, step 3521/7134 completed (loss: 0.6285197734832764, acc: 0.8502994179725647)
[2024-12-17 01:54:14,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:14,849][root][INFO] - Training Epoch: 1/2, step 3522/7134 completed (loss: 0.5131914019584656, acc: 0.8888888955116272)
[2024-12-17 01:54:15,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:15,148][root][INFO] - Training Epoch: 1/2, step 3523/7134 completed (loss: 0.7609249353408813, acc: 0.8013244867324829)
[2024-12-17 01:54:15,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:15,439][root][INFO] - Training Epoch: 1/2, step 3524/7134 completed (loss: 0.7830055952072144, acc: 0.7967032790184021)
[2024-12-17 01:54:15,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:15,720][root][INFO] - Training Epoch: 1/2, step 3525/7134 completed (loss: 0.9754824042320251, acc: 0.7837837934494019)
[2024-12-17 01:54:15,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:15,999][root][INFO] - Training Epoch: 1/2, step 3526/7134 completed (loss: 0.9928528666496277, acc: 0.7828282713890076)
[2024-12-17 01:54:16,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:16,285][root][INFO] - Training Epoch: 1/2, step 3527/7134 completed (loss: 1.1499618291854858, acc: 0.728723406791687)
[2024-12-17 01:54:16,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:16,562][root][INFO] - Training Epoch: 1/2, step 3528/7134 completed (loss: 0.5346599221229553, acc: 0.879807710647583)
[2024-12-17 01:54:16,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:16,851][root][INFO] - Training Epoch: 1/2, step 3529/7134 completed (loss: 0.6453028321266174, acc: 0.8454545736312866)
[2024-12-17 01:54:17,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:17,167][root][INFO] - Training Epoch: 1/2, step 3530/7134 completed (loss: 1.0201784372329712, acc: 0.8053097128868103)
[2024-12-17 01:54:17,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:17,455][root][INFO] - Training Epoch: 1/2, step 3531/7134 completed (loss: 0.9789700508117676, acc: 0.800000011920929)
[2024-12-17 01:54:17,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:17,734][root][INFO] - Training Epoch: 1/2, step 3532/7134 completed (loss: 0.7718572020530701, acc: 0.8243243098258972)
[2024-12-17 01:54:17,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:18,015][root][INFO] - Training Epoch: 1/2, step 3533/7134 completed (loss: 0.7498042583465576, acc: 0.8222222328186035)
[2024-12-17 01:54:18,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:18,300][root][INFO] - Training Epoch: 1/2, step 3534/7134 completed (loss: 1.368134617805481, acc: 0.7134503126144409)
[2024-12-17 01:54:18,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:18,580][root][INFO] - Training Epoch: 1/2, step 3535/7134 completed (loss: 1.3802663087844849, acc: 0.7625899314880371)
[2024-12-17 01:54:18,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:18,863][root][INFO] - Training Epoch: 1/2, step 3536/7134 completed (loss: 1.2070672512054443, acc: 0.7407407164573669)
[2024-12-17 01:54:18,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:19,128][root][INFO] - Training Epoch: 1/2, step 3537/7134 completed (loss: 1.2411024570465088, acc: 0.75)
[2024-12-17 01:54:19,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:19,394][root][INFO] - Training Epoch: 1/2, step 3538/7134 completed (loss: 0.9326785802841187, acc: 0.8067227005958557)
[2024-12-17 01:54:19,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:19,633][root][INFO] - Training Epoch: 1/2, step 3539/7134 completed (loss: 1.3797632455825806, acc: 0.6781609058380127)
[2024-12-17 01:54:19,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:19,902][root][INFO] - Training Epoch: 1/2, step 3540/7134 completed (loss: 1.6815838813781738, acc: 0.692307710647583)
[2024-12-17 01:54:20,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:20,185][root][INFO] - Training Epoch: 1/2, step 3541/7134 completed (loss: 1.4418405294418335, acc: 0.6666666865348816)
[2024-12-17 01:54:20,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:20,459][root][INFO] - Training Epoch: 1/2, step 3542/7134 completed (loss: 0.8346979022026062, acc: 0.8082191944122314)
[2024-12-17 01:54:20,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:20,718][root][INFO] - Training Epoch: 1/2, step 3543/7134 completed (loss: 1.1361910104751587, acc: 0.7394366264343262)
[2024-12-17 01:54:20,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:20,996][root][INFO] - Training Epoch: 1/2, step 3544/7134 completed (loss: 1.2603873014450073, acc: 0.748344361782074)
[2024-12-17 01:54:21,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:21,286][root][INFO] - Training Epoch: 1/2, step 3545/7134 completed (loss: 0.8247458934783936, acc: 0.7847222089767456)
[2024-12-17 01:54:21,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:21,567][root][INFO] - Training Epoch: 1/2, step 3546/7134 completed (loss: 1.3086153268814087, acc: 0.7194244861602783)
[2024-12-17 01:54:21,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:21,861][root][INFO] - Training Epoch: 1/2, step 3547/7134 completed (loss: 1.4051321744918823, acc: 0.700564980506897)
[2024-12-17 01:54:21,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:22,145][root][INFO] - Training Epoch: 1/2, step 3548/7134 completed (loss: 1.295780062675476, acc: 0.7064220309257507)
[2024-12-17 01:54:22,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:22,417][root][INFO] - Training Epoch: 1/2, step 3549/7134 completed (loss: 1.3887383937835693, acc: 0.7368420958518982)
[2024-12-17 01:54:22,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:22,691][root][INFO] - Training Epoch: 1/2, step 3550/7134 completed (loss: 1.134552001953125, acc: 0.7445255517959595)
[2024-12-17 01:54:22,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:22,970][root][INFO] - Training Epoch: 1/2, step 3551/7134 completed (loss: 1.5658228397369385, acc: 0.7074829936027527)
[2024-12-17 01:54:23,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:23,261][root][INFO] - Training Epoch: 1/2, step 3552/7134 completed (loss: 1.2401726245880127, acc: 0.7007874250411987)
[2024-12-17 01:54:23,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:23,530][root][INFO] - Training Epoch: 1/2, step 3553/7134 completed (loss: 0.9876292943954468, acc: 0.779411792755127)
[2024-12-17 01:54:23,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:23,806][root][INFO] - Training Epoch: 1/2, step 3554/7134 completed (loss: 1.3067818880081177, acc: 0.7607361674308777)
[2024-12-17 01:54:23,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:24,076][root][INFO] - Training Epoch: 1/2, step 3555/7134 completed (loss: 1.4532350301742554, acc: 0.7032257914543152)
[2024-12-17 01:54:24,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:24,330][root][INFO] - Training Epoch: 1/2, step 3556/7134 completed (loss: 1.1220641136169434, acc: 0.7272727489471436)
[2024-12-17 01:54:24,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:24,615][root][INFO] - Training Epoch: 1/2, step 3557/7134 completed (loss: 1.1908133029937744, acc: 0.7659574747085571)
[2024-12-17 01:54:24,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:24,892][root][INFO] - Training Epoch: 1/2, step 3558/7134 completed (loss: 1.3386814594268799, acc: 0.7039999961853027)
[2024-12-17 01:54:25,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:25,164][root][INFO] - Training Epoch: 1/2, step 3559/7134 completed (loss: 1.0554970502853394, acc: 0.7797619104385376)
[2024-12-17 01:54:25,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:25,436][root][INFO] - Training Epoch: 1/2, step 3560/7134 completed (loss: 0.8502250909805298, acc: 0.8032786846160889)
[2024-12-17 01:54:25,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:25,720][root][INFO] - Training Epoch: 1/2, step 3561/7134 completed (loss: 0.8973683714866638, acc: 0.8079096078872681)
[2024-12-17 01:54:25,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:25,986][root][INFO] - Training Epoch: 1/2, step 3562/7134 completed (loss: 0.9383076429367065, acc: 0.8161764740943909)
[2024-12-17 01:54:26,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:26,250][root][INFO] - Training Epoch: 1/2, step 3563/7134 completed (loss: 0.9657039642333984, acc: 0.7801418304443359)
[2024-12-17 01:54:26,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:26,525][root][INFO] - Training Epoch: 1/2, step 3564/7134 completed (loss: 1.252000093460083, acc: 0.761904776096344)
[2024-12-17 01:54:26,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:26,805][root][INFO] - Training Epoch: 1/2, step 3565/7134 completed (loss: 1.0808428525924683, acc: 0.7426470518112183)
[2024-12-17 01:54:27,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:27,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:28,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:28,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:28,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:29,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:29,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:29,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:29,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:30,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:30,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:30,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:30,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:31,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:31,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:31,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:31,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:32,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:32,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:32,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:33,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:33,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:33,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:34,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:34,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:34,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:34,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:35,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:35,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:35,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:36,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:36,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:36,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:37,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:37,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:37,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:38,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:38,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:38,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:38,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:39,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:39,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:39,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:40,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:40,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:40,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:41,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:41,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:41,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:42,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:42,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:42,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:43,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:43,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:43,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:43,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:44,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:44,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:44,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:45,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:45,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:45,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:45,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:46,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:46,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:46,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:47,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:47,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:47,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:47,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:48,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:48,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:48,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:49,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:49,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:49,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:49,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:50,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:50,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:50,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:51,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:51,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:51,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:51,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:52,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:52,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:52,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:53,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:53,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:53,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:54,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:54,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:54,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:54,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:55,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:55,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:55,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:55,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:56,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:56,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:56,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:57,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:57,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:57,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:57,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:57,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:58,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:58,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:58,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:59,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:59,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:59,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:00,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:00,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:00,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:01,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:01,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:01,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:01,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:02,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:02,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:02,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:03,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:03,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:03,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:04,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:04,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:04,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:04,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:05,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:05,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:05,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:06,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:06,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:06,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:07,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:07,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:07,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:07,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:08,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:08,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:08,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:09,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:09,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:09,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:10,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:10,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:10,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:11,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:11,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:11,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:11,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:12,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:12,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:12,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:12,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:13,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:13,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:13,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:14,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:14,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:14,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:15,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:15,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:15,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:15,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:16,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:16,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:16,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:17,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:17,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:17,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:17,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:18,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:18,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:19,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:19,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:19,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:19,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:20,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:20,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:20,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:21,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:21,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:21,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:21,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:22,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:22,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:22,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:23,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:23,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:23,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:23,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:24,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:24,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:24,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:25,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:25,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:25,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:26,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:26,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:26,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:27,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:27,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:27,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:28,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:28,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:28,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:28,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:29,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:29,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:29,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:30,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:30,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:30,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:31,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:31,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:31,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:32,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:32,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:32,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:32,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:33,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:33,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:33,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:34,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:34,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:34,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:34,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:35,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:35,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:35,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:36,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:36,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:36,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:36,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:37,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:37,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:37,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:37,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:38,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:38,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:38,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:38,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:39,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:39,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:40,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:40,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:41,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:41,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:41,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:42,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:42,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:42,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:42,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:43,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:43,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:43,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:44,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:44,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:44,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:45,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:45,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:45,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:45,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:46,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:46,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:46,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:47,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:47,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:47,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:48,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:48,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:48,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:49,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:49,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:49,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:50,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:50,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:50,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:51,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:51,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:51,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:52,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:52,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:52,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:53,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:53,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:53,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:54,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:54,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:54,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:55,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:55,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:55,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:56,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:56,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:57,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:57,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:57,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:57,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:58,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:58,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:58,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:59,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:59,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:59,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:59,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:00,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:00,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:00,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:00,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:01,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:01,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:01,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:02,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:02,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:02,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:03,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:03,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:03,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:04,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:04,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:04,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:04,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:05,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:05,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:05,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:06,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:06,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:06,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:07,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:07,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:07,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:07,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:08,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:08,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:08,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:09,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:09,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:09,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:10,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:10,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:11,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:11,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:11,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:12,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:12,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:12,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:13,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:13,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:13,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:13,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:14,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:14,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:14,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:15,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:15,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:15,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:16,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:16,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:17,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:17,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:17,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:18,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:18,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:19,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:19,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:19,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:20,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:20,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:20,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:21,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:21,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:21,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:21,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:22,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:22,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:22,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:23,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:23,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:23,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:24,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:24,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:24,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:25,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:25,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:25,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:25,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:26,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:26,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:26,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:26,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:27,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:27,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:27,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:27,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:28,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:28,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:28,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:29,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:29,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:29,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:30,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:30,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:30,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:30,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:31,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:31,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:31,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:31,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:32,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:32,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:32,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:32,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:33,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:33,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:33,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:34,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:34,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:34,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:35,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:35,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:35,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:35,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:36,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:36,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:36,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:36,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:37,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:37,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:37,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:38,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:38,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:38,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:39,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:39,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:39,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:39,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:40,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:40,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:40,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:41,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:41,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:41,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:42,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:42,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:42,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:43,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:43,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:43,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:43,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:44,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:44,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:44,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:44,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:45,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:45,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:45,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:45,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:46,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:46,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:46,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:47,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:47,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:47,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:47,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:48,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:48,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:48,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:49,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:49,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:49,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:49,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:50,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:50,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:50,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:51,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:51,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:51,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:51,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:52,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:52,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:52,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:53,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:53,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:53,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:54,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:54,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:54,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:55,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:55,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:55,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:56,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:56,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:56,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:57,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:57,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:57,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:58,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:58,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:58,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:59,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:59,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:00,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:00,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:00,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:00,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:00,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:01,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:01,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:01,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:02,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:02,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:02,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:03,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:03,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:03,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:04,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:04,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:04,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:04,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:05,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:05,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:06,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:06,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:06,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:07,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:07,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:07,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:08,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:08,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:08,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:09,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:09,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:09,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:10,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:10,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:10,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:11,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:11,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:11,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:12,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:12,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:12,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:12,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:13,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:13,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:13,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:13,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:14,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:14,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:14,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:15,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:15,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:15,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:16,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:16,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:16,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:17,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:17,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:17,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:17,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:18,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:18,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:18,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:19,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:19,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:19,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:20,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:20,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:20,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:21,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:21,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:21,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:22,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:22,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:22,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:23,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:23,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:23,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:24,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:24,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:25,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:25,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:25,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:26,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:26,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:26,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:27,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:27,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:27,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:27,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:28,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:28,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:28,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:29,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:29,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:29,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:30,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:30,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:30,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:30,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:31,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:31,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:31,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:32,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:32,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:32,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:33,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:33,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:33,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:33,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:34,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:34,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:34,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:35,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:35,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:35,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:36,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:36,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:36,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:37,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:37,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:37,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:37,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:38,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:39,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:39,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:39,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:39,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:40,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:40,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:41,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:41,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:41,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:42,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:42,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:42,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:42,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:43,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:43,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:43,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:43,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:44,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:44,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:44,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:45,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:45,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:45,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:46,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:46,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:46,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:47,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:47,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:47,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:48,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:48,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:48,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:49,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:49,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:49,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:49,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:50,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:50,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:51,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:51,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:51,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:51,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:52,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:52,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:52,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:53,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:53,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:53,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:54,362][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.6556, device='cuda:0') eval_epoch_loss=tensor(0.9767, device='cuda:0') eval_epoch_acc=tensor(0.7861, device='cuda:0')
[2024-12-17 01:57:54,364][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-12-17 01:57:54,364][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 01:57:54,542][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_1_step_3566_loss_0.9766708016395569/model.pt
[2024-12-17 01:57:54,552][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 0.9766708016395569
[2024-12-17 01:57:54,553][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.7861495614051819
[2024-12-17 01:57:54,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:54,860][root][INFO] - Training Epoch: 1/2, step 3566/7134 completed (loss: 1.4734253883361816, acc: 0.6974790096282959)
[2024-12-17 01:57:54,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:55,122][root][INFO] - Training Epoch: 1/2, step 3567/7134 completed (loss: 0.9684638381004333, acc: 0.8202247023582458)
[2024-12-17 01:57:55,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:55,401][root][INFO] - Training Epoch: 1/2, step 3568/7134 completed (loss: 1.1686686277389526, acc: 0.7234042286872864)
[2024-12-17 01:57:55,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:55,682][root][INFO] - Training Epoch: 1/2, step 3569/7134 completed (loss: 1.1461372375488281, acc: 0.7416666746139526)
[2024-12-17 01:57:55,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:55,948][root][INFO] - Training Epoch: 1/2, step 3570/7134 completed (loss: 1.2244868278503418, acc: 0.7647058963775635)
[2024-12-17 01:57:56,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:56,225][root][INFO] - Training Epoch: 1/2, step 3571/7134 completed (loss: 1.1672303676605225, acc: 0.7584269642829895)
[2024-12-17 01:57:56,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:56,509][root][INFO] - Training Epoch: 1/2, step 3572/7134 completed (loss: 0.8053969144821167, acc: 0.8392857313156128)
[2024-12-17 01:57:56,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:56,792][root][INFO] - Training Epoch: 1/2, step 3573/7134 completed (loss: 1.1237975358963013, acc: 0.75)
[2024-12-17 01:57:56,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:57,059][root][INFO] - Training Epoch: 1/2, step 3574/7134 completed (loss: 1.4078643321990967, acc: 0.6942148804664612)
[2024-12-17 01:57:57,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:57,336][root][INFO] - Training Epoch: 1/2, step 3575/7134 completed (loss: 1.6948118209838867, acc: 0.6118420958518982)
[2024-12-17 01:57:57,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:57,605][root][INFO] - Training Epoch: 1/2, step 3576/7134 completed (loss: 1.178836464881897, acc: 0.7611940503120422)
[2024-12-17 01:57:57,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:57,917][root][INFO] - Training Epoch: 1/2, step 3577/7134 completed (loss: 0.9540020823478699, acc: 0.7783505320549011)
[2024-12-17 01:57:58,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:58,198][root][INFO] - Training Epoch: 1/2, step 3578/7134 completed (loss: 0.8571944832801819, acc: 0.7530120611190796)
[2024-12-17 01:57:58,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:58,481][root][INFO] - Training Epoch: 1/2, step 3579/7134 completed (loss: 1.0034539699554443, acc: 0.7906976938247681)
[2024-12-17 01:57:58,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:58,758][root][INFO] - Training Epoch: 1/2, step 3580/7134 completed (loss: 1.4229135513305664, acc: 0.7167630195617676)
[2024-12-17 01:57:58,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:59,044][root][INFO] - Training Epoch: 1/2, step 3581/7134 completed (loss: 1.3286020755767822, acc: 0.7176470756530762)
[2024-12-17 01:57:59,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:59,332][root][INFO] - Training Epoch: 1/2, step 3582/7134 completed (loss: 0.9498894810676575, acc: 0.811965823173523)
[2024-12-17 01:57:59,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:59,613][root][INFO] - Training Epoch: 1/2, step 3583/7134 completed (loss: 0.8353440761566162, acc: 0.796407163143158)
[2024-12-17 01:57:59,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:59,890][root][INFO] - Training Epoch: 1/2, step 3584/7134 completed (loss: 1.366450548171997, acc: 0.6914893388748169)
[2024-12-17 01:58:00,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:00,182][root][INFO] - Training Epoch: 1/2, step 3585/7134 completed (loss: 0.9858886003494263, acc: 0.8343558311462402)
[2024-12-17 01:58:00,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:00,476][root][INFO] - Training Epoch: 1/2, step 3586/7134 completed (loss: 0.8285847902297974, acc: 0.8535031676292419)
[2024-12-17 01:58:00,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:00,781][root][INFO] - Training Epoch: 1/2, step 3587/7134 completed (loss: 0.7269930839538574, acc: 0.8531468510627747)
[2024-12-17 01:58:00,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:01,093][root][INFO] - Training Epoch: 1/2, step 3588/7134 completed (loss: 1.0186249017715454, acc: 0.7514451146125793)
[2024-12-17 01:58:01,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:01,388][root][INFO] - Training Epoch: 1/2, step 3589/7134 completed (loss: 0.8413845300674438, acc: 0.8142076730728149)
[2024-12-17 01:58:01,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:01,672][root][INFO] - Training Epoch: 1/2, step 3590/7134 completed (loss: 0.7216676473617554, acc: 0.8166666626930237)
[2024-12-17 01:58:01,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:01,953][root][INFO] - Training Epoch: 1/2, step 3591/7134 completed (loss: 0.9112195372581482, acc: 0.8011695742607117)
[2024-12-17 01:58:02,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:02,231][root][INFO] - Training Epoch: 1/2, step 3592/7134 completed (loss: 0.48693352937698364, acc: 0.8785714507102966)
[2024-12-17 01:58:02,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:02,514][root][INFO] - Training Epoch: 1/2, step 3593/7134 completed (loss: 0.8130801916122437, acc: 0.7957746386528015)
[2024-12-17 01:58:02,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:02,786][root][INFO] - Training Epoch: 1/2, step 3594/7134 completed (loss: 0.8448470234870911, acc: 0.8013244867324829)
[2024-12-17 01:58:02,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:03,061][root][INFO] - Training Epoch: 1/2, step 3595/7134 completed (loss: 0.9410884976387024, acc: 0.7843137383460999)
[2024-12-17 01:58:03,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:03,339][root][INFO] - Training Epoch: 1/2, step 3596/7134 completed (loss: 1.1214637756347656, acc: 0.7764706015586853)
[2024-12-17 01:58:03,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:03,613][root][INFO] - Training Epoch: 1/2, step 3597/7134 completed (loss: 0.9715065956115723, acc: 0.75)
[2024-12-17 01:58:03,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:03,916][root][INFO] - Training Epoch: 1/2, step 3598/7134 completed (loss: 1.1187360286712646, acc: 0.7440758347511292)
[2024-12-17 01:58:04,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:04,204][root][INFO] - Training Epoch: 1/2, step 3599/7134 completed (loss: 0.9537551999092102, acc: 0.7945945858955383)
[2024-12-17 01:58:04,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:04,488][root][INFO] - Training Epoch: 1/2, step 3600/7134 completed (loss: 1.271201252937317, acc: 0.6994818449020386)
[2024-12-17 01:58:04,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:04,782][root][INFO] - Training Epoch: 1/2, step 3601/7134 completed (loss: 1.4797362089157104, acc: 0.6797752976417542)
[2024-12-17 01:58:04,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:05,078][root][INFO] - Training Epoch: 1/2, step 3602/7134 completed (loss: 1.4533804655075073, acc: 0.6883720755577087)
[2024-12-17 01:58:05,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:05,357][root][INFO] - Training Epoch: 1/2, step 3603/7134 completed (loss: 1.10257089138031, acc: 0.7295597195625305)
[2024-12-17 01:58:05,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:05,646][root][INFO] - Training Epoch: 1/2, step 3604/7134 completed (loss: 1.018322467803955, acc: 0.7716535329818726)
[2024-12-17 01:58:05,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:05,936][root][INFO] - Training Epoch: 1/2, step 3605/7134 completed (loss: 0.9292795062065125, acc: 0.7668161392211914)
[2024-12-17 01:58:06,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:06,216][root][INFO] - Training Epoch: 1/2, step 3606/7134 completed (loss: 1.346590280532837, acc: 0.7123287916183472)
[2024-12-17 01:58:06,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:06,485][root][INFO] - Training Epoch: 1/2, step 3607/7134 completed (loss: 1.061846137046814, acc: 0.767123281955719)
[2024-12-17 01:58:06,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:06,767][root][INFO] - Training Epoch: 1/2, step 3608/7134 completed (loss: 0.9935083389282227, acc: 0.7718446850776672)
[2024-12-17 01:58:06,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:07,055][root][INFO] - Training Epoch: 1/2, step 3609/7134 completed (loss: 0.7168472409248352, acc: 0.8105263113975525)
[2024-12-17 01:58:07,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:07,341][root][INFO] - Training Epoch: 1/2, step 3610/7134 completed (loss: 1.0310949087142944, acc: 0.7857142686843872)
[2024-12-17 01:58:07,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:07,634][root][INFO] - Training Epoch: 1/2, step 3611/7134 completed (loss: 1.0630637407302856, acc: 0.7828571200370789)
[2024-12-17 01:58:07,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:07,941][root][INFO] - Training Epoch: 1/2, step 3612/7134 completed (loss: 1.089502215385437, acc: 0.767241358757019)
[2024-12-17 01:58:08,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:08,226][root][INFO] - Training Epoch: 1/2, step 3613/7134 completed (loss: 1.113875389099121, acc: 0.7377049326896667)
[2024-12-17 01:58:08,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:08,520][root][INFO] - Training Epoch: 1/2, step 3614/7134 completed (loss: 0.9076308608055115, acc: 0.813829779624939)
[2024-12-17 01:58:08,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:08,802][root][INFO] - Training Epoch: 1/2, step 3615/7134 completed (loss: 0.9506913423538208, acc: 0.8040540814399719)
[2024-12-17 01:58:08,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:09,084][root][INFO] - Training Epoch: 1/2, step 3616/7134 completed (loss: 0.8525775671005249, acc: 0.7950310707092285)
[2024-12-17 01:58:09,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:09,374][root][INFO] - Training Epoch: 1/2, step 3617/7134 completed (loss: 0.9984379410743713, acc: 0.7837837934494019)
[2024-12-17 01:58:09,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:09,648][root][INFO] - Training Epoch: 1/2, step 3618/7134 completed (loss: 1.1309603452682495, acc: 0.7668711543083191)
[2024-12-17 01:58:09,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:09,934][root][INFO] - Training Epoch: 1/2, step 3619/7134 completed (loss: 1.096096158027649, acc: 0.7379912734031677)
[2024-12-17 01:58:10,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:10,230][root][INFO] - Training Epoch: 1/2, step 3620/7134 completed (loss: 1.0485860109329224, acc: 0.742514967918396)
[2024-12-17 01:58:10,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:10,519][root][INFO] - Training Epoch: 1/2, step 3621/7134 completed (loss: 0.9603396654129028, acc: 0.7515923380851746)
[2024-12-17 01:58:10,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:10,833][root][INFO] - Training Epoch: 1/2, step 3622/7134 completed (loss: 0.7972252368927002, acc: 0.8441558480262756)
[2024-12-17 01:58:10,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:11,128][root][INFO] - Training Epoch: 1/2, step 3623/7134 completed (loss: 0.8391068577766418, acc: 0.7678571343421936)
[2024-12-17 01:58:11,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:11,419][root][INFO] - Training Epoch: 1/2, step 3624/7134 completed (loss: 0.9865185618400574, acc: 0.7769784331321716)
[2024-12-17 01:58:11,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:11,697][root][INFO] - Training Epoch: 1/2, step 3625/7134 completed (loss: 1.1700167655944824, acc: 0.6974790096282959)
[2024-12-17 01:58:11,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:11,994][root][INFO] - Training Epoch: 1/2, step 3626/7134 completed (loss: 1.0278581380844116, acc: 0.7752808928489685)
[2024-12-17 01:58:12,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:12,275][root][INFO] - Training Epoch: 1/2, step 3627/7134 completed (loss: 0.9718214273452759, acc: 0.7830188870429993)
[2024-12-17 01:58:12,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:12,556][root][INFO] - Training Epoch: 1/2, step 3628/7134 completed (loss: 1.0010948181152344, acc: 0.761904776096344)
[2024-12-17 01:58:12,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:12,821][root][INFO] - Training Epoch: 1/2, step 3629/7134 completed (loss: 0.9198500514030457, acc: 0.75)
[2024-12-17 01:58:12,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:13,109][root][INFO] - Training Epoch: 1/2, step 3630/7134 completed (loss: 1.1031687259674072, acc: 0.774193525314331)
[2024-12-17 01:58:13,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:13,406][root][INFO] - Training Epoch: 1/2, step 3631/7134 completed (loss: 1.3013731241226196, acc: 0.7285714149475098)
[2024-12-17 01:58:13,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:13,698][root][INFO] - Training Epoch: 1/2, step 3632/7134 completed (loss: 1.1486414670944214, acc: 0.7295082211494446)
[2024-12-17 01:58:13,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:13,979][root][INFO] - Training Epoch: 1/2, step 3633/7134 completed (loss: 0.7824456691741943, acc: 0.7898089289665222)
[2024-12-17 01:58:14,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:14,246][root][INFO] - Training Epoch: 1/2, step 3634/7134 completed (loss: 1.067496657371521, acc: 0.7663551568984985)
[2024-12-17 01:58:14,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:14,516][root][INFO] - Training Epoch: 1/2, step 3635/7134 completed (loss: 0.858542263507843, acc: 0.7931034564971924)
[2024-12-17 01:58:14,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:14,828][root][INFO] - Training Epoch: 1/2, step 3636/7134 completed (loss: 0.6017447710037231, acc: 0.8207547068595886)
[2024-12-17 01:58:14,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:15,130][root][INFO] - Training Epoch: 1/2, step 3637/7134 completed (loss: 0.9613237380981445, acc: 0.7454545497894287)
[2024-12-17 01:58:15,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:15,400][root][INFO] - Training Epoch: 1/2, step 3638/7134 completed (loss: 0.7492709159851074, acc: 0.8131868243217468)
[2024-12-17 01:58:15,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:15,678][root][INFO] - Training Epoch: 1/2, step 3639/7134 completed (loss: 0.8143635392189026, acc: 0.8297872543334961)
[2024-12-17 01:58:15,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:15,975][root][INFO] - Training Epoch: 1/2, step 3640/7134 completed (loss: 0.7585970163345337, acc: 0.8429751992225647)
[2024-12-17 01:58:16,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:16,229][root][INFO] - Training Epoch: 1/2, step 3641/7134 completed (loss: 0.6017321348190308, acc: 0.8387096524238586)
[2024-12-17 01:58:16,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:16,512][root][INFO] - Training Epoch: 1/2, step 3642/7134 completed (loss: 0.3928263485431671, acc: 0.8791946172714233)
[2024-12-17 01:58:16,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:16,807][root][INFO] - Training Epoch: 1/2, step 3643/7134 completed (loss: 0.5599226355552673, acc: 0.875)
[2024-12-17 01:58:16,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:17,116][root][INFO] - Training Epoch: 1/2, step 3644/7134 completed (loss: 0.7784804105758667, acc: 0.8310810923576355)
[2024-12-17 01:58:17,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:17,422][root][INFO] - Training Epoch: 1/2, step 3645/7134 completed (loss: 1.0123724937438965, acc: 0.78125)
[2024-12-17 01:58:17,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:17,727][root][INFO] - Training Epoch: 1/2, step 3646/7134 completed (loss: 1.2077140808105469, acc: 0.7045454382896423)
[2024-12-17 01:58:17,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:18,000][root][INFO] - Training Epoch: 1/2, step 3647/7134 completed (loss: 0.7721467614173889, acc: 0.8426966071128845)
[2024-12-17 01:58:18,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:18,290][root][INFO] - Training Epoch: 1/2, step 3648/7134 completed (loss: 0.8268165588378906, acc: 0.8106508851051331)
[2024-12-17 01:58:18,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:18,592][root][INFO] - Training Epoch: 1/2, step 3649/7134 completed (loss: 0.9843966364860535, acc: 0.791946291923523)
[2024-12-17 01:58:18,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:18,878][root][INFO] - Training Epoch: 1/2, step 3650/7134 completed (loss: 0.9539229869842529, acc: 0.7633135914802551)
[2024-12-17 01:58:19,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:19,160][root][INFO] - Training Epoch: 1/2, step 3651/7134 completed (loss: 1.149692177772522, acc: 0.7530120611190796)
[2024-12-17 01:58:19,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:19,425][root][INFO] - Training Epoch: 1/2, step 3652/7134 completed (loss: 0.6930540800094604, acc: 0.8367347121238708)
[2024-12-17 01:58:19,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:19,716][root][INFO] - Training Epoch: 1/2, step 3653/7134 completed (loss: 1.1994699239730835, acc: 0.7300613522529602)
[2024-12-17 01:58:19,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:20,002][root][INFO] - Training Epoch: 1/2, step 3654/7134 completed (loss: 0.6193822622299194, acc: 0.871999979019165)
[2024-12-17 01:58:20,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:20,283][root][INFO] - Training Epoch: 1/2, step 3655/7134 completed (loss: 0.967792272567749, acc: 0.7604790329933167)
[2024-12-17 01:58:20,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:20,565][root][INFO] - Training Epoch: 1/2, step 3656/7134 completed (loss: 1.0875976085662842, acc: 0.7753623127937317)
[2024-12-17 01:58:20,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:20,853][root][INFO] - Training Epoch: 1/2, step 3657/7134 completed (loss: 0.5088961124420166, acc: 0.881118893623352)
[2024-12-17 01:58:20,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:21,137][root][INFO] - Training Epoch: 1/2, step 3658/7134 completed (loss: 0.7956882119178772, acc: 0.8055555820465088)
[2024-12-17 01:58:21,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:21,441][root][INFO] - Training Epoch: 1/2, step 3659/7134 completed (loss: 1.2280447483062744, acc: 0.7551020383834839)
[2024-12-17 01:58:21,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:21,706][root][INFO] - Training Epoch: 1/2, step 3660/7134 completed (loss: 1.0628595352172852, acc: 0.7654321193695068)
[2024-12-17 01:58:21,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:21,958][root][INFO] - Training Epoch: 1/2, step 3661/7134 completed (loss: 0.6315310597419739, acc: 0.8142856955528259)
[2024-12-17 01:58:22,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:22,257][root][INFO] - Training Epoch: 1/2, step 3662/7134 completed (loss: 1.1926003694534302, acc: 0.7329192757606506)
[2024-12-17 01:58:22,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:22,554][root][INFO] - Training Epoch: 1/2, step 3663/7134 completed (loss: 1.201731562614441, acc: 0.75)
[2024-12-17 01:58:22,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:22,838][root][INFO] - Training Epoch: 1/2, step 3664/7134 completed (loss: 1.0587477684020996, acc: 0.7467532753944397)
[2024-12-17 01:58:22,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:23,118][root][INFO] - Training Epoch: 1/2, step 3665/7134 completed (loss: 0.8485364317893982, acc: 0.8175675868988037)
[2024-12-17 01:58:23,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:23,398][root][INFO] - Training Epoch: 1/2, step 3666/7134 completed (loss: 0.9881805777549744, acc: 0.767123281955719)
[2024-12-17 01:58:23,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:23,687][root][INFO] - Training Epoch: 1/2, step 3667/7134 completed (loss: 1.3501360416412354, acc: 0.682170569896698)
[2024-12-17 01:58:23,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:23,964][root][INFO] - Training Epoch: 1/2, step 3668/7134 completed (loss: 0.7884628772735596, acc: 0.7931034564971924)
[2024-12-17 01:58:24,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:24,255][root][INFO] - Training Epoch: 1/2, step 3669/7134 completed (loss: 0.5016055703163147, acc: 0.8760330677032471)
[2024-12-17 01:58:24,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:24,543][root][INFO] - Training Epoch: 1/2, step 3670/7134 completed (loss: 0.4815370440483093, acc: 0.8734939694404602)
[2024-12-17 01:58:24,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:24,818][root][INFO] - Training Epoch: 1/2, step 3671/7134 completed (loss: 0.7854993343353271, acc: 0.8354430198669434)
[2024-12-17 01:58:24,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:25,118][root][INFO] - Training Epoch: 1/2, step 3672/7134 completed (loss: 0.6316076517105103, acc: 0.8508287072181702)
[2024-12-17 01:58:25,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:25,408][root][INFO] - Training Epoch: 1/2, step 3673/7134 completed (loss: 0.6313555240631104, acc: 0.8551723957061768)
[2024-12-17 01:58:25,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:25,692][root][INFO] - Training Epoch: 1/2, step 3674/7134 completed (loss: 0.3583332896232605, acc: 0.9054054021835327)
[2024-12-17 01:58:25,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:25,973][root][INFO] - Training Epoch: 1/2, step 3675/7134 completed (loss: 0.603392481803894, acc: 0.8508287072181702)
[2024-12-17 01:58:26,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:26,249][root][INFO] - Training Epoch: 1/2, step 3676/7134 completed (loss: 0.6249732971191406, acc: 0.8205128312110901)
[2024-12-17 01:58:26,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:26,534][root][INFO] - Training Epoch: 1/2, step 3677/7134 completed (loss: 0.5774937868118286, acc: 0.8579545617103577)
[2024-12-17 01:58:26,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:26,819][root][INFO] - Training Epoch: 1/2, step 3678/7134 completed (loss: 0.9017175436019897, acc: 0.8164557218551636)
[2024-12-17 01:58:26,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:27,112][root][INFO] - Training Epoch: 1/2, step 3679/7134 completed (loss: 0.7956427931785583, acc: 0.8538461327552795)
[2024-12-17 01:58:27,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:27,394][root][INFO] - Training Epoch: 1/2, step 3680/7134 completed (loss: 0.6565740704536438, acc: 0.8600000143051147)
[2024-12-17 01:58:27,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:27,671][root][INFO] - Training Epoch: 1/2, step 3681/7134 completed (loss: 0.7618703246116638, acc: 0.831250011920929)
[2024-12-17 01:58:27,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:27,956][root][INFO] - Training Epoch: 1/2, step 3682/7134 completed (loss: 0.5584946870803833, acc: 0.8690476417541504)
[2024-12-17 01:58:28,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:28,251][root][INFO] - Training Epoch: 1/2, step 3683/7134 completed (loss: 0.5430382490158081, acc: 0.9117646813392639)
[2024-12-17 01:58:28,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:28,527][root][INFO] - Training Epoch: 1/2, step 3684/7134 completed (loss: 0.485726922750473, acc: 0.8947368264198303)
[2024-12-17 01:58:28,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:28,799][root][INFO] - Training Epoch: 1/2, step 3685/7134 completed (loss: 0.49722298979759216, acc: 0.869918704032898)
[2024-12-17 01:58:28,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:29,085][root][INFO] - Training Epoch: 1/2, step 3686/7134 completed (loss: 0.6186977028846741, acc: 0.8802816867828369)
[2024-12-17 01:58:29,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:29,366][root][INFO] - Training Epoch: 1/2, step 3687/7134 completed (loss: 0.603725790977478, acc: 0.8633540272712708)
[2024-12-17 01:58:29,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:29,644][root][INFO] - Training Epoch: 1/2, step 3688/7134 completed (loss: 0.6315032243728638, acc: 0.8666666746139526)
[2024-12-17 01:58:29,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:29,924][root][INFO] - Training Epoch: 1/2, step 3689/7134 completed (loss: 0.6057910919189453, acc: 0.8510638475418091)
[2024-12-17 01:58:30,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:30,230][root][INFO] - Training Epoch: 1/2, step 3690/7134 completed (loss: 0.5235018730163574, acc: 0.8734177350997925)
[2024-12-17 01:58:30,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:30,496][root][INFO] - Training Epoch: 1/2, step 3691/7134 completed (loss: 0.4265642464160919, acc: 0.8910890817642212)
[2024-12-17 01:58:30,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:30,778][root][INFO] - Training Epoch: 1/2, step 3692/7134 completed (loss: 0.697265088558197, acc: 0.8282208442687988)
[2024-12-17 01:58:30,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:31,070][root][INFO] - Training Epoch: 1/2, step 3693/7134 completed (loss: 0.5514705181121826, acc: 0.8787878751754761)
[2024-12-17 01:58:31,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:31,360][root][INFO] - Training Epoch: 1/2, step 3694/7134 completed (loss: 0.6393812894821167, acc: 0.8687499761581421)
[2024-12-17 01:58:31,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:31,642][root][INFO] - Training Epoch: 1/2, step 3695/7134 completed (loss: 0.5675429701805115, acc: 0.8598726391792297)
[2024-12-17 01:58:31,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:31,933][root][INFO] - Training Epoch: 1/2, step 3696/7134 completed (loss: 0.6059144139289856, acc: 0.8678160905838013)
[2024-12-17 01:58:32,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:32,203][root][INFO] - Training Epoch: 1/2, step 3697/7134 completed (loss: 0.3740914762020111, acc: 0.9268292784690857)
[2024-12-17 01:58:32,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:32,474][root][INFO] - Training Epoch: 1/2, step 3698/7134 completed (loss: 0.297785222530365, acc: 0.9379310607910156)
[2024-12-17 01:58:32,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:32,741][root][INFO] - Training Epoch: 1/2, step 3699/7134 completed (loss: 0.4113917648792267, acc: 0.9212598204612732)
[2024-12-17 01:58:32,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:33,021][root][INFO] - Training Epoch: 1/2, step 3700/7134 completed (loss: 0.5185419321060181, acc: 0.8805031180381775)
[2024-12-17 01:58:33,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:33,308][root][INFO] - Training Epoch: 1/2, step 3701/7134 completed (loss: 0.4520133435726166, acc: 0.8759124279022217)
[2024-12-17 01:58:33,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:33,585][root][INFO] - Training Epoch: 1/2, step 3702/7134 completed (loss: 0.5932239890098572, acc: 0.8909090757369995)
[2024-12-17 01:58:33,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:33,880][root][INFO] - Training Epoch: 1/2, step 3703/7134 completed (loss: 0.4936020076274872, acc: 0.875)
[2024-12-17 01:58:34,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:34,155][root][INFO] - Training Epoch: 1/2, step 3704/7134 completed (loss: 0.41811564564704895, acc: 0.9207921028137207)
[2024-12-17 01:58:34,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:34,434][root][INFO] - Training Epoch: 1/2, step 3705/7134 completed (loss: 1.0168451070785522, acc: 0.7668711543083191)
[2024-12-17 01:58:34,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:34,712][root][INFO] - Training Epoch: 1/2, step 3706/7134 completed (loss: 0.7327826619148254, acc: 0.8564356565475464)
[2024-12-17 01:58:34,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:34,989][root][INFO] - Training Epoch: 1/2, step 3707/7134 completed (loss: 0.4479787051677704, acc: 0.8933333158493042)
[2024-12-17 01:58:35,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:35,286][root][INFO] - Training Epoch: 1/2, step 3708/7134 completed (loss: 0.6586424708366394, acc: 0.8410256505012512)
[2024-12-17 01:58:35,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:35,578][root][INFO] - Training Epoch: 1/2, step 3709/7134 completed (loss: 0.5938756465911865, acc: 0.8796296119689941)
[2024-12-17 01:58:35,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:35,866][root][INFO] - Training Epoch: 1/2, step 3710/7134 completed (loss: 0.7455105185508728, acc: 0.8240740895271301)
[2024-12-17 01:58:36,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:36,139][root][INFO] - Training Epoch: 1/2, step 3711/7134 completed (loss: 0.6515831351280212, acc: 0.8296703100204468)
[2024-12-17 01:58:36,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:36,430][root][INFO] - Training Epoch: 1/2, step 3712/7134 completed (loss: 0.8715370893478394, acc: 0.8369565010070801)
[2024-12-17 01:58:36,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:36,711][root][INFO] - Training Epoch: 1/2, step 3713/7134 completed (loss: 0.5419557690620422, acc: 0.8848921060562134)
[2024-12-17 01:58:36,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:36,993][root][INFO] - Training Epoch: 1/2, step 3714/7134 completed (loss: 0.5036880970001221, acc: 0.8756476640701294)
[2024-12-17 01:58:37,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:37,266][root][INFO] - Training Epoch: 1/2, step 3715/7134 completed (loss: 0.3703111708164215, acc: 0.9202127456665039)
[2024-12-17 01:58:37,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:37,550][root][INFO] - Training Epoch: 1/2, step 3716/7134 completed (loss: 0.7094455361366272, acc: 0.8578680157661438)
[2024-12-17 01:58:37,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:37,840][root][INFO] - Training Epoch: 1/2, step 3717/7134 completed (loss: 0.5457334518432617, acc: 0.8963414430618286)
[2024-12-17 01:58:37,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:38,137][root][INFO] - Training Epoch: 1/2, step 3718/7134 completed (loss: 0.5780864953994751, acc: 0.859375)
[2024-12-17 01:58:38,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:38,423][root][INFO] - Training Epoch: 1/2, step 3719/7134 completed (loss: 0.6404563784599304, acc: 0.8421052694320679)
[2024-12-17 01:58:38,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:38,731][root][INFO] - Training Epoch: 1/2, step 3720/7134 completed (loss: 0.2796413004398346, acc: 0.9240506291389465)
[2024-12-17 01:58:38,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:39,039][root][INFO] - Training Epoch: 1/2, step 3721/7134 completed (loss: 0.567213773727417, acc: 0.849711000919342)
[2024-12-17 01:58:39,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:39,341][root][INFO] - Training Epoch: 1/2, step 3722/7134 completed (loss: 0.536182165145874, acc: 0.8652849793434143)
[2024-12-17 01:58:39,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:39,639][root][INFO] - Training Epoch: 1/2, step 3723/7134 completed (loss: 0.5600770115852356, acc: 0.8645161390304565)
[2024-12-17 01:58:39,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:39,939][root][INFO] - Training Epoch: 1/2, step 3724/7134 completed (loss: 0.44843077659606934, acc: 0.9036144614219666)
[2024-12-17 01:58:40,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:40,246][root][INFO] - Training Epoch: 1/2, step 3725/7134 completed (loss: 0.7524031400680542, acc: 0.8658536672592163)
[2024-12-17 01:58:40,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:40,552][root][INFO] - Training Epoch: 1/2, step 3726/7134 completed (loss: 0.4540577530860901, acc: 0.8894472122192383)
[2024-12-17 01:58:40,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:40,829][root][INFO] - Training Epoch: 1/2, step 3727/7134 completed (loss: 0.38621753454208374, acc: 0.8959537744522095)
[2024-12-17 01:58:40,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:41,115][root][INFO] - Training Epoch: 1/2, step 3728/7134 completed (loss: 0.495857834815979, acc: 0.8522167205810547)
[2024-12-17 01:58:41,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:41,401][root][INFO] - Training Epoch: 1/2, step 3729/7134 completed (loss: 0.41914886236190796, acc: 0.8915094137191772)
[2024-12-17 01:58:41,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:41,682][root][INFO] - Training Epoch: 1/2, step 3730/7134 completed (loss: 0.4655575454235077, acc: 0.8848484754562378)
[2024-12-17 01:58:41,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:41,975][root][INFO] - Training Epoch: 1/2, step 3731/7134 completed (loss: 0.41871556639671326, acc: 0.9137930870056152)
[2024-12-17 01:58:42,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:42,266][root][INFO] - Training Epoch: 1/2, step 3732/7134 completed (loss: 0.4261716306209564, acc: 0.8974359035491943)
[2024-12-17 01:58:42,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:42,537][root][INFO] - Training Epoch: 1/2, step 3733/7134 completed (loss: 0.5038849711418152, acc: 0.888198733329773)
[2024-12-17 01:58:42,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:42,821][root][INFO] - Training Epoch: 1/2, step 3734/7134 completed (loss: 0.8740889430046082, acc: 0.8205128312110901)
[2024-12-17 01:58:42,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:43,103][root][INFO] - Training Epoch: 1/2, step 3735/7134 completed (loss: 0.6349180936813354, acc: 0.850649356842041)
[2024-12-17 01:58:43,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:43,390][root][INFO] - Training Epoch: 1/2, step 3736/7134 completed (loss: 0.6280232071876526, acc: 0.8235294222831726)
[2024-12-17 01:58:43,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:43,674][root][INFO] - Training Epoch: 1/2, step 3737/7134 completed (loss: 0.44002246856689453, acc: 0.8727272748947144)
[2024-12-17 01:58:43,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:43,945][root][INFO] - Training Epoch: 1/2, step 3738/7134 completed (loss: 0.38310641050338745, acc: 0.9166666865348816)
[2024-12-17 01:58:44,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:44,225][root][INFO] - Training Epoch: 1/2, step 3739/7134 completed (loss: 0.7775476574897766, acc: 0.8510638475418091)
[2024-12-17 01:58:44,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:44,505][root][INFO] - Training Epoch: 1/2, step 3740/7134 completed (loss: 0.44875434041023254, acc: 0.8853503465652466)
[2024-12-17 01:58:44,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:44,791][root][INFO] - Training Epoch: 1/2, step 3741/7134 completed (loss: 0.5545223355293274, acc: 0.8908045887947083)
[2024-12-17 01:58:44,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:45,065][root][INFO] - Training Epoch: 1/2, step 3742/7134 completed (loss: 0.6451235413551331, acc: 0.8979591727256775)
[2024-12-17 01:58:45,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:45,346][root][INFO] - Training Epoch: 1/2, step 3743/7134 completed (loss: 0.6671554446220398, acc: 0.8529411554336548)
[2024-12-17 01:58:45,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:45,636][root][INFO] - Training Epoch: 1/2, step 3744/7134 completed (loss: 0.550775945186615, acc: 0.8779069781303406)
[2024-12-17 01:58:45,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:45,918][root][INFO] - Training Epoch: 1/2, step 3745/7134 completed (loss: 0.8212860226631165, acc: 0.8476190567016602)
[2024-12-17 01:58:46,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:46,200][root][INFO] - Training Epoch: 1/2, step 3746/7134 completed (loss: 0.48742011189460754, acc: 0.8926553726196289)
[2024-12-17 01:58:46,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:46,496][root][INFO] - Training Epoch: 1/2, step 3747/7134 completed (loss: 0.594139575958252, acc: 0.8777777552604675)
[2024-12-17 01:58:46,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:46,767][root][INFO] - Training Epoch: 1/2, step 3748/7134 completed (loss: 0.4258030951023102, acc: 0.8866666555404663)
[2024-12-17 01:58:46,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:47,058][root][INFO] - Training Epoch: 1/2, step 3749/7134 completed (loss: 0.682741105556488, acc: 0.8690476417541504)
[2024-12-17 01:58:47,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:47,352][root][INFO] - Training Epoch: 1/2, step 3750/7134 completed (loss: 0.3198290765285492, acc: 0.907975435256958)
[2024-12-17 01:58:47,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:47,649][root][INFO] - Training Epoch: 1/2, step 3751/7134 completed (loss: 0.6939830183982849, acc: 0.8313252925872803)
[2024-12-17 01:58:47,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:47,958][root][INFO] - Training Epoch: 1/2, step 3752/7134 completed (loss: 0.7548266053199768, acc: 0.8679245114326477)
[2024-12-17 01:58:48,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:48,261][root][INFO] - Training Epoch: 1/2, step 3753/7134 completed (loss: 0.8767707943916321, acc: 0.803680956363678)
[2024-12-17 01:58:48,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:48,543][root][INFO] - Training Epoch: 1/2, step 3754/7134 completed (loss: 0.40234217047691345, acc: 0.8903225660324097)
[2024-12-17 01:58:48,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:48,816][root][INFO] - Training Epoch: 1/2, step 3755/7134 completed (loss: 0.7002927660942078, acc: 0.8347107172012329)
[2024-12-17 01:58:48,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:49,097][root][INFO] - Training Epoch: 1/2, step 3756/7134 completed (loss: 0.5736622214317322, acc: 0.8728323578834534)
[2024-12-17 01:58:49,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:49,391][root][INFO] - Training Epoch: 1/2, step 3757/7134 completed (loss: 0.948144793510437, acc: 0.8246753215789795)
[2024-12-17 01:58:49,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:49,674][root][INFO] - Training Epoch: 1/2, step 3758/7134 completed (loss: 0.7299066185951233, acc: 0.8582677245140076)
[2024-12-17 01:58:49,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:49,946][root][INFO] - Training Epoch: 1/2, step 3759/7134 completed (loss: 0.6450269222259521, acc: 0.8251748085021973)
[2024-12-17 01:58:50,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:50,256][root][INFO] - Training Epoch: 1/2, step 3760/7134 completed (loss: 0.6029002666473389, acc: 0.8475610017776489)
[2024-12-17 01:58:50,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:50,539][root][INFO] - Training Epoch: 1/2, step 3761/7134 completed (loss: 0.46568766236305237, acc: 0.8863636255264282)
[2024-12-17 01:58:50,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:50,838][root][INFO] - Training Epoch: 1/2, step 3762/7134 completed (loss: 0.45482420921325684, acc: 0.8881579041481018)
[2024-12-17 01:58:50,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:51,132][root][INFO] - Training Epoch: 1/2, step 3763/7134 completed (loss: 0.39395302534103394, acc: 0.9214285612106323)
[2024-12-17 01:58:51,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:51,416][root][INFO] - Training Epoch: 1/2, step 3764/7134 completed (loss: 0.6617477536201477, acc: 0.8383233547210693)
[2024-12-17 01:58:51,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:51,740][root][INFO] - Training Epoch: 1/2, step 3765/7134 completed (loss: 0.5234054923057556, acc: 0.8863636255264282)
[2024-12-17 01:58:51,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:52,005][root][INFO] - Training Epoch: 1/2, step 3766/7134 completed (loss: 0.6829128265380859, acc: 0.8389261960983276)
[2024-12-17 01:58:52,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:52,282][root][INFO] - Training Epoch: 1/2, step 3767/7134 completed (loss: 0.4262509047985077, acc: 0.916201114654541)
[2024-12-17 01:58:52,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:52,596][root][INFO] - Training Epoch: 1/2, step 3768/7134 completed (loss: 0.7128387689590454, acc: 0.8557692170143127)
[2024-12-17 01:58:52,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:52,881][root][INFO] - Training Epoch: 1/2, step 3769/7134 completed (loss: 0.6003731489181519, acc: 0.8647058606147766)
[2024-12-17 01:58:52,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:53,156][root][INFO] - Training Epoch: 1/2, step 3770/7134 completed (loss: 0.39692431688308716, acc: 0.8859060406684875)
[2024-12-17 01:58:53,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:53,440][root][INFO] - Training Epoch: 1/2, step 3771/7134 completed (loss: 0.425203412771225, acc: 0.9013158082962036)
[2024-12-17 01:58:53,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:53,728][root][INFO] - Training Epoch: 1/2, step 3772/7134 completed (loss: 0.6472811102867126, acc: 0.8571428656578064)
[2024-12-17 01:58:53,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:54,017][root][INFO] - Training Epoch: 1/2, step 3773/7134 completed (loss: 0.5111046433448792, acc: 0.8936170339584351)
[2024-12-17 01:58:54,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:54,314][root][INFO] - Training Epoch: 1/2, step 3774/7134 completed (loss: 0.5169438719749451, acc: 0.8516483306884766)
[2024-12-17 01:58:54,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:54,600][root][INFO] - Training Epoch: 1/2, step 3775/7134 completed (loss: 0.5670064687728882, acc: 0.888198733329773)
[2024-12-17 01:58:54,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:54,906][root][INFO] - Training Epoch: 1/2, step 3776/7134 completed (loss: 0.6627878546714783, acc: 0.8461538553237915)
[2024-12-17 01:58:55,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:55,210][root][INFO] - Training Epoch: 1/2, step 3777/7134 completed (loss: 0.4715929925441742, acc: 0.8999999761581421)
[2024-12-17 01:58:55,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:55,518][root][INFO] - Training Epoch: 1/2, step 3778/7134 completed (loss: 0.5239246487617493, acc: 0.8662790656089783)
[2024-12-17 01:58:55,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:55,807][root][INFO] - Training Epoch: 1/2, step 3779/7134 completed (loss: 0.5113983750343323, acc: 0.862500011920929)
[2024-12-17 01:58:55,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:56,105][root][INFO] - Training Epoch: 1/2, step 3780/7134 completed (loss: 0.37856245040893555, acc: 0.903030276298523)
[2024-12-17 01:58:56,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:56,399][root][INFO] - Training Epoch: 1/2, step 3781/7134 completed (loss: 0.5754450559616089, acc: 0.8757764101028442)
[2024-12-17 01:58:56,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:56,684][root][INFO] - Training Epoch: 1/2, step 3782/7134 completed (loss: 0.5728960037231445, acc: 0.8553459048271179)
[2024-12-17 01:58:56,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:56,972][root][INFO] - Training Epoch: 1/2, step 3783/7134 completed (loss: 0.5967750549316406, acc: 0.8520709872245789)
[2024-12-17 01:58:57,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:57,255][root][INFO] - Training Epoch: 1/2, step 3784/7134 completed (loss: 0.7037162184715271, acc: 0.8255033493041992)
[2024-12-17 01:58:57,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:57,534][root][INFO] - Training Epoch: 1/2, step 3785/7134 completed (loss: 0.3805621266365051, acc: 0.8794326186180115)
[2024-12-17 01:58:57,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:57,822][root][INFO] - Training Epoch: 1/2, step 3786/7134 completed (loss: 0.45965084433555603, acc: 0.898809552192688)
[2024-12-17 01:58:57,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:58,129][root][INFO] - Training Epoch: 1/2, step 3787/7134 completed (loss: 0.5281234979629517, acc: 0.8769230842590332)
[2024-12-17 01:58:58,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:58,418][root][INFO] - Training Epoch: 1/2, step 3788/7134 completed (loss: 0.6565994620323181, acc: 0.8588957190513611)
[2024-12-17 01:58:58,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:58,711][root][INFO] - Training Epoch: 1/2, step 3789/7134 completed (loss: 0.584235668182373, acc: 0.8764705657958984)
[2024-12-17 01:58:58,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:59,003][root][INFO] - Training Epoch: 1/2, step 3790/7134 completed (loss: 0.8969591856002808, acc: 0.8235294222831726)
[2024-12-17 01:58:59,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:59,272][root][INFO] - Training Epoch: 1/2, step 3791/7134 completed (loss: 0.4679661989212036, acc: 0.9017341136932373)
[2024-12-17 01:58:59,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:59,544][root][INFO] - Training Epoch: 1/2, step 3792/7134 completed (loss: 0.4596811532974243, acc: 0.8796992301940918)
[2024-12-17 01:58:59,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:59,818][root][INFO] - Training Epoch: 1/2, step 3793/7134 completed (loss: 0.5412915945053101, acc: 0.8620689511299133)
[2024-12-17 01:58:59,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:00,117][root][INFO] - Training Epoch: 1/2, step 3794/7134 completed (loss: 0.8110837340354919, acc: 0.8444444537162781)
[2024-12-17 01:59:00,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:00,409][root][INFO] - Training Epoch: 1/2, step 3795/7134 completed (loss: 0.7423906922340393, acc: 0.8055555820465088)
[2024-12-17 01:59:00,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:00,693][root][INFO] - Training Epoch: 1/2, step 3796/7134 completed (loss: 0.6831514835357666, acc: 0.8304093480110168)
[2024-12-17 01:59:00,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:00,980][root][INFO] - Training Epoch: 1/2, step 3797/7134 completed (loss: 0.5456934571266174, acc: 0.8545454740524292)
[2024-12-17 01:59:01,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:01,285][root][INFO] - Training Epoch: 1/2, step 3798/7134 completed (loss: 0.7354117631912231, acc: 0.8427672982215881)
[2024-12-17 01:59:01,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:01,586][root][INFO] - Training Epoch: 1/2, step 3799/7134 completed (loss: 0.6669100522994995, acc: 0.8644067645072937)
[2024-12-17 01:59:01,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:01,876][root][INFO] - Training Epoch: 1/2, step 3800/7134 completed (loss: 0.7486700415611267, acc: 0.8068965673446655)
[2024-12-17 01:59:02,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:02,166][root][INFO] - Training Epoch: 1/2, step 3801/7134 completed (loss: 0.629174530506134, acc: 0.8287292718887329)
[2024-12-17 01:59:02,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:02,459][root][INFO] - Training Epoch: 1/2, step 3802/7134 completed (loss: 0.5149512887001038, acc: 0.8541666865348816)
[2024-12-17 01:59:02,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:02,750][root][INFO] - Training Epoch: 1/2, step 3803/7134 completed (loss: 0.4814901053905487, acc: 0.8789808750152588)
[2024-12-17 01:59:02,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:03,047][root][INFO] - Training Epoch: 1/2, step 3804/7134 completed (loss: 0.84205162525177, acc: 0.7816901206970215)
[2024-12-17 01:59:03,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:03,339][root][INFO] - Training Epoch: 1/2, step 3805/7134 completed (loss: 0.5403541326522827, acc: 0.868571400642395)
[2024-12-17 01:59:03,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:03,639][root][INFO] - Training Epoch: 1/2, step 3806/7134 completed (loss: 0.6737063527107239, acc: 0.8055555820465088)
[2024-12-17 01:59:03,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:03,911][root][INFO] - Training Epoch: 1/2, step 3807/7134 completed (loss: 0.4535132646560669, acc: 0.8904109597206116)
[2024-12-17 01:59:04,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:04,226][root][INFO] - Training Epoch: 1/2, step 3808/7134 completed (loss: 0.6075338125228882, acc: 0.83152174949646)
[2024-12-17 01:59:04,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:04,510][root][INFO] - Training Epoch: 1/2, step 3809/7134 completed (loss: 0.5408232808113098, acc: 0.8488371968269348)
[2024-12-17 01:59:04,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:04,793][root][INFO] - Training Epoch: 1/2, step 3810/7134 completed (loss: 0.5496088266372681, acc: 0.8766233921051025)
[2024-12-17 01:59:04,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:05,082][root][INFO] - Training Epoch: 1/2, step 3811/7134 completed (loss: 0.6103431582450867, acc: 0.85628741979599)
[2024-12-17 01:59:05,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:05,372][root][INFO] - Training Epoch: 1/2, step 3812/7134 completed (loss: 0.765988826751709, acc: 0.8299319744110107)
[2024-12-17 01:59:05,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:05,663][root][INFO] - Training Epoch: 1/2, step 3813/7134 completed (loss: 0.7602363228797913, acc: 0.8324324488639832)
[2024-12-17 01:59:05,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:05,959][root][INFO] - Training Epoch: 1/2, step 3814/7134 completed (loss: 0.2593326270580292, acc: 0.9142857193946838)
[2024-12-17 01:59:06,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:06,231][root][INFO] - Training Epoch: 1/2, step 3815/7134 completed (loss: 0.5569011569023132, acc: 0.8552631735801697)
[2024-12-17 01:59:06,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:06,523][root][INFO] - Training Epoch: 1/2, step 3816/7134 completed (loss: 0.5116918683052063, acc: 0.8731343150138855)
[2024-12-17 01:59:06,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:06,807][root][INFO] - Training Epoch: 1/2, step 3817/7134 completed (loss: 0.8426546454429626, acc: 0.8314606547355652)
[2024-12-17 01:59:06,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:07,104][root][INFO] - Training Epoch: 1/2, step 3818/7134 completed (loss: 0.629773736000061, acc: 0.8245614171028137)
[2024-12-17 01:59:07,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:07,412][root][INFO] - Training Epoch: 1/2, step 3819/7134 completed (loss: 0.9424648880958557, acc: 0.7857142686843872)
[2024-12-17 01:59:07,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:07,700][root][INFO] - Training Epoch: 1/2, step 3820/7134 completed (loss: 0.846190869808197, acc: 0.8611111044883728)
[2024-12-17 01:59:07,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:07,978][root][INFO] - Training Epoch: 1/2, step 3821/7134 completed (loss: 0.6411364674568176, acc: 0.8424657583236694)
[2024-12-17 01:59:08,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:08,254][root][INFO] - Training Epoch: 1/2, step 3822/7134 completed (loss: 0.7003201842308044, acc: 0.8207547068595886)
[2024-12-17 01:59:08,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:08,547][root][INFO] - Training Epoch: 1/2, step 3823/7134 completed (loss: 0.4305550456047058, acc: 0.8791946172714233)
[2024-12-17 01:59:08,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:08,816][root][INFO] - Training Epoch: 1/2, step 3824/7134 completed (loss: 0.8332054018974304, acc: 0.875)
[2024-12-17 01:59:08,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:09,111][root][INFO] - Training Epoch: 1/2, step 3825/7134 completed (loss: 0.4577982723712921, acc: 0.8796296119689941)
[2024-12-17 01:59:09,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:09,410][root][INFO] - Training Epoch: 1/2, step 3826/7134 completed (loss: 0.6236806511878967, acc: 0.8521126508712769)
[2024-12-17 01:59:09,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:09,698][root][INFO] - Training Epoch: 1/2, step 3827/7134 completed (loss: 0.477133572101593, acc: 0.8662420511245728)
[2024-12-17 01:59:09,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:09,991][root][INFO] - Training Epoch: 1/2, step 3828/7134 completed (loss: 0.5139018297195435, acc: 0.875)
[2024-12-17 01:59:10,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:10,283][root][INFO] - Training Epoch: 1/2, step 3829/7134 completed (loss: 0.8224261999130249, acc: 0.828125)
[2024-12-17 01:59:10,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:10,591][root][INFO] - Training Epoch: 1/2, step 3830/7134 completed (loss: 0.6511666774749756, acc: 0.8666666746139526)
[2024-12-17 01:59:10,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:10,871][root][INFO] - Training Epoch: 1/2, step 3831/7134 completed (loss: 0.5507197976112366, acc: 0.8684210777282715)
[2024-12-17 01:59:11,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:11,198][root][INFO] - Training Epoch: 1/2, step 3832/7134 completed (loss: 0.24474550783634186, acc: 0.9553571343421936)
[2024-12-17 01:59:11,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:11,486][root][INFO] - Training Epoch: 1/2, step 3833/7134 completed (loss: 0.27274850010871887, acc: 0.9344262480735779)
[2024-12-17 01:59:11,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:11,770][root][INFO] - Training Epoch: 1/2, step 3834/7134 completed (loss: 0.21249791979789734, acc: 0.9512194991111755)
[2024-12-17 01:59:11,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:12,053][root][INFO] - Training Epoch: 1/2, step 3835/7134 completed (loss: 0.27850449085235596, acc: 0.9375)
[2024-12-17 01:59:12,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:12,352][root][INFO] - Training Epoch: 1/2, step 3836/7134 completed (loss: 0.46941447257995605, acc: 0.8518518805503845)
[2024-12-17 01:59:12,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:12,642][root][INFO] - Training Epoch: 1/2, step 3837/7134 completed (loss: 0.32557612657546997, acc: 0.9490445852279663)
[2024-12-17 01:59:12,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:12,942][root][INFO] - Training Epoch: 1/2, step 3838/7134 completed (loss: 0.2649727761745453, acc: 0.915730357170105)
[2024-12-17 01:59:13,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:13,246][root][INFO] - Training Epoch: 1/2, step 3839/7134 completed (loss: 0.4114423096179962, acc: 0.9068322777748108)
[2024-12-17 01:59:13,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:13,538][root][INFO] - Training Epoch: 1/2, step 3840/7134 completed (loss: 0.42150041460990906, acc: 0.903030276298523)
[2024-12-17 01:59:13,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:13,832][root][INFO] - Training Epoch: 1/2, step 3841/7134 completed (loss: 0.5778906941413879, acc: 0.8643215894699097)
[2024-12-17 01:59:13,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:14,093][root][INFO] - Training Epoch: 1/2, step 3842/7134 completed (loss: 0.2763965129852295, acc: 0.9175257682800293)
[2024-12-17 01:59:14,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:14,419][root][INFO] - Training Epoch: 1/2, step 3843/7134 completed (loss: 0.348452627658844, acc: 0.9189189076423645)
[2024-12-17 01:59:14,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:14,721][root][INFO] - Training Epoch: 1/2, step 3844/7134 completed (loss: 0.5945744514465332, acc: 0.8638743162155151)
[2024-12-17 01:59:14,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:15,003][root][INFO] - Training Epoch: 1/2, step 3845/7134 completed (loss: 0.3755573630332947, acc: 0.9142857193946838)
[2024-12-17 01:59:15,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:15,285][root][INFO] - Training Epoch: 1/2, step 3846/7134 completed (loss: 0.32812437415122986, acc: 0.9270073175430298)
[2024-12-17 01:59:15,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:15,577][root][INFO] - Training Epoch: 1/2, step 3847/7134 completed (loss: 0.3903752863407135, acc: 0.914893627166748)
[2024-12-17 01:59:15,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:15,864][root][INFO] - Training Epoch: 1/2, step 3848/7134 completed (loss: 0.32873350381851196, acc: 0.9147727489471436)
[2024-12-17 01:59:15,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:16,133][root][INFO] - Training Epoch: 1/2, step 3849/7134 completed (loss: 0.4448793828487396, acc: 0.8962963223457336)
[2024-12-17 01:59:16,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:16,401][root][INFO] - Training Epoch: 1/2, step 3850/7134 completed (loss: 0.5505044460296631, acc: 0.8306010961532593)
[2024-12-17 01:59:16,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:16,685][root][INFO] - Training Epoch: 1/2, step 3851/7134 completed (loss: 0.608340322971344, acc: 0.8452380895614624)
[2024-12-17 01:59:16,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:16,967][root][INFO] - Training Epoch: 1/2, step 3852/7134 completed (loss: 0.3988727927207947, acc: 0.9136690497398376)
[2024-12-17 01:59:17,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:17,265][root][INFO] - Training Epoch: 1/2, step 3853/7134 completed (loss: 0.578848659992218, acc: 0.8826815485954285)
[2024-12-17 01:59:17,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:17,548][root][INFO] - Training Epoch: 1/2, step 3854/7134 completed (loss: 0.4812314808368683, acc: 0.8535031676292419)
[2024-12-17 01:59:17,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:17,858][root][INFO] - Training Epoch: 1/2, step 3855/7134 completed (loss: 0.742842435836792, acc: 0.826347291469574)
[2024-12-17 01:59:17,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:18,149][root][INFO] - Training Epoch: 1/2, step 3856/7134 completed (loss: 0.49861976504325867, acc: 0.8917197585105896)
[2024-12-17 01:59:18,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:18,453][root][INFO] - Training Epoch: 1/2, step 3857/7134 completed (loss: 0.47583580017089844, acc: 0.8513513803482056)
[2024-12-17 01:59:18,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:18,739][root][INFO] - Training Epoch: 1/2, step 3858/7134 completed (loss: 0.6828563809394836, acc: 0.862500011920929)
[2024-12-17 01:59:18,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:19,065][root][INFO] - Training Epoch: 1/2, step 3859/7134 completed (loss: 0.6236096620559692, acc: 0.8531073331832886)
[2024-12-17 01:59:19,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:19,344][root][INFO] - Training Epoch: 1/2, step 3860/7134 completed (loss: 0.44174912571907043, acc: 0.8743455410003662)
[2024-12-17 01:59:19,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:19,630][root][INFO] - Training Epoch: 1/2, step 3861/7134 completed (loss: 0.6972134709358215, acc: 0.8300653696060181)
[2024-12-17 01:59:19,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:19,955][root][INFO] - Training Epoch: 1/2, step 3862/7134 completed (loss: 0.5555064678192139, acc: 0.8846153616905212)
[2024-12-17 01:59:20,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:20,248][root][INFO] - Training Epoch: 1/2, step 3863/7134 completed (loss: 0.30509552359580994, acc: 0.9186046719551086)
[2024-12-17 01:59:20,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:20,522][root][INFO] - Training Epoch: 1/2, step 3864/7134 completed (loss: 0.5562533736228943, acc: 0.8636363744735718)
[2024-12-17 01:59:20,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:20,822][root][INFO] - Training Epoch: 1/2, step 3865/7134 completed (loss: 0.7422699928283691, acc: 0.8571428656578064)
[2024-12-17 01:59:20,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:21,097][root][INFO] - Training Epoch: 1/2, step 3866/7134 completed (loss: 0.4311915636062622, acc: 0.8899999856948853)
[2024-12-17 01:59:21,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:21,365][root][INFO] - Training Epoch: 1/2, step 3867/7134 completed (loss: 0.4401971697807312, acc: 0.8999999761581421)
[2024-12-17 01:59:21,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:21,636][root][INFO] - Training Epoch: 1/2, step 3868/7134 completed (loss: 0.3616194725036621, acc: 0.9338235259056091)
[2024-12-17 01:59:21,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:21,923][root][INFO] - Training Epoch: 1/2, step 3869/7134 completed (loss: 0.5257192850112915, acc: 0.881118893623352)
[2024-12-17 01:59:22,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:22,201][root][INFO] - Training Epoch: 1/2, step 3870/7134 completed (loss: 0.6818918585777283, acc: 0.8562091588973999)
[2024-12-17 01:59:22,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:22,500][root][INFO] - Training Epoch: 1/2, step 3871/7134 completed (loss: 0.6831766963005066, acc: 0.8275862336158752)
[2024-12-17 01:59:22,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:22,788][root][INFO] - Training Epoch: 1/2, step 3872/7134 completed (loss: 0.6423695087432861, acc: 0.8333333134651184)
[2024-12-17 01:59:22,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:23,068][root][INFO] - Training Epoch: 1/2, step 3873/7134 completed (loss: 0.4951116442680359, acc: 0.8666666746139526)
[2024-12-17 01:59:23,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:23,344][root][INFO] - Training Epoch: 1/2, step 3874/7134 completed (loss: 0.49450671672821045, acc: 0.8830409646034241)
[2024-12-17 01:59:23,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:23,627][root][INFO] - Training Epoch: 1/2, step 3875/7134 completed (loss: 0.5345478653907776, acc: 0.8734177350997925)
[2024-12-17 01:59:23,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:23,880][root][INFO] - Training Epoch: 1/2, step 3876/7134 completed (loss: 0.32591891288757324, acc: 0.9359999895095825)
[2024-12-17 01:59:23,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:24,147][root][INFO] - Training Epoch: 1/2, step 3877/7134 completed (loss: 0.4052503705024719, acc: 0.9011628031730652)
[2024-12-17 01:59:24,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:24,412][root][INFO] - Training Epoch: 1/2, step 3878/7134 completed (loss: 0.9826934337615967, acc: 0.7732558250427246)
[2024-12-17 01:59:24,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:24,705][root][INFO] - Training Epoch: 1/2, step 3879/7134 completed (loss: 0.4386990964412689, acc: 0.9104477763175964)
[2024-12-17 01:59:24,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:25,028][root][INFO] - Training Epoch: 1/2, step 3880/7134 completed (loss: 0.5682578682899475, acc: 0.8717948794364929)
[2024-12-17 01:59:25,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:25,313][root][INFO] - Training Epoch: 1/2, step 3881/7134 completed (loss: 0.7588468194007874, acc: 0.8128342032432556)
[2024-12-17 01:59:25,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:25,612][root][INFO] - Training Epoch: 1/2, step 3882/7134 completed (loss: 0.6812133193016052, acc: 0.8453608155250549)
[2024-12-17 01:59:25,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:25,896][root][INFO] - Training Epoch: 1/2, step 3883/7134 completed (loss: 0.655640184879303, acc: 0.8627451062202454)
[2024-12-17 01:59:26,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:26,190][root][INFO] - Training Epoch: 1/2, step 3884/7134 completed (loss: 0.5165513157844543, acc: 0.868571400642395)
[2024-12-17 01:59:26,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:26,461][root][INFO] - Training Epoch: 1/2, step 3885/7134 completed (loss: 0.2988492250442505, acc: 0.9363057613372803)
[2024-12-17 01:59:26,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:26,747][root][INFO] - Training Epoch: 1/2, step 3886/7134 completed (loss: 0.4522516131401062, acc: 0.8888888955116272)
[2024-12-17 01:59:26,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:27,023][root][INFO] - Training Epoch: 1/2, step 3887/7134 completed (loss: 0.5261507630348206, acc: 0.8993710875511169)
[2024-12-17 01:59:27,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:27,300][root][INFO] - Training Epoch: 1/2, step 3888/7134 completed (loss: 0.5406163930892944, acc: 0.8604651093482971)
[2024-12-17 01:59:27,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:27,594][root][INFO] - Training Epoch: 1/2, step 3889/7134 completed (loss: 0.2996300160884857, acc: 0.9378530979156494)
[2024-12-17 01:59:27,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:27,882][root][INFO] - Training Epoch: 1/2, step 3890/7134 completed (loss: 0.42858704924583435, acc: 0.907216489315033)
[2024-12-17 01:59:27,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:28,165][root][INFO] - Training Epoch: 1/2, step 3891/7134 completed (loss: 0.44928133487701416, acc: 0.884393036365509)
[2024-12-17 01:59:28,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:28,452][root][INFO] - Training Epoch: 1/2, step 3892/7134 completed (loss: 0.5292654633522034, acc: 0.8799999952316284)
[2024-12-17 01:59:28,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:28,756][root][INFO] - Training Epoch: 1/2, step 3893/7134 completed (loss: 0.49352961778640747, acc: 0.907216489315033)
[2024-12-17 01:59:28,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:29,044][root][INFO] - Training Epoch: 1/2, step 3894/7134 completed (loss: 0.4298607110977173, acc: 0.8797468543052673)
[2024-12-17 01:59:29,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:29,370][root][INFO] - Training Epoch: 1/2, step 3895/7134 completed (loss: 0.48520201444625854, acc: 0.8839778900146484)
[2024-12-17 01:59:29,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:29,681][root][INFO] - Training Epoch: 1/2, step 3896/7134 completed (loss: 0.329934298992157, acc: 0.9099525809288025)
[2024-12-17 01:59:29,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:30,002][root][INFO] - Training Epoch: 1/2, step 3897/7134 completed (loss: 0.4997047185897827, acc: 0.8895348906517029)
[2024-12-17 01:59:30,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:30,321][root][INFO] - Training Epoch: 1/2, step 3898/7134 completed (loss: 0.5385758280754089, acc: 0.8908045887947083)
[2024-12-17 01:59:30,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:30,627][root][INFO] - Training Epoch: 1/2, step 3899/7134 completed (loss: 0.5051910281181335, acc: 0.8728323578834534)
[2024-12-17 01:59:30,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:30,958][root][INFO] - Training Epoch: 1/2, step 3900/7134 completed (loss: 0.5580901503562927, acc: 0.8711340427398682)
[2024-12-17 01:59:31,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:31,237][root][INFO] - Training Epoch: 1/2, step 3901/7134 completed (loss: 0.9689486622810364, acc: 0.7951807379722595)
[2024-12-17 01:59:31,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:31,521][root][INFO] - Training Epoch: 1/2, step 3902/7134 completed (loss: 0.6948752403259277, acc: 0.875)
[2024-12-17 01:59:31,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:31,824][root][INFO] - Training Epoch: 1/2, step 3903/7134 completed (loss: 0.9623337388038635, acc: 0.7357512712478638)
[2024-12-17 01:59:31,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:32,126][root][INFO] - Training Epoch: 1/2, step 3904/7134 completed (loss: 0.7483639121055603, acc: 0.8187134265899658)
[2024-12-17 01:59:32,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:32,419][root][INFO] - Training Epoch: 1/2, step 3905/7134 completed (loss: 0.5555161833763123, acc: 0.8444444537162781)
[2024-12-17 01:59:32,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:32,706][root][INFO] - Training Epoch: 1/2, step 3906/7134 completed (loss: 0.5169684290885925, acc: 0.8595505356788635)
[2024-12-17 01:59:32,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:32,990][root][INFO] - Training Epoch: 1/2, step 3907/7134 completed (loss: 0.5472389459609985, acc: 0.8814433217048645)
[2024-12-17 01:59:33,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:33,285][root][INFO] - Training Epoch: 1/2, step 3908/7134 completed (loss: 0.6977358460426331, acc: 0.849711000919342)
[2024-12-17 01:59:33,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:33,586][root][INFO] - Training Epoch: 1/2, step 3909/7134 completed (loss: 0.5260219573974609, acc: 0.8742138147354126)
[2024-12-17 01:59:33,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:33,856][root][INFO] - Training Epoch: 1/2, step 3910/7134 completed (loss: 0.4990803897380829, acc: 0.8636363744735718)
[2024-12-17 01:59:33,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:34,144][root][INFO] - Training Epoch: 1/2, step 3911/7134 completed (loss: 0.5490847826004028, acc: 0.8616352081298828)
[2024-12-17 01:59:34,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:34,417][root][INFO] - Training Epoch: 1/2, step 3912/7134 completed (loss: 0.2737177312374115, acc: 0.929411768913269)
[2024-12-17 01:59:34,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:34,711][root][INFO] - Training Epoch: 1/2, step 3913/7134 completed (loss: 0.41090697050094604, acc: 0.8888888955116272)
[2024-12-17 01:59:34,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:34,999][root][INFO] - Training Epoch: 1/2, step 3914/7134 completed (loss: 0.49156108498573303, acc: 0.8553459048271179)
[2024-12-17 01:59:35,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:35,282][root][INFO] - Training Epoch: 1/2, step 3915/7134 completed (loss: 0.3081929683685303, acc: 0.9195402264595032)
[2024-12-17 01:59:35,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:35,572][root][INFO] - Training Epoch: 1/2, step 3916/7134 completed (loss: 0.4872128367424011, acc: 0.8928571343421936)
[2024-12-17 01:59:35,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:35,862][root][INFO] - Training Epoch: 1/2, step 3917/7134 completed (loss: 0.2745368182659149, acc: 0.930232584476471)
[2024-12-17 01:59:35,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:36,154][root][INFO] - Training Epoch: 1/2, step 3918/7134 completed (loss: 0.47235971689224243, acc: 0.8857142925262451)
[2024-12-17 01:59:36,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:36,447][root][INFO] - Training Epoch: 1/2, step 3919/7134 completed (loss: 0.5658499598503113, acc: 0.8757396340370178)
[2024-12-17 01:59:36,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:36,771][root][INFO] - Training Epoch: 1/2, step 3920/7134 completed (loss: 0.8946327567100525, acc: 0.796407163143158)
[2024-12-17 01:59:36,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:37,052][root][INFO] - Training Epoch: 1/2, step 3921/7134 completed (loss: 0.7907490134239197, acc: 0.8098591566085815)
[2024-12-17 01:59:37,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:37,325][root][INFO] - Training Epoch: 1/2, step 3922/7134 completed (loss: 0.8815873265266418, acc: 0.7857142686843872)
[2024-12-17 01:59:37,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:37,635][root][INFO] - Training Epoch: 1/2, step 3923/7134 completed (loss: 1.0010854005813599, acc: 0.7559523582458496)
[2024-12-17 01:59:37,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:37,927][root][INFO] - Training Epoch: 1/2, step 3924/7134 completed (loss: 0.6063299179077148, acc: 0.8556700944900513)
[2024-12-17 01:59:38,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:38,206][root][INFO] - Training Epoch: 1/2, step 3925/7134 completed (loss: 0.5283800959587097, acc: 0.9060773253440857)
[2024-12-17 01:59:38,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:38,496][root][INFO] - Training Epoch: 1/2, step 3926/7134 completed (loss: 0.6892821192741394, acc: 0.8417721390724182)
[2024-12-17 01:59:38,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:38,781][root][INFO] - Training Epoch: 1/2, step 3927/7134 completed (loss: 0.5263752937316895, acc: 0.8666666746139526)
[2024-12-17 01:59:38,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:39,077][root][INFO] - Training Epoch: 1/2, step 3928/7134 completed (loss: 0.7834678292274475, acc: 0.832335352897644)
[2024-12-17 01:59:39,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:39,373][root][INFO] - Training Epoch: 1/2, step 3929/7134 completed (loss: 0.5521848797798157, acc: 0.8701298832893372)
[2024-12-17 01:59:39,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:39,655][root][INFO] - Training Epoch: 1/2, step 3930/7134 completed (loss: 0.8300741910934448, acc: 0.8389830589294434)
[2024-12-17 01:59:39,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:39,932][root][INFO] - Training Epoch: 1/2, step 3931/7134 completed (loss: 0.6653603911399841, acc: 0.8607594966888428)
[2024-12-17 01:59:40,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:40,217][root][INFO] - Training Epoch: 1/2, step 3932/7134 completed (loss: 0.5250029563903809, acc: 0.8727272748947144)
[2024-12-17 01:59:40,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:40,490][root][INFO] - Training Epoch: 1/2, step 3933/7134 completed (loss: 0.34617671370506287, acc: 0.8999999761581421)
[2024-12-17 01:59:40,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:40,771][root][INFO] - Training Epoch: 1/2, step 3934/7134 completed (loss: 0.5786754488945007, acc: 0.8981481194496155)
[2024-12-17 01:59:40,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:41,038][root][INFO] - Training Epoch: 1/2, step 3935/7134 completed (loss: 0.33250290155410767, acc: 0.9041095972061157)
[2024-12-17 01:59:41,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:41,351][root][INFO] - Training Epoch: 1/2, step 3936/7134 completed (loss: 0.5520254969596863, acc: 0.8709677457809448)
[2024-12-17 01:59:41,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:41,652][root][INFO] - Training Epoch: 1/2, step 3937/7134 completed (loss: 0.8165866136550903, acc: 0.8644067645072937)
[2024-12-17 01:59:41,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:41,927][root][INFO] - Training Epoch: 1/2, step 3938/7134 completed (loss: 0.6951795816421509, acc: 0.8288288116455078)
[2024-12-17 01:59:42,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:42,190][root][INFO] - Training Epoch: 1/2, step 3939/7134 completed (loss: 0.619604766368866, acc: 0.8518518805503845)
[2024-12-17 01:59:42,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:42,486][root][INFO] - Training Epoch: 1/2, step 3940/7134 completed (loss: 0.574202299118042, acc: 0.8913043737411499)
[2024-12-17 01:59:42,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:42,762][root][INFO] - Training Epoch: 1/2, step 3941/7134 completed (loss: 0.5679035186767578, acc: 0.8658536672592163)
[2024-12-17 01:59:42,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:43,082][root][INFO] - Training Epoch: 1/2, step 3942/7134 completed (loss: 0.5407616496086121, acc: 0.8560000061988831)
[2024-12-17 01:59:43,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:43,370][root][INFO] - Training Epoch: 1/2, step 3943/7134 completed (loss: 0.4188809096813202, acc: 0.9436619877815247)
[2024-12-17 01:59:43,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:43,692][root][INFO] - Training Epoch: 1/2, step 3944/7134 completed (loss: 0.5535236597061157, acc: 0.9104477763175964)
[2024-12-17 01:59:43,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:43,989][root][INFO] - Training Epoch: 1/2, step 3945/7134 completed (loss: 0.3184286057949066, acc: 0.9407894611358643)
[2024-12-17 01:59:44,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:44,251][root][INFO] - Training Epoch: 1/2, step 3946/7134 completed (loss: 0.28161126375198364, acc: 0.9375)
[2024-12-17 01:59:44,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:44,511][root][INFO] - Training Epoch: 1/2, step 3947/7134 completed (loss: 0.33447137475013733, acc: 0.9230769276618958)
[2024-12-17 01:59:44,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:44,794][root][INFO] - Training Epoch: 1/2, step 3948/7134 completed (loss: 0.23961500823497772, acc: 0.9399999976158142)
[2024-12-17 01:59:44,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:45,079][root][INFO] - Training Epoch: 1/2, step 3949/7134 completed (loss: 0.35810086131095886, acc: 0.90625)
[2024-12-17 01:59:45,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:45,344][root][INFO] - Training Epoch: 1/2, step 3950/7134 completed (loss: 0.6046093106269836, acc: 0.8771929740905762)
[2024-12-17 01:59:45,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:45,632][root][INFO] - Training Epoch: 1/2, step 3951/7134 completed (loss: 0.3148221969604492, acc: 0.9278350472450256)
[2024-12-17 01:59:45,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:45,927][root][INFO] - Training Epoch: 1/2, step 3952/7134 completed (loss: 0.5068314075469971, acc: 0.8775510191917419)
[2024-12-17 01:59:46,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:46,203][root][INFO] - Training Epoch: 1/2, step 3953/7134 completed (loss: 0.40743619203567505, acc: 0.9275362491607666)
[2024-12-17 01:59:46,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:46,480][root][INFO] - Training Epoch: 1/2, step 3954/7134 completed (loss: 0.19427743554115295, acc: 0.9484536051750183)
[2024-12-17 01:59:46,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:46,748][root][INFO] - Training Epoch: 1/2, step 3955/7134 completed (loss: 0.3233429789543152, acc: 0.9291338324546814)
[2024-12-17 01:59:46,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:47,034][root][INFO] - Training Epoch: 1/2, step 3956/7134 completed (loss: 0.46968114376068115, acc: 0.8954248428344727)
[2024-12-17 01:59:47,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:47,306][root][INFO] - Training Epoch: 1/2, step 3957/7134 completed (loss: 0.4491589069366455, acc: 0.9059829115867615)
[2024-12-17 01:59:47,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:47,570][root][INFO] - Training Epoch: 1/2, step 3958/7134 completed (loss: 0.5243349075317383, acc: 0.8809523582458496)
[2024-12-17 01:59:47,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:47,849][root][INFO] - Training Epoch: 1/2, step 3959/7134 completed (loss: 0.39169496297836304, acc: 0.8879310488700867)
[2024-12-17 01:59:47,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:48,132][root][INFO] - Training Epoch: 1/2, step 3960/7134 completed (loss: 0.4588363766670227, acc: 0.8882681727409363)
[2024-12-17 01:59:48,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:48,411][root][INFO] - Training Epoch: 1/2, step 3961/7134 completed (loss: 0.3074156939983368, acc: 0.9074074029922485)
[2024-12-17 01:59:48,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:48,705][root][INFO] - Training Epoch: 1/2, step 3962/7134 completed (loss: 0.3699096441268921, acc: 0.899328887462616)
[2024-12-17 01:59:48,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:48,992][root][INFO] - Training Epoch: 1/2, step 3963/7134 completed (loss: 0.6235170960426331, acc: 0.8695651888847351)
[2024-12-17 01:59:49,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:49,266][root][INFO] - Training Epoch: 1/2, step 3964/7134 completed (loss: 0.6235020160675049, acc: 0.8538461327552795)
[2024-12-17 01:59:49,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:49,542][root][INFO] - Training Epoch: 1/2, step 3965/7134 completed (loss: 0.43566423654556274, acc: 0.8909090757369995)
[2024-12-17 01:59:49,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:49,826][root][INFO] - Training Epoch: 1/2, step 3966/7134 completed (loss: 0.4923080801963806, acc: 0.890625)
[2024-12-17 01:59:49,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:50,113][root][INFO] - Training Epoch: 1/2, step 3967/7134 completed (loss: 0.8841583132743835, acc: 0.8478260636329651)
[2024-12-17 01:59:50,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:50,403][root][INFO] - Training Epoch: 1/2, step 3968/7134 completed (loss: 0.27961453795433044, acc: 0.9497206807136536)
[2024-12-17 01:59:50,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:50,681][root][INFO] - Training Epoch: 1/2, step 3969/7134 completed (loss: 0.8735750913619995, acc: 0.8396226167678833)
[2024-12-17 01:59:50,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:50,987][root][INFO] - Training Epoch: 1/2, step 3970/7134 completed (loss: 0.5342814326286316, acc: 0.8901734352111816)
[2024-12-17 01:59:51,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:51,272][root][INFO] - Training Epoch: 1/2, step 3971/7134 completed (loss: 0.9147194027900696, acc: 0.8256410360336304)
[2024-12-17 01:59:51,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:51,569][root][INFO] - Training Epoch: 1/2, step 3972/7134 completed (loss: 1.2042001485824585, acc: 0.7596153616905212)
[2024-12-17 01:59:51,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:51,867][root][INFO] - Training Epoch: 1/2, step 3973/7134 completed (loss: 0.5202078223228455, acc: 0.8943662047386169)
[2024-12-17 01:59:52,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:52,162][root][INFO] - Training Epoch: 1/2, step 3974/7134 completed (loss: 0.6274611949920654, acc: 0.8717948794364929)
[2024-12-17 01:59:52,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:52,458][root][INFO] - Training Epoch: 1/2, step 3975/7134 completed (loss: 0.684929609298706, acc: 0.8342857360839844)
[2024-12-17 01:59:52,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:52,742][root][INFO] - Training Epoch: 1/2, step 3976/7134 completed (loss: 0.9703535437583923, acc: 0.8132529854774475)
[2024-12-17 01:59:52,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:53,037][root][INFO] - Training Epoch: 1/2, step 3977/7134 completed (loss: 0.40564531087875366, acc: 0.9202898740768433)
[2024-12-17 01:59:53,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:53,332][root][INFO] - Training Epoch: 1/2, step 3978/7134 completed (loss: 0.412600576877594, acc: 0.9004974961280823)
[2024-12-17 01:59:53,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:53,618][root][INFO] - Training Epoch: 1/2, step 3979/7134 completed (loss: 0.6507343053817749, acc: 0.8467153310775757)
[2024-12-17 01:59:53,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:53,902][root][INFO] - Training Epoch: 1/2, step 3980/7134 completed (loss: 0.4647485613822937, acc: 0.8709677457809448)
[2024-12-17 01:59:54,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:54,202][root][INFO] - Training Epoch: 1/2, step 3981/7134 completed (loss: 0.5739145874977112, acc: 0.8614457845687866)
[2024-12-17 01:59:54,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:54,491][root][INFO] - Training Epoch: 1/2, step 3982/7134 completed (loss: 0.8264407515525818, acc: 0.8313953280448914)
[2024-12-17 01:59:54,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:54,776][root][INFO] - Training Epoch: 1/2, step 3983/7134 completed (loss: 1.90493905544281, acc: 0.6589147448539734)
[2024-12-17 01:59:54,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:55,089][root][INFO] - Training Epoch: 1/2, step 3984/7134 completed (loss: 0.9303917288780212, acc: 0.8031914830207825)
[2024-12-17 01:59:55,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:55,372][root][INFO] - Training Epoch: 1/2, step 3985/7134 completed (loss: 0.4357600510120392, acc: 0.9230769276618958)
[2024-12-17 01:59:55,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:55,662][root][INFO] - Training Epoch: 1/2, step 3986/7134 completed (loss: 1.0601775646209717, acc: 0.7784090638160706)
[2024-12-17 01:59:55,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:55,932][root][INFO] - Training Epoch: 1/2, step 3987/7134 completed (loss: 0.6608495116233826, acc: 0.8492063283920288)
[2024-12-17 01:59:56,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:56,211][root][INFO] - Training Epoch: 1/2, step 3988/7134 completed (loss: 0.6951262354850769, acc: 0.8708133697509766)
[2024-12-17 01:59:56,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:56,483][root][INFO] - Training Epoch: 1/2, step 3989/7134 completed (loss: 0.7815577983856201, acc: 0.8099173307418823)
[2024-12-17 01:59:56,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:56,765][root][INFO] - Training Epoch: 1/2, step 3990/7134 completed (loss: 1.004455327987671, acc: 0.8278145790100098)
[2024-12-17 01:59:56,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:57,052][root][INFO] - Training Epoch: 1/2, step 3991/7134 completed (loss: 0.5469610095024109, acc: 0.8666666746139526)
[2024-12-17 01:59:57,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:57,319][root][INFO] - Training Epoch: 1/2, step 3992/7134 completed (loss: 0.6534249782562256, acc: 0.8241758346557617)
[2024-12-17 01:59:57,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:57,605][root][INFO] - Training Epoch: 1/2, step 3993/7134 completed (loss: 0.6611757874488831, acc: 0.8425925970077515)
[2024-12-17 01:59:57,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:57,881][root][INFO] - Training Epoch: 1/2, step 3994/7134 completed (loss: 0.5288974046707153, acc: 0.8823529481887817)
[2024-12-17 01:59:57,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:58,150][root][INFO] - Training Epoch: 1/2, step 3995/7134 completed (loss: 0.7969531416893005, acc: 0.7984496355056763)
[2024-12-17 01:59:58,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:58,437][root][INFO] - Training Epoch: 1/2, step 3996/7134 completed (loss: 0.5998973846435547, acc: 0.8760330677032471)
[2024-12-17 01:59:58,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:58,721][root][INFO] - Training Epoch: 1/2, step 3997/7134 completed (loss: 0.6391558647155762, acc: 0.8448275923728943)
[2024-12-17 01:59:58,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:59,006][root][INFO] - Training Epoch: 1/2, step 3998/7134 completed (loss: 0.8115819692611694, acc: 0.8461538553237915)
[2024-12-17 01:59:59,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:59,303][root][INFO] - Training Epoch: 1/2, step 3999/7134 completed (loss: 0.785263180732727, acc: 0.8467742204666138)
[2024-12-17 01:59:59,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:59,578][root][INFO] - Training Epoch: 1/2, step 4000/7134 completed (loss: 0.5413112044334412, acc: 0.8780487775802612)
[2024-12-17 01:59:59,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:59,845][root][INFO] - Training Epoch: 1/2, step 4001/7134 completed (loss: 0.7334892153739929, acc: 0.8145161271095276)
[2024-12-17 01:59:59,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:00,116][root][INFO] - Training Epoch: 1/2, step 4002/7134 completed (loss: 0.9352973699569702, acc: 0.7943925261497498)
[2024-12-17 02:00:00,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:00,400][root][INFO] - Training Epoch: 1/2, step 4003/7134 completed (loss: 0.7242140173912048, acc: 0.8421052694320679)
[2024-12-17 02:00:00,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:00,694][root][INFO] - Training Epoch: 1/2, step 4004/7134 completed (loss: 0.8900978565216064, acc: 0.7699999809265137)
[2024-12-17 02:00:00,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:00,966][root][INFO] - Training Epoch: 1/2, step 4005/7134 completed (loss: 0.36038926243782043, acc: 0.9084967374801636)
[2024-12-17 02:00:01,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:01,273][root][INFO] - Training Epoch: 1/2, step 4006/7134 completed (loss: 0.3634517192840576, acc: 0.9009009003639221)
[2024-12-17 02:00:01,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:01,534][root][INFO] - Training Epoch: 1/2, step 4007/7134 completed (loss: 0.3570735454559326, acc: 0.9166666865348816)
[2024-12-17 02:00:01,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:01,815][root][INFO] - Training Epoch: 1/2, step 4008/7134 completed (loss: 0.3147887885570526, acc: 0.9147982001304626)
[2024-12-17 02:00:01,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:02,088][root][INFO] - Training Epoch: 1/2, step 4009/7134 completed (loss: 0.2038899064064026, acc: 0.9608938694000244)
[2024-12-17 02:00:02,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:02,375][root][INFO] - Training Epoch: 1/2, step 4010/7134 completed (loss: 0.25007152557373047, acc: 0.9377990365028381)
[2024-12-17 02:00:02,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:02,658][root][INFO] - Training Epoch: 1/2, step 4011/7134 completed (loss: 0.27870994806289673, acc: 0.9371428489685059)
[2024-12-17 02:00:02,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:02,933][root][INFO] - Training Epoch: 1/2, step 4012/7134 completed (loss: 0.27779027819633484, acc: 0.9337349534034729)
[2024-12-17 02:00:03,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:03,231][root][INFO] - Training Epoch: 1/2, step 4013/7134 completed (loss: 0.21082541346549988, acc: 0.9580419659614563)
[2024-12-17 02:00:03,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:03,520][root][INFO] - Training Epoch: 1/2, step 4014/7134 completed (loss: 0.21018758416175842, acc: 0.95333331823349)
[2024-12-17 02:00:03,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:03,813][root][INFO] - Training Epoch: 1/2, step 4015/7134 completed (loss: 0.15406334400177002, acc: 0.951724112033844)
[2024-12-17 02:00:03,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:04,119][root][INFO] - Training Epoch: 1/2, step 4016/7134 completed (loss: 0.5221726298332214, acc: 0.9015544056892395)
[2024-12-17 02:00:04,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:04,412][root][INFO] - Training Epoch: 1/2, step 4017/7134 completed (loss: 0.6322106122970581, acc: 0.8711340427398682)
[2024-12-17 02:00:04,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:04,707][root][INFO] - Training Epoch: 1/2, step 4018/7134 completed (loss: 0.4853057265281677, acc: 0.8937197923660278)
[2024-12-17 02:00:04,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:04,982][root][INFO] - Training Epoch: 1/2, step 4019/7134 completed (loss: 0.41473400592803955, acc: 0.8833333253860474)
[2024-12-17 02:00:05,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:05,262][root][INFO] - Training Epoch: 1/2, step 4020/7134 completed (loss: 0.5504216551780701, acc: 0.8579545617103577)
[2024-12-17 02:00:05,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:05,567][root][INFO] - Training Epoch: 1/2, step 4021/7134 completed (loss: 0.3566332757472992, acc: 0.8823529481887817)
[2024-12-17 02:00:05,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:05,872][root][INFO] - Training Epoch: 1/2, step 4022/7134 completed (loss: 0.3899426758289337, acc: 0.9086538553237915)
[2024-12-17 02:00:06,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:06,167][root][INFO] - Training Epoch: 1/2, step 4023/7134 completed (loss: 0.6475164890289307, acc: 0.8342857360839844)
[2024-12-17 02:00:06,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:06,449][root][INFO] - Training Epoch: 1/2, step 4024/7134 completed (loss: 0.6838558912277222, acc: 0.8563218116760254)
[2024-12-17 02:00:06,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:06,728][root][INFO] - Training Epoch: 1/2, step 4025/7134 completed (loss: 0.5534818768501282, acc: 0.8795811533927917)
[2024-12-17 02:00:06,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:07,037][root][INFO] - Training Epoch: 1/2, step 4026/7134 completed (loss: 0.5455694794654846, acc: 0.850931704044342)
[2024-12-17 02:00:07,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:07,321][root][INFO] - Training Epoch: 1/2, step 4027/7134 completed (loss: 0.40279537439346313, acc: 0.8932584524154663)
[2024-12-17 02:00:07,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:07,584][root][INFO] - Training Epoch: 1/2, step 4028/7134 completed (loss: 0.6478645205497742, acc: 0.7952755689620972)
[2024-12-17 02:00:07,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:07,864][root][INFO] - Training Epoch: 1/2, step 4029/7134 completed (loss: 0.42690661549568176, acc: 0.8810811042785645)
[2024-12-17 02:00:07,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:08,133][root][INFO] - Training Epoch: 1/2, step 4030/7134 completed (loss: 0.2894025444984436, acc: 0.9230769276618958)
[2024-12-17 02:00:08,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:08,405][root][INFO] - Training Epoch: 1/2, step 4031/7134 completed (loss: 0.265902578830719, acc: 0.9440993666648865)
[2024-12-17 02:00:08,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:08,682][root][INFO] - Training Epoch: 1/2, step 4032/7134 completed (loss: 0.42575928568840027, acc: 0.9011628031730652)
[2024-12-17 02:00:08,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:08,998][root][INFO] - Training Epoch: 1/2, step 4033/7134 completed (loss: 0.27493590116500854, acc: 0.9358288645744324)
[2024-12-17 02:00:09,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:09,283][root][INFO] - Training Epoch: 1/2, step 4034/7134 completed (loss: 0.2274402678012848, acc: 0.9489796161651611)
[2024-12-17 02:00:09,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:09,604][root][INFO] - Training Epoch: 1/2, step 4035/7134 completed (loss: 0.6819043159484863, acc: 0.8439024686813354)
[2024-12-17 02:00:09,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:09,906][root][INFO] - Training Epoch: 1/2, step 4036/7134 completed (loss: 0.43264317512512207, acc: 0.9153845906257629)
[2024-12-17 02:00:10,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:10,222][root][INFO] - Training Epoch: 1/2, step 4037/7134 completed (loss: 0.3639143407344818, acc: 0.9114583134651184)
[2024-12-17 02:00:10,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:10,530][root][INFO] - Training Epoch: 1/2, step 4038/7134 completed (loss: 0.47533005475997925, acc: 0.8977272510528564)
[2024-12-17 02:00:10,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:10,840][root][INFO] - Training Epoch: 1/2, step 4039/7134 completed (loss: 0.6130105257034302, acc: 0.8461538553237915)
[2024-12-17 02:00:10,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:11,165][root][INFO] - Training Epoch: 1/2, step 4040/7134 completed (loss: 0.4004592001438141, acc: 0.9016393423080444)
[2024-12-17 02:00:11,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:11,450][root][INFO] - Training Epoch: 1/2, step 4041/7134 completed (loss: 0.31084269285202026, acc: 0.9421965479850769)
[2024-12-17 02:00:11,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:11,721][root][INFO] - Training Epoch: 1/2, step 4042/7134 completed (loss: 0.4884452223777771, acc: 0.9189189076423645)
[2024-12-17 02:00:11,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:11,981][root][INFO] - Training Epoch: 1/2, step 4043/7134 completed (loss: 0.4660346508026123, acc: 0.905063271522522)
[2024-12-17 02:00:12,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:12,273][root][INFO] - Training Epoch: 1/2, step 4044/7134 completed (loss: 0.23566342890262604, acc: 0.9505494236946106)
[2024-12-17 02:00:12,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:12,558][root][INFO] - Training Epoch: 1/2, step 4045/7134 completed (loss: 0.38063615560531616, acc: 0.8914285898208618)
[2024-12-17 02:00:12,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:12,848][root][INFO] - Training Epoch: 1/2, step 4046/7134 completed (loss: 0.42014285922050476, acc: 0.8888888955116272)
[2024-12-17 02:00:12,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:13,140][root][INFO] - Training Epoch: 1/2, step 4047/7134 completed (loss: 0.49661797285079956, acc: 0.874316930770874)
[2024-12-17 02:00:13,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:13,428][root][INFO] - Training Epoch: 1/2, step 4048/7134 completed (loss: 0.25865715742111206, acc: 0.9238578677177429)
[2024-12-17 02:00:13,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:13,755][root][INFO] - Training Epoch: 1/2, step 4049/7134 completed (loss: 0.5027683973312378, acc: 0.8905472755432129)
[2024-12-17 02:00:13,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:14,029][root][INFO] - Training Epoch: 1/2, step 4050/7134 completed (loss: 0.4398442804813385, acc: 0.8812500238418579)
[2024-12-17 02:00:14,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:14,319][root][INFO] - Training Epoch: 1/2, step 4051/7134 completed (loss: 0.5123763084411621, acc: 0.8826815485954285)
[2024-12-17 02:00:14,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:14,592][root][INFO] - Training Epoch: 1/2, step 4052/7134 completed (loss: 0.48082947731018066, acc: 0.8926553726196289)
[2024-12-17 02:00:14,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:14,890][root][INFO] - Training Epoch: 1/2, step 4053/7134 completed (loss: 0.6418864130973816, acc: 0.851190447807312)
[2024-12-17 02:00:15,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:15,186][root][INFO] - Training Epoch: 1/2, step 4054/7134 completed (loss: 0.48626238107681274, acc: 0.8782608509063721)
[2024-12-17 02:00:15,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:15,473][root][INFO] - Training Epoch: 1/2, step 4055/7134 completed (loss: 0.4348410665988922, acc: 0.9202127456665039)
[2024-12-17 02:00:15,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:15,765][root][INFO] - Training Epoch: 1/2, step 4056/7134 completed (loss: 0.3692748546600342, acc: 0.9157894849777222)
[2024-12-17 02:00:15,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:16,061][root][INFO] - Training Epoch: 1/2, step 4057/7134 completed (loss: 0.3486825227737427, acc: 0.9176470637321472)
[2024-12-17 02:00:16,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:16,378][root][INFO] - Training Epoch: 1/2, step 4058/7134 completed (loss: 0.4662824273109436, acc: 0.8787878751754761)
[2024-12-17 02:00:16,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:16,700][root][INFO] - Training Epoch: 1/2, step 4059/7134 completed (loss: 0.25770676136016846, acc: 0.9477611780166626)
[2024-12-17 02:00:16,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:16,996][root][INFO] - Training Epoch: 1/2, step 4060/7134 completed (loss: 0.29003819823265076, acc: 0.9459459185600281)
[2024-12-17 02:00:17,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:17,286][root][INFO] - Training Epoch: 1/2, step 4061/7134 completed (loss: 0.13544055819511414, acc: 0.9593023061752319)
[2024-12-17 02:00:17,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:17,553][root][INFO] - Training Epoch: 1/2, step 4062/7134 completed (loss: 0.16834504902362823, acc: 0.9473684430122375)
[2024-12-17 02:00:17,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:17,840][root][INFO] - Training Epoch: 1/2, step 4063/7134 completed (loss: 0.2715151607990265, acc: 0.9473684430122375)
[2024-12-17 02:00:17,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:18,134][root][INFO] - Training Epoch: 1/2, step 4064/7134 completed (loss: 0.14702671766281128, acc: 0.9738562107086182)
[2024-12-17 02:00:18,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:18,432][root][INFO] - Training Epoch: 1/2, step 4065/7134 completed (loss: 0.3137129545211792, acc: 0.9032257795333862)
[2024-12-17 02:00:18,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:18,747][root][INFO] - Training Epoch: 1/2, step 4066/7134 completed (loss: 0.18658997118473053, acc: 0.9477124214172363)
[2024-12-17 02:00:18,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:19,030][root][INFO] - Training Epoch: 1/2, step 4067/7134 completed (loss: 0.3945431709289551, acc: 0.8835616707801819)
[2024-12-17 02:00:19,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:19,312][root][INFO] - Training Epoch: 1/2, step 4068/7134 completed (loss: 0.6089067459106445, acc: 0.8677685856819153)
[2024-12-17 02:00:19,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:19,603][root][INFO] - Training Epoch: 1/2, step 4069/7134 completed (loss: 0.31251347064971924, acc: 0.9154929518699646)
[2024-12-17 02:00:19,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:19,889][root][INFO] - Training Epoch: 1/2, step 4070/7134 completed (loss: 0.43421927094459534, acc: 0.887417197227478)
[2024-12-17 02:00:20,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:20,163][root][INFO] - Training Epoch: 1/2, step 4071/7134 completed (loss: 0.2742767632007599, acc: 0.9452054500579834)
[2024-12-17 02:00:20,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:20,445][root][INFO] - Training Epoch: 1/2, step 4072/7134 completed (loss: 0.23448163270950317, acc: 0.957317054271698)
[2024-12-17 02:00:20,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:20,733][root][INFO] - Training Epoch: 1/2, step 4073/7134 completed (loss: 0.2218504250049591, acc: 0.9277108311653137)
[2024-12-17 02:00:20,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:21,021][root][INFO] - Training Epoch: 1/2, step 4074/7134 completed (loss: 0.2286827713251114, acc: 0.9536423683166504)
[2024-12-17 02:00:21,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:21,309][root][INFO] - Training Epoch: 1/2, step 4075/7134 completed (loss: 0.18975277245044708, acc: 0.95333331823349)
[2024-12-17 02:00:21,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:21,597][root][INFO] - Training Epoch: 1/2, step 4076/7134 completed (loss: 0.2073213756084442, acc: 0.9634146094322205)
[2024-12-17 02:00:21,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:21,905][root][INFO] - Training Epoch: 1/2, step 4077/7134 completed (loss: 0.38710907101631165, acc: 0.9047619104385376)
[2024-12-17 02:00:22,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:22,196][root][INFO] - Training Epoch: 1/2, step 4078/7134 completed (loss: 0.39941611886024475, acc: 0.9182389974594116)
[2024-12-17 02:00:22,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:22,457][root][INFO] - Training Epoch: 1/2, step 4079/7134 completed (loss: 0.3000900149345398, acc: 0.9236640930175781)
[2024-12-17 02:00:22,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:22,745][root][INFO] - Training Epoch: 1/2, step 4080/7134 completed (loss: 0.1732373982667923, acc: 0.9586206674575806)
[2024-12-17 02:00:22,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:23,017][root][INFO] - Training Epoch: 1/2, step 4081/7134 completed (loss: 0.18953357636928558, acc: 0.9513888955116272)
[2024-12-17 02:00:23,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:23,336][root][INFO] - Training Epoch: 1/2, step 4082/7134 completed (loss: 0.5918184518814087, acc: 0.8815789222717285)
[2024-12-17 02:00:23,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:23,642][root][INFO] - Training Epoch: 1/2, step 4083/7134 completed (loss: 0.7508566975593567, acc: 0.8362573385238647)
[2024-12-17 02:00:23,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:23,918][root][INFO] - Training Epoch: 1/2, step 4084/7134 completed (loss: 0.8402132391929626, acc: 0.8120805621147156)
[2024-12-17 02:00:24,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:24,205][root][INFO] - Training Epoch: 1/2, step 4085/7134 completed (loss: 0.4631165862083435, acc: 0.8842105269432068)
[2024-12-17 02:00:24,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:24,538][root][INFO] - Training Epoch: 1/2, step 4086/7134 completed (loss: 0.6770868897438049, acc: 0.8205128312110901)
[2024-12-17 02:00:24,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:24,824][root][INFO] - Training Epoch: 1/2, step 4087/7134 completed (loss: 0.23538392782211304, acc: 0.9408602118492126)
[2024-12-17 02:00:24,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:25,119][root][INFO] - Training Epoch: 1/2, step 4088/7134 completed (loss: 0.5119662880897522, acc: 0.8781725764274597)
[2024-12-17 02:00:25,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:25,406][root][INFO] - Training Epoch: 1/2, step 4089/7134 completed (loss: 0.6391000151634216, acc: 0.8636363744735718)
[2024-12-17 02:00:25,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:25,724][root][INFO] - Training Epoch: 1/2, step 4090/7134 completed (loss: 0.8856093287467957, acc: 0.8277512192726135)
[2024-12-17 02:00:25,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:26,026][root][INFO] - Training Epoch: 1/2, step 4091/7134 completed (loss: 1.065386414527893, acc: 0.7921348214149475)
[2024-12-17 02:00:26,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:26,324][root][INFO] - Training Epoch: 1/2, step 4092/7134 completed (loss: 0.4906902313232422, acc: 0.8586387634277344)
[2024-12-17 02:00:26,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:26,595][root][INFO] - Training Epoch: 1/2, step 4093/7134 completed (loss: 0.38173794746398926, acc: 0.9120000004768372)
[2024-12-17 02:00:26,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:26,877][root][INFO] - Training Epoch: 1/2, step 4094/7134 completed (loss: 0.4897390305995941, acc: 0.9024389982223511)
[2024-12-17 02:00:27,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:27,172][root][INFO] - Training Epoch: 1/2, step 4095/7134 completed (loss: 0.36322200298309326, acc: 0.9235668778419495)
[2024-12-17 02:00:27,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:27,440][root][INFO] - Training Epoch: 1/2, step 4096/7134 completed (loss: 0.8249731063842773, acc: 0.7662337422370911)
[2024-12-17 02:00:27,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:27,744][root][INFO] - Training Epoch: 1/2, step 4097/7134 completed (loss: 0.43765029311180115, acc: 0.9066666960716248)
[2024-12-17 02:00:27,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:28,032][root][INFO] - Training Epoch: 1/2, step 4098/7134 completed (loss: 0.3493898808956146, acc: 0.9195402264595032)
[2024-12-17 02:00:28,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:28,304][root][INFO] - Training Epoch: 1/2, step 4099/7134 completed (loss: 0.5417596101760864, acc: 0.8712121248245239)
[2024-12-17 02:00:28,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:28,604][root][INFO] - Training Epoch: 1/2, step 4100/7134 completed (loss: 0.18420661985874176, acc: 0.9607843160629272)
[2024-12-17 02:00:28,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:28,903][root][INFO] - Training Epoch: 1/2, step 4101/7134 completed (loss: 0.4237169027328491, acc: 0.8960000276565552)
[2024-12-17 02:00:29,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:29,191][root][INFO] - Training Epoch: 1/2, step 4102/7134 completed (loss: 0.6419875621795654, acc: 0.869918704032898)
[2024-12-17 02:00:29,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:29,477][root][INFO] - Training Epoch: 1/2, step 4103/7134 completed (loss: 0.22938796877861023, acc: 0.9542483687400818)
[2024-12-17 02:00:29,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:29,769][root][INFO] - Training Epoch: 1/2, step 4104/7134 completed (loss: 0.33909475803375244, acc: 0.9057971239089966)
[2024-12-17 02:00:29,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:30,049][root][INFO] - Training Epoch: 1/2, step 4105/7134 completed (loss: 0.2830856740474701, acc: 0.9399999976158142)
[2024-12-17 02:00:30,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:30,325][root][INFO] - Training Epoch: 1/2, step 4106/7134 completed (loss: 0.3522614538669586, acc: 0.918367326259613)
[2024-12-17 02:00:30,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:30,631][root][INFO] - Training Epoch: 1/2, step 4107/7134 completed (loss: 0.3773361146450043, acc: 0.9264705777168274)
[2024-12-17 02:00:30,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:30,916][root][INFO] - Training Epoch: 1/2, step 4108/7134 completed (loss: 0.2829665541648865, acc: 0.9387755393981934)
[2024-12-17 02:00:31,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:31,206][root][INFO] - Training Epoch: 1/2, step 4109/7134 completed (loss: 0.29372063279151917, acc: 0.918367326259613)
[2024-12-17 02:00:31,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:31,486][root][INFO] - Training Epoch: 1/2, step 4110/7134 completed (loss: 0.29619061946868896, acc: 0.930232584476471)
[2024-12-17 02:00:31,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:31,780][root][INFO] - Training Epoch: 1/2, step 4111/7134 completed (loss: 0.3788236677646637, acc: 0.9172413945198059)
[2024-12-17 02:00:31,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:32,070][root][INFO] - Training Epoch: 1/2, step 4112/7134 completed (loss: 0.31258320808410645, acc: 0.930232584476471)
[2024-12-17 02:00:32,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:32,352][root][INFO] - Training Epoch: 1/2, step 4113/7134 completed (loss: 0.37711331248283386, acc: 0.8951048851013184)
[2024-12-17 02:00:32,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:32,636][root][INFO] - Training Epoch: 1/2, step 4114/7134 completed (loss: 0.8305459022521973, acc: 0.747826099395752)
[2024-12-17 02:00:32,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:32,924][root][INFO] - Training Epoch: 1/2, step 4115/7134 completed (loss: 0.7573981881141663, acc: 0.8135592937469482)
[2024-12-17 02:00:33,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:33,228][root][INFO] - Training Epoch: 1/2, step 4116/7134 completed (loss: 0.39521992206573486, acc: 0.9160305261611938)
[2024-12-17 02:00:33,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:33,522][root][INFO] - Training Epoch: 1/2, step 4117/7134 completed (loss: 0.27952566742897034, acc: 0.9444444179534912)
[2024-12-17 02:00:33,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:33,811][root][INFO] - Training Epoch: 1/2, step 4118/7134 completed (loss: 0.2536199390888214, acc: 0.9270833134651184)
[2024-12-17 02:00:33,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:34,084][root][INFO] - Training Epoch: 1/2, step 4119/7134 completed (loss: 0.35416001081466675, acc: 0.912162184715271)
[2024-12-17 02:00:34,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:34,369][root][INFO] - Training Epoch: 1/2, step 4120/7134 completed (loss: 0.32849347591400146, acc: 0.9398496150970459)
[2024-12-17 02:00:34,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:34,646][root][INFO] - Training Epoch: 1/2, step 4121/7134 completed (loss: 0.3327711224555969, acc: 0.9207317233085632)
[2024-12-17 02:00:34,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:34,926][root][INFO] - Training Epoch: 1/2, step 4122/7134 completed (loss: 0.1677093505859375, acc: 0.9747899174690247)
[2024-12-17 02:00:35,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:35,238][root][INFO] - Training Epoch: 1/2, step 4123/7134 completed (loss: 0.17105595767498016, acc: 0.9545454382896423)
[2024-12-17 02:00:35,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:35,536][root][INFO] - Training Epoch: 1/2, step 4124/7134 completed (loss: 0.21326549351215363, acc: 0.9437500238418579)
[2024-12-17 02:00:35,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:35,823][root][INFO] - Training Epoch: 1/2, step 4125/7134 completed (loss: 0.22460170090198517, acc: 0.9622641801834106)
[2024-12-17 02:00:35,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:36,108][root][INFO] - Training Epoch: 1/2, step 4126/7134 completed (loss: 0.2543582618236542, acc: 0.9407894611358643)
[2024-12-17 02:00:36,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:36,382][root][INFO] - Training Epoch: 1/2, step 4127/7134 completed (loss: 0.30194762349128723, acc: 0.9194630980491638)
[2024-12-17 02:00:36,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:36,670][root][INFO] - Training Epoch: 1/2, step 4128/7134 completed (loss: 0.3163433372974396, acc: 0.9248120188713074)
[2024-12-17 02:00:36,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:36,983][root][INFO] - Training Epoch: 1/2, step 4129/7134 completed (loss: 0.24269892275333405, acc: 0.926174521446228)
[2024-12-17 02:00:37,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:37,265][root][INFO] - Training Epoch: 1/2, step 4130/7134 completed (loss: 0.37477487325668335, acc: 0.9051724076271057)
[2024-12-17 02:00:37,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:37,555][root][INFO] - Training Epoch: 1/2, step 4131/7134 completed (loss: 0.19790393114089966, acc: 0.9555555582046509)
[2024-12-17 02:00:37,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:37,854][root][INFO] - Training Epoch: 1/2, step 4132/7134 completed (loss: 0.11225324869155884, acc: 0.9629629850387573)
[2024-12-17 02:00:37,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:38,157][root][INFO] - Training Epoch: 1/2, step 4133/7134 completed (loss: 0.4446459710597992, acc: 0.8881118893623352)
[2024-12-17 02:00:38,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:38,440][root][INFO] - Training Epoch: 1/2, step 4134/7134 completed (loss: 0.7244842648506165, acc: 0.8181818127632141)
[2024-12-17 02:00:38,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:38,719][root][INFO] - Training Epoch: 1/2, step 4135/7134 completed (loss: 0.1402931809425354, acc: 0.9785714149475098)
[2024-12-17 02:00:38,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:39,015][root][INFO] - Training Epoch: 1/2, step 4136/7134 completed (loss: 0.2832840383052826, acc: 0.9097744226455688)
[2024-12-17 02:00:39,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:39,322][root][INFO] - Training Epoch: 1/2, step 4137/7134 completed (loss: 0.24558331072330475, acc: 0.9338235259056091)
[2024-12-17 02:00:39,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:39,631][root][INFO] - Training Epoch: 1/2, step 4138/7134 completed (loss: 0.4340946078300476, acc: 0.8954248428344727)
[2024-12-17 02:00:39,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:39,926][root][INFO] - Training Epoch: 1/2, step 4139/7134 completed (loss: 0.5645264983177185, acc: 0.8571428656578064)
[2024-12-17 02:00:40,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:40,249][root][INFO] - Training Epoch: 1/2, step 4140/7134 completed (loss: 0.555518388748169, acc: 0.8531073331832886)
[2024-12-17 02:00:40,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:40,551][root][INFO] - Training Epoch: 1/2, step 4141/7134 completed (loss: 0.7174740433692932, acc: 0.8205128312110901)
[2024-12-17 02:00:40,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:40,850][root][INFO] - Training Epoch: 1/2, step 4142/7134 completed (loss: 0.5520850419998169, acc: 0.8450000286102295)
[2024-12-17 02:00:40,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:41,134][root][INFO] - Training Epoch: 1/2, step 4143/7134 completed (loss: 0.4524720311164856, acc: 0.8908296823501587)
[2024-12-17 02:00:41,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:41,423][root][INFO] - Training Epoch: 1/2, step 4144/7134 completed (loss: 0.6330078840255737, acc: 0.8358974456787109)
[2024-12-17 02:00:41,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:41,699][root][INFO] - Training Epoch: 1/2, step 4145/7134 completed (loss: 0.6577773094177246, acc: 0.8474576473236084)
[2024-12-17 02:00:41,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:41,975][root][INFO] - Training Epoch: 1/2, step 4146/7134 completed (loss: 1.1332775354385376, acc: 0.7053571343421936)
[2024-12-17 02:00:42,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:42,260][root][INFO] - Training Epoch: 1/2, step 4147/7134 completed (loss: 1.3370075225830078, acc: 0.7203390002250671)
[2024-12-17 02:00:42,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:42,552][root][INFO] - Training Epoch: 1/2, step 4148/7134 completed (loss: 1.2852962017059326, acc: 0.7114093899726868)
[2024-12-17 02:00:42,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:42,865][root][INFO] - Training Epoch: 1/2, step 4149/7134 completed (loss: 1.1439745426177979, acc: 0.8139534592628479)
[2024-12-17 02:00:42,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:43,159][root][INFO] - Training Epoch: 1/2, step 4150/7134 completed (loss: 1.2355260848999023, acc: 0.7264957427978516)
[2024-12-17 02:00:43,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:43,456][root][INFO] - Training Epoch: 1/2, step 4151/7134 completed (loss: 0.8257310390472412, acc: 0.8099173307418823)
[2024-12-17 02:00:43,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:43,748][root][INFO] - Training Epoch: 1/2, step 4152/7134 completed (loss: 0.7399842143058777, acc: 0.8503401279449463)
[2024-12-17 02:00:43,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:44,062][root][INFO] - Training Epoch: 1/2, step 4153/7134 completed (loss: 0.6475839614868164, acc: 0.8428571224212646)
[2024-12-17 02:00:44,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:44,401][root][INFO] - Training Epoch: 1/2, step 4154/7134 completed (loss: 0.6632240414619446, acc: 0.8277512192726135)
[2024-12-17 02:00:44,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:44,733][root][INFO] - Training Epoch: 1/2, step 4155/7134 completed (loss: 0.7198284864425659, acc: 0.8456375598907471)
[2024-12-17 02:00:44,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:45,015][root][INFO] - Training Epoch: 1/2, step 4156/7134 completed (loss: 0.6485745310783386, acc: 0.859649121761322)
[2024-12-17 02:00:45,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:45,288][root][INFO] - Training Epoch: 1/2, step 4157/7134 completed (loss: 0.8089526295661926, acc: 0.7983193397521973)
[2024-12-17 02:00:45,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:45,597][root][INFO] - Training Epoch: 1/2, step 4158/7134 completed (loss: 0.7459442615509033, acc: 0.8461538553237915)
[2024-12-17 02:00:45,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:45,893][root][INFO] - Training Epoch: 1/2, step 4159/7134 completed (loss: 0.6756494045257568, acc: 0.8496240377426147)
[2024-12-17 02:00:46,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:46,180][root][INFO] - Training Epoch: 1/2, step 4160/7134 completed (loss: 0.6403710246086121, acc: 0.8571428656578064)
[2024-12-17 02:00:46,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:46,458][root][INFO] - Training Epoch: 1/2, step 4161/7134 completed (loss: 0.4585089087486267, acc: 0.8965517282485962)
[2024-12-17 02:00:46,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:46,733][root][INFO] - Training Epoch: 1/2, step 4162/7134 completed (loss: 0.5398927330970764, acc: 0.8742514848709106)
[2024-12-17 02:00:46,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:47,012][root][INFO] - Training Epoch: 1/2, step 4163/7134 completed (loss: 0.7405445575714111, acc: 0.8523489832878113)
[2024-12-17 02:00:47,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:47,293][root][INFO] - Training Epoch: 1/2, step 4164/7134 completed (loss: 0.6122825145721436, acc: 0.8695651888847351)
[2024-12-17 02:00:47,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:47,584][root][INFO] - Training Epoch: 1/2, step 4165/7134 completed (loss: 0.6431568264961243, acc: 0.8064516186714172)
[2024-12-17 02:00:47,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:47,864][root][INFO] - Training Epoch: 1/2, step 4166/7134 completed (loss: 0.6255933046340942, acc: 0.8141025900840759)
[2024-12-17 02:00:48,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:48,189][root][INFO] - Training Epoch: 1/2, step 4167/7134 completed (loss: 0.4954466223716736, acc: 0.869918704032898)
[2024-12-17 02:00:48,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:48,485][root][INFO] - Training Epoch: 1/2, step 4168/7134 completed (loss: 0.5581672787666321, acc: 0.8796992301940918)
[2024-12-17 02:00:48,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:48,784][root][INFO] - Training Epoch: 1/2, step 4169/7134 completed (loss: 0.5100383162498474, acc: 0.8755760192871094)
[2024-12-17 02:00:48,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:49,085][root][INFO] - Training Epoch: 1/2, step 4170/7134 completed (loss: 0.6288806796073914, acc: 0.8857142925262451)
[2024-12-17 02:00:49,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:49,381][root][INFO] - Training Epoch: 1/2, step 4171/7134 completed (loss: 0.3820045590400696, acc: 0.9162561297416687)
[2024-12-17 02:00:49,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:49,663][root][INFO] - Training Epoch: 1/2, step 4172/7134 completed (loss: 0.6302044987678528, acc: 0.855555534362793)
[2024-12-17 02:00:49,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:49,983][root][INFO] - Training Epoch: 1/2, step 4173/7134 completed (loss: 0.6206050515174866, acc: 0.8425925970077515)
[2024-12-17 02:00:50,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:50,274][root][INFO] - Training Epoch: 1/2, step 4174/7134 completed (loss: 0.19901661574840546, acc: 0.9523809552192688)
[2024-12-17 02:00:50,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:50,568][root][INFO] - Training Epoch: 1/2, step 4175/7134 completed (loss: 0.3203945755958557, acc: 0.922535240650177)
[2024-12-17 02:00:50,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:50,867][root][INFO] - Training Epoch: 1/2, step 4176/7134 completed (loss: 0.33714672923088074, acc: 0.9161290526390076)
[2024-12-17 02:00:51,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:51,191][root][INFO] - Training Epoch: 1/2, step 4177/7134 completed (loss: 0.28137144446372986, acc: 0.9181286692619324)
[2024-12-17 02:00:51,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:51,475][root][INFO] - Training Epoch: 1/2, step 4178/7134 completed (loss: 0.3213277757167816, acc: 0.9144737124443054)
[2024-12-17 02:00:51,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:51,775][root][INFO] - Training Epoch: 1/2, step 4179/7134 completed (loss: 0.23973241448402405, acc: 0.925000011920929)
[2024-12-17 02:00:51,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:52,066][root][INFO] - Training Epoch: 1/2, step 4180/7134 completed (loss: 0.21250569820404053, acc: 0.9437500238418579)
[2024-12-17 02:00:52,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:52,356][root][INFO] - Training Epoch: 1/2, step 4181/7134 completed (loss: 0.2418050616979599, acc: 0.95652174949646)
[2024-12-17 02:00:52,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:52,637][root][INFO] - Training Epoch: 1/2, step 4182/7134 completed (loss: 0.22600959241390228, acc: 0.948051929473877)
[2024-12-17 02:00:52,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:52,929][root][INFO] - Training Epoch: 1/2, step 4183/7134 completed (loss: 0.2854216694831848, acc: 0.9386503100395203)
[2024-12-17 02:00:53,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:53,211][root][INFO] - Training Epoch: 1/2, step 4184/7134 completed (loss: 0.2863410413265228, acc: 0.9529411792755127)
[2024-12-17 02:00:53,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:53,500][root][INFO] - Training Epoch: 1/2, step 4185/7134 completed (loss: 0.3351869583129883, acc: 0.9428571462631226)
[2024-12-17 02:00:53,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:53,815][root][INFO] - Training Epoch: 1/2, step 4186/7134 completed (loss: 0.3412012457847595, acc: 0.938144326210022)
[2024-12-17 02:00:53,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:54,103][root][INFO] - Training Epoch: 1/2, step 4187/7134 completed (loss: 0.2682339549064636, acc: 0.9354838728904724)
[2024-12-17 02:00:54,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:54,403][root][INFO] - Training Epoch: 1/2, step 4188/7134 completed (loss: 0.13052016496658325, acc: 0.9736841917037964)
[2024-12-17 02:00:54,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:54,711][root][INFO] - Training Epoch: 1/2, step 4189/7134 completed (loss: 0.2806009352207184, acc: 0.940119743347168)
[2024-12-17 02:00:54,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:55,010][root][INFO] - Training Epoch: 1/2, step 4190/7134 completed (loss: 0.30628296732902527, acc: 0.9064327478408813)
[2024-12-17 02:00:55,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:55,267][root][INFO] - Training Epoch: 1/2, step 4191/7134 completed (loss: 0.29679039120674133, acc: 0.932692289352417)
[2024-12-17 02:00:55,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:55,548][root][INFO] - Training Epoch: 1/2, step 4192/7134 completed (loss: 0.14654363691806793, acc: 0.9863013625144958)
[2024-12-17 02:00:55,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:55,835][root][INFO] - Training Epoch: 1/2, step 4193/7134 completed (loss: 0.21372199058532715, acc: 0.9273743033409119)
[2024-12-17 02:00:55,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:56,121][root][INFO] - Training Epoch: 1/2, step 4194/7134 completed (loss: 0.10577602684497833, acc: 0.9615384340286255)
[2024-12-17 02:00:56,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:56,411][root][INFO] - Training Epoch: 1/2, step 4195/7134 completed (loss: 0.2973039448261261, acc: 0.9200000166893005)
[2024-12-17 02:00:56,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:56,697][root][INFO] - Training Epoch: 1/2, step 4196/7134 completed (loss: 0.21407277882099152, acc: 0.9568345546722412)
[2024-12-17 02:00:56,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:57,028][root][INFO] - Training Epoch: 1/2, step 4197/7134 completed (loss: 0.3235871195793152, acc: 0.9402173757553101)
[2024-12-17 02:00:57,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:57,314][root][INFO] - Training Epoch: 1/2, step 4198/7134 completed (loss: 0.2630252242088318, acc: 0.9599999785423279)
[2024-12-17 02:00:57,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:57,584][root][INFO] - Training Epoch: 1/2, step 4199/7134 completed (loss: 0.44227102398872375, acc: 0.8591549396514893)
[2024-12-17 02:00:57,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:57,860][root][INFO] - Training Epoch: 1/2, step 4200/7134 completed (loss: 0.4812662601470947, acc: 0.8758620619773865)
[2024-12-17 02:00:57,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:58,154][root][INFO] - Training Epoch: 1/2, step 4201/7134 completed (loss: 0.19820456206798553, acc: 0.9432623982429504)
[2024-12-17 02:00:58,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:58,460][root][INFO] - Training Epoch: 1/2, step 4202/7134 completed (loss: 0.3603586256504059, acc: 0.9097744226455688)
[2024-12-17 02:00:58,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:58,749][root][INFO] - Training Epoch: 1/2, step 4203/7134 completed (loss: 0.33625558018684387, acc: 0.9177215099334717)
[2024-12-17 02:00:58,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:59,027][root][INFO] - Training Epoch: 1/2, step 4204/7134 completed (loss: 0.611789345741272, acc: 0.8571428656578064)
[2024-12-17 02:00:59,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:59,302][root][INFO] - Training Epoch: 1/2, step 4205/7134 completed (loss: 0.4398132860660553, acc: 0.8999999761581421)
[2024-12-17 02:00:59,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:59,602][root][INFO] - Training Epoch: 1/2, step 4206/7134 completed (loss: 0.4287663400173187, acc: 0.8763440847396851)
[2024-12-17 02:00:59,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:59,897][root][INFO] - Training Epoch: 1/2, step 4207/7134 completed (loss: 0.4935537278652191, acc: 0.8742138147354126)
[2024-12-17 02:01:00,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:00,193][root][INFO] - Training Epoch: 1/2, step 4208/7134 completed (loss: 0.6481088399887085, acc: 0.8620689511299133)
[2024-12-17 02:01:00,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:00,480][root][INFO] - Training Epoch: 1/2, step 4209/7134 completed (loss: 0.3717026114463806, acc: 0.8950276374816895)
[2024-12-17 02:01:00,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:00,759][root][INFO] - Training Epoch: 1/2, step 4210/7134 completed (loss: 0.2507164478302002, acc: 0.9298245906829834)
[2024-12-17 02:01:00,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:01,055][root][INFO] - Training Epoch: 1/2, step 4211/7134 completed (loss: 0.2673683166503906, acc: 0.9344262480735779)
[2024-12-17 02:01:01,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:01,382][root][INFO] - Training Epoch: 1/2, step 4212/7134 completed (loss: 0.3654405474662781, acc: 0.9225806593894958)
[2024-12-17 02:01:01,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:01,675][root][INFO] - Training Epoch: 1/2, step 4213/7134 completed (loss: 0.19374729692935944, acc: 0.954023003578186)
[2024-12-17 02:01:01,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:01,972][root][INFO] - Training Epoch: 1/2, step 4214/7134 completed (loss: 0.3838309943675995, acc: 0.9239766001701355)
[2024-12-17 02:01:02,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:02,235][root][INFO] - Training Epoch: 1/2, step 4215/7134 completed (loss: 0.34518498182296753, acc: 0.9055117964744568)
[2024-12-17 02:01:02,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:02,504][root][INFO] - Training Epoch: 1/2, step 4216/7134 completed (loss: 0.21068350970745087, acc: 0.9692307710647583)
[2024-12-17 02:01:02,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:02,755][root][INFO] - Training Epoch: 1/2, step 4217/7134 completed (loss: 0.19420333206653595, acc: 0.949999988079071)
[2024-12-17 02:01:02,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:03,035][root][INFO] - Training Epoch: 1/2, step 4218/7134 completed (loss: 0.43279367685317993, acc: 0.9029850959777832)
[2024-12-17 02:01:03,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:03,277][root][INFO] - Training Epoch: 1/2, step 4219/7134 completed (loss: 0.32373160123825073, acc: 0.9420289993286133)
[2024-12-17 02:01:03,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:03,579][root][INFO] - Training Epoch: 1/2, step 4220/7134 completed (loss: 0.48282620310783386, acc: 0.8977272510528564)
[2024-12-17 02:01:03,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:03,869][root][INFO] - Training Epoch: 1/2, step 4221/7134 completed (loss: 0.2402343451976776, acc: 0.9594594836235046)
[2024-12-17 02:01:03,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:04,129][root][INFO] - Training Epoch: 1/2, step 4222/7134 completed (loss: 0.7389055490493774, acc: 0.8508771657943726)
[2024-12-17 02:01:04,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:04,414][root][INFO] - Training Epoch: 1/2, step 4223/7134 completed (loss: 0.6497976779937744, acc: 0.839195966720581)
[2024-12-17 02:01:04,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:04,690][root][INFO] - Training Epoch: 1/2, step 4224/7134 completed (loss: 0.4419155716896057, acc: 0.9435483813285828)
[2024-12-17 02:01:04,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:04,977][root][INFO] - Training Epoch: 1/2, step 4225/7134 completed (loss: 0.5499261021614075, acc: 0.8525640964508057)
[2024-12-17 02:01:05,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:05,269][root][INFO] - Training Epoch: 1/2, step 4226/7134 completed (loss: 0.6398579478263855, acc: 0.8578680157661438)
[2024-12-17 02:01:05,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:05,544][root][INFO] - Training Epoch: 1/2, step 4227/7134 completed (loss: 1.0578463077545166, acc: 0.7735849022865295)
[2024-12-17 02:01:05,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:05,837][root][INFO] - Training Epoch: 1/2, step 4228/7134 completed (loss: 0.8403418064117432, acc: 0.8141025900840759)
[2024-12-17 02:01:05,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:06,097][root][INFO] - Training Epoch: 1/2, step 4229/7134 completed (loss: 0.5755529999732971, acc: 0.8640000224113464)
[2024-12-17 02:01:06,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:06,363][root][INFO] - Training Epoch: 1/2, step 4230/7134 completed (loss: 0.5327539443969727, acc: 0.8837209343910217)
[2024-12-17 02:01:06,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:06,635][root][INFO] - Training Epoch: 1/2, step 4231/7134 completed (loss: 0.8747116923332214, acc: 0.8523489832878113)
[2024-12-17 02:01:06,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:06,918][root][INFO] - Training Epoch: 1/2, step 4232/7134 completed (loss: 0.6822448968887329, acc: 0.8444444537162781)
[2024-12-17 02:01:07,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:07,215][root][INFO] - Training Epoch: 1/2, step 4233/7134 completed (loss: 0.6518510580062866, acc: 0.8652482032775879)
[2024-12-17 02:01:07,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:07,523][root][INFO] - Training Epoch: 1/2, step 4234/7134 completed (loss: 0.35346677899360657, acc: 0.9219858050346375)
[2024-12-17 02:01:07,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:07,838][root][INFO] - Training Epoch: 1/2, step 4235/7134 completed (loss: 0.3879125714302063, acc: 0.9347826242446899)
[2024-12-17 02:01:07,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:08,148][root][INFO] - Training Epoch: 1/2, step 4236/7134 completed (loss: 0.32574236392974854, acc: 0.9139785170555115)
[2024-12-17 02:01:08,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:08,461][root][INFO] - Training Epoch: 1/2, step 4237/7134 completed (loss: 0.2557741105556488, acc: 0.9252336621284485)
[2024-12-17 02:01:08,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:08,771][root][INFO] - Training Epoch: 1/2, step 4238/7134 completed (loss: 0.4116584360599518, acc: 0.892307698726654)
[2024-12-17 02:01:08,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:09,081][root][INFO] - Training Epoch: 1/2, step 4239/7134 completed (loss: 0.34512123465538025, acc: 0.9120000004768372)
[2024-12-17 02:01:09,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:09,417][root][INFO] - Training Epoch: 1/2, step 4240/7134 completed (loss: 0.38212358951568604, acc: 0.908450722694397)
[2024-12-17 02:01:09,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:09,742][root][INFO] - Training Epoch: 1/2, step 4241/7134 completed (loss: 0.27892380952835083, acc: 0.9399999976158142)
[2024-12-17 02:01:09,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:10,044][root][INFO] - Training Epoch: 1/2, step 4242/7134 completed (loss: 0.3774484395980835, acc: 0.8775510191917419)
[2024-12-17 02:01:10,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:10,351][root][INFO] - Training Epoch: 1/2, step 4243/7134 completed (loss: 0.4570370614528656, acc: 0.9008264541625977)
[2024-12-17 02:01:10,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:10,626][root][INFO] - Training Epoch: 1/2, step 4244/7134 completed (loss: 0.3050991892814636, acc: 0.9245283007621765)
[2024-12-17 02:01:10,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:10,940][root][INFO] - Training Epoch: 1/2, step 4245/7134 completed (loss: 0.33152562379837036, acc: 0.9052631855010986)
[2024-12-17 02:01:11,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:11,257][root][INFO] - Training Epoch: 1/2, step 4246/7134 completed (loss: 0.2942884564399719, acc: 0.9246575236320496)
[2024-12-17 02:01:11,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:11,566][root][INFO] - Training Epoch: 1/2, step 4247/7134 completed (loss: 0.23979751765727997, acc: 0.9359999895095825)
[2024-12-17 02:01:11,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:11,872][root][INFO] - Training Epoch: 1/2, step 4248/7134 completed (loss: 0.4111766517162323, acc: 0.9109588861465454)
[2024-12-17 02:01:12,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:12,213][root][INFO] - Training Epoch: 1/2, step 4249/7134 completed (loss: 0.34069761633872986, acc: 0.9191176295280457)
[2024-12-17 02:01:12,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:12,494][root][INFO] - Training Epoch: 1/2, step 4250/7134 completed (loss: 0.3774009644985199, acc: 0.9272727370262146)
[2024-12-17 02:01:12,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:12,767][root][INFO] - Training Epoch: 1/2, step 4251/7134 completed (loss: 0.34171468019485474, acc: 0.9172932505607605)
[2024-12-17 02:01:12,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:13,045][root][INFO] - Training Epoch: 1/2, step 4252/7134 completed (loss: 0.31406694650650024, acc: 0.9354838728904724)
[2024-12-17 02:01:13,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:13,324][root][INFO] - Training Epoch: 1/2, step 4253/7134 completed (loss: 0.375663697719574, acc: 0.9130434989929199)
[2024-12-17 02:01:13,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:13,605][root][INFO] - Training Epoch: 1/2, step 4254/7134 completed (loss: 0.20256461203098297, acc: 0.9431818127632141)
[2024-12-17 02:01:13,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:13,903][root][INFO] - Training Epoch: 1/2, step 4255/7134 completed (loss: 0.553887665271759, acc: 0.8692307472229004)
[2024-12-17 02:01:14,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:14,186][root][INFO] - Training Epoch: 1/2, step 4256/7134 completed (loss: 0.2125196009874344, acc: 0.9658119678497314)
[2024-12-17 02:01:14,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:14,483][root][INFO] - Training Epoch: 1/2, step 4257/7134 completed (loss: 0.18829365074634552, acc: 0.9545454382896423)
[2024-12-17 02:01:14,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:14,779][root][INFO] - Training Epoch: 1/2, step 4258/7134 completed (loss: 0.1735578030347824, acc: 0.9568965435028076)
[2024-12-17 02:01:14,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:15,071][root][INFO] - Training Epoch: 1/2, step 4259/7134 completed (loss: 0.454881489276886, acc: 0.887499988079071)
[2024-12-17 02:01:15,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:15,365][root][INFO] - Training Epoch: 1/2, step 4260/7134 completed (loss: 0.27567359805107117, acc: 0.9266055226325989)
[2024-12-17 02:01:15,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:15,647][root][INFO] - Training Epoch: 1/2, step 4261/7134 completed (loss: 0.3767724335193634, acc: 0.8782608509063721)
[2024-12-17 02:01:15,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:15,935][root][INFO] - Training Epoch: 1/2, step 4262/7134 completed (loss: 0.43397200107574463, acc: 0.881118893623352)
[2024-12-17 02:01:16,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:16,220][root][INFO] - Training Epoch: 1/2, step 4263/7134 completed (loss: 0.3130040466785431, acc: 0.9333333373069763)
[2024-12-17 02:01:16,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:16,506][root][INFO] - Training Epoch: 1/2, step 4264/7134 completed (loss: 0.5585905313491821, acc: 0.8707864880561829)
[2024-12-17 02:01:16,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:16,784][root][INFO] - Training Epoch: 1/2, step 4265/7134 completed (loss: 0.4881492555141449, acc: 0.8895348906517029)
[2024-12-17 02:01:16,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:17,083][root][INFO] - Training Epoch: 1/2, step 4266/7134 completed (loss: 0.3002159893512726, acc: 0.9214659929275513)
[2024-12-17 02:01:17,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:17,398][root][INFO] - Training Epoch: 1/2, step 4267/7134 completed (loss: 0.340513676404953, acc: 0.8989899158477783)
[2024-12-17 02:01:17,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:17,693][root][INFO] - Training Epoch: 1/2, step 4268/7134 completed (loss: 0.48874208331108093, acc: 0.8861788511276245)
[2024-12-17 02:01:17,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:18,000][root][INFO] - Training Epoch: 1/2, step 4269/7134 completed (loss: 0.6760671734809875, acc: 0.8439306616783142)
[2024-12-17 02:01:18,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:18,305][root][INFO] - Training Epoch: 1/2, step 4270/7134 completed (loss: 0.4921117126941681, acc: 0.8854166865348816)
[2024-12-17 02:01:18,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:18,592][root][INFO] - Training Epoch: 1/2, step 4271/7134 completed (loss: 0.3404182493686676, acc: 0.908108115196228)
[2024-12-17 02:01:18,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:18,885][root][INFO] - Training Epoch: 1/2, step 4272/7134 completed (loss: 0.3910733163356781, acc: 0.9004974961280823)
[2024-12-17 02:01:19,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:19,184][root][INFO] - Training Epoch: 1/2, step 4273/7134 completed (loss: 0.29824867844581604, acc: 0.9153439402580261)
[2024-12-17 02:01:19,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:19,476][root][INFO] - Training Epoch: 1/2, step 4274/7134 completed (loss: 0.5617194771766663, acc: 0.8627451062202454)
[2024-12-17 02:01:19,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:19,747][root][INFO] - Training Epoch: 1/2, step 4275/7134 completed (loss: 0.28071466088294983, acc: 0.9385474920272827)
[2024-12-17 02:01:19,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:20,033][root][INFO] - Training Epoch: 1/2, step 4276/7134 completed (loss: 0.39091482758522034, acc: 0.908108115196228)
[2024-12-17 02:01:20,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:20,311][root][INFO] - Training Epoch: 1/2, step 4277/7134 completed (loss: 0.2327229380607605, acc: 0.9366196990013123)
[2024-12-17 02:01:20,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:20,593][root][INFO] - Training Epoch: 1/2, step 4278/7134 completed (loss: 0.3134688436985016, acc: 0.9132652878761292)
[2024-12-17 02:01:20,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:20,872][root][INFO] - Training Epoch: 1/2, step 4279/7134 completed (loss: 0.1990472972393036, acc: 0.95652174949646)
[2024-12-17 02:01:21,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:21,160][root][INFO] - Training Epoch: 1/2, step 4280/7134 completed (loss: 0.24367974698543549, acc: 0.936170220375061)
[2024-12-17 02:01:21,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:21,460][root][INFO] - Training Epoch: 1/2, step 4281/7134 completed (loss: 0.3359537720680237, acc: 0.9408602118492126)
[2024-12-17 02:01:21,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:21,744][root][INFO] - Training Epoch: 1/2, step 4282/7134 completed (loss: 0.2585866153240204, acc: 0.9396551847457886)
[2024-12-17 02:01:21,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:22,028][root][INFO] - Training Epoch: 1/2, step 4283/7134 completed (loss: 0.2647344172000885, acc: 0.9438775777816772)
[2024-12-17 02:01:22,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:22,294][root][INFO] - Training Epoch: 1/2, step 4284/7134 completed (loss: 0.5986153483390808, acc: 0.8682170510292053)
[2024-12-17 02:01:22,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:22,601][root][INFO] - Training Epoch: 1/2, step 4285/7134 completed (loss: 0.36370566487312317, acc: 0.9069767594337463)
[2024-12-17 02:01:22,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:22,922][root][INFO] - Training Epoch: 1/2, step 4286/7134 completed (loss: 0.33726170659065247, acc: 0.9159663915634155)
[2024-12-17 02:01:23,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:23,232][root][INFO] - Training Epoch: 1/2, step 4287/7134 completed (loss: 0.34115365147590637, acc: 0.9347826242446899)
[2024-12-17 02:01:23,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:23,546][root][INFO] - Training Epoch: 1/2, step 4288/7134 completed (loss: 0.44624778628349304, acc: 0.8823529481887817)
[2024-12-17 02:01:23,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:23,860][root][INFO] - Training Epoch: 1/2, step 4289/7134 completed (loss: 0.27935582399368286, acc: 0.9509202241897583)
[2024-12-17 02:01:24,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:24,152][root][INFO] - Training Epoch: 1/2, step 4290/7134 completed (loss: 0.3538650572299957, acc: 0.8959537744522095)
[2024-12-17 02:01:24,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:24,437][root][INFO] - Training Epoch: 1/2, step 4291/7134 completed (loss: 0.17980310320854187, acc: 0.9364162087440491)
[2024-12-17 02:01:24,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:24,731][root][INFO] - Training Epoch: 1/2, step 4292/7134 completed (loss: 0.31727564334869385, acc: 0.9290322661399841)
[2024-12-17 02:01:24,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:25,043][root][INFO] - Training Epoch: 1/2, step 4293/7134 completed (loss: 0.30929604172706604, acc: 0.9583333134651184)
[2024-12-17 02:01:25,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:25,340][root][INFO] - Training Epoch: 1/2, step 4294/7134 completed (loss: 0.41203975677490234, acc: 0.9085714221000671)
[2024-12-17 02:01:25,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:25,639][root][INFO] - Training Epoch: 1/2, step 4295/7134 completed (loss: 0.2908865213394165, acc: 0.949999988079071)
[2024-12-17 02:01:25,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:25,930][root][INFO] - Training Epoch: 1/2, step 4296/7134 completed (loss: 0.2647366225719452, acc: 0.9405940771102905)
[2024-12-17 02:01:26,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:26,236][root][INFO] - Training Epoch: 1/2, step 4297/7134 completed (loss: 0.1375342160463333, acc: 0.9714285731315613)
[2024-12-17 02:01:26,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:26,543][root][INFO] - Training Epoch: 1/2, step 4298/7134 completed (loss: 0.27937614917755127, acc: 0.9261363744735718)
[2024-12-17 02:01:26,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:26,834][root][INFO] - Training Epoch: 1/2, step 4299/7134 completed (loss: 0.25719475746154785, acc: 0.9354838728904724)
[2024-12-17 02:01:26,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:27,114][root][INFO] - Training Epoch: 1/2, step 4300/7134 completed (loss: 0.49399450421333313, acc: 0.8823529481887817)
[2024-12-17 02:01:27,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:27,439][root][INFO] - Training Epoch: 1/2, step 4301/7134 completed (loss: 0.2546130120754242, acc: 0.9507042169570923)
[2024-12-17 02:01:27,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:27,734][root][INFO] - Training Epoch: 1/2, step 4302/7134 completed (loss: 0.2945970296859741, acc: 0.9363057613372803)
[2024-12-17 02:01:27,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:28,023][root][INFO] - Training Epoch: 1/2, step 4303/7134 completed (loss: 0.317024827003479, acc: 0.905940592288971)
[2024-12-17 02:01:28,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:28,334][root][INFO] - Training Epoch: 1/2, step 4304/7134 completed (loss: 0.24765026569366455, acc: 0.9408283829689026)
[2024-12-17 02:01:28,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:28,630][root][INFO] - Training Epoch: 1/2, step 4305/7134 completed (loss: 0.3850852847099304, acc: 0.9150000214576721)
[2024-12-17 02:01:28,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:28,922][root][INFO] - Training Epoch: 1/2, step 4306/7134 completed (loss: 0.4692038595676422, acc: 0.8952879309654236)
[2024-12-17 02:01:29,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:29,202][root][INFO] - Training Epoch: 1/2, step 4307/7134 completed (loss: 0.3476245701313019, acc: 0.9215686321258545)
[2024-12-17 02:01:29,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:29,496][root][INFO] - Training Epoch: 1/2, step 4308/7134 completed (loss: 0.33004316687583923, acc: 0.9304812550544739)
[2024-12-17 02:01:29,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:29,784][root][INFO] - Training Epoch: 1/2, step 4309/7134 completed (loss: 0.3481057584285736, acc: 0.9204545617103577)
[2024-12-17 02:01:29,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:30,100][root][INFO] - Training Epoch: 1/2, step 4310/7134 completed (loss: 0.34487006068229675, acc: 0.913705587387085)
[2024-12-17 02:01:30,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:30,388][root][INFO] - Training Epoch: 1/2, step 4311/7134 completed (loss: 0.2775615453720093, acc: 0.9219858050346375)
[2024-12-17 02:01:30,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:30,667][root][INFO] - Training Epoch: 1/2, step 4312/7134 completed (loss: 0.30599403381347656, acc: 0.9141104221343994)
[2024-12-17 02:01:30,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:30,962][root][INFO] - Training Epoch: 1/2, step 4313/7134 completed (loss: 0.24511654675006866, acc: 0.9151515364646912)
[2024-12-17 02:01:31,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:31,268][root][INFO] - Training Epoch: 1/2, step 4314/7134 completed (loss: 0.21850471198558807, acc: 0.9411764740943909)
[2024-12-17 02:01:31,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:31,578][root][INFO] - Training Epoch: 1/2, step 4315/7134 completed (loss: 0.3535240590572357, acc: 0.9226190447807312)
[2024-12-17 02:01:31,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:31,871][root][INFO] - Training Epoch: 1/2, step 4316/7134 completed (loss: 0.346119225025177, acc: 0.9221556782722473)
[2024-12-17 02:01:32,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:32,155][root][INFO] - Training Epoch: 1/2, step 4317/7134 completed (loss: 0.3150527775287628, acc: 0.930232584476471)
[2024-12-17 02:01:32,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:32,446][root][INFO] - Training Epoch: 1/2, step 4318/7134 completed (loss: 0.417804092168808, acc: 0.8979591727256775)
[2024-12-17 02:01:32,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:32,747][root][INFO] - Training Epoch: 1/2, step 4319/7134 completed (loss: 0.3264104425907135, acc: 0.9211822748184204)
[2024-12-17 02:01:32,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:33,024][root][INFO] - Training Epoch: 1/2, step 4320/7134 completed (loss: 0.31938862800598145, acc: 0.9038461446762085)
[2024-12-17 02:01:33,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:33,323][root][INFO] - Training Epoch: 1/2, step 4321/7134 completed (loss: 0.766838550567627, acc: 0.8316831588745117)
[2024-12-17 02:01:33,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:33,616][root][INFO] - Training Epoch: 1/2, step 4322/7134 completed (loss: 0.4996814429759979, acc: 0.8805031180381775)
[2024-12-17 02:01:33,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:33,894][root][INFO] - Training Epoch: 1/2, step 4323/7134 completed (loss: 0.2790127694606781, acc: 0.8947368264198303)
[2024-12-17 02:01:34,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:34,175][root][INFO] - Training Epoch: 1/2, step 4324/7134 completed (loss: 0.4778415560722351, acc: 0.904347836971283)
[2024-12-17 02:01:34,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:34,466][root][INFO] - Training Epoch: 1/2, step 4325/7134 completed (loss: 0.35986804962158203, acc: 0.9109588861465454)
[2024-12-17 02:01:34,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:34,745][root][INFO] - Training Epoch: 1/2, step 4326/7134 completed (loss: 0.44212988018989563, acc: 0.8863636255264282)
[2024-12-17 02:01:34,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:35,028][root][INFO] - Training Epoch: 1/2, step 4327/7134 completed (loss: 0.2596512734889984, acc: 0.9416058659553528)
[2024-12-17 02:01:35,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:35,320][root][INFO] - Training Epoch: 1/2, step 4328/7134 completed (loss: 0.3226422071456909, acc: 0.9140625)
[2024-12-17 02:01:35,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:35,614][root][INFO] - Training Epoch: 1/2, step 4329/7134 completed (loss: 0.3902365267276764, acc: 0.9298245906829834)
[2024-12-17 02:01:35,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:35,902][root][INFO] - Training Epoch: 1/2, step 4330/7134 completed (loss: 0.3291019797325134, acc: 0.9009009003639221)
[2024-12-17 02:01:36,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:36,181][root][INFO] - Training Epoch: 1/2, step 4331/7134 completed (loss: 0.4281516373157501, acc: 0.8641975522041321)
[2024-12-17 02:01:36,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:36,475][root][INFO] - Training Epoch: 1/2, step 4332/7134 completed (loss: 0.450661301612854, acc: 0.9126983880996704)
[2024-12-17 02:01:36,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:36,756][root][INFO] - Training Epoch: 1/2, step 4333/7134 completed (loss: 0.306316614151001, acc: 0.949999988079071)
[2024-12-17 02:01:36,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:37,059][root][INFO] - Training Epoch: 1/2, step 4334/7134 completed (loss: 0.45221659541130066, acc: 0.9141104221343994)
[2024-12-17 02:01:37,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:37,361][root][INFO] - Training Epoch: 1/2, step 4335/7134 completed (loss: 0.32029789686203003, acc: 0.942148745059967)
[2024-12-17 02:01:37,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:37,672][root][INFO] - Training Epoch: 1/2, step 4336/7134 completed (loss: 0.19317293167114258, acc: 0.9496402740478516)
[2024-12-17 02:01:37,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:37,984][root][INFO] - Training Epoch: 1/2, step 4337/7134 completed (loss: 0.2152983546257019, acc: 0.9230769276618958)
[2024-12-17 02:01:38,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:38,272][root][INFO] - Training Epoch: 1/2, step 4338/7134 completed (loss: 0.302170068025589, acc: 0.9333333373069763)
[2024-12-17 02:01:38,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:38,558][root][INFO] - Training Epoch: 1/2, step 4339/7134 completed (loss: 0.25455260276794434, acc: 0.9470587968826294)
[2024-12-17 02:01:38,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:38,857][root][INFO] - Training Epoch: 1/2, step 4340/7134 completed (loss: 0.2750082015991211, acc: 0.9448275566101074)
[2024-12-17 02:01:38,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:39,134][root][INFO] - Training Epoch: 1/2, step 4341/7134 completed (loss: 0.33341729640960693, acc: 0.918367326259613)
[2024-12-17 02:01:39,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:39,430][root][INFO] - Training Epoch: 1/2, step 4342/7134 completed (loss: 0.3630991578102112, acc: 0.9271523356437683)
[2024-12-17 02:01:39,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:39,713][root][INFO] - Training Epoch: 1/2, step 4343/7134 completed (loss: 0.4382777512073517, acc: 0.9111111164093018)
[2024-12-17 02:01:39,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:40,012][root][INFO] - Training Epoch: 1/2, step 4344/7134 completed (loss: 0.3150157630443573, acc: 0.904347836971283)
[2024-12-17 02:01:40,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:40,302][root][INFO] - Training Epoch: 1/2, step 4345/7134 completed (loss: 0.26208099722862244, acc: 0.9279279112815857)
[2024-12-17 02:01:40,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:40,603][root][INFO] - Training Epoch: 1/2, step 4346/7134 completed (loss: 0.294325053691864, acc: 0.9099099040031433)
[2024-12-17 02:01:40,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:40,876][root][INFO] - Training Epoch: 1/2, step 4347/7134 completed (loss: 0.4481751620769501, acc: 0.9230769276618958)
[2024-12-17 02:01:40,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:41,145][root][INFO] - Training Epoch: 1/2, step 4348/7134 completed (loss: 0.3155406415462494, acc: 0.9319728016853333)
[2024-12-17 02:01:41,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:41,473][root][INFO] - Training Epoch: 1/2, step 4349/7134 completed (loss: 0.2912045419216156, acc: 0.9270833134651184)
[2024-12-17 02:01:41,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:41,763][root][INFO] - Training Epoch: 1/2, step 4350/7134 completed (loss: 0.32630306482315063, acc: 0.9382022619247437)
[2024-12-17 02:01:41,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:42,037][root][INFO] - Training Epoch: 1/2, step 4351/7134 completed (loss: 0.41108179092407227, acc: 0.8910256624221802)
[2024-12-17 02:01:42,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:42,320][root][INFO] - Training Epoch: 1/2, step 4352/7134 completed (loss: 0.500519871711731, acc: 0.888198733329773)
[2024-12-17 02:01:42,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:42,598][root][INFO] - Training Epoch: 1/2, step 4353/7134 completed (loss: 0.38595330715179443, acc: 0.8982036113739014)
[2024-12-17 02:01:42,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:42,887][root][INFO] - Training Epoch: 1/2, step 4354/7134 completed (loss: 0.2776359021663666, acc: 0.9325153231620789)
[2024-12-17 02:01:43,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:43,162][root][INFO] - Training Epoch: 1/2, step 4355/7134 completed (loss: 0.4504113495349884, acc: 0.9006211161613464)
[2024-12-17 02:01:43,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:43,452][root][INFO] - Training Epoch: 1/2, step 4356/7134 completed (loss: 0.36191174387931824, acc: 0.9186046719551086)
[2024-12-17 02:01:43,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:43,742][root][INFO] - Training Epoch: 1/2, step 4357/7134 completed (loss: 0.6936386227607727, acc: 0.818791925907135)
[2024-12-17 02:01:43,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:44,053][root][INFO] - Training Epoch: 1/2, step 4358/7134 completed (loss: 0.5541639924049377, acc: 0.8658536672592163)
[2024-12-17 02:01:44,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:44,336][root][INFO] - Training Epoch: 1/2, step 4359/7134 completed (loss: 0.29707586765289307, acc: 0.9126983880996704)
[2024-12-17 02:01:44,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:44,648][root][INFO] - Training Epoch: 1/2, step 4360/7134 completed (loss: 0.4041459560394287, acc: 0.8917197585105896)
[2024-12-17 02:01:44,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:44,931][root][INFO] - Training Epoch: 1/2, step 4361/7134 completed (loss: 0.3267016112804413, acc: 0.9006622433662415)
[2024-12-17 02:01:45,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:45,216][root][INFO] - Training Epoch: 1/2, step 4362/7134 completed (loss: 0.3026045858860016, acc: 0.929347813129425)
[2024-12-17 02:01:45,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:45,504][root][INFO] - Training Epoch: 1/2, step 4363/7134 completed (loss: 0.4345487058162689, acc: 0.9015151262283325)
[2024-12-17 02:01:45,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:45,767][root][INFO] - Training Epoch: 1/2, step 4364/7134 completed (loss: 0.354213684797287, acc: 0.9224806427955627)
[2024-12-17 02:01:45,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:46,085][root][INFO] - Training Epoch: 1/2, step 4365/7134 completed (loss: 0.3338063359260559, acc: 0.8920863270759583)
[2024-12-17 02:01:46,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:46,389][root][INFO] - Training Epoch: 1/2, step 4366/7134 completed (loss: 0.3034898638725281, acc: 0.930232584476471)
[2024-12-17 02:01:46,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:46,677][root][INFO] - Training Epoch: 1/2, step 4367/7134 completed (loss: 0.38534265756607056, acc: 0.899328887462616)
[2024-12-17 02:01:46,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:47,020][root][INFO] - Training Epoch: 1/2, step 4368/7134 completed (loss: 0.24086503684520721, acc: 0.940119743347168)
[2024-12-17 02:01:47,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:47,299][root][INFO] - Training Epoch: 1/2, step 4369/7134 completed (loss: 0.26233354210853577, acc: 0.934959352016449)
[2024-12-17 02:01:47,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:47,608][root][INFO] - Training Epoch: 1/2, step 4370/7134 completed (loss: 0.5450510382652283, acc: 0.9127907156944275)
[2024-12-17 02:01:47,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:47,903][root][INFO] - Training Epoch: 1/2, step 4371/7134 completed (loss: 0.43105000257492065, acc: 0.8658536672592163)
[2024-12-17 02:01:48,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:48,205][root][INFO] - Training Epoch: 1/2, step 4372/7134 completed (loss: 0.30952924489974976, acc: 0.9262295365333557)
[2024-12-17 02:01:48,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:48,497][root][INFO] - Training Epoch: 1/2, step 4373/7134 completed (loss: 0.4208492040634155, acc: 0.8950276374816895)
[2024-12-17 02:01:48,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:48,802][root][INFO] - Training Epoch: 1/2, step 4374/7134 completed (loss: 0.3701689541339874, acc: 0.8963414430618286)
[2024-12-17 02:01:48,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:49,101][root][INFO] - Training Epoch: 1/2, step 4375/7134 completed (loss: 0.34124720096588135, acc: 0.9226190447807312)
[2024-12-17 02:01:49,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:49,384][root][INFO] - Training Epoch: 1/2, step 4376/7134 completed (loss: 0.37304115295410156, acc: 0.8854166865348816)
[2024-12-17 02:01:49,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:49,670][root][INFO] - Training Epoch: 1/2, step 4377/7134 completed (loss: 0.4711352288722992, acc: 0.8999999761581421)
[2024-12-17 02:01:49,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:49,944][root][INFO] - Training Epoch: 1/2, step 4378/7134 completed (loss: 0.5175051093101501, acc: 0.8721804618835449)
[2024-12-17 02:01:50,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:50,237][root][INFO] - Training Epoch: 1/2, step 4379/7134 completed (loss: 0.5379490256309509, acc: 0.8897058963775635)
[2024-12-17 02:01:50,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:50,512][root][INFO] - Training Epoch: 1/2, step 4380/7134 completed (loss: 0.5992845296859741, acc: 0.8531468510627747)
[2024-12-17 02:01:50,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:50,797][root][INFO] - Training Epoch: 1/2, step 4381/7134 completed (loss: 0.3576224446296692, acc: 0.886227548122406)
[2024-12-17 02:01:50,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:51,067][root][INFO] - Training Epoch: 1/2, step 4382/7134 completed (loss: 0.508701503276825, acc: 0.8838709592819214)
[2024-12-17 02:01:51,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:51,359][root][INFO] - Training Epoch: 1/2, step 4383/7134 completed (loss: 0.6684933304786682, acc: 0.8477157354354858)
[2024-12-17 02:01:51,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:51,628][root][INFO] - Training Epoch: 1/2, step 4384/7134 completed (loss: 0.37658995389938354, acc: 0.8863636255264282)
[2024-12-17 02:01:51,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:51,937][root][INFO] - Training Epoch: 1/2, step 4385/7134 completed (loss: 0.5522357225418091, acc: 0.8704662919044495)
[2024-12-17 02:01:52,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:52,232][root][INFO] - Training Epoch: 1/2, step 4386/7134 completed (loss: 0.44179490208625793, acc: 0.893203854560852)
[2024-12-17 02:01:52,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:52,541][root][INFO] - Training Epoch: 1/2, step 4387/7134 completed (loss: 0.48454251885414124, acc: 0.8588235378265381)
[2024-12-17 02:01:52,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:52,833][root][INFO] - Training Epoch: 1/2, step 4388/7134 completed (loss: 0.5719796419143677, acc: 0.8571428656578064)
[2024-12-17 02:01:52,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:53,111][root][INFO] - Training Epoch: 1/2, step 4389/7134 completed (loss: 0.9187324047088623, acc: 0.8695651888847351)
[2024-12-17 02:01:53,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:53,402][root][INFO] - Training Epoch: 1/2, step 4390/7134 completed (loss: 0.6358394622802734, acc: 0.8466257452964783)
[2024-12-17 02:01:53,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:53,672][root][INFO] - Training Epoch: 1/2, step 4391/7134 completed (loss: 0.8325868844985962, acc: 0.8150684833526611)
[2024-12-17 02:01:53,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:53,946][root][INFO] - Training Epoch: 1/2, step 4392/7134 completed (loss: 0.3470064699649811, acc: 0.9153439402580261)
[2024-12-17 02:01:54,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:54,238][root][INFO] - Training Epoch: 1/2, step 4393/7134 completed (loss: 0.3011271059513092, acc: 0.9133333563804626)
[2024-12-17 02:01:54,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:54,535][root][INFO] - Training Epoch: 1/2, step 4394/7134 completed (loss: 0.38353437185287476, acc: 0.9194630980491638)
[2024-12-17 02:01:54,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:54,817][root][INFO] - Training Epoch: 1/2, step 4395/7134 completed (loss: 0.7604197859764099, acc: 0.8260869383811951)
[2024-12-17 02:01:54,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:55,097][root][INFO] - Training Epoch: 1/2, step 4396/7134 completed (loss: 0.7101328372955322, acc: 0.8359788656234741)
[2024-12-17 02:01:55,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:55,384][root][INFO] - Training Epoch: 1/2, step 4397/7134 completed (loss: 1.1965278387069702, acc: 0.792792797088623)
[2024-12-17 02:01:55,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:55,654][root][INFO] - Training Epoch: 1/2, step 4398/7134 completed (loss: 0.5934130549430847, acc: 0.8999999761581421)
[2024-12-17 02:01:55,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:55,963][root][INFO] - Training Epoch: 1/2, step 4399/7134 completed (loss: 0.4944707155227661, acc: 0.9027777910232544)
[2024-12-17 02:01:56,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:56,272][root][INFO] - Training Epoch: 1/2, step 4400/7134 completed (loss: 0.40614673495292664, acc: 0.9315789341926575)
[2024-12-17 02:01:56,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:56,604][root][INFO] - Training Epoch: 1/2, step 4401/7134 completed (loss: 0.6349189281463623, acc: 0.8838709592819214)
[2024-12-17 02:01:56,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:56,893][root][INFO] - Training Epoch: 1/2, step 4402/7134 completed (loss: 0.7663686275482178, acc: 0.8271604776382446)
[2024-12-17 02:01:56,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:57,179][root][INFO] - Training Epoch: 1/2, step 4403/7134 completed (loss: 0.8915964365005493, acc: 0.7909091114997864)
[2024-12-17 02:01:57,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:57,452][root][INFO] - Training Epoch: 1/2, step 4404/7134 completed (loss: 0.7305189371109009, acc: 0.8195876479148865)
[2024-12-17 02:01:57,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:57,747][root][INFO] - Training Epoch: 1/2, step 4405/7134 completed (loss: 0.5254866480827332, acc: 0.8762376308441162)
[2024-12-17 02:01:57,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:58,044][root][INFO] - Training Epoch: 1/2, step 4406/7134 completed (loss: 0.25339242815971375, acc: 0.9365853667259216)
[2024-12-17 02:01:58,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:58,331][root][INFO] - Training Epoch: 1/2, step 4407/7134 completed (loss: 0.42260196805000305, acc: 0.8928571343421936)
[2024-12-17 02:01:58,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:58,627][root][INFO] - Training Epoch: 1/2, step 4408/7134 completed (loss: 0.6693020462989807, acc: 0.8269230723381042)
[2024-12-17 02:01:58,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:58,910][root][INFO] - Training Epoch: 1/2, step 4409/7134 completed (loss: 0.45434728264808655, acc: 0.9010416865348816)
[2024-12-17 02:01:59,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:59,182][root][INFO] - Training Epoch: 1/2, step 4410/7134 completed (loss: 0.7479528784751892, acc: 0.8041958212852478)
[2024-12-17 02:01:59,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:59,455][root][INFO] - Training Epoch: 1/2, step 4411/7134 completed (loss: 0.7722815871238708, acc: 0.8279569745063782)
[2024-12-17 02:01:59,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:59,747][root][INFO] - Training Epoch: 1/2, step 4412/7134 completed (loss: 1.146953821182251, acc: 0.7688442468643188)
[2024-12-17 02:01:59,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:00,045][root][INFO] - Training Epoch: 1/2, step 4413/7134 completed (loss: 0.8475521206855774, acc: 0.8290155529975891)
[2024-12-17 02:02:00,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:00,331][root][INFO] - Training Epoch: 1/2, step 4414/7134 completed (loss: 0.3543357849121094, acc: 0.897849440574646)
[2024-12-17 02:02:00,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:00,614][root][INFO] - Training Epoch: 1/2, step 4415/7134 completed (loss: 0.5372164249420166, acc: 0.8595505356788635)
[2024-12-17 02:02:00,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:00,901][root][INFO] - Training Epoch: 1/2, step 4416/7134 completed (loss: 0.43209969997406006, acc: 0.8549222946166992)
[2024-12-17 02:02:01,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:01,182][root][INFO] - Training Epoch: 1/2, step 4417/7134 completed (loss: 0.7089340686798096, acc: 0.8383838534355164)
[2024-12-17 02:02:01,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:01,467][root][INFO] - Training Epoch: 1/2, step 4418/7134 completed (loss: 0.48948201537132263, acc: 0.8695651888847351)
[2024-12-17 02:02:01,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:01,745][root][INFO] - Training Epoch: 1/2, step 4419/7134 completed (loss: 0.5559546947479248, acc: 0.8731707334518433)
[2024-12-17 02:02:01,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:02,044][root][INFO] - Training Epoch: 1/2, step 4420/7134 completed (loss: 0.6828036904335022, acc: 0.8497409224510193)
[2024-12-17 02:02:02,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:02,336][root][INFO] - Training Epoch: 1/2, step 4421/7134 completed (loss: 0.5335211157798767, acc: 0.8669725060462952)
[2024-12-17 02:02:02,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:02,624][root][INFO] - Training Epoch: 1/2, step 4422/7134 completed (loss: 0.5993587374687195, acc: 0.8742514848709106)
[2024-12-17 02:02:02,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:02,918][root][INFO] - Training Epoch: 1/2, step 4423/7134 completed (loss: 0.46900230646133423, acc: 0.8794642686843872)
[2024-12-17 02:02:03,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:03,226][root][INFO] - Training Epoch: 1/2, step 4424/7134 completed (loss: 0.31556686758995056, acc: 0.9147727489471436)
[2024-12-17 02:02:03,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:03,551][root][INFO] - Training Epoch: 1/2, step 4425/7134 completed (loss: 0.37086597084999084, acc: 0.9257425665855408)
[2024-12-17 02:02:03,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:03,850][root][INFO] - Training Epoch: 1/2, step 4426/7134 completed (loss: 0.46648719906806946, acc: 0.8920000195503235)
[2024-12-17 02:02:03,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:04,120][root][INFO] - Training Epoch: 1/2, step 4427/7134 completed (loss: 0.9057905673980713, acc: 0.8017241358757019)
[2024-12-17 02:02:04,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:04,421][root][INFO] - Training Epoch: 1/2, step 4428/7134 completed (loss: 0.42354288697242737, acc: 0.9190751314163208)
[2024-12-17 02:02:04,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:04,678][root][INFO] - Training Epoch: 1/2, step 4429/7134 completed (loss: 0.7804049253463745, acc: 0.8190476298332214)
[2024-12-17 02:02:04,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:04,975][root][INFO] - Training Epoch: 1/2, step 4430/7134 completed (loss: 0.5455248355865479, acc: 0.8707864880561829)
[2024-12-17 02:02:05,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:05,273][root][INFO] - Training Epoch: 1/2, step 4431/7134 completed (loss: 0.581674337387085, acc: 0.8779069781303406)
[2024-12-17 02:02:05,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:05,554][root][INFO] - Training Epoch: 1/2, step 4432/7134 completed (loss: 0.40952587127685547, acc: 0.9108280539512634)
[2024-12-17 02:02:05,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:05,848][root][INFO] - Training Epoch: 1/2, step 4433/7134 completed (loss: 0.4526952803134918, acc: 0.9095237851142883)
[2024-12-17 02:02:05,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:06,159][root][INFO] - Training Epoch: 1/2, step 4434/7134 completed (loss: 0.5861474871635437, acc: 0.8399999737739563)
[2024-12-17 02:02:06,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:06,468][root][INFO] - Training Epoch: 1/2, step 4435/7134 completed (loss: 0.4305114448070526, acc: 0.9166666865348816)
[2024-12-17 02:02:06,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:06,763][root][INFO] - Training Epoch: 1/2, step 4436/7134 completed (loss: 0.5489394068717957, acc: 0.8757396340370178)
[2024-12-17 02:02:06,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:07,048][root][INFO] - Training Epoch: 1/2, step 4437/7134 completed (loss: 0.2654879689216614, acc: 0.9508196711540222)
[2024-12-17 02:02:07,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:07,345][root][INFO] - Training Epoch: 1/2, step 4438/7134 completed (loss: 0.5667715668678284, acc: 0.89552241563797)
[2024-12-17 02:02:07,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:07,636][root][INFO] - Training Epoch: 1/2, step 4439/7134 completed (loss: 0.21890677511692047, acc: 0.957446813583374)
[2024-12-17 02:02:07,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:07,903][root][INFO] - Training Epoch: 1/2, step 4440/7134 completed (loss: 0.3119407892227173, acc: 0.9036144614219666)
[2024-12-17 02:02:08,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:08,226][root][INFO] - Training Epoch: 1/2, step 4441/7134 completed (loss: 0.29558470845222473, acc: 0.9182389974594116)
[2024-12-17 02:02:08,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:08,512][root][INFO] - Training Epoch: 1/2, step 4442/7134 completed (loss: 0.5543277859687805, acc: 0.898876428604126)
[2024-12-17 02:02:08,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:08,826][root][INFO] - Training Epoch: 1/2, step 4443/7134 completed (loss: 0.376523494720459, acc: 0.8882352709770203)
[2024-12-17 02:02:08,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:09,096][root][INFO] - Training Epoch: 1/2, step 4444/7134 completed (loss: 0.29709795117378235, acc: 0.9197080135345459)
[2024-12-17 02:02:09,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:09,370][root][INFO] - Training Epoch: 1/2, step 4445/7134 completed (loss: 0.7288326025009155, acc: 0.857988178730011)
[2024-12-17 02:02:09,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:09,648][root][INFO] - Training Epoch: 1/2, step 4446/7134 completed (loss: 0.2668745517730713, acc: 0.961240291595459)
[2024-12-17 02:02:09,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:09,941][root][INFO] - Training Epoch: 1/2, step 4447/7134 completed (loss: 0.2697030305862427, acc: 0.9367815852165222)
[2024-12-17 02:02:10,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:10,230][root][INFO] - Training Epoch: 1/2, step 4448/7134 completed (loss: 0.3898913562297821, acc: 0.9147287011146545)
[2024-12-17 02:02:10,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:10,496][root][INFO] - Training Epoch: 1/2, step 4449/7134 completed (loss: 0.3329135775566101, acc: 0.9237288236618042)
[2024-12-17 02:02:10,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:10,812][root][INFO] - Training Epoch: 1/2, step 4450/7134 completed (loss: 0.4965144991874695, acc: 0.8457446694374084)
[2024-12-17 02:02:10,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:11,097][root][INFO] - Training Epoch: 1/2, step 4451/7134 completed (loss: 0.6594237685203552, acc: 0.8471337556838989)
[2024-12-17 02:02:11,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:11,378][root][INFO] - Training Epoch: 1/2, step 4452/7134 completed (loss: 0.3839176297187805, acc: 0.9185185432434082)
[2024-12-17 02:02:11,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:11,684][root][INFO] - Training Epoch: 1/2, step 4453/7134 completed (loss: 0.40700188279151917, acc: 0.9346405267715454)
[2024-12-17 02:02:11,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:11,975][root][INFO] - Training Epoch: 1/2, step 4454/7134 completed (loss: 0.5205236673355103, acc: 0.888198733329773)
[2024-12-17 02:02:12,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:12,292][root][INFO] - Training Epoch: 1/2, step 4455/7134 completed (loss: 0.5936300754547119, acc: 0.8703703880310059)
[2024-12-17 02:02:12,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:12,569][root][INFO] - Training Epoch: 1/2, step 4456/7134 completed (loss: 0.22735269367694855, acc: 0.9333333373069763)
[2024-12-17 02:02:12,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:12,832][root][INFO] - Training Epoch: 1/2, step 4457/7134 completed (loss: 0.30765500664711, acc: 0.9220778942108154)
[2024-12-17 02:02:12,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:13,109][root][INFO] - Training Epoch: 1/2, step 4458/7134 completed (loss: 0.10120510309934616, acc: 0.9860140085220337)
[2024-12-17 02:02:13,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:13,415][root][INFO] - Training Epoch: 1/2, step 4459/7134 completed (loss: 0.17200875282287598, acc: 0.9651162624359131)
[2024-12-17 02:02:13,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:13,726][root][INFO] - Training Epoch: 1/2, step 4460/7134 completed (loss: 0.2601414918899536, acc: 0.9408866763114929)
[2024-12-17 02:02:13,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:14,008][root][INFO] - Training Epoch: 1/2, step 4461/7134 completed (loss: 0.32419994473457336, acc: 0.9010416865348816)
[2024-12-17 02:02:14,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:14,284][root][INFO] - Training Epoch: 1/2, step 4462/7134 completed (loss: 0.2806399464607239, acc: 0.9257143139839172)
[2024-12-17 02:02:14,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:14,582][root][INFO] - Training Epoch: 1/2, step 4463/7134 completed (loss: 0.24462054669857025, acc: 0.9523809552192688)
[2024-12-17 02:02:14,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:14,910][root][INFO] - Training Epoch: 1/2, step 4464/7134 completed (loss: 0.22515428066253662, acc: 0.965753436088562)
[2024-12-17 02:02:15,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:15,210][root][INFO] - Training Epoch: 1/2, step 4465/7134 completed (loss: 0.25102895498275757, acc: 0.9494949579238892)
[2024-12-17 02:02:15,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:15,503][root][INFO] - Training Epoch: 1/2, step 4466/7134 completed (loss: 0.29905492067337036, acc: 0.9343434572219849)
[2024-12-17 02:02:15,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:15,800][root][INFO] - Training Epoch: 1/2, step 4467/7134 completed (loss: 0.28227871656417847, acc: 0.9358288645744324)
[2024-12-17 02:02:15,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:16,085][root][INFO] - Training Epoch: 1/2, step 4468/7134 completed (loss: 0.13701586425304413, acc: 0.9625668525695801)
[2024-12-17 02:02:16,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:16,378][root][INFO] - Training Epoch: 1/2, step 4469/7134 completed (loss: 0.22935092449188232, acc: 0.9306930899620056)
[2024-12-17 02:02:16,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:16,676][root][INFO] - Training Epoch: 1/2, step 4470/7134 completed (loss: 0.19255605340003967, acc: 0.9519230723381042)
[2024-12-17 02:02:16,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:16,975][root][INFO] - Training Epoch: 1/2, step 4471/7134 completed (loss: 0.1010221317410469, acc: 0.9747474789619446)
[2024-12-17 02:02:17,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:17,269][root][INFO] - Training Epoch: 1/2, step 4472/7134 completed (loss: 0.20690150558948517, acc: 0.9444444179534912)
[2024-12-17 02:02:17,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:17,565][root][INFO] - Training Epoch: 1/2, step 4473/7134 completed (loss: 0.3721102774143219, acc: 0.88165682554245)
[2024-12-17 02:02:17,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:17,848][root][INFO] - Training Epoch: 1/2, step 4474/7134 completed (loss: 0.40193378925323486, acc: 0.9192546606063843)
[2024-12-17 02:02:17,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:18,140][root][INFO] - Training Epoch: 1/2, step 4475/7134 completed (loss: 0.49207979440689087, acc: 0.8670212626457214)
[2024-12-17 02:02:18,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:18,438][root][INFO] - Training Epoch: 1/2, step 4476/7134 completed (loss: 0.4339164197444916, acc: 0.8736263513565063)
[2024-12-17 02:02:18,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:18,728][root][INFO] - Training Epoch: 1/2, step 4477/7134 completed (loss: 0.14790496230125427, acc: 0.954081654548645)
[2024-12-17 02:02:18,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:19,014][root][INFO] - Training Epoch: 1/2, step 4478/7134 completed (loss: 0.2995879650115967, acc: 0.9476439952850342)
[2024-12-17 02:02:19,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:19,293][root][INFO] - Training Epoch: 1/2, step 4479/7134 completed (loss: 0.2671878933906555, acc: 0.9166666865348816)
[2024-12-17 02:02:19,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:19,589][root][INFO] - Training Epoch: 1/2, step 4480/7134 completed (loss: 0.40720751881599426, acc: 0.9108911156654358)
[2024-12-17 02:02:19,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:19,896][root][INFO] - Training Epoch: 1/2, step 4481/7134 completed (loss: 0.2890159487724304, acc: 0.9449999928474426)
[2024-12-17 02:02:20,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:20,187][root][INFO] - Training Epoch: 1/2, step 4482/7134 completed (loss: 0.18983620405197144, acc: 0.9603960514068604)
[2024-12-17 02:02:20,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:20,482][root][INFO] - Training Epoch: 1/2, step 4483/7134 completed (loss: 0.40543654561042786, acc: 0.9130434989929199)
[2024-12-17 02:02:20,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:20,789][root][INFO] - Training Epoch: 1/2, step 4484/7134 completed (loss: 0.24145005643367767, acc: 0.9375)
[2024-12-17 02:02:20,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:21,086][root][INFO] - Training Epoch: 1/2, step 4485/7134 completed (loss: 0.23046822845935822, acc: 0.9281045794487)
[2024-12-17 02:02:21,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:21,364][root][INFO] - Training Epoch: 1/2, step 4486/7134 completed (loss: 0.19823220372200012, acc: 0.9503105878829956)
[2024-12-17 02:02:21,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:21,647][root][INFO] - Training Epoch: 1/2, step 4487/7134 completed (loss: 0.18838073313236237, acc: 0.9570552110671997)
[2024-12-17 02:02:21,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:21,929][root][INFO] - Training Epoch: 1/2, step 4488/7134 completed (loss: 0.2948201596736908, acc: 0.9069767594337463)
[2024-12-17 02:02:22,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:22,215][root][INFO] - Training Epoch: 1/2, step 4489/7134 completed (loss: 0.39583098888397217, acc: 0.931034505367279)
[2024-12-17 02:02:22,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:22,525][root][INFO] - Training Epoch: 1/2, step 4490/7134 completed (loss: 0.2733909487724304, acc: 0.9279999732971191)
[2024-12-17 02:02:22,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:22,825][root][INFO] - Training Epoch: 1/2, step 4491/7134 completed (loss: 0.24068328738212585, acc: 0.9312977194786072)
[2024-12-17 02:02:22,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:23,114][root][INFO] - Training Epoch: 1/2, step 4492/7134 completed (loss: 0.1917709857225418, acc: 0.9624060392379761)
[2024-12-17 02:02:23,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:23,399][root][INFO] - Training Epoch: 1/2, step 4493/7134 completed (loss: 0.2596338987350464, acc: 0.930232584476471)
[2024-12-17 02:02:23,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:23,704][root][INFO] - Training Epoch: 1/2, step 4494/7134 completed (loss: 0.22565220296382904, acc: 0.9382022619247437)
[2024-12-17 02:02:23,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:23,987][root][INFO] - Training Epoch: 1/2, step 4495/7134 completed (loss: 0.21156403422355652, acc: 0.9484536051750183)
[2024-12-17 02:02:24,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:24,271][root][INFO] - Training Epoch: 1/2, step 4496/7134 completed (loss: 0.22713789343833923, acc: 0.9473684430122375)
[2024-12-17 02:02:24,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:24,563][root][INFO] - Training Epoch: 1/2, step 4497/7134 completed (loss: 0.14165902137756348, acc: 0.9682539701461792)
[2024-12-17 02:02:24,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:24,854][root][INFO] - Training Epoch: 1/2, step 4498/7134 completed (loss: 0.21539540588855743, acc: 0.9479768872261047)
[2024-12-17 02:02:24,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:25,160][root][INFO] - Training Epoch: 1/2, step 4499/7134 completed (loss: 0.3697451651096344, acc: 0.9078013896942139)
[2024-12-17 02:02:25,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:25,471][root][INFO] - Training Epoch: 1/2, step 4500/7134 completed (loss: 0.22890302538871765, acc: 0.9358288645744324)
[2024-12-17 02:02:25,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:25,773][root][INFO] - Training Epoch: 1/2, step 4501/7134 completed (loss: 0.13699884712696075, acc: 0.9668508172035217)
[2024-12-17 02:02:25,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:26,077][root][INFO] - Training Epoch: 1/2, step 4502/7134 completed (loss: 0.14709657430648804, acc: 0.9647058844566345)
[2024-12-17 02:02:26,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:26,374][root][INFO] - Training Epoch: 1/2, step 4503/7134 completed (loss: 0.20252841711044312, acc: 0.9371069073677063)
[2024-12-17 02:02:26,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:26,667][root][INFO] - Training Epoch: 1/2, step 4504/7134 completed (loss: 0.44291725754737854, acc: 0.888198733329773)
[2024-12-17 02:02:26,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:26,955][root][INFO] - Training Epoch: 1/2, step 4505/7134 completed (loss: 0.32230278849601746, acc: 0.929729700088501)
[2024-12-17 02:02:27,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:27,236][root][INFO] - Training Epoch: 1/2, step 4506/7134 completed (loss: 0.3101434111595154, acc: 0.9202454090118408)
[2024-12-17 02:02:27,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:27,495][root][INFO] - Training Epoch: 1/2, step 4507/7134 completed (loss: 0.2321671098470688, acc: 0.9220778942108154)
[2024-12-17 02:02:27,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:27,787][root][INFO] - Training Epoch: 1/2, step 4508/7134 completed (loss: 0.3357661962509155, acc: 0.9068322777748108)
[2024-12-17 02:02:27,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:28,079][root][INFO] - Training Epoch: 1/2, step 4509/7134 completed (loss: 0.26297828555107117, acc: 0.9515151381492615)
[2024-12-17 02:02:28,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:28,360][root][INFO] - Training Epoch: 1/2, step 4510/7134 completed (loss: 0.35639986395835876, acc: 0.8928571343421936)
[2024-12-17 02:02:28,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:28,667][root][INFO] - Training Epoch: 1/2, step 4511/7134 completed (loss: 0.47267332673072815, acc: 0.9090909361839294)
[2024-12-17 02:02:28,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:28,936][root][INFO] - Training Epoch: 1/2, step 4512/7134 completed (loss: 0.6289928555488586, acc: 0.8222222328186035)
[2024-12-17 02:02:29,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:29,225][root][INFO] - Training Epoch: 1/2, step 4513/7134 completed (loss: 0.4418167173862457, acc: 0.9122806787490845)
[2024-12-17 02:02:29,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:29,517][root][INFO] - Training Epoch: 1/2, step 4514/7134 completed (loss: 0.5919238328933716, acc: 0.8612716794013977)
[2024-12-17 02:02:29,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:29,790][root][INFO] - Training Epoch: 1/2, step 4515/7134 completed (loss: 0.3824308216571808, acc: 0.8947368264198303)
[2024-12-17 02:02:29,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:30,066][root][INFO] - Training Epoch: 1/2, step 4516/7134 completed (loss: 0.3486332893371582, acc: 0.9144384860992432)
[2024-12-17 02:02:30,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:30,371][root][INFO] - Training Epoch: 1/2, step 4517/7134 completed (loss: 0.38196414709091187, acc: 0.8949999809265137)
[2024-12-17 02:02:30,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:30,664][root][INFO] - Training Epoch: 1/2, step 4518/7134 completed (loss: 0.2958276867866516, acc: 0.9226804375648499)
[2024-12-17 02:02:30,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:30,957][root][INFO] - Training Epoch: 1/2, step 4519/7134 completed (loss: 0.2069484442472458, acc: 0.9502487778663635)
[2024-12-17 02:02:31,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:31,243][root][INFO] - Training Epoch: 1/2, step 4520/7134 completed (loss: 0.3537321090698242, acc: 0.9197860956192017)
[2024-12-17 02:02:31,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:31,536][root][INFO] - Training Epoch: 1/2, step 4521/7134 completed (loss: 0.3533337414264679, acc: 0.9200000166893005)
[2024-12-17 02:02:31,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:31,823][root][INFO] - Training Epoch: 1/2, step 4522/7134 completed (loss: 0.45588916540145874, acc: 0.8767772316932678)
[2024-12-17 02:02:31,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:32,112][root][INFO] - Training Epoch: 1/2, step 4523/7134 completed (loss: 0.20289663970470428, acc: 0.9483568072319031)
[2024-12-17 02:02:32,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:32,402][root][INFO] - Training Epoch: 1/2, step 4524/7134 completed (loss: 0.3564664423465729, acc: 0.9214659929275513)
[2024-12-17 02:02:32,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:32,695][root][INFO] - Training Epoch: 1/2, step 4525/7134 completed (loss: 0.43366095423698425, acc: 0.9014778137207031)
[2024-12-17 02:02:32,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:33,004][root][INFO] - Training Epoch: 1/2, step 4526/7134 completed (loss: 0.43170586228370667, acc: 0.8846153616905212)
[2024-12-17 02:02:33,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:33,308][root][INFO] - Training Epoch: 1/2, step 4527/7134 completed (loss: 0.36574408411979675, acc: 0.9147982001304626)
[2024-12-17 02:02:33,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:33,594][root][INFO] - Training Epoch: 1/2, step 4528/7134 completed (loss: 0.5005745887756348, acc: 0.8768472671508789)
[2024-12-17 02:02:33,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:33,857][root][INFO] - Training Epoch: 1/2, step 4529/7134 completed (loss: 0.44508570432662964, acc: 0.8900523781776428)
[2024-12-17 02:02:34,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:34,149][root][INFO] - Training Epoch: 1/2, step 4530/7134 completed (loss: 0.17479920387268066, acc: 0.9451219439506531)
[2024-12-17 02:02:34,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:34,428][root][INFO] - Training Epoch: 1/2, step 4531/7134 completed (loss: 0.2117767333984375, acc: 0.9375)
[2024-12-17 02:02:34,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:34,729][root][INFO] - Training Epoch: 1/2, step 4532/7134 completed (loss: 0.39972230792045593, acc: 0.8945147395133972)
[2024-12-17 02:02:34,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:35,019][root][INFO] - Training Epoch: 1/2, step 4533/7134 completed (loss: 0.29896223545074463, acc: 0.9351851940155029)
[2024-12-17 02:02:35,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:35,311][root][INFO] - Training Epoch: 1/2, step 4534/7134 completed (loss: 0.20648381114006042, acc: 0.9390863180160522)
[2024-12-17 02:02:35,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:35,599][root][INFO] - Training Epoch: 1/2, step 4535/7134 completed (loss: 0.24490539729595184, acc: 0.942307710647583)
[2024-12-17 02:02:35,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:35,894][root][INFO] - Training Epoch: 1/2, step 4536/7134 completed (loss: 0.1620418131351471, acc: 0.9518072009086609)
[2024-12-17 02:02:36,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:36,178][root][INFO] - Training Epoch: 1/2, step 4537/7134 completed (loss: 0.13867387175559998, acc: 0.9728506803512573)
[2024-12-17 02:02:36,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:36,480][root][INFO] - Training Epoch: 1/2, step 4538/7134 completed (loss: 0.246391162276268, acc: 0.9420289993286133)
[2024-12-17 02:02:36,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:36,769][root][INFO] - Training Epoch: 1/2, step 4539/7134 completed (loss: 0.2554573118686676, acc: 0.934272289276123)
[2024-12-17 02:02:36,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:37,056][root][INFO] - Training Epoch: 1/2, step 4540/7134 completed (loss: 0.38029745221138, acc: 0.9107142686843872)
[2024-12-17 02:02:37,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:37,344][root][INFO] - Training Epoch: 1/2, step 4541/7134 completed (loss: 0.33358752727508545, acc: 0.9098360538482666)
[2024-12-17 02:02:37,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:37,640][root][INFO] - Training Epoch: 1/2, step 4542/7134 completed (loss: 0.6098337173461914, acc: 0.8245614171028137)
[2024-12-17 02:02:37,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:37,958][root][INFO] - Training Epoch: 1/2, step 4543/7134 completed (loss: 0.6814055442810059, acc: 0.8116883039474487)
[2024-12-17 02:02:38,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:38,277][root][INFO] - Training Epoch: 1/2, step 4544/7134 completed (loss: 0.38068410754203796, acc: 0.8918918967247009)
[2024-12-17 02:02:38,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:38,581][root][INFO] - Training Epoch: 1/2, step 4545/7134 completed (loss: 0.31123965978622437, acc: 0.9259259104728699)
[2024-12-17 02:02:38,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:38,874][root][INFO] - Training Epoch: 1/2, step 4546/7134 completed (loss: 0.2885963022708893, acc: 0.9527559280395508)
[2024-12-17 02:02:38,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:39,167][root][INFO] - Training Epoch: 1/2, step 4547/7134 completed (loss: 0.26178282499313354, acc: 0.9237288236618042)
[2024-12-17 02:02:39,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:39,496][root][INFO] - Training Epoch: 1/2, step 4548/7134 completed (loss: 0.33961838483810425, acc: 0.913385808467865)
[2024-12-17 02:02:39,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:39,810][root][INFO] - Training Epoch: 1/2, step 4549/7134 completed (loss: 0.563011109828949, acc: 0.859649121761322)
[2024-12-17 02:02:39,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:40,173][root][INFO] - Training Epoch: 1/2, step 4550/7134 completed (loss: 0.2909969985485077, acc: 0.9172932505607605)
[2024-12-17 02:02:40,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:40,486][root][INFO] - Training Epoch: 1/2, step 4551/7134 completed (loss: 0.41877490282058716, acc: 0.8986486196517944)
[2024-12-17 02:02:40,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:40,790][root][INFO] - Training Epoch: 1/2, step 4552/7134 completed (loss: 0.3812820017337799, acc: 0.8947368264198303)
[2024-12-17 02:02:40,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:41,096][root][INFO] - Training Epoch: 1/2, step 4553/7134 completed (loss: 0.31909099221229553, acc: 0.9166666865348816)
[2024-12-17 02:02:41,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:41,402][root][INFO] - Training Epoch: 1/2, step 4554/7134 completed (loss: 0.37586510181427, acc: 0.9270073175430298)
[2024-12-17 02:02:41,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:41,700][root][INFO] - Training Epoch: 1/2, step 4555/7134 completed (loss: 0.5758477449417114, acc: 0.8541666865348816)
[2024-12-17 02:02:41,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:41,995][root][INFO] - Training Epoch: 1/2, step 4556/7134 completed (loss: 0.5671800971031189, acc: 0.8903225660324097)
[2024-12-17 02:02:42,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:42,252][root][INFO] - Training Epoch: 1/2, step 4557/7134 completed (loss: 0.24099549651145935, acc: 0.9850746393203735)
[2024-12-17 02:02:42,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:42,545][root][INFO] - Training Epoch: 1/2, step 4558/7134 completed (loss: 0.48326748609542847, acc: 0.8992248177528381)
[2024-12-17 02:02:42,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:42,830][root][INFO] - Training Epoch: 1/2, step 4559/7134 completed (loss: 0.6215717792510986, acc: 0.8636363744735718)
[2024-12-17 02:02:42,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:43,122][root][INFO] - Training Epoch: 1/2, step 4560/7134 completed (loss: 0.34352418780326843, acc: 0.9193548560142517)
[2024-12-17 02:02:43,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:43,403][root][INFO] - Training Epoch: 1/2, step 4561/7134 completed (loss: 0.450913667678833, acc: 0.8770492076873779)
[2024-12-17 02:02:43,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:43,687][root][INFO] - Training Epoch: 1/2, step 4562/7134 completed (loss: 0.42597365379333496, acc: 0.8943089246749878)
[2024-12-17 02:02:43,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:43,986][root][INFO] - Training Epoch: 1/2, step 4563/7134 completed (loss: 0.3476511538028717, acc: 0.914893627166748)
[2024-12-17 02:02:44,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:44,279][root][INFO] - Training Epoch: 1/2, step 4564/7134 completed (loss: 0.5269908905029297, acc: 0.8831169009208679)
[2024-12-17 02:02:44,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:44,550][root][INFO] - Training Epoch: 1/2, step 4565/7134 completed (loss: 0.5426129698753357, acc: 0.8495575189590454)
[2024-12-17 02:02:44,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:44,863][root][INFO] - Training Epoch: 1/2, step 4566/7134 completed (loss: 0.40351346135139465, acc: 0.902255654335022)
[2024-12-17 02:02:44,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:45,147][root][INFO] - Training Epoch: 1/2, step 4567/7134 completed (loss: 0.18151895701885223, acc: 0.9459459185600281)
[2024-12-17 02:02:45,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:45,449][root][INFO] - Training Epoch: 1/2, step 4568/7134 completed (loss: 0.463642954826355, acc: 0.8842105269432068)
[2024-12-17 02:02:45,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:45,744][root][INFO] - Training Epoch: 1/2, step 4569/7134 completed (loss: 0.3054504096508026, acc: 0.9115044474601746)
[2024-12-17 02:02:45,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:46,044][root][INFO] - Training Epoch: 1/2, step 4570/7134 completed (loss: 0.27667438983917236, acc: 0.9545454382896423)
[2024-12-17 02:02:46,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:46,336][root][INFO] - Training Epoch: 1/2, step 4571/7134 completed (loss: 0.3020626902580261, acc: 0.9252873659133911)
[2024-12-17 02:02:46,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:46,618][root][INFO] - Training Epoch: 1/2, step 4572/7134 completed (loss: 0.32706204056739807, acc: 0.9210526347160339)
[2024-12-17 02:02:46,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:46,906][root][INFO] - Training Epoch: 1/2, step 4573/7134 completed (loss: 0.23063160479068756, acc: 0.9358974099159241)
[2024-12-17 02:02:47,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:47,184][root][INFO] - Training Epoch: 1/2, step 4574/7134 completed (loss: 0.2672574818134308, acc: 0.9318181872367859)
[2024-12-17 02:02:47,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:47,468][root][INFO] - Training Epoch: 1/2, step 4575/7134 completed (loss: 0.29937300086021423, acc: 0.9281768202781677)
[2024-12-17 02:02:47,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:47,762][root][INFO] - Training Epoch: 1/2, step 4576/7134 completed (loss: 0.21003594994544983, acc: 0.9599999785423279)
[2024-12-17 02:02:47,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:48,059][root][INFO] - Training Epoch: 1/2, step 4577/7134 completed (loss: 0.4668341875076294, acc: 0.8895348906517029)
[2024-12-17 02:02:48,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:48,344][root][INFO] - Training Epoch: 1/2, step 4578/7134 completed (loss: 0.30322501063346863, acc: 0.939393937587738)
[2024-12-17 02:02:48,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:48,622][root][INFO] - Training Epoch: 1/2, step 4579/7134 completed (loss: 0.37129682302474976, acc: 0.9240506291389465)
[2024-12-17 02:02:48,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:48,933][root][INFO] - Training Epoch: 1/2, step 4580/7134 completed (loss: 0.29477232694625854, acc: 0.9240506291389465)
[2024-12-17 02:02:49,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:49,213][root][INFO] - Training Epoch: 1/2, step 4581/7134 completed (loss: 0.13430733978748322, acc: 0.9580419659614563)
[2024-12-17 02:02:49,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:49,498][root][INFO] - Training Epoch: 1/2, step 4582/7134 completed (loss: 0.24487106502056122, acc: 0.9444444179534912)
[2024-12-17 02:02:49,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:49,768][root][INFO] - Training Epoch: 1/2, step 4583/7134 completed (loss: 0.21317355334758759, acc: 0.9399999976158142)
[2024-12-17 02:02:49,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:50,060][root][INFO] - Training Epoch: 1/2, step 4584/7134 completed (loss: 0.21692274510860443, acc: 0.9724137783050537)
[2024-12-17 02:02:50,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:50,342][root][INFO] - Training Epoch: 1/2, step 4585/7134 completed (loss: 0.2504822313785553, acc: 0.9615384340286255)
[2024-12-17 02:02:50,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:50,631][root][INFO] - Training Epoch: 1/2, step 4586/7134 completed (loss: 0.266581267118454, acc: 0.9349112510681152)
[2024-12-17 02:02:50,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:50,921][root][INFO] - Training Epoch: 1/2, step 4587/7134 completed (loss: 0.3893372416496277, acc: 0.9186046719551086)
[2024-12-17 02:02:51,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:51,217][root][INFO] - Training Epoch: 1/2, step 4588/7134 completed (loss: 0.32334572076797485, acc: 0.9375)
[2024-12-17 02:02:51,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:51,491][root][INFO] - Training Epoch: 1/2, step 4589/7134 completed (loss: 0.3074600100517273, acc: 0.9367815852165222)
[2024-12-17 02:02:51,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:51,777][root][INFO] - Training Epoch: 1/2, step 4590/7134 completed (loss: 0.38422852754592896, acc: 0.8928571343421936)
[2024-12-17 02:02:51,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:52,062][root][INFO] - Training Epoch: 1/2, step 4591/7134 completed (loss: 0.3055586516857147, acc: 0.9204545617103577)
[2024-12-17 02:02:52,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:52,371][root][INFO] - Training Epoch: 1/2, step 4592/7134 completed (loss: 0.28621336817741394, acc: 0.9207317233085632)
[2024-12-17 02:02:52,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:52,657][root][INFO] - Training Epoch: 1/2, step 4593/7134 completed (loss: 0.4709298014640808, acc: 0.8421052694320679)
[2024-12-17 02:02:52,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:52,960][root][INFO] - Training Epoch: 1/2, step 4594/7134 completed (loss: 0.5266568064689636, acc: 0.8624338507652283)
[2024-12-17 02:02:53,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:53,249][root][INFO] - Training Epoch: 1/2, step 4595/7134 completed (loss: 0.30868157744407654, acc: 0.892405092716217)
[2024-12-17 02:02:53,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:53,521][root][INFO] - Training Epoch: 1/2, step 4596/7134 completed (loss: 0.3440759778022766, acc: 0.90625)
[2024-12-17 02:02:53,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:53,795][root][INFO] - Training Epoch: 1/2, step 4597/7134 completed (loss: 0.30935826897621155, acc: 0.9333333373069763)
[2024-12-17 02:02:53,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:54,082][root][INFO] - Training Epoch: 1/2, step 4598/7134 completed (loss: 0.5369300842285156, acc: 0.8810811042785645)
[2024-12-17 02:02:54,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:54,359][root][INFO] - Training Epoch: 1/2, step 4599/7134 completed (loss: 0.21137870848178864, acc: 0.9275362491607666)
[2024-12-17 02:02:54,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:54,641][root][INFO] - Training Epoch: 1/2, step 4600/7134 completed (loss: 0.3139875829219818, acc: 0.9245283007621765)
[2024-12-17 02:02:54,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:54,941][root][INFO] - Training Epoch: 1/2, step 4601/7134 completed (loss: 0.2238471508026123, acc: 0.9378530979156494)
[2024-12-17 02:02:55,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:55,239][root][INFO] - Training Epoch: 1/2, step 4602/7134 completed (loss: 0.44366973638534546, acc: 0.894444465637207)
[2024-12-17 02:02:55,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:55,526][root][INFO] - Training Epoch: 1/2, step 4603/7134 completed (loss: 0.2967739403247833, acc: 0.930232584476471)
[2024-12-17 02:02:55,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:55,823][root][INFO] - Training Epoch: 1/2, step 4604/7134 completed (loss: 0.3177497386932373, acc: 0.9230769276618958)
[2024-12-17 02:02:55,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:56,099][root][INFO] - Training Epoch: 1/2, step 4605/7134 completed (loss: 0.29130563139915466, acc: 0.9090909361839294)
[2024-12-17 02:02:56,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:56,385][root][INFO] - Training Epoch: 1/2, step 4606/7134 completed (loss: 0.17511224746704102, acc: 0.9622641801834106)
[2024-12-17 02:02:56,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:56,684][root][INFO] - Training Epoch: 1/2, step 4607/7134 completed (loss: 0.31982937455177307, acc: 0.9432623982429504)
[2024-12-17 02:02:56,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:56,971][root][INFO] - Training Epoch: 1/2, step 4608/7134 completed (loss: 0.23224209249019623, acc: 0.9473684430122375)
[2024-12-17 02:02:57,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:57,276][root][INFO] - Training Epoch: 1/2, step 4609/7134 completed (loss: 0.31451231241226196, acc: 0.9160305261611938)
[2024-12-17 02:02:57,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:57,562][root][INFO] - Training Epoch: 1/2, step 4610/7134 completed (loss: 0.17049098014831543, acc: 0.9497206807136536)
[2024-12-17 02:02:57,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:57,847][root][INFO] - Training Epoch: 1/2, step 4611/7134 completed (loss: 0.16389797627925873, acc: 0.9379310607910156)
[2024-12-17 02:02:57,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:58,132][root][INFO] - Training Epoch: 1/2, step 4612/7134 completed (loss: 0.24545051157474518, acc: 0.9407407641410828)
[2024-12-17 02:02:58,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:58,407][root][INFO] - Training Epoch: 1/2, step 4613/7134 completed (loss: 0.15329007804393768, acc: 0.9691358208656311)
[2024-12-17 02:02:58,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:58,676][root][INFO] - Training Epoch: 1/2, step 4614/7134 completed (loss: 0.2796919047832489, acc: 0.9461538195610046)
[2024-12-17 02:02:58,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:58,963][root][INFO] - Training Epoch: 1/2, step 4615/7134 completed (loss: 0.3998565673828125, acc: 0.8922155499458313)
[2024-12-17 02:02:59,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:59,257][root][INFO] - Training Epoch: 1/2, step 4616/7134 completed (loss: 0.4560759365558624, acc: 0.8779069781303406)
[2024-12-17 02:02:59,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:59,524][root][INFO] - Training Epoch: 1/2, step 4617/7134 completed (loss: 0.5825129747390747, acc: 0.8922155499458313)
[2024-12-17 02:02:59,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:59,822][root][INFO] - Training Epoch: 1/2, step 4618/7134 completed (loss: 0.5363070964813232, acc: 0.8604651093482971)
[2024-12-17 02:02:59,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:00,104][root][INFO] - Training Epoch: 1/2, step 4619/7134 completed (loss: 0.41925615072250366, acc: 0.9125000238418579)
[2024-12-17 02:03:00,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:00,405][root][INFO] - Training Epoch: 1/2, step 4620/7134 completed (loss: 0.1542344093322754, acc: 0.9588235020637512)
[2024-12-17 02:03:00,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:00,726][root][INFO] - Training Epoch: 1/2, step 4621/7134 completed (loss: 0.2419901192188263, acc: 0.9451219439506531)
[2024-12-17 02:03:00,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:01,000][root][INFO] - Training Epoch: 1/2, step 4622/7134 completed (loss: 0.333784818649292, acc: 0.9222221970558167)
[2024-12-17 02:03:01,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:01,272][root][INFO] - Training Epoch: 1/2, step 4623/7134 completed (loss: 0.4328452944755554, acc: 0.8999999761581421)
[2024-12-17 02:03:01,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:01,607][root][INFO] - Training Epoch: 1/2, step 4624/7134 completed (loss: 0.47005364298820496, acc: 0.8588235378265381)
[2024-12-17 02:03:01,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:01,884][root][INFO] - Training Epoch: 1/2, step 4625/7134 completed (loss: 0.8184919953346252, acc: 0.8159509301185608)
[2024-12-17 02:03:02,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:02,201][root][INFO] - Training Epoch: 1/2, step 4626/7134 completed (loss: 0.6213439702987671, acc: 0.8586956262588501)
[2024-12-17 02:03:02,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:02,482][root][INFO] - Training Epoch: 1/2, step 4627/7134 completed (loss: 0.5158865451812744, acc: 0.8903225660324097)
[2024-12-17 02:03:02,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:02,771][root][INFO] - Training Epoch: 1/2, step 4628/7134 completed (loss: 0.399253249168396, acc: 0.9085366129875183)
[2024-12-17 02:03:02,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:03,044][root][INFO] - Training Epoch: 1/2, step 4629/7134 completed (loss: 0.3858870565891266, acc: 0.9025974273681641)
[2024-12-17 02:03:03,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:03,331][root][INFO] - Training Epoch: 1/2, step 4630/7134 completed (loss: 0.21614238619804382, acc: 0.9555555582046509)
[2024-12-17 02:03:03,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:03,627][root][INFO] - Training Epoch: 1/2, step 4631/7134 completed (loss: 0.4110991954803467, acc: 0.9209302067756653)
[2024-12-17 02:03:03,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:03,933][root][INFO] - Training Epoch: 1/2, step 4632/7134 completed (loss: 0.3925895690917969, acc: 0.9156626462936401)
[2024-12-17 02:03:04,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:04,207][root][INFO] - Training Epoch: 1/2, step 4633/7134 completed (loss: 0.5384801626205444, acc: 0.8675799369812012)
[2024-12-17 02:03:04,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:04,499][root][INFO] - Training Epoch: 1/2, step 4634/7134 completed (loss: 0.37168946862220764, acc: 0.9259259104728699)
[2024-12-17 02:03:04,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:04,766][root][INFO] - Training Epoch: 1/2, step 4635/7134 completed (loss: 0.49212735891342163, acc: 0.9146341681480408)
[2024-12-17 02:03:04,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:05,009][root][INFO] - Training Epoch: 1/2, step 4636/7134 completed (loss: 0.19216839969158173, acc: 0.957446813583374)
[2024-12-17 02:03:05,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:05,301][root][INFO] - Training Epoch: 1/2, step 4637/7134 completed (loss: 0.34463369846343994, acc: 0.920634925365448)
[2024-12-17 02:03:05,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:05,581][root][INFO] - Training Epoch: 1/2, step 4638/7134 completed (loss: 0.625204861164093, acc: 0.884393036365509)
[2024-12-17 02:03:05,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:05,858][root][INFO] - Training Epoch: 1/2, step 4639/7134 completed (loss: 0.31266579031944275, acc: 0.9351351261138916)
[2024-12-17 02:03:05,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:06,149][root][INFO] - Training Epoch: 1/2, step 4640/7134 completed (loss: 0.39097079634666443, acc: 0.9100528955459595)
[2024-12-17 02:03:06,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:06,424][root][INFO] - Training Epoch: 1/2, step 4641/7134 completed (loss: 0.44567856192588806, acc: 0.8888888955116272)
[2024-12-17 02:03:06,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:06,702][root][INFO] - Training Epoch: 1/2, step 4642/7134 completed (loss: 0.2913552224636078, acc: 0.9209039807319641)
[2024-12-17 02:03:06,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:07,003][root][INFO] - Training Epoch: 1/2, step 4643/7134 completed (loss: 0.2182682454586029, acc: 0.9317073225975037)
[2024-12-17 02:03:07,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:07,295][root][INFO] - Training Epoch: 1/2, step 4644/7134 completed (loss: 0.2835575044155121, acc: 0.935960590839386)
[2024-12-17 02:03:07,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:07,585][root][INFO] - Training Epoch: 1/2, step 4645/7134 completed (loss: 0.1822398602962494, acc: 0.9451219439506531)
[2024-12-17 02:03:07,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:07,868][root][INFO] - Training Epoch: 1/2, step 4646/7134 completed (loss: 0.41093236207962036, acc: 0.9142857193946838)
[2024-12-17 02:03:07,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:08,156][root][INFO] - Training Epoch: 1/2, step 4647/7134 completed (loss: 0.3797069191932678, acc: 0.9071038365364075)
[2024-12-17 02:03:08,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:08,429][root][INFO] - Training Epoch: 1/2, step 4648/7134 completed (loss: 0.3460856080055237, acc: 0.9044585824012756)
[2024-12-17 02:03:08,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:08,709][root][INFO] - Training Epoch: 1/2, step 4649/7134 completed (loss: 0.36086219549179077, acc: 0.9186992049217224)
[2024-12-17 02:03:08,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:09,034][root][INFO] - Training Epoch: 1/2, step 4650/7134 completed (loss: 0.41229572892189026, acc: 0.8851351141929626)
[2024-12-17 02:03:09,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:09,320][root][INFO] - Training Epoch: 1/2, step 4651/7134 completed (loss: 0.6067755818367004, acc: 0.8826815485954285)
[2024-12-17 02:03:09,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:09,626][root][INFO] - Training Epoch: 1/2, step 4652/7134 completed (loss: 0.2601466774940491, acc: 0.9382715821266174)
[2024-12-17 02:03:09,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:09,949][root][INFO] - Training Epoch: 1/2, step 4653/7134 completed (loss: 0.32281067967414856, acc: 0.9227052927017212)
[2024-12-17 02:03:10,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:10,261][root][INFO] - Training Epoch: 1/2, step 4654/7134 completed (loss: 0.5247325897216797, acc: 0.8972973227500916)
[2024-12-17 02:03:10,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:10,599][root][INFO] - Training Epoch: 1/2, step 4655/7134 completed (loss: 0.423542320728302, acc: 0.9200000166893005)
[2024-12-17 02:03:10,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:10,920][root][INFO] - Training Epoch: 1/2, step 4656/7134 completed (loss: 0.4530026316642761, acc: 0.8813559412956238)
[2024-12-17 02:03:11,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:11,197][root][INFO] - Training Epoch: 1/2, step 4657/7134 completed (loss: 0.36622384190559387, acc: 0.9022988677024841)
[2024-12-17 02:03:11,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:11,470][root][INFO] - Training Epoch: 1/2, step 4658/7134 completed (loss: 0.4025726318359375, acc: 0.8977272510528564)
[2024-12-17 02:03:11,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:11,763][root][INFO] - Training Epoch: 1/2, step 4659/7134 completed (loss: 0.3813752233982086, acc: 0.8941798806190491)
[2024-12-17 02:03:11,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:12,061][root][INFO] - Training Epoch: 1/2, step 4660/7134 completed (loss: 0.5264147520065308, acc: 0.8717948794364929)
[2024-12-17 02:03:12,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:12,342][root][INFO] - Training Epoch: 1/2, step 4661/7134 completed (loss: 0.4520939886569977, acc: 0.9141104221343994)
[2024-12-17 02:03:12,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:12,627][root][INFO] - Training Epoch: 1/2, step 4662/7134 completed (loss: 0.7610470056533813, acc: 0.8368794322013855)
[2024-12-17 02:03:12,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:12,918][root][INFO] - Training Epoch: 1/2, step 4663/7134 completed (loss: 0.39737263321876526, acc: 0.8961748480796814)
[2024-12-17 02:03:13,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:13,208][root][INFO] - Training Epoch: 1/2, step 4664/7134 completed (loss: 0.33704379200935364, acc: 0.9189189076423645)
[2024-12-17 02:03:13,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:13,509][root][INFO] - Training Epoch: 1/2, step 4665/7134 completed (loss: 0.2863950729370117, acc: 0.9120879173278809)
[2024-12-17 02:03:13,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:13,822][root][INFO] - Training Epoch: 1/2, step 4666/7134 completed (loss: 0.5584951639175415, acc: 0.8601036071777344)
[2024-12-17 02:03:13,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:14,090][root][INFO] - Training Epoch: 1/2, step 4667/7134 completed (loss: 0.4596560299396515, acc: 0.9054054021835327)
[2024-12-17 02:03:14,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:14,376][root][INFO] - Training Epoch: 1/2, step 4668/7134 completed (loss: 0.29800713062286377, acc: 0.9127516746520996)
[2024-12-17 02:03:14,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:14,668][root][INFO] - Training Epoch: 1/2, step 4669/7134 completed (loss: 0.444086492061615, acc: 0.909604549407959)
[2024-12-17 02:03:14,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:14,941][root][INFO] - Training Epoch: 1/2, step 4670/7134 completed (loss: 0.35222187638282776, acc: 0.9104477763175964)
[2024-12-17 02:03:15,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:15,219][root][INFO] - Training Epoch: 1/2, step 4671/7134 completed (loss: 0.26622000336647034, acc: 0.9508196711540222)
[2024-12-17 02:03:15,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:15,497][root][INFO] - Training Epoch: 1/2, step 4672/7134 completed (loss: 0.4279487431049347, acc: 0.8965517282485962)
[2024-12-17 02:03:15,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:15,774][root][INFO] - Training Epoch: 1/2, step 4673/7134 completed (loss: 0.2933688759803772, acc: 0.9182389974594116)
[2024-12-17 02:03:15,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:16,048][root][INFO] - Training Epoch: 1/2, step 4674/7134 completed (loss: 0.2324095070362091, acc: 0.9415584206581116)
[2024-12-17 02:03:16,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:16,354][root][INFO] - Training Epoch: 1/2, step 4675/7134 completed (loss: 0.3069998621940613, acc: 0.928205132484436)
[2024-12-17 02:03:16,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:16,638][root][INFO] - Training Epoch: 1/2, step 4676/7134 completed (loss: 0.2950893044471741, acc: 0.9350649118423462)
[2024-12-17 02:03:16,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:16,919][root][INFO] - Training Epoch: 1/2, step 4677/7134 completed (loss: 0.30982205271720886, acc: 0.9411764740943909)
[2024-12-17 02:03:17,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:17,200][root][INFO] - Training Epoch: 1/2, step 4678/7134 completed (loss: 0.4081864356994629, acc: 0.910179615020752)
[2024-12-17 02:03:17,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:17,500][root][INFO] - Training Epoch: 1/2, step 4679/7134 completed (loss: 0.2957807183265686, acc: 0.9421965479850769)
[2024-12-17 02:03:17,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:17,793][root][INFO] - Training Epoch: 1/2, step 4680/7134 completed (loss: 0.32694268226623535, acc: 0.9272727370262146)
[2024-12-17 02:03:17,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:18,074][root][INFO] - Training Epoch: 1/2, step 4681/7134 completed (loss: 0.3610577881336212, acc: 0.9090909361839294)
[2024-12-17 02:03:18,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:18,364][root][INFO] - Training Epoch: 1/2, step 4682/7134 completed (loss: 0.2953828275203705, acc: 0.9116021990776062)
[2024-12-17 02:03:18,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:18,618][root][INFO] - Training Epoch: 1/2, step 4683/7134 completed (loss: 0.4409894347190857, acc: 0.8999999761581421)
[2024-12-17 02:03:18,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:18,898][root][INFO] - Training Epoch: 1/2, step 4684/7134 completed (loss: 0.5190192461013794, acc: 0.8711340427398682)
[2024-12-17 02:03:19,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:19,185][root][INFO] - Training Epoch: 1/2, step 4685/7134 completed (loss: 0.3176076412200928, acc: 0.9014778137207031)
[2024-12-17 02:03:19,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:19,475][root][INFO] - Training Epoch: 1/2, step 4686/7134 completed (loss: 0.3914494216442108, acc: 0.8994709253311157)
[2024-12-17 02:03:19,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:19,778][root][INFO] - Training Epoch: 1/2, step 4687/7134 completed (loss: 1.0411045551300049, acc: 0.739130437374115)
[2024-12-17 02:03:19,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:20,061][root][INFO] - Training Epoch: 1/2, step 4688/7134 completed (loss: 1.128777027130127, acc: 0.78125)
[2024-12-17 02:03:20,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:20,359][root][INFO] - Training Epoch: 1/2, step 4689/7134 completed (loss: 0.7164743542671204, acc: 0.8505747318267822)
[2024-12-17 02:03:20,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:20,670][root][INFO] - Training Epoch: 1/2, step 4690/7134 completed (loss: 0.7257004976272583, acc: 0.9122806787490845)
[2024-12-17 02:03:20,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:20,944][root][INFO] - Training Epoch: 1/2, step 4691/7134 completed (loss: 0.3684558868408203, acc: 0.9076923131942749)
[2024-12-17 02:03:21,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:21,192][root][INFO] - Training Epoch: 1/2, step 4692/7134 completed (loss: 1.121484637260437, acc: 0.7698412537574768)
[2024-12-17 02:03:21,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:21,502][root][INFO] - Training Epoch: 1/2, step 4693/7134 completed (loss: 1.2290555238723755, acc: 0.7599999904632568)
[2024-12-17 02:03:21,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:21,762][root][INFO] - Training Epoch: 1/2, step 4694/7134 completed (loss: 0.9761684536933899, acc: 0.817460298538208)
[2024-12-17 02:03:21,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:22,055][root][INFO] - Training Epoch: 1/2, step 4695/7134 completed (loss: 0.7043522596359253, acc: 0.8799999952316284)
[2024-12-17 02:03:22,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:22,348][root][INFO] - Training Epoch: 1/2, step 4696/7134 completed (loss: 0.29334756731987, acc: 0.9333333373069763)
[2024-12-17 02:03:22,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:22,624][root][INFO] - Training Epoch: 1/2, step 4697/7134 completed (loss: 0.2431110292673111, acc: 0.9523809552192688)
[2024-12-17 02:03:22,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:22,888][root][INFO] - Training Epoch: 1/2, step 4698/7134 completed (loss: 0.8385197520256042, acc: 0.7785714268684387)
[2024-12-17 02:03:23,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:23,170][root][INFO] - Training Epoch: 1/2, step 4699/7134 completed (loss: 0.666350781917572, acc: 0.8273381590843201)
[2024-12-17 02:03:23,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:23,455][root][INFO] - Training Epoch: 1/2, step 4700/7134 completed (loss: 0.6734557151794434, acc: 0.857988178730011)
[2024-12-17 02:03:23,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:23,743][root][INFO] - Training Epoch: 1/2, step 4701/7134 completed (loss: 1.1264598369598389, acc: 0.7749999761581421)
[2024-12-17 02:03:23,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:24,062][root][INFO] - Training Epoch: 1/2, step 4702/7134 completed (loss: 0.45676711201667786, acc: 0.8709677457809448)
[2024-12-17 02:03:24,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:24,373][root][INFO] - Training Epoch: 1/2, step 4703/7134 completed (loss: 0.27063602209091187, acc: 0.9235293865203857)
[2024-12-17 02:03:24,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:24,677][root][INFO] - Training Epoch: 1/2, step 4704/7134 completed (loss: 0.270528107881546, acc: 0.9384615421295166)
[2024-12-17 02:03:24,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:24,978][root][INFO] - Training Epoch: 1/2, step 4705/7134 completed (loss: 0.5042385458946228, acc: 0.871921181678772)
[2024-12-17 02:03:25,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:25,270][root][INFO] - Training Epoch: 1/2, step 4706/7134 completed (loss: 0.5592115521430969, acc: 0.8910256624221802)
[2024-12-17 02:03:25,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:25,542][root][INFO] - Training Epoch: 1/2, step 4707/7134 completed (loss: 1.1133472919464111, acc: 0.7987421154975891)
[2024-12-17 02:03:25,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:25,823][root][INFO] - Training Epoch: 1/2, step 4708/7134 completed (loss: 0.3716924488544464, acc: 0.9246231317520142)
[2024-12-17 02:03:25,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:26,116][root][INFO] - Training Epoch: 1/2, step 4709/7134 completed (loss: 0.25860103964805603, acc: 0.929729700088501)
[2024-12-17 02:03:26,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:26,392][root][INFO] - Training Epoch: 1/2, step 4710/7134 completed (loss: 0.3764871060848236, acc: 0.8909090757369995)
[2024-12-17 02:03:26,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:26,689][root][INFO] - Training Epoch: 1/2, step 4711/7134 completed (loss: 0.4213830530643463, acc: 0.912162184715271)
[2024-12-17 02:03:26,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:26,963][root][INFO] - Training Epoch: 1/2, step 4712/7134 completed (loss: 0.7735111117362976, acc: 0.843137264251709)
[2024-12-17 02:03:27,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:27,240][root][INFO] - Training Epoch: 1/2, step 4713/7134 completed (loss: 0.27674660086631775, acc: 0.9253731369972229)
[2024-12-17 02:03:27,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:27,496][root][INFO] - Training Epoch: 1/2, step 4714/7134 completed (loss: 0.5350276231765747, acc: 0.8931297659873962)
[2024-12-17 02:03:27,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:27,773][root][INFO] - Training Epoch: 1/2, step 4715/7134 completed (loss: 0.7608091831207275, acc: 0.8666666746139526)
[2024-12-17 02:03:27,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:28,091][root][INFO] - Training Epoch: 1/2, step 4716/7134 completed (loss: 0.23513484001159668, acc: 0.9419354796409607)
[2024-12-17 02:03:28,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:28,369][root][INFO] - Training Epoch: 1/2, step 4717/7134 completed (loss: 0.3290537893772125, acc: 0.9333333373069763)
[2024-12-17 02:03:28,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:28,647][root][INFO] - Training Epoch: 1/2, step 4718/7134 completed (loss: 0.2194506675004959, acc: 0.9424460530281067)
[2024-12-17 02:03:28,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:28,925][root][INFO] - Training Epoch: 1/2, step 4719/7134 completed (loss: 0.20771096646785736, acc: 0.9526627063751221)
[2024-12-17 02:03:29,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:29,227][root][INFO] - Training Epoch: 1/2, step 4720/7134 completed (loss: 0.16012941300868988, acc: 0.9624999761581421)
[2024-12-17 02:03:29,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:29,534][root][INFO] - Training Epoch: 1/2, step 4721/7134 completed (loss: 0.09838690608739853, acc: 0.9876543283462524)
[2024-12-17 02:03:29,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:29,847][root][INFO] - Training Epoch: 1/2, step 4722/7134 completed (loss: 0.30592080950737, acc: 0.9245283007621765)
[2024-12-17 02:03:29,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:30,134][root][INFO] - Training Epoch: 1/2, step 4723/7134 completed (loss: 0.2982235550880432, acc: 0.9363057613372803)
[2024-12-17 02:03:30,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:30,428][root][INFO] - Training Epoch: 1/2, step 4724/7134 completed (loss: 0.28726673126220703, acc: 0.9207317233085632)
[2024-12-17 02:03:30,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:30,699][root][INFO] - Training Epoch: 1/2, step 4725/7134 completed (loss: 0.4794918894767761, acc: 0.8837209343910217)
[2024-12-17 02:03:30,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:31,024][root][INFO] - Training Epoch: 1/2, step 4726/7134 completed (loss: 0.6995271444320679, acc: 0.8448275923728943)
[2024-12-17 02:03:31,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:31,301][root][INFO] - Training Epoch: 1/2, step 4727/7134 completed (loss: 0.3163565695285797, acc: 0.9271523356437683)
[2024-12-17 02:03:31,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:31,581][root][INFO] - Training Epoch: 1/2, step 4728/7134 completed (loss: 0.4702534079551697, acc: 0.9072847962379456)
[2024-12-17 02:03:31,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:31,853][root][INFO] - Training Epoch: 1/2, step 4729/7134 completed (loss: 0.19031526148319244, acc: 0.9421965479850769)
[2024-12-17 02:03:31,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:32,138][root][INFO] - Training Epoch: 1/2, step 4730/7134 completed (loss: 0.3456047773361206, acc: 0.9356725215911865)
[2024-12-17 02:03:32,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:32,422][root][INFO] - Training Epoch: 1/2, step 4731/7134 completed (loss: 0.4728729724884033, acc: 0.882758617401123)
[2024-12-17 02:03:32,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:32,725][root][INFO] - Training Epoch: 1/2, step 4732/7134 completed (loss: 0.35963574051856995, acc: 0.904411792755127)
[2024-12-17 02:03:32,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:33,000][root][INFO] - Training Epoch: 1/2, step 4733/7134 completed (loss: 0.44268372654914856, acc: 0.9347826242446899)
[2024-12-17 02:03:33,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:33,279][root][INFO] - Training Epoch: 1/2, step 4734/7134 completed (loss: 0.6627985835075378, acc: 0.8867924809455872)
[2024-12-17 02:03:33,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:33,569][root][INFO] - Training Epoch: 1/2, step 4735/7134 completed (loss: 0.34916719794273376, acc: 0.9308176040649414)
[2024-12-17 02:03:33,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:33,872][root][INFO] - Training Epoch: 1/2, step 4736/7134 completed (loss: 0.5828220844268799, acc: 0.8833333253860474)
[2024-12-17 02:03:34,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:34,183][root][INFO] - Training Epoch: 1/2, step 4737/7134 completed (loss: 0.38018903136253357, acc: 0.9241379499435425)
[2024-12-17 02:03:34,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:34,490][root][INFO] - Training Epoch: 1/2, step 4738/7134 completed (loss: 0.4652453362941742, acc: 0.875)
[2024-12-17 02:03:34,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:34,768][root][INFO] - Training Epoch: 1/2, step 4739/7134 completed (loss: 0.6137365102767944, acc: 0.8539325594902039)
[2024-12-17 02:03:34,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:35,061][root][INFO] - Training Epoch: 1/2, step 4740/7134 completed (loss: 0.5968544483184814, acc: 0.8833333253860474)
[2024-12-17 02:03:35,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:35,360][root][INFO] - Training Epoch: 1/2, step 4741/7134 completed (loss: 0.4025877118110657, acc: 0.9071428775787354)
[2024-12-17 02:03:35,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:35,636][root][INFO] - Training Epoch: 1/2, step 4742/7134 completed (loss: 0.8281676173210144, acc: 0.8181818127632141)
[2024-12-17 02:03:35,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:35,929][root][INFO] - Training Epoch: 1/2, step 4743/7134 completed (loss: 0.473702073097229, acc: 0.8618420958518982)
[2024-12-17 02:03:36,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:36,244][root][INFO] - Training Epoch: 1/2, step 4744/7134 completed (loss: 0.33062559366226196, acc: 0.9266055226325989)
[2024-12-17 02:03:36,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:36,505][root][INFO] - Training Epoch: 1/2, step 4745/7134 completed (loss: 0.6192352771759033, acc: 0.9305555820465088)
[2024-12-17 02:03:36,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:36,790][root][INFO] - Training Epoch: 1/2, step 4746/7134 completed (loss: 0.23294121026992798, acc: 0.9457364082336426)
[2024-12-17 02:03:36,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:37,079][root][INFO] - Training Epoch: 1/2, step 4747/7134 completed (loss: 0.3331904411315918, acc: 0.9127907156944275)
[2024-12-17 02:03:37,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:37,356][root][INFO] - Training Epoch: 1/2, step 4748/7134 completed (loss: 0.5642394423484802, acc: 0.8284023404121399)
[2024-12-17 02:03:37,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:37,634][root][INFO] - Training Epoch: 1/2, step 4749/7134 completed (loss: 0.3032247722148895, acc: 0.9186046719551086)
[2024-12-17 02:03:37,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:37,908][root][INFO] - Training Epoch: 1/2, step 4750/7134 completed (loss: 0.3725563585758209, acc: 0.9186992049217224)
[2024-12-17 02:03:38,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:38,196][root][INFO] - Training Epoch: 1/2, step 4751/7134 completed (loss: 0.2322392761707306, acc: 0.9390243887901306)
[2024-12-17 02:03:38,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:38,486][root][INFO] - Training Epoch: 1/2, step 4752/7134 completed (loss: 0.39304494857788086, acc: 0.9316770434379578)
[2024-12-17 02:03:38,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:38,773][root][INFO] - Training Epoch: 1/2, step 4753/7134 completed (loss: 0.4509187936782837, acc: 0.8875739574432373)
[2024-12-17 02:03:38,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:39,081][root][INFO] - Training Epoch: 1/2, step 4754/7134 completed (loss: 0.1600353717803955, acc: 0.9675324559211731)
[2024-12-17 02:03:39,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:39,372][root][INFO] - Training Epoch: 1/2, step 4755/7134 completed (loss: 0.40806567668914795, acc: 0.906593382358551)
[2024-12-17 02:03:39,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:39,665][root][INFO] - Training Epoch: 1/2, step 4756/7134 completed (loss: 0.5666056275367737, acc: 0.8790322542190552)
[2024-12-17 02:03:39,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:39,967][root][INFO] - Training Epoch: 1/2, step 4757/7134 completed (loss: 0.22540856897830963, acc: 0.9549999833106995)
[2024-12-17 02:03:40,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:40,254][root][INFO] - Training Epoch: 1/2, step 4758/7134 completed (loss: 0.3082578182220459, acc: 0.9337016344070435)
[2024-12-17 02:03:40,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:40,554][root][INFO] - Training Epoch: 1/2, step 4759/7134 completed (loss: 0.14658024907112122, acc: 0.9503546357154846)
[2024-12-17 02:03:40,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:40,823][root][INFO] - Training Epoch: 1/2, step 4760/7134 completed (loss: 0.4115353524684906, acc: 0.8823529481887817)
[2024-12-17 02:03:40,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:41,112][root][INFO] - Training Epoch: 1/2, step 4761/7134 completed (loss: 0.2849276661872864, acc: 0.9512194991111755)
[2024-12-17 02:03:41,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:41,396][root][INFO] - Training Epoch: 1/2, step 4762/7134 completed (loss: 0.40916144847869873, acc: 0.9230769276618958)
[2024-12-17 02:03:41,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:41,669][root][INFO] - Training Epoch: 1/2, step 4763/7134 completed (loss: 0.2527291774749756, acc: 0.9337748289108276)
[2024-12-17 02:03:41,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:41,965][root][INFO] - Training Epoch: 1/2, step 4764/7134 completed (loss: 0.37780025601387024, acc: 0.9175257682800293)
[2024-12-17 02:03:42,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:42,264][root][INFO] - Training Epoch: 1/2, step 4765/7134 completed (loss: 0.547877311706543, acc: 0.8799999952316284)
[2024-12-17 02:03:42,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:42,548][root][INFO] - Training Epoch: 1/2, step 4766/7134 completed (loss: 0.32820382714271545, acc: 0.9222221970558167)
[2024-12-17 02:03:42,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:42,826][root][INFO] - Training Epoch: 1/2, step 4767/7134 completed (loss: 0.261771559715271, acc: 0.9387755393981934)
[2024-12-17 02:03:42,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:43,143][root][INFO] - Training Epoch: 1/2, step 4768/7134 completed (loss: 0.2355296015739441, acc: 0.9411764740943909)
[2024-12-17 02:03:43,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:43,440][root][INFO] - Training Epoch: 1/2, step 4769/7134 completed (loss: 0.3349303901195526, acc: 0.9144737124443054)
[2024-12-17 02:03:43,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:43,728][root][INFO] - Training Epoch: 1/2, step 4770/7134 completed (loss: 0.20984399318695068, acc: 0.9520000219345093)
[2024-12-17 02:03:43,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:44,021][root][INFO] - Training Epoch: 1/2, step 4771/7134 completed (loss: 0.46232959628105164, acc: 0.8773006200790405)
[2024-12-17 02:03:44,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:44,297][root][INFO] - Training Epoch: 1/2, step 4772/7134 completed (loss: 0.4782012403011322, acc: 0.8774193525314331)
[2024-12-17 02:03:44,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:44,574][root][INFO] - Training Epoch: 1/2, step 4773/7134 completed (loss: 0.2687622606754303, acc: 0.9230769276618958)
[2024-12-17 02:03:44,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:44,848][root][INFO] - Training Epoch: 1/2, step 4774/7134 completed (loss: 0.2911600172519684, acc: 0.9349112510681152)
[2024-12-17 02:03:44,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:45,122][root][INFO] - Training Epoch: 1/2, step 4775/7134 completed (loss: 0.3179027736186981, acc: 0.9308176040649414)
[2024-12-17 02:03:45,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:45,418][root][INFO] - Training Epoch: 1/2, step 4776/7134 completed (loss: 0.5425207018852234, acc: 0.8591549396514893)
[2024-12-17 02:03:45,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:45,738][root][INFO] - Training Epoch: 1/2, step 4777/7134 completed (loss: 0.4248895049095154, acc: 0.9041095972061157)
[2024-12-17 02:03:45,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:46,044][root][INFO] - Training Epoch: 1/2, step 4778/7134 completed (loss: 0.21879324316978455, acc: 0.9285714030265808)
[2024-12-17 02:03:46,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:46,335][root][INFO] - Training Epoch: 1/2, step 4779/7134 completed (loss: 0.3992268741130829, acc: 0.9111111164093018)
[2024-12-17 02:03:46,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:46,651][root][INFO] - Training Epoch: 1/2, step 4780/7134 completed (loss: 0.23238742351531982, acc: 0.9358974099159241)
[2024-12-17 02:03:46,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:46,954][root][INFO] - Training Epoch: 1/2, step 4781/7134 completed (loss: 0.3461003601551056, acc: 0.9112903475761414)
[2024-12-17 02:03:47,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:47,263][root][INFO] - Training Epoch: 1/2, step 4782/7134 completed (loss: 0.23268699645996094, acc: 0.956250011920929)
[2024-12-17 02:03:47,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:47,561][root][INFO] - Training Epoch: 1/2, step 4783/7134 completed (loss: 0.555578351020813, acc: 0.8913043737411499)
[2024-12-17 02:03:47,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:47,881][root][INFO] - Training Epoch: 1/2, step 4784/7134 completed (loss: 0.27206146717071533, acc: 0.9444444179534912)
[2024-12-17 02:03:48,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:48,187][root][INFO] - Training Epoch: 1/2, step 4785/7134 completed (loss: 0.4653039276599884, acc: 0.9029850959777832)
[2024-12-17 02:03:48,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:48,520][root][INFO] - Training Epoch: 1/2, step 4786/7134 completed (loss: 0.2920721769332886, acc: 0.9320987462997437)
[2024-12-17 02:03:48,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:48,819][root][INFO] - Training Epoch: 1/2, step 4787/7134 completed (loss: 0.32065290212631226, acc: 0.9182389974594116)
[2024-12-17 02:03:48,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:49,121][root][INFO] - Training Epoch: 1/2, step 4788/7134 completed (loss: 0.20218773186206818, acc: 0.9307692050933838)
[2024-12-17 02:03:49,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:49,419][root][INFO] - Training Epoch: 1/2, step 4789/7134 completed (loss: 0.3531583249568939, acc: 0.9166666865348816)
[2024-12-17 02:03:49,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:49,707][root][INFO] - Training Epoch: 1/2, step 4790/7134 completed (loss: 0.2382623553276062, acc: 0.966292142868042)
[2024-12-17 02:03:49,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:49,984][root][INFO] - Training Epoch: 1/2, step 4791/7134 completed (loss: 0.14559677243232727, acc: 0.9477611780166626)
[2024-12-17 02:03:50,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:50,277][root][INFO] - Training Epoch: 1/2, step 4792/7134 completed (loss: 0.19702693819999695, acc: 0.9729729890823364)
[2024-12-17 02:03:50,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:50,545][root][INFO] - Training Epoch: 1/2, step 4793/7134 completed (loss: 0.5600287914276123, acc: 0.8631578683853149)
[2024-12-17 02:03:50,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:50,847][root][INFO] - Training Epoch: 1/2, step 4794/7134 completed (loss: 0.6269907355308533, acc: 0.8368794322013855)
[2024-12-17 02:03:50,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:51,145][root][INFO] - Training Epoch: 1/2, step 4795/7134 completed (loss: 0.4912501275539398, acc: 0.8834356069564819)
[2024-12-17 02:03:51,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:51,422][root][INFO] - Training Epoch: 1/2, step 4796/7134 completed (loss: 0.3675459921360016, acc: 0.9013158082962036)
[2024-12-17 02:03:51,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:51,705][root][INFO] - Training Epoch: 1/2, step 4797/7134 completed (loss: 0.31407231092453003, acc: 0.9016393423080444)
[2024-12-17 02:03:51,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:52,008][root][INFO] - Training Epoch: 1/2, step 4798/7134 completed (loss: 0.2967640459537506, acc: 0.9281437397003174)
[2024-12-17 02:03:52,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:52,298][root][INFO] - Training Epoch: 1/2, step 4799/7134 completed (loss: 0.4292263984680176, acc: 0.875)
[2024-12-17 02:03:52,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:52,611][root][INFO] - Training Epoch: 1/2, step 4800/7134 completed (loss: 0.33231115341186523, acc: 0.9078947305679321)
[2024-12-17 02:03:52,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:52,911][root][INFO] - Training Epoch: 1/2, step 4801/7134 completed (loss: 0.1619189977645874, acc: 0.9744898080825806)
[2024-12-17 02:03:53,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:53,212][root][INFO] - Training Epoch: 1/2, step 4802/7134 completed (loss: 0.42626580595970154, acc: 0.9175257682800293)
[2024-12-17 02:03:53,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:53,478][root][INFO] - Training Epoch: 1/2, step 4803/7134 completed (loss: 0.42444005608558655, acc: 0.8909090757369995)
[2024-12-17 02:03:53,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:53,760][root][INFO] - Training Epoch: 1/2, step 4804/7134 completed (loss: 0.49287962913513184, acc: 0.8855421543121338)
[2024-12-17 02:03:53,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:54,039][root][INFO] - Training Epoch: 1/2, step 4805/7134 completed (loss: 0.19960515201091766, acc: 0.9602649211883545)
[2024-12-17 02:03:54,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:54,307][root][INFO] - Training Epoch: 1/2, step 4806/7134 completed (loss: 0.25672483444213867, acc: 0.9720279574394226)
[2024-12-17 02:03:54,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:54,586][root][INFO] - Training Epoch: 1/2, step 4807/7134 completed (loss: 0.238904669880867, acc: 0.9367088675498962)
[2024-12-17 02:03:54,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:54,888][root][INFO] - Training Epoch: 1/2, step 4808/7134 completed (loss: 0.23295773565769196, acc: 0.9318181872367859)
[2024-12-17 02:03:54,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:55,155][root][INFO] - Training Epoch: 1/2, step 4809/7134 completed (loss: 0.2810269296169281, acc: 0.931034505367279)
[2024-12-17 02:03:55,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:55,444][root][INFO] - Training Epoch: 1/2, step 4810/7134 completed (loss: 0.2960357069969177, acc: 0.9411764740943909)
[2024-12-17 02:03:55,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:55,718][root][INFO] - Training Epoch: 1/2, step 4811/7134 completed (loss: 0.25802186131477356, acc: 0.9262295365333557)
[2024-12-17 02:03:55,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:56,015][root][INFO] - Training Epoch: 1/2, step 4812/7134 completed (loss: 0.3545580804347992, acc: 0.9322034120559692)
[2024-12-17 02:03:56,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:56,249][root][INFO] - Training Epoch: 1/2, step 4813/7134 completed (loss: 0.13837184011936188, acc: 0.9791666865348816)
[2024-12-17 02:03:56,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:56,529][root][INFO] - Training Epoch: 1/2, step 4814/7134 completed (loss: 0.22701093554496765, acc: 0.945652186870575)
[2024-12-17 02:03:56,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:56,802][root][INFO] - Training Epoch: 1/2, step 4815/7134 completed (loss: 0.0518987812101841, acc: 1.0)
[2024-12-17 02:03:56,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:57,085][root][INFO] - Training Epoch: 1/2, step 4816/7134 completed (loss: 0.08313621580600739, acc: 0.9849246144294739)
[2024-12-17 02:03:57,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:57,367][root][INFO] - Training Epoch: 1/2, step 4817/7134 completed (loss: 0.16398410499095917, acc: 0.9696969985961914)
[2024-12-17 02:03:57,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:57,689][root][INFO] - Training Epoch: 1/2, step 4818/7134 completed (loss: 0.23601576685905457, acc: 0.9523809552192688)
[2024-12-17 02:03:57,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:57,977][root][INFO] - Training Epoch: 1/2, step 4819/7134 completed (loss: 0.11826273053884506, acc: 0.9750000238418579)
[2024-12-17 02:03:58,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:58,260][root][INFO] - Training Epoch: 1/2, step 4820/7134 completed (loss: 0.1361619383096695, acc: 0.9839572310447693)
[2024-12-17 02:03:58,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:58,538][root][INFO] - Training Epoch: 1/2, step 4821/7134 completed (loss: 0.1842578649520874, acc: 0.9595375657081604)
[2024-12-17 02:03:58,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:58,823][root][INFO] - Training Epoch: 1/2, step 4822/7134 completed (loss: 0.0992790162563324, acc: 0.9779411554336548)
[2024-12-17 02:03:58,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:59,114][root][INFO] - Training Epoch: 1/2, step 4823/7134 completed (loss: 0.404089093208313, acc: 0.9245283007621765)
[2024-12-17 02:03:59,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:59,409][root][INFO] - Training Epoch: 1/2, step 4824/7134 completed (loss: 0.24558313190937042, acc: 0.9491525292396545)
[2024-12-17 02:03:59,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:59,684][root][INFO] - Training Epoch: 1/2, step 4825/7134 completed (loss: 0.15397226810455322, acc: 0.9558823704719543)
[2024-12-17 02:03:59,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:59,987][root][INFO] - Training Epoch: 1/2, step 4826/7134 completed (loss: 0.2590770423412323, acc: 0.9173553586006165)
[2024-12-17 02:04:00,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:00,295][root][INFO] - Training Epoch: 1/2, step 4827/7134 completed (loss: 0.4753575026988983, acc: 0.9161290526390076)
[2024-12-17 02:04:00,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:00,582][root][INFO] - Training Epoch: 1/2, step 4828/7134 completed (loss: 0.22255000472068787, acc: 0.9438775777816772)
[2024-12-17 02:04:00,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:00,897][root][INFO] - Training Epoch: 1/2, step 4829/7134 completed (loss: 0.0820155069231987, acc: 0.9851484894752502)
[2024-12-17 02:04:01,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:01,207][root][INFO] - Training Epoch: 1/2, step 4830/7134 completed (loss: 0.13357217609882355, acc: 0.9636363387107849)
[2024-12-17 02:04:01,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:01,496][root][INFO] - Training Epoch: 1/2, step 4831/7134 completed (loss: 0.11765827983617783, acc: 0.977142870426178)
[2024-12-17 02:04:01,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:01,815][root][INFO] - Training Epoch: 1/2, step 4832/7134 completed (loss: 0.15303489565849304, acc: 0.9738562107086182)
[2024-12-17 02:04:01,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:02,134][root][INFO] - Training Epoch: 1/2, step 4833/7134 completed (loss: 0.13992072641849518, acc: 0.9593908786773682)
[2024-12-17 02:04:02,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:02,442][root][INFO] - Training Epoch: 1/2, step 4834/7134 completed (loss: 0.29567018151283264, acc: 0.9581395387649536)
[2024-12-17 02:04:02,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:02,754][root][INFO] - Training Epoch: 1/2, step 4835/7134 completed (loss: 0.1483258605003357, acc: 0.964102566242218)
[2024-12-17 02:04:02,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:03,050][root][INFO] - Training Epoch: 1/2, step 4836/7134 completed (loss: 0.13334007561206818, acc: 0.9629629850387573)
[2024-12-17 02:04:03,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:03,327][root][INFO] - Training Epoch: 1/2, step 4837/7134 completed (loss: 0.5543485283851624, acc: 0.8785714507102966)
[2024-12-17 02:04:03,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:03,630][root][INFO] - Training Epoch: 1/2, step 4838/7134 completed (loss: 0.5885862112045288, acc: 0.8848921060562134)
[2024-12-17 02:04:03,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:03,909][root][INFO] - Training Epoch: 1/2, step 4839/7134 completed (loss: 0.2914501428604126, acc: 0.930232584476471)
[2024-12-17 02:04:04,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:04,200][root][INFO] - Training Epoch: 1/2, step 4840/7134 completed (loss: 0.4018082022666931, acc: 0.8881579041481018)
[2024-12-17 02:04:04,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:04,482][root][INFO] - Training Epoch: 1/2, step 4841/7134 completed (loss: 0.31475594639778137, acc: 0.9166666865348816)
[2024-12-17 02:04:04,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:04,780][root][INFO] - Training Epoch: 1/2, step 4842/7134 completed (loss: 0.37906256318092346, acc: 0.9111111164093018)
[2024-12-17 02:04:04,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:05,072][root][INFO] - Training Epoch: 1/2, step 4843/7134 completed (loss: 0.4638991951942444, acc: 0.8805031180381775)
[2024-12-17 02:04:05,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:05,340][root][INFO] - Training Epoch: 1/2, step 4844/7134 completed (loss: 0.3503265678882599, acc: 0.8999999761581421)
[2024-12-17 02:04:05,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:05,622][root][INFO] - Training Epoch: 1/2, step 4845/7134 completed (loss: 0.510567307472229, acc: 0.875)
[2024-12-17 02:04:05,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:05,893][root][INFO] - Training Epoch: 1/2, step 4846/7134 completed (loss: 0.4477822184562683, acc: 0.90625)
[2024-12-17 02:04:05,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:06,160][root][INFO] - Training Epoch: 1/2, step 4847/7134 completed (loss: 0.31162965297698975, acc: 0.9349112510681152)
[2024-12-17 02:04:06,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:06,449][root][INFO] - Training Epoch: 1/2, step 4848/7134 completed (loss: 0.3662734031677246, acc: 0.9320987462997437)
[2024-12-17 02:04:06,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:06,734][root][INFO] - Training Epoch: 1/2, step 4849/7134 completed (loss: 0.2481735199689865, acc: 0.9452054500579834)
[2024-12-17 02:04:06,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:07,041][root][INFO] - Training Epoch: 1/2, step 4850/7134 completed (loss: 0.30568796396255493, acc: 0.8938547372817993)
[2024-12-17 02:04:07,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:07,363][root][INFO] - Training Epoch: 1/2, step 4851/7134 completed (loss: 0.3740736246109009, acc: 0.8972973227500916)
[2024-12-17 02:04:07,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:07,672][root][INFO] - Training Epoch: 1/2, step 4852/7134 completed (loss: 0.602893590927124, acc: 0.8488371968269348)
[2024-12-17 02:04:07,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:07,959][root][INFO] - Training Epoch: 1/2, step 4853/7134 completed (loss: 0.8467006087303162, acc: 0.8383233547210693)
[2024-12-17 02:04:08,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:08,247][root][INFO] - Training Epoch: 1/2, step 4854/7134 completed (loss: 0.2618624269962311, acc: 0.9194630980491638)
[2024-12-17 02:04:08,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:08,530][root][INFO] - Training Epoch: 1/2, step 4855/7134 completed (loss: 0.28949251770973206, acc: 0.9195402264595032)
[2024-12-17 02:04:08,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:08,817][root][INFO] - Training Epoch: 1/2, step 4856/7134 completed (loss: 0.2329932153224945, acc: 0.9345238208770752)
[2024-12-17 02:04:08,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:09,094][root][INFO] - Training Epoch: 1/2, step 4857/7134 completed (loss: 0.3714260458946228, acc: 0.9074074029922485)
[2024-12-17 02:04:09,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:09,387][root][INFO] - Training Epoch: 1/2, step 4858/7134 completed (loss: 0.6211069822311401, acc: 0.8765432238578796)
[2024-12-17 02:04:09,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:09,676][root][INFO] - Training Epoch: 1/2, step 4859/7134 completed (loss: 0.3094290494918823, acc: 0.9166666865348816)
[2024-12-17 02:04:09,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:09,964][root][INFO] - Training Epoch: 1/2, step 4860/7134 completed (loss: 0.3291299641132355, acc: 0.9122806787490845)
[2024-12-17 02:04:10,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:10,242][root][INFO] - Training Epoch: 1/2, step 4861/7134 completed (loss: 0.23629996180534363, acc: 0.9349112510681152)
[2024-12-17 02:04:10,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:10,547][root][INFO] - Training Epoch: 1/2, step 4862/7134 completed (loss: 0.2738514840602875, acc: 0.9342105388641357)
[2024-12-17 02:04:10,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:10,826][root][INFO] - Training Epoch: 1/2, step 4863/7134 completed (loss: 0.4592059254646301, acc: 0.8914728760719299)
[2024-12-17 02:04:10,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:11,101][root][INFO] - Training Epoch: 1/2, step 4864/7134 completed (loss: 0.2595779299736023, acc: 0.9171974658966064)
[2024-12-17 02:04:11,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:11,388][root][INFO] - Training Epoch: 1/2, step 4865/7134 completed (loss: 0.43093401193618774, acc: 0.897849440574646)
[2024-12-17 02:04:11,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:11,687][root][INFO] - Training Epoch: 1/2, step 4866/7134 completed (loss: 0.38884806632995605, acc: 0.895348846912384)
[2024-12-17 02:04:11,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:11,968][root][INFO] - Training Epoch: 1/2, step 4867/7134 completed (loss: 0.4511219263076782, acc: 0.9217877388000488)
[2024-12-17 02:04:12,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:12,254][root][INFO] - Training Epoch: 1/2, step 4868/7134 completed (loss: 0.4237141013145447, acc: 0.8655462265014648)
[2024-12-17 02:04:12,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:12,540][root][INFO] - Training Epoch: 1/2, step 4869/7134 completed (loss: 0.3090587556362152, acc: 0.918367326259613)
[2024-12-17 02:04:12,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:12,823][root][INFO] - Training Epoch: 1/2, step 4870/7134 completed (loss: 0.2560136020183563, acc: 0.9189189076423645)
[2024-12-17 02:04:12,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:13,100][root][INFO] - Training Epoch: 1/2, step 4871/7134 completed (loss: 0.22799521684646606, acc: 0.9539473652839661)
[2024-12-17 02:04:13,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:13,378][root][INFO] - Training Epoch: 1/2, step 4872/7134 completed (loss: 0.14070375263690948, acc: 0.9642857313156128)
[2024-12-17 02:04:13,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:13,677][root][INFO] - Training Epoch: 1/2, step 4873/7134 completed (loss: 0.29284337162971497, acc: 0.9508196711540222)
[2024-12-17 02:04:13,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:13,969][root][INFO] - Training Epoch: 1/2, step 4874/7134 completed (loss: 0.25106576085090637, acc: 0.9365853667259216)
[2024-12-17 02:04:14,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:14,294][root][INFO] - Training Epoch: 1/2, step 4875/7134 completed (loss: 0.17013069987297058, acc: 0.95652174949646)
[2024-12-17 02:04:14,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:14,610][root][INFO] - Training Epoch: 1/2, step 4876/7134 completed (loss: 0.27829840779304504, acc: 0.9166666865348816)
[2024-12-17 02:04:14,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:14,912][root][INFO] - Training Epoch: 1/2, step 4877/7134 completed (loss: 0.3365018665790558, acc: 0.9179487228393555)
[2024-12-17 02:04:15,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:15,217][root][INFO] - Training Epoch: 1/2, step 4878/7134 completed (loss: 0.3228917419910431, acc: 0.9155844449996948)
[2024-12-17 02:04:15,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:15,506][root][INFO] - Training Epoch: 1/2, step 4879/7134 completed (loss: 0.19764161109924316, acc: 0.9551281929016113)
[2024-12-17 02:04:15,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:15,794][root][INFO] - Training Epoch: 1/2, step 4880/7134 completed (loss: 0.1749575138092041, acc: 0.9529411792755127)
[2024-12-17 02:04:15,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:16,079][root][INFO] - Training Epoch: 1/2, step 4881/7134 completed (loss: 0.3728182017803192, acc: 0.926174521446228)
[2024-12-17 02:04:16,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:16,367][root][INFO] - Training Epoch: 1/2, step 4882/7134 completed (loss: 0.3503042459487915, acc: 0.9096774458885193)
[2024-12-17 02:04:16,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:16,666][root][INFO] - Training Epoch: 1/2, step 4883/7134 completed (loss: 0.27090510725975037, acc: 0.9266666769981384)
[2024-12-17 02:04:16,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:16,943][root][INFO] - Training Epoch: 1/2, step 4884/7134 completed (loss: 0.20921063423156738, acc: 0.9477124214172363)
[2024-12-17 02:04:17,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:17,250][root][INFO] - Training Epoch: 1/2, step 4885/7134 completed (loss: 0.3593302071094513, acc: 0.9354838728904724)
[2024-12-17 02:04:17,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:17,560][root][INFO] - Training Epoch: 1/2, step 4886/7134 completed (loss: 0.36975347995758057, acc: 0.9230769276618958)
[2024-12-17 02:04:17,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:17,885][root][INFO] - Training Epoch: 1/2, step 4887/7134 completed (loss: 0.24319986999034882, acc: 0.9424083828926086)
[2024-12-17 02:04:18,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:18,199][root][INFO] - Training Epoch: 1/2, step 4888/7134 completed (loss: 0.19873133301734924, acc: 0.9560439586639404)
[2024-12-17 02:04:18,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:18,493][root][INFO] - Training Epoch: 1/2, step 4889/7134 completed (loss: 0.14817902445793152, acc: 0.9465240836143494)
[2024-12-17 02:04:18,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:18,765][root][INFO] - Training Epoch: 1/2, step 4890/7134 completed (loss: 0.34421196579933167, acc: 0.9150943160057068)
[2024-12-17 02:04:18,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:19,042][root][INFO] - Training Epoch: 1/2, step 4891/7134 completed (loss: 0.220454141497612, acc: 0.9438775777816772)
[2024-12-17 02:04:19,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:19,324][root][INFO] - Training Epoch: 1/2, step 4892/7134 completed (loss: 0.23018093407154083, acc: 0.9285714030265808)
[2024-12-17 02:04:19,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:19,604][root][INFO] - Training Epoch: 1/2, step 4893/7134 completed (loss: 0.945408284664154, acc: 0.8103448152542114)
[2024-12-17 02:04:19,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:19,877][root][INFO] - Training Epoch: 1/2, step 4894/7134 completed (loss: 0.18447290360927582, acc: 0.9470587968826294)
[2024-12-17 02:04:20,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:20,161][root][INFO] - Training Epoch: 1/2, step 4895/7134 completed (loss: 0.2645051181316376, acc: 0.9285714030265808)
[2024-12-17 02:04:20,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:20,435][root][INFO] - Training Epoch: 1/2, step 4896/7134 completed (loss: 0.20251059532165527, acc: 0.9664804339408875)
[2024-12-17 02:04:20,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:20,726][root][INFO] - Training Epoch: 1/2, step 4897/7134 completed (loss: 0.17726658284664154, acc: 0.9753694534301758)
[2024-12-17 02:04:20,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:21,014][root][INFO] - Training Epoch: 1/2, step 4898/7134 completed (loss: 0.18955475091934204, acc: 0.9516128897666931)
[2024-12-17 02:04:21,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:21,319][root][INFO] - Training Epoch: 1/2, step 4899/7134 completed (loss: 0.23975355923175812, acc: 0.9451219439506531)
[2024-12-17 02:04:21,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:21,611][root][INFO] - Training Epoch: 1/2, step 4900/7134 completed (loss: 0.2110629379749298, acc: 0.9465240836143494)
[2024-12-17 02:04:21,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:21,910][root][INFO] - Training Epoch: 1/2, step 4901/7134 completed (loss: 0.24293559789657593, acc: 0.9207317233085632)
[2024-12-17 02:04:22,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:22,214][root][INFO] - Training Epoch: 1/2, step 4902/7134 completed (loss: 0.14340978860855103, acc: 0.9538461565971375)
[2024-12-17 02:04:22,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:22,528][root][INFO] - Training Epoch: 1/2, step 4903/7134 completed (loss: 0.16960470378398895, acc: 0.9635036587715149)
[2024-12-17 02:04:22,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:22,819][root][INFO] - Training Epoch: 1/2, step 4904/7134 completed (loss: 0.2066495269536972, acc: 0.9529411792755127)
[2024-12-17 02:04:22,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:23,105][root][INFO] - Training Epoch: 1/2, step 4905/7134 completed (loss: 0.07695131748914719, acc: 0.9803921580314636)
[2024-12-17 02:04:23,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:23,399][root][INFO] - Training Epoch: 1/2, step 4906/7134 completed (loss: 0.13546398282051086, acc: 0.969924807548523)
[2024-12-17 02:04:23,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:23,684][root][INFO] - Training Epoch: 1/2, step 4907/7134 completed (loss: 0.16162890195846558, acc: 0.9523809552192688)
[2024-12-17 02:04:23,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:23,968][root][INFO] - Training Epoch: 1/2, step 4908/7134 completed (loss: 0.11075633019208908, acc: 0.9740259647369385)
[2024-12-17 02:04:24,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:24,255][root][INFO] - Training Epoch: 1/2, step 4909/7134 completed (loss: 0.07899004220962524, acc: 0.9798657894134521)
[2024-12-17 02:04:24,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:24,543][root][INFO] - Training Epoch: 1/2, step 4910/7134 completed (loss: 0.22136200964450836, acc: 0.948387086391449)
[2024-12-17 02:04:24,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:24,840][root][INFO] - Training Epoch: 1/2, step 4911/7134 completed (loss: 0.15427252650260925, acc: 0.9679144620895386)
[2024-12-17 02:04:24,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:25,141][root][INFO] - Training Epoch: 1/2, step 4912/7134 completed (loss: 0.13736148178577423, acc: 0.9701492786407471)
[2024-12-17 02:04:25,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:25,435][root][INFO] - Training Epoch: 1/2, step 4913/7134 completed (loss: 0.24169689416885376, acc: 0.9440559148788452)
[2024-12-17 02:04:25,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:25,721][root][INFO] - Training Epoch: 1/2, step 4914/7134 completed (loss: 0.19822943210601807, acc: 0.9548386931419373)
[2024-12-17 02:04:25,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:26,034][root][INFO] - Training Epoch: 1/2, step 4915/7134 completed (loss: 0.09949452430009842, acc: 0.9753086566925049)
[2024-12-17 02:04:26,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:26,307][root][INFO] - Training Epoch: 1/2, step 4916/7134 completed (loss: 0.3252139687538147, acc: 0.9239130616188049)
[2024-12-17 02:04:26,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:26,595][root][INFO] - Training Epoch: 1/2, step 4917/7134 completed (loss: 0.3587794601917267, acc: 0.9044585824012756)
[2024-12-17 02:04:26,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:26,902][root][INFO] - Training Epoch: 1/2, step 4918/7134 completed (loss: 0.09890635311603546, acc: 0.9814814925193787)
[2024-12-17 02:04:27,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:27,251][root][INFO] - Training Epoch: 1/2, step 4919/7134 completed (loss: 0.2512393593788147, acc: 0.9548022747039795)
[2024-12-17 02:04:27,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:27,545][root][INFO] - Training Epoch: 1/2, step 4920/7134 completed (loss: 0.4066999852657318, acc: 0.9068322777748108)
[2024-12-17 02:04:27,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:27,823][root][INFO] - Training Epoch: 1/2, step 4921/7134 completed (loss: 0.3802662491798401, acc: 0.9270073175430298)
[2024-12-17 02:04:27,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:28,121][root][INFO] - Training Epoch: 1/2, step 4922/7134 completed (loss: 0.19744980335235596, acc: 0.9440993666648865)
[2024-12-17 02:04:28,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:28,418][root][INFO] - Training Epoch: 1/2, step 4923/7134 completed (loss: 0.1642271727323532, acc: 0.9492753744125366)
[2024-12-17 02:04:28,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:28,690][root][INFO] - Training Epoch: 1/2, step 4924/7134 completed (loss: 0.25776126980781555, acc: 0.9320388436317444)
[2024-12-17 02:04:28,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:28,968][root][INFO] - Training Epoch: 1/2, step 4925/7134 completed (loss: 0.3313181400299072, acc: 0.9395973086357117)
[2024-12-17 02:04:29,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:29,234][root][INFO] - Training Epoch: 1/2, step 4926/7134 completed (loss: 0.14364920556545258, acc: 0.9530201554298401)
[2024-12-17 02:04:29,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:29,495][root][INFO] - Training Epoch: 1/2, step 4927/7134 completed (loss: 0.18322589993476868, acc: 0.948387086391449)
[2024-12-17 02:04:29,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:29,788][root][INFO] - Training Epoch: 1/2, step 4928/7134 completed (loss: 0.20515033602714539, acc: 0.9473684430122375)
[2024-12-17 02:04:29,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:30,101][root][INFO] - Training Epoch: 1/2, step 4929/7134 completed (loss: 0.19664181768894196, acc: 0.9539473652839661)
[2024-12-17 02:04:30,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:30,368][root][INFO] - Training Epoch: 1/2, step 4930/7134 completed (loss: 0.30025526881217957, acc: 0.9324324131011963)
[2024-12-17 02:04:30,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:30,681][root][INFO] - Training Epoch: 1/2, step 4931/7134 completed (loss: 0.22673366963863373, acc: 0.9447852969169617)
[2024-12-17 02:04:30,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:30,968][root][INFO] - Training Epoch: 1/2, step 4932/7134 completed (loss: 0.21871687471866608, acc: 0.9588235020637512)
[2024-12-17 02:04:31,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:31,253][root][INFO] - Training Epoch: 1/2, step 4933/7134 completed (loss: 0.2685486972332001, acc: 0.9214659929275513)
[2024-12-17 02:04:31,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:31,552][root][INFO] - Training Epoch: 1/2, step 4934/7134 completed (loss: 0.15815864503383636, acc: 0.9647058844566345)
[2024-12-17 02:04:31,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:31,835][root][INFO] - Training Epoch: 1/2, step 4935/7134 completed (loss: 0.15473994612693787, acc: 0.970588207244873)
[2024-12-17 02:04:31,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:32,116][root][INFO] - Training Epoch: 1/2, step 4936/7134 completed (loss: 0.18703584372997284, acc: 0.9523809552192688)
[2024-12-17 02:04:32,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:32,404][root][INFO] - Training Epoch: 1/2, step 4937/7134 completed (loss: 0.2687388062477112, acc: 0.9440559148788452)
[2024-12-17 02:04:32,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:32,699][root][INFO] - Training Epoch: 1/2, step 4938/7134 completed (loss: 0.23971903324127197, acc: 0.9567901492118835)
[2024-12-17 02:04:32,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:32,976][root][INFO] - Training Epoch: 1/2, step 4939/7134 completed (loss: 0.20585672557353973, acc: 0.9428571462631226)
[2024-12-17 02:04:33,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:33,261][root][INFO] - Training Epoch: 1/2, step 4940/7134 completed (loss: 0.38554516434669495, acc: 0.9224806427955627)
[2024-12-17 02:04:33,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:33,555][root][INFO] - Training Epoch: 1/2, step 4941/7134 completed (loss: 0.2466154247522354, acc: 0.9281437397003174)
[2024-12-17 02:04:33,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:33,847][root][INFO] - Training Epoch: 1/2, step 4942/7134 completed (loss: 0.2484930008649826, acc: 0.9240506291389465)
[2024-12-17 02:04:33,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:34,142][root][INFO] - Training Epoch: 1/2, step 4943/7134 completed (loss: 0.3513800799846649, acc: 0.9125000238418579)
[2024-12-17 02:04:34,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:34,437][root][INFO] - Training Epoch: 1/2, step 4944/7134 completed (loss: 0.4259907901287079, acc: 0.8991596698760986)
[2024-12-17 02:04:34,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:34,712][root][INFO] - Training Epoch: 1/2, step 4945/7134 completed (loss: 0.5845975875854492, acc: 0.8712121248245239)
[2024-12-17 02:04:34,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:34,992][root][INFO] - Training Epoch: 1/2, step 4946/7134 completed (loss: 0.4082667827606201, acc: 0.8984375)
[2024-12-17 02:04:35,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:35,278][root][INFO] - Training Epoch: 1/2, step 4947/7134 completed (loss: 0.5095812678337097, acc: 0.852173924446106)
[2024-12-17 02:04:35,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:35,560][root][INFO] - Training Epoch: 1/2, step 4948/7134 completed (loss: 0.35355788469314575, acc: 0.9047619104385376)
[2024-12-17 02:04:35,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:35,849][root][INFO] - Training Epoch: 1/2, step 4949/7134 completed (loss: 0.26931461691856384, acc: 0.9382715821266174)
[2024-12-17 02:04:35,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:36,147][root][INFO] - Training Epoch: 1/2, step 4950/7134 completed (loss: 0.2906002998352051, acc: 0.9387755393981934)
[2024-12-17 02:04:36,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:36,447][root][INFO] - Training Epoch: 1/2, step 4951/7134 completed (loss: 0.3982504606246948, acc: 0.9101123809814453)
[2024-12-17 02:04:36,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:36,782][root][INFO] - Training Epoch: 1/2, step 4952/7134 completed (loss: 0.22106415033340454, acc: 0.9256756901741028)
[2024-12-17 02:04:36,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:37,084][root][INFO] - Training Epoch: 1/2, step 4953/7134 completed (loss: 0.29230204224586487, acc: 0.9189189076423645)
[2024-12-17 02:04:37,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:37,383][root][INFO] - Training Epoch: 1/2, step 4954/7134 completed (loss: 0.49856311082839966, acc: 0.918367326259613)
[2024-12-17 02:04:37,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:37,669][root][INFO] - Training Epoch: 1/2, step 4955/7134 completed (loss: 0.432915061712265, acc: 0.90625)
[2024-12-17 02:04:37,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:37,963][root][INFO] - Training Epoch: 1/2, step 4956/7134 completed (loss: 0.33745598793029785, acc: 0.9117646813392639)
[2024-12-17 02:04:38,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:38,266][root][INFO] - Training Epoch: 1/2, step 4957/7134 completed (loss: 0.30617162585258484, acc: 0.9290780425071716)
[2024-12-17 02:04:38,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:38,573][root][INFO] - Training Epoch: 1/2, step 4958/7134 completed (loss: 0.3144826591014862, acc: 0.9308176040649414)
[2024-12-17 02:04:38,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:38,880][root][INFO] - Training Epoch: 1/2, step 4959/7134 completed (loss: 0.2948133051395416, acc: 0.9457831382751465)
[2024-12-17 02:04:39,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:39,167][root][INFO] - Training Epoch: 1/2, step 4960/7134 completed (loss: 0.3521828055381775, acc: 0.9191176295280457)
[2024-12-17 02:04:39,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:39,459][root][INFO] - Training Epoch: 1/2, step 4961/7134 completed (loss: 0.4387895464897156, acc: 0.8984375)
[2024-12-17 02:04:39,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:39,760][root][INFO] - Training Epoch: 1/2, step 4962/7134 completed (loss: 0.2626315653324127, acc: 0.9329268336296082)
[2024-12-17 02:04:39,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:40,049][root][INFO] - Training Epoch: 1/2, step 4963/7134 completed (loss: 0.2416357696056366, acc: 0.9225806593894958)
[2024-12-17 02:04:40,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:40,333][root][INFO] - Training Epoch: 1/2, step 4964/7134 completed (loss: 0.44745713472366333, acc: 0.9208633303642273)
[2024-12-17 02:04:40,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:40,597][root][INFO] - Training Epoch: 1/2, step 4965/7134 completed (loss: 0.12911447882652283, acc: 0.95652174949646)
[2024-12-17 02:04:40,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:40,877][root][INFO] - Training Epoch: 1/2, step 4966/7134 completed (loss: 0.2582259178161621, acc: 0.9450549483299255)
[2024-12-17 02:04:41,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:41,162][root][INFO] - Training Epoch: 1/2, step 4967/7134 completed (loss: 0.36941102147102356, acc: 0.9069767594337463)
[2024-12-17 02:04:41,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:41,456][root][INFO] - Training Epoch: 1/2, step 4968/7134 completed (loss: 0.6834699511528015, acc: 0.8368794322013855)
[2024-12-17 02:04:41,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:41,760][root][INFO] - Training Epoch: 1/2, step 4969/7134 completed (loss: 0.44305482506752014, acc: 0.9103448390960693)
[2024-12-17 02:04:41,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:42,059][root][INFO] - Training Epoch: 1/2, step 4970/7134 completed (loss: 0.21238087117671967, acc: 0.9448275566101074)
[2024-12-17 02:04:42,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:42,354][root][INFO] - Training Epoch: 1/2, step 4971/7134 completed (loss: 0.2536757290363312, acc: 0.9602649211883545)
[2024-12-17 02:04:42,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:42,653][root][INFO] - Training Epoch: 1/2, step 4972/7134 completed (loss: 0.35609787702560425, acc: 0.925000011920929)
[2024-12-17 02:04:42,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:42,957][root][INFO] - Training Epoch: 1/2, step 4973/7134 completed (loss: 0.3844020664691925, acc: 0.9015151262283325)
[2024-12-17 02:04:43,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:43,236][root][INFO] - Training Epoch: 1/2, step 4974/7134 completed (loss: 0.26692453026771545, acc: 0.9318181872367859)
[2024-12-17 02:04:43,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:43,523][root][INFO] - Training Epoch: 1/2, step 4975/7134 completed (loss: 0.42572832107543945, acc: 0.882758617401123)
[2024-12-17 02:04:43,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:43,819][root][INFO] - Training Epoch: 1/2, step 4976/7134 completed (loss: 0.34334704279899597, acc: 0.9052631855010986)
[2024-12-17 02:04:43,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:44,120][root][INFO] - Training Epoch: 1/2, step 4977/7134 completed (loss: 0.4397878646850586, acc: 0.9320388436317444)
[2024-12-17 02:04:44,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:44,403][root][INFO] - Training Epoch: 1/2, step 4978/7134 completed (loss: 0.19749195873737335, acc: 0.9482758641242981)
[2024-12-17 02:04:44,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:44,678][root][INFO] - Training Epoch: 1/2, step 4979/7134 completed (loss: 0.44470202922821045, acc: 0.9020978808403015)
[2024-12-17 02:04:44,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:44,972][root][INFO] - Training Epoch: 1/2, step 4980/7134 completed (loss: 0.4925820529460907, acc: 0.8999999761581421)
[2024-12-17 02:04:45,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:45,253][root][INFO] - Training Epoch: 1/2, step 4981/7134 completed (loss: 0.3326476514339447, acc: 0.9214285612106323)
[2024-12-17 02:04:45,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:45,533][root][INFO] - Training Epoch: 1/2, step 4982/7134 completed (loss: 0.4056689739227295, acc: 0.9099099040031433)
[2024-12-17 02:04:45,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:45,824][root][INFO] - Training Epoch: 1/2, step 4983/7134 completed (loss: 0.2703767716884613, acc: 0.9568345546722412)
[2024-12-17 02:04:45,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:46,023][root][INFO] - Training Epoch: 1/2, step 4984/7134 completed (loss: 0.44918274879455566, acc: 0.9433962106704712)
[2024-12-17 02:04:46,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:46,286][root][INFO] - Training Epoch: 1/2, step 4985/7134 completed (loss: 0.2019319087266922, acc: 0.9459459185600281)
[2024-12-17 02:04:46,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:46,583][root][INFO] - Training Epoch: 1/2, step 4986/7134 completed (loss: 0.21787501871585846, acc: 0.9650349617004395)
[2024-12-17 02:04:46,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:46,869][root][INFO] - Training Epoch: 1/2, step 4987/7134 completed (loss: 0.23784556984901428, acc: 0.9528301954269409)
[2024-12-17 02:04:47,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:47,166][root][INFO] - Training Epoch: 1/2, step 4988/7134 completed (loss: 0.18858544528484344, acc: 0.931034505367279)
[2024-12-17 02:04:47,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:47,449][root][INFO] - Training Epoch: 1/2, step 4989/7134 completed (loss: 0.22242484986782074, acc: 0.9764705896377563)
[2024-12-17 02:04:47,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:47,725][root][INFO] - Training Epoch: 1/2, step 4990/7134 completed (loss: 0.2664308547973633, acc: 0.9316239356994629)
[2024-12-17 02:04:47,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:48,025][root][INFO] - Training Epoch: 1/2, step 4991/7134 completed (loss: 0.2313193529844284, acc: 0.9398496150970459)
[2024-12-17 02:04:48,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:48,321][root][INFO] - Training Epoch: 1/2, step 4992/7134 completed (loss: 0.2461426556110382, acc: 0.931034505367279)
[2024-12-17 02:04:48,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:48,581][root][INFO] - Training Epoch: 1/2, step 4993/7134 completed (loss: 0.21174834668636322, acc: 0.9800000190734863)
[2024-12-17 02:04:48,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:48,874][root][INFO] - Training Epoch: 1/2, step 4994/7134 completed (loss: 0.11958717554807663, acc: 0.9735099077224731)
[2024-12-17 02:04:49,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:49,160][root][INFO] - Training Epoch: 1/2, step 4995/7134 completed (loss: 0.332336962223053, acc: 0.9444444179534912)
[2024-12-17 02:04:49,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:49,431][root][INFO] - Training Epoch: 1/2, step 4996/7134 completed (loss: 0.16975095868110657, acc: 0.949999988079071)
[2024-12-17 02:04:49,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:49,727][root][INFO] - Training Epoch: 1/2, step 4997/7134 completed (loss: 0.2829439342021942, acc: 0.9160305261611938)
[2024-12-17 02:04:49,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:50,004][root][INFO] - Training Epoch: 1/2, step 4998/7134 completed (loss: 0.14991126954555511, acc: 0.9599999785423279)
[2024-12-17 02:04:50,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:50,279][root][INFO] - Training Epoch: 1/2, step 4999/7134 completed (loss: 0.25699514150619507, acc: 0.9448819160461426)
[2024-12-17 02:04:50,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:50,569][root][INFO] - Training Epoch: 1/2, step 5000/7134 completed (loss: 0.19640706479549408, acc: 0.9484536051750183)
[2024-12-17 02:04:50,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:50,851][root][INFO] - Training Epoch: 1/2, step 5001/7134 completed (loss: 0.3442564606666565, acc: 0.9387755393981934)
[2024-12-17 02:04:50,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:51,116][root][INFO] - Training Epoch: 1/2, step 5002/7134 completed (loss: 0.1551632136106491, acc: 0.9557521939277649)
[2024-12-17 02:04:51,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:51,375][root][INFO] - Training Epoch: 1/2, step 5003/7134 completed (loss: 0.2126823216676712, acc: 0.9407407641410828)
[2024-12-17 02:04:51,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:51,630][root][INFO] - Training Epoch: 1/2, step 5004/7134 completed (loss: 0.12847162783145905, acc: 0.9719626307487488)
[2024-12-17 02:04:51,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:51,904][root][INFO] - Training Epoch: 1/2, step 5005/7134 completed (loss: 0.2741154134273529, acc: 0.9780219793319702)
[2024-12-17 02:04:52,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:52,180][root][INFO] - Training Epoch: 1/2, step 5006/7134 completed (loss: 0.16567178070545197, acc: 0.9605262875556946)
[2024-12-17 02:04:52,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:52,439][root][INFO] - Training Epoch: 1/2, step 5007/7134 completed (loss: 0.24872064590454102, acc: 0.9629629850387573)
[2024-12-17 02:04:52,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:52,735][root][INFO] - Training Epoch: 1/2, step 5008/7134 completed (loss: 0.3591921925544739, acc: 0.9166666865348816)
[2024-12-17 02:04:52,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:53,047][root][INFO] - Training Epoch: 1/2, step 5009/7134 completed (loss: 0.44599461555480957, acc: 0.876288652420044)
[2024-12-17 02:04:53,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:53,351][root][INFO] - Training Epoch: 1/2, step 5010/7134 completed (loss: 0.3153241276741028, acc: 0.9145299196243286)
[2024-12-17 02:04:53,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:53,660][root][INFO] - Training Epoch: 1/2, step 5011/7134 completed (loss: 0.25544220209121704, acc: 0.9379310607910156)
[2024-12-17 02:04:53,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:53,891][root][INFO] - Training Epoch: 1/2, step 5012/7134 completed (loss: 0.15681882202625275, acc: 0.9624999761581421)
[2024-12-17 02:04:54,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:54,168][root][INFO] - Training Epoch: 1/2, step 5013/7134 completed (loss: 0.15615355968475342, acc: 0.9572649598121643)
[2024-12-17 02:04:54,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:54,469][root][INFO] - Training Epoch: 1/2, step 5014/7134 completed (loss: 0.23864637315273285, acc: 0.932692289352417)
[2024-12-17 02:04:54,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:54,753][root][INFO] - Training Epoch: 1/2, step 5015/7134 completed (loss: 0.40642252564430237, acc: 0.9202454090118408)
[2024-12-17 02:04:54,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:55,047][root][INFO] - Training Epoch: 1/2, step 5016/7134 completed (loss: 0.41432490944862366, acc: 0.9312977194786072)
[2024-12-17 02:04:55,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:55,336][root][INFO] - Training Epoch: 1/2, step 5017/7134 completed (loss: 0.1492612659931183, acc: 0.9545454382896423)
[2024-12-17 02:04:55,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:55,619][root][INFO] - Training Epoch: 1/2, step 5018/7134 completed (loss: 0.2336435317993164, acc: 0.932330846786499)
[2024-12-17 02:04:55,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:55,919][root][INFO] - Training Epoch: 1/2, step 5019/7134 completed (loss: 0.5177527070045471, acc: 0.9209039807319641)
[2024-12-17 02:04:56,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:56,248][root][INFO] - Training Epoch: 1/2, step 5020/7134 completed (loss: 0.48565149307250977, acc: 0.8994709253311157)
[2024-12-17 02:04:56,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:56,533][root][INFO] - Training Epoch: 1/2, step 5021/7134 completed (loss: 0.203120157122612, acc: 0.9714285731315613)
[2024-12-17 02:04:56,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:56,827][root][INFO] - Training Epoch: 1/2, step 5022/7134 completed (loss: 0.17995081841945648, acc: 0.9637681245803833)
[2024-12-17 02:04:56,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:57,114][root][INFO] - Training Epoch: 1/2, step 5023/7134 completed (loss: 0.14459411799907684, acc: 0.9741935729980469)
[2024-12-17 02:04:57,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:57,397][root][INFO] - Training Epoch: 1/2, step 5024/7134 completed (loss: 0.14595510065555573, acc: 0.9879518151283264)
[2024-12-17 02:04:57,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:57,665][root][INFO] - Training Epoch: 1/2, step 5025/7134 completed (loss: 0.31225302815437317, acc: 0.9230769276618958)
[2024-12-17 02:04:57,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:57,922][root][INFO] - Training Epoch: 1/2, step 5026/7134 completed (loss: 0.40655869245529175, acc: 0.9389312863349915)
[2024-12-17 02:04:58,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:58,208][root][INFO] - Training Epoch: 1/2, step 5027/7134 completed (loss: 0.1759973168373108, acc: 0.9457364082336426)
[2024-12-17 02:04:58,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:58,507][root][INFO] - Training Epoch: 1/2, step 5028/7134 completed (loss: 0.15509194135665894, acc: 0.9577465057373047)
[2024-12-17 02:04:58,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:58,811][root][INFO] - Training Epoch: 1/2, step 5029/7134 completed (loss: 0.1636134833097458, acc: 0.9538461565971375)
[2024-12-17 02:04:58,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:59,125][root][INFO] - Training Epoch: 1/2, step 5030/7134 completed (loss: 0.1748533695936203, acc: 0.9520958065986633)
[2024-12-17 02:04:59,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:59,432][root][INFO] - Training Epoch: 1/2, step 5031/7134 completed (loss: 0.5224934816360474, acc: 0.9130434989929199)
[2024-12-17 02:04:59,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:59,729][root][INFO] - Training Epoch: 1/2, step 5032/7134 completed (loss: 0.18661880493164062, acc: 0.9788732528686523)
[2024-12-17 02:04:59,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:00,014][root][INFO] - Training Epoch: 1/2, step 5033/7134 completed (loss: 0.12570129334926605, acc: 0.9647887349128723)
[2024-12-17 02:05:00,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:00,322][root][INFO] - Training Epoch: 1/2, step 5034/7134 completed (loss: 0.10474545508623123, acc: 0.9774436354637146)
[2024-12-17 02:05:00,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:00,632][root][INFO] - Training Epoch: 1/2, step 5035/7134 completed (loss: 0.03445933386683464, acc: 1.0)
[2024-12-17 02:05:00,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:00,932][root][INFO] - Training Epoch: 1/2, step 5036/7134 completed (loss: 0.2855587303638458, acc: 0.932692289352417)
[2024-12-17 02:05:01,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:01,229][root][INFO] - Training Epoch: 1/2, step 5037/7134 completed (loss: 0.187405064702034, acc: 0.9647058844566345)
[2024-12-17 02:05:01,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:01,517][root][INFO] - Training Epoch: 1/2, step 5038/7134 completed (loss: 0.6286489367485046, acc: 0.8782608509063721)
[2024-12-17 02:05:01,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:01,804][root][INFO] - Training Epoch: 1/2, step 5039/7134 completed (loss: 0.32840803265571594, acc: 0.9078013896942139)
[2024-12-17 02:05:01,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:02,138][root][INFO] - Training Epoch: 1/2, step 5040/7134 completed (loss: 0.24338577687740326, acc: 0.949999988079071)
[2024-12-17 02:05:02,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:02,420][root][INFO] - Training Epoch: 1/2, step 5041/7134 completed (loss: 0.13864336907863617, acc: 0.9651162624359131)
[2024-12-17 02:05:02,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:02,739][root][INFO] - Training Epoch: 1/2, step 5042/7134 completed (loss: 0.3383830487728119, acc: 0.9417475461959839)
[2024-12-17 02:05:02,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:03,024][root][INFO] - Training Epoch: 1/2, step 5043/7134 completed (loss: 0.19893577694892883, acc: 0.9380530714988708)
[2024-12-17 02:05:03,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:03,320][root][INFO] - Training Epoch: 1/2, step 5044/7134 completed (loss: 0.18257452547550201, acc: 0.9554139971733093)
[2024-12-17 02:05:03,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:03,612][root][INFO] - Training Epoch: 1/2, step 5045/7134 completed (loss: 0.17760956287384033, acc: 0.9567567706108093)
[2024-12-17 02:05:03,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:03,876][root][INFO] - Training Epoch: 1/2, step 5046/7134 completed (loss: 0.4878862202167511, acc: 0.9032257795333862)
[2024-12-17 02:05:03,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:04,145][root][INFO] - Training Epoch: 1/2, step 5047/7134 completed (loss: 0.4522307813167572, acc: 0.9124087691307068)
[2024-12-17 02:05:04,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:04,441][root][INFO] - Training Epoch: 1/2, step 5048/7134 completed (loss: 0.20867671072483063, acc: 0.9642857313156128)
[2024-12-17 02:05:04,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:04,751][root][INFO] - Training Epoch: 1/2, step 5049/7134 completed (loss: 0.531786322593689, acc: 0.8598726391792297)
[2024-12-17 02:05:04,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:05,041][root][INFO] - Training Epoch: 1/2, step 5050/7134 completed (loss: 0.3856206238269806, acc: 0.90625)
[2024-12-17 02:05:05,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:05,330][root][INFO] - Training Epoch: 1/2, step 5051/7134 completed (loss: 0.5807666778564453, acc: 0.884353756904602)
[2024-12-17 02:05:05,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:05,609][root][INFO] - Training Epoch: 1/2, step 5052/7134 completed (loss: 0.341007262468338, acc: 0.9358974099159241)
[2024-12-17 02:05:05,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:05,896][root][INFO] - Training Epoch: 1/2, step 5053/7134 completed (loss: 0.5301506519317627, acc: 0.9166666865348816)
[2024-12-17 02:05:06,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:06,191][root][INFO] - Training Epoch: 1/2, step 5054/7134 completed (loss: 0.3336145877838135, acc: 0.9037036895751953)
[2024-12-17 02:05:06,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:06,477][root][INFO] - Training Epoch: 1/2, step 5055/7134 completed (loss: 0.4142962098121643, acc: 0.9115044474601746)
[2024-12-17 02:05:06,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:06,759][root][INFO] - Training Epoch: 1/2, step 5056/7134 completed (loss: 0.3754943311214447, acc: 0.9127516746520996)
[2024-12-17 02:05:06,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:07,046][root][INFO] - Training Epoch: 1/2, step 5057/7134 completed (loss: 0.5428186655044556, acc: 0.8726114630699158)
[2024-12-17 02:05:07,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:07,368][root][INFO] - Training Epoch: 1/2, step 5058/7134 completed (loss: 0.28201258182525635, acc: 0.9390243887901306)
[2024-12-17 02:05:07,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:07,671][root][INFO] - Training Epoch: 1/2, step 5059/7134 completed (loss: 0.34968310594558716, acc: 0.910179615020752)
[2024-12-17 02:05:07,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:07,971][root][INFO] - Training Epoch: 1/2, step 5060/7134 completed (loss: 0.17796100676059723, acc: 0.9399999976158142)
[2024-12-17 02:05:08,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:08,244][root][INFO] - Training Epoch: 1/2, step 5061/7134 completed (loss: 0.40347427129745483, acc: 0.8761904835700989)
[2024-12-17 02:05:08,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:08,531][root][INFO] - Training Epoch: 1/2, step 5062/7134 completed (loss: 0.29701313376426697, acc: 0.9185185432434082)
[2024-12-17 02:05:08,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:08,821][root][INFO] - Training Epoch: 1/2, step 5063/7134 completed (loss: 0.2326505482196808, acc: 0.9370629191398621)
[2024-12-17 02:05:08,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:09,104][root][INFO] - Training Epoch: 1/2, step 5064/7134 completed (loss: 0.24721172451972961, acc: 0.9428571462631226)
[2024-12-17 02:05:09,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:09,396][root][INFO] - Training Epoch: 1/2, step 5065/7134 completed (loss: 0.36321163177490234, acc: 0.9182389974594116)
[2024-12-17 02:05:09,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:09,672][root][INFO] - Training Epoch: 1/2, step 5066/7134 completed (loss: 0.30703842639923096, acc: 0.9103448390960693)
[2024-12-17 02:05:09,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:09,953][root][INFO] - Training Epoch: 1/2, step 5067/7134 completed (loss: 0.20453870296478271, acc: 0.9262295365333557)
[2024-12-17 02:05:10,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:10,258][root][INFO] - Training Epoch: 1/2, step 5068/7134 completed (loss: 0.29482874274253845, acc: 0.922535240650177)
[2024-12-17 02:05:10,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:10,582][root][INFO] - Training Epoch: 1/2, step 5069/7134 completed (loss: 0.15647682547569275, acc: 0.9729729890823364)
[2024-12-17 02:05:10,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:10,869][root][INFO] - Training Epoch: 1/2, step 5070/7134 completed (loss: 0.10569529235363007, acc: 0.9878048896789551)
[2024-12-17 02:05:10,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:11,145][root][INFO] - Training Epoch: 1/2, step 5071/7134 completed (loss: 0.36091962456703186, acc: 0.9176470637321472)
[2024-12-17 02:05:11,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:11,428][root][INFO] - Training Epoch: 1/2, step 5072/7134 completed (loss: 0.40816324949264526, acc: 0.906593382358551)
[2024-12-17 02:05:11,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:11,715][root][INFO] - Training Epoch: 1/2, step 5073/7134 completed (loss: 0.3220938444137573, acc: 0.9160305261611938)
[2024-12-17 02:05:11,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:12,002][root][INFO] - Training Epoch: 1/2, step 5074/7134 completed (loss: 0.34301596879959106, acc: 0.930232584476471)
[2024-12-17 02:05:12,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:12,280][root][INFO] - Training Epoch: 1/2, step 5075/7134 completed (loss: 0.46069633960723877, acc: 0.904347836971283)
[2024-12-17 02:05:12,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:12,573][root][INFO] - Training Epoch: 1/2, step 5076/7134 completed (loss: 0.30601656436920166, acc: 0.9086021780967712)
[2024-12-17 02:05:12,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:12,860][root][INFO] - Training Epoch: 1/2, step 5077/7134 completed (loss: 0.23682630062103271, acc: 0.9485294222831726)
[2024-12-17 02:05:12,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:13,155][root][INFO] - Training Epoch: 1/2, step 5078/7134 completed (loss: 0.542808473110199, acc: 0.8666666746139526)
[2024-12-17 02:05:13,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:13,459][root][INFO] - Training Epoch: 1/2, step 5079/7134 completed (loss: 0.22873461246490479, acc: 0.9388889074325562)
[2024-12-17 02:05:13,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:13,754][root][INFO] - Training Epoch: 1/2, step 5080/7134 completed (loss: 0.1614968329668045, acc: 0.9460784196853638)
[2024-12-17 02:05:13,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:14,041][root][INFO] - Training Epoch: 1/2, step 5081/7134 completed (loss: 0.18766693770885468, acc: 0.9537572264671326)
[2024-12-17 02:05:14,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:14,348][root][INFO] - Training Epoch: 1/2, step 5082/7134 completed (loss: 0.19072917103767395, acc: 0.951724112033844)
[2024-12-17 02:05:14,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:14,658][root][INFO] - Training Epoch: 1/2, step 5083/7134 completed (loss: 0.27405846118927, acc: 0.9467455744743347)
[2024-12-17 02:05:14,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:14,979][root][INFO] - Training Epoch: 1/2, step 5084/7134 completed (loss: 0.20506370067596436, acc: 0.9504950642585754)
[2024-12-17 02:05:15,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:15,298][root][INFO] - Training Epoch: 1/2, step 5085/7134 completed (loss: 0.3134479820728302, acc: 0.938144326210022)
[2024-12-17 02:05:15,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:15,572][root][INFO] - Training Epoch: 1/2, step 5086/7134 completed (loss: 0.19760575890541077, acc: 0.9337016344070435)
[2024-12-17 02:05:15,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:15,853][root][INFO] - Training Epoch: 1/2, step 5087/7134 completed (loss: 0.2597782611846924, acc: 0.9405405521392822)
[2024-12-17 02:05:15,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:16,141][root][INFO] - Training Epoch: 1/2, step 5088/7134 completed (loss: 0.10300609469413757, acc: 0.9881656765937805)
[2024-12-17 02:05:16,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:16,423][root][INFO] - Training Epoch: 1/2, step 5089/7134 completed (loss: 0.17307770252227783, acc: 0.9642857313156128)
[2024-12-17 02:05:16,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:16,715][root][INFO] - Training Epoch: 1/2, step 5090/7134 completed (loss: 0.1491013616323471, acc: 0.9611650705337524)
[2024-12-17 02:05:16,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:17,012][root][INFO] - Training Epoch: 1/2, step 5091/7134 completed (loss: 0.2173699587583542, acc: 0.9450549483299255)
[2024-12-17 02:05:17,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:17,303][root][INFO] - Training Epoch: 1/2, step 5092/7134 completed (loss: 0.1854289025068283, acc: 0.967391312122345)
[2024-12-17 02:05:17,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:17,587][root][INFO] - Training Epoch: 1/2, step 5093/7134 completed (loss: 0.15869511663913727, acc: 0.9602272510528564)
[2024-12-17 02:05:17,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:17,887][root][INFO] - Training Epoch: 1/2, step 5094/7134 completed (loss: 0.1886383295059204, acc: 0.9461538195610046)
[2024-12-17 02:05:18,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:18,159][root][INFO] - Training Epoch: 1/2, step 5095/7134 completed (loss: 0.3581385612487793, acc: 0.9426751732826233)
[2024-12-17 02:05:18,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:18,445][root][INFO] - Training Epoch: 1/2, step 5096/7134 completed (loss: 0.26884737610816956, acc: 0.9468085169792175)
[2024-12-17 02:05:18,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:18,726][root][INFO] - Training Epoch: 1/2, step 5097/7134 completed (loss: 0.23880955576896667, acc: 0.9518716335296631)
[2024-12-17 02:05:18,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:19,011][root][INFO] - Training Epoch: 1/2, step 5098/7134 completed (loss: 0.3237402141094208, acc: 0.9336734414100647)
[2024-12-17 02:05:19,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:19,336][root][INFO] - Training Epoch: 1/2, step 5099/7134 completed (loss: 0.25952884554862976, acc: 0.9312169551849365)
[2024-12-17 02:05:19,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:19,640][root][INFO] - Training Epoch: 1/2, step 5100/7134 completed (loss: 0.24972473084926605, acc: 0.9313725233078003)
[2024-12-17 02:05:19,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:19,921][root][INFO] - Training Epoch: 1/2, step 5101/7134 completed (loss: 0.19273130595684052, acc: 0.9424083828926086)
[2024-12-17 02:05:20,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:20,212][root][INFO] - Training Epoch: 1/2, step 5102/7134 completed (loss: 0.22902269661426544, acc: 0.9268292784690857)
[2024-12-17 02:05:20,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:20,535][root][INFO] - Training Epoch: 1/2, step 5103/7134 completed (loss: 0.2325131595134735, acc: 0.9571428298950195)
[2024-12-17 02:05:20,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:20,836][root][INFO] - Training Epoch: 1/2, step 5104/7134 completed (loss: 0.20218925178050995, acc: 0.9526315927505493)
[2024-12-17 02:05:20,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:21,105][root][INFO] - Training Epoch: 1/2, step 5105/7134 completed (loss: 0.307687371969223, acc: 0.9337748289108276)
[2024-12-17 02:05:21,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:21,383][root][INFO] - Training Epoch: 1/2, step 5106/7134 completed (loss: 0.4166277348995209, acc: 0.8767123222351074)
[2024-12-17 02:05:21,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:21,662][root][INFO] - Training Epoch: 1/2, step 5107/7134 completed (loss: 0.7354053854942322, acc: 0.8163265585899353)
[2024-12-17 02:05:21,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:21,952][root][INFO] - Training Epoch: 1/2, step 5108/7134 completed (loss: 0.7848631739616394, acc: 0.8226950168609619)
[2024-12-17 02:05:22,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:22,248][root][INFO] - Training Epoch: 1/2, step 5109/7134 completed (loss: 0.7901924848556519, acc: 0.8241205811500549)
[2024-12-17 02:05:22,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:22,530][root][INFO] - Training Epoch: 1/2, step 5110/7134 completed (loss: 0.5473051071166992, acc: 0.8681318759918213)
[2024-12-17 02:05:22,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:22,814][root][INFO] - Training Epoch: 1/2, step 5111/7134 completed (loss: 0.3086433708667755, acc: 0.9137930870056152)
[2024-12-17 02:05:22,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:23,100][root][INFO] - Training Epoch: 1/2, step 5112/7134 completed (loss: 0.31655484437942505, acc: 0.9135135412216187)
[2024-12-17 02:05:23,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:23,391][root][INFO] - Training Epoch: 1/2, step 5113/7134 completed (loss: 0.4409695565700531, acc: 0.887417197227478)
[2024-12-17 02:05:23,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:23,685][root][INFO] - Training Epoch: 1/2, step 5114/7134 completed (loss: 0.27053359150886536, acc: 0.9470198750495911)
[2024-12-17 02:05:23,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:24,017][root][INFO] - Training Epoch: 1/2, step 5115/7134 completed (loss: 0.22137980163097382, acc: 0.9417989253997803)
[2024-12-17 02:05:24,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:24,314][root][INFO] - Training Epoch: 1/2, step 5116/7134 completed (loss: 0.28153008222579956, acc: 0.9259259104728699)
[2024-12-17 02:05:24,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:24,600][root][INFO] - Training Epoch: 1/2, step 5117/7134 completed (loss: 0.24273782968521118, acc: 0.9447513818740845)
[2024-12-17 02:05:24,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:24,868][root][INFO] - Training Epoch: 1/2, step 5118/7134 completed (loss: 0.34870341420173645, acc: 0.9156626462936401)
[2024-12-17 02:05:25,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:25,162][root][INFO] - Training Epoch: 1/2, step 5119/7134 completed (loss: 0.2862967848777771, acc: 0.931034505367279)
[2024-12-17 02:05:25,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:25,436][root][INFO] - Training Epoch: 1/2, step 5120/7134 completed (loss: 0.3264077603816986, acc: 0.9312169551849365)
[2024-12-17 02:05:25,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:25,726][root][INFO] - Training Epoch: 1/2, step 5121/7134 completed (loss: 0.11459733545780182, acc: 0.9878787994384766)
[2024-12-17 02:05:25,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:26,049][root][INFO] - Training Epoch: 1/2, step 5122/7134 completed (loss: 0.29905402660369873, acc: 0.9127907156944275)
[2024-12-17 02:05:26,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:26,346][root][INFO] - Training Epoch: 1/2, step 5123/7134 completed (loss: 0.16774509847164154, acc: 0.9702970385551453)
[2024-12-17 02:05:26,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:26,627][root][INFO] - Training Epoch: 1/2, step 5124/7134 completed (loss: 0.28152239322662354, acc: 0.9261083602905273)
[2024-12-17 02:05:26,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:26,919][root][INFO] - Training Epoch: 1/2, step 5125/7134 completed (loss: 0.13098499178886414, acc: 0.9869281053543091)
[2024-12-17 02:05:27,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:27,202][root][INFO] - Training Epoch: 1/2, step 5126/7134 completed (loss: 0.24667949974536896, acc: 0.951724112033844)
[2024-12-17 02:05:27,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:27,482][root][INFO] - Training Epoch: 1/2, step 5127/7134 completed (loss: 0.3515723943710327, acc: 0.8965517282485962)
[2024-12-17 02:05:27,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:27,769][root][INFO] - Training Epoch: 1/2, step 5128/7134 completed (loss: 0.2146853804588318, acc: 0.943965494632721)
[2024-12-17 02:05:27,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:28,054][root][INFO] - Training Epoch: 1/2, step 5129/7134 completed (loss: 0.3920707702636719, acc: 0.9224806427955627)
[2024-12-17 02:05:28,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:28,354][root][INFO] - Training Epoch: 1/2, step 5130/7134 completed (loss: 0.24152560532093048, acc: 0.9545454382896423)
[2024-12-17 02:05:28,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:28,638][root][INFO] - Training Epoch: 1/2, step 5131/7134 completed (loss: 0.37381353974342346, acc: 0.9166666865348816)
[2024-12-17 02:05:28,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:28,909][root][INFO] - Training Epoch: 1/2, step 5132/7134 completed (loss: 0.3179227113723755, acc: 0.921875)
[2024-12-17 02:05:29,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:29,187][root][INFO] - Training Epoch: 1/2, step 5133/7134 completed (loss: 0.4405980110168457, acc: 0.8719512224197388)
[2024-12-17 02:05:29,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:29,484][root][INFO] - Training Epoch: 1/2, step 5134/7134 completed (loss: 0.23681308329105377, acc: 0.9347826242446899)
[2024-12-17 02:05:29,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:29,795][root][INFO] - Training Epoch: 1/2, step 5135/7134 completed (loss: 0.3142952024936676, acc: 0.9710982441902161)
[2024-12-17 02:05:29,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:30,092][root][INFO] - Training Epoch: 1/2, step 5136/7134 completed (loss: 0.1505887508392334, acc: 0.9516128897666931)
[2024-12-17 02:05:30,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:30,417][root][INFO] - Training Epoch: 1/2, step 5137/7134 completed (loss: 0.34738484025001526, acc: 0.9275362491607666)
[2024-12-17 02:05:30,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:30,715][root][INFO] - Training Epoch: 1/2, step 5138/7134 completed (loss: 0.45126810669898987, acc: 0.936170220375061)
[2024-12-17 02:05:30,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:31,005][root][INFO] - Training Epoch: 1/2, step 5139/7134 completed (loss: 0.31936562061309814, acc: 0.9411764740943909)
[2024-12-17 02:05:31,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:31,293][root][INFO] - Training Epoch: 1/2, step 5140/7134 completed (loss: 0.3518126308917999, acc: 0.9083333611488342)
[2024-12-17 02:05:31,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:31,531][root][INFO] - Training Epoch: 1/2, step 5141/7134 completed (loss: 0.27254629135131836, acc: 0.9344262480735779)
[2024-12-17 02:05:31,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:31,823][root][INFO] - Training Epoch: 1/2, step 5142/7134 completed (loss: 0.2352675050497055, acc: 0.93034827709198)
[2024-12-17 02:05:31,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:32,108][root][INFO] - Training Epoch: 1/2, step 5143/7134 completed (loss: 0.27133098244667053, acc: 0.93034827709198)
[2024-12-17 02:05:32,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:32,392][root][INFO] - Training Epoch: 1/2, step 5144/7134 completed (loss: 0.21143724024295807, acc: 0.9629629850387573)
[2024-12-17 02:05:32,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:32,682][root][INFO] - Training Epoch: 1/2, step 5145/7134 completed (loss: 0.16635754704475403, acc: 0.984375)
[2024-12-17 02:05:32,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:32,970][root][INFO] - Training Epoch: 1/2, step 5146/7134 completed (loss: 0.37864089012145996, acc: 0.8907103538513184)
[2024-12-17 02:05:33,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:33,278][root][INFO] - Training Epoch: 1/2, step 5147/7134 completed (loss: 0.23683509230613708, acc: 0.9166666865348816)
[2024-12-17 02:05:33,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:33,567][root][INFO] - Training Epoch: 1/2, step 5148/7134 completed (loss: 0.3351503610610962, acc: 0.925000011920929)
[2024-12-17 02:05:33,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:33,863][root][INFO] - Training Epoch: 1/2, step 5149/7134 completed (loss: 0.33127066493034363, acc: 0.9140271544456482)
[2024-12-17 02:05:34,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:34,148][root][INFO] - Training Epoch: 1/2, step 5150/7134 completed (loss: 0.4059687554836273, acc: 0.9221556782722473)
[2024-12-17 02:05:34,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:34,431][root][INFO] - Training Epoch: 1/2, step 5151/7134 completed (loss: 0.5516814589500427, acc: 0.8857142925262451)
[2024-12-17 02:05:34,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:34,736][root][INFO] - Training Epoch: 1/2, step 5152/7134 completed (loss: 0.3028166592121124, acc: 0.9352940917015076)
[2024-12-17 02:05:34,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:35,034][root][INFO] - Training Epoch: 1/2, step 5153/7134 completed (loss: 0.37799838185310364, acc: 0.9215686321258545)
[2024-12-17 02:05:35,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:35,353][root][INFO] - Training Epoch: 1/2, step 5154/7134 completed (loss: 0.20783671736717224, acc: 0.9399999976158142)
[2024-12-17 02:05:35,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:35,694][root][INFO] - Training Epoch: 1/2, step 5155/7134 completed (loss: 0.5093874931335449, acc: 0.8978102207183838)
[2024-12-17 02:05:35,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:35,990][root][INFO] - Training Epoch: 1/2, step 5156/7134 completed (loss: 0.30015280842781067, acc: 0.9305555820465088)
[2024-12-17 02:05:36,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:36,268][root][INFO] - Training Epoch: 1/2, step 5157/7134 completed (loss: 0.3457406759262085, acc: 0.9204545617103577)
[2024-12-17 02:05:36,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:36,565][root][INFO] - Training Epoch: 1/2, step 5158/7134 completed (loss: 0.42320898175239563, acc: 0.9038461446762085)
[2024-12-17 02:05:36,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:36,857][root][INFO] - Training Epoch: 1/2, step 5159/7134 completed (loss: 0.3228330612182617, acc: 0.9242424368858337)
[2024-12-17 02:05:36,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:37,157][root][INFO] - Training Epoch: 1/2, step 5160/7134 completed (loss: 0.3490625023841858, acc: 0.9222221970558167)
[2024-12-17 02:05:37,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:37,443][root][INFO] - Training Epoch: 1/2, step 5161/7134 completed (loss: 0.47826987504959106, acc: 0.8870967626571655)
[2024-12-17 02:05:37,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:37,742][root][INFO] - Training Epoch: 1/2, step 5162/7134 completed (loss: 0.4007435739040375, acc: 0.8857142925262451)
[2024-12-17 02:05:37,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:38,021][root][INFO] - Training Epoch: 1/2, step 5163/7134 completed (loss: 0.22342140972614288, acc: 0.9408602118492126)
[2024-12-17 02:05:38,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:38,312][root][INFO] - Training Epoch: 1/2, step 5164/7134 completed (loss: 0.16695070266723633, acc: 0.9548386931419373)
[2024-12-17 02:05:38,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:38,627][root][INFO] - Training Epoch: 1/2, step 5165/7134 completed (loss: 0.27147379517555237, acc: 0.939393937587738)
[2024-12-17 02:05:38,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:38,932][root][INFO] - Training Epoch: 1/2, step 5166/7134 completed (loss: 0.36455753445625305, acc: 0.9012345671653748)
[2024-12-17 02:05:39,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:39,215][root][INFO] - Training Epoch: 1/2, step 5167/7134 completed (loss: 0.447944313287735, acc: 0.9060773253440857)
[2024-12-17 02:05:39,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:39,543][root][INFO] - Training Epoch: 1/2, step 5168/7134 completed (loss: 0.49681800603866577, acc: 0.8720930218696594)
[2024-12-17 02:05:39,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:39,824][root][INFO] - Training Epoch: 1/2, step 5169/7134 completed (loss: 0.3329678177833557, acc: 0.9329268336296082)
[2024-12-17 02:05:39,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:40,102][root][INFO] - Training Epoch: 1/2, step 5170/7134 completed (loss: 0.41535675525665283, acc: 0.9119170904159546)
[2024-12-17 02:05:40,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:40,384][root][INFO] - Training Epoch: 1/2, step 5171/7134 completed (loss: 0.23390966653823853, acc: 0.9512194991111755)
[2024-12-17 02:05:40,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:40,689][root][INFO] - Training Epoch: 1/2, step 5172/7134 completed (loss: 0.7432767748832703, acc: 0.8475610017776489)
[2024-12-17 02:05:40,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:40,966][root][INFO] - Training Epoch: 1/2, step 5173/7134 completed (loss: 0.383762389421463, acc: 0.9325153231620789)
[2024-12-17 02:05:41,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:41,266][root][INFO] - Training Epoch: 1/2, step 5174/7134 completed (loss: 0.16932061314582825, acc: 0.9479768872261047)
[2024-12-17 02:05:41,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:41,560][root][INFO] - Training Epoch: 1/2, step 5175/7134 completed (loss: 0.23524834215641022, acc: 0.9580838084220886)
[2024-12-17 02:05:41,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:41,850][root][INFO] - Training Epoch: 1/2, step 5176/7134 completed (loss: 0.2674313485622406, acc: 0.9144737124443054)
[2024-12-17 02:05:41,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:42,152][root][INFO] - Training Epoch: 1/2, step 5177/7134 completed (loss: 0.4162736237049103, acc: 0.9266666769981384)
[2024-12-17 02:05:42,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:42,458][root][INFO] - Training Epoch: 1/2, step 5178/7134 completed (loss: 0.5570621490478516, acc: 0.9200000166893005)
[2024-12-17 02:05:42,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:42,760][root][INFO] - Training Epoch: 1/2, step 5179/7134 completed (loss: 0.3786979913711548, acc: 0.9285714030265808)
[2024-12-17 02:05:42,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:43,060][root][INFO] - Training Epoch: 1/2, step 5180/7134 completed (loss: 0.43880605697631836, acc: 0.8936170339584351)
[2024-12-17 02:05:43,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:43,320][root][INFO] - Training Epoch: 1/2, step 5181/7134 completed (loss: 0.6600396633148193, acc: 0.8651685118675232)
[2024-12-17 02:05:43,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:43,653][root][INFO] - Training Epoch: 1/2, step 5182/7134 completed (loss: 1.0118765830993652, acc: 0.8188976645469666)
[2024-12-17 02:05:43,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:43,962][root][INFO] - Training Epoch: 1/2, step 5183/7134 completed (loss: 0.4130741059780121, acc: 0.9191176295280457)
[2024-12-17 02:05:44,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:44,271][root][INFO] - Training Epoch: 1/2, step 5184/7134 completed (loss: 0.27017539739608765, acc: 0.932692289352417)
[2024-12-17 02:05:44,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:44,578][root][INFO] - Training Epoch: 1/2, step 5185/7134 completed (loss: 0.23078122735023499, acc: 0.9603960514068604)
[2024-12-17 02:05:44,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:44,867][root][INFO] - Training Epoch: 1/2, step 5186/7134 completed (loss: 0.38412487506866455, acc: 0.9055117964744568)
[2024-12-17 02:05:44,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:45,156][root][INFO] - Training Epoch: 1/2, step 5187/7134 completed (loss: 0.16551661491394043, acc: 0.9760000109672546)
[2024-12-17 02:05:45,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:45,440][root][INFO] - Training Epoch: 1/2, step 5188/7134 completed (loss: 0.33939579129219055, acc: 0.9275362491607666)
[2024-12-17 02:05:45,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:45,724][root][INFO] - Training Epoch: 1/2, step 5189/7134 completed (loss: 0.40354862809181213, acc: 0.9009901285171509)
[2024-12-17 02:05:45,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:45,995][root][INFO] - Training Epoch: 1/2, step 5190/7134 completed (loss: 0.3406243622303009, acc: 0.9454545378684998)
[2024-12-17 02:05:46,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:46,292][root][INFO] - Training Epoch: 1/2, step 5191/7134 completed (loss: 0.4644102454185486, acc: 0.8888888955116272)
[2024-12-17 02:05:46,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:46,573][root][INFO] - Training Epoch: 1/2, step 5192/7134 completed (loss: 0.2869197726249695, acc: 0.9494949579238892)
[2024-12-17 02:05:46,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:46,845][root][INFO] - Training Epoch: 1/2, step 5193/7134 completed (loss: 0.26300927996635437, acc: 0.9583333134651184)
[2024-12-17 02:05:46,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:47,126][root][INFO] - Training Epoch: 1/2, step 5194/7134 completed (loss: 0.6993757486343384, acc: 0.8662420511245728)
[2024-12-17 02:05:47,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:47,373][root][INFO] - Training Epoch: 1/2, step 5195/7134 completed (loss: 0.4393322467803955, acc: 0.9259259104728699)
[2024-12-17 02:05:47,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:47,676][root][INFO] - Training Epoch: 1/2, step 5196/7134 completed (loss: 0.44220519065856934, acc: 0.9100000262260437)
[2024-12-17 02:05:47,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:47,957][root][INFO] - Training Epoch: 1/2, step 5197/7134 completed (loss: 0.34173688292503357, acc: 0.8888888955116272)
[2024-12-17 02:05:48,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:48,234][root][INFO] - Training Epoch: 1/2, step 5198/7134 completed (loss: 0.5939441323280334, acc: 0.868852436542511)
[2024-12-17 02:05:48,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:48,540][root][INFO] - Training Epoch: 1/2, step 5199/7134 completed (loss: 0.45770853757858276, acc: 0.8720930218696594)
[2024-12-17 02:05:48,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:48,829][root][INFO] - Training Epoch: 1/2, step 5200/7134 completed (loss: 0.22215373814105988, acc: 0.920634925365448)
[2024-12-17 02:05:48,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:49,147][root][INFO] - Training Epoch: 1/2, step 5201/7134 completed (loss: 0.36019226908683777, acc: 0.8985507488250732)
[2024-12-17 02:05:49,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:49,428][root][INFO] - Training Epoch: 1/2, step 5202/7134 completed (loss: 0.4153986871242523, acc: 0.890625)
[2024-12-17 02:05:49,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:49,708][root][INFO] - Training Epoch: 1/2, step 5203/7134 completed (loss: 0.2728464901447296, acc: 0.9395604133605957)
[2024-12-17 02:05:49,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:49,990][root][INFO] - Training Epoch: 1/2, step 5204/7134 completed (loss: 0.2733222544193268, acc: 0.9180327653884888)
[2024-12-17 02:05:50,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:50,258][root][INFO] - Training Epoch: 1/2, step 5205/7134 completed (loss: 0.27435436844825745, acc: 0.9036144614219666)
[2024-12-17 02:05:50,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:50,610][root][INFO] - Training Epoch: 1/2, step 5206/7134 completed (loss: 0.2541772425174713, acc: 0.9532163739204407)
[2024-12-17 02:05:50,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:50,905][root][INFO] - Training Epoch: 1/2, step 5207/7134 completed (loss: 0.5171326398849487, acc: 0.8809523582458496)
[2024-12-17 02:05:51,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:51,240][root][INFO] - Training Epoch: 1/2, step 5208/7134 completed (loss: 0.2181900292634964, acc: 0.9482758641242981)
[2024-12-17 02:05:51,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:51,557][root][INFO] - Training Epoch: 1/2, step 5209/7134 completed (loss: 0.3537265658378601, acc: 0.9172932505607605)
[2024-12-17 02:05:51,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:51,881][root][INFO] - Training Epoch: 1/2, step 5210/7134 completed (loss: 0.2252892255783081, acc: 0.9526627063751221)
[2024-12-17 02:05:52,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:52,191][root][INFO] - Training Epoch: 1/2, step 5211/7134 completed (loss: 0.35628554224967957, acc: 0.9365079402923584)
[2024-12-17 02:05:52,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:52,475][root][INFO] - Training Epoch: 1/2, step 5212/7134 completed (loss: 0.471369206905365, acc: 0.8831169009208679)
[2024-12-17 02:05:52,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:52,746][root][INFO] - Training Epoch: 1/2, step 5213/7134 completed (loss: 0.32039695978164673, acc: 0.9382715821266174)
[2024-12-17 02:05:52,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:53,011][root][INFO] - Training Epoch: 1/2, step 5214/7134 completed (loss: 0.47476962208747864, acc: 0.8991596698760986)
[2024-12-17 02:05:53,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:53,327][root][INFO] - Training Epoch: 1/2, step 5215/7134 completed (loss: 0.49249565601348877, acc: 0.9108911156654358)
[2024-12-17 02:05:53,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:53,591][root][INFO] - Training Epoch: 1/2, step 5216/7134 completed (loss: 0.4457917809486389, acc: 0.875)
[2024-12-17 02:05:53,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:53,859][root][INFO] - Training Epoch: 1/2, step 5217/7134 completed (loss: 0.6018627882003784, acc: 0.8804348111152649)
[2024-12-17 02:05:53,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:54,154][root][INFO] - Training Epoch: 1/2, step 5218/7134 completed (loss: 0.42896369099617004, acc: 0.9009901285171509)
[2024-12-17 02:05:54,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:54,448][root][INFO] - Training Epoch: 1/2, step 5219/7134 completed (loss: 0.45035794377326965, acc: 0.9259259104728699)
[2024-12-17 02:05:54,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:54,740][root][INFO] - Training Epoch: 1/2, step 5220/7134 completed (loss: 0.2528732120990753, acc: 0.9383561611175537)
[2024-12-17 02:05:54,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:55,046][root][INFO] - Training Epoch: 1/2, step 5221/7134 completed (loss: 0.2951168119907379, acc: 0.9382715821266174)
[2024-12-17 02:05:55,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:55,328][root][INFO] - Training Epoch: 1/2, step 5222/7134 completed (loss: 0.2625673711299896, acc: 0.9285714030265808)
[2024-12-17 02:05:55,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:55,621][root][INFO] - Training Epoch: 1/2, step 5223/7134 completed (loss: 0.13992440700531006, acc: 0.9646017551422119)
[2024-12-17 02:05:55,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:55,892][root][INFO] - Training Epoch: 1/2, step 5224/7134 completed (loss: 0.306781530380249, acc: 0.9259259104728699)
[2024-12-17 02:05:55,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:56,205][root][INFO] - Training Epoch: 1/2, step 5225/7134 completed (loss: 0.38262128829956055, acc: 0.9407894611358643)
[2024-12-17 02:05:56,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:56,489][root][INFO] - Training Epoch: 1/2, step 5226/7134 completed (loss: 0.4287790060043335, acc: 0.9358974099159241)
[2024-12-17 02:05:56,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:56,780][root][INFO] - Training Epoch: 1/2, step 5227/7134 completed (loss: 0.32164856791496277, acc: 0.9230769276618958)
[2024-12-17 02:05:56,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:57,052][root][INFO] - Training Epoch: 1/2, step 5228/7134 completed (loss: 0.2423265129327774, acc: 0.9085714221000671)
[2024-12-17 02:05:57,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:57,340][root][INFO] - Training Epoch: 1/2, step 5229/7134 completed (loss: 0.1616668999195099, acc: 0.9548386931419373)
[2024-12-17 02:05:57,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:57,661][root][INFO] - Training Epoch: 1/2, step 5230/7134 completed (loss: 0.2137112021446228, acc: 0.9558011293411255)
[2024-12-17 02:05:57,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:57,960][root][INFO] - Training Epoch: 1/2, step 5231/7134 completed (loss: 0.15084892511367798, acc: 0.9639175534248352)
[2024-12-17 02:05:58,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:58,262][root][INFO] - Training Epoch: 1/2, step 5232/7134 completed (loss: 0.18199162185192108, acc: 0.9604519605636597)
[2024-12-17 02:05:58,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:58,599][root][INFO] - Training Epoch: 1/2, step 5233/7134 completed (loss: 0.36155131459236145, acc: 0.9220183491706848)
[2024-12-17 02:05:58,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:58,915][root][INFO] - Training Epoch: 1/2, step 5234/7134 completed (loss: 0.19705773890018463, acc: 0.9631578922271729)
[2024-12-17 02:05:59,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:59,190][root][INFO] - Training Epoch: 1/2, step 5235/7134 completed (loss: 0.1010061502456665, acc: 0.9729729890823364)
[2024-12-17 02:05:59,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:59,496][root][INFO] - Training Epoch: 1/2, step 5236/7134 completed (loss: 0.16045676171779633, acc: 0.970802903175354)
[2024-12-17 02:05:59,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:59,813][root][INFO] - Training Epoch: 1/2, step 5237/7134 completed (loss: 0.14792212843894958, acc: 0.9647887349128723)
[2024-12-17 02:05:59,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:00,108][root][INFO] - Training Epoch: 1/2, step 5238/7134 completed (loss: 0.16962002217769623, acc: 0.9701492786407471)
[2024-12-17 02:06:00,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:00,399][root][INFO] - Training Epoch: 1/2, step 5239/7134 completed (loss: 0.36113518476486206, acc: 0.9159663915634155)
[2024-12-17 02:06:00,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:00,682][root][INFO] - Training Epoch: 1/2, step 5240/7134 completed (loss: 0.14817999303340912, acc: 0.9593023061752319)
[2024-12-17 02:06:00,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:00,971][root][INFO] - Training Epoch: 1/2, step 5241/7134 completed (loss: 0.34061792492866516, acc: 0.9161290526390076)
[2024-12-17 02:06:01,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:01,268][root][INFO] - Training Epoch: 1/2, step 5242/7134 completed (loss: 0.17644940316677094, acc: 0.9473684430122375)
[2024-12-17 02:06:01,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:01,546][root][INFO] - Training Epoch: 1/2, step 5243/7134 completed (loss: 0.1075095683336258, acc: 0.9714285731315613)
[2024-12-17 02:06:01,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:01,838][root][INFO] - Training Epoch: 1/2, step 5244/7134 completed (loss: 0.2402021437883377, acc: 0.9534883499145508)
[2024-12-17 02:06:02,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:02,203][root][INFO] - Training Epoch: 1/2, step 5245/7134 completed (loss: 0.25728705525398254, acc: 0.9365079402923584)
[2024-12-17 02:06:02,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:02,518][root][INFO] - Training Epoch: 1/2, step 5246/7134 completed (loss: 0.24090011417865753, acc: 0.9430379867553711)
[2024-12-17 02:06:02,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:02,806][root][INFO] - Training Epoch: 1/2, step 5247/7134 completed (loss: 0.3023783266544342, acc: 0.9185185432434082)
[2024-12-17 02:06:02,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:03,078][root][INFO] - Training Epoch: 1/2, step 5248/7134 completed (loss: 0.26124340295791626, acc: 0.9618320465087891)
[2024-12-17 02:06:03,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:03,375][root][INFO] - Training Epoch: 1/2, step 5249/7134 completed (loss: 0.19803543388843536, acc: 0.9554139971733093)
[2024-12-17 02:06:03,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:03,695][root][INFO] - Training Epoch: 1/2, step 5250/7134 completed (loss: 0.2296241819858551, acc: 0.95652174949646)
[2024-12-17 02:06:03,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:03,979][root][INFO] - Training Epoch: 1/2, step 5251/7134 completed (loss: 0.18645410239696503, acc: 0.9583333134651184)
[2024-12-17 02:06:04,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:04,256][root][INFO] - Training Epoch: 1/2, step 5252/7134 completed (loss: 0.30053627490997314, acc: 0.9292035102844238)
[2024-12-17 02:06:04,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:04,561][root][INFO] - Training Epoch: 1/2, step 5253/7134 completed (loss: 0.12101606279611588, acc: 0.9652777910232544)
[2024-12-17 02:06:04,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:04,851][root][INFO] - Training Epoch: 1/2, step 5254/7134 completed (loss: 0.42399460077285767, acc: 0.8881118893623352)
[2024-12-17 02:06:05,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:05,155][root][INFO] - Training Epoch: 1/2, step 5255/7134 completed (loss: 0.2844289541244507, acc: 0.931034505367279)
[2024-12-17 02:06:05,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:05,460][root][INFO] - Training Epoch: 1/2, step 5256/7134 completed (loss: 0.2925078570842743, acc: 0.9399999976158142)
[2024-12-17 02:06:05,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:05,794][root][INFO] - Training Epoch: 1/2, step 5257/7134 completed (loss: 0.5980582237243652, acc: 0.886227548122406)
[2024-12-17 02:06:05,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:06,095][root][INFO] - Training Epoch: 1/2, step 5258/7134 completed (loss: 0.33114421367645264, acc: 0.9153439402580261)
[2024-12-17 02:06:06,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:06,431][root][INFO] - Training Epoch: 1/2, step 5259/7134 completed (loss: 0.422892302274704, acc: 0.8920863270759583)
[2024-12-17 02:06:06,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:06,720][root][INFO] - Training Epoch: 1/2, step 5260/7134 completed (loss: 0.25703567266464233, acc: 0.9312169551849365)
[2024-12-17 02:06:06,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:07,002][root][INFO] - Training Epoch: 1/2, step 5261/7134 completed (loss: 0.40195465087890625, acc: 0.9160839319229126)
[2024-12-17 02:06:07,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:07,301][root][INFO] - Training Epoch: 1/2, step 5262/7134 completed (loss: 0.4049677550792694, acc: 0.9156626462936401)
[2024-12-17 02:06:07,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:07,581][root][INFO] - Training Epoch: 1/2, step 5263/7134 completed (loss: 0.3006729483604431, acc: 0.9507042169570923)
[2024-12-17 02:06:07,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:07,875][root][INFO] - Training Epoch: 1/2, step 5264/7134 completed (loss: 0.25795915722846985, acc: 0.9336734414100647)
[2024-12-17 02:06:07,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:08,190][root][INFO] - Training Epoch: 1/2, step 5265/7134 completed (loss: 0.30458202958106995, acc: 0.9180327653884888)
[2024-12-17 02:06:08,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:08,465][root][INFO] - Training Epoch: 1/2, step 5266/7134 completed (loss: 0.18435834348201752, acc: 0.9691358208656311)
[2024-12-17 02:06:08,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:08,738][root][INFO] - Training Epoch: 1/2, step 5267/7134 completed (loss: 0.518875241279602, acc: 0.8703703880310059)
[2024-12-17 02:06:08,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:09,061][root][INFO] - Training Epoch: 1/2, step 5268/7134 completed (loss: 0.5240005850791931, acc: 0.8682170510292053)
[2024-12-17 02:06:09,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:09,373][root][INFO] - Training Epoch: 1/2, step 5269/7134 completed (loss: 0.34505948424339294, acc: 0.9285714030265808)
[2024-12-17 02:06:09,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:09,673][root][INFO] - Training Epoch: 1/2, step 5270/7134 completed (loss: 0.42625510692596436, acc: 0.9137930870056152)
[2024-12-17 02:06:09,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:09,976][root][INFO] - Training Epoch: 1/2, step 5271/7134 completed (loss: 0.2582947015762329, acc: 0.9064748287200928)
[2024-12-17 02:06:10,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:10,258][root][INFO] - Training Epoch: 1/2, step 5272/7134 completed (loss: 0.272569477558136, acc: 0.9190751314163208)
[2024-12-17 02:06:10,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:10,547][root][INFO] - Training Epoch: 1/2, step 5273/7134 completed (loss: 0.295279860496521, acc: 0.9305555820465088)
[2024-12-17 02:06:10,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:10,833][root][INFO] - Training Epoch: 1/2, step 5274/7134 completed (loss: 0.39543387293815613, acc: 0.9230769276618958)
[2024-12-17 02:06:10,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:11,131][root][INFO] - Training Epoch: 1/2, step 5275/7134 completed (loss: 0.1433945894241333, acc: 0.9756097793579102)
[2024-12-17 02:06:11,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:11,430][root][INFO] - Training Epoch: 1/2, step 5276/7134 completed (loss: 0.38474366068840027, acc: 0.8947368264198303)
[2024-12-17 02:06:11,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:11,709][root][INFO] - Training Epoch: 1/2, step 5277/7134 completed (loss: 0.2631586790084839, acc: 0.9299362897872925)
[2024-12-17 02:06:11,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:12,033][root][INFO] - Training Epoch: 1/2, step 5278/7134 completed (loss: 0.5182337164878845, acc: 0.8848484754562378)
[2024-12-17 02:06:12,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:12,326][root][INFO] - Training Epoch: 1/2, step 5279/7134 completed (loss: 0.08753162622451782, acc: 0.9837398529052734)
[2024-12-17 02:06:12,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:12,608][root][INFO] - Training Epoch: 1/2, step 5280/7134 completed (loss: 0.34299999475479126, acc: 0.9142857193946838)
[2024-12-17 02:06:12,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:12,880][root][INFO] - Training Epoch: 1/2, step 5281/7134 completed (loss: 0.21841417253017426, acc: 0.95652174949646)
[2024-12-17 02:06:12,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:13,146][root][INFO] - Training Epoch: 1/2, step 5282/7134 completed (loss: 0.34065133333206177, acc: 0.9244186282157898)
[2024-12-17 02:06:13,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:13,418][root][INFO] - Training Epoch: 1/2, step 5283/7134 completed (loss: 0.21504315733909607, acc: 0.9344262480735779)
[2024-12-17 02:06:13,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:13,700][root][INFO] - Training Epoch: 1/2, step 5284/7134 completed (loss: 0.3330483138561249, acc: 0.9437500238418579)
[2024-12-17 02:06:13,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:13,991][root][INFO] - Training Epoch: 1/2, step 5285/7134 completed (loss: 0.27878329157829285, acc: 0.9408602118492126)
[2024-12-17 02:06:14,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:14,281][root][INFO] - Training Epoch: 1/2, step 5286/7134 completed (loss: 0.40542691946029663, acc: 0.9194630980491638)
[2024-12-17 02:06:14,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:14,564][root][INFO] - Training Epoch: 1/2, step 5287/7134 completed (loss: 0.2975408136844635, acc: 0.9444444179534912)
[2024-12-17 02:06:14,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:14,835][root][INFO] - Training Epoch: 1/2, step 5288/7134 completed (loss: 0.19184032082557678, acc: 0.949999988079071)
[2024-12-17 02:06:14,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:15,124][root][INFO] - Training Epoch: 1/2, step 5289/7134 completed (loss: 0.3116365075111389, acc: 0.9204545617103577)
[2024-12-17 02:06:15,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:15,412][root][INFO] - Training Epoch: 1/2, step 5290/7134 completed (loss: 0.4840061366558075, acc: 0.8994709253311157)
[2024-12-17 02:06:15,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:15,700][root][INFO] - Training Epoch: 1/2, step 5291/7134 completed (loss: 0.15266865491867065, acc: 0.9621621370315552)
[2024-12-17 02:06:15,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:16,011][root][INFO] - Training Epoch: 1/2, step 5292/7134 completed (loss: 0.1888643205165863, acc: 0.9491525292396545)
[2024-12-17 02:06:16,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:16,297][root][INFO] - Training Epoch: 1/2, step 5293/7134 completed (loss: 0.3047569692134857, acc: 0.9044585824012756)
[2024-12-17 02:06:16,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:16,574][root][INFO] - Training Epoch: 1/2, step 5294/7134 completed (loss: 0.29777950048446655, acc: 0.9112426042556763)
[2024-12-17 02:06:16,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:16,863][root][INFO] - Training Epoch: 1/2, step 5295/7134 completed (loss: 0.23662453889846802, acc: 0.9534883499145508)
[2024-12-17 02:06:16,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:17,157][root][INFO] - Training Epoch: 1/2, step 5296/7134 completed (loss: 0.16611622273921967, acc: 0.9604519605636597)
[2024-12-17 02:06:17,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:17,462][root][INFO] - Training Epoch: 1/2, step 5297/7134 completed (loss: 0.19936926662921906, acc: 0.9518072009086609)
[2024-12-17 02:06:17,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:17,825][root][INFO] - Training Epoch: 1/2, step 5298/7134 completed (loss: 0.2925374507904053, acc: 0.9432623982429504)
[2024-12-17 02:06:17,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:18,105][root][INFO] - Training Epoch: 1/2, step 5299/7134 completed (loss: 0.16870757937431335, acc: 0.9589040875434875)
[2024-12-17 02:06:18,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:18,383][root][INFO] - Training Epoch: 1/2, step 5300/7134 completed (loss: 0.16732801496982574, acc: 0.9638554453849792)
[2024-12-17 02:06:18,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:18,653][root][INFO] - Training Epoch: 1/2, step 5301/7134 completed (loss: 0.15020976960659027, acc: 0.9634146094322205)
[2024-12-17 02:06:18,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:18,941][root][INFO] - Training Epoch: 1/2, step 5302/7134 completed (loss: 0.3004896938800812, acc: 0.9273743033409119)
[2024-12-17 02:06:19,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:19,232][root][INFO] - Training Epoch: 1/2, step 5303/7134 completed (loss: 0.6189953088760376, acc: 0.8560606241226196)
[2024-12-17 02:06:19,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:19,516][root][INFO] - Training Epoch: 1/2, step 5304/7134 completed (loss: 0.6558141708374023, acc: 0.8904109597206116)
[2024-12-17 02:06:19,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:19,795][root][INFO] - Training Epoch: 1/2, step 5305/7134 completed (loss: 0.3762522339820862, acc: 0.90625)
[2024-12-17 02:06:19,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:20,071][root][INFO] - Training Epoch: 1/2, step 5306/7134 completed (loss: 0.21946509182453156, acc: 0.9388889074325562)
[2024-12-17 02:06:20,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:20,350][root][INFO] - Training Epoch: 1/2, step 5307/7134 completed (loss: 0.5528857707977295, acc: 0.8830409646034241)
[2024-12-17 02:06:20,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:20,619][root][INFO] - Training Epoch: 1/2, step 5308/7134 completed (loss: 0.3453371524810791, acc: 0.9135802388191223)
[2024-12-17 02:06:20,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:20,910][root][INFO] - Training Epoch: 1/2, step 5309/7134 completed (loss: 0.888847827911377, acc: 0.8181818127632141)
[2024-12-17 02:06:21,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:21,198][root][INFO] - Training Epoch: 1/2, step 5310/7134 completed (loss: 0.5601304173469543, acc: 0.8693181872367859)
[2024-12-17 02:06:21,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:21,490][root][INFO] - Training Epoch: 1/2, step 5311/7134 completed (loss: 0.6050280332565308, acc: 0.8695651888847351)
[2024-12-17 02:06:21,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:21,771][root][INFO] - Training Epoch: 1/2, step 5312/7134 completed (loss: 0.5121069550514221, acc: 0.8888888955116272)
[2024-12-17 02:06:21,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:22,058][root][INFO] - Training Epoch: 1/2, step 5313/7134 completed (loss: 0.2739053964614868, acc: 0.9426229596138)
[2024-12-17 02:06:22,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:22,331][root][INFO] - Training Epoch: 1/2, step 5314/7134 completed (loss: 0.32882657647132874, acc: 0.9142857193946838)
[2024-12-17 02:06:22,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:22,653][root][INFO] - Training Epoch: 1/2, step 5315/7134 completed (loss: 0.18895894289016724, acc: 0.9568345546722412)
[2024-12-17 02:06:22,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:22,929][root][INFO] - Training Epoch: 1/2, step 5316/7134 completed (loss: 0.2720477879047394, acc: 0.9266666769981384)
[2024-12-17 02:06:23,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:23,194][root][INFO] - Training Epoch: 1/2, step 5317/7134 completed (loss: 0.27546969056129456, acc: 0.9365079402923584)
[2024-12-17 02:06:23,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:23,460][root][INFO] - Training Epoch: 1/2, step 5318/7134 completed (loss: 0.12927758693695068, acc: 0.9554139971733093)
[2024-12-17 02:06:23,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:23,752][root][INFO] - Training Epoch: 1/2, step 5319/7134 completed (loss: 0.3561651110649109, acc: 0.902255654335022)
[2024-12-17 02:06:23,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:24,050][root][INFO] - Training Epoch: 1/2, step 5320/7134 completed (loss: 0.38807663321495056, acc: 0.9056603908538818)
[2024-12-17 02:06:24,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:24,363][root][INFO] - Training Epoch: 1/2, step 5321/7134 completed (loss: 0.3668876588344574, acc: 0.9285714030265808)
[2024-12-17 02:06:24,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:24,650][root][INFO] - Training Epoch: 1/2, step 5322/7134 completed (loss: 0.27416273951530457, acc: 0.9266666769981384)
[2024-12-17 02:06:24,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:24,939][root][INFO] - Training Epoch: 1/2, step 5323/7134 completed (loss: 0.44738563895225525, acc: 0.8791946172714233)
[2024-12-17 02:06:25,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:25,239][root][INFO] - Training Epoch: 1/2, step 5324/7134 completed (loss: 0.2652982771396637, acc: 0.9407894611358643)
[2024-12-17 02:06:25,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:25,542][root][INFO] - Training Epoch: 1/2, step 5325/7134 completed (loss: 0.2586185336112976, acc: 0.9202898740768433)
[2024-12-17 02:06:25,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:25,835][root][INFO] - Training Epoch: 1/2, step 5326/7134 completed (loss: 0.36710411310195923, acc: 0.9034482836723328)
[2024-12-17 02:06:25,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:26,107][root][INFO] - Training Epoch: 1/2, step 5327/7134 completed (loss: 0.3140384554862976, acc: 0.896774172782898)
[2024-12-17 02:06:26,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:26,375][root][INFO] - Training Epoch: 1/2, step 5328/7134 completed (loss: 0.3393884301185608, acc: 0.9248120188713074)
[2024-12-17 02:06:26,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:26,656][root][INFO] - Training Epoch: 1/2, step 5329/7134 completed (loss: 0.28249576687812805, acc: 0.9133333563804626)
[2024-12-17 02:06:26,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:26,934][root][INFO] - Training Epoch: 1/2, step 5330/7134 completed (loss: 0.3196514844894409, acc: 0.9303797483444214)
[2024-12-17 02:06:27,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:27,222][root][INFO] - Training Epoch: 1/2, step 5331/7134 completed (loss: 0.3317081332206726, acc: 0.9259259104728699)
[2024-12-17 02:06:27,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:27,534][root][INFO] - Training Epoch: 1/2, step 5332/7134 completed (loss: 0.27865883708000183, acc: 0.9246575236320496)
[2024-12-17 02:06:27,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:27,794][root][INFO] - Training Epoch: 1/2, step 5333/7134 completed (loss: 0.23009271919727325, acc: 0.9473684430122375)
[2024-12-17 02:06:27,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:28,075][root][INFO] - Training Epoch: 1/2, step 5334/7134 completed (loss: 0.4621852934360504, acc: 0.8928571343421936)
[2024-12-17 02:06:28,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:28,365][root][INFO] - Training Epoch: 1/2, step 5335/7134 completed (loss: 0.26068058609962463, acc: 0.9328858852386475)
[2024-12-17 02:06:28,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:28,654][root][INFO] - Training Epoch: 1/2, step 5336/7134 completed (loss: 0.3102513551712036, acc: 0.9295774698257446)
[2024-12-17 02:06:28,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:28,954][root][INFO] - Training Epoch: 1/2, step 5337/7134 completed (loss: 0.3612247705459595, acc: 0.9205607771873474)
[2024-12-17 02:06:29,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:29,252][root][INFO] - Training Epoch: 1/2, step 5338/7134 completed (loss: 0.19210322201251984, acc: 0.9620853066444397)
[2024-12-17 02:06:29,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:29,505][root][INFO] - Training Epoch: 1/2, step 5339/7134 completed (loss: 0.45053914189338684, acc: 0.9175823926925659)
[2024-12-17 02:06:29,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:29,788][root][INFO] - Training Epoch: 1/2, step 5340/7134 completed (loss: 0.42008692026138306, acc: 0.8791946172714233)
[2024-12-17 02:06:29,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:30,053][root][INFO] - Training Epoch: 1/2, step 5341/7134 completed (loss: 0.2624557614326477, acc: 0.925000011920929)
[2024-12-17 02:06:30,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:30,344][root][INFO] - Training Epoch: 1/2, step 5342/7134 completed (loss: 0.5802261829376221, acc: 0.8631578683853149)
[2024-12-17 02:06:30,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:30,627][root][INFO] - Training Epoch: 1/2, step 5343/7134 completed (loss: 0.44374367594718933, acc: 0.8648648858070374)
[2024-12-17 02:06:30,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:30,926][root][INFO] - Training Epoch: 1/2, step 5344/7134 completed (loss: 0.37098178267478943, acc: 0.9035087823867798)
[2024-12-17 02:06:31,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:31,204][root][INFO] - Training Epoch: 1/2, step 5345/7134 completed (loss: 0.32826507091522217, acc: 0.9040403962135315)
[2024-12-17 02:06:31,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:31,479][root][INFO] - Training Epoch: 1/2, step 5346/7134 completed (loss: 0.3903953433036804, acc: 0.89449542760849)
[2024-12-17 02:06:31,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:31,770][root][INFO] - Training Epoch: 1/2, step 5347/7134 completed (loss: 0.33063989877700806, acc: 0.9354838728904724)
[2024-12-17 02:06:31,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:32,062][root][INFO] - Training Epoch: 1/2, step 5348/7134 completed (loss: 0.42960795760154724, acc: 0.8975903391838074)
[2024-12-17 02:06:32,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:33,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:33,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:33,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:34,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:34,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:34,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:34,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:35,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:35,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:35,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:36,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:36,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:36,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:36,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:37,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:37,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:37,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:38,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:38,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:38,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:39,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:39,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:39,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:39,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:40,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:40,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:40,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:41,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:41,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:41,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:42,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:42,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:42,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:42,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:43,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:43,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:43,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:43,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:44,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:44,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:44,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:45,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:45,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:45,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:46,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:46,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:47,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:47,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:47,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:48,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:48,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:48,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:49,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:49,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:49,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:50,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:50,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:50,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:50,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:51,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:51,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:51,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:51,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:52,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:52,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:52,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:52,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:53,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:53,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:53,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:54,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:54,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:54,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:54,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:55,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:55,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:55,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:56,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:56,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:56,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:57,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:57,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:57,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:57,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:58,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:58,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:58,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:58,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:59,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:59,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:59,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:00,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:00,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:00,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:00,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:01,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:01,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:01,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:02,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:02,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:02,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:03,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:03,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:03,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:03,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:04,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:04,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:04,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:05,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:05,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:05,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:05,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:06,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:06,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:06,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:06,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:07,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:07,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:07,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:07,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:08,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:08,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:08,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:09,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:09,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:09,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:10,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:10,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:10,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:10,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:11,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:11,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:11,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:12,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:12,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:12,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:13,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:13,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:13,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:14,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:14,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:14,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:15,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:15,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:15,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:16,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:16,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:16,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:17,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:17,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:17,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:18,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:18,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:18,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:19,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:19,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:19,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:20,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:20,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:20,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:21,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:21,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:21,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:22,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:22,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:22,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:23,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:23,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:23,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:23,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:24,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:24,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:24,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:25,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:25,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:25,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:26,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:26,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:26,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:27,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:27,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:27,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:27,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:28,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:28,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:28,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:28,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:29,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:29,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:29,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:30,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:30,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:30,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:31,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:31,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:31,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:31,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:32,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:32,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:32,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:33,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:33,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:33,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:34,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:34,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:34,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:34,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:35,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:35,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:35,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:36,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:36,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:36,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:37,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:37,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:37,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:37,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:38,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:38,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:38,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:39,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:39,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:39,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:40,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:40,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:40,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:40,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:41,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:41,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:41,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:41,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:42,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:42,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:42,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:43,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:43,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:43,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:44,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:44,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:44,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:44,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:45,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:45,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:45,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:46,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:46,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:47,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:47,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:47,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:48,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:48,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:48,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:49,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:49,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:49,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:50,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:50,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:50,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:50,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:51,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:51,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:51,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:52,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:52,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:52,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:53,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:53,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:53,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:53,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:54,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:54,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:54,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:55,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:55,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:55,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:56,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:56,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:56,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:57,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:57,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:57,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:58,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:58,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:59,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:59,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:59,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:00,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:00,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:00,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:01,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:01,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:01,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:02,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:02,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:02,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:03,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:03,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:03,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:04,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:04,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:04,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:05,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:05,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:05,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:05,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:06,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:06,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:06,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:07,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:07,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:07,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:08,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:08,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:08,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:09,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:09,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:09,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:10,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:10,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:10,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:10,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:11,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:11,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:11,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:12,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:12,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:13,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:13,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:13,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:14,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:14,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:14,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:14,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:15,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:15,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:15,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:16,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:16,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:16,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:17,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:17,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:18,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:18,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:18,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:19,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:19,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:19,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:20,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:20,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:20,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:20,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:21,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:21,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:21,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:21,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:22,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:22,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:22,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:22,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:23,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:24,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:24,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:24,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:25,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:25,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:26,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:26,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:26,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:27,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:27,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:27,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:28,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:28,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:28,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:28,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:28,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:29,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:29,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:29,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:30,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:30,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:30,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:31,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:31,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:31,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:31,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:32,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:32,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:32,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:32,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:33,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:33,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:33,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:33,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:34,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:34,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:34,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:35,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:35,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:35,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:35,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:36,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:36,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:36,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:36,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:37,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:37,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:37,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:38,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:38,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:38,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:38,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:39,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:39,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:39,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:40,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:40,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:41,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:41,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:41,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:41,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:42,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:42,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:42,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:43,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:43,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:43,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:43,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:44,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:44,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:44,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:44,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:45,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:45,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:45,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:45,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:46,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:46,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:46,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:46,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:47,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:47,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:47,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:48,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:48,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:48,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:49,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:49,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:49,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:49,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:50,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:50,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:50,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:50,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:51,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:51,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:51,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:52,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:52,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:52,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:52,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:53,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:53,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:53,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:54,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:54,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:54,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:54,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:55,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:55,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:55,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:56,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:56,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:56,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:57,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:57,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:57,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:58,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:58,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:58,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:59,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:59,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:59,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:00,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:00,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:00,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:01,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:01,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:01,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:01,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:02,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:02,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:02,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:03,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:03,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:03,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:04,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:04,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:04,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:05,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:05,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:05,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:06,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:06,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:06,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:07,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:07,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:08,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:08,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:08,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:08,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:09,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:09,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:09,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:09,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:10,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:10,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:10,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:11,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:11,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:11,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:12,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:12,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:12,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:12,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:13,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:13,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:13,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:14,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:14,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:15,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:15,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:15,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:16,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:16,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:16,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:17,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:17,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:17,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:18,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:18,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:18,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:19,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:19,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:19,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:19,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:20,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:20,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:20,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:21,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:21,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:21,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:21,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:22,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:22,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:22,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:22,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:23,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:23,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:23,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:23,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:24,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:24,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:25,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:25,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:25,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:25,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:26,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:26,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:26,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:27,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:27,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:27,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:28,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:28,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:28,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:29,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:29,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:29,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:30,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:30,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:30,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:31,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:31,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:32,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:32,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:32,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:32,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:33,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:33,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:33,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:33,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:34,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:34,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:34,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:35,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:35,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:35,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:36,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:36,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:36,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:36,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:37,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:37,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:37,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:38,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:38,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:38,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:39,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:39,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:39,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:40,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:40,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:40,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:41,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:41,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:41,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:42,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:42,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:42,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:43,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:43,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:43,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:44,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:44,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:45,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:45,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:46,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:46,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:46,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:47,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:47,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:47,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:48,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:48,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:49,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:49,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:49,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:49,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:50,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:50,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:50,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:51,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:51,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:51,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:52,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:52,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:53,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:53,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:53,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:53,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:54,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:54,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:54,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:54,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:55,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:55,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:55,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:55,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:56,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:56,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:56,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:57,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:57,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:57,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:58,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:58,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:58,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:59,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:59,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:59,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:00,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:00,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:00,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:01,204][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.4449, device='cuda:0') eval_epoch_loss=tensor(0.3680, device='cuda:0') eval_epoch_acc=tensor(0.9133, device='cuda:0')
[2024-12-17 02:10:01,207][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-12-17 02:10:01,207][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 02:10:01,462][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_1_step_5349_loss_0.3680223822593689/model.pt
[2024-12-17 02:10:01,481][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 0.3680223822593689
[2024-12-17 02:10:01,482][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.9133220314979553
[2024-12-17 02:10:01,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:01,841][root][INFO] - Training Epoch: 1/2, step 5349/7134 completed (loss: 0.509971559047699, acc: 0.8742856979370117)
[2024-12-17 02:10:01,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:02,120][root][INFO] - Training Epoch: 1/2, step 5350/7134 completed (loss: 0.31452676653862, acc: 0.929411768913269)
[2024-12-17 02:10:02,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:02,407][root][INFO] - Training Epoch: 1/2, step 5351/7134 completed (loss: 0.34560132026672363, acc: 0.908108115196228)
[2024-12-17 02:10:02,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:02,692][root][INFO] - Training Epoch: 1/2, step 5352/7134 completed (loss: 0.29706740379333496, acc: 0.8922155499458313)
[2024-12-17 02:10:02,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:03,001][root][INFO] - Training Epoch: 1/2, step 5353/7134 completed (loss: 0.354843407869339, acc: 0.9090909361839294)
[2024-12-17 02:10:03,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:03,311][root][INFO] - Training Epoch: 1/2, step 5354/7134 completed (loss: 0.34796690940856934, acc: 0.9120370149612427)
[2024-12-17 02:10:03,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:03,616][root][INFO] - Training Epoch: 1/2, step 5355/7134 completed (loss: 0.4011947214603424, acc: 0.9010416865348816)
[2024-12-17 02:10:03,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:03,921][root][INFO] - Training Epoch: 1/2, step 5356/7134 completed (loss: 0.3987337350845337, acc: 0.8936170339584351)
[2024-12-17 02:10:04,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:04,213][root][INFO] - Training Epoch: 1/2, step 5357/7134 completed (loss: 0.3522554337978363, acc: 0.9078013896942139)
[2024-12-17 02:10:04,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:04,518][root][INFO] - Training Epoch: 1/2, step 5358/7134 completed (loss: 0.5552590489387512, acc: 0.8846153616905212)
[2024-12-17 02:10:04,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:04,809][root][INFO] - Training Epoch: 1/2, step 5359/7134 completed (loss: 0.23659412562847137, acc: 0.9408866763114929)
[2024-12-17 02:10:04,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:05,082][root][INFO] - Training Epoch: 1/2, step 5360/7134 completed (loss: 0.24513249099254608, acc: 0.9425287246704102)
[2024-12-17 02:10:05,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:05,365][root][INFO] - Training Epoch: 1/2, step 5361/7134 completed (loss: 0.45981040596961975, acc: 0.903553307056427)
[2024-12-17 02:10:05,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:05,644][root][INFO] - Training Epoch: 1/2, step 5362/7134 completed (loss: 0.5041122436523438, acc: 0.9189189076423645)
[2024-12-17 02:10:05,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:05,937][root][INFO] - Training Epoch: 1/2, step 5363/7134 completed (loss: 0.3924145996570587, acc: 0.8963414430618286)
[2024-12-17 02:10:06,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:06,228][root][INFO] - Training Epoch: 1/2, step 5364/7134 completed (loss: 0.31705936789512634, acc: 0.9248554706573486)
[2024-12-17 02:10:06,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:06,537][root][INFO] - Training Epoch: 1/2, step 5365/7134 completed (loss: 0.28041109442710876, acc: 0.9090909361839294)
[2024-12-17 02:10:06,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:06,815][root][INFO] - Training Epoch: 1/2, step 5366/7134 completed (loss: 0.421434223651886, acc: 0.9328358173370361)
[2024-12-17 02:10:06,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:07,119][root][INFO] - Training Epoch: 1/2, step 5367/7134 completed (loss: 0.30746737122535706, acc: 0.907608687877655)
[2024-12-17 02:10:07,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:07,417][root][INFO] - Training Epoch: 1/2, step 5368/7134 completed (loss: 0.4180736839771271, acc: 0.8992248177528381)
[2024-12-17 02:10:07,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:07,693][root][INFO] - Training Epoch: 1/2, step 5369/7134 completed (loss: 0.43275490403175354, acc: 0.9067796468734741)
[2024-12-17 02:10:07,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:07,983][root][INFO] - Training Epoch: 1/2, step 5370/7134 completed (loss: 0.3792223632335663, acc: 0.9155844449996948)
[2024-12-17 02:10:08,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:08,280][root][INFO] - Training Epoch: 1/2, step 5371/7134 completed (loss: 0.5418937802314758, acc: 0.8933333158493042)
[2024-12-17 02:10:08,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:08,556][root][INFO] - Training Epoch: 1/2, step 5372/7134 completed (loss: 0.15343846380710602, acc: 0.9622641801834106)
[2024-12-17 02:10:08,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:08,841][root][INFO] - Training Epoch: 1/2, step 5373/7134 completed (loss: 0.2571568489074707, acc: 0.9365079402923584)
[2024-12-17 02:10:08,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:09,073][root][INFO] - Training Epoch: 1/2, step 5374/7134 completed (loss: 0.2130204141139984, acc: 0.9404761791229248)
[2024-12-17 02:10:09,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:09,349][root][INFO] - Training Epoch: 1/2, step 5375/7134 completed (loss: 0.2375958263874054, acc: 0.9534883499145508)
[2024-12-17 02:10:09,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:09,618][root][INFO] - Training Epoch: 1/2, step 5376/7134 completed (loss: 0.16328835487365723, acc: 0.9527027010917664)
[2024-12-17 02:10:09,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:09,893][root][INFO] - Training Epoch: 1/2, step 5377/7134 completed (loss: 0.22170905768871307, acc: 0.9753086566925049)
[2024-12-17 02:10:09,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:10,169][root][INFO] - Training Epoch: 1/2, step 5378/7134 completed (loss: 0.14980268478393555, acc: 0.9578947424888611)
[2024-12-17 02:10:10,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:10,445][root][INFO] - Training Epoch: 1/2, step 5379/7134 completed (loss: 0.13111001253128052, acc: 0.9739583134651184)
[2024-12-17 02:10:10,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:10,718][root][INFO] - Training Epoch: 1/2, step 5380/7134 completed (loss: 0.17187908291816711, acc: 0.9629629850387573)
[2024-12-17 02:10:10,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:10,988][root][INFO] - Training Epoch: 1/2, step 5381/7134 completed (loss: 0.14541499316692352, acc: 0.9717513918876648)
[2024-12-17 02:10:11,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:11,248][root][INFO] - Training Epoch: 1/2, step 5382/7134 completed (loss: 0.11624453961849213, acc: 0.9855072498321533)
[2024-12-17 02:10:11,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:11,521][root][INFO] - Training Epoch: 1/2, step 5383/7134 completed (loss: 0.09047464281320572, acc: 0.9919354915618896)
[2024-12-17 02:10:11,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:11,814][root][INFO] - Training Epoch: 1/2, step 5384/7134 completed (loss: 0.15493033826351166, acc: 0.9492385983467102)
[2024-12-17 02:10:11,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:12,088][root][INFO] - Training Epoch: 1/2, step 5385/7134 completed (loss: 0.29376426339149475, acc: 0.9593023061752319)
[2024-12-17 02:10:12,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:12,366][root][INFO] - Training Epoch: 1/2, step 5386/7134 completed (loss: 0.12295031547546387, acc: 0.9560439586639404)
[2024-12-17 02:10:12,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:12,653][root][INFO] - Training Epoch: 1/2, step 5387/7134 completed (loss: 0.15381109714508057, acc: 0.9508196711540222)
[2024-12-17 02:10:12,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:12,936][root][INFO] - Training Epoch: 1/2, step 5388/7134 completed (loss: 0.16272740066051483, acc: 0.9720670580863953)
[2024-12-17 02:10:13,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:13,205][root][INFO] - Training Epoch: 1/2, step 5389/7134 completed (loss: 0.12413385510444641, acc: 0.9727891087532043)
[2024-12-17 02:10:13,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:13,486][root][INFO] - Training Epoch: 1/2, step 5390/7134 completed (loss: 0.4012662172317505, acc: 0.9371069073677063)
[2024-12-17 02:10:13,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:13,717][root][INFO] - Training Epoch: 1/2, step 5391/7134 completed (loss: 0.2347799688577652, acc: 0.9208633303642273)
[2024-12-17 02:10:13,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:13,985][root][INFO] - Training Epoch: 1/2, step 5392/7134 completed (loss: 0.3984983563423157, acc: 0.9090909361839294)
[2024-12-17 02:10:14,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:14,256][root][INFO] - Training Epoch: 1/2, step 5393/7134 completed (loss: 0.2733395993709564, acc: 0.9083333611488342)
[2024-12-17 02:10:14,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:14,529][root][INFO] - Training Epoch: 1/2, step 5394/7134 completed (loss: 0.6290433406829834, acc: 0.8671875)
[2024-12-17 02:10:14,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:14,804][root][INFO] - Training Epoch: 1/2, step 5395/7134 completed (loss: 0.1913866251707077, acc: 0.9391891956329346)
[2024-12-17 02:10:14,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:15,086][root][INFO] - Training Epoch: 1/2, step 5396/7134 completed (loss: 0.2694838047027588, acc: 0.9473684430122375)
[2024-12-17 02:10:15,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:15,363][root][INFO] - Training Epoch: 1/2, step 5397/7134 completed (loss: 0.19495706260204315, acc: 0.9432623982429504)
[2024-12-17 02:10:15,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:15,634][root][INFO] - Training Epoch: 1/2, step 5398/7134 completed (loss: 0.2430475354194641, acc: 0.9156626462936401)
[2024-12-17 02:10:15,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:15,911][root][INFO] - Training Epoch: 1/2, step 5399/7134 completed (loss: 0.23263061046600342, acc: 0.9314285516738892)
[2024-12-17 02:10:16,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:16,193][root][INFO] - Training Epoch: 1/2, step 5400/7134 completed (loss: 0.4147227704524994, acc: 0.931034505367279)
[2024-12-17 02:10:16,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:16,477][root][INFO] - Training Epoch: 1/2, step 5401/7134 completed (loss: 0.2690785527229309, acc: 0.9305555820465088)
[2024-12-17 02:10:16,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:16,749][root][INFO] - Training Epoch: 1/2, step 5402/7134 completed (loss: 0.4542194604873657, acc: 0.8904109597206116)
[2024-12-17 02:10:16,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:16,985][root][INFO] - Training Epoch: 1/2, step 5403/7134 completed (loss: 0.35752686858177185, acc: 0.8934426307678223)
[2024-12-17 02:10:17,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:17,260][root][INFO] - Training Epoch: 1/2, step 5404/7134 completed (loss: 0.6016229391098022, acc: 0.8926174640655518)
[2024-12-17 02:10:17,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:17,548][root][INFO] - Training Epoch: 1/2, step 5405/7134 completed (loss: 0.3146916627883911, acc: 0.9130434989929199)
[2024-12-17 02:10:17,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:17,822][root][INFO] - Training Epoch: 1/2, step 5406/7134 completed (loss: 0.32514238357543945, acc: 0.9099099040031433)
[2024-12-17 02:10:17,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:18,073][root][INFO] - Training Epoch: 1/2, step 5407/7134 completed (loss: 0.37905555963516235, acc: 0.9230769276618958)
[2024-12-17 02:10:18,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:18,347][root][INFO] - Training Epoch: 1/2, step 5408/7134 completed (loss: 0.4793291985988617, acc: 0.914893627166748)
[2024-12-17 02:10:18,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:18,619][root][INFO] - Training Epoch: 1/2, step 5409/7134 completed (loss: 0.46683016419410706, acc: 0.9090909361839294)
[2024-12-17 02:10:18,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:18,893][root][INFO] - Training Epoch: 1/2, step 5410/7134 completed (loss: 0.20601239800453186, acc: 0.9457831382751465)
[2024-12-17 02:10:18,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:19,149][root][INFO] - Training Epoch: 1/2, step 5411/7134 completed (loss: 0.5542051792144775, acc: 0.8802816867828369)
[2024-12-17 02:10:19,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:19,429][root][INFO] - Training Epoch: 1/2, step 5412/7134 completed (loss: 0.39143306016921997, acc: 0.9115044474601746)
[2024-12-17 02:10:19,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:19,714][root][INFO] - Training Epoch: 1/2, step 5413/7134 completed (loss: 0.6233673691749573, acc: 0.8472222089767456)
[2024-12-17 02:10:19,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:19,993][root][INFO] - Training Epoch: 1/2, step 5414/7134 completed (loss: 0.6216985583305359, acc: 0.8502994179725647)
[2024-12-17 02:10:20,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:20,259][root][INFO] - Training Epoch: 1/2, step 5415/7134 completed (loss: 0.5026161670684814, acc: 0.8896104097366333)
[2024-12-17 02:10:20,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:20,541][root][INFO] - Training Epoch: 1/2, step 5416/7134 completed (loss: 0.4748501777648926, acc: 0.8716577291488647)
[2024-12-17 02:10:20,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:20,816][root][INFO] - Training Epoch: 1/2, step 5417/7134 completed (loss: 0.31846868991851807, acc: 0.9166666865348816)
[2024-12-17 02:10:20,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:21,083][root][INFO] - Training Epoch: 1/2, step 5418/7134 completed (loss: 0.6090829968452454, acc: 0.8611111044883728)
[2024-12-17 02:10:21,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:21,356][root][INFO] - Training Epoch: 1/2, step 5419/7134 completed (loss: 0.7210725545883179, acc: 0.8248175382614136)
[2024-12-17 02:10:21,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:21,632][root][INFO] - Training Epoch: 1/2, step 5420/7134 completed (loss: 0.8410702347755432, acc: 0.8270676732063293)
[2024-12-17 02:10:21,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:21,904][root][INFO] - Training Epoch: 1/2, step 5421/7134 completed (loss: 0.695461094379425, acc: 0.8500000238418579)
[2024-12-17 02:10:21,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:22,178][root][INFO] - Training Epoch: 1/2, step 5422/7134 completed (loss: 0.37422093749046326, acc: 0.8819444179534912)
[2024-12-17 02:10:22,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:22,404][root][INFO] - Training Epoch: 1/2, step 5423/7134 completed (loss: 0.45470938086509705, acc: 0.887499988079071)
[2024-12-17 02:10:22,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:22,671][root][INFO] - Training Epoch: 1/2, step 5424/7134 completed (loss: 0.3746427297592163, acc: 0.892307698726654)
[2024-12-17 02:10:22,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:22,926][root][INFO] - Training Epoch: 1/2, step 5425/7134 completed (loss: 0.2950563430786133, acc: 0.9453125)
[2024-12-17 02:10:23,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:23,193][root][INFO] - Training Epoch: 1/2, step 5426/7134 completed (loss: 0.34059926867485046, acc: 0.9426229596138)
[2024-12-17 02:10:23,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:23,469][root][INFO] - Training Epoch: 1/2, step 5427/7134 completed (loss: 0.2719973027706146, acc: 0.9281045794487)
[2024-12-17 02:10:23,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:23,745][root][INFO] - Training Epoch: 1/2, step 5428/7134 completed (loss: 0.369221955537796, acc: 0.9103448390960693)
[2024-12-17 02:10:23,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:24,000][root][INFO] - Training Epoch: 1/2, step 5429/7134 completed (loss: 0.40819329023361206, acc: 0.899328887462616)
[2024-12-17 02:10:24,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:24,276][root][INFO] - Training Epoch: 1/2, step 5430/7134 completed (loss: 0.36933404207229614, acc: 0.9415584206581116)
[2024-12-17 02:10:24,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:24,539][root][INFO] - Training Epoch: 1/2, step 5431/7134 completed (loss: 0.3978400230407715, acc: 0.9097744226455688)
[2024-12-17 02:10:24,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:24,814][root][INFO] - Training Epoch: 1/2, step 5432/7134 completed (loss: 0.21593117713928223, acc: 0.9296875)
[2024-12-17 02:10:24,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:25,055][root][INFO] - Training Epoch: 1/2, step 5433/7134 completed (loss: 0.4457119107246399, acc: 0.8907563090324402)
[2024-12-17 02:10:25,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:25,320][root][INFO] - Training Epoch: 1/2, step 5434/7134 completed (loss: 0.4730461835861206, acc: 0.8870967626571655)
[2024-12-17 02:10:25,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:25,590][root][INFO] - Training Epoch: 1/2, step 5435/7134 completed (loss: 0.3171541094779968, acc: 0.9200000166893005)
[2024-12-17 02:10:25,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:25,855][root][INFO] - Training Epoch: 1/2, step 5436/7134 completed (loss: 0.29714125394821167, acc: 0.9290322661399841)
[2024-12-17 02:10:25,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:26,121][root][INFO] - Training Epoch: 1/2, step 5437/7134 completed (loss: 0.3014757037162781, acc: 0.9624060392379761)
[2024-12-17 02:10:26,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:26,400][root][INFO] - Training Epoch: 1/2, step 5438/7134 completed (loss: 0.3410501182079315, acc: 0.9222221970558167)
[2024-12-17 02:10:26,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:26,686][root][INFO] - Training Epoch: 1/2, step 5439/7134 completed (loss: 0.5973267555236816, acc: 0.8545454740524292)
[2024-12-17 02:10:26,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:26,966][root][INFO] - Training Epoch: 1/2, step 5440/7134 completed (loss: 0.315287321805954, acc: 0.9166666865348816)
[2024-12-17 02:10:27,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:27,238][root][INFO] - Training Epoch: 1/2, step 5441/7134 completed (loss: 0.363214373588562, acc: 0.9189189076423645)
[2024-12-17 02:10:27,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:27,515][root][INFO] - Training Epoch: 1/2, step 5442/7134 completed (loss: 0.22649061679840088, acc: 0.9285714030265808)
[2024-12-17 02:10:27,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:27,774][root][INFO] - Training Epoch: 1/2, step 5443/7134 completed (loss: 0.24721750617027283, acc: 0.9390243887901306)
[2024-12-17 02:10:27,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:28,056][root][INFO] - Training Epoch: 1/2, step 5444/7134 completed (loss: 0.2980152368545532, acc: 0.9264705777168274)
[2024-12-17 02:10:28,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:28,330][root][INFO] - Training Epoch: 1/2, step 5445/7134 completed (loss: 0.4242182970046997, acc: 0.904411792755127)
[2024-12-17 02:10:28,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:28,610][root][INFO] - Training Epoch: 1/2, step 5446/7134 completed (loss: 0.23035533726215363, acc: 0.9325153231620789)
[2024-12-17 02:10:28,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:28,870][root][INFO] - Training Epoch: 1/2, step 5447/7134 completed (loss: 0.3535066246986389, acc: 0.9109588861465454)
[2024-12-17 02:10:28,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:29,161][root][INFO] - Training Epoch: 1/2, step 5448/7134 completed (loss: 0.2950599491596222, acc: 0.9120879173278809)
[2024-12-17 02:10:29,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:29,427][root][INFO] - Training Epoch: 1/2, step 5449/7134 completed (loss: 0.39260271191596985, acc: 0.9016393423080444)
[2024-12-17 02:10:29,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:29,704][root][INFO] - Training Epoch: 1/2, step 5450/7134 completed (loss: 0.2605395019054413, acc: 0.9333333373069763)
[2024-12-17 02:10:29,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:29,976][root][INFO] - Training Epoch: 1/2, step 5451/7134 completed (loss: 0.2860345244407654, acc: 0.9408283829689026)
[2024-12-17 02:10:30,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:30,258][root][INFO] - Training Epoch: 1/2, step 5452/7134 completed (loss: 0.27503445744514465, acc: 0.9408283829689026)
[2024-12-17 02:10:30,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:30,537][root][INFO] - Training Epoch: 1/2, step 5453/7134 completed (loss: 0.42917048931121826, acc: 0.9111111164093018)
[2024-12-17 02:10:30,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:30,821][root][INFO] - Training Epoch: 1/2, step 5454/7134 completed (loss: 0.2954440116882324, acc: 0.9347826242446899)
[2024-12-17 02:10:30,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:31,121][root][INFO] - Training Epoch: 1/2, step 5455/7134 completed (loss: 0.33406782150268555, acc: 0.9251337051391602)
[2024-12-17 02:10:31,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:31,426][root][INFO] - Training Epoch: 1/2, step 5456/7134 completed (loss: 0.29928141832351685, acc: 0.9301075339317322)
[2024-12-17 02:10:31,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:31,722][root][INFO] - Training Epoch: 1/2, step 5457/7134 completed (loss: 0.3538537621498108, acc: 0.9080459475517273)
[2024-12-17 02:10:31,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:31,999][root][INFO] - Training Epoch: 1/2, step 5458/7134 completed (loss: 0.31974297761917114, acc: 0.9281768202781677)
[2024-12-17 02:10:32,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:32,272][root][INFO] - Training Epoch: 1/2, step 5459/7134 completed (loss: 0.0876297727227211, acc: 0.987730085849762)
[2024-12-17 02:10:32,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:32,541][root][INFO] - Training Epoch: 1/2, step 5460/7134 completed (loss: 0.19815760850906372, acc: 0.9526627063751221)
[2024-12-17 02:10:32,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:32,805][root][INFO] - Training Epoch: 1/2, step 5461/7134 completed (loss: 0.529873788356781, acc: 0.9174311757087708)
[2024-12-17 02:10:32,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:33,093][root][INFO] - Training Epoch: 1/2, step 5462/7134 completed (loss: 0.17603884637355804, acc: 0.9447852969169617)
[2024-12-17 02:10:33,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:33,371][root][INFO] - Training Epoch: 1/2, step 5463/7134 completed (loss: 0.33098068833351135, acc: 0.9320987462997437)
[2024-12-17 02:10:33,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:33,646][root][INFO] - Training Epoch: 1/2, step 5464/7134 completed (loss: 0.32303565740585327, acc: 0.9453551769256592)
[2024-12-17 02:10:33,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:33,941][root][INFO] - Training Epoch: 1/2, step 5465/7134 completed (loss: 0.15167266130447388, acc: 0.956250011920929)
[2024-12-17 02:10:34,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:34,246][root][INFO] - Training Epoch: 1/2, step 5466/7134 completed (loss: 0.17895671725273132, acc: 0.9601989984512329)
[2024-12-17 02:10:34,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:34,549][root][INFO] - Training Epoch: 1/2, step 5467/7134 completed (loss: 0.17498305439949036, acc: 0.9601989984512329)
[2024-12-17 02:10:34,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:34,852][root][INFO] - Training Epoch: 1/2, step 5468/7134 completed (loss: 0.19992652535438538, acc: 0.963350772857666)
[2024-12-17 02:10:34,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:35,137][root][INFO] - Training Epoch: 1/2, step 5469/7134 completed (loss: 0.34331443905830383, acc: 0.9365079402923584)
[2024-12-17 02:10:35,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:35,427][root][INFO] - Training Epoch: 1/2, step 5470/7134 completed (loss: 0.1724376380443573, acc: 0.9552238583564758)
[2024-12-17 02:10:35,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:35,713][root][INFO] - Training Epoch: 1/2, step 5471/7134 completed (loss: 0.15040390193462372, acc: 0.9588235020637512)
[2024-12-17 02:10:35,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:35,991][root][INFO] - Training Epoch: 1/2, step 5472/7134 completed (loss: 0.23056137561798096, acc: 0.9385474920272827)
[2024-12-17 02:10:36,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:36,279][root][INFO] - Training Epoch: 1/2, step 5473/7134 completed (loss: 0.1409781575202942, acc: 0.9545454382896423)
[2024-12-17 02:10:36,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:36,563][root][INFO] - Training Epoch: 1/2, step 5474/7134 completed (loss: 0.1739218533039093, acc: 0.9515151381492615)
[2024-12-17 02:10:36,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:36,849][root][INFO] - Training Epoch: 1/2, step 5475/7134 completed (loss: 0.12933552265167236, acc: 0.9691358208656311)
[2024-12-17 02:10:36,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:37,129][root][INFO] - Training Epoch: 1/2, step 5476/7134 completed (loss: 0.13813818991184235, acc: 0.9740259647369385)
[2024-12-17 02:10:37,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:37,427][root][INFO] - Training Epoch: 1/2, step 5477/7134 completed (loss: 0.18780983984470367, acc: 0.9693877696990967)
[2024-12-17 02:10:37,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:37,728][root][INFO] - Training Epoch: 1/2, step 5478/7134 completed (loss: 0.18172875046730042, acc: 0.9407407641410828)
[2024-12-17 02:10:37,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:38,017][root][INFO] - Training Epoch: 1/2, step 5479/7134 completed (loss: 0.4052690863609314, acc: 0.9256756901741028)
[2024-12-17 02:10:38,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:38,295][root][INFO] - Training Epoch: 1/2, step 5480/7134 completed (loss: 0.32284218072891235, acc: 0.9107142686843872)
[2024-12-17 02:10:38,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:38,561][root][INFO] - Training Epoch: 1/2, step 5481/7134 completed (loss: 0.3065948486328125, acc: 0.9180327653884888)
[2024-12-17 02:10:38,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:39,096][root][INFO] - Training Epoch: 1/2, step 5482/7134 completed (loss: 0.43729424476623535, acc: 0.8814433217048645)
[2024-12-17 02:10:39,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:39,463][root][INFO] - Training Epoch: 1/2, step 5483/7134 completed (loss: 0.2893597185611725, acc: 0.9090909361839294)
[2024-12-17 02:10:39,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:39,762][root][INFO] - Training Epoch: 1/2, step 5484/7134 completed (loss: 0.2735985517501831, acc: 0.9074074029922485)
[2024-12-17 02:10:39,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:40,040][root][INFO] - Training Epoch: 1/2, step 5485/7134 completed (loss: 0.3876798748970032, acc: 0.8870967626571655)
[2024-12-17 02:10:40,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:40,343][root][INFO] - Training Epoch: 1/2, step 5486/7134 completed (loss: 0.4429035186767578, acc: 0.8863636255264282)
[2024-12-17 02:10:40,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:40,652][root][INFO] - Training Epoch: 1/2, step 5487/7134 completed (loss: 0.31559300422668457, acc: 0.918367326259613)
[2024-12-17 02:10:40,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:40,968][root][INFO] - Training Epoch: 1/2, step 5488/7134 completed (loss: 0.4071390628814697, acc: 0.8682634830474854)
[2024-12-17 02:10:41,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:41,263][root][INFO] - Training Epoch: 1/2, step 5489/7134 completed (loss: 0.6228360533714294, acc: 0.8597561120986938)
[2024-12-17 02:10:41,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:41,519][root][INFO] - Training Epoch: 1/2, step 5490/7134 completed (loss: 0.31745103001594543, acc: 0.9090909361839294)
[2024-12-17 02:10:41,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:41,800][root][INFO] - Training Epoch: 1/2, step 5491/7134 completed (loss: 0.2586739659309387, acc: 0.9415204524993896)
[2024-12-17 02:10:41,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:42,102][root][INFO] - Training Epoch: 1/2, step 5492/7134 completed (loss: 0.29964137077331543, acc: 0.9179104566574097)
[2024-12-17 02:10:42,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:42,396][root][INFO] - Training Epoch: 1/2, step 5493/7134 completed (loss: 0.4374179542064667, acc: 0.90625)
[2024-12-17 02:10:42,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:42,687][root][INFO] - Training Epoch: 1/2, step 5494/7134 completed (loss: 0.29953381419181824, acc: 0.8993710875511169)
[2024-12-17 02:10:42,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:43,004][root][INFO] - Training Epoch: 1/2, step 5495/7134 completed (loss: 0.23140497505664825, acc: 0.9548872113227844)
[2024-12-17 02:10:43,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:43,280][root][INFO] - Training Epoch: 1/2, step 5496/7134 completed (loss: 0.3777405023574829, acc: 0.920634925365448)
[2024-12-17 02:10:43,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:43,545][root][INFO] - Training Epoch: 1/2, step 5497/7134 completed (loss: 0.47344812750816345, acc: 0.8705882430076599)
[2024-12-17 02:10:43,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:43,812][root][INFO] - Training Epoch: 1/2, step 5498/7134 completed (loss: 0.2648536264896393, acc: 0.957446813583374)
[2024-12-17 02:10:43,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:44,097][root][INFO] - Training Epoch: 1/2, step 5499/7134 completed (loss: 0.371021568775177, acc: 0.9009009003639221)
[2024-12-17 02:10:44,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:44,398][root][INFO] - Training Epoch: 1/2, step 5500/7134 completed (loss: 0.22456736862659454, acc: 0.9637305736541748)
[2024-12-17 02:10:44,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:44,680][root][INFO] - Training Epoch: 1/2, step 5501/7134 completed (loss: 0.3585965633392334, acc: 0.8989899158477783)
[2024-12-17 02:10:44,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:44,961][root][INFO] - Training Epoch: 1/2, step 5502/7134 completed (loss: 0.32820311188697815, acc: 0.8926553726196289)
[2024-12-17 02:10:45,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:45,246][root][INFO] - Training Epoch: 1/2, step 5503/7134 completed (loss: 0.5979363918304443, acc: 0.8461538553237915)
[2024-12-17 02:10:45,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:45,531][root][INFO] - Training Epoch: 1/2, step 5504/7134 completed (loss: 0.5494174361228943, acc: 0.8433734774589539)
[2024-12-17 02:10:45,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:45,809][root][INFO] - Training Epoch: 1/2, step 5505/7134 completed (loss: 0.5503326058387756, acc: 0.8522727489471436)
[2024-12-17 02:10:45,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:46,085][root][INFO] - Training Epoch: 1/2, step 5506/7134 completed (loss: 0.44826018810272217, acc: 0.8989899158477783)
[2024-12-17 02:10:46,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:46,359][root][INFO] - Training Epoch: 1/2, step 5507/7134 completed (loss: 0.2846214473247528, acc: 0.9415204524993896)
[2024-12-17 02:10:46,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:46,649][root][INFO] - Training Epoch: 1/2, step 5508/7134 completed (loss: 0.30497533082962036, acc: 0.9377990365028381)
[2024-12-17 02:10:46,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:46,937][root][INFO] - Training Epoch: 1/2, step 5509/7134 completed (loss: 0.3456067144870758, acc: 0.928909957408905)
[2024-12-17 02:10:47,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:47,226][root][INFO] - Training Epoch: 1/2, step 5510/7134 completed (loss: 0.5047118663787842, acc: 0.8924731016159058)
[2024-12-17 02:10:47,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:47,525][root][INFO] - Training Epoch: 1/2, step 5511/7134 completed (loss: 0.32287031412124634, acc: 0.893203854560852)
[2024-12-17 02:10:47,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:47,798][root][INFO] - Training Epoch: 1/2, step 5512/7134 completed (loss: 0.42210203409194946, acc: 0.9120879173278809)
[2024-12-17 02:10:47,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:48,069][root][INFO] - Training Epoch: 1/2, step 5513/7134 completed (loss: 0.5096204876899719, acc: 0.8757396340370178)
[2024-12-17 02:10:48,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:48,356][root][INFO] - Training Epoch: 1/2, step 5514/7134 completed (loss: 0.6220234632492065, acc: 0.8425925970077515)
[2024-12-17 02:10:48,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:48,627][root][INFO] - Training Epoch: 1/2, step 5515/7134 completed (loss: 0.34538254141807556, acc: 0.9226190447807312)
[2024-12-17 02:10:48,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:48,891][root][INFO] - Training Epoch: 1/2, step 5516/7134 completed (loss: 0.29381176829338074, acc: 0.931034505367279)
[2024-12-17 02:10:49,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:49,170][root][INFO] - Training Epoch: 1/2, step 5517/7134 completed (loss: 0.24802042543888092, acc: 0.9608938694000244)
[2024-12-17 02:10:49,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:49,480][root][INFO] - Training Epoch: 1/2, step 5518/7134 completed (loss: 0.3041263222694397, acc: 0.8999999761581421)
[2024-12-17 02:10:49,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:49,762][root][INFO] - Training Epoch: 1/2, step 5519/7134 completed (loss: 0.25641265511512756, acc: 0.9320987462997437)
[2024-12-17 02:10:49,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:50,048][root][INFO] - Training Epoch: 1/2, step 5520/7134 completed (loss: 0.2832109034061432, acc: 0.928909957408905)
[2024-12-17 02:10:50,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:50,342][root][INFO] - Training Epoch: 1/2, step 5521/7134 completed (loss: 0.3747253715991974, acc: 0.9005235433578491)
[2024-12-17 02:10:50,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:50,618][root][INFO] - Training Epoch: 1/2, step 5522/7134 completed (loss: 0.451768696308136, acc: 0.8743455410003662)
[2024-12-17 02:10:50,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:50,876][root][INFO] - Training Epoch: 1/2, step 5523/7134 completed (loss: 0.35554563999176025, acc: 0.8901098966598511)
[2024-12-17 02:10:50,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:51,143][root][INFO] - Training Epoch: 1/2, step 5524/7134 completed (loss: 0.46866920590400696, acc: 0.8670886158943176)
[2024-12-17 02:10:51,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:51,423][root][INFO] - Training Epoch: 1/2, step 5525/7134 completed (loss: 0.3403124511241913, acc: 0.9024389982223511)
[2024-12-17 02:10:51,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:51,704][root][INFO] - Training Epoch: 1/2, step 5526/7134 completed (loss: 0.24633537232875824, acc: 0.9316770434379578)
[2024-12-17 02:10:51,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:51,991][root][INFO] - Training Epoch: 1/2, step 5527/7134 completed (loss: 0.40147238969802856, acc: 0.9160839319229126)
[2024-12-17 02:10:52,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:52,270][root][INFO] - Training Epoch: 1/2, step 5528/7134 completed (loss: 0.336530864238739, acc: 0.9242424368858337)
[2024-12-17 02:10:52,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:52,561][root][INFO] - Training Epoch: 1/2, step 5529/7134 completed (loss: 0.2620585858821869, acc: 0.9409090876579285)
[2024-12-17 02:10:52,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:52,854][root][INFO] - Training Epoch: 1/2, step 5530/7134 completed (loss: 0.313833087682724, acc: 0.9251700639724731)
[2024-12-17 02:10:52,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:53,140][root][INFO] - Training Epoch: 1/2, step 5531/7134 completed (loss: 0.35322365164756775, acc: 0.9216867685317993)
[2024-12-17 02:10:53,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:53,432][root][INFO] - Training Epoch: 1/2, step 5532/7134 completed (loss: 0.5090705156326294, acc: 0.8757061958312988)
[2024-12-17 02:10:53,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:53,719][root][INFO] - Training Epoch: 1/2, step 5533/7134 completed (loss: 0.13595828413963318, acc: 0.9777777791023254)
[2024-12-17 02:10:53,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:54,007][root][INFO] - Training Epoch: 1/2, step 5534/7134 completed (loss: 0.3439277708530426, acc: 0.9213483333587646)
[2024-12-17 02:10:54,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:54,295][root][INFO] - Training Epoch: 1/2, step 5535/7134 completed (loss: 0.24090072512626648, acc: 0.9481865167617798)
[2024-12-17 02:10:54,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:54,572][root][INFO] - Training Epoch: 1/2, step 5536/7134 completed (loss: 0.25321435928344727, acc: 0.9344262480735779)
[2024-12-17 02:10:54,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:54,845][root][INFO] - Training Epoch: 1/2, step 5537/7134 completed (loss: 0.26232612133026123, acc: 0.954023003578186)
[2024-12-17 02:10:54,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:55,128][root][INFO] - Training Epoch: 1/2, step 5538/7134 completed (loss: 0.19726791977882385, acc: 0.9685863852500916)
[2024-12-17 02:10:55,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:55,414][root][INFO] - Training Epoch: 1/2, step 5539/7134 completed (loss: 0.38613128662109375, acc: 0.9180327653884888)
[2024-12-17 02:10:55,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:55,686][root][INFO] - Training Epoch: 1/2, step 5540/7134 completed (loss: 0.283992201089859, acc: 0.9216867685317993)
[2024-12-17 02:10:55,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:55,957][root][INFO] - Training Epoch: 1/2, step 5541/7134 completed (loss: 0.19240379333496094, acc: 0.9651162624359131)
[2024-12-17 02:10:56,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:56,220][root][INFO] - Training Epoch: 1/2, step 5542/7134 completed (loss: 0.0991998091340065, acc: 0.9677419066429138)
[2024-12-17 02:10:56,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:56,508][root][INFO] - Training Epoch: 1/2, step 5543/7134 completed (loss: 0.2015419602394104, acc: 0.9679144620895386)
[2024-12-17 02:10:56,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:56,795][root][INFO] - Training Epoch: 1/2, step 5544/7134 completed (loss: 0.18034444749355316, acc: 0.9562841653823853)
[2024-12-17 02:10:56,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:57,069][root][INFO] - Training Epoch: 1/2, step 5545/7134 completed (loss: 0.2753913998603821, acc: 0.9226190447807312)
[2024-12-17 02:10:57,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:57,347][root][INFO] - Training Epoch: 1/2, step 5546/7134 completed (loss: 0.2449335753917694, acc: 0.9221556782722473)
[2024-12-17 02:10:57,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:57,647][root][INFO] - Training Epoch: 1/2, step 5547/7134 completed (loss: 0.20719608664512634, acc: 0.939226508140564)
[2024-12-17 02:10:57,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:57,921][root][INFO] - Training Epoch: 1/2, step 5548/7134 completed (loss: 0.22486922144889832, acc: 0.9470587968826294)
[2024-12-17 02:10:58,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:58,177][root][INFO] - Training Epoch: 1/2, step 5549/7134 completed (loss: 0.26920580863952637, acc: 0.9530201554298401)
[2024-12-17 02:10:58,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:58,455][root][INFO] - Training Epoch: 1/2, step 5550/7134 completed (loss: 0.1733631044626236, acc: 0.966292142868042)
[2024-12-17 02:10:58,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:58,730][root][INFO] - Training Epoch: 1/2, step 5551/7134 completed (loss: 0.3610600531101227, acc: 0.9032257795333862)
[2024-12-17 02:10:58,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:59,018][root][INFO] - Training Epoch: 1/2, step 5552/7134 completed (loss: 0.14520303905010223, acc: 0.9570552110671997)
[2024-12-17 02:10:59,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:59,308][root][INFO] - Training Epoch: 1/2, step 5553/7134 completed (loss: 0.25665056705474854, acc: 0.9289940595626831)
[2024-12-17 02:10:59,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:59,599][root][INFO] - Training Epoch: 1/2, step 5554/7134 completed (loss: 0.20733730494976044, acc: 0.9554139971733093)
[2024-12-17 02:10:59,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:59,896][root][INFO] - Training Epoch: 1/2, step 5555/7134 completed (loss: 0.31748321652412415, acc: 0.9345238208770752)
[2024-12-17 02:11:00,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:00,173][root][INFO] - Training Epoch: 1/2, step 5556/7134 completed (loss: 0.3379989564418793, acc: 0.9329608678817749)
[2024-12-17 02:11:00,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:00,463][root][INFO] - Training Epoch: 1/2, step 5557/7134 completed (loss: 0.2700987160205841, acc: 0.95652174949646)
[2024-12-17 02:11:00,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:00,746][root][INFO] - Training Epoch: 1/2, step 5558/7134 completed (loss: 0.2495858371257782, acc: 0.9388889074325562)
[2024-12-17 02:11:00,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:01,023][root][INFO] - Training Epoch: 1/2, step 5559/7134 completed (loss: 0.35865509510040283, acc: 0.9273743033409119)
[2024-12-17 02:11:01,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:01,291][root][INFO] - Training Epoch: 1/2, step 5560/7134 completed (loss: 0.4385831952095032, acc: 0.9222221970558167)
[2024-12-17 02:11:01,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:01,570][root][INFO] - Training Epoch: 1/2, step 5561/7134 completed (loss: 0.2880038917064667, acc: 0.9508196711540222)
[2024-12-17 02:11:01,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:01,849][root][INFO] - Training Epoch: 1/2, step 5562/7134 completed (loss: 0.2722729742527008, acc: 0.9424460530281067)
[2024-12-17 02:11:01,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:02,131][root][INFO] - Training Epoch: 1/2, step 5563/7134 completed (loss: 0.1382581889629364, acc: 0.9791666865348816)
[2024-12-17 02:11:02,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:02,416][root][INFO] - Training Epoch: 1/2, step 5564/7134 completed (loss: 0.16063328087329865, acc: 0.949999988079071)
[2024-12-17 02:11:02,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:02,694][root][INFO] - Training Epoch: 1/2, step 5565/7134 completed (loss: 0.13038358092308044, acc: 0.9666666388511658)
[2024-12-17 02:11:02,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:02,982][root][INFO] - Training Epoch: 1/2, step 5566/7134 completed (loss: 0.14536476135253906, acc: 0.9695431590080261)
[2024-12-17 02:11:03,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:03,280][root][INFO] - Training Epoch: 1/2, step 5567/7134 completed (loss: 0.08907701820135117, acc: 0.9800994992256165)
[2024-12-17 02:11:03,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:03,552][root][INFO] - Training Epoch: 1/2, step 5568/7134 completed (loss: 0.12567037343978882, acc: 0.9505494236946106)
[2024-12-17 02:11:03,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:03,844][root][INFO] - Training Epoch: 1/2, step 5569/7134 completed (loss: 0.10577577352523804, acc: 0.984375)
[2024-12-17 02:11:03,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:04,134][root][INFO] - Training Epoch: 1/2, step 5570/7134 completed (loss: 0.12304507195949554, acc: 0.9510869383811951)
[2024-12-17 02:11:04,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:04,415][root][INFO] - Training Epoch: 1/2, step 5571/7134 completed (loss: 0.11742426455020905, acc: 0.9683544039726257)
[2024-12-17 02:11:04,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:04,710][root][INFO] - Training Epoch: 1/2, step 5572/7134 completed (loss: 0.16175298392772675, acc: 0.9631901979446411)
[2024-12-17 02:11:04,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:05,010][root][INFO] - Training Epoch: 1/2, step 5573/7134 completed (loss: 0.12336995452642441, acc: 0.9607843160629272)
[2024-12-17 02:11:05,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:05,291][root][INFO] - Training Epoch: 1/2, step 5574/7134 completed (loss: 0.18739013373851776, acc: 0.9791666865348816)
[2024-12-17 02:11:05,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:05,572][root][INFO] - Training Epoch: 1/2, step 5575/7134 completed (loss: 0.3223884701728821, acc: 0.9266666769981384)
[2024-12-17 02:11:05,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:05,876][root][INFO] - Training Epoch: 1/2, step 5576/7134 completed (loss: 0.0947733074426651, acc: 0.976190447807312)
[2024-12-17 02:11:06,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:06,162][root][INFO] - Training Epoch: 1/2, step 5577/7134 completed (loss: 0.5635741353034973, acc: 0.8592592477798462)
[2024-12-17 02:11:06,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:06,449][root][INFO] - Training Epoch: 1/2, step 5578/7134 completed (loss: 0.33930057287216187, acc: 0.905063271522522)
[2024-12-17 02:11:06,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:06,730][root][INFO] - Training Epoch: 1/2, step 5579/7134 completed (loss: 0.28222212195396423, acc: 0.9202454090118408)
[2024-12-17 02:11:06,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:06,997][root][INFO] - Training Epoch: 1/2, step 5580/7134 completed (loss: 0.19020390510559082, acc: 0.949999988079071)
[2024-12-17 02:11:07,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:07,280][root][INFO] - Training Epoch: 1/2, step 5581/7134 completed (loss: 0.26158249378204346, acc: 0.9212121367454529)
[2024-12-17 02:11:07,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:07,574][root][INFO] - Training Epoch: 1/2, step 5582/7134 completed (loss: 0.19754989445209503, acc: 0.9447513818740845)
[2024-12-17 02:11:07,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:07,862][root][INFO] - Training Epoch: 1/2, step 5583/7134 completed (loss: 0.20070232450962067, acc: 0.9447236061096191)
[2024-12-17 02:11:07,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:08,135][root][INFO] - Training Epoch: 1/2, step 5584/7134 completed (loss: 0.2873918414115906, acc: 0.9430379867553711)
[2024-12-17 02:11:08,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:08,433][root][INFO] - Training Epoch: 1/2, step 5585/7134 completed (loss: 0.26767101883888245, acc: 0.9414634108543396)
[2024-12-17 02:11:08,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:08,703][root][INFO] - Training Epoch: 1/2, step 5586/7134 completed (loss: 0.22255702316761017, acc: 0.9251700639724731)
[2024-12-17 02:11:08,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:08,989][root][INFO] - Training Epoch: 1/2, step 5587/7134 completed (loss: 0.28187867999076843, acc: 0.9485714435577393)
[2024-12-17 02:11:09,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:09,278][root][INFO] - Training Epoch: 1/2, step 5588/7134 completed (loss: 0.2000812292098999, acc: 0.9567901492118835)
[2024-12-17 02:11:09,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:09,576][root][INFO] - Training Epoch: 1/2, step 5589/7134 completed (loss: 0.2224281281232834, acc: 0.9440993666648865)
[2024-12-17 02:11:09,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:09,866][root][INFO] - Training Epoch: 1/2, step 5590/7134 completed (loss: 0.3164234161376953, acc: 0.9248554706573486)
[2024-12-17 02:11:10,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:10,163][root][INFO] - Training Epoch: 1/2, step 5591/7134 completed (loss: 0.15850213170051575, acc: 0.9710982441902161)
[2024-12-17 02:11:10,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:10,481][root][INFO] - Training Epoch: 1/2, step 5592/7134 completed (loss: 0.17855976521968842, acc: 0.9534883499145508)
[2024-12-17 02:11:10,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:10,790][root][INFO] - Training Epoch: 1/2, step 5593/7134 completed (loss: 0.20778191089630127, acc: 0.9619565010070801)
[2024-12-17 02:11:10,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:11,063][root][INFO] - Training Epoch: 1/2, step 5594/7134 completed (loss: 0.15243206918239594, acc: 0.9545454382896423)
[2024-12-17 02:11:11,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:11,343][root][INFO] - Training Epoch: 1/2, step 5595/7134 completed (loss: 0.22834090888500214, acc: 0.9545454382896423)
[2024-12-17 02:11:11,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:11,614][root][INFO] - Training Epoch: 1/2, step 5596/7134 completed (loss: 0.21924686431884766, acc: 0.940119743347168)
[2024-12-17 02:11:11,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:11,912][root][INFO] - Training Epoch: 1/2, step 5597/7134 completed (loss: 0.34928107261657715, acc: 0.9397590160369873)
[2024-12-17 02:11:12,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:12,189][root][INFO] - Training Epoch: 1/2, step 5598/7134 completed (loss: 0.18733471632003784, acc: 0.9537572264671326)
[2024-12-17 02:11:12,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:12,482][root][INFO] - Training Epoch: 1/2, step 5599/7134 completed (loss: 0.332962304353714, acc: 0.9387755393981934)
[2024-12-17 02:11:12,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:12,778][root][INFO] - Training Epoch: 1/2, step 5600/7134 completed (loss: 0.25827136635780334, acc: 0.9357143044471741)
[2024-12-17 02:11:12,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:13,045][root][INFO] - Training Epoch: 1/2, step 5601/7134 completed (loss: 0.2291124314069748, acc: 0.9389312863349915)
[2024-12-17 02:11:13,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:13,327][root][INFO] - Training Epoch: 1/2, step 5602/7134 completed (loss: 0.3073182702064514, acc: 0.922535240650177)
[2024-12-17 02:11:13,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:13,614][root][INFO] - Training Epoch: 1/2, step 5603/7134 completed (loss: 0.28808337450027466, acc: 0.9344262480735779)
[2024-12-17 02:11:13,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:13,895][root][INFO] - Training Epoch: 1/2, step 5604/7134 completed (loss: 0.4992583394050598, acc: 0.9024389982223511)
[2024-12-17 02:11:14,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:14,171][root][INFO] - Training Epoch: 1/2, step 5605/7134 completed (loss: 0.3190775513648987, acc: 0.8976377844810486)
[2024-12-17 02:11:14,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:14,460][root][INFO] - Training Epoch: 1/2, step 5606/7134 completed (loss: 0.33408302068710327, acc: 0.9252336621284485)
[2024-12-17 02:11:14,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:14,734][root][INFO] - Training Epoch: 1/2, step 5607/7134 completed (loss: 0.13155676424503326, acc: 0.9568345546722412)
[2024-12-17 02:11:14,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:15,001][root][INFO] - Training Epoch: 1/2, step 5608/7134 completed (loss: 0.3333921730518341, acc: 0.9379844665527344)
[2024-12-17 02:11:15,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:15,280][root][INFO] - Training Epoch: 1/2, step 5609/7134 completed (loss: 0.36651578545570374, acc: 0.9083333611488342)
[2024-12-17 02:11:15,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:15,557][root][INFO] - Training Epoch: 1/2, step 5610/7134 completed (loss: 0.12508587539196014, acc: 0.9636363387107849)
[2024-12-17 02:11:15,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:15,853][root][INFO] - Training Epoch: 1/2, step 5611/7134 completed (loss: 0.24437081813812256, acc: 0.9253731369972229)
[2024-12-17 02:11:15,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:16,146][root][INFO] - Training Epoch: 1/2, step 5612/7134 completed (loss: 0.33514389395713806, acc: 0.9366196990013123)
[2024-12-17 02:11:16,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:16,424][root][INFO] - Training Epoch: 1/2, step 5613/7134 completed (loss: 0.3564261496067047, acc: 0.9107142686843872)
[2024-12-17 02:11:16,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:16,695][root][INFO] - Training Epoch: 1/2, step 5614/7134 completed (loss: 0.3065012991428375, acc: 0.9463087320327759)
[2024-12-17 02:11:16,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:16,979][root][INFO] - Training Epoch: 1/2, step 5615/7134 completed (loss: 0.19119131565093994, acc: 0.9428571462631226)
[2024-12-17 02:11:17,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:17,269][root][INFO] - Training Epoch: 1/2, step 5616/7134 completed (loss: 0.1790076345205307, acc: 0.970370352268219)
[2024-12-17 02:11:17,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:17,537][root][INFO] - Training Epoch: 1/2, step 5617/7134 completed (loss: 0.16593246161937714, acc: 0.9534883499145508)
[2024-12-17 02:11:17,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:17,825][root][INFO] - Training Epoch: 1/2, step 5618/7134 completed (loss: 0.27835726737976074, acc: 0.9117646813392639)
[2024-12-17 02:11:17,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:18,081][root][INFO] - Training Epoch: 1/2, step 5619/7134 completed (loss: 0.3925110697746277, acc: 0.8991596698760986)
[2024-12-17 02:11:18,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:18,350][root][INFO] - Training Epoch: 1/2, step 5620/7134 completed (loss: 0.24278141558170319, acc: 0.947826087474823)
[2024-12-17 02:11:18,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:18,635][root][INFO] - Training Epoch: 1/2, step 5621/7134 completed (loss: 0.19136153161525726, acc: 0.9419354796409607)
[2024-12-17 02:11:18,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:18,931][root][INFO] - Training Epoch: 1/2, step 5622/7134 completed (loss: 0.21337847411632538, acc: 0.9358288645744324)
[2024-12-17 02:11:19,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:19,197][root][INFO] - Training Epoch: 1/2, step 5623/7134 completed (loss: 0.26447203755378723, acc: 0.9375)
[2024-12-17 02:11:19,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:19,477][root][INFO] - Training Epoch: 1/2, step 5624/7134 completed (loss: 0.1605048030614853, acc: 0.9738562107086182)
[2024-12-17 02:11:19,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:19,737][root][INFO] - Training Epoch: 1/2, step 5625/7134 completed (loss: 0.16608910262584686, acc: 0.9607843160629272)
[2024-12-17 02:11:19,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:20,008][root][INFO] - Training Epoch: 1/2, step 5626/7134 completed (loss: 0.10591818392276764, acc: 0.9793103337287903)
[2024-12-17 02:11:20,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:20,274][root][INFO] - Training Epoch: 1/2, step 5627/7134 completed (loss: 0.6308109760284424, acc: 0.8666666746139526)
[2024-12-17 02:11:20,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:20,560][root][INFO] - Training Epoch: 1/2, step 5628/7134 completed (loss: 0.4588015079498291, acc: 0.8571428656578064)
[2024-12-17 02:11:20,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:20,851][root][INFO] - Training Epoch: 1/2, step 5629/7134 completed (loss: 0.20841164886951447, acc: 0.9508196711540222)
[2024-12-17 02:11:20,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:21,129][root][INFO] - Training Epoch: 1/2, step 5630/7134 completed (loss: 0.26416754722595215, acc: 0.9313725233078003)
[2024-12-17 02:11:21,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:21,398][root][INFO] - Training Epoch: 1/2, step 5631/7134 completed (loss: 0.3657519519329071, acc: 0.9024389982223511)
[2024-12-17 02:11:21,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:21,690][root][INFO] - Training Epoch: 1/2, step 5632/7134 completed (loss: 0.4399866759777069, acc: 0.8942307829856873)
[2024-12-17 02:11:21,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:21,976][root][INFO] - Training Epoch: 1/2, step 5633/7134 completed (loss: 0.31547003984451294, acc: 0.9017857313156128)
[2024-12-17 02:11:22,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:22,251][root][INFO] - Training Epoch: 1/2, step 5634/7134 completed (loss: 0.23799747228622437, acc: 0.9115044474601746)
[2024-12-17 02:11:22,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:22,537][root][INFO] - Training Epoch: 1/2, step 5635/7134 completed (loss: 0.18024566769599915, acc: 0.953125)
[2024-12-17 02:11:22,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:22,818][root][INFO] - Training Epoch: 1/2, step 5636/7134 completed (loss: 0.23811747133731842, acc: 0.9538461565971375)
[2024-12-17 02:11:22,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:23,105][root][INFO] - Training Epoch: 1/2, step 5637/7134 completed (loss: 0.2000126838684082, acc: 0.9545454382896423)
[2024-12-17 02:11:23,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:23,374][root][INFO] - Training Epoch: 1/2, step 5638/7134 completed (loss: 0.2017606794834137, acc: 0.9385964870452881)
[2024-12-17 02:11:23,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:23,679][root][INFO] - Training Epoch: 1/2, step 5639/7134 completed (loss: 0.22195221483707428, acc: 0.9220778942108154)
[2024-12-17 02:11:23,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:23,953][root][INFO] - Training Epoch: 1/2, step 5640/7134 completed (loss: 0.23347319662570953, acc: 0.9219858050346375)
[2024-12-17 02:11:24,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:24,241][root][INFO] - Training Epoch: 1/2, step 5641/7134 completed (loss: 0.19052213430404663, acc: 0.9438202381134033)
[2024-12-17 02:11:24,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:24,517][root][INFO] - Training Epoch: 1/2, step 5642/7134 completed (loss: 0.4327358305454254, acc: 0.9090909361839294)
[2024-12-17 02:11:24,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:24,788][root][INFO] - Training Epoch: 1/2, step 5643/7134 completed (loss: 0.2982635498046875, acc: 0.9157894849777222)
[2024-12-17 02:11:24,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:25,076][root][INFO] - Training Epoch: 1/2, step 5644/7134 completed (loss: 0.2686086893081665, acc: 0.9523809552192688)
[2024-12-17 02:11:25,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:25,344][root][INFO] - Training Epoch: 1/2, step 5645/7134 completed (loss: 0.1685110479593277, acc: 0.9513888955116272)
[2024-12-17 02:11:25,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:25,615][root][INFO] - Training Epoch: 1/2, step 5646/7134 completed (loss: 0.18082940578460693, acc: 0.949999988079071)
[2024-12-17 02:11:25,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:25,921][root][INFO] - Training Epoch: 1/2, step 5647/7134 completed (loss: 0.33945339918136597, acc: 0.9444444179534912)
[2024-12-17 02:11:26,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:26,225][root][INFO] - Training Epoch: 1/2, step 5648/7134 completed (loss: 0.3747338354587555, acc: 0.9066666960716248)
[2024-12-17 02:11:26,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:26,492][root][INFO] - Training Epoch: 1/2, step 5649/7134 completed (loss: 0.39651045203208923, acc: 0.9054054021835327)
[2024-12-17 02:11:26,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:26,775][root][INFO] - Training Epoch: 1/2, step 5650/7134 completed (loss: 0.37758201360702515, acc: 0.8951612710952759)
[2024-12-17 02:11:26,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:27,058][root][INFO] - Training Epoch: 1/2, step 5651/7134 completed (loss: 0.17972713708877563, acc: 0.9455782175064087)
[2024-12-17 02:11:27,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:27,353][root][INFO] - Training Epoch: 1/2, step 5652/7134 completed (loss: 0.3495006561279297, acc: 0.9136690497398376)
[2024-12-17 02:11:27,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:27,633][root][INFO] - Training Epoch: 1/2, step 5653/7134 completed (loss: 0.3993224799633026, acc: 0.8701298832893372)
[2024-12-17 02:11:27,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:27,922][root][INFO] - Training Epoch: 1/2, step 5654/7134 completed (loss: 0.22226405143737793, acc: 0.953125)
[2024-12-17 02:11:28,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:28,203][root][INFO] - Training Epoch: 1/2, step 5655/7134 completed (loss: 0.3336672782897949, acc: 0.9065420627593994)
[2024-12-17 02:11:28,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:28,488][root][INFO] - Training Epoch: 1/2, step 5656/7134 completed (loss: 0.22550204396247864, acc: 0.9262295365333557)
[2024-12-17 02:11:28,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:28,765][root][INFO] - Training Epoch: 1/2, step 5657/7134 completed (loss: 0.42082706093788147, acc: 0.8940397500991821)
[2024-12-17 02:11:28,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:29,050][root][INFO] - Training Epoch: 1/2, step 5658/7134 completed (loss: 0.24250096082687378, acc: 0.9411764740943909)
[2024-12-17 02:11:29,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:29,319][root][INFO] - Training Epoch: 1/2, step 5659/7134 completed (loss: 0.3787967562675476, acc: 0.8999999761581421)
[2024-12-17 02:11:29,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:29,596][root][INFO] - Training Epoch: 1/2, step 5660/7134 completed (loss: 0.2807323932647705, acc: 0.921875)
[2024-12-17 02:11:29,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:29,880][root][INFO] - Training Epoch: 1/2, step 5661/7134 completed (loss: 0.24973313510417938, acc: 0.9327731132507324)
[2024-12-17 02:11:30,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:30,174][root][INFO] - Training Epoch: 1/2, step 5662/7134 completed (loss: 0.24273039400577545, acc: 0.9424460530281067)
[2024-12-17 02:11:30,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:30,454][root][INFO] - Training Epoch: 1/2, step 5663/7134 completed (loss: 0.15172241628170013, acc: 0.9637681245803833)
[2024-12-17 02:11:30,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:30,742][root][INFO] - Training Epoch: 1/2, step 5664/7134 completed (loss: 0.40667247772216797, acc: 0.9109588861465454)
[2024-12-17 02:11:30,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:31,019][root][INFO] - Training Epoch: 1/2, step 5665/7134 completed (loss: 0.20494958758354187, acc: 0.9659863710403442)
[2024-12-17 02:11:31,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:31,300][root][INFO] - Training Epoch: 1/2, step 5666/7134 completed (loss: 0.19714140892028809, acc: 0.9607843160629272)
[2024-12-17 02:11:31,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:31,559][root][INFO] - Training Epoch: 1/2, step 5667/7134 completed (loss: 0.27154651284217834, acc: 0.9512194991111755)
[2024-12-17 02:11:31,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:31,824][root][INFO] - Training Epoch: 1/2, step 5668/7134 completed (loss: 0.3535839915275574, acc: 0.9259259104728699)
[2024-12-17 02:11:31,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:32,092][root][INFO] - Training Epoch: 1/2, step 5669/7134 completed (loss: 0.4688693881034851, acc: 0.8789808750152588)
[2024-12-17 02:11:32,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:32,369][root][INFO] - Training Epoch: 1/2, step 5670/7134 completed (loss: 0.1258137971162796, acc: 0.9682539701461792)
[2024-12-17 02:11:32,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:32,664][root][INFO] - Training Epoch: 1/2, step 5671/7134 completed (loss: 0.3050704598426819, acc: 0.9269663095474243)
[2024-12-17 02:11:32,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:32,952][root][INFO] - Training Epoch: 1/2, step 5672/7134 completed (loss: 0.2238949090242386, acc: 0.9481481313705444)
[2024-12-17 02:11:33,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:33,214][root][INFO] - Training Epoch: 1/2, step 5673/7134 completed (loss: 0.18472082912921906, acc: 0.9520547986030579)
[2024-12-17 02:11:33,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:33,499][root][INFO] - Training Epoch: 1/2, step 5674/7134 completed (loss: 0.2987808287143707, acc: 0.9251700639724731)
[2024-12-17 02:11:33,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:33,774][root][INFO] - Training Epoch: 1/2, step 5675/7134 completed (loss: 0.5120164752006531, acc: 0.8866666555404663)
[2024-12-17 02:11:33,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:34,053][root][INFO] - Training Epoch: 1/2, step 5676/7134 completed (loss: 0.476079523563385, acc: 0.8563218116760254)
[2024-12-17 02:11:34,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:34,333][root][INFO] - Training Epoch: 1/2, step 5677/7134 completed (loss: 0.47439634799957275, acc: 0.8846153616905212)
[2024-12-17 02:11:34,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:34,632][root][INFO] - Training Epoch: 1/2, step 5678/7134 completed (loss: 0.28831982612609863, acc: 0.9074074029922485)
[2024-12-17 02:11:34,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:34,947][root][INFO] - Training Epoch: 1/2, step 5679/7134 completed (loss: 0.5765972137451172, acc: 0.8670886158943176)
[2024-12-17 02:11:35,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:35,257][root][INFO] - Training Epoch: 1/2, step 5680/7134 completed (loss: 0.6771341562271118, acc: 0.8478260636329651)
[2024-12-17 02:11:35,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:35,565][root][INFO] - Training Epoch: 1/2, step 5681/7134 completed (loss: 0.619718611240387, acc: 0.8606060743331909)
[2024-12-17 02:11:35,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:35,866][root][INFO] - Training Epoch: 1/2, step 5682/7134 completed (loss: 0.3992542624473572, acc: 0.9036144614219666)
[2024-12-17 02:11:36,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:36,174][root][INFO] - Training Epoch: 1/2, step 5683/7134 completed (loss: 0.5069819092750549, acc: 0.8722222447395325)
[2024-12-17 02:11:36,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:36,492][root][INFO] - Training Epoch: 1/2, step 5684/7134 completed (loss: 0.5746164917945862, acc: 0.8658536672592163)
[2024-12-17 02:11:36,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:36,785][root][INFO] - Training Epoch: 1/2, step 5685/7134 completed (loss: 0.476450115442276, acc: 0.8818897604942322)
[2024-12-17 02:11:36,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:37,078][root][INFO] - Training Epoch: 1/2, step 5686/7134 completed (loss: 0.3876289129257202, acc: 0.9064748287200928)
[2024-12-17 02:11:37,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:37,339][root][INFO] - Training Epoch: 1/2, step 5687/7134 completed (loss: 0.42716512084007263, acc: 0.9166666865348816)
[2024-12-17 02:11:37,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:37,624][root][INFO] - Training Epoch: 1/2, step 5688/7134 completed (loss: 0.5185332894325256, acc: 0.8888888955116272)
[2024-12-17 02:11:37,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:37,915][root][INFO] - Training Epoch: 1/2, step 5689/7134 completed (loss: 0.4231436550617218, acc: 0.9085366129875183)
[2024-12-17 02:11:38,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:38,207][root][INFO] - Training Epoch: 1/2, step 5690/7134 completed (loss: 0.25712910294532776, acc: 0.9175257682800293)
[2024-12-17 02:11:38,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:38,469][root][INFO] - Training Epoch: 1/2, step 5691/7134 completed (loss: 0.3394363820552826, acc: 0.9289617538452148)
[2024-12-17 02:11:38,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:38,758][root][INFO] - Training Epoch: 1/2, step 5692/7134 completed (loss: 0.28643137216567993, acc: 0.9428571462631226)
[2024-12-17 02:11:38,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:39,028][root][INFO] - Training Epoch: 1/2, step 5693/7134 completed (loss: 0.2203163057565689, acc: 0.9496855139732361)
[2024-12-17 02:11:39,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:39,291][root][INFO] - Training Epoch: 1/2, step 5694/7134 completed (loss: 0.1631866991519928, acc: 0.9476743936538696)
[2024-12-17 02:11:39,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:39,575][root][INFO] - Training Epoch: 1/2, step 5695/7134 completed (loss: 0.21983793377876282, acc: 0.9447852969169617)
[2024-12-17 02:11:39,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:39,858][root][INFO] - Training Epoch: 1/2, step 5696/7134 completed (loss: 0.19890713691711426, acc: 0.9603960514068604)
[2024-12-17 02:11:40,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:40,146][root][INFO] - Training Epoch: 1/2, step 5697/7134 completed (loss: 0.2815098464488983, acc: 0.9333333373069763)
[2024-12-17 02:11:40,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:40,425][root][INFO] - Training Epoch: 1/2, step 5698/7134 completed (loss: 0.2534574568271637, acc: 0.9431818127632141)
[2024-12-17 02:11:40,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:40,719][root][INFO] - Training Epoch: 1/2, step 5699/7134 completed (loss: 0.5213615894317627, acc: 0.8563218116760254)
[2024-12-17 02:11:40,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:40,996][root][INFO] - Training Epoch: 1/2, step 5700/7134 completed (loss: 0.19470013678073883, acc: 0.9617834687232971)
[2024-12-17 02:11:41,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:41,289][root][INFO] - Training Epoch: 1/2, step 5701/7134 completed (loss: 0.2795366048812866, acc: 0.9459459185600281)
[2024-12-17 02:11:41,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:41,561][root][INFO] - Training Epoch: 1/2, step 5702/7134 completed (loss: 0.1756526231765747, acc: 0.9534883499145508)
[2024-12-17 02:11:41,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:41,862][root][INFO] - Training Epoch: 1/2, step 5703/7134 completed (loss: 0.1679733842611313, acc: 0.9496855139732361)
[2024-12-17 02:11:41,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:42,137][root][INFO] - Training Epoch: 1/2, step 5704/7134 completed (loss: 0.3237287402153015, acc: 0.9235293865203857)
[2024-12-17 02:11:42,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:42,381][root][INFO] - Training Epoch: 1/2, step 5705/7134 completed (loss: 0.13232268393039703, acc: 0.9558823704719543)
[2024-12-17 02:11:42,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:42,678][root][INFO] - Training Epoch: 1/2, step 5706/7134 completed (loss: 0.21443553268909454, acc: 0.9356435537338257)
[2024-12-17 02:11:42,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:42,964][root][INFO] - Training Epoch: 1/2, step 5707/7134 completed (loss: 0.3014836609363556, acc: 0.9279999732971191)
[2024-12-17 02:11:43,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:43,237][root][INFO] - Training Epoch: 1/2, step 5708/7134 completed (loss: 0.11248760670423508, acc: 0.9615384340286255)
[2024-12-17 02:11:43,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:43,525][root][INFO] - Training Epoch: 1/2, step 5709/7134 completed (loss: 0.3834918439388275, acc: 0.9254658222198486)
[2024-12-17 02:11:43,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:43,822][root][INFO] - Training Epoch: 1/2, step 5710/7134 completed (loss: 0.26258620619773865, acc: 0.9371428489685059)
[2024-12-17 02:11:43,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:44,097][root][INFO] - Training Epoch: 1/2, step 5711/7134 completed (loss: 0.3814754784107208, acc: 0.9193548560142517)
[2024-12-17 02:11:44,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:44,371][root][INFO] - Training Epoch: 1/2, step 5712/7134 completed (loss: 0.1510750651359558, acc: 0.9516128897666931)
[2024-12-17 02:11:44,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:44,678][root][INFO] - Training Epoch: 1/2, step 5713/7134 completed (loss: 0.1676768660545349, acc: 0.9719101190567017)
[2024-12-17 02:11:44,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:44,985][root][INFO] - Training Epoch: 1/2, step 5714/7134 completed (loss: 0.18624639511108398, acc: 0.9510869383811951)
[2024-12-17 02:11:45,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:45,266][root][INFO] - Training Epoch: 1/2, step 5715/7134 completed (loss: 0.3338594436645508, acc: 0.9411764740943909)
[2024-12-17 02:11:45,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:45,543][root][INFO] - Training Epoch: 1/2, step 5716/7134 completed (loss: 0.2855284810066223, acc: 0.9236111044883728)
[2024-12-17 02:11:45,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:45,820][root][INFO] - Training Epoch: 1/2, step 5717/7134 completed (loss: 0.4074457585811615, acc: 0.9239766001701355)
[2024-12-17 02:11:45,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:46,077][root][INFO] - Training Epoch: 1/2, step 5718/7134 completed (loss: 0.21937480568885803, acc: 0.9342105388641357)
[2024-12-17 02:11:46,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:46,341][root][INFO] - Training Epoch: 1/2, step 5719/7134 completed (loss: 0.24481609463691711, acc: 0.9058823585510254)
[2024-12-17 02:11:46,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:46,604][root][INFO] - Training Epoch: 1/2, step 5720/7134 completed (loss: 0.3971399664878845, acc: 0.9230769276618958)
[2024-12-17 02:11:46,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:46,879][root][INFO] - Training Epoch: 1/2, step 5721/7134 completed (loss: 0.3028257191181183, acc: 0.9222797751426697)
[2024-12-17 02:11:46,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:47,114][root][INFO] - Training Epoch: 1/2, step 5722/7134 completed (loss: 0.19572673738002777, acc: 0.9363636374473572)
[2024-12-17 02:11:47,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:47,386][root][INFO] - Training Epoch: 1/2, step 5723/7134 completed (loss: 0.332600474357605, acc: 0.9153439402580261)
[2024-12-17 02:11:47,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:47,664][root][INFO] - Training Epoch: 1/2, step 5724/7134 completed (loss: 0.34807291626930237, acc: 0.9151515364646912)
[2024-12-17 02:11:47,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:47,955][root][INFO] - Training Epoch: 1/2, step 5725/7134 completed (loss: 0.257077693939209, acc: 0.9200000166893005)
[2024-12-17 02:11:48,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:48,219][root][INFO] - Training Epoch: 1/2, step 5726/7134 completed (loss: 0.42464393377304077, acc: 0.8922155499458313)
[2024-12-17 02:11:48,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:48,497][root][INFO] - Training Epoch: 1/2, step 5727/7134 completed (loss: 0.14371363818645477, acc: 0.9648241400718689)
[2024-12-17 02:11:48,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:48,780][root][INFO] - Training Epoch: 1/2, step 5728/7134 completed (loss: 0.07764104753732681, acc: 0.9779411554336548)
[2024-12-17 02:11:48,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:49,050][root][INFO] - Training Epoch: 1/2, step 5729/7134 completed (loss: 0.11986315995454788, acc: 0.9740259647369385)
[2024-12-17 02:11:49,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:49,320][root][INFO] - Training Epoch: 1/2, step 5730/7134 completed (loss: 0.2712880074977875, acc: 0.9407407641410828)
[2024-12-17 02:11:49,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:49,613][root][INFO] - Training Epoch: 1/2, step 5731/7134 completed (loss: 0.2500138282775879, acc: 0.9312499761581421)
[2024-12-17 02:11:49,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:49,874][root][INFO] - Training Epoch: 1/2, step 5732/7134 completed (loss: 0.9063910841941833, acc: 0.7771084308624268)
[2024-12-17 02:11:50,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:50,178][root][INFO] - Training Epoch: 1/2, step 5733/7134 completed (loss: 0.29813817143440247, acc: 0.9367088675498962)
[2024-12-17 02:11:50,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:50,482][root][INFO] - Training Epoch: 1/2, step 5734/7134 completed (loss: 0.45893874764442444, acc: 0.8928571343421936)
[2024-12-17 02:11:50,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:50,779][root][INFO] - Training Epoch: 1/2, step 5735/7134 completed (loss: 0.4259187877178192, acc: 0.9072847962379456)
[2024-12-17 02:11:50,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:51,108][root][INFO] - Training Epoch: 1/2, step 5736/7134 completed (loss: 0.6359655261039734, acc: 0.8729282021522522)
[2024-12-17 02:11:51,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:51,391][root][INFO] - Training Epoch: 1/2, step 5737/7134 completed (loss: 0.2673034965991974, acc: 0.9356725215911865)
[2024-12-17 02:11:51,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:51,676][root][INFO] - Training Epoch: 1/2, step 5738/7134 completed (loss: 0.27376222610473633, acc: 0.9292929172515869)
[2024-12-17 02:11:51,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:51,963][root][INFO] - Training Epoch: 1/2, step 5739/7134 completed (loss: 0.3516313433647156, acc: 0.9166666865348816)
[2024-12-17 02:11:52,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:52,251][root][INFO] - Training Epoch: 1/2, step 5740/7134 completed (loss: 0.2870747745037079, acc: 0.9322916865348816)
[2024-12-17 02:11:52,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:52,534][root][INFO] - Training Epoch: 1/2, step 5741/7134 completed (loss: 0.32335683703422546, acc: 0.9147727489471436)
[2024-12-17 02:11:52,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:52,810][root][INFO] - Training Epoch: 1/2, step 5742/7134 completed (loss: 0.24605442583560944, acc: 0.9269663095474243)
[2024-12-17 02:11:52,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:53,104][root][INFO] - Training Epoch: 1/2, step 5743/7134 completed (loss: 0.2312234491109848, acc: 0.9479166865348816)
[2024-12-17 02:11:53,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:53,374][root][INFO] - Training Epoch: 1/2, step 5744/7134 completed (loss: 0.21251174807548523, acc: 0.9469026327133179)
[2024-12-17 02:11:53,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:53,666][root][INFO] - Training Epoch: 1/2, step 5745/7134 completed (loss: 0.3598809540271759, acc: 0.932584285736084)
[2024-12-17 02:11:53,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:53,939][root][INFO] - Training Epoch: 1/2, step 5746/7134 completed (loss: 0.23542355000972748, acc: 0.9382715821266174)
[2024-12-17 02:11:54,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:54,225][root][INFO] - Training Epoch: 1/2, step 5747/7134 completed (loss: 0.2043984830379486, acc: 0.9515151381492615)
[2024-12-17 02:11:54,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:54,519][root][INFO] - Training Epoch: 1/2, step 5748/7134 completed (loss: 0.09829290211200714, acc: 0.9685039520263672)
[2024-12-17 02:11:54,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:54,807][root][INFO] - Training Epoch: 1/2, step 5749/7134 completed (loss: 0.2915304899215698, acc: 0.9585798978805542)
[2024-12-17 02:11:54,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:55,094][root][INFO] - Training Epoch: 1/2, step 5750/7134 completed (loss: 0.32858964800834656, acc: 0.9273743033409119)
[2024-12-17 02:11:55,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:55,373][root][INFO] - Training Epoch: 1/2, step 5751/7134 completed (loss: 0.34253785014152527, acc: 0.9205297827720642)
[2024-12-17 02:11:55,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:55,665][root][INFO] - Training Epoch: 1/2, step 5752/7134 completed (loss: 0.7473611235618591, acc: 0.8167939186096191)
[2024-12-17 02:11:55,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:55,922][root][INFO] - Training Epoch: 1/2, step 5753/7134 completed (loss: 0.4128127992153168, acc: 0.9194630980491638)
[2024-12-17 02:11:56,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:56,221][root][INFO] - Training Epoch: 1/2, step 5754/7134 completed (loss: 0.4074917435646057, acc: 0.931034505367279)
[2024-12-17 02:11:56,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:56,513][root][INFO] - Training Epoch: 1/2, step 5755/7134 completed (loss: 0.4199380874633789, acc: 0.9025974273681641)
[2024-12-17 02:11:56,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:56,807][root][INFO] - Training Epoch: 1/2, step 5756/7134 completed (loss: 0.45924457907676697, acc: 0.8779069781303406)
[2024-12-17 02:11:56,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:57,121][root][INFO] - Training Epoch: 1/2, step 5757/7134 completed (loss: 0.4152100086212158, acc: 0.898876428604126)
[2024-12-17 02:11:57,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:57,400][root][INFO] - Training Epoch: 1/2, step 5758/7134 completed (loss: 0.4771175682544708, acc: 0.8765432238578796)
[2024-12-17 02:11:57,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:57,690][root][INFO] - Training Epoch: 1/2, step 5759/7134 completed (loss: 0.9113323092460632, acc: 0.8349514603614807)
[2024-12-17 02:11:57,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:57,963][root][INFO] - Training Epoch: 1/2, step 5760/7134 completed (loss: 0.3056248128414154, acc: 0.9285714030265808)
[2024-12-17 02:11:58,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:58,250][root][INFO] - Training Epoch: 1/2, step 5761/7134 completed (loss: 0.2883797883987427, acc: 0.9200000166893005)
[2024-12-17 02:11:58,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:58,529][root][INFO] - Training Epoch: 1/2, step 5762/7134 completed (loss: 0.29659250378608704, acc: 0.9379844665527344)
[2024-12-17 02:11:58,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:58,820][root][INFO] - Training Epoch: 1/2, step 5763/7134 completed (loss: 0.16250011324882507, acc: 0.9562841653823853)
[2024-12-17 02:11:58,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:59,078][root][INFO] - Training Epoch: 1/2, step 5764/7134 completed (loss: 0.13071802258491516, acc: 0.9694656729698181)
[2024-12-17 02:11:59,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:59,362][root][INFO] - Training Epoch: 1/2, step 5765/7134 completed (loss: 0.2661682963371277, acc: 0.9371069073677063)
[2024-12-17 02:11:59,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:59,646][root][INFO] - Training Epoch: 1/2, step 5766/7134 completed (loss: 0.14282236993312836, acc: 0.9870967864990234)
[2024-12-17 02:11:59,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:59,936][root][INFO] - Training Epoch: 1/2, step 5767/7134 completed (loss: 0.17838633060455322, acc: 0.9627329111099243)
[2024-12-17 02:12:00,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:00,232][root][INFO] - Training Epoch: 1/2, step 5768/7134 completed (loss: 0.13051837682724, acc: 0.96875)
[2024-12-17 02:12:00,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:00,525][root][INFO] - Training Epoch: 1/2, step 5769/7134 completed (loss: 0.1168496385216713, acc: 0.9714285731315613)
[2024-12-17 02:12:00,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:00,819][root][INFO] - Training Epoch: 1/2, step 5770/7134 completed (loss: 0.1037345603108406, acc: 0.9837837815284729)
[2024-12-17 02:12:00,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:01,097][root][INFO] - Training Epoch: 1/2, step 5771/7134 completed (loss: 0.2924700677394867, acc: 0.9631901979446411)
[2024-12-17 02:12:01,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:01,384][root][INFO] - Training Epoch: 1/2, step 5772/7134 completed (loss: 0.10360082238912582, acc: 0.9750000238418579)
[2024-12-17 02:12:01,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:01,668][root][INFO] - Training Epoch: 1/2, step 5773/7134 completed (loss: 0.1832660734653473, acc: 0.9473684430122375)
[2024-12-17 02:12:01,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:01,961][root][INFO] - Training Epoch: 1/2, step 5774/7134 completed (loss: 0.16702944040298462, acc: 0.9691358208656311)
[2024-12-17 02:12:02,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:02,222][root][INFO] - Training Epoch: 1/2, step 5775/7134 completed (loss: 0.24817413091659546, acc: 0.9066666960716248)
[2024-12-17 02:12:02,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:02,497][root][INFO] - Training Epoch: 1/2, step 5776/7134 completed (loss: 0.30287638306617737, acc: 0.9101123809814453)
[2024-12-17 02:12:02,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:02,780][root][INFO] - Training Epoch: 1/2, step 5777/7134 completed (loss: 0.3592025637626648, acc: 0.9112149477005005)
[2024-12-17 02:12:02,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:03,065][root][INFO] - Training Epoch: 1/2, step 5778/7134 completed (loss: 0.550409197807312, acc: 0.8658536672592163)
[2024-12-17 02:12:03,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:03,356][root][INFO] - Training Epoch: 1/2, step 5779/7134 completed (loss: 0.36625537276268005, acc: 0.929411768913269)
[2024-12-17 02:12:03,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:03,651][root][INFO] - Training Epoch: 1/2, step 5780/7134 completed (loss: 0.18465735018253326, acc: 0.9452736377716064)
[2024-12-17 02:12:03,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:03,939][root][INFO] - Training Epoch: 1/2, step 5781/7134 completed (loss: 0.3829270303249359, acc: 0.9190751314163208)
[2024-12-17 02:12:04,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:04,226][root][INFO] - Training Epoch: 1/2, step 5782/7134 completed (loss: 0.18008524179458618, acc: 0.9779005646705627)
[2024-12-17 02:12:04,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:04,508][root][INFO] - Training Epoch: 1/2, step 5783/7134 completed (loss: 0.2757052779197693, acc: 0.9537572264671326)
[2024-12-17 02:12:04,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:04,794][root][INFO] - Training Epoch: 1/2, step 5784/7134 completed (loss: 0.25804242491722107, acc: 0.9322034120559692)
[2024-12-17 02:12:04,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:05,083][root][INFO] - Training Epoch: 1/2, step 5785/7134 completed (loss: 0.4214131534099579, acc: 0.9027026891708374)
[2024-12-17 02:12:05,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:05,355][root][INFO] - Training Epoch: 1/2, step 5786/7134 completed (loss: 0.32285216450691223, acc: 0.920634925365448)
[2024-12-17 02:12:05,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:05,637][root][INFO] - Training Epoch: 1/2, step 5787/7134 completed (loss: 0.1976851373910904, acc: 0.9581151604652405)
[2024-12-17 02:12:05,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:05,914][root][INFO] - Training Epoch: 1/2, step 5788/7134 completed (loss: 0.12033560127019882, acc: 0.9736841917037964)
[2024-12-17 02:12:06,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:06,198][root][INFO] - Training Epoch: 1/2, step 5789/7134 completed (loss: 0.2737795114517212, acc: 0.9242424368858337)
[2024-12-17 02:12:06,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:06,486][root][INFO] - Training Epoch: 1/2, step 5790/7134 completed (loss: 0.2258705198764801, acc: 0.9464285969734192)
[2024-12-17 02:12:06,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:06,764][root][INFO] - Training Epoch: 1/2, step 5791/7134 completed (loss: 0.24619850516319275, acc: 0.9104477763175964)
[2024-12-17 02:12:06,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:07,056][root][INFO] - Training Epoch: 1/2, step 5792/7134 completed (loss: 0.5235623121261597, acc: 0.8590604066848755)
[2024-12-17 02:12:07,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:07,339][root][INFO] - Training Epoch: 1/2, step 5793/7134 completed (loss: 0.4154124855995178, acc: 0.89570552110672)
[2024-12-17 02:12:07,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:07,611][root][INFO] - Training Epoch: 1/2, step 5794/7134 completed (loss: 0.6808964014053345, acc: 0.8535031676292419)
[2024-12-17 02:12:07,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:07,892][root][INFO] - Training Epoch: 1/2, step 5795/7134 completed (loss: 0.657697856426239, acc: 0.8195488452911377)
[2024-12-17 02:12:08,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:08,170][root][INFO] - Training Epoch: 1/2, step 5796/7134 completed (loss: 0.5671740174293518, acc: 0.8702290058135986)
[2024-12-17 02:12:08,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:08,446][root][INFO] - Training Epoch: 1/2, step 5797/7134 completed (loss: 0.42037075757980347, acc: 0.8926174640655518)
[2024-12-17 02:12:08,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:08,716][root][INFO] - Training Epoch: 1/2, step 5798/7134 completed (loss: 0.9975730776786804, acc: 0.8313953280448914)
[2024-12-17 02:12:08,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:08,992][root][INFO] - Training Epoch: 1/2, step 5799/7134 completed (loss: 0.47147828340530396, acc: 0.8897637724876404)
[2024-12-17 02:12:09,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:09,269][root][INFO] - Training Epoch: 1/2, step 5800/7134 completed (loss: 0.44738560914993286, acc: 0.9136690497398376)
[2024-12-17 02:12:09,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:09,549][root][INFO] - Training Epoch: 1/2, step 5801/7134 completed (loss: 0.5306410789489746, acc: 0.8518518805503845)
[2024-12-17 02:12:09,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:09,829][root][INFO] - Training Epoch: 1/2, step 5802/7134 completed (loss: 0.3843100368976593, acc: 0.8897058963775635)
[2024-12-17 02:12:09,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:10,113][root][INFO] - Training Epoch: 1/2, step 5803/7134 completed (loss: 0.17035257816314697, acc: 0.959770143032074)
[2024-12-17 02:12:10,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:10,418][root][INFO] - Training Epoch: 1/2, step 5804/7134 completed (loss: 0.3854066729545593, acc: 0.8789808750152588)
[2024-12-17 02:12:10,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:10,734][root][INFO] - Training Epoch: 1/2, step 5805/7134 completed (loss: 0.3581175208091736, acc: 0.9006622433662415)
[2024-12-17 02:12:10,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:11,023][root][INFO] - Training Epoch: 1/2, step 5806/7134 completed (loss: 0.19811080396175385, acc: 0.9636363387107849)
[2024-12-17 02:12:11,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:11,311][root][INFO] - Training Epoch: 1/2, step 5807/7134 completed (loss: 0.32793235778808594, acc: 0.9366196990013123)
[2024-12-17 02:12:11,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:11,614][root][INFO] - Training Epoch: 1/2, step 5808/7134 completed (loss: 0.130380317568779, acc: 0.9620253443717957)
[2024-12-17 02:12:11,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:11,886][root][INFO] - Training Epoch: 1/2, step 5809/7134 completed (loss: 0.21469561755657196, acc: 0.9313725233078003)
[2024-12-17 02:12:12,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:12,176][root][INFO] - Training Epoch: 1/2, step 5810/7134 completed (loss: 0.2644374966621399, acc: 0.93388432264328)
[2024-12-17 02:12:12,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:12,432][root][INFO] - Training Epoch: 1/2, step 5811/7134 completed (loss: 0.18825586140155792, acc: 0.9670329689979553)
[2024-12-17 02:12:12,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:12,701][root][INFO] - Training Epoch: 1/2, step 5812/7134 completed (loss: 0.11884389072656631, acc: 0.9779411554336548)
[2024-12-17 02:12:12,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:12,967][root][INFO] - Training Epoch: 1/2, step 5813/7134 completed (loss: 0.17315056920051575, acc: 0.9672130942344666)
[2024-12-17 02:12:13,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:13,307][root][INFO] - Training Epoch: 1/2, step 5814/7134 completed (loss: 0.1932704597711563, acc: 0.9599999785423279)
[2024-12-17 02:12:13,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:13,607][root][INFO] - Training Epoch: 1/2, step 5815/7134 completed (loss: 0.26809021830558777, acc: 0.9224137663841248)
[2024-12-17 02:12:13,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:13,905][root][INFO] - Training Epoch: 1/2, step 5816/7134 completed (loss: 0.09872033447027206, acc: 0.9679144620895386)
[2024-12-17 02:12:14,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:14,216][root][INFO] - Training Epoch: 1/2, step 5817/7134 completed (loss: 0.19557340443134308, acc: 0.9714285731315613)
[2024-12-17 02:12:14,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:14,518][root][INFO] - Training Epoch: 1/2, step 5818/7134 completed (loss: 0.19620612263679504, acc: 0.9477124214172363)
[2024-12-17 02:12:14,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:14,779][root][INFO] - Training Epoch: 1/2, step 5819/7134 completed (loss: 0.2065001279115677, acc: 0.9577465057373047)
[2024-12-17 02:12:14,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:15,034][root][INFO] - Training Epoch: 1/2, step 5820/7134 completed (loss: 0.23524580895900726, acc: 0.9669421315193176)
[2024-12-17 02:12:15,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:15,310][root][INFO] - Training Epoch: 1/2, step 5821/7134 completed (loss: 0.12771917879581451, acc: 0.9862068891525269)
[2024-12-17 02:12:15,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:15,584][root][INFO] - Training Epoch: 1/2, step 5822/7134 completed (loss: 0.1797417402267456, acc: 0.9664429426193237)
[2024-12-17 02:12:15,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:15,848][root][INFO] - Training Epoch: 1/2, step 5823/7134 completed (loss: 0.08247924596071243, acc: 0.9727891087532043)
[2024-12-17 02:12:15,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:16,131][root][INFO] - Training Epoch: 1/2, step 5824/7134 completed (loss: 0.12787829339504242, acc: 0.9818181991577148)
[2024-12-17 02:12:16,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:16,411][root][INFO] - Training Epoch: 1/2, step 5825/7134 completed (loss: 0.2859104871749878, acc: 0.9236640930175781)
[2024-12-17 02:12:16,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:16,683][root][INFO] - Training Epoch: 1/2, step 5826/7134 completed (loss: 0.1100437343120575, acc: 0.9767441749572754)
[2024-12-17 02:12:16,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:16,949][root][INFO] - Training Epoch: 1/2, step 5827/7134 completed (loss: 0.12727175652980804, acc: 0.9677419066429138)
[2024-12-17 02:12:17,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:17,232][root][INFO] - Training Epoch: 1/2, step 5828/7134 completed (loss: 0.1594717800617218, acc: 0.9607843160629272)
[2024-12-17 02:12:17,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:17,517][root][INFO] - Training Epoch: 1/2, step 5829/7134 completed (loss: 0.14580602943897247, acc: 0.9695122241973877)
[2024-12-17 02:12:17,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:17,807][root][INFO] - Training Epoch: 1/2, step 5830/7134 completed (loss: 0.13912636041641235, acc: 0.9760000109672546)
[2024-12-17 02:12:17,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:18,111][root][INFO] - Training Epoch: 1/2, step 5831/7134 completed (loss: 0.07757669687271118, acc: 0.9795918464660645)
[2024-12-17 02:12:18,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:18,420][root][INFO] - Training Epoch: 1/2, step 5832/7134 completed (loss: 0.20887066423892975, acc: 0.9770992398262024)
[2024-12-17 02:12:18,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:18,714][root][INFO] - Training Epoch: 1/2, step 5833/7134 completed (loss: 0.15120364725589752, acc: 0.9774436354637146)
[2024-12-17 02:12:18,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:19,013][root][INFO] - Training Epoch: 1/2, step 5834/7134 completed (loss: 0.4079245328903198, acc: 0.8830409646034241)
[2024-12-17 02:12:19,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:19,309][root][INFO] - Training Epoch: 1/2, step 5835/7134 completed (loss: 0.20904554426670074, acc: 0.9466666579246521)
[2024-12-17 02:12:19,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:19,590][root][INFO] - Training Epoch: 1/2, step 5836/7134 completed (loss: 0.39665964245796204, acc: 0.8980891704559326)
[2024-12-17 02:12:19,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:19,863][root][INFO] - Training Epoch: 1/2, step 5837/7134 completed (loss: 0.6284460425376892, acc: 0.8590604066848755)
[2024-12-17 02:12:19,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:20,148][root][INFO] - Training Epoch: 1/2, step 5838/7134 completed (loss: 0.4159710109233856, acc: 0.9064748287200928)
[2024-12-17 02:12:20,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:20,427][root][INFO] - Training Epoch: 1/2, step 5839/7134 completed (loss: 0.3014192581176758, acc: 0.9347826242446899)
[2024-12-17 02:12:20,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:20,698][root][INFO] - Training Epoch: 1/2, step 5840/7134 completed (loss: 0.07149029523134232, acc: 0.9720279574394226)
[2024-12-17 02:12:20,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:20,990][root][INFO] - Training Epoch: 1/2, step 5841/7134 completed (loss: 0.48608145117759705, acc: 0.862500011920929)
[2024-12-17 02:12:21,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:21,266][root][INFO] - Training Epoch: 1/2, step 5842/7134 completed (loss: 0.22392460703849792, acc: 0.9504132270812988)
[2024-12-17 02:12:21,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:21,553][root][INFO] - Training Epoch: 1/2, step 5843/7134 completed (loss: 0.3110584616661072, acc: 0.9285714030265808)
[2024-12-17 02:12:21,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:21,846][root][INFO] - Training Epoch: 1/2, step 5844/7134 completed (loss: 0.195598304271698, acc: 0.9337349534034729)
[2024-12-17 02:12:21,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:22,124][root][INFO] - Training Epoch: 1/2, step 5845/7134 completed (loss: 0.23917964100837708, acc: 0.9415584206581116)
[2024-12-17 02:12:22,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:22,398][root][INFO] - Training Epoch: 1/2, step 5846/7134 completed (loss: 0.2535236179828644, acc: 0.9285714030265808)
[2024-12-17 02:12:22,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:22,690][root][INFO] - Training Epoch: 1/2, step 5847/7134 completed (loss: 0.16570444405078888, acc: 0.9457831382751465)
[2024-12-17 02:12:22,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:22,959][root][INFO] - Training Epoch: 1/2, step 5848/7134 completed (loss: 0.23412036895751953, acc: 0.9391891956329346)
[2024-12-17 02:12:23,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:23,227][root][INFO] - Training Epoch: 1/2, step 5849/7134 completed (loss: 0.32089710235595703, acc: 0.9025974273681641)
[2024-12-17 02:12:23,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:23,501][root][INFO] - Training Epoch: 1/2, step 5850/7134 completed (loss: 0.2720876634120941, acc: 0.9366196990013123)
[2024-12-17 02:12:23,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:23,778][root][INFO] - Training Epoch: 1/2, step 5851/7134 completed (loss: 0.3605792224407196, acc: 0.9178082346916199)
[2024-12-17 02:12:23,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:24,044][root][INFO] - Training Epoch: 1/2, step 5852/7134 completed (loss: 0.28098562359809875, acc: 0.9440559148788452)
[2024-12-17 02:12:24,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:24,323][root][INFO] - Training Epoch: 1/2, step 5853/7134 completed (loss: 0.33715131878852844, acc: 0.898876428604126)
[2024-12-17 02:12:24,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:24,588][root][INFO] - Training Epoch: 1/2, step 5854/7134 completed (loss: 0.5018883347511292, acc: 0.9076923131942749)
[2024-12-17 02:12:24,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:24,855][root][INFO] - Training Epoch: 1/2, step 5855/7134 completed (loss: 0.36566445231437683, acc: 0.9152542352676392)
[2024-12-17 02:12:24,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:25,132][root][INFO] - Training Epoch: 1/2, step 5856/7134 completed (loss: 0.5524969696998596, acc: 0.7957746386528015)
[2024-12-17 02:12:25,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:25,422][root][INFO] - Training Epoch: 1/2, step 5857/7134 completed (loss: 0.3806963264942169, acc: 0.9248120188713074)
[2024-12-17 02:12:25,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:25,685][root][INFO] - Training Epoch: 1/2, step 5858/7134 completed (loss: 0.2734769880771637, acc: 0.9266055226325989)
[2024-12-17 02:12:25,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:25,961][root][INFO] - Training Epoch: 1/2, step 5859/7134 completed (loss: 0.2379414439201355, acc: 0.9396551847457886)
[2024-12-17 02:12:26,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:26,230][root][INFO] - Training Epoch: 1/2, step 5860/7134 completed (loss: 0.20541362464427948, acc: 0.9318181872367859)
[2024-12-17 02:12:26,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:26,481][root][INFO] - Training Epoch: 1/2, step 5861/7134 completed (loss: 0.241446390748024, acc: 0.9523809552192688)
[2024-12-17 02:12:26,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:26,760][root][INFO] - Training Epoch: 1/2, step 5862/7134 completed (loss: 0.33870163559913635, acc: 0.9067796468734741)
[2024-12-17 02:12:26,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:27,008][root][INFO] - Training Epoch: 1/2, step 5863/7134 completed (loss: 0.4730229079723358, acc: 0.8817204236984253)
[2024-12-17 02:12:27,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:27,288][root][INFO] - Training Epoch: 1/2, step 5864/7134 completed (loss: 0.45955225825309753, acc: 0.8947368264198303)
[2024-12-17 02:12:27,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:27,552][root][INFO] - Training Epoch: 1/2, step 5865/7134 completed (loss: 0.33255255222320557, acc: 0.9166666865348816)
[2024-12-17 02:12:27,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:27,840][root][INFO] - Training Epoch: 1/2, step 5866/7134 completed (loss: 0.2133343517780304, acc: 0.9670329689979553)
[2024-12-17 02:12:27,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:28,136][root][INFO] - Training Epoch: 1/2, step 5867/7134 completed (loss: 0.3386181890964508, acc: 0.9256756901741028)
[2024-12-17 02:12:28,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:28,439][root][INFO] - Training Epoch: 1/2, step 5868/7134 completed (loss: 0.36809977889060974, acc: 0.8954248428344727)
[2024-12-17 02:12:28,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:28,716][root][INFO] - Training Epoch: 1/2, step 5869/7134 completed (loss: 0.31254902482032776, acc: 0.9041916131973267)
[2024-12-17 02:12:28,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:29,024][root][INFO] - Training Epoch: 1/2, step 5870/7134 completed (loss: 0.34037163853645325, acc: 0.9259259104728699)
[2024-12-17 02:12:29,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:29,311][root][INFO] - Training Epoch: 1/2, step 5871/7134 completed (loss: 0.14208725094795227, acc: 0.963302731513977)
[2024-12-17 02:12:29,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:29,603][root][INFO] - Training Epoch: 1/2, step 5872/7134 completed (loss: 0.32897183299064636, acc: 0.9378882050514221)
[2024-12-17 02:12:29,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:29,920][root][INFO] - Training Epoch: 1/2, step 5873/7134 completed (loss: 0.3257260322570801, acc: 0.9358288645744324)
[2024-12-17 02:12:29,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:30,159][root][INFO] - Training Epoch: 1/2, step 5874/7134 completed (loss: 0.2424241602420807, acc: 0.9444444179534912)
[2024-12-17 02:12:30,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:30,421][root][INFO] - Training Epoch: 1/2, step 5875/7134 completed (loss: 0.3752691447734833, acc: 0.9166666865348816)
[2024-12-17 02:12:30,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:30,694][root][INFO] - Training Epoch: 1/2, step 5876/7134 completed (loss: 0.21903662383556366, acc: 0.966292142868042)
[2024-12-17 02:12:30,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:30,969][root][INFO] - Training Epoch: 1/2, step 5877/7134 completed (loss: 0.20889316499233246, acc: 0.9441340565681458)
[2024-12-17 02:12:31,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:31,254][root][INFO] - Training Epoch: 1/2, step 5878/7134 completed (loss: 0.33464258909225464, acc: 0.918181836605072)
[2024-12-17 02:12:31,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:31,529][root][INFO] - Training Epoch: 1/2, step 5879/7134 completed (loss: 0.2032005935907364, acc: 0.9444444179534912)
[2024-12-17 02:12:31,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:31,793][root][INFO] - Training Epoch: 1/2, step 5880/7134 completed (loss: 0.22165344655513763, acc: 0.9642857313156128)
[2024-12-17 02:12:31,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:32,066][root][INFO] - Training Epoch: 1/2, step 5881/7134 completed (loss: 0.15813304483890533, acc: 0.9743589758872986)
[2024-12-17 02:12:32,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:32,325][root][INFO] - Training Epoch: 1/2, step 5882/7134 completed (loss: 0.12501570582389832, acc: 0.970588207244873)
[2024-12-17 02:12:32,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:32,613][root][INFO] - Training Epoch: 1/2, step 5883/7134 completed (loss: 0.19013051688671112, acc: 0.9461538195610046)
[2024-12-17 02:12:32,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:32,904][root][INFO] - Training Epoch: 1/2, step 5884/7134 completed (loss: 0.3536233603954315, acc: 0.9047619104385376)
[2024-12-17 02:12:33,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:33,205][root][INFO] - Training Epoch: 1/2, step 5885/7134 completed (loss: 0.6146036982536316, acc: 0.8627451062202454)
[2024-12-17 02:12:33,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:33,488][root][INFO] - Training Epoch: 1/2, step 5886/7134 completed (loss: 0.09006109088659286, acc: 0.976190447807312)
[2024-12-17 02:12:33,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:33,753][root][INFO] - Training Epoch: 1/2, step 5887/7134 completed (loss: 0.16376635432243347, acc: 0.9583333134651184)
[2024-12-17 02:12:33,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:34,040][root][INFO] - Training Epoch: 1/2, step 5888/7134 completed (loss: 0.4201721251010895, acc: 0.9219858050346375)
[2024-12-17 02:12:34,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:34,255][root][INFO] - Training Epoch: 1/2, step 5889/7134 completed (loss: 0.32316336035728455, acc: 0.9230769276618958)
[2024-12-17 02:12:34,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:34,535][root][INFO] - Training Epoch: 1/2, step 5890/7134 completed (loss: 0.11339489370584488, acc: 0.9729729890823364)
[2024-12-17 02:12:34,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:34,827][root][INFO] - Training Epoch: 1/2, step 5891/7134 completed (loss: 0.29983776807785034, acc: 0.9357143044471741)
[2024-12-17 02:12:34,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:35,124][root][INFO] - Training Epoch: 1/2, step 5892/7134 completed (loss: 0.19150543212890625, acc: 0.9651162624359131)
[2024-12-17 02:12:35,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:35,405][root][INFO] - Training Epoch: 1/2, step 5893/7134 completed (loss: 0.19105494022369385, acc: 0.9447852969169617)
[2024-12-17 02:12:35,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:35,690][root][INFO] - Training Epoch: 1/2, step 5894/7134 completed (loss: 0.2462993860244751, acc: 0.9594594836235046)
[2024-12-17 02:12:35,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:35,971][root][INFO] - Training Epoch: 1/2, step 5895/7134 completed (loss: 0.2633022665977478, acc: 0.9375)
[2024-12-17 02:12:36,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:36,243][root][INFO] - Training Epoch: 1/2, step 5896/7134 completed (loss: 0.23678706586360931, acc: 0.9371069073677063)
[2024-12-17 02:12:36,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:36,524][root][INFO] - Training Epoch: 1/2, step 5897/7134 completed (loss: 0.18198484182357788, acc: 0.9488636255264282)
[2024-12-17 02:12:36,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:36,812][root][INFO] - Training Epoch: 1/2, step 5898/7134 completed (loss: 0.5410317182540894, acc: 0.9017857313156128)
[2024-12-17 02:12:36,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:37,072][root][INFO] - Training Epoch: 1/2, step 5899/7134 completed (loss: 0.14509184658527374, acc: 0.9743589758872986)
[2024-12-17 02:12:37,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:37,323][root][INFO] - Training Epoch: 1/2, step 5900/7134 completed (loss: 0.16888459026813507, acc: 0.9506173133850098)
[2024-12-17 02:12:37,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:37,597][root][INFO] - Training Epoch: 1/2, step 5901/7134 completed (loss: 0.48014017939567566, acc: 0.8969072103500366)
[2024-12-17 02:12:37,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:37,874][root][INFO] - Training Epoch: 1/2, step 5902/7134 completed (loss: 0.18397484719753265, acc: 0.9489796161651611)
[2024-12-17 02:12:37,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:38,139][root][INFO] - Training Epoch: 1/2, step 5903/7134 completed (loss: 0.29029208421707153, acc: 0.9115044474601746)
[2024-12-17 02:12:38,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:38,424][root][INFO] - Training Epoch: 1/2, step 5904/7134 completed (loss: 0.354117214679718, acc: 0.9154929518699646)
[2024-12-17 02:12:38,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:38,694][root][INFO] - Training Epoch: 1/2, step 5905/7134 completed (loss: 0.25707101821899414, acc: 0.9527027010917664)
[2024-12-17 02:12:38,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:38,983][root][INFO] - Training Epoch: 1/2, step 5906/7134 completed (loss: 0.3788915276527405, acc: 0.8954248428344727)
[2024-12-17 02:12:39,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:39,286][root][INFO] - Training Epoch: 1/2, step 5907/7134 completed (loss: 0.1869969218969345, acc: 0.9652777910232544)
[2024-12-17 02:12:39,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:39,602][root][INFO] - Training Epoch: 1/2, step 5908/7134 completed (loss: 0.2708744406700134, acc: 0.9285714030265808)
[2024-12-17 02:12:39,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:40,001][root][INFO] - Training Epoch: 1/2, step 5909/7134 completed (loss: 0.3657817840576172, acc: 0.9124087691307068)
[2024-12-17 02:12:40,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:40,304][root][INFO] - Training Epoch: 1/2, step 5910/7134 completed (loss: 0.41981151700019836, acc: 0.8940397500991821)
[2024-12-17 02:12:40,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:40,585][root][INFO] - Training Epoch: 1/2, step 5911/7134 completed (loss: 0.3577333986759186, acc: 0.895652174949646)
[2024-12-17 02:12:40,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:40,842][root][INFO] - Training Epoch: 1/2, step 5912/7134 completed (loss: 0.22038021683692932, acc: 0.9453125)
[2024-12-17 02:12:40,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:41,132][root][INFO] - Training Epoch: 1/2, step 5913/7134 completed (loss: 0.28184184432029724, acc: 0.9408283829689026)
[2024-12-17 02:12:41,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:41,414][root][INFO] - Training Epoch: 1/2, step 5914/7134 completed (loss: 0.2659655809402466, acc: 0.9428571462631226)
[2024-12-17 02:12:41,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:41,703][root][INFO] - Training Epoch: 1/2, step 5915/7134 completed (loss: 0.40899157524108887, acc: 0.9160305261611938)
[2024-12-17 02:12:41,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:41,983][root][INFO] - Training Epoch: 1/2, step 5916/7134 completed (loss: 0.3396669626235962, acc: 0.940397322177887)
[2024-12-17 02:12:42,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:42,240][root][INFO] - Training Epoch: 1/2, step 5917/7134 completed (loss: 0.2633383274078369, acc: 0.9440000057220459)
[2024-12-17 02:12:42,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:42,529][root][INFO] - Training Epoch: 1/2, step 5918/7134 completed (loss: 0.3527095913887024, acc: 0.9020978808403015)
[2024-12-17 02:12:42,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:42,814][root][INFO] - Training Epoch: 1/2, step 5919/7134 completed (loss: 0.20236466825008392, acc: 0.9477611780166626)
[2024-12-17 02:12:42,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:43,091][root][INFO] - Training Epoch: 1/2, step 5920/7134 completed (loss: 0.2739545702934265, acc: 0.9029850959777832)
[2024-12-17 02:12:43,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:43,365][root][INFO] - Training Epoch: 1/2, step 5921/7134 completed (loss: 0.3776004910469055, acc: 0.8879310488700867)
[2024-12-17 02:12:43,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:43,656][root][INFO] - Training Epoch: 1/2, step 5922/7134 completed (loss: 1.0122051239013672, acc: 0.7756410241127014)
[2024-12-17 02:12:43,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:43,941][root][INFO] - Training Epoch: 1/2, step 5923/7134 completed (loss: 0.5371660590171814, acc: 0.8860759735107422)
[2024-12-17 02:12:44,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:44,216][root][INFO] - Training Epoch: 1/2, step 5924/7134 completed (loss: 0.4016122817993164, acc: 0.875)
[2024-12-17 02:12:44,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:44,463][root][INFO] - Training Epoch: 1/2, step 5925/7134 completed (loss: 0.9388981461524963, acc: 0.8444444537162781)
[2024-12-17 02:12:44,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:44,733][root][INFO] - Training Epoch: 1/2, step 5926/7134 completed (loss: 0.5614616274833679, acc: 0.8684210777282715)
[2024-12-17 02:12:44,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:44,996][root][INFO] - Training Epoch: 1/2, step 5927/7134 completed (loss: 0.4089639186859131, acc: 0.9107142686843872)
[2024-12-17 02:12:45,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:45,229][root][INFO] - Training Epoch: 1/2, step 5928/7134 completed (loss: 1.2038320302963257, acc: 0.8513513803482056)
[2024-12-17 02:12:45,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:45,505][root][INFO] - Training Epoch: 1/2, step 5929/7134 completed (loss: 0.5323828458786011, acc: 0.8387096524238586)
[2024-12-17 02:12:45,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:45,765][root][INFO] - Training Epoch: 1/2, step 5930/7134 completed (loss: 0.9554124474525452, acc: 0.8181818127632141)
[2024-12-17 02:12:45,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:46,026][root][INFO] - Training Epoch: 1/2, step 5931/7134 completed (loss: 0.42893198132514954, acc: 0.8547008633613586)
[2024-12-17 02:12:46,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:46,301][root][INFO] - Training Epoch: 1/2, step 5932/7134 completed (loss: 0.6257594227790833, acc: 0.8417266011238098)
[2024-12-17 02:12:46,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:46,551][root][INFO] - Training Epoch: 1/2, step 5933/7134 completed (loss: 0.6795470714569092, acc: 0.8382353186607361)
[2024-12-17 02:12:46,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:46,822][root][INFO] - Training Epoch: 1/2, step 5934/7134 completed (loss: 0.39537349343299866, acc: 0.9071428775787354)
[2024-12-17 02:12:46,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:47,086][root][INFO] - Training Epoch: 1/2, step 5935/7134 completed (loss: 0.23814699053764343, acc: 0.9180327653884888)
[2024-12-17 02:12:47,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:47,342][root][INFO] - Training Epoch: 1/2, step 5936/7134 completed (loss: 0.5300258994102478, acc: 0.8834356069564819)
[2024-12-17 02:12:47,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:47,618][root][INFO] - Training Epoch: 1/2, step 5937/7134 completed (loss: 0.24210046231746674, acc: 0.9436619877815247)
[2024-12-17 02:12:47,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:47,891][root][INFO] - Training Epoch: 1/2, step 5938/7134 completed (loss: 0.2605687975883484, acc: 0.9398496150970459)
[2024-12-17 02:12:47,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:48,141][root][INFO] - Training Epoch: 1/2, step 5939/7134 completed (loss: 1.2370283603668213, acc: 0.7758620977401733)
[2024-12-17 02:12:48,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:48,434][root][INFO] - Training Epoch: 1/2, step 5940/7134 completed (loss: 0.4006786346435547, acc: 0.9068322777748108)
[2024-12-17 02:12:48,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:48,694][root][INFO] - Training Epoch: 1/2, step 5941/7134 completed (loss: 0.32751551270484924, acc: 0.9166666865348816)
[2024-12-17 02:12:48,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:48,957][root][INFO] - Training Epoch: 1/2, step 5942/7134 completed (loss: 0.15368172526359558, acc: 0.9440000057220459)
[2024-12-17 02:12:49,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:49,219][root][INFO] - Training Epoch: 1/2, step 5943/7134 completed (loss: 0.20420430600643158, acc: 0.9631901979446411)
[2024-12-17 02:12:49,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:49,505][root][INFO] - Training Epoch: 1/2, step 5944/7134 completed (loss: 0.33351391553878784, acc: 0.9132652878761292)
[2024-12-17 02:12:49,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:49,798][root][INFO] - Training Epoch: 1/2, step 5945/7134 completed (loss: 0.18953774869441986, acc: 0.9644970297813416)
[2024-12-17 02:12:49,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:50,063][root][INFO] - Training Epoch: 1/2, step 5946/7134 completed (loss: 0.2923433184623718, acc: 0.8958333134651184)
[2024-12-17 02:12:50,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:50,345][root][INFO] - Training Epoch: 1/2, step 5947/7134 completed (loss: 0.3245733082294464, acc: 0.9278846383094788)
[2024-12-17 02:12:50,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:50,618][root][INFO] - Training Epoch: 1/2, step 5948/7134 completed (loss: 0.464044451713562, acc: 0.8943089246749878)
[2024-12-17 02:12:50,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:50,891][root][INFO] - Training Epoch: 1/2, step 5949/7134 completed (loss: 0.16258348524570465, acc: 0.9555555582046509)
[2024-12-17 02:12:50,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:51,153][root][INFO] - Training Epoch: 1/2, step 5950/7134 completed (loss: 0.45679187774658203, acc: 0.8811880946159363)
[2024-12-17 02:12:51,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:51,435][root][INFO] - Training Epoch: 1/2, step 5951/7134 completed (loss: 0.5440402030944824, acc: 0.886904776096344)
[2024-12-17 02:12:51,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:51,728][root][INFO] - Training Epoch: 1/2, step 5952/7134 completed (loss: 0.7788093686103821, acc: 0.8486841917037964)
[2024-12-17 02:12:51,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:52,007][root][INFO] - Training Epoch: 1/2, step 5953/7134 completed (loss: 0.281825989484787, acc: 0.9339622855186462)
[2024-12-17 02:12:52,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:52,277][root][INFO] - Training Epoch: 1/2, step 5954/7134 completed (loss: 0.13947255909442902, acc: 0.9603960514068604)
[2024-12-17 02:12:52,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:52,489][root][INFO] - Training Epoch: 1/2, step 5955/7134 completed (loss: 0.28142133355140686, acc: 0.9444444179534912)
[2024-12-17 02:12:52,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:52,743][root][INFO] - Training Epoch: 1/2, step 5956/7134 completed (loss: 0.31837308406829834, acc: 0.925000011920929)
[2024-12-17 02:12:52,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:53,001][root][INFO] - Training Epoch: 1/2, step 5957/7134 completed (loss: 0.2549339234828949, acc: 0.9268292784690857)
[2024-12-17 02:12:53,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:53,282][root][INFO] - Training Epoch: 1/2, step 5958/7134 completed (loss: 0.3898930549621582, acc: 0.9142857193946838)
[2024-12-17 02:12:53,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:53,559][root][INFO] - Training Epoch: 1/2, step 5959/7134 completed (loss: 0.20033590495586395, acc: 0.9521276354789734)
[2024-12-17 02:12:53,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:53,834][root][INFO] - Training Epoch: 1/2, step 5960/7134 completed (loss: 0.03510462865233421, acc: 0.9940476417541504)
[2024-12-17 02:12:53,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:54,088][root][INFO] - Training Epoch: 1/2, step 5961/7134 completed (loss: 0.4204448163509369, acc: 0.8888888955116272)
[2024-12-17 02:12:54,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:54,358][root][INFO] - Training Epoch: 1/2, step 5962/7134 completed (loss: 0.29324185848236084, acc: 0.9103448390960693)
[2024-12-17 02:12:54,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:54,635][root][INFO] - Training Epoch: 1/2, step 5963/7134 completed (loss: 0.2428443729877472, acc: 0.9314285516738892)
[2024-12-17 02:12:54,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:54,913][root][INFO] - Training Epoch: 1/2, step 5964/7134 completed (loss: 0.15551064908504486, acc: 0.960629940032959)
[2024-12-17 02:12:55,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:55,188][root][INFO] - Training Epoch: 1/2, step 5965/7134 completed (loss: 0.155489981174469, acc: 0.9551281929016113)
[2024-12-17 02:12:55,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:55,476][root][INFO] - Training Epoch: 1/2, step 5966/7134 completed (loss: 0.25818198919296265, acc: 0.945652186870575)
[2024-12-17 02:12:55,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:55,783][root][INFO] - Training Epoch: 1/2, step 5967/7134 completed (loss: 0.241984024643898, acc: 0.9375)
[2024-12-17 02:12:55,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:56,059][root][INFO] - Training Epoch: 1/2, step 5968/7134 completed (loss: 0.25078678131103516, acc: 0.9700000286102295)
[2024-12-17 02:12:56,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:56,339][root][INFO] - Training Epoch: 1/2, step 5969/7134 completed (loss: 0.20608872175216675, acc: 0.9612902998924255)
[2024-12-17 02:12:56,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:56,625][root][INFO] - Training Epoch: 1/2, step 5970/7134 completed (loss: 0.17541325092315674, acc: 0.9609375)
[2024-12-17 02:12:56,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:56,945][root][INFO] - Training Epoch: 1/2, step 5971/7134 completed (loss: 0.11523506790399551, acc: 0.9578947424888611)
[2024-12-17 02:12:57,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:57,233][root][INFO] - Training Epoch: 1/2, step 5972/7134 completed (loss: 0.47956717014312744, acc: 0.8588957190513611)
[2024-12-17 02:12:57,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:57,535][root][INFO] - Training Epoch: 1/2, step 5973/7134 completed (loss: 0.25171762704849243, acc: 0.954285740852356)
[2024-12-17 02:12:57,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:57,828][root][INFO] - Training Epoch: 1/2, step 5974/7134 completed (loss: 0.15984998643398285, acc: 0.970588207244873)
[2024-12-17 02:12:57,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:58,077][root][INFO] - Training Epoch: 1/2, step 5975/7134 completed (loss: 0.13345688581466675, acc: 0.9695122241973877)
[2024-12-17 02:12:58,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:58,353][root][INFO] - Training Epoch: 1/2, step 5976/7134 completed (loss: 0.29573190212249756, acc: 0.9346405267715454)
[2024-12-17 02:12:58,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:58,627][root][INFO] - Training Epoch: 1/2, step 5977/7134 completed (loss: 0.2020772397518158, acc: 0.9599999785423279)
[2024-12-17 02:12:58,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:58,910][root][INFO] - Training Epoch: 1/2, step 5978/7134 completed (loss: 0.2832631766796112, acc: 0.9316770434379578)
[2024-12-17 02:12:59,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:59,159][root][INFO] - Training Epoch: 1/2, step 5979/7134 completed (loss: 0.42451098561286926, acc: 0.9263157844543457)
[2024-12-17 02:12:59,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:59,431][root][INFO] - Training Epoch: 1/2, step 5980/7134 completed (loss: 0.12184810638427734, acc: 0.9728260636329651)
[2024-12-17 02:12:59,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:59,711][root][INFO] - Training Epoch: 1/2, step 5981/7134 completed (loss: 0.143545001745224, acc: 0.9796954393386841)
[2024-12-17 02:12:59,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:59,962][root][INFO] - Training Epoch: 1/2, step 5982/7134 completed (loss: 0.17314237356185913, acc: 0.9596773982048035)
[2024-12-17 02:13:00,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:00,225][root][INFO] - Training Epoch: 1/2, step 5983/7134 completed (loss: 0.32866033911705017, acc: 0.8850574493408203)
[2024-12-17 02:13:00,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:00,492][root][INFO] - Training Epoch: 1/2, step 5984/7134 completed (loss: 0.18566405773162842, acc: 0.9575757384300232)
[2024-12-17 02:13:00,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:00,766][root][INFO] - Training Epoch: 1/2, step 5985/7134 completed (loss: 0.17720791697502136, acc: 0.9606741666793823)
[2024-12-17 02:13:00,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:01,056][root][INFO] - Training Epoch: 1/2, step 5986/7134 completed (loss: 0.26771456003189087, acc: 0.9523809552192688)
[2024-12-17 02:13:01,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:01,338][root][INFO] - Training Epoch: 1/2, step 5987/7134 completed (loss: 0.23080673813819885, acc: 0.9365853667259216)
[2024-12-17 02:13:01,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:01,600][root][INFO] - Training Epoch: 1/2, step 5988/7134 completed (loss: 0.12737219035625458, acc: 0.9666666388511658)
[2024-12-17 02:13:01,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:01,874][root][INFO] - Training Epoch: 1/2, step 5989/7134 completed (loss: 0.2140091508626938, acc: 0.9307692050933838)
[2024-12-17 02:13:01,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:02,174][root][INFO] - Training Epoch: 1/2, step 5990/7134 completed (loss: 0.3780550956726074, acc: 0.9171270728111267)
[2024-12-17 02:13:02,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:02,454][root][INFO] - Training Epoch: 1/2, step 5991/7134 completed (loss: 0.18804477155208588, acc: 0.9659090638160706)
[2024-12-17 02:13:02,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:02,747][root][INFO] - Training Epoch: 1/2, step 5992/7134 completed (loss: 0.1474115550518036, acc: 0.9438775777816772)
[2024-12-17 02:13:02,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:03,012][root][INFO] - Training Epoch: 1/2, step 5993/7134 completed (loss: 0.1619829386472702, acc: 0.966292142868042)
[2024-12-17 02:13:03,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:03,304][root][INFO] - Training Epoch: 1/2, step 5994/7134 completed (loss: 0.10362139344215393, acc: 0.9752066135406494)
[2024-12-17 02:13:03,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:03,587][root][INFO] - Training Epoch: 1/2, step 5995/7134 completed (loss: 0.1291547417640686, acc: 0.9653179049491882)
[2024-12-17 02:13:03,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:03,866][root][INFO] - Training Epoch: 1/2, step 5996/7134 completed (loss: 0.21858225762844086, acc: 0.9399999976158142)
[2024-12-17 02:13:03,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:04,138][root][INFO] - Training Epoch: 1/2, step 5997/7134 completed (loss: 0.1747758388519287, acc: 0.9602272510528564)
[2024-12-17 02:13:04,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:04,408][root][INFO] - Training Epoch: 1/2, step 5998/7134 completed (loss: 0.15595340728759766, acc: 0.9470899701118469)
[2024-12-17 02:13:04,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:04,670][root][INFO] - Training Epoch: 1/2, step 5999/7134 completed (loss: 0.09921743720769882, acc: 0.9855072498321533)
[2024-12-17 02:13:04,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:04,924][root][INFO] - Training Epoch: 1/2, step 6000/7134 completed (loss: 0.1254884898662567, acc: 0.9718309640884399)
[2024-12-17 02:13:05,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:05,203][root][INFO] - Training Epoch: 1/2, step 6001/7134 completed (loss: 0.11398980021476746, acc: 0.987730085849762)
[2024-12-17 02:13:05,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:05,478][root][INFO] - Training Epoch: 1/2, step 6002/7134 completed (loss: 0.1648712456226349, acc: 0.9504132270812988)
[2024-12-17 02:13:05,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:05,790][root][INFO] - Training Epoch: 1/2, step 6003/7134 completed (loss: 0.26868242025375366, acc: 0.9285714030265808)
[2024-12-17 02:13:05,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:06,073][root][INFO] - Training Epoch: 1/2, step 6004/7134 completed (loss: 0.7151228189468384, acc: 0.8670520186424255)
[2024-12-17 02:13:06,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:06,337][root][INFO] - Training Epoch: 1/2, step 6005/7134 completed (loss: 0.3366891145706177, acc: 0.9271523356437683)
[2024-12-17 02:13:06,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:06,613][root][INFO] - Training Epoch: 1/2, step 6006/7134 completed (loss: 0.26502612233161926, acc: 0.9359999895095825)
[2024-12-17 02:13:06,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:06,894][root][INFO] - Training Epoch: 1/2, step 6007/7134 completed (loss: 0.22935429215431213, acc: 0.9411764740943909)
[2024-12-17 02:13:06,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:07,167][root][INFO] - Training Epoch: 1/2, step 6008/7134 completed (loss: 0.26657742261886597, acc: 0.9160839319229126)
[2024-12-17 02:13:07,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:07,434][root][INFO] - Training Epoch: 1/2, step 6009/7134 completed (loss: 0.2942788600921631, acc: 0.932330846786499)
[2024-12-17 02:13:07,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:07,704][root][INFO] - Training Epoch: 1/2, step 6010/7134 completed (loss: 0.3628951907157898, acc: 0.8987341523170471)
[2024-12-17 02:13:07,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:07,987][root][INFO] - Training Epoch: 1/2, step 6011/7134 completed (loss: 0.3838904798030853, acc: 0.9107142686843872)
[2024-12-17 02:13:08,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:08,264][root][INFO] - Training Epoch: 1/2, step 6012/7134 completed (loss: 0.167397141456604, acc: 0.9454545378684998)
[2024-12-17 02:13:08,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:08,537][root][INFO] - Training Epoch: 1/2, step 6013/7134 completed (loss: 0.4297950863838196, acc: 0.9213483333587646)
[2024-12-17 02:13:08,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:08,797][root][INFO] - Training Epoch: 1/2, step 6014/7134 completed (loss: 0.3370533585548401, acc: 0.8818897604942322)
[2024-12-17 02:13:08,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:09,089][root][INFO] - Training Epoch: 1/2, step 6015/7134 completed (loss: 0.3729892671108246, acc: 0.9009009003639221)
[2024-12-17 02:13:09,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:09,351][root][INFO] - Training Epoch: 1/2, step 6016/7134 completed (loss: 0.30389681458473206, acc: 0.9324324131011963)
[2024-12-17 02:13:09,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:09,599][root][INFO] - Training Epoch: 1/2, step 6017/7134 completed (loss: 0.3827149271965027, acc: 0.9038461446762085)
[2024-12-17 02:13:09,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:09,860][root][INFO] - Training Epoch: 1/2, step 6018/7134 completed (loss: 0.3066455125808716, acc: 0.9230769276618958)
[2024-12-17 02:13:09,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:10,101][root][INFO] - Training Epoch: 1/2, step 6019/7134 completed (loss: 0.4929213523864746, acc: 0.8888888955116272)
[2024-12-17 02:13:10,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:10,341][root][INFO] - Training Epoch: 1/2, step 6020/7134 completed (loss: 0.09799697995185852, acc: 0.9841269850730896)
[2024-12-17 02:13:10,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:10,569][root][INFO] - Training Epoch: 1/2, step 6021/7134 completed (loss: 0.09769514948129654, acc: 0.9756097793579102)
[2024-12-17 02:13:10,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:10,823][root][INFO] - Training Epoch: 1/2, step 6022/7134 completed (loss: 0.25558769702911377, acc: 0.9342105388641357)
[2024-12-17 02:13:10,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:11,057][root][INFO] - Training Epoch: 1/2, step 6023/7134 completed (loss: 0.07193488627672195, acc: 0.9772727489471436)
[2024-12-17 02:13:11,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:11,283][root][INFO] - Training Epoch: 1/2, step 6024/7134 completed (loss: 0.08325155824422836, acc: 1.0)
[2024-12-17 02:13:11,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:11,566][root][INFO] - Training Epoch: 1/2, step 6025/7134 completed (loss: 0.22073137760162354, acc: 0.9180327653884888)
[2024-12-17 02:13:11,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:11,815][root][INFO] - Training Epoch: 1/2, step 6026/7134 completed (loss: 0.45902252197265625, acc: 0.8983050584793091)
[2024-12-17 02:13:11,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:12,075][root][INFO] - Training Epoch: 1/2, step 6027/7134 completed (loss: 0.22127336263656616, acc: 0.932584285736084)
[2024-12-17 02:13:12,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:12,349][root][INFO] - Training Epoch: 1/2, step 6028/7134 completed (loss: 0.3881319761276245, acc: 0.9166666865348816)
[2024-12-17 02:13:12,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:12,629][root][INFO] - Training Epoch: 1/2, step 6029/7134 completed (loss: 0.2529626488685608, acc: 0.9154929518699646)
[2024-12-17 02:13:12,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:12,919][root][INFO] - Training Epoch: 1/2, step 6030/7134 completed (loss: 0.1431940346956253, acc: 0.9696969985961914)
[2024-12-17 02:13:13,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:13,234][root][INFO] - Training Epoch: 1/2, step 6031/7134 completed (loss: 0.2099098414182663, acc: 0.930232584476471)
[2024-12-17 02:13:13,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:13,513][root][INFO] - Training Epoch: 1/2, step 6032/7134 completed (loss: 0.111721932888031, acc: 0.9702970385551453)
[2024-12-17 02:13:13,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:13,818][root][INFO] - Training Epoch: 1/2, step 6033/7134 completed (loss: 0.2643471956253052, acc: 0.939393937587738)
[2024-12-17 02:13:13,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:14,056][root][INFO] - Training Epoch: 1/2, step 6034/7134 completed (loss: 0.3814252018928528, acc: 0.9253731369972229)
[2024-12-17 02:13:14,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:14,374][root][INFO] - Training Epoch: 1/2, step 6035/7134 completed (loss: 0.463890016078949, acc: 0.8826290965080261)
[2024-12-17 02:13:14,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:14,685][root][INFO] - Training Epoch: 1/2, step 6036/7134 completed (loss: 0.48033571243286133, acc: 0.8764045238494873)
[2024-12-17 02:13:14,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:14,999][root][INFO] - Training Epoch: 1/2, step 6037/7134 completed (loss: 0.3459412753582001, acc: 0.9219858050346375)
[2024-12-17 02:13:15,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:15,305][root][INFO] - Training Epoch: 1/2, step 6038/7134 completed (loss: 0.48099973797798157, acc: 0.8872548937797546)
[2024-12-17 02:13:15,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:15,604][root][INFO] - Training Epoch: 1/2, step 6039/7134 completed (loss: 0.3586280345916748, acc: 0.9219512343406677)
[2024-12-17 02:13:15,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:15,901][root][INFO] - Training Epoch: 1/2, step 6040/7134 completed (loss: 0.33135244250297546, acc: 0.933920681476593)
[2024-12-17 02:13:16,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:16,167][root][INFO] - Training Epoch: 1/2, step 6041/7134 completed (loss: 0.36860430240631104, acc: 0.8870967626571655)
[2024-12-17 02:13:16,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:16,437][root][INFO] - Training Epoch: 1/2, step 6042/7134 completed (loss: 0.19047890603542328, acc: 0.9541284441947937)
[2024-12-17 02:13:16,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:16,714][root][INFO] - Training Epoch: 1/2, step 6043/7134 completed (loss: 0.3489669859409332, acc: 0.9193548560142517)
[2024-12-17 02:13:16,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:16,989][root][INFO] - Training Epoch: 1/2, step 6044/7134 completed (loss: 0.21034760773181915, acc: 0.9428571462631226)
[2024-12-17 02:13:17,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:17,265][root][INFO] - Training Epoch: 1/2, step 6045/7134 completed (loss: 0.29959166049957275, acc: 0.9186602830886841)
[2024-12-17 02:13:17,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:17,544][root][INFO] - Training Epoch: 1/2, step 6046/7134 completed (loss: 0.49363839626312256, acc: 0.8698630332946777)
[2024-12-17 02:13:17,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:17,822][root][INFO] - Training Epoch: 1/2, step 6047/7134 completed (loss: 0.5377270579338074, acc: 0.8775510191917419)
[2024-12-17 02:13:17,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:18,096][root][INFO] - Training Epoch: 1/2, step 6048/7134 completed (loss: 0.5251566171646118, acc: 0.8455284833908081)
[2024-12-17 02:13:18,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:18,350][root][INFO] - Training Epoch: 1/2, step 6049/7134 completed (loss: 0.30872398614883423, acc: 0.9020978808403015)
[2024-12-17 02:13:18,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:18,610][root][INFO] - Training Epoch: 1/2, step 6050/7134 completed (loss: 0.47606492042541504, acc: 0.8439306616783142)
[2024-12-17 02:13:18,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:18,899][root][INFO] - Training Epoch: 1/2, step 6051/7134 completed (loss: 0.46381646394729614, acc: 0.8977272510528564)
[2024-12-17 02:13:19,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:19,186][root][INFO] - Training Epoch: 1/2, step 6052/7134 completed (loss: 0.5518500804901123, acc: 0.8533333539962769)
[2024-12-17 02:13:19,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:19,466][root][INFO] - Training Epoch: 1/2, step 6053/7134 completed (loss: 0.4183761477470398, acc: 0.8982300758361816)
[2024-12-17 02:13:19,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:19,737][root][INFO] - Training Epoch: 1/2, step 6054/7134 completed (loss: 0.3062715530395508, acc: 0.9274611473083496)
[2024-12-17 02:13:19,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:19,984][root][INFO] - Training Epoch: 1/2, step 6055/7134 completed (loss: 0.3534410893917084, acc: 0.8896104097366333)
[2024-12-17 02:13:20,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:20,262][root][INFO] - Training Epoch: 1/2, step 6056/7134 completed (loss: 0.7895817756652832, acc: 0.8018018007278442)
[2024-12-17 02:13:20,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:20,525][root][INFO] - Training Epoch: 1/2, step 6057/7134 completed (loss: 0.35391008853912354, acc: 0.8961039185523987)
[2024-12-17 02:13:20,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:20,792][root][INFO] - Training Epoch: 1/2, step 6058/7134 completed (loss: 0.13956643640995026, acc: 0.9661017060279846)
[2024-12-17 02:13:20,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:21,052][root][INFO] - Training Epoch: 1/2, step 6059/7134 completed (loss: 0.17153960466384888, acc: 0.9589040875434875)
[2024-12-17 02:13:21,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:21,324][root][INFO] - Training Epoch: 1/2, step 6060/7134 completed (loss: 0.3037564754486084, acc: 0.9135802388191223)
[2024-12-17 02:13:21,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:21,589][root][INFO] - Training Epoch: 1/2, step 6061/7134 completed (loss: 0.5132938027381897, acc: 0.8943662047386169)
[2024-12-17 02:13:21,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:21,863][root][INFO] - Training Epoch: 1/2, step 6062/7134 completed (loss: 0.4512188732624054, acc: 0.8835979104042053)
[2024-12-17 02:13:21,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:22,125][root][INFO] - Training Epoch: 1/2, step 6063/7134 completed (loss: 0.3926735818386078, acc: 0.8728813529014587)
[2024-12-17 02:13:22,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:22,400][root][INFO] - Training Epoch: 1/2, step 6064/7134 completed (loss: 0.39698320627212524, acc: 0.9006211161613464)
[2024-12-17 02:13:22,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:22,672][root][INFO] - Training Epoch: 1/2, step 6065/7134 completed (loss: 0.3593381345272064, acc: 0.9086294174194336)
[2024-12-17 02:13:22,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:22,939][root][INFO] - Training Epoch: 1/2, step 6066/7134 completed (loss: 0.4675803780555725, acc: 0.8962963223457336)
[2024-12-17 02:13:23,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:23,205][root][INFO] - Training Epoch: 1/2, step 6067/7134 completed (loss: 0.6016771793365479, acc: 0.8486841917037964)
[2024-12-17 02:13:23,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:23,527][root][INFO] - Training Epoch: 1/2, step 6068/7134 completed (loss: 0.6457036733627319, acc: 0.8270270228385925)
[2024-12-17 02:13:23,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:23,791][root][INFO] - Training Epoch: 1/2, step 6069/7134 completed (loss: 0.4615929424762726, acc: 0.8647058606147766)
[2024-12-17 02:13:23,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:24,083][root][INFO] - Training Epoch: 1/2, step 6070/7134 completed (loss: 0.35053467750549316, acc: 0.9085714221000671)
[2024-12-17 02:13:24,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:24,343][root][INFO] - Training Epoch: 1/2, step 6071/7134 completed (loss: 0.40448540449142456, acc: 0.8757396340370178)
[2024-12-17 02:13:24,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:24,603][root][INFO] - Training Epoch: 1/2, step 6072/7134 completed (loss: 0.6601144075393677, acc: 0.8333333134651184)
[2024-12-17 02:13:24,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:24,883][root][INFO] - Training Epoch: 1/2, step 6073/7134 completed (loss: 0.4718894362449646, acc: 0.8789808750152588)
[2024-12-17 02:13:25,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:25,156][root][INFO] - Training Epoch: 1/2, step 6074/7134 completed (loss: 0.5525422692298889, acc: 0.8580645322799683)
[2024-12-17 02:13:25,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:25,436][root][INFO] - Training Epoch: 1/2, step 6075/7134 completed (loss: 0.39068564772605896, acc: 0.9157894849777222)
[2024-12-17 02:13:25,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:25,737][root][INFO] - Training Epoch: 1/2, step 6076/7134 completed (loss: 0.5602355003356934, acc: 0.8609625697135925)
[2024-12-17 02:13:25,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:26,029][root][INFO] - Training Epoch: 1/2, step 6077/7134 completed (loss: 0.39786186814308167, acc: 0.8934911489486694)
[2024-12-17 02:13:26,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:26,312][root][INFO] - Training Epoch: 1/2, step 6078/7134 completed (loss: 0.4410606324672699, acc: 0.8926553726196289)
[2024-12-17 02:13:26,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:26,604][root][INFO] - Training Epoch: 1/2, step 6079/7134 completed (loss: 0.2682535648345947, acc: 0.939393937587738)
[2024-12-17 02:13:26,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:26,895][root][INFO] - Training Epoch: 1/2, step 6080/7134 completed (loss: 0.29256388545036316, acc: 0.9425287246704102)
[2024-12-17 02:13:27,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:27,179][root][INFO] - Training Epoch: 1/2, step 6081/7134 completed (loss: 0.4750082194805145, acc: 0.9054054021835327)
[2024-12-17 02:13:27,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:27,456][root][INFO] - Training Epoch: 1/2, step 6082/7134 completed (loss: 0.23732972145080566, acc: 0.9395973086357117)
[2024-12-17 02:13:27,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:27,745][root][INFO] - Training Epoch: 1/2, step 6083/7134 completed (loss: 0.16915416717529297, acc: 0.9533678889274597)
[2024-12-17 02:13:27,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:28,005][root][INFO] - Training Epoch: 1/2, step 6084/7134 completed (loss: 0.38687455654144287, acc: 0.9066666960716248)
[2024-12-17 02:13:28,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:28,283][root][INFO] - Training Epoch: 1/2, step 6085/7134 completed (loss: 0.3570829927921295, acc: 0.9166666865348816)
[2024-12-17 02:13:28,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:28,580][root][INFO] - Training Epoch: 1/2, step 6086/7134 completed (loss: 0.14897951483726501, acc: 0.9617486596107483)
[2024-12-17 02:13:28,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:28,871][root][INFO] - Training Epoch: 1/2, step 6087/7134 completed (loss: 0.37421301007270813, acc: 0.9215686321258545)
[2024-12-17 02:13:29,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:29,153][root][INFO] - Training Epoch: 1/2, step 6088/7134 completed (loss: 0.3481343984603882, acc: 0.9243243336677551)
[2024-12-17 02:13:29,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:29,448][root][INFO] - Training Epoch: 1/2, step 6089/7134 completed (loss: 0.29113829135894775, acc: 0.9200000166893005)
[2024-12-17 02:13:29,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:29,738][root][INFO] - Training Epoch: 1/2, step 6090/7134 completed (loss: 0.1660052090883255, acc: 0.9518716335296631)
[2024-12-17 02:13:29,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:30,031][root][INFO] - Training Epoch: 1/2, step 6091/7134 completed (loss: 0.3774637281894684, acc: 0.8917197585105896)
[2024-12-17 02:13:30,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:30,310][root][INFO] - Training Epoch: 1/2, step 6092/7134 completed (loss: 0.3778477609157562, acc: 0.9151515364646912)
[2024-12-17 02:13:30,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:30,580][root][INFO] - Training Epoch: 1/2, step 6093/7134 completed (loss: 0.3654419779777527, acc: 0.9253731369972229)
[2024-12-17 02:13:30,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:30,867][root][INFO] - Training Epoch: 1/2, step 6094/7134 completed (loss: 0.5301805734634399, acc: 0.8693181872367859)
[2024-12-17 02:13:31,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:31,175][root][INFO] - Training Epoch: 1/2, step 6095/7134 completed (loss: 0.22707314789295197, acc: 0.9325153231620789)
[2024-12-17 02:13:31,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:31,486][root][INFO] - Training Epoch: 1/2, step 6096/7134 completed (loss: 0.41654646396636963, acc: 0.9086294174194336)
[2024-12-17 02:13:31,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:31,791][root][INFO] - Training Epoch: 1/2, step 6097/7134 completed (loss: 0.4059981405735016, acc: 0.8944099545478821)
[2024-12-17 02:13:31,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:32,093][root][INFO] - Training Epoch: 1/2, step 6098/7134 completed (loss: 0.3952528238296509, acc: 0.9064327478408813)
[2024-12-17 02:13:32,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:32,404][root][INFO] - Training Epoch: 1/2, step 6099/7134 completed (loss: 0.3117292821407318, acc: 0.9047619104385376)
[2024-12-17 02:13:32,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:32,691][root][INFO] - Training Epoch: 1/2, step 6100/7134 completed (loss: 0.5688151121139526, acc: 0.8974359035491943)
[2024-12-17 02:13:32,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:32,965][root][INFO] - Training Epoch: 1/2, step 6101/7134 completed (loss: 0.21119660139083862, acc: 0.9305555820465088)
[2024-12-17 02:13:33,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:33,244][root][INFO] - Training Epoch: 1/2, step 6102/7134 completed (loss: 0.35903871059417725, acc: 0.90625)
[2024-12-17 02:13:33,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:33,523][root][INFO] - Training Epoch: 1/2, step 6103/7134 completed (loss: 0.2995728850364685, acc: 0.9090909361839294)
[2024-12-17 02:13:33,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:33,793][root][INFO] - Training Epoch: 1/2, step 6104/7134 completed (loss: 0.6685123443603516, acc: 0.8581081032752991)
[2024-12-17 02:13:33,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:34,085][root][INFO] - Training Epoch: 1/2, step 6105/7134 completed (loss: 0.8500282764434814, acc: 0.8121212124824524)
[2024-12-17 02:13:34,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:34,337][root][INFO] - Training Epoch: 1/2, step 6106/7134 completed (loss: 0.48389166593551636, acc: 0.9212598204612732)
[2024-12-17 02:13:34,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:34,613][root][INFO] - Training Epoch: 1/2, step 6107/7134 completed (loss: 0.2455012947320938, acc: 0.94017094373703)
[2024-12-17 02:13:34,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:34,892][root][INFO] - Training Epoch: 1/2, step 6108/7134 completed (loss: 0.3090720474720001, acc: 0.9173553586006165)
[2024-12-17 02:13:35,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:35,152][root][INFO] - Training Epoch: 1/2, step 6109/7134 completed (loss: 0.18356172740459442, acc: 0.95652174949646)
[2024-12-17 02:13:35,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:35,435][root][INFO] - Training Epoch: 1/2, step 6110/7134 completed (loss: 0.529687225818634, acc: 0.8828125)
[2024-12-17 02:13:35,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:35,680][root][INFO] - Training Epoch: 1/2, step 6111/7134 completed (loss: 0.4844001233577728, acc: 0.8695651888847351)
[2024-12-17 02:13:35,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:35,960][root][INFO] - Training Epoch: 1/2, step 6112/7134 completed (loss: 0.5400116443634033, acc: 0.8496732115745544)
[2024-12-17 02:13:36,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:36,242][root][INFO] - Training Epoch: 1/2, step 6113/7134 completed (loss: 0.4615940451622009, acc: 0.9390243887901306)
[2024-12-17 02:13:36,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:36,501][root][INFO] - Training Epoch: 1/2, step 6114/7134 completed (loss: 0.2997608184814453, acc: 0.9300699234008789)
[2024-12-17 02:13:36,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:36,779][root][INFO] - Training Epoch: 1/2, step 6115/7134 completed (loss: 0.2721693813800812, acc: 0.9279999732971191)
[2024-12-17 02:13:36,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:37,067][root][INFO] - Training Epoch: 1/2, step 6116/7134 completed (loss: 0.5386064052581787, acc: 0.9032257795333862)
[2024-12-17 02:13:37,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:37,363][root][INFO] - Training Epoch: 1/2, step 6117/7134 completed (loss: 0.4510159194469452, acc: 0.8922155499458313)
[2024-12-17 02:13:37,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:37,657][root][INFO] - Training Epoch: 1/2, step 6118/7134 completed (loss: 0.2619035542011261, acc: 0.9285714030265808)
[2024-12-17 02:13:37,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:37,946][root][INFO] - Training Epoch: 1/2, step 6119/7134 completed (loss: 0.37828493118286133, acc: 0.9027026891708374)
[2024-12-17 02:13:38,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:38,222][root][INFO] - Training Epoch: 1/2, step 6120/7134 completed (loss: 0.20179270207881927, acc: 0.939393937587738)
[2024-12-17 02:13:38,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:38,512][root][INFO] - Training Epoch: 1/2, step 6121/7134 completed (loss: 0.37046125531196594, acc: 0.9212598204612732)
[2024-12-17 02:13:38,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:38,799][root][INFO] - Training Epoch: 1/2, step 6122/7134 completed (loss: 0.3165130317211151, acc: 0.9112903475761414)
[2024-12-17 02:13:38,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:39,076][root][INFO] - Training Epoch: 1/2, step 6123/7134 completed (loss: 0.35641175508499146, acc: 0.9230769276618958)
[2024-12-17 02:13:39,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:39,346][root][INFO] - Training Epoch: 1/2, step 6124/7134 completed (loss: 0.23025435209274292, acc: 0.9495798349380493)
[2024-12-17 02:13:39,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:39,661][root][INFO] - Training Epoch: 1/2, step 6125/7134 completed (loss: 0.4964762032032013, acc: 0.9065420627593994)
[2024-12-17 02:13:39,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:39,959][root][INFO] - Training Epoch: 1/2, step 6126/7134 completed (loss: 0.23006540536880493, acc: 0.9668874144554138)
[2024-12-17 02:13:40,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:40,218][root][INFO] - Training Epoch: 1/2, step 6127/7134 completed (loss: 0.2785471975803375, acc: 0.9019607901573181)
[2024-12-17 02:13:40,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:40,487][root][INFO] - Training Epoch: 1/2, step 6128/7134 completed (loss: 0.3650292754173279, acc: 0.8991596698760986)
[2024-12-17 02:13:40,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:40,770][root][INFO] - Training Epoch: 1/2, step 6129/7134 completed (loss: 0.40946945548057556, acc: 0.8875739574432373)
[2024-12-17 02:13:40,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:41,042][root][INFO] - Training Epoch: 1/2, step 6130/7134 completed (loss: 0.45211488008499146, acc: 0.8731343150138855)
[2024-12-17 02:13:41,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:41,326][root][INFO] - Training Epoch: 1/2, step 6131/7134 completed (loss: 0.5086861252784729, acc: 0.8980582356452942)
[2024-12-17 02:13:41,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:41,591][root][INFO] - Training Epoch: 1/2, step 6132/7134 completed (loss: 0.32161015272140503, acc: 0.9230769276618958)
[2024-12-17 02:13:41,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:41,891][root][INFO] - Training Epoch: 1/2, step 6133/7134 completed (loss: 0.4055230915546417, acc: 0.9086538553237915)
[2024-12-17 02:13:42,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:42,171][root][INFO] - Training Epoch: 1/2, step 6134/7134 completed (loss: 0.505316436290741, acc: 0.8670520186424255)
[2024-12-17 02:13:42,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:42,475][root][INFO] - Training Epoch: 1/2, step 6135/7134 completed (loss: 0.24203729629516602, acc: 0.9689922332763672)
[2024-12-17 02:13:42,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:42,762][root][INFO] - Training Epoch: 1/2, step 6136/7134 completed (loss: 0.34066325426101685, acc: 0.916167676448822)
[2024-12-17 02:13:42,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:43,027][root][INFO] - Training Epoch: 1/2, step 6137/7134 completed (loss: 0.4136514961719513, acc: 0.9285714030265808)
[2024-12-17 02:13:43,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:43,293][root][INFO] - Training Epoch: 1/2, step 6138/7134 completed (loss: 0.32995662093162537, acc: 0.9202454090118408)
[2024-12-17 02:13:43,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:43,561][root][INFO] - Training Epoch: 1/2, step 6139/7134 completed (loss: 0.599666178226471, acc: 0.8503401279449463)
[2024-12-17 02:13:43,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:43,863][root][INFO] - Training Epoch: 1/2, step 6140/7134 completed (loss: 0.29167991876602173, acc: 0.9230769276618958)
[2024-12-17 02:13:43,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:44,119][root][INFO] - Training Epoch: 1/2, step 6141/7134 completed (loss: 0.7340168952941895, acc: 0.7971014380455017)
[2024-12-17 02:13:44,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:44,399][root][INFO] - Training Epoch: 1/2, step 6142/7134 completed (loss: 0.28453394770622253, acc: 0.954285740852356)
[2024-12-17 02:13:44,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:44,679][root][INFO] - Training Epoch: 1/2, step 6143/7134 completed (loss: 0.33789876103401184, acc: 0.9272727370262146)
[2024-12-17 02:13:44,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:44,961][root][INFO] - Training Epoch: 1/2, step 6144/7134 completed (loss: 0.360405296087265, acc: 0.9041095972061157)
[2024-12-17 02:13:45,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:45,247][root][INFO] - Training Epoch: 1/2, step 6145/7134 completed (loss: 0.452762246131897, acc: 0.8852459192276001)
[2024-12-17 02:13:45,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:45,509][root][INFO] - Training Epoch: 1/2, step 6146/7134 completed (loss: 0.3462744653224945, acc: 0.9156626462936401)
[2024-12-17 02:13:45,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:45,788][root][INFO] - Training Epoch: 1/2, step 6147/7134 completed (loss: 0.17109276354312897, acc: 0.9527559280395508)
[2024-12-17 02:13:45,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:46,095][root][INFO] - Training Epoch: 1/2, step 6148/7134 completed (loss: 0.2692128121852875, acc: 0.9172413945198059)
[2024-12-17 02:13:46,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:46,375][root][INFO] - Training Epoch: 1/2, step 6149/7134 completed (loss: 0.4193972647190094, acc: 0.8675496578216553)
[2024-12-17 02:13:46,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:46,653][root][INFO] - Training Epoch: 1/2, step 6150/7134 completed (loss: 0.2317320853471756, acc: 0.9300699234008789)
[2024-12-17 02:13:46,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:46,912][root][INFO] - Training Epoch: 1/2, step 6151/7134 completed (loss: 0.2614554166793823, acc: 0.9426751732826233)
[2024-12-17 02:13:47,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:47,195][root][INFO] - Training Epoch: 1/2, step 6152/7134 completed (loss: 0.32910633087158203, acc: 0.9314285516738892)
[2024-12-17 02:13:47,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:47,491][root][INFO] - Training Epoch: 1/2, step 6153/7134 completed (loss: 0.2069305181503296, acc: 0.9567901492118835)
[2024-12-17 02:13:47,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:47,783][root][INFO] - Training Epoch: 1/2, step 6154/7134 completed (loss: 0.32884249091148376, acc: 0.9337016344070435)
[2024-12-17 02:13:47,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:48,067][root][INFO] - Training Epoch: 1/2, step 6155/7134 completed (loss: 0.3360254764556885, acc: 0.9349112510681152)
[2024-12-17 02:13:48,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:48,337][root][INFO] - Training Epoch: 1/2, step 6156/7134 completed (loss: 0.24516721069812775, acc: 0.9430379867553711)
[2024-12-17 02:13:48,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:48,622][root][INFO] - Training Epoch: 1/2, step 6157/7134 completed (loss: 0.21327228844165802, acc: 0.9620253443717957)
[2024-12-17 02:13:48,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:48,919][root][INFO] - Training Epoch: 1/2, step 6158/7134 completed (loss: 0.2933140993118286, acc: 0.9561403393745422)
[2024-12-17 02:13:49,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:49,228][root][INFO] - Training Epoch: 1/2, step 6159/7134 completed (loss: 0.3654220700263977, acc: 0.9107142686843872)
[2024-12-17 02:13:49,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:49,530][root][INFO] - Training Epoch: 1/2, step 6160/7134 completed (loss: 0.4735051393508911, acc: 0.8598726391792297)
[2024-12-17 02:13:49,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:49,827][root][INFO] - Training Epoch: 1/2, step 6161/7134 completed (loss: 0.39985132217407227, acc: 0.9055117964744568)
[2024-12-17 02:13:49,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:50,116][root][INFO] - Training Epoch: 1/2, step 6162/7134 completed (loss: 0.4915126860141754, acc: 0.9166666865348816)
[2024-12-17 02:13:50,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:50,394][root][INFO] - Training Epoch: 1/2, step 6163/7134 completed (loss: 0.6119106411933899, acc: 0.8527131676673889)
[2024-12-17 02:13:50,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:50,677][root][INFO] - Training Epoch: 1/2, step 6164/7134 completed (loss: 0.38924235105514526, acc: 0.8963414430618286)
[2024-12-17 02:13:50,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:50,932][root][INFO] - Training Epoch: 1/2, step 6165/7134 completed (loss: 0.37256288528442383, acc: 0.9160305261611938)
[2024-12-17 02:13:51,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:51,213][root][INFO] - Training Epoch: 1/2, step 6166/7134 completed (loss: 0.27614355087280273, acc: 0.9416058659553528)
[2024-12-17 02:13:51,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:51,497][root][INFO] - Training Epoch: 1/2, step 6167/7134 completed (loss: 0.15746083855628967, acc: 0.9709302186965942)
[2024-12-17 02:13:51,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:51,778][root][INFO] - Training Epoch: 1/2, step 6168/7134 completed (loss: 0.1436496078968048, acc: 0.9623655676841736)
[2024-12-17 02:13:51,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:52,050][root][INFO] - Training Epoch: 1/2, step 6169/7134 completed (loss: 0.15736863017082214, acc: 0.9759036302566528)
[2024-12-17 02:13:52,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:52,347][root][INFO] - Training Epoch: 1/2, step 6170/7134 completed (loss: 0.2845538854598999, acc: 0.935251772403717)
[2024-12-17 02:13:52,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:52,626][root][INFO] - Training Epoch: 1/2, step 6171/7134 completed (loss: 0.10142132639884949, acc: 0.9725274443626404)
[2024-12-17 02:13:52,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:52,889][root][INFO] - Training Epoch: 1/2, step 6172/7134 completed (loss: 0.1694049835205078, acc: 0.9609375)
[2024-12-17 02:13:53,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:53,173][root][INFO] - Training Epoch: 1/2, step 6173/7134 completed (loss: 0.2879638671875, acc: 0.9358974099159241)
[2024-12-17 02:13:53,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:53,456][root][INFO] - Training Epoch: 1/2, step 6174/7134 completed (loss: 0.18915647268295288, acc: 0.9575757384300232)
[2024-12-17 02:13:53,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:53,731][root][INFO] - Training Epoch: 1/2, step 6175/7134 completed (loss: 0.27894681692123413, acc: 0.9197530746459961)
[2024-12-17 02:13:53,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:53,990][root][INFO] - Training Epoch: 1/2, step 6176/7134 completed (loss: 0.22140786051750183, acc: 0.9329268336296082)
[2024-12-17 02:13:54,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:54,265][root][INFO] - Training Epoch: 1/2, step 6177/7134 completed (loss: 0.20406340062618256, acc: 0.9505494236946106)
[2024-12-17 02:13:54,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:54,546][root][INFO] - Training Epoch: 1/2, step 6178/7134 completed (loss: 0.2803348898887634, acc: 0.9281045794487)
[2024-12-17 02:13:54,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:54,828][root][INFO] - Training Epoch: 1/2, step 6179/7134 completed (loss: 0.3357584774494171, acc: 0.9266666769981384)
[2024-12-17 02:13:54,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:55,094][root][INFO] - Training Epoch: 1/2, step 6180/7134 completed (loss: 0.8318470120429993, acc: 0.8191489577293396)
[2024-12-17 02:13:55,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:55,375][root][INFO] - Training Epoch: 1/2, step 6181/7134 completed (loss: 1.2022958993911743, acc: 0.7222222089767456)
[2024-12-17 02:13:55,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:55,661][root][INFO] - Training Epoch: 1/2, step 6182/7134 completed (loss: 0.5656530261039734, acc: 0.8604651093482971)
[2024-12-17 02:13:55,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:55,936][root][INFO] - Training Epoch: 1/2, step 6183/7134 completed (loss: 0.7675131559371948, acc: 0.8518518805503845)
[2024-12-17 02:13:56,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:56,214][root][INFO] - Training Epoch: 1/2, step 6184/7134 completed (loss: 0.8191831111907959, acc: 0.8260869383811951)
[2024-12-17 02:13:56,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:56,517][root][INFO] - Training Epoch: 1/2, step 6185/7134 completed (loss: 0.39387455582618713, acc: 0.9112903475761414)
[2024-12-17 02:13:56,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:56,808][root][INFO] - Training Epoch: 1/2, step 6186/7134 completed (loss: 0.3064252436161041, acc: 0.9160305261611938)
[2024-12-17 02:13:56,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:57,129][root][INFO] - Training Epoch: 1/2, step 6187/7134 completed (loss: 0.3466334044933319, acc: 0.9298245906829834)
[2024-12-17 02:13:57,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:57,424][root][INFO] - Training Epoch: 1/2, step 6188/7134 completed (loss: 0.3330899775028229, acc: 0.915032684803009)
[2024-12-17 02:13:57,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:57,725][root][INFO] - Training Epoch: 1/2, step 6189/7134 completed (loss: 0.4993399381637573, acc: 0.8951048851013184)
[2024-12-17 02:13:57,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:58,020][root][INFO] - Training Epoch: 1/2, step 6190/7134 completed (loss: 0.7133275270462036, acc: 0.8571428656578064)
[2024-12-17 02:13:58,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:58,312][root][INFO] - Training Epoch: 1/2, step 6191/7134 completed (loss: 0.33786410093307495, acc: 0.934959352016449)
[2024-12-17 02:13:58,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:58,621][root][INFO] - Training Epoch: 1/2, step 6192/7134 completed (loss: 0.33561980724334717, acc: 0.9170731902122498)
[2024-12-17 02:13:58,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:58,923][root][INFO] - Training Epoch: 1/2, step 6193/7134 completed (loss: 0.5151078104972839, acc: 0.9090909361839294)
[2024-12-17 02:13:59,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:59,224][root][INFO] - Training Epoch: 1/2, step 6194/7134 completed (loss: 0.34194958209991455, acc: 0.9180327653884888)
[2024-12-17 02:13:59,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:59,524][root][INFO] - Training Epoch: 1/2, step 6195/7134 completed (loss: 0.5270988941192627, acc: 0.8584905862808228)
[2024-12-17 02:13:59,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:59,798][root][INFO] - Training Epoch: 1/2, step 6196/7134 completed (loss: 0.3938687741756439, acc: 0.895061731338501)
[2024-12-17 02:13:59,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:00,077][root][INFO] - Training Epoch: 1/2, step 6197/7134 completed (loss: 0.5282062292098999, acc: 0.8693181872367859)
[2024-12-17 02:14:00,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:00,352][root][INFO] - Training Epoch: 1/2, step 6198/7134 completed (loss: 0.30186304450035095, acc: 0.9203540086746216)
[2024-12-17 02:14:00,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:00,633][root][INFO] - Training Epoch: 1/2, step 6199/7134 completed (loss: 0.3632797598838806, acc: 0.9259259104728699)
[2024-12-17 02:14:00,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:00,923][root][INFO] - Training Epoch: 1/2, step 6200/7134 completed (loss: 0.19783616065979004, acc: 0.9435897469520569)
[2024-12-17 02:14:01,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:01,214][root][INFO] - Training Epoch: 1/2, step 6201/7134 completed (loss: 0.23123715817928314, acc: 0.9282296895980835)
[2024-12-17 02:14:01,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:01,499][root][INFO] - Training Epoch: 1/2, step 6202/7134 completed (loss: 0.36978232860565186, acc: 0.8857142925262451)
[2024-12-17 02:14:01,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:01,779][root][INFO] - Training Epoch: 1/2, step 6203/7134 completed (loss: 0.37691715359687805, acc: 0.9011628031730652)
[2024-12-17 02:14:01,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:02,072][root][INFO] - Training Epoch: 1/2, step 6204/7134 completed (loss: 0.2560906708240509, acc: 0.9916666746139526)
[2024-12-17 02:14:02,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:02,356][root][INFO] - Training Epoch: 1/2, step 6205/7134 completed (loss: 0.2667487561702728, acc: 0.935251772403717)
[2024-12-17 02:14:02,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:02,625][root][INFO] - Training Epoch: 1/2, step 6206/7134 completed (loss: 0.24746781587600708, acc: 0.9316770434379578)
[2024-12-17 02:14:02,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:02,907][root][INFO] - Training Epoch: 1/2, step 6207/7134 completed (loss: 0.6808635592460632, acc: 0.8484848737716675)
[2024-12-17 02:14:03,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:03,188][root][INFO] - Training Epoch: 1/2, step 6208/7134 completed (loss: 0.28178906440734863, acc: 0.9375)
[2024-12-17 02:14:03,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:03,476][root][INFO] - Training Epoch: 1/2, step 6209/7134 completed (loss: 0.21529679000377655, acc: 0.9464285969734192)
[2024-12-17 02:14:03,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:03,801][root][INFO] - Training Epoch: 1/2, step 6210/7134 completed (loss: 0.3271263837814331, acc: 0.903743326663971)
[2024-12-17 02:14:03,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:04,091][root][INFO] - Training Epoch: 1/2, step 6211/7134 completed (loss: 0.2701989412307739, acc: 0.9454545378684998)
[2024-12-17 02:14:04,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:04,364][root][INFO] - Training Epoch: 1/2, step 6212/7134 completed (loss: 0.24128857254981995, acc: 0.9572649598121643)
[2024-12-17 02:14:04,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:04,627][root][INFO] - Training Epoch: 1/2, step 6213/7134 completed (loss: 0.1776692420244217, acc: 0.9636363387107849)
[2024-12-17 02:14:04,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:04,891][root][INFO] - Training Epoch: 1/2, step 6214/7134 completed (loss: 0.19228030741214752, acc: 0.9604519605636597)
[2024-12-17 02:14:05,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:05,173][root][INFO] - Training Epoch: 1/2, step 6215/7134 completed (loss: 0.40870505571365356, acc: 0.8937197923660278)
[2024-12-17 02:14:05,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:05,423][root][INFO] - Training Epoch: 1/2, step 6216/7134 completed (loss: 0.28904643654823303, acc: 0.918367326259613)
[2024-12-17 02:14:05,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:05,709][root][INFO] - Training Epoch: 1/2, step 6217/7134 completed (loss: 0.20359253883361816, acc: 0.949367105960846)
[2024-12-17 02:14:05,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:06,002][root][INFO] - Training Epoch: 1/2, step 6218/7134 completed (loss: 0.2843249440193176, acc: 0.9419354796409607)
[2024-12-17 02:14:06,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:06,271][root][INFO] - Training Epoch: 1/2, step 6219/7134 completed (loss: 0.3205288052558899, acc: 0.9346405267715454)
[2024-12-17 02:14:06,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:06,545][root][INFO] - Training Epoch: 1/2, step 6220/7134 completed (loss: 0.32795408368110657, acc: 0.9425287246704102)
[2024-12-17 02:14:06,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:06,835][root][INFO] - Training Epoch: 1/2, step 6221/7134 completed (loss: 0.08365098387002945, acc: 0.9701492786407471)
[2024-12-17 02:14:06,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:07,095][root][INFO] - Training Epoch: 1/2, step 6222/7134 completed (loss: 0.5948169827461243, acc: 0.8674699068069458)
[2024-12-17 02:14:07,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:07,386][root][INFO] - Training Epoch: 1/2, step 6223/7134 completed (loss: 0.4395056664943695, acc: 0.8854166865348816)
[2024-12-17 02:14:07,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:07,665][root][INFO] - Training Epoch: 1/2, step 6224/7134 completed (loss: 0.1918163299560547, acc: 0.9324324131011963)
[2024-12-17 02:14:07,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:07,950][root][INFO] - Training Epoch: 1/2, step 6225/7134 completed (loss: 0.26082685589790344, acc: 0.9329608678817749)
[2024-12-17 02:14:08,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:08,225][root][INFO] - Training Epoch: 1/2, step 6226/7134 completed (loss: 0.4657909870147705, acc: 0.8804348111152649)
[2024-12-17 02:14:08,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:08,511][root][INFO] - Training Epoch: 1/2, step 6227/7134 completed (loss: 0.15038827061653137, acc: 0.9624999761581421)
[2024-12-17 02:14:08,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:08,792][root][INFO] - Training Epoch: 1/2, step 6228/7134 completed (loss: 0.28695571422576904, acc: 0.9308510422706604)
[2024-12-17 02:14:08,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:09,071][root][INFO] - Training Epoch: 1/2, step 6229/7134 completed (loss: 0.5001477003097534, acc: 0.8682926893234253)
[2024-12-17 02:14:09,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:09,359][root][INFO] - Training Epoch: 1/2, step 6230/7134 completed (loss: 0.37337955832481384, acc: 0.8989361524581909)
[2024-12-17 02:14:09,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:09,633][root][INFO] - Training Epoch: 1/2, step 6231/7134 completed (loss: 0.19281958043575287, acc: 0.9532163739204407)
[2024-12-17 02:14:09,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:09,928][root][INFO] - Training Epoch: 1/2, step 6232/7134 completed (loss: 0.32538849115371704, acc: 0.9120879173278809)
[2024-12-17 02:14:10,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:10,225][root][INFO] - Training Epoch: 1/2, step 6233/7134 completed (loss: 0.2859574556350708, acc: 0.9137930870056152)
[2024-12-17 02:14:10,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:10,522][root][INFO] - Training Epoch: 1/2, step 6234/7134 completed (loss: 0.2985299825668335, acc: 0.9333333373069763)
[2024-12-17 02:14:10,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:10,798][root][INFO] - Training Epoch: 1/2, step 6235/7134 completed (loss: 0.1658572107553482, acc: 0.9523809552192688)
[2024-12-17 02:14:10,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:11,093][root][INFO] - Training Epoch: 1/2, step 6236/7134 completed (loss: 0.25686776638031006, acc: 0.9273743033409119)
[2024-12-17 02:14:11,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:11,406][root][INFO] - Training Epoch: 1/2, step 6237/7134 completed (loss: 0.4272492527961731, acc: 0.903954803943634)
[2024-12-17 02:14:11,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:11,695][root][INFO] - Training Epoch: 1/2, step 6238/7134 completed (loss: 0.2646682560443878, acc: 0.9337748289108276)
[2024-12-17 02:14:11,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:11,999][root][INFO] - Training Epoch: 1/2, step 6239/7134 completed (loss: 0.23923838138580322, acc: 0.9222797751426697)
[2024-12-17 02:14:12,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:12,298][root][INFO] - Training Epoch: 1/2, step 6240/7134 completed (loss: 0.06630218774080276, acc: 0.9819276928901672)
[2024-12-17 02:14:12,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:12,615][root][INFO] - Training Epoch: 1/2, step 6241/7134 completed (loss: 0.22771230340003967, acc: 0.9399999976158142)
[2024-12-17 02:14:12,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:12,915][root][INFO] - Training Epoch: 1/2, step 6242/7134 completed (loss: 0.2035442739725113, acc: 0.9455782175064087)
[2024-12-17 02:14:13,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:13,210][root][INFO] - Training Epoch: 1/2, step 6243/7134 completed (loss: 0.2876557409763336, acc: 0.926174521446228)
[2024-12-17 02:14:13,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:13,484][root][INFO] - Training Epoch: 1/2, step 6244/7134 completed (loss: 0.23233096301555634, acc: 0.946107804775238)
[2024-12-17 02:14:13,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:13,756][root][INFO] - Training Epoch: 1/2, step 6245/7134 completed (loss: 0.2157679945230484, acc: 0.9467455744743347)
[2024-12-17 02:14:13,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:14,051][root][INFO] - Training Epoch: 1/2, step 6246/7134 completed (loss: 0.12414492666721344, acc: 0.9518716335296631)
[2024-12-17 02:14:14,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:14,338][root][INFO] - Training Epoch: 1/2, step 6247/7134 completed (loss: 0.22672021389007568, acc: 0.929347813129425)
[2024-12-17 02:14:14,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:14,630][root][INFO] - Training Epoch: 1/2, step 6248/7134 completed (loss: 0.4965202510356903, acc: 0.8922155499458313)
[2024-12-17 02:14:14,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:14,898][root][INFO] - Training Epoch: 1/2, step 6249/7134 completed (loss: 0.0670907199382782, acc: 0.9801324605941772)
[2024-12-17 02:14:15,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:15,183][root][INFO] - Training Epoch: 1/2, step 6250/7134 completed (loss: 0.05817980691790581, acc: 0.97826087474823)
[2024-12-17 02:14:15,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:15,467][root][INFO] - Training Epoch: 1/2, step 6251/7134 completed (loss: 0.21126660704612732, acc: 0.9536423683166504)
[2024-12-17 02:14:15,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:15,765][root][INFO] - Training Epoch: 1/2, step 6252/7134 completed (loss: 0.11306291818618774, acc: 0.9857142567634583)
[2024-12-17 02:14:15,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:16,047][root][INFO] - Training Epoch: 1/2, step 6253/7134 completed (loss: 0.0963231697678566, acc: 0.9720279574394226)
[2024-12-17 02:14:16,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:16,317][root][INFO] - Training Epoch: 1/2, step 6254/7134 completed (loss: 0.3271862864494324, acc: 0.9552238583564758)
[2024-12-17 02:14:16,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:16,600][root][INFO] - Training Epoch: 1/2, step 6255/7134 completed (loss: 0.24695712327957153, acc: 0.9431818127632141)
[2024-12-17 02:14:16,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:16,876][root][INFO] - Training Epoch: 1/2, step 6256/7134 completed (loss: 0.16077066957950592, acc: 0.9661017060279846)
[2024-12-17 02:14:17,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:17,160][root][INFO] - Training Epoch: 1/2, step 6257/7134 completed (loss: 0.19226478040218353, acc: 0.9526627063751221)
[2024-12-17 02:14:17,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:17,428][root][INFO] - Training Epoch: 1/2, step 6258/7134 completed (loss: 0.1812121570110321, acc: 0.9466666579246521)
[2024-12-17 02:14:17,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:17,716][root][INFO] - Training Epoch: 1/2, step 6259/7134 completed (loss: 0.1327303647994995, acc: 0.9627329111099243)
[2024-12-17 02:14:17,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:17,983][root][INFO] - Training Epoch: 1/2, step 6260/7134 completed (loss: 0.14374542236328125, acc: 0.9617834687232971)
[2024-12-17 02:14:18,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:18,293][root][INFO] - Training Epoch: 1/2, step 6261/7134 completed (loss: 0.15721583366394043, acc: 0.9627329111099243)
[2024-12-17 02:14:18,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:18,575][root][INFO] - Training Epoch: 1/2, step 6262/7134 completed (loss: 0.06053558364510536, acc: 0.9938271641731262)
[2024-12-17 02:14:18,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:18,857][root][INFO] - Training Epoch: 1/2, step 6263/7134 completed (loss: 0.07859773933887482, acc: 0.9743589758872986)
[2024-12-17 02:14:18,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:19,140][root][INFO] - Training Epoch: 1/2, step 6264/7134 completed (loss: 0.059656959027051926, acc: 0.9931507110595703)
[2024-12-17 02:14:19,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:19,434][root][INFO] - Training Epoch: 1/2, step 6265/7134 completed (loss: 0.08228102326393127, acc: 0.9754601120948792)
[2024-12-17 02:14:19,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:19,710][root][INFO] - Training Epoch: 1/2, step 6266/7134 completed (loss: 0.12647674977779388, acc: 0.9538461565971375)
[2024-12-17 02:14:19,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:19,993][root][INFO] - Training Epoch: 1/2, step 6267/7134 completed (loss: 0.12287268042564392, acc: 0.9802631735801697)
[2024-12-17 02:14:20,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:20,281][root][INFO] - Training Epoch: 1/2, step 6268/7134 completed (loss: 0.14756350219249725, acc: 0.9627329111099243)
[2024-12-17 02:14:20,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:20,558][root][INFO] - Training Epoch: 1/2, step 6269/7134 completed (loss: 0.08863510191440582, acc: 0.9821428656578064)
[2024-12-17 02:14:20,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:20,839][root][INFO] - Training Epoch: 1/2, step 6270/7134 completed (loss: 0.05048403888940811, acc: 0.9934210777282715)
[2024-12-17 02:14:20,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:21,122][root][INFO] - Training Epoch: 1/2, step 6271/7134 completed (loss: 0.10869500041007996, acc: 0.9772727489471436)
[2024-12-17 02:14:21,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:21,420][root][INFO] - Training Epoch: 1/2, step 6272/7134 completed (loss: 0.03434286266565323, acc: 0.987730085849762)
[2024-12-17 02:14:21,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:21,712][root][INFO] - Training Epoch: 1/2, step 6273/7134 completed (loss: 0.07924946397542953, acc: 0.9881656765937805)
[2024-12-17 02:14:21,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:21,995][root][INFO] - Training Epoch: 1/2, step 6274/7134 completed (loss: 0.04912194609642029, acc: 1.0)
[2024-12-17 02:14:22,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:22,285][root][INFO] - Training Epoch: 1/2, step 6275/7134 completed (loss: 0.0997966080904007, acc: 0.9731543660163879)
[2024-12-17 02:14:22,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:22,548][root][INFO] - Training Epoch: 1/2, step 6276/7134 completed (loss: 0.18690216541290283, acc: 0.9512194991111755)
[2024-12-17 02:14:22,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:22,818][root][INFO] - Training Epoch: 1/2, step 6277/7134 completed (loss: 0.3548821806907654, acc: 0.8962264060974121)
[2024-12-17 02:14:22,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:23,088][root][INFO] - Training Epoch: 1/2, step 6278/7134 completed (loss: 0.11514905095100403, acc: 0.9558823704719543)
[2024-12-17 02:14:23,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:23,353][root][INFO] - Training Epoch: 1/2, step 6279/7134 completed (loss: 0.15067046880722046, acc: 0.9615384340286255)
[2024-12-17 02:14:23,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:23,651][root][INFO] - Training Epoch: 1/2, step 6280/7134 completed (loss: 0.24115058779716492, acc: 0.9402984976768494)
[2024-12-17 02:14:23,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:23,941][root][INFO] - Training Epoch: 1/2, step 6281/7134 completed (loss: 0.098281629383564, acc: 0.970588207244873)
[2024-12-17 02:14:24,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:24,227][root][INFO] - Training Epoch: 1/2, step 6282/7134 completed (loss: 0.14532285928726196, acc: 0.9722222089767456)
[2024-12-17 02:14:24,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:24,520][root][INFO] - Training Epoch: 1/2, step 6283/7134 completed (loss: 0.15539604425430298, acc: 0.9652174115180969)
[2024-12-17 02:14:24,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:24,811][root][INFO] - Training Epoch: 1/2, step 6284/7134 completed (loss: 0.26246577501296997, acc: 0.9272727370262146)
[2024-12-17 02:14:24,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:25,078][root][INFO] - Training Epoch: 1/2, step 6285/7134 completed (loss: 0.3023049533367157, acc: 0.9157894849777222)
[2024-12-17 02:14:25,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:25,348][root][INFO] - Training Epoch: 1/2, step 6286/7134 completed (loss: 0.07100623100996017, acc: 0.9791666865348816)
[2024-12-17 02:14:25,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:25,630][root][INFO] - Training Epoch: 1/2, step 6287/7134 completed (loss: 0.14879415929317474, acc: 0.9621211886405945)
[2024-12-17 02:14:25,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:25,911][root][INFO] - Training Epoch: 1/2, step 6288/7134 completed (loss: 0.08090653270483017, acc: 0.978723406791687)
[2024-12-17 02:14:26,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:26,197][root][INFO] - Training Epoch: 1/2, step 6289/7134 completed (loss: 0.1283625066280365, acc: 0.9696969985961914)
[2024-12-17 02:14:26,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:26,508][root][INFO] - Training Epoch: 1/2, step 6290/7134 completed (loss: 0.15162338316440582, acc: 0.9776119589805603)
[2024-12-17 02:14:26,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:26,792][root][INFO] - Training Epoch: 1/2, step 6291/7134 completed (loss: 0.05738425254821777, acc: 0.9924242496490479)
[2024-12-17 02:14:26,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:27,066][root][INFO] - Training Epoch: 1/2, step 6292/7134 completed (loss: 0.23219813406467438, acc: 0.9196428656578064)
[2024-12-17 02:14:27,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:27,360][root][INFO] - Training Epoch: 1/2, step 6293/7134 completed (loss: 0.2571880519390106, acc: 0.9575757384300232)
[2024-12-17 02:14:27,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:27,655][root][INFO] - Training Epoch: 1/2, step 6294/7134 completed (loss: 0.2650204598903656, acc: 0.9342105388641357)
[2024-12-17 02:14:27,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:27,931][root][INFO] - Training Epoch: 1/2, step 6295/7134 completed (loss: 0.23025059700012207, acc: 0.9621211886405945)
[2024-12-17 02:14:28,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:28,195][root][INFO] - Training Epoch: 1/2, step 6296/7134 completed (loss: 0.29957908391952515, acc: 0.935251772403717)
[2024-12-17 02:14:28,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:28,471][root][INFO] - Training Epoch: 1/2, step 6297/7134 completed (loss: 0.3198651373386383, acc: 0.902255654335022)
[2024-12-17 02:14:28,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:28,748][root][INFO] - Training Epoch: 1/2, step 6298/7134 completed (loss: 0.30060118436813354, acc: 0.9166666865348816)
[2024-12-17 02:14:28,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:29,036][root][INFO] - Training Epoch: 1/2, step 6299/7134 completed (loss: 0.3251970410346985, acc: 0.9342105388641357)
[2024-12-17 02:14:29,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:29,317][root][INFO] - Training Epoch: 1/2, step 6300/7134 completed (loss: 0.2926992177963257, acc: 0.9473684430122375)
[2024-12-17 02:14:29,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:29,605][root][INFO] - Training Epoch: 1/2, step 6301/7134 completed (loss: 0.11345499753952026, acc: 0.9675925970077515)
[2024-12-17 02:14:29,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:29,888][root][INFO] - Training Epoch: 1/2, step 6302/7134 completed (loss: 0.11239737272262573, acc: 0.9664804339408875)
[2024-12-17 02:14:30,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:30,188][root][INFO] - Training Epoch: 1/2, step 6303/7134 completed (loss: 0.0788816586136818, acc: 0.9820627570152283)
[2024-12-17 02:14:30,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:30,465][root][INFO] - Training Epoch: 1/2, step 6304/7134 completed (loss: 0.09023560583591461, acc: 0.9715909361839294)
[2024-12-17 02:14:30,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:30,759][root][INFO] - Training Epoch: 1/2, step 6305/7134 completed (loss: 0.1738109439611435, acc: 0.965753436088562)
[2024-12-17 02:14:30,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:31,064][root][INFO] - Training Epoch: 1/2, step 6306/7134 completed (loss: 0.18642427027225494, acc: 0.9573459625244141)
[2024-12-17 02:14:31,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:31,343][root][INFO] - Training Epoch: 1/2, step 6307/7134 completed (loss: 0.24212105572223663, acc: 0.9618320465087891)
[2024-12-17 02:14:31,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:31,623][root][INFO] - Training Epoch: 1/2, step 6308/7134 completed (loss: 0.14700129628181458, acc: 0.9637305736541748)
[2024-12-17 02:14:31,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:31,907][root][INFO] - Training Epoch: 1/2, step 6309/7134 completed (loss: 0.11718453466892242, acc: 0.9644970297813416)
[2024-12-17 02:14:32,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:32,193][root][INFO] - Training Epoch: 1/2, step 6310/7134 completed (loss: 0.4032886326313019, acc: 0.8947368264198303)
[2024-12-17 02:14:32,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:32,465][root][INFO] - Training Epoch: 1/2, step 6311/7134 completed (loss: 0.18625938892364502, acc: 0.9479166865348816)
[2024-12-17 02:14:32,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:32,729][root][INFO] - Training Epoch: 1/2, step 6312/7134 completed (loss: 0.20125168561935425, acc: 0.9617834687232971)
[2024-12-17 02:14:32,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:33,001][root][INFO] - Training Epoch: 1/2, step 6313/7134 completed (loss: 0.13229575753211975, acc: 0.9729729890823364)
[2024-12-17 02:14:33,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:33,277][root][INFO] - Training Epoch: 1/2, step 6314/7134 completed (loss: 0.17735068500041962, acc: 0.9516128897666931)
[2024-12-17 02:14:33,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:33,559][root][INFO] - Training Epoch: 1/2, step 6315/7134 completed (loss: 0.2786013185977936, acc: 0.9463087320327759)
[2024-12-17 02:14:33,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:33,837][root][INFO] - Training Epoch: 1/2, step 6316/7134 completed (loss: 0.1678076833486557, acc: 0.9586206674575806)
[2024-12-17 02:14:33,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:34,136][root][INFO] - Training Epoch: 1/2, step 6317/7134 completed (loss: 0.16124466061592102, acc: 0.9527027010917664)
[2024-12-17 02:14:34,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:34,405][root][INFO] - Training Epoch: 1/2, step 6318/7134 completed (loss: 0.20378278195858002, acc: 0.9539473652839661)
[2024-12-17 02:14:34,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:34,687][root][INFO] - Training Epoch: 1/2, step 6319/7134 completed (loss: 0.09703705459833145, acc: 0.9688888788223267)
[2024-12-17 02:14:34,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:35,003][root][INFO] - Training Epoch: 1/2, step 6320/7134 completed (loss: 0.14801368117332458, acc: 0.9459459185600281)
[2024-12-17 02:14:35,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:35,305][root][INFO] - Training Epoch: 1/2, step 6321/7134 completed (loss: 0.09781035780906677, acc: 0.976190447807312)
[2024-12-17 02:14:35,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:35,588][root][INFO] - Training Epoch: 1/2, step 6322/7134 completed (loss: 0.1927526742219925, acc: 0.9426751732826233)
[2024-12-17 02:14:35,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:35,875][root][INFO] - Training Epoch: 1/2, step 6323/7134 completed (loss: 0.16316768527030945, acc: 0.9624999761581421)
[2024-12-17 02:14:35,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:36,164][root][INFO] - Training Epoch: 1/2, step 6324/7134 completed (loss: 0.2413453459739685, acc: 0.9398906826972961)
[2024-12-17 02:14:36,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:36,443][root][INFO] - Training Epoch: 1/2, step 6325/7134 completed (loss: 0.2517571449279785, acc: 0.9354838728904724)
[2024-12-17 02:14:36,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:36,731][root][INFO] - Training Epoch: 1/2, step 6326/7134 completed (loss: 0.2909131646156311, acc: 0.9308176040649414)
[2024-12-17 02:14:36,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:37,010][root][INFO] - Training Epoch: 1/2, step 6327/7134 completed (loss: 0.09533800184726715, acc: 0.9780219793319702)
[2024-12-17 02:14:37,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:37,291][root][INFO] - Training Epoch: 1/2, step 6328/7134 completed (loss: 0.2936256527900696, acc: 0.8944099545478821)
[2024-12-17 02:14:37,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:37,571][root][INFO] - Training Epoch: 1/2, step 6329/7134 completed (loss: 0.17846816778182983, acc: 0.9487179517745972)
[2024-12-17 02:14:37,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:37,853][root][INFO] - Training Epoch: 1/2, step 6330/7134 completed (loss: 0.18856240808963776, acc: 0.9433962106704712)
[2024-12-17 02:14:37,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:38,126][root][INFO] - Training Epoch: 1/2, step 6331/7134 completed (loss: 0.09631871432065964, acc: 0.9776119589805603)
[2024-12-17 02:14:38,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:38,436][root][INFO] - Training Epoch: 1/2, step 6332/7134 completed (loss: 0.46504026651382446, acc: 0.9078013896942139)
[2024-12-17 02:14:38,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:38,722][root][INFO] - Training Epoch: 1/2, step 6333/7134 completed (loss: 0.3364533483982086, acc: 0.9022988677024841)
[2024-12-17 02:14:38,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:38,992][root][INFO] - Training Epoch: 1/2, step 6334/7134 completed (loss: 0.15859991312026978, acc: 0.9632353186607361)
[2024-12-17 02:14:39,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:39,275][root][INFO] - Training Epoch: 1/2, step 6335/7134 completed (loss: 0.12581458687782288, acc: 0.9745222926139832)
[2024-12-17 02:14:39,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:39,556][root][INFO] - Training Epoch: 1/2, step 6336/7134 completed (loss: 0.1766735315322876, acc: 0.9473684430122375)
[2024-12-17 02:14:39,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:39,856][root][INFO] - Training Epoch: 1/2, step 6337/7134 completed (loss: 0.11012033373117447, acc: 0.9860140085220337)
[2024-12-17 02:14:39,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:40,142][root][INFO] - Training Epoch: 1/2, step 6338/7134 completed (loss: 0.22175979614257812, acc: 0.955974817276001)
[2024-12-17 02:14:40,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:40,419][root][INFO] - Training Epoch: 1/2, step 6339/7134 completed (loss: 0.1366601586341858, acc: 0.9542483687400818)
[2024-12-17 02:14:40,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:40,742][root][INFO] - Training Epoch: 1/2, step 6340/7134 completed (loss: 0.10376898944377899, acc: 0.9815950989723206)
[2024-12-17 02:14:40,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:41,040][root][INFO] - Training Epoch: 1/2, step 6341/7134 completed (loss: 0.21000441908836365, acc: 0.960629940032959)
[2024-12-17 02:14:41,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:41,337][root][INFO] - Training Epoch: 1/2, step 6342/7134 completed (loss: 0.19911345839500427, acc: 0.9537572264671326)
[2024-12-17 02:14:41,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:41,632][root][INFO] - Training Epoch: 1/2, step 6343/7134 completed (loss: 0.257232666015625, acc: 0.9452054500579834)
[2024-12-17 02:14:41,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:41,959][root][INFO] - Training Epoch: 1/2, step 6344/7134 completed (loss: 0.21818409860134125, acc: 0.950276255607605)
[2024-12-17 02:14:42,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:42,255][root][INFO] - Training Epoch: 1/2, step 6345/7134 completed (loss: 0.17161796987056732, acc: 0.9728260636329651)
[2024-12-17 02:14:42,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:42,538][root][INFO] - Training Epoch: 1/2, step 6346/7134 completed (loss: 0.48029953241348267, acc: 0.9127907156944275)
[2024-12-17 02:14:42,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:42,802][root][INFO] - Training Epoch: 1/2, step 6347/7134 completed (loss: 0.3300187289714813, acc: 0.9327731132507324)
[2024-12-17 02:14:42,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:43,092][root][INFO] - Training Epoch: 1/2, step 6348/7134 completed (loss: 0.22667638957500458, acc: 0.9305555820465088)
[2024-12-17 02:14:43,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:43,377][root][INFO] - Training Epoch: 1/2, step 6349/7134 completed (loss: 0.1833494007587433, acc: 0.9469696879386902)
[2024-12-17 02:14:43,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:43,686][root][INFO] - Training Epoch: 1/2, step 6350/7134 completed (loss: 0.3864084482192993, acc: 0.8994709253311157)
[2024-12-17 02:14:43,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:43,979][root][INFO] - Training Epoch: 1/2, step 6351/7134 completed (loss: 0.31897690892219543, acc: 0.9221556782722473)
[2024-12-17 02:14:44,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:44,270][root][INFO] - Training Epoch: 1/2, step 6352/7134 completed (loss: 0.4914126992225647, acc: 0.8959537744522095)
[2024-12-17 02:14:44,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:44,565][root][INFO] - Training Epoch: 1/2, step 6353/7134 completed (loss: 0.34578514099121094, acc: 0.9141104221343994)
[2024-12-17 02:14:44,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:44,847][root][INFO] - Training Epoch: 1/2, step 6354/7134 completed (loss: 0.1636698693037033, acc: 0.9655172228813171)
[2024-12-17 02:14:44,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:45,142][root][INFO] - Training Epoch: 1/2, step 6355/7134 completed (loss: 0.12732993066310883, acc: 0.9666666388511658)
[2024-12-17 02:14:45,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:45,418][root][INFO] - Training Epoch: 1/2, step 6356/7134 completed (loss: 0.16280749440193176, acc: 0.9681528806686401)
[2024-12-17 02:14:45,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:45,700][root][INFO] - Training Epoch: 1/2, step 6357/7134 completed (loss: 0.11510522663593292, acc: 0.9636363387107849)
[2024-12-17 02:14:45,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:45,998][root][INFO] - Training Epoch: 1/2, step 6358/7134 completed (loss: 0.23770949244499207, acc: 0.9298245906829834)
[2024-12-17 02:14:46,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:46,274][root][INFO] - Training Epoch: 1/2, step 6359/7134 completed (loss: 0.2270255982875824, acc: 0.9664804339408875)
[2024-12-17 02:14:46,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:46,568][root][INFO] - Training Epoch: 1/2, step 6360/7134 completed (loss: 0.19380517303943634, acc: 0.9523809552192688)
[2024-12-17 02:14:46,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:46,863][root][INFO] - Training Epoch: 1/2, step 6361/7134 completed (loss: 0.34518399834632874, acc: 0.9064748287200928)
[2024-12-17 02:14:46,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:47,164][root][INFO] - Training Epoch: 1/2, step 6362/7134 completed (loss: 0.2002577930688858, acc: 0.948387086391449)
[2024-12-17 02:14:47,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:47,470][root][INFO] - Training Epoch: 1/2, step 6363/7134 completed (loss: 0.28948336839675903, acc: 0.9349112510681152)
[2024-12-17 02:14:47,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:47,759][root][INFO] - Training Epoch: 1/2, step 6364/7134 completed (loss: 0.12003885209560394, acc: 0.9681528806686401)
[2024-12-17 02:14:47,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:48,038][root][INFO] - Training Epoch: 1/2, step 6365/7134 completed (loss: 0.20229613780975342, acc: 0.9576271176338196)
[2024-12-17 02:14:48,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:48,351][root][INFO] - Training Epoch: 1/2, step 6366/7134 completed (loss: 0.33302587270736694, acc: 0.9171597361564636)
[2024-12-17 02:14:48,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:48,629][root][INFO] - Training Epoch: 1/2, step 6367/7134 completed (loss: 0.17451247572898865, acc: 0.9457364082336426)
[2024-12-17 02:14:48,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:48,920][root][INFO] - Training Epoch: 1/2, step 6368/7134 completed (loss: 0.2613910734653473, acc: 0.9457831382751465)
[2024-12-17 02:14:49,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:49,218][root][INFO] - Training Epoch: 1/2, step 6369/7134 completed (loss: 0.2323392629623413, acc: 0.9523809552192688)
[2024-12-17 02:14:49,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:49,511][root][INFO] - Training Epoch: 1/2, step 6370/7134 completed (loss: 0.502808153629303, acc: 0.8662790656089783)
[2024-12-17 02:14:49,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:49,786][root][INFO] - Training Epoch: 1/2, step 6371/7134 completed (loss: 0.5294021368026733, acc: 0.8692810535430908)
[2024-12-17 02:14:49,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:50,070][root][INFO] - Training Epoch: 1/2, step 6372/7134 completed (loss: 0.5720375776290894, acc: 0.818965494632721)
[2024-12-17 02:14:50,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:50,333][root][INFO] - Training Epoch: 1/2, step 6373/7134 completed (loss: 0.4924682676792145, acc: 0.8629032373428345)
[2024-12-17 02:14:50,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:50,630][root][INFO] - Training Epoch: 1/2, step 6374/7134 completed (loss: 0.19827863574028015, acc: 0.9663865566253662)
[2024-12-17 02:14:50,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:50,933][root][INFO] - Training Epoch: 1/2, step 6375/7134 completed (loss: 0.27620044350624084, acc: 0.9226519465446472)
[2024-12-17 02:14:51,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:51,199][root][INFO] - Training Epoch: 1/2, step 6376/7134 completed (loss: 0.116573266685009, acc: 0.9593495726585388)
[2024-12-17 02:14:51,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:51,458][root][INFO] - Training Epoch: 1/2, step 6377/7134 completed (loss: 0.2745978832244873, acc: 0.9279999732971191)
[2024-12-17 02:14:51,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:51,752][root][INFO] - Training Epoch: 1/2, step 6378/7134 completed (loss: 0.3095414340496063, acc: 0.9023255705833435)
[2024-12-17 02:14:51,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:52,015][root][INFO] - Training Epoch: 1/2, step 6379/7134 completed (loss: 0.34005630016326904, acc: 0.8947368264198303)
[2024-12-17 02:14:52,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:52,309][root][INFO] - Training Epoch: 1/2, step 6380/7134 completed (loss: 0.2803719639778137, acc: 0.9375)
[2024-12-17 02:14:52,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:52,600][root][INFO] - Training Epoch: 1/2, step 6381/7134 completed (loss: 0.11866948753595352, acc: 0.9797297120094299)
[2024-12-17 02:14:52,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:52,888][root][INFO] - Training Epoch: 1/2, step 6382/7134 completed (loss: 0.1834108680486679, acc: 0.9560439586639404)
[2024-12-17 02:14:53,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:53,189][root][INFO] - Training Epoch: 1/2, step 6383/7134 completed (loss: 0.45335516333580017, acc: 0.913294792175293)
[2024-12-17 02:14:53,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:53,485][root][INFO] - Training Epoch: 1/2, step 6384/7134 completed (loss: 0.18499846756458282, acc: 0.9556962251663208)
[2024-12-17 02:14:53,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:53,785][root][INFO] - Training Epoch: 1/2, step 6385/7134 completed (loss: 0.34440991282463074, acc: 0.9219512343406677)
[2024-12-17 02:14:53,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:54,065][root][INFO] - Training Epoch: 1/2, step 6386/7134 completed (loss: 0.2914969325065613, acc: 0.9462365508079529)
[2024-12-17 02:14:54,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:54,336][root][INFO] - Training Epoch: 1/2, step 6387/7134 completed (loss: 0.20685669779777527, acc: 0.939393937587738)
[2024-12-17 02:14:54,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:54,609][root][INFO] - Training Epoch: 1/2, step 6388/7134 completed (loss: 0.3000546991825104, acc: 0.9113923907279968)
[2024-12-17 02:14:54,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:54,892][root][INFO] - Training Epoch: 1/2, step 6389/7134 completed (loss: 0.19585107266902924, acc: 0.9375)
[2024-12-17 02:14:54,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:55,179][root][INFO] - Training Epoch: 1/2, step 6390/7134 completed (loss: 0.18976633250713348, acc: 0.9521738886833191)
[2024-12-17 02:14:55,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:55,441][root][INFO] - Training Epoch: 1/2, step 6391/7134 completed (loss: 0.2551579773426056, acc: 0.9476743936538696)
[2024-12-17 02:14:55,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:55,711][root][INFO] - Training Epoch: 1/2, step 6392/7134 completed (loss: 0.4262053668498993, acc: 0.904347836971283)
[2024-12-17 02:14:55,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:55,995][root][INFO] - Training Epoch: 1/2, step 6393/7134 completed (loss: 0.19822876155376434, acc: 0.9444444179534912)
[2024-12-17 02:14:56,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:56,270][root][INFO] - Training Epoch: 1/2, step 6394/7134 completed (loss: 0.3151519298553467, acc: 0.9222221970558167)
[2024-12-17 02:14:56,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:56,555][root][INFO] - Training Epoch: 1/2, step 6395/7134 completed (loss: 0.2063065469264984, acc: 0.9455445408821106)
[2024-12-17 02:14:56,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:56,833][root][INFO] - Training Epoch: 1/2, step 6396/7134 completed (loss: 0.18078944087028503, acc: 0.9617224931716919)
[2024-12-17 02:14:56,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:57,117][root][INFO] - Training Epoch: 1/2, step 6397/7134 completed (loss: 0.1292642205953598, acc: 0.9701492786407471)
[2024-12-17 02:14:57,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:57,395][root][INFO] - Training Epoch: 1/2, step 6398/7134 completed (loss: 0.15937785804271698, acc: 0.9586206674575806)
[2024-12-17 02:14:57,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:57,688][root][INFO] - Training Epoch: 1/2, step 6399/7134 completed (loss: 0.31919315457344055, acc: 0.9438202381134033)
[2024-12-17 02:14:57,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:57,965][root][INFO] - Training Epoch: 1/2, step 6400/7134 completed (loss: 0.10869333148002625, acc: 0.9698795080184937)
[2024-12-17 02:14:58,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:58,251][root][INFO] - Training Epoch: 1/2, step 6401/7134 completed (loss: 0.1361554116010666, acc: 0.9666666388511658)
[2024-12-17 02:14:58,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:58,551][root][INFO] - Training Epoch: 1/2, step 6402/7134 completed (loss: 0.2949989140033722, acc: 0.9292929172515869)
[2024-12-17 02:14:58,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:58,814][root][INFO] - Training Epoch: 1/2, step 6403/7134 completed (loss: 0.06597696989774704, acc: 0.984455943107605)
[2024-12-17 02:14:58,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:59,083][root][INFO] - Training Epoch: 1/2, step 6404/7134 completed (loss: 0.06935613602399826, acc: 0.9822485446929932)
[2024-12-17 02:14:59,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:59,421][root][INFO] - Training Epoch: 1/2, step 6405/7134 completed (loss: 0.17024357616901398, acc: 0.9567307829856873)
[2024-12-17 02:14:59,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:59,716][root][INFO] - Training Epoch: 1/2, step 6406/7134 completed (loss: 0.22547714412212372, acc: 0.9300000071525574)
[2024-12-17 02:14:59,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:00,013][root][INFO] - Training Epoch: 1/2, step 6407/7134 completed (loss: 0.15950754284858704, acc: 0.9611111283302307)
[2024-12-17 02:15:00,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:00,285][root][INFO] - Training Epoch: 1/2, step 6408/7134 completed (loss: 0.35510191321372986, acc: 0.9166666865348816)
[2024-12-17 02:15:00,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:00,550][root][INFO] - Training Epoch: 1/2, step 6409/7134 completed (loss: 0.20503322780132294, acc: 0.9817073345184326)
[2024-12-17 02:15:00,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:00,827][root][INFO] - Training Epoch: 1/2, step 6410/7134 completed (loss: 0.3641088306903839, acc: 0.925000011920929)
[2024-12-17 02:15:00,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:01,086][root][INFO] - Training Epoch: 1/2, step 6411/7134 completed (loss: 0.3475482761859894, acc: 0.8837209343910217)
[2024-12-17 02:15:01,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:01,355][root][INFO] - Training Epoch: 1/2, step 6412/7134 completed (loss: 0.12217789888381958, acc: 0.9677419066429138)
[2024-12-17 02:15:01,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:01,645][root][INFO] - Training Epoch: 1/2, step 6413/7134 completed (loss: 0.21874678134918213, acc: 0.9463087320327759)
[2024-12-17 02:15:01,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:01,907][root][INFO] - Training Epoch: 1/2, step 6414/7134 completed (loss: 0.16461606323719025, acc: 0.9539473652839661)
[2024-12-17 02:15:01,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:02,173][root][INFO] - Training Epoch: 1/2, step 6415/7134 completed (loss: 0.11794085055589676, acc: 0.9602272510528564)
[2024-12-17 02:15:02,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:02,455][root][INFO] - Training Epoch: 1/2, step 6416/7134 completed (loss: 0.35548877716064453, acc: 0.9275362491607666)
[2024-12-17 02:15:02,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:02,730][root][INFO] - Training Epoch: 1/2, step 6417/7134 completed (loss: 0.5269332528114319, acc: 0.8914728760719299)
[2024-12-17 02:15:02,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:03,005][root][INFO] - Training Epoch: 1/2, step 6418/7134 completed (loss: 0.6744763255119324, acc: 0.8389261960983276)
[2024-12-17 02:15:03,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:03,271][root][INFO] - Training Epoch: 1/2, step 6419/7134 completed (loss: 0.5381960868835449, acc: 0.8831169009208679)
[2024-12-17 02:15:03,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:03,546][root][INFO] - Training Epoch: 1/2, step 6420/7134 completed (loss: 0.38179436326026917, acc: 0.8797468543052673)
[2024-12-17 02:15:03,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:03,818][root][INFO] - Training Epoch: 1/2, step 6421/7134 completed (loss: 0.26854386925697327, acc: 0.9457831382751465)
[2024-12-17 02:15:03,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:04,097][root][INFO] - Training Epoch: 1/2, step 6422/7134 completed (loss: 0.30043914914131165, acc: 0.9273743033409119)
[2024-12-17 02:15:04,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:04,378][root][INFO] - Training Epoch: 1/2, step 6423/7134 completed (loss: 0.29974687099456787, acc: 0.9487179517745972)
[2024-12-17 02:15:04,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:04,662][root][INFO] - Training Epoch: 1/2, step 6424/7134 completed (loss: 0.26958391070365906, acc: 0.9414893388748169)
[2024-12-17 02:15:04,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:04,950][root][INFO] - Training Epoch: 1/2, step 6425/7134 completed (loss: 0.21949459612369537, acc: 0.9329608678817749)
[2024-12-17 02:15:05,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:05,244][root][INFO] - Training Epoch: 1/2, step 6426/7134 completed (loss: 0.22422583401203156, acc: 0.9441340565681458)
[2024-12-17 02:15:05,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:05,521][root][INFO] - Training Epoch: 1/2, step 6427/7134 completed (loss: 0.24125398695468903, acc: 0.9171974658966064)
[2024-12-17 02:15:05,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:05,801][root][INFO] - Training Epoch: 1/2, step 6428/7134 completed (loss: 0.1804676502943039, acc: 0.9681528806686401)
[2024-12-17 02:15:05,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:06,073][root][INFO] - Training Epoch: 1/2, step 6429/7134 completed (loss: 0.10544297099113464, acc: 0.9870967864990234)
[2024-12-17 02:15:06,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:06,358][root][INFO] - Training Epoch: 1/2, step 6430/7134 completed (loss: 0.3723786473274231, acc: 0.9312499761581421)
[2024-12-17 02:15:06,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:06,622][root][INFO] - Training Epoch: 1/2, step 6431/7134 completed (loss: 0.4126735031604767, acc: 0.9027026891708374)
[2024-12-17 02:15:06,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:06,890][root][INFO] - Training Epoch: 1/2, step 6432/7134 completed (loss: 1.2206530570983887, acc: 0.774193525314331)
[2024-12-17 02:15:06,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:07,174][root][INFO] - Training Epoch: 1/2, step 6433/7134 completed (loss: 0.4918263256549835, acc: 0.9204545617103577)
[2024-12-17 02:15:07,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:07,435][root][INFO] - Training Epoch: 1/2, step 6434/7134 completed (loss: 0.1601596623659134, acc: 0.9479768872261047)
[2024-12-17 02:15:07,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:07,710][root][INFO] - Training Epoch: 1/2, step 6435/7134 completed (loss: 0.15167182683944702, acc: 0.9420289993286133)
[2024-12-17 02:15:07,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:07,984][root][INFO] - Training Epoch: 1/2, step 6436/7134 completed (loss: 0.26359349489212036, acc: 0.9597315192222595)
[2024-12-17 02:15:08,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:08,259][root][INFO] - Training Epoch: 1/2, step 6437/7134 completed (loss: 0.503760576248169, acc: 0.9210526347160339)
[2024-12-17 02:15:08,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:08,543][root][INFO] - Training Epoch: 1/2, step 6438/7134 completed (loss: 0.5530233383178711, acc: 0.8883495330810547)
[2024-12-17 02:15:08,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:08,812][root][INFO] - Training Epoch: 1/2, step 6439/7134 completed (loss: 0.22882184386253357, acc: 0.9316770434379578)
[2024-12-17 02:15:08,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:09,112][root][INFO] - Training Epoch: 1/2, step 6440/7134 completed (loss: 0.3274034857749939, acc: 0.9375)
[2024-12-17 02:15:09,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:09,376][root][INFO] - Training Epoch: 1/2, step 6441/7134 completed (loss: 0.18225927650928497, acc: 0.9622641801834106)
[2024-12-17 02:15:09,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:09,675][root][INFO] - Training Epoch: 1/2, step 6442/7134 completed (loss: 0.19537901878356934, acc: 0.9708737730979919)
[2024-12-17 02:15:09,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:09,955][root][INFO] - Training Epoch: 1/2, step 6443/7134 completed (loss: 0.11127298325300217, acc: 0.9754902124404907)
[2024-12-17 02:15:10,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:10,235][root][INFO] - Training Epoch: 1/2, step 6444/7134 completed (loss: 0.3768380880355835, acc: 0.9055555462837219)
[2024-12-17 02:15:10,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:10,515][root][INFO] - Training Epoch: 1/2, step 6445/7134 completed (loss: 0.4072993993759155, acc: 0.9211822748184204)
[2024-12-17 02:15:10,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:10,789][root][INFO] - Training Epoch: 1/2, step 6446/7134 completed (loss: 0.18467240035533905, acc: 0.9558823704719543)
[2024-12-17 02:15:10,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:11,082][root][INFO] - Training Epoch: 1/2, step 6447/7134 completed (loss: 0.2510353624820709, acc: 0.9479166865348816)
[2024-12-17 02:15:11,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:11,356][root][INFO] - Training Epoch: 1/2, step 6448/7134 completed (loss: 0.6844797134399414, acc: 0.8580645322799683)
[2024-12-17 02:15:11,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:11,636][root][INFO] - Training Epoch: 1/2, step 6449/7134 completed (loss: 0.26720091700553894, acc: 0.9481865167617798)
[2024-12-17 02:15:11,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:11,917][root][INFO] - Training Epoch: 1/2, step 6450/7134 completed (loss: 0.21116885542869568, acc: 0.9421965479850769)
[2024-12-17 02:15:12,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:12,239][root][INFO] - Training Epoch: 1/2, step 6451/7134 completed (loss: 0.3318774700164795, acc: 0.9033613204956055)
[2024-12-17 02:15:12,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:12,507][root][INFO] - Training Epoch: 1/2, step 6452/7134 completed (loss: 0.19704419374465942, acc: 0.9489796161651611)
[2024-12-17 02:15:12,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:12,779][root][INFO] - Training Epoch: 1/2, step 6453/7134 completed (loss: 0.2574220299720764, acc: 0.9386503100395203)
[2024-12-17 02:15:12,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:13,069][root][INFO] - Training Epoch: 1/2, step 6454/7134 completed (loss: 0.3224100172519684, acc: 0.9289617538452148)
[2024-12-17 02:15:13,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:13,339][root][INFO] - Training Epoch: 1/2, step 6455/7134 completed (loss: 0.4235978424549103, acc: 0.9266666769981384)
[2024-12-17 02:15:13,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:13,611][root][INFO] - Training Epoch: 1/2, step 6456/7134 completed (loss: 0.6492207050323486, acc: 0.8682634830474854)
[2024-12-17 02:15:13,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:13,906][root][INFO] - Training Epoch: 1/2, step 6457/7134 completed (loss: 0.288406640291214, acc: 0.9266055226325989)
[2024-12-17 02:15:14,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:14,164][root][INFO] - Training Epoch: 1/2, step 6458/7134 completed (loss: 0.22125792503356934, acc: 0.9527027010917664)
[2024-12-17 02:15:14,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:14,423][root][INFO] - Training Epoch: 1/2, step 6459/7134 completed (loss: 0.0825103297829628, acc: 0.9754601120948792)
[2024-12-17 02:15:14,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:14,700][root][INFO] - Training Epoch: 1/2, step 6460/7134 completed (loss: 0.08954575657844543, acc: 0.9693877696990967)
[2024-12-17 02:15:14,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:14,969][root][INFO] - Training Epoch: 1/2, step 6461/7134 completed (loss: 0.11854461580514908, acc: 0.9595375657081604)
[2024-12-17 02:15:15,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:15,253][root][INFO] - Training Epoch: 1/2, step 6462/7134 completed (loss: 0.16298742592334747, acc: 0.957446813583374)
[2024-12-17 02:15:15,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:15,577][root][INFO] - Training Epoch: 1/2, step 6463/7134 completed (loss: 0.24756310880184174, acc: 0.9271844625473022)
[2024-12-17 02:15:15,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:15,858][root][INFO] - Training Epoch: 1/2, step 6464/7134 completed (loss: 0.20490311086177826, acc: 0.9497206807136536)
[2024-12-17 02:15:15,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:16,128][root][INFO] - Training Epoch: 1/2, step 6465/7134 completed (loss: 0.13485585153102875, acc: 0.9781420826911926)
[2024-12-17 02:15:16,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:16,415][root][INFO] - Training Epoch: 1/2, step 6466/7134 completed (loss: 0.22118137776851654, acc: 0.9312169551849365)
[2024-12-17 02:15:16,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:16,692][root][INFO] - Training Epoch: 1/2, step 6467/7134 completed (loss: 0.35282251238822937, acc: 0.9216867685317993)
[2024-12-17 02:15:16,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:16,973][root][INFO] - Training Epoch: 1/2, step 6468/7134 completed (loss: 0.22806872427463531, acc: 0.9632353186607361)
[2024-12-17 02:15:17,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:17,274][root][INFO] - Training Epoch: 1/2, step 6469/7134 completed (loss: 0.3354368209838867, acc: 0.8925233483314514)
[2024-12-17 02:15:17,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:17,541][root][INFO] - Training Epoch: 1/2, step 6470/7134 completed (loss: 0.3485109210014343, acc: 0.9117646813392639)
[2024-12-17 02:15:17,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:17,830][root][INFO] - Training Epoch: 1/2, step 6471/7134 completed (loss: 0.14322271943092346, acc: 0.971222996711731)
[2024-12-17 02:15:17,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:18,120][root][INFO] - Training Epoch: 1/2, step 6472/7134 completed (loss: 0.3148254156112671, acc: 0.9200000166893005)
[2024-12-17 02:15:18,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:18,406][root][INFO] - Training Epoch: 1/2, step 6473/7134 completed (loss: 0.13153193891048431, acc: 0.9722222089767456)
[2024-12-17 02:15:18,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:18,679][root][INFO] - Training Epoch: 1/2, step 6474/7134 completed (loss: 0.19098281860351562, acc: 0.9408602118492126)
[2024-12-17 02:15:18,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:18,941][root][INFO] - Training Epoch: 1/2, step 6475/7134 completed (loss: 0.19171668589115143, acc: 0.9428571462631226)
[2024-12-17 02:15:19,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:19,214][root][INFO] - Training Epoch: 1/2, step 6476/7134 completed (loss: 0.21343307197093964, acc: 0.9333333373069763)
[2024-12-17 02:15:19,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:19,488][root][INFO] - Training Epoch: 1/2, step 6477/7134 completed (loss: 0.1649632602930069, acc: 0.9652174115180969)
[2024-12-17 02:15:19,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:19,772][root][INFO] - Training Epoch: 1/2, step 6478/7134 completed (loss: 0.17779777944087982, acc: 0.95652174949646)
[2024-12-17 02:15:19,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:20,066][root][INFO] - Training Epoch: 1/2, step 6479/7134 completed (loss: 0.21112138032913208, acc: 0.9328858852386475)
[2024-12-17 02:15:20,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:20,350][root][INFO] - Training Epoch: 1/2, step 6480/7134 completed (loss: 0.29089561104774475, acc: 0.9285714030265808)
[2024-12-17 02:15:20,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:20,636][root][INFO] - Training Epoch: 1/2, step 6481/7134 completed (loss: 0.10398665070533752, acc: 0.9714285731315613)
[2024-12-17 02:15:20,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:20,946][root][INFO] - Training Epoch: 1/2, step 6482/7134 completed (loss: 0.15213298797607422, acc: 0.9700000286102295)
[2024-12-17 02:15:21,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:21,225][root][INFO] - Training Epoch: 1/2, step 6483/7134 completed (loss: 0.17759700119495392, acc: 0.9652777910232544)
[2024-12-17 02:15:21,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:21,515][root][INFO] - Training Epoch: 1/2, step 6484/7134 completed (loss: 0.19262556731700897, acc: 0.9649122953414917)
[2024-12-17 02:15:21,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:21,810][root][INFO] - Training Epoch: 1/2, step 6485/7134 completed (loss: 0.19755005836486816, acc: 0.9579831957817078)
[2024-12-17 02:15:21,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:22,094][root][INFO] - Training Epoch: 1/2, step 6486/7134 completed (loss: 0.6123476028442383, acc: 0.8695651888847351)
[2024-12-17 02:15:22,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:22,355][root][INFO] - Training Epoch: 1/2, step 6487/7134 completed (loss: 0.44406870007514954, acc: 0.875)
[2024-12-17 02:15:22,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:22,634][root][INFO] - Training Epoch: 1/2, step 6488/7134 completed (loss: 0.4508994519710541, acc: 0.8560606241226196)
[2024-12-17 02:15:22,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:22,903][root][INFO] - Training Epoch: 1/2, step 6489/7134 completed (loss: 0.5183647871017456, acc: 0.9059829115867615)
[2024-12-17 02:15:23,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:23,163][root][INFO] - Training Epoch: 1/2, step 6490/7134 completed (loss: 0.7234505414962769, acc: 0.8358209133148193)
[2024-12-17 02:15:23,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:23,440][root][INFO] - Training Epoch: 1/2, step 6491/7134 completed (loss: 0.4060189425945282, acc: 0.8896104097366333)
[2024-12-17 02:15:23,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:23,724][root][INFO] - Training Epoch: 1/2, step 6492/7134 completed (loss: 0.1976904571056366, acc: 0.9290322661399841)
[2024-12-17 02:15:23,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:24,008][root][INFO] - Training Epoch: 1/2, step 6493/7134 completed (loss: 0.36855989694595337, acc: 0.9166666865348816)
[2024-12-17 02:15:24,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:24,292][root][INFO] - Training Epoch: 1/2, step 6494/7134 completed (loss: 0.4048558473587036, acc: 0.8938053250312805)
[2024-12-17 02:15:24,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:24,583][root][INFO] - Training Epoch: 1/2, step 6495/7134 completed (loss: 0.35373008251190186, acc: 0.9074074029922485)
[2024-12-17 02:15:24,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:24,870][root][INFO] - Training Epoch: 1/2, step 6496/7134 completed (loss: 0.48812296986579895, acc: 0.8612716794013977)
[2024-12-17 02:15:24,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:25,141][root][INFO] - Training Epoch: 1/2, step 6497/7134 completed (loss: 0.5245230197906494, acc: 0.8819444179534912)
[2024-12-17 02:15:25,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:25,428][root][INFO] - Training Epoch: 1/2, step 6498/7134 completed (loss: 0.30137160420417786, acc: 0.9352940917015076)
[2024-12-17 02:15:25,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:25,714][root][INFO] - Training Epoch: 1/2, step 6499/7134 completed (loss: 0.34395644068717957, acc: 0.9202127456665039)
[2024-12-17 02:15:25,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:26,013][root][INFO] - Training Epoch: 1/2, step 6500/7134 completed (loss: 0.556678056716919, acc: 0.8505747318267822)
[2024-12-17 02:15:26,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:26,283][root][INFO] - Training Epoch: 1/2, step 6501/7134 completed (loss: 0.7037043571472168, acc: 0.8556700944900513)
[2024-12-17 02:15:26,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:26,614][root][INFO] - Training Epoch: 1/2, step 6502/7134 completed (loss: 0.27681782841682434, acc: 0.9191918969154358)
[2024-12-17 02:15:26,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:26,882][root][INFO] - Training Epoch: 1/2, step 6503/7134 completed (loss: 0.37736019492149353, acc: 0.9316770434379578)
[2024-12-17 02:15:27,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:27,142][root][INFO] - Training Epoch: 1/2, step 6504/7134 completed (loss: 0.43739616870880127, acc: 0.8767123222351074)
[2024-12-17 02:15:27,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:27,423][root][INFO] - Training Epoch: 1/2, step 6505/7134 completed (loss: 0.46912139654159546, acc: 0.8600000143051147)
[2024-12-17 02:15:27,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:27,736][root][INFO] - Training Epoch: 1/2, step 6506/7134 completed (loss: 0.43744462728500366, acc: 0.8969072103500366)
[2024-12-17 02:15:27,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:28,025][root][INFO] - Training Epoch: 1/2, step 6507/7134 completed (loss: 0.5280487537384033, acc: 0.8711656332015991)
[2024-12-17 02:15:28,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:28,310][root][INFO] - Training Epoch: 1/2, step 6508/7134 completed (loss: 0.2792366147041321, acc: 0.9222221970558167)
[2024-12-17 02:15:28,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:28,586][root][INFO] - Training Epoch: 1/2, step 6509/7134 completed (loss: 0.22154271602630615, acc: 0.9329897165298462)
[2024-12-17 02:15:28,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:28,891][root][INFO] - Training Epoch: 1/2, step 6510/7134 completed (loss: 0.27065014839172363, acc: 0.917475700378418)
[2024-12-17 02:15:29,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:29,168][root][INFO] - Training Epoch: 1/2, step 6511/7134 completed (loss: 0.40147486329078674, acc: 0.888059675693512)
[2024-12-17 02:15:29,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:29,427][root][INFO] - Training Epoch: 1/2, step 6512/7134 completed (loss: 0.28006845712661743, acc: 0.8909090757369995)
[2024-12-17 02:15:29,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:29,693][root][INFO] - Training Epoch: 1/2, step 6513/7134 completed (loss: 0.18354742228984833, acc: 0.9555555582046509)
[2024-12-17 02:15:29,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:29,977][root][INFO] - Training Epoch: 1/2, step 6514/7134 completed (loss: 0.48104768991470337, acc: 0.9135802388191223)
[2024-12-17 02:15:30,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:30,273][root][INFO] - Training Epoch: 1/2, step 6515/7134 completed (loss: 0.23300115764141083, acc: 0.9340659379959106)
[2024-12-17 02:15:30,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:30,556][root][INFO] - Training Epoch: 1/2, step 6516/7134 completed (loss: 0.3443630337715149, acc: 0.929411768913269)
[2024-12-17 02:15:30,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:30,832][root][INFO] - Training Epoch: 1/2, step 6517/7134 completed (loss: 0.19972585141658783, acc: 0.9503105878829956)
[2024-12-17 02:15:30,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:31,114][root][INFO] - Training Epoch: 1/2, step 6518/7134 completed (loss: 0.14251475036144257, acc: 0.9520958065986633)
[2024-12-17 02:15:31,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:31,390][root][INFO] - Training Epoch: 1/2, step 6519/7134 completed (loss: 0.16723336279392242, acc: 0.960629940032959)
[2024-12-17 02:15:31,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:31,665][root][INFO] - Training Epoch: 1/2, step 6520/7134 completed (loss: 0.09800660610198975, acc: 0.9740259647369385)
[2024-12-17 02:15:31,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:31,948][root][INFO] - Training Epoch: 1/2, step 6521/7134 completed (loss: 0.16143549978733063, acc: 0.9459459185600281)
[2024-12-17 02:15:32,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:32,225][root][INFO] - Training Epoch: 1/2, step 6522/7134 completed (loss: 0.33837780356407166, acc: 0.9215686321258545)
[2024-12-17 02:15:32,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:32,501][root][INFO] - Training Epoch: 1/2, step 6523/7134 completed (loss: 0.44101279973983765, acc: 0.8888888955116272)
[2024-12-17 02:15:32,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:32,785][root][INFO] - Training Epoch: 1/2, step 6524/7134 completed (loss: 0.26805680990219116, acc: 0.950276255607605)
[2024-12-17 02:15:32,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:33,086][root][INFO] - Training Epoch: 1/2, step 6525/7134 completed (loss: 0.266851544380188, acc: 0.9586777091026306)
[2024-12-17 02:15:33,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:33,431][root][INFO] - Training Epoch: 1/2, step 6526/7134 completed (loss: 0.3248870372772217, acc: 0.9593908786773682)
[2024-12-17 02:15:33,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:33,730][root][INFO] - Training Epoch: 1/2, step 6527/7134 completed (loss: 0.42253953218460083, acc: 0.905063271522522)
[2024-12-17 02:15:33,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:34,015][root][INFO] - Training Epoch: 1/2, step 6528/7134 completed (loss: 0.44752275943756104, acc: 0.9202898740768433)
[2024-12-17 02:15:34,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:34,296][root][INFO] - Training Epoch: 1/2, step 6529/7134 completed (loss: 0.6823079586029053, acc: 0.8931297659873962)
[2024-12-17 02:15:34,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:34,629][root][INFO] - Training Epoch: 1/2, step 6530/7134 completed (loss: 0.28716403245925903, acc: 0.9337016344070435)
[2024-12-17 02:15:34,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:34,931][root][INFO] - Training Epoch: 1/2, step 6531/7134 completed (loss: 0.23376286029815674, acc: 0.9207317233085632)
[2024-12-17 02:15:35,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:35,235][root][INFO] - Training Epoch: 1/2, step 6532/7134 completed (loss: 0.34905216097831726, acc: 0.9395604133605957)
[2024-12-17 02:15:35,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:35,542][root][INFO] - Training Epoch: 1/2, step 6533/7134 completed (loss: 0.11025038361549377, acc: 0.9610389471054077)
[2024-12-17 02:15:35,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:35,819][root][INFO] - Training Epoch: 1/2, step 6534/7134 completed (loss: 0.352689266204834, acc: 0.9421965479850769)
[2024-12-17 02:15:35,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:36,087][root][INFO] - Training Epoch: 1/2, step 6535/7134 completed (loss: 0.15235856175422668, acc: 0.9622641801834106)
[2024-12-17 02:15:36,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:36,360][root][INFO] - Training Epoch: 1/2, step 6536/7134 completed (loss: 0.12791095674037933, acc: 0.9652174115180969)
[2024-12-17 02:15:36,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:36,624][root][INFO] - Training Epoch: 1/2, step 6537/7134 completed (loss: 0.2756809890270233, acc: 0.9285714030265808)
[2024-12-17 02:15:36,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:36,894][root][INFO] - Training Epoch: 1/2, step 6538/7134 completed (loss: 0.2837763726711273, acc: 0.9452054500579834)
[2024-12-17 02:15:36,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:37,107][root][INFO] - Training Epoch: 1/2, step 6539/7134 completed (loss: 0.13419683277606964, acc: 0.9610389471054077)
[2024-12-17 02:15:37,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:37,366][root][INFO] - Training Epoch: 1/2, step 6540/7134 completed (loss: 0.9845417141914368, acc: 0.8636363744735718)
[2024-12-17 02:15:37,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:37,655][root][INFO] - Training Epoch: 1/2, step 6541/7134 completed (loss: 0.14710822701454163, acc: 0.9558011293411255)
[2024-12-17 02:15:37,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:37,941][root][INFO] - Training Epoch: 1/2, step 6542/7134 completed (loss: 0.23344671726226807, acc: 0.949999988079071)
[2024-12-17 02:15:38,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:38,220][root][INFO] - Training Epoch: 1/2, step 6543/7134 completed (loss: 0.14834685623645782, acc: 0.9649122953414917)
[2024-12-17 02:15:38,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:38,498][root][INFO] - Training Epoch: 1/2, step 6544/7134 completed (loss: 0.22565315663814545, acc: 0.9459459185600281)
[2024-12-17 02:15:38,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:38,768][root][INFO] - Training Epoch: 1/2, step 6545/7134 completed (loss: 0.10524574667215347, acc: 0.9834710955619812)
[2024-12-17 02:15:38,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:39,034][root][INFO] - Training Epoch: 1/2, step 6546/7134 completed (loss: 0.25050318241119385, acc: 0.9637681245803833)
[2024-12-17 02:15:39,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:39,310][root][INFO] - Training Epoch: 1/2, step 6547/7134 completed (loss: 0.3589845597743988, acc: 0.9420289993286133)
[2024-12-17 02:15:39,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:39,578][root][INFO] - Training Epoch: 1/2, step 6548/7134 completed (loss: 0.2768952250480652, acc: 0.9142857193946838)
[2024-12-17 02:15:39,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:39,861][root][INFO] - Training Epoch: 1/2, step 6549/7134 completed (loss: 0.43502363562583923, acc: 0.9160305261611938)
[2024-12-17 02:15:39,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:40,140][root][INFO] - Training Epoch: 1/2, step 6550/7134 completed (loss: 0.29671815037727356, acc: 0.9426751732826233)
[2024-12-17 02:15:40,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:40,423][root][INFO] - Training Epoch: 1/2, step 6551/7134 completed (loss: 0.22306948900222778, acc: 0.9644669890403748)
[2024-12-17 02:15:40,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:40,732][root][INFO] - Training Epoch: 1/2, step 6552/7134 completed (loss: 0.5005254149436951, acc: 0.8766520023345947)
[2024-12-17 02:15:40,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:41,033][root][INFO] - Training Epoch: 1/2, step 6553/7134 completed (loss: 0.34678515791893005, acc: 0.9191918969154358)
[2024-12-17 02:15:41,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:41,324][root][INFO] - Training Epoch: 1/2, step 6554/7134 completed (loss: 0.26416969299316406, acc: 0.9392523169517517)
[2024-12-17 02:15:41,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:41,613][root][INFO] - Training Epoch: 1/2, step 6555/7134 completed (loss: 0.4131142199039459, acc: 0.9137930870056152)
[2024-12-17 02:15:41,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:41,880][root][INFO] - Training Epoch: 1/2, step 6556/7134 completed (loss: 0.357220321893692, acc: 0.9049773812294006)
[2024-12-17 02:15:42,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:42,176][root][INFO] - Training Epoch: 1/2, step 6557/7134 completed (loss: 0.3507084250450134, acc: 0.9324324131011963)
[2024-12-17 02:15:42,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:42,477][root][INFO] - Training Epoch: 1/2, step 6558/7134 completed (loss: 0.34060579538345337, acc: 0.9252336621284485)
[2024-12-17 02:15:42,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:42,753][root][INFO] - Training Epoch: 1/2, step 6559/7134 completed (loss: 0.31944650411605835, acc: 0.9277108311653137)
[2024-12-17 02:15:42,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:43,108][root][INFO] - Training Epoch: 1/2, step 6560/7134 completed (loss: 0.14517900347709656, acc: 0.9685863852500916)
[2024-12-17 02:15:43,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:43,374][root][INFO] - Training Epoch: 1/2, step 6561/7134 completed (loss: 0.16633498668670654, acc: 0.963350772857666)
[2024-12-17 02:15:43,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:43,658][root][INFO] - Training Epoch: 1/2, step 6562/7134 completed (loss: 0.26445886492729187, acc: 0.9056603908538818)
[2024-12-17 02:15:43,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:43,958][root][INFO] - Training Epoch: 1/2, step 6563/7134 completed (loss: 0.2845340371131897, acc: 0.9191918969154358)
[2024-12-17 02:15:44,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:44,231][root][INFO] - Training Epoch: 1/2, step 6564/7134 completed (loss: 0.22983920574188232, acc: 0.9457831382751465)
[2024-12-17 02:15:44,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:44,522][root][INFO] - Training Epoch: 1/2, step 6565/7134 completed (loss: 0.46198806166648865, acc: 0.9144144058227539)
[2024-12-17 02:15:44,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:44,824][root][INFO] - Training Epoch: 1/2, step 6566/7134 completed (loss: 0.23839162290096283, acc: 0.9395161271095276)
[2024-12-17 02:15:44,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:45,165][root][INFO] - Training Epoch: 1/2, step 6567/7134 completed (loss: 0.25806060433387756, acc: 0.9466666579246521)
[2024-12-17 02:15:45,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:45,450][root][INFO] - Training Epoch: 1/2, step 6568/7134 completed (loss: 0.22535747289657593, acc: 0.9285714030265808)
[2024-12-17 02:15:45,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:45,730][root][INFO] - Training Epoch: 1/2, step 6569/7134 completed (loss: 0.20827089250087738, acc: 0.9593908786773682)
[2024-12-17 02:15:45,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:46,022][root][INFO] - Training Epoch: 1/2, step 6570/7134 completed (loss: 0.26728081703186035, acc: 0.935960590839386)
[2024-12-17 02:15:46,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:46,277][root][INFO] - Training Epoch: 1/2, step 6571/7134 completed (loss: 0.16811135411262512, acc: 0.9575757384300232)
[2024-12-17 02:15:46,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:46,554][root][INFO] - Training Epoch: 1/2, step 6572/7134 completed (loss: 0.23779281973838806, acc: 0.9317073225975037)
[2024-12-17 02:15:46,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:46,836][root][INFO] - Training Epoch: 1/2, step 6573/7134 completed (loss: 0.15991638600826263, acc: 0.9708737730979919)
[2024-12-17 02:15:46,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:47,111][root][INFO] - Training Epoch: 1/2, step 6574/7134 completed (loss: 0.25004181265830994, acc: 0.943965494632721)
[2024-12-17 02:15:47,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:47,427][root][INFO] - Training Epoch: 1/2, step 6575/7134 completed (loss: 0.2927755117416382, acc: 0.934272289276123)
[2024-12-17 02:15:47,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:47,714][root][INFO] - Training Epoch: 1/2, step 6576/7134 completed (loss: 0.20471733808517456, acc: 0.9587156176567078)
[2024-12-17 02:15:47,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:47,991][root][INFO] - Training Epoch: 1/2, step 6577/7134 completed (loss: 0.3398749530315399, acc: 0.9333333373069763)
[2024-12-17 02:15:48,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:48,396][root][INFO] - Training Epoch: 1/2, step 6578/7134 completed (loss: 0.21935418248176575, acc: 0.938524603843689)
[2024-12-17 02:15:48,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:48,663][root][INFO] - Training Epoch: 1/2, step 6579/7134 completed (loss: 0.5001228451728821, acc: 0.8872180581092834)
[2024-12-17 02:15:48,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:48,989][root][INFO] - Training Epoch: 1/2, step 6580/7134 completed (loss: 0.23623709380626678, acc: 0.9368420839309692)
[2024-12-17 02:15:49,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:49,276][root][INFO] - Training Epoch: 1/2, step 6581/7134 completed (loss: 0.3767484426498413, acc: 0.9189189076423645)
[2024-12-17 02:15:49,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:49,562][root][INFO] - Training Epoch: 1/2, step 6582/7134 completed (loss: 0.512137234210968, acc: 0.8947368264198303)
[2024-12-17 02:15:49,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:49,854][root][INFO] - Training Epoch: 1/2, step 6583/7134 completed (loss: 0.3322702646255493, acc: 0.9246231317520142)
[2024-12-17 02:15:49,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:50,145][root][INFO] - Training Epoch: 1/2, step 6584/7134 completed (loss: 0.3448276221752167, acc: 0.8870967626571655)
[2024-12-17 02:15:50,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:50,439][root][INFO] - Training Epoch: 1/2, step 6585/7134 completed (loss: 0.28435999155044556, acc: 0.9189189076423645)
[2024-12-17 02:15:50,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:50,751][root][INFO] - Training Epoch: 1/2, step 6586/7134 completed (loss: 0.2494872361421585, acc: 0.9509202241897583)
[2024-12-17 02:15:50,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:51,027][root][INFO] - Training Epoch: 1/2, step 6587/7134 completed (loss: 0.3343048095703125, acc: 0.9432989954948425)
[2024-12-17 02:15:51,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:51,303][root][INFO] - Training Epoch: 1/2, step 6588/7134 completed (loss: 0.35676467418670654, acc: 0.930232584476471)
[2024-12-17 02:15:51,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:51,582][root][INFO] - Training Epoch: 1/2, step 6589/7134 completed (loss: 0.2831193804740906, acc: 0.9440993666648865)
[2024-12-17 02:15:51,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:51,867][root][INFO] - Training Epoch: 1/2, step 6590/7134 completed (loss: 0.32936450839042664, acc: 0.8989361524581909)
[2024-12-17 02:15:51,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:52,153][root][INFO] - Training Epoch: 1/2, step 6591/7134 completed (loss: 0.3361116051673889, acc: 0.9239766001701355)
[2024-12-17 02:15:52,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:52,436][root][INFO] - Training Epoch: 1/2, step 6592/7134 completed (loss: 0.23658595979213715, acc: 0.9408866763114929)
[2024-12-17 02:15:52,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:52,710][root][INFO] - Training Epoch: 1/2, step 6593/7134 completed (loss: 0.2801011800765991, acc: 0.95333331823349)
[2024-12-17 02:15:52,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:52,993][root][INFO] - Training Epoch: 1/2, step 6594/7134 completed (loss: 0.25557950139045715, acc: 0.935960590839386)
[2024-12-17 02:15:53,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:53,279][root][INFO] - Training Epoch: 1/2, step 6595/7134 completed (loss: 0.20264284312725067, acc: 0.9506173133850098)
[2024-12-17 02:15:53,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:53,544][root][INFO] - Training Epoch: 1/2, step 6596/7134 completed (loss: 0.2773999273777008, acc: 0.9337349534034729)
[2024-12-17 02:15:53,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:53,839][root][INFO] - Training Epoch: 1/2, step 6597/7134 completed (loss: 0.24943314492702484, acc: 0.9371727705001831)
[2024-12-17 02:15:53,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:54,123][root][INFO] - Training Epoch: 1/2, step 6598/7134 completed (loss: 0.24972088634967804, acc: 0.9617486596107483)
[2024-12-17 02:15:54,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:54,430][root][INFO] - Training Epoch: 1/2, step 6599/7134 completed (loss: 0.2809053957462311, acc: 0.9219512343406677)
[2024-12-17 02:15:54,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:54,703][root][INFO] - Training Epoch: 1/2, step 6600/7134 completed (loss: 0.3318869471549988, acc: 0.9269663095474243)
[2024-12-17 02:15:54,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:54,997][root][INFO] - Training Epoch: 1/2, step 6601/7134 completed (loss: 0.43619686365127563, acc: 0.9215686321258545)
[2024-12-17 02:15:55,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:55,284][root][INFO] - Training Epoch: 1/2, step 6602/7134 completed (loss: 0.30172231793403625, acc: 0.9207921028137207)
[2024-12-17 02:15:55,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:55,577][root][INFO] - Training Epoch: 1/2, step 6603/7134 completed (loss: 0.2824733257293701, acc: 0.9182389974594116)
[2024-12-17 02:15:55,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:55,865][root][INFO] - Training Epoch: 1/2, step 6604/7134 completed (loss: 0.45845237374305725, acc: 0.8602150678634644)
[2024-12-17 02:15:55,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:56,162][root][INFO] - Training Epoch: 1/2, step 6605/7134 completed (loss: 0.4385948181152344, acc: 0.8763440847396851)
[2024-12-17 02:15:56,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:56,474][root][INFO] - Training Epoch: 1/2, step 6606/7134 completed (loss: 0.2689875662326813, acc: 0.8938547372817993)
[2024-12-17 02:15:56,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:56,790][root][INFO] - Training Epoch: 1/2, step 6607/7134 completed (loss: 0.40691450238227844, acc: 0.9225806593894958)
[2024-12-17 02:15:56,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:57,112][root][INFO] - Training Epoch: 1/2, step 6608/7134 completed (loss: 0.2203814834356308, acc: 0.9520547986030579)
[2024-12-17 02:15:57,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:57,410][root][INFO] - Training Epoch: 1/2, step 6609/7134 completed (loss: 0.38955429196357727, acc: 0.8993710875511169)
[2024-12-17 02:15:57,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:57,713][root][INFO] - Training Epoch: 1/2, step 6610/7134 completed (loss: 0.3658766746520996, acc: 0.8848484754562378)
[2024-12-17 02:15:57,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:58,017][root][INFO] - Training Epoch: 1/2, step 6611/7134 completed (loss: 0.2617354691028595, acc: 0.9178082346916199)
[2024-12-17 02:15:58,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:58,342][root][INFO] - Training Epoch: 1/2, step 6612/7134 completed (loss: 0.4637354910373688, acc: 0.8820512890815735)
[2024-12-17 02:15:58,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:58,639][root][INFO] - Training Epoch: 1/2, step 6613/7134 completed (loss: 0.3050331771373749, acc: 0.9395973086357117)
[2024-12-17 02:15:58,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:58,909][root][INFO] - Training Epoch: 1/2, step 6614/7134 completed (loss: 0.2807680666446686, acc: 0.9340659379959106)
[2024-12-17 02:15:59,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:59,172][root][INFO] - Training Epoch: 1/2, step 6615/7134 completed (loss: 0.26194849610328674, acc: 0.9391891956329346)
[2024-12-17 02:15:59,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:59,452][root][INFO] - Training Epoch: 1/2, step 6616/7134 completed (loss: 0.37240955233573914, acc: 0.9090909361839294)
[2024-12-17 02:15:59,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:59,733][root][INFO] - Training Epoch: 1/2, step 6617/7134 completed (loss: 0.22736823558807373, acc: 0.9407407641410828)
[2024-12-17 02:15:59,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:59,986][root][INFO] - Training Epoch: 1/2, step 6618/7134 completed (loss: 0.12261317670345306, acc: 0.97826087474823)
[2024-12-17 02:16:00,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:00,277][root][INFO] - Training Epoch: 1/2, step 6619/7134 completed (loss: 0.20118094980716705, acc: 0.9548022747039795)
[2024-12-17 02:16:00,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:00,559][root][INFO] - Training Epoch: 1/2, step 6620/7134 completed (loss: 0.35114067792892456, acc: 0.9236111044883728)
[2024-12-17 02:16:00,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:00,830][root][INFO] - Training Epoch: 1/2, step 6621/7134 completed (loss: 0.27423399686813354, acc: 0.9257143139839172)
[2024-12-17 02:16:00,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:01,098][root][INFO] - Training Epoch: 1/2, step 6622/7134 completed (loss: 0.23009903728961945, acc: 0.942307710647583)
[2024-12-17 02:16:01,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:01,402][root][INFO] - Training Epoch: 1/2, step 6623/7134 completed (loss: 0.29371610283851624, acc: 0.910179615020752)
[2024-12-17 02:16:01,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:01,692][root][INFO] - Training Epoch: 1/2, step 6624/7134 completed (loss: 0.15367193520069122, acc: 0.9681528806686401)
[2024-12-17 02:16:01,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:01,970][root][INFO] - Training Epoch: 1/2, step 6625/7134 completed (loss: 0.09838881343603134, acc: 0.9801324605941772)
[2024-12-17 02:16:02,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:02,280][root][INFO] - Training Epoch: 1/2, step 6626/7134 completed (loss: 0.2591630518436432, acc: 0.9200000166893005)
[2024-12-17 02:16:02,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:02,600][root][INFO] - Training Epoch: 1/2, step 6627/7134 completed (loss: 0.22621744871139526, acc: 0.9301075339317322)
[2024-12-17 02:16:02,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:02,888][root][INFO] - Training Epoch: 1/2, step 6628/7134 completed (loss: 0.2653530240058899, acc: 0.9345238208770752)
[2024-12-17 02:16:02,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:03,144][root][INFO] - Training Epoch: 1/2, step 6629/7134 completed (loss: 0.42518267035484314, acc: 0.9437500238418579)
[2024-12-17 02:16:03,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:03,448][root][INFO] - Training Epoch: 1/2, step 6630/7134 completed (loss: 0.22512133419513702, acc: 0.9583333134651184)
[2024-12-17 02:16:03,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:03,734][root][INFO] - Training Epoch: 1/2, step 6631/7134 completed (loss: 0.12160841375589371, acc: 0.9813664555549622)
[2024-12-17 02:16:03,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:04,072][root][INFO] - Training Epoch: 1/2, step 6632/7134 completed (loss: 0.16921836137771606, acc: 0.9492385983467102)
[2024-12-17 02:16:04,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:04,358][root][INFO] - Training Epoch: 1/2, step 6633/7134 completed (loss: 0.21766377985477448, acc: 0.9615384340286255)
[2024-12-17 02:16:04,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:04,638][root][INFO] - Training Epoch: 1/2, step 6634/7134 completed (loss: 0.1912558525800705, acc: 0.932330846786499)
[2024-12-17 02:16:04,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:04,904][root][INFO] - Training Epoch: 1/2, step 6635/7134 completed (loss: 0.5281690359115601, acc: 0.8949999809265137)
[2024-12-17 02:16:05,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:05,186][root][INFO] - Training Epoch: 1/2, step 6636/7134 completed (loss: 0.3025900721549988, acc: 0.9219512343406677)
[2024-12-17 02:16:05,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:05,470][root][INFO] - Training Epoch: 1/2, step 6637/7134 completed (loss: 0.3235052227973938, acc: 0.925000011920929)
[2024-12-17 02:16:05,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:05,808][root][INFO] - Training Epoch: 1/2, step 6638/7134 completed (loss: 0.1719561368227005, acc: 0.9505494236946106)
[2024-12-17 02:16:05,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:06,095][root][INFO] - Training Epoch: 1/2, step 6639/7134 completed (loss: 0.5200493931770325, acc: 0.910179615020752)
[2024-12-17 02:16:06,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:06,386][root][INFO] - Training Epoch: 1/2, step 6640/7134 completed (loss: 0.1872478723526001, acc: 0.9617834687232971)
[2024-12-17 02:16:06,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:06,691][root][INFO] - Training Epoch: 1/2, step 6641/7134 completed (loss: 0.4840247929096222, acc: 0.9070796370506287)
[2024-12-17 02:16:06,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:07,008][root][INFO] - Training Epoch: 1/2, step 6642/7134 completed (loss: 0.3499707579612732, acc: 0.8975903391838074)
[2024-12-17 02:16:07,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:07,314][root][INFO] - Training Epoch: 1/2, step 6643/7134 completed (loss: 0.26750075817108154, acc: 0.9408602118492126)
[2024-12-17 02:16:07,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:07,610][root][INFO] - Training Epoch: 1/2, step 6644/7134 completed (loss: 0.3448014259338379, acc: 0.9170124530792236)
[2024-12-17 02:16:07,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:07,907][root][INFO] - Training Epoch: 1/2, step 6645/7134 completed (loss: 0.26087066531181335, acc: 0.9259259104728699)
[2024-12-17 02:16:08,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:08,202][root][INFO] - Training Epoch: 1/2, step 6646/7134 completed (loss: 0.3069864511489868, acc: 0.9213973879814148)
[2024-12-17 02:16:08,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:08,481][root][INFO] - Training Epoch: 1/2, step 6647/7134 completed (loss: 0.19964630901813507, acc: 0.9411764740943909)
[2024-12-17 02:16:08,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:08,778][root][INFO] - Training Epoch: 1/2, step 6648/7134 completed (loss: 0.24062366783618927, acc: 0.9354838728904724)
[2024-12-17 02:16:08,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:09,093][root][INFO] - Training Epoch: 1/2, step 6649/7134 completed (loss: 0.3374106287956238, acc: 0.9082125425338745)
[2024-12-17 02:16:09,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:09,425][root][INFO] - Training Epoch: 1/2, step 6650/7134 completed (loss: 0.2872496247291565, acc: 0.9272727370262146)
[2024-12-17 02:16:09,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:09,730][root][INFO] - Training Epoch: 1/2, step 6651/7134 completed (loss: 0.31431877613067627, acc: 0.9261363744735718)
[2024-12-17 02:16:09,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:10,018][root][INFO] - Training Epoch: 1/2, step 6652/7134 completed (loss: 0.4673588275909424, acc: 0.8921568393707275)
[2024-12-17 02:16:10,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:10,319][root][INFO] - Training Epoch: 1/2, step 6653/7134 completed (loss: 0.5555782914161682, acc: 0.8636363744735718)
[2024-12-17 02:16:10,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:10,608][root][INFO] - Training Epoch: 1/2, step 6654/7134 completed (loss: 0.4041292071342468, acc: 0.9113923907279968)
[2024-12-17 02:16:10,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:10,901][root][INFO] - Training Epoch: 1/2, step 6655/7134 completed (loss: 0.31923922896385193, acc: 0.9047619104385376)
[2024-12-17 02:16:11,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:11,170][root][INFO] - Training Epoch: 1/2, step 6656/7134 completed (loss: 0.38521406054496765, acc: 0.8947368264198303)
[2024-12-17 02:16:11,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:11,456][root][INFO] - Training Epoch: 1/2, step 6657/7134 completed (loss: 0.44473797082901, acc: 0.8776595592498779)
[2024-12-17 02:16:11,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:11,764][root][INFO] - Training Epoch: 1/2, step 6658/7134 completed (loss: 0.27733394503593445, acc: 0.9441624283790588)
[2024-12-17 02:16:11,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:12,065][root][INFO] - Training Epoch: 1/2, step 6659/7134 completed (loss: 0.2794831693172455, acc: 0.9234972596168518)
[2024-12-17 02:16:12,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:12,367][root][INFO] - Training Epoch: 1/2, step 6660/7134 completed (loss: 0.2030114084482193, acc: 0.9590163826942444)
[2024-12-17 02:16:12,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:12,694][root][INFO] - Training Epoch: 1/2, step 6661/7134 completed (loss: 0.471273273229599, acc: 0.8805969953536987)
[2024-12-17 02:16:12,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:12,990][root][INFO] - Training Epoch: 1/2, step 6662/7134 completed (loss: 0.46371257305145264, acc: 0.8705036044120789)
[2024-12-17 02:16:13,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:13,275][root][INFO] - Training Epoch: 1/2, step 6663/7134 completed (loss: 0.17328782379627228, acc: 0.9567099809646606)
[2024-12-17 02:16:13,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:13,550][root][INFO] - Training Epoch: 1/2, step 6664/7134 completed (loss: 0.7656952738761902, acc: 0.8357142806053162)
[2024-12-17 02:16:13,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:13,835][root][INFO] - Training Epoch: 1/2, step 6665/7134 completed (loss: 0.5558130145072937, acc: 0.8616352081298828)
[2024-12-17 02:16:13,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:14,129][root][INFO] - Training Epoch: 1/2, step 6666/7134 completed (loss: 0.18027986586093903, acc: 0.9696969985961914)
[2024-12-17 02:16:14,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:14,435][root][INFO] - Training Epoch: 1/2, step 6667/7134 completed (loss: 0.38883501291275024, acc: 0.8979591727256775)
[2024-12-17 02:16:14,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:14,723][root][INFO] - Training Epoch: 1/2, step 6668/7134 completed (loss: 0.12979543209075928, acc: 0.9489051103591919)
[2024-12-17 02:16:14,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:14,984][root][INFO] - Training Epoch: 1/2, step 6669/7134 completed (loss: 0.18064731359481812, acc: 0.9722222089767456)
[2024-12-17 02:16:15,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:15,245][root][INFO] - Training Epoch: 1/2, step 6670/7134 completed (loss: 0.18268385529518127, acc: 0.9496402740478516)
[2024-12-17 02:16:15,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:15,541][root][INFO] - Training Epoch: 1/2, step 6671/7134 completed (loss: 0.20093980431556702, acc: 0.9451219439506531)
[2024-12-17 02:16:15,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:15,828][root][INFO] - Training Epoch: 1/2, step 6672/7134 completed (loss: 0.17303475737571716, acc: 0.9359999895095825)
[2024-12-17 02:16:15,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:16,116][root][INFO] - Training Epoch: 1/2, step 6673/7134 completed (loss: 0.1730768084526062, acc: 0.9433962106704712)
[2024-12-17 02:16:16,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:16,392][root][INFO] - Training Epoch: 1/2, step 6674/7134 completed (loss: 0.13584770262241364, acc: 0.9661017060279846)
[2024-12-17 02:16:16,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:16,704][root][INFO] - Training Epoch: 1/2, step 6675/7134 completed (loss: 0.2653551697731018, acc: 0.9411764740943909)
[2024-12-17 02:16:16,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:17,025][root][INFO] - Training Epoch: 1/2, step 6676/7134 completed (loss: 0.11719314754009247, acc: 0.9599999785423279)
[2024-12-17 02:16:17,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:17,315][root][INFO] - Training Epoch: 1/2, step 6677/7134 completed (loss: 0.1909872144460678, acc: 0.9694656729698181)
[2024-12-17 02:16:17,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:17,611][root][INFO] - Training Epoch: 1/2, step 6678/7134 completed (loss: 0.15451861917972565, acc: 0.9555555582046509)
[2024-12-17 02:16:17,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:17,911][root][INFO] - Training Epoch: 1/2, step 6679/7134 completed (loss: 0.29523804783821106, acc: 0.9557521939277649)
[2024-12-17 02:16:18,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:18,176][root][INFO] - Training Epoch: 1/2, step 6680/7134 completed (loss: 0.14221176505088806, acc: 0.977011501789093)
[2024-12-17 02:16:18,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:18,466][root][INFO] - Training Epoch: 1/2, step 6681/7134 completed (loss: 0.07962033152580261, acc: 0.9765625)
[2024-12-17 02:16:18,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:18,748][root][INFO] - Training Epoch: 1/2, step 6682/7134 completed (loss: 0.3323240578174591, acc: 0.9514563083648682)
[2024-12-17 02:16:18,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:19,022][root][INFO] - Training Epoch: 1/2, step 6683/7134 completed (loss: 0.4059763550758362, acc: 0.9425287246704102)
[2024-12-17 02:16:19,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:19,316][root][INFO] - Training Epoch: 1/2, step 6684/7134 completed (loss: 0.2507307231426239, acc: 0.960629940032959)
[2024-12-17 02:16:19,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:19,593][root][INFO] - Training Epoch: 1/2, step 6685/7134 completed (loss: 0.339290976524353, acc: 0.9359999895095825)
[2024-12-17 02:16:19,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:19,880][root][INFO] - Training Epoch: 1/2, step 6686/7134 completed (loss: 0.34938544034957886, acc: 0.9137930870056152)
[2024-12-17 02:16:20,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:20,160][root][INFO] - Training Epoch: 1/2, step 6687/7134 completed (loss: 0.28906548023223877, acc: 0.9418604373931885)
[2024-12-17 02:16:20,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:20,467][root][INFO] - Training Epoch: 1/2, step 6688/7134 completed (loss: 0.5227963924407959, acc: 0.8489208817481995)
[2024-12-17 02:16:20,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:20,750][root][INFO] - Training Epoch: 1/2, step 6689/7134 completed (loss: 0.43059590458869934, acc: 0.8703703880310059)
[2024-12-17 02:16:20,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:21,025][root][INFO] - Training Epoch: 1/2, step 6690/7134 completed (loss: 0.6214362382888794, acc: 0.8333333134651184)
[2024-12-17 02:16:21,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:21,309][root][INFO] - Training Epoch: 1/2, step 6691/7134 completed (loss: 0.23172889649868011, acc: 0.9444444179534912)
[2024-12-17 02:16:21,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:21,565][root][INFO] - Training Epoch: 1/2, step 6692/7134 completed (loss: 0.5101081728935242, acc: 0.8785046935081482)
[2024-12-17 02:16:21,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:21,854][root][INFO] - Training Epoch: 1/2, step 6693/7134 completed (loss: 0.3580753207206726, acc: 0.9185185432434082)
[2024-12-17 02:16:21,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:22,138][root][INFO] - Training Epoch: 1/2, step 6694/7134 completed (loss: 0.31252995133399963, acc: 0.9205297827720642)
[2024-12-17 02:16:22,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:22,421][root][INFO] - Training Epoch: 1/2, step 6695/7134 completed (loss: 0.2539459466934204, acc: 0.9147727489471436)
[2024-12-17 02:16:22,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:22,705][root][INFO] - Training Epoch: 1/2, step 6696/7134 completed (loss: 0.340276837348938, acc: 0.9027777910232544)
[2024-12-17 02:16:22,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:22,990][root][INFO] - Training Epoch: 1/2, step 6697/7134 completed (loss: 0.49736201763153076, acc: 0.8642857074737549)
[2024-12-17 02:16:23,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:23,261][root][INFO] - Training Epoch: 1/2, step 6698/7134 completed (loss: 0.36608102917671204, acc: 0.926174521446228)
[2024-12-17 02:16:23,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:23,561][root][INFO] - Training Epoch: 1/2, step 6699/7134 completed (loss: 0.2880497872829437, acc: 0.9238095283508301)
[2024-12-17 02:16:23,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:23,856][root][INFO] - Training Epoch: 1/2, step 6700/7134 completed (loss: 0.6033027768135071, acc: 0.8370370268821716)
[2024-12-17 02:16:23,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:24,125][root][INFO] - Training Epoch: 1/2, step 6701/7134 completed (loss: 0.6927725672721863, acc: 0.8358209133148193)
[2024-12-17 02:16:24,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:24,389][root][INFO] - Training Epoch: 1/2, step 6702/7134 completed (loss: 0.38942548632621765, acc: 0.904347836971283)
[2024-12-17 02:16:24,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:24,662][root][INFO] - Training Epoch: 1/2, step 6703/7134 completed (loss: 0.3971637487411499, acc: 0.9202898740768433)
[2024-12-17 02:16:24,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:24,941][root][INFO] - Training Epoch: 1/2, step 6704/7134 completed (loss: 0.5085726976394653, acc: 0.8793103694915771)
[2024-12-17 02:16:25,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:25,234][root][INFO] - Training Epoch: 1/2, step 6705/7134 completed (loss: 0.26483455300331116, acc: 0.9190751314163208)
[2024-12-17 02:16:25,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:25,517][root][INFO] - Training Epoch: 1/2, step 6706/7134 completed (loss: 0.1847320944070816, acc: 0.9636363387107849)
[2024-12-17 02:16:25,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:25,795][root][INFO] - Training Epoch: 1/2, step 6707/7134 completed (loss: 0.22888317704200745, acc: 0.9316239356994629)
[2024-12-17 02:16:25,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:26,101][root][INFO] - Training Epoch: 1/2, step 6708/7134 completed (loss: 0.43871501088142395, acc: 0.8931297659873962)
[2024-12-17 02:16:26,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:26,459][root][INFO] - Training Epoch: 1/2, step 6709/7134 completed (loss: 0.33517107367515564, acc: 0.9207317233085632)
[2024-12-17 02:16:26,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:26,750][root][INFO] - Training Epoch: 1/2, step 6710/7134 completed (loss: 0.4552217423915863, acc: 0.902255654335022)
[2024-12-17 02:16:26,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:27,040][root][INFO] - Training Epoch: 1/2, step 6711/7134 completed (loss: 0.21628987789154053, acc: 0.9556962251663208)
[2024-12-17 02:16:27,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:27,319][root][INFO] - Training Epoch: 1/2, step 6712/7134 completed (loss: 0.46009159088134766, acc: 0.8965517282485962)
[2024-12-17 02:16:27,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:27,668][root][INFO] - Training Epoch: 1/2, step 6713/7134 completed (loss: 0.48150232434272766, acc: 0.89570552110672)
[2024-12-17 02:16:27,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:27,957][root][INFO] - Training Epoch: 1/2, step 6714/7134 completed (loss: 0.37461036443710327, acc: 0.8959537744522095)
[2024-12-17 02:16:28,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:28,236][root][INFO] - Training Epoch: 1/2, step 6715/7134 completed (loss: 0.5587616562843323, acc: 0.8918918967247009)
[2024-12-17 02:16:28,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:28,514][root][INFO] - Training Epoch: 1/2, step 6716/7134 completed (loss: 0.2646561563014984, acc: 0.931506872177124)
[2024-12-17 02:16:28,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:28,783][root][INFO] - Training Epoch: 1/2, step 6717/7134 completed (loss: 0.42357298731803894, acc: 0.8918918967247009)
[2024-12-17 02:16:28,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:29,055][root][INFO] - Training Epoch: 1/2, step 6718/7134 completed (loss: 0.32045263051986694, acc: 0.931034505367279)
[2024-12-17 02:16:29,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:29,322][root][INFO] - Training Epoch: 1/2, step 6719/7134 completed (loss: 0.2959662079811096, acc: 0.926174521446228)
[2024-12-17 02:16:29,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:29,598][root][INFO] - Training Epoch: 1/2, step 6720/7134 completed (loss: 0.4776342511177063, acc: 0.9022988677024841)
[2024-12-17 02:16:29,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:29,852][root][INFO] - Training Epoch: 1/2, step 6721/7134 completed (loss: 0.5080433487892151, acc: 0.8917197585105896)
[2024-12-17 02:16:29,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:30,088][root][INFO] - Training Epoch: 1/2, step 6722/7134 completed (loss: 0.5852032899856567, acc: 0.867132842540741)
[2024-12-17 02:16:30,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:30,373][root][INFO] - Training Epoch: 1/2, step 6723/7134 completed (loss: 0.2000308781862259, acc: 0.9398906826972961)
[2024-12-17 02:16:30,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:30,648][root][INFO] - Training Epoch: 1/2, step 6724/7134 completed (loss: 0.32213401794433594, acc: 0.9371069073677063)
[2024-12-17 02:16:30,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:30,898][root][INFO] - Training Epoch: 1/2, step 6725/7134 completed (loss: 0.34918490052223206, acc: 0.9276315569877625)
[2024-12-17 02:16:30,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:31,146][root][INFO] - Training Epoch: 1/2, step 6726/7134 completed (loss: 0.40602490305900574, acc: 0.9173553586006165)
[2024-12-17 02:16:31,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:31,429][root][INFO] - Training Epoch: 1/2, step 6727/7134 completed (loss: 0.33670511841773987, acc: 0.8992805480957031)
[2024-12-17 02:16:31,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:31,711][root][INFO] - Training Epoch: 1/2, step 6728/7134 completed (loss: 0.43167349696159363, acc: 0.8838709592819214)
[2024-12-17 02:16:31,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:31,996][root][INFO] - Training Epoch: 1/2, step 6729/7134 completed (loss: 0.22019821405410767, acc: 0.9367088675498962)
[2024-12-17 02:16:32,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:32,292][root][INFO] - Training Epoch: 1/2, step 6730/7134 completed (loss: 0.37328335642814636, acc: 0.8965517282485962)
[2024-12-17 02:16:32,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:32,590][root][INFO] - Training Epoch: 1/2, step 6731/7134 completed (loss: 0.3324624300003052, acc: 0.9216867685317993)
[2024-12-17 02:16:32,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:32,866][root][INFO] - Training Epoch: 1/2, step 6732/7134 completed (loss: 0.214035302400589, acc: 0.9358974099159241)
[2024-12-17 02:16:32,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:33,127][root][INFO] - Training Epoch: 1/2, step 6733/7134 completed (loss: 0.1832299530506134, acc: 0.9568345546722412)
[2024-12-17 02:16:33,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:33,396][root][INFO] - Training Epoch: 1/2, step 6734/7134 completed (loss: 0.3475660979747772, acc: 0.9370629191398621)
[2024-12-17 02:16:33,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:33,663][root][INFO] - Training Epoch: 1/2, step 6735/7134 completed (loss: 0.40488630533218384, acc: 0.8974359035491943)
[2024-12-17 02:16:33,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:33,959][root][INFO] - Training Epoch: 1/2, step 6736/7134 completed (loss: 0.30816712975502014, acc: 0.9111111164093018)
[2024-12-17 02:16:34,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:34,252][root][INFO] - Training Epoch: 1/2, step 6737/7134 completed (loss: 0.5420289039611816, acc: 0.8807947039604187)
[2024-12-17 02:16:34,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:34,527][root][INFO] - Training Epoch: 1/2, step 6738/7134 completed (loss: 0.2533891201019287, acc: 0.9338235259056091)
[2024-12-17 02:16:34,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:34,770][root][INFO] - Training Epoch: 1/2, step 6739/7134 completed (loss: 0.29971587657928467, acc: 0.9214285612106323)
[2024-12-17 02:16:34,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:35,053][root][INFO] - Training Epoch: 1/2, step 6740/7134 completed (loss: 0.3057391047477722, acc: 0.9189189076423645)
[2024-12-17 02:16:35,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:35,320][root][INFO] - Training Epoch: 1/2, step 6741/7134 completed (loss: 0.11631319671869278, acc: 0.9638554453849792)
[2024-12-17 02:16:35,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:35,568][root][INFO] - Training Epoch: 1/2, step 6742/7134 completed (loss: 0.1244283989071846, acc: 0.9647058844566345)
[2024-12-17 02:16:35,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:35,862][root][INFO] - Training Epoch: 1/2, step 6743/7134 completed (loss: 0.09476586431264877, acc: 0.9774011373519897)
[2024-12-17 02:16:35,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:36,139][root][INFO] - Training Epoch: 1/2, step 6744/7134 completed (loss: 0.09592301398515701, acc: 0.9662162065505981)
[2024-12-17 02:16:36,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:36,413][root][INFO] - Training Epoch: 1/2, step 6745/7134 completed (loss: 0.06937697529792786, acc: 0.9825581312179565)
[2024-12-17 02:16:36,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:36,668][root][INFO] - Training Epoch: 1/2, step 6746/7134 completed (loss: 0.1759488731622696, acc: 0.9776119589805603)
[2024-12-17 02:16:36,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:36,941][root][INFO] - Training Epoch: 1/2, step 6747/7134 completed (loss: 0.15104348957538605, acc: 0.9581151604652405)
[2024-12-17 02:16:37,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:37,230][root][INFO] - Training Epoch: 1/2, step 6748/7134 completed (loss: 0.14149844646453857, acc: 0.970588207244873)
[2024-12-17 02:16:37,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:37,532][root][INFO] - Training Epoch: 1/2, step 6749/7134 completed (loss: 0.1917475312948227, acc: 0.9555555582046509)
[2024-12-17 02:16:37,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:37,818][root][INFO] - Training Epoch: 1/2, step 6750/7134 completed (loss: 0.23659303784370422, acc: 0.9504950642585754)
[2024-12-17 02:16:37,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:38,114][root][INFO] - Training Epoch: 1/2, step 6751/7134 completed (loss: 0.13692007958889008, acc: 0.9701492786407471)
[2024-12-17 02:16:38,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:38,391][root][INFO] - Training Epoch: 1/2, step 6752/7134 completed (loss: 0.17726989090442657, acc: 0.9631901979446411)
[2024-12-17 02:16:38,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:38,673][root][INFO] - Training Epoch: 1/2, step 6753/7134 completed (loss: 0.12228745222091675, acc: 0.9696969985961914)
[2024-12-17 02:16:38,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:38,933][root][INFO] - Training Epoch: 1/2, step 6754/7134 completed (loss: 0.14058682322502136, acc: 0.9528796076774597)
[2024-12-17 02:16:39,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:39,215][root][INFO] - Training Epoch: 1/2, step 6755/7134 completed (loss: 0.3120461404323578, acc: 0.9371727705001831)
[2024-12-17 02:16:39,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:39,489][root][INFO] - Training Epoch: 1/2, step 6756/7134 completed (loss: 0.048213813453912735, acc: 0.9887640476226807)
[2024-12-17 02:16:39,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:39,823][root][INFO] - Training Epoch: 1/2, step 6757/7134 completed (loss: 0.09170695394277573, acc: 0.9741935729980469)
[2024-12-17 02:16:39,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:40,138][root][INFO] - Training Epoch: 1/2, step 6758/7134 completed (loss: 0.14087192714214325, acc: 0.9896373152732849)
[2024-12-17 02:16:40,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:40,426][root][INFO] - Training Epoch: 1/2, step 6759/7134 completed (loss: 0.13591034710407257, acc: 0.9776785969734192)
[2024-12-17 02:16:40,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:40,712][root][INFO] - Training Epoch: 1/2, step 6760/7134 completed (loss: 0.27785876393318176, acc: 0.9627659320831299)
[2024-12-17 02:16:40,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:40,988][root][INFO] - Training Epoch: 1/2, step 6761/7134 completed (loss: 0.27260270714759827, acc: 0.9428571462631226)
[2024-12-17 02:16:41,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:41,275][root][INFO] - Training Epoch: 1/2, step 6762/7134 completed (loss: 0.1264609843492508, acc: 0.949999988079071)
[2024-12-17 02:16:41,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:41,564][root][INFO] - Training Epoch: 1/2, step 6763/7134 completed (loss: 0.15677951276302338, acc: 0.9732620120048523)
[2024-12-17 02:16:41,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:41,871][root][INFO] - Training Epoch: 1/2, step 6764/7134 completed (loss: 0.11219116300344467, acc: 0.9647058844566345)
[2024-12-17 02:16:42,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:42,168][root][INFO] - Training Epoch: 1/2, step 6765/7134 completed (loss: 0.09379324316978455, acc: 0.9670329689979553)
[2024-12-17 02:16:42,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:42,439][root][INFO] - Training Epoch: 1/2, step 6766/7134 completed (loss: 0.1580895632505417, acc: 0.9657142758369446)
[2024-12-17 02:16:42,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:42,649][root][INFO] - Training Epoch: 1/2, step 6767/7134 completed (loss: 0.19748400151729584, acc: 0.9285714030265808)
[2024-12-17 02:16:42,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:42,927][root][INFO] - Training Epoch: 1/2, step 6768/7134 completed (loss: 0.08053865283727646, acc: 0.9841269850730896)
[2024-12-17 02:16:43,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:43,199][root][INFO] - Training Epoch: 1/2, step 6769/7134 completed (loss: 0.43817663192749023, acc: 0.8846153616905212)
[2024-12-17 02:16:43,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:43,489][root][INFO] - Training Epoch: 1/2, step 6770/7134 completed (loss: 0.33377382159233093, acc: 0.8999999761581421)
[2024-12-17 02:16:43,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:43,786][root][INFO] - Training Epoch: 1/2, step 6771/7134 completed (loss: 0.1823767125606537, acc: 0.9707602262496948)
[2024-12-17 02:16:43,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:44,082][root][INFO] - Training Epoch: 1/2, step 6772/7134 completed (loss: 0.5415858626365662, acc: 0.9160839319229126)
[2024-12-17 02:16:44,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:44,345][root][INFO] - Training Epoch: 1/2, step 6773/7134 completed (loss: 0.4436521530151367, acc: 0.895061731338501)
[2024-12-17 02:16:44,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:44,630][root][INFO] - Training Epoch: 1/2, step 6774/7134 completed (loss: 0.508152186870575, acc: 0.88165682554245)
[2024-12-17 02:16:44,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:44,903][root][INFO] - Training Epoch: 1/2, step 6775/7134 completed (loss: 0.3635385036468506, acc: 0.9172413945198059)
[2024-12-17 02:16:44,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:45,182][root][INFO] - Training Epoch: 1/2, step 6776/7134 completed (loss: 0.26603150367736816, acc: 0.9520000219345093)
[2024-12-17 02:16:45,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:45,453][root][INFO] - Training Epoch: 1/2, step 6777/7134 completed (loss: 0.28980234265327454, acc: 0.9428571462631226)
[2024-12-17 02:16:45,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:45,739][root][INFO] - Training Epoch: 1/2, step 6778/7134 completed (loss: 0.14607225358486176, acc: 0.9772727489471436)
[2024-12-17 02:16:45,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:46,009][root][INFO] - Training Epoch: 1/2, step 6779/7134 completed (loss: 0.20024001598358154, acc: 0.9583333134651184)
[2024-12-17 02:16:46,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:46,292][root][INFO] - Training Epoch: 1/2, step 6780/7134 completed (loss: 0.07835736125707626, acc: 0.9820359349250793)
[2024-12-17 02:16:46,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:46,580][root][INFO] - Training Epoch: 1/2, step 6781/7134 completed (loss: 0.11289291828870773, acc: 0.9707602262496948)
[2024-12-17 02:16:46,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:46,859][root][INFO] - Training Epoch: 1/2, step 6782/7134 completed (loss: 0.15663626790046692, acc: 0.9548386931419373)
[2024-12-17 02:16:46,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:47,116][root][INFO] - Training Epoch: 1/2, step 6783/7134 completed (loss: 0.19384075701236725, acc: 0.9655172228813171)
[2024-12-17 02:16:47,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:47,385][root][INFO] - Training Epoch: 1/2, step 6784/7134 completed (loss: 0.10692189633846283, acc: 0.9746835231781006)
[2024-12-17 02:16:47,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:47,667][root][INFO] - Training Epoch: 1/2, step 6785/7134 completed (loss: 0.10010858625173569, acc: 0.9673202633857727)
[2024-12-17 02:16:47,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:47,976][root][INFO] - Training Epoch: 1/2, step 6786/7134 completed (loss: 0.0906204804778099, acc: 0.9717513918876648)
[2024-12-17 02:16:48,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:48,291][root][INFO] - Training Epoch: 1/2, step 6787/7134 completed (loss: 0.2136957198381424, acc: 0.9562841653823853)
[2024-12-17 02:16:48,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:48,577][root][INFO] - Training Epoch: 1/2, step 6788/7134 completed (loss: 0.16440124809741974, acc: 0.9640287756919861)
[2024-12-17 02:16:48,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:48,860][root][INFO] - Training Epoch: 1/2, step 6789/7134 completed (loss: 0.1442878544330597, acc: 0.9645389914512634)
[2024-12-17 02:16:49,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:49,190][root][INFO] - Training Epoch: 1/2, step 6790/7134 completed (loss: 0.2770645320415497, acc: 0.9488636255264282)
[2024-12-17 02:16:49,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:49,471][root][INFO] - Training Epoch: 1/2, step 6791/7134 completed (loss: 0.13398441672325134, acc: 0.9743589758872986)
[2024-12-17 02:16:49,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:49,754][root][INFO] - Training Epoch: 1/2, step 6792/7134 completed (loss: 0.15055646002292633, acc: 0.9626865386962891)
[2024-12-17 02:16:49,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:50,041][root][INFO] - Training Epoch: 1/2, step 6793/7134 completed (loss: 0.1850440353155136, acc: 0.9561403393745422)
[2024-12-17 02:16:50,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:50,326][root][INFO] - Training Epoch: 1/2, step 6794/7134 completed (loss: 0.180787593126297, acc: 0.9523809552192688)
[2024-12-17 02:16:50,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:50,598][root][INFO] - Training Epoch: 1/2, step 6795/7134 completed (loss: 0.1459270864725113, acc: 0.9599999785423279)
[2024-12-17 02:16:50,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:50,877][root][INFO] - Training Epoch: 1/2, step 6796/7134 completed (loss: 0.0885503813624382, acc: 0.9709302186965942)
[2024-12-17 02:16:50,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:51,163][root][INFO] - Training Epoch: 1/2, step 6797/7134 completed (loss: 0.32161128520965576, acc: 0.9085366129875183)
[2024-12-17 02:16:51,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:51,434][root][INFO] - Training Epoch: 1/2, step 6798/7134 completed (loss: 0.20960116386413574, acc: 0.9457831382751465)
[2024-12-17 02:16:51,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:51,712][root][INFO] - Training Epoch: 1/2, step 6799/7134 completed (loss: 0.15343821048736572, acc: 0.9520958065986633)
[2024-12-17 02:16:51,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:51,979][root][INFO] - Training Epoch: 1/2, step 6800/7134 completed (loss: 0.27496305108070374, acc: 0.9303797483444214)
[2024-12-17 02:16:52,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:52,260][root][INFO] - Training Epoch: 1/2, step 6801/7134 completed (loss: 0.24080641567707062, acc: 0.9424460530281067)
[2024-12-17 02:16:52,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:52,530][root][INFO] - Training Epoch: 1/2, step 6802/7134 completed (loss: 0.18858219683170319, acc: 0.9510489702224731)
[2024-12-17 02:16:52,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:52,811][root][INFO] - Training Epoch: 1/2, step 6803/7134 completed (loss: 0.26426464319229126, acc: 0.9388889074325562)
[2024-12-17 02:16:52,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:53,088][root][INFO] - Training Epoch: 1/2, step 6804/7134 completed (loss: 0.31742018461227417, acc: 0.9395973086357117)
[2024-12-17 02:16:53,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:53,370][root][INFO] - Training Epoch: 1/2, step 6805/7134 completed (loss: 0.3286533057689667, acc: 0.9259259104728699)
[2024-12-17 02:16:53,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:53,645][root][INFO] - Training Epoch: 1/2, step 6806/7134 completed (loss: 0.19440948963165283, acc: 0.932584285736084)
[2024-12-17 02:16:53,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:53,935][root][INFO] - Training Epoch: 1/2, step 6807/7134 completed (loss: 0.23528464138507843, acc: 0.956250011920929)
[2024-12-17 02:16:54,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:54,215][root][INFO] - Training Epoch: 1/2, step 6808/7134 completed (loss: 0.27320396900177, acc: 0.9127516746520996)
[2024-12-17 02:16:54,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:54,509][root][INFO] - Training Epoch: 1/2, step 6809/7134 completed (loss: 0.27363526821136475, acc: 0.9615384340286255)
[2024-12-17 02:16:54,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:54,791][root][INFO] - Training Epoch: 1/2, step 6810/7134 completed (loss: 0.13093747198581696, acc: 0.9772727489471436)
[2024-12-17 02:16:54,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:55,083][root][INFO] - Training Epoch: 1/2, step 6811/7134 completed (loss: 0.18189376592636108, acc: 0.9593023061752319)
[2024-12-17 02:16:55,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:55,363][root][INFO] - Training Epoch: 1/2, step 6812/7134 completed (loss: 0.17954108119010925, acc: 0.9333333373069763)
[2024-12-17 02:16:55,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:55,642][root][INFO] - Training Epoch: 1/2, step 6813/7134 completed (loss: 0.12793822586536407, acc: 0.96875)
[2024-12-17 02:16:55,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:55,926][root][INFO] - Training Epoch: 1/2, step 6814/7134 completed (loss: 0.11218439042568207, acc: 0.9828571677207947)
[2024-12-17 02:16:56,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:56,224][root][INFO] - Training Epoch: 1/2, step 6815/7134 completed (loss: 0.0926474928855896, acc: 0.9941176176071167)
[2024-12-17 02:16:56,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:56,511][root][INFO] - Training Epoch: 1/2, step 6816/7134 completed (loss: 0.18624848127365112, acc: 0.9652777910232544)
[2024-12-17 02:16:56,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:56,801][root][INFO] - Training Epoch: 1/2, step 6817/7134 completed (loss: 0.4054665267467499, acc: 0.908450722694397)
[2024-12-17 02:16:56,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:57,093][root][INFO] - Training Epoch: 1/2, step 6818/7134 completed (loss: 0.1273972988128662, acc: 0.9727891087532043)
[2024-12-17 02:16:57,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:57,385][root][INFO] - Training Epoch: 1/2, step 6819/7134 completed (loss: 0.18320192396640778, acc: 0.9635036587715149)
[2024-12-17 02:16:57,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:57,666][root][INFO] - Training Epoch: 1/2, step 6820/7134 completed (loss: 0.22219762206077576, acc: 0.9416058659553528)
[2024-12-17 02:16:57,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:57,914][root][INFO] - Training Epoch: 1/2, step 6821/7134 completed (loss: 0.07885561138391495, acc: 0.9818181991577148)
[2024-12-17 02:16:58,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:58,195][root][INFO] - Training Epoch: 1/2, step 6822/7134 completed (loss: 0.41434767842292786, acc: 0.8992248177528381)
[2024-12-17 02:16:58,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:58,475][root][INFO] - Training Epoch: 1/2, step 6823/7134 completed (loss: 0.20755720138549805, acc: 0.9397590160369873)
[2024-12-17 02:16:58,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:58,734][root][INFO] - Training Epoch: 1/2, step 6824/7134 completed (loss: 0.46656182408332825, acc: 0.8536585569381714)
[2024-12-17 02:16:58,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:58,996][root][INFO] - Training Epoch: 1/2, step 6825/7134 completed (loss: 0.26216253638267517, acc: 0.9354838728904724)
[2024-12-17 02:16:59,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:59,262][root][INFO] - Training Epoch: 1/2, step 6826/7134 completed (loss: 0.34738022089004517, acc: 0.9130434989929199)
[2024-12-17 02:16:59,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:59,555][root][INFO] - Training Epoch: 1/2, step 6827/7134 completed (loss: 0.5336758494377136, acc: 0.8697916865348816)
[2024-12-17 02:16:59,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:59,842][root][INFO] - Training Epoch: 1/2, step 6828/7134 completed (loss: 0.7012103796005249, acc: 0.8591549396514893)
[2024-12-17 02:16:59,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:00,127][root][INFO] - Training Epoch: 1/2, step 6829/7134 completed (loss: 0.4368115961551666, acc: 0.8934911489486694)
[2024-12-17 02:17:00,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:00,393][root][INFO] - Training Epoch: 1/2, step 6830/7134 completed (loss: 0.277128130197525, acc: 0.9324324131011963)
[2024-12-17 02:17:00,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:00,675][root][INFO] - Training Epoch: 1/2, step 6831/7134 completed (loss: 0.3902810513973236, acc: 0.8882681727409363)
[2024-12-17 02:17:00,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:00,954][root][INFO] - Training Epoch: 1/2, step 6832/7134 completed (loss: 0.326504111289978, acc: 0.8958333134651184)
[2024-12-17 02:17:01,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:01,224][root][INFO] - Training Epoch: 1/2, step 6833/7134 completed (loss: 0.24414119124412537, acc: 0.9235668778419495)
[2024-12-17 02:17:01,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:01,477][root][INFO] - Training Epoch: 1/2, step 6834/7134 completed (loss: 0.40892648696899414, acc: 0.926174521446228)
[2024-12-17 02:17:01,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:01,746][root][INFO] - Training Epoch: 1/2, step 6835/7134 completed (loss: 0.3297763466835022, acc: 0.9411764740943909)
[2024-12-17 02:17:01,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:02,012][root][INFO] - Training Epoch: 1/2, step 6836/7134 completed (loss: 0.2855053246021271, acc: 0.8957346081733704)
[2024-12-17 02:17:02,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:02,298][root][INFO] - Training Epoch: 1/2, step 6837/7134 completed (loss: 0.26676684617996216, acc: 0.9494949579238892)
[2024-12-17 02:17:02,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:02,572][root][INFO] - Training Epoch: 1/2, step 6838/7134 completed (loss: 0.44924038648605347, acc: 0.9156626462936401)
[2024-12-17 02:17:02,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:02,832][root][INFO] - Training Epoch: 1/2, step 6839/7134 completed (loss: 0.7598204612731934, acc: 0.8266666531562805)
[2024-12-17 02:17:02,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:03,104][root][INFO] - Training Epoch: 1/2, step 6840/7134 completed (loss: 0.5001624226570129, acc: 0.8980891704559326)
[2024-12-17 02:17:03,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:03,368][root][INFO] - Training Epoch: 1/2, step 6841/7134 completed (loss: 0.3430531322956085, acc: 0.9207317233085632)
[2024-12-17 02:17:03,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:03,656][root][INFO] - Training Epoch: 1/2, step 6842/7134 completed (loss: 0.4458332657814026, acc: 0.901098906993866)
[2024-12-17 02:17:03,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:03,949][root][INFO] - Training Epoch: 1/2, step 6843/7134 completed (loss: 0.3344120681285858, acc: 0.9119170904159546)
[2024-12-17 02:17:04,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:04,225][root][INFO] - Training Epoch: 1/2, step 6844/7134 completed (loss: 0.5831388831138611, acc: 0.8523489832878113)
[2024-12-17 02:17:04,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:04,512][root][INFO] - Training Epoch: 1/2, step 6845/7134 completed (loss: 0.2792728543281555, acc: 0.9307692050933838)
[2024-12-17 02:17:04,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:04,791][root][INFO] - Training Epoch: 1/2, step 6846/7134 completed (loss: 0.45889583230018616, acc: 0.9012345671653748)
[2024-12-17 02:17:04,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:05,080][root][INFO] - Training Epoch: 1/2, step 6847/7134 completed (loss: 0.4274914860725403, acc: 0.875)
[2024-12-17 02:17:05,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:05,343][root][INFO] - Training Epoch: 1/2, step 6848/7134 completed (loss: 0.3919016420841217, acc: 0.898876428604126)
[2024-12-17 02:17:05,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:05,634][root][INFO] - Training Epoch: 1/2, step 6849/7134 completed (loss: 0.3382951617240906, acc: 0.9285714030265808)
[2024-12-17 02:17:05,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:05,906][root][INFO] - Training Epoch: 1/2, step 6850/7134 completed (loss: 0.41920799016952515, acc: 0.8761904835700989)
[2024-12-17 02:17:06,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:06,195][root][INFO] - Training Epoch: 1/2, step 6851/7134 completed (loss: 0.37712618708610535, acc: 0.9337016344070435)
[2024-12-17 02:17:06,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:06,474][root][INFO] - Training Epoch: 1/2, step 6852/7134 completed (loss: 0.3609867990016937, acc: 0.9142857193946838)
[2024-12-17 02:17:06,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:06,774][root][INFO] - Training Epoch: 1/2, step 6853/7134 completed (loss: 0.3505306839942932, acc: 0.9017341136932373)
[2024-12-17 02:17:06,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:07,032][root][INFO] - Training Epoch: 1/2, step 6854/7134 completed (loss: 0.3187654912471771, acc: 0.9237288236618042)
[2024-12-17 02:17:07,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:07,311][root][INFO] - Training Epoch: 1/2, step 6855/7134 completed (loss: 0.1519666314125061, acc: 0.9439252614974976)
[2024-12-17 02:17:07,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:07,588][root][INFO] - Training Epoch: 1/2, step 6856/7134 completed (loss: 0.06575476378202438, acc: 0.9879518151283264)
[2024-12-17 02:17:07,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:07,880][root][INFO] - Training Epoch: 1/2, step 6857/7134 completed (loss: 0.1226608157157898, acc: 0.9702380895614624)
[2024-12-17 02:17:08,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:08,140][root][INFO] - Training Epoch: 1/2, step 6858/7134 completed (loss: 0.11266065388917923, acc: 0.9848484992980957)
[2024-12-17 02:17:08,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:08,428][root][INFO] - Training Epoch: 1/2, step 6859/7134 completed (loss: 0.09022431820631027, acc: 0.9719101190567017)
[2024-12-17 02:17:08,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:08,710][root][INFO] - Training Epoch: 1/2, step 6860/7134 completed (loss: 0.1392223834991455, acc: 0.951724112033844)
[2024-12-17 02:17:08,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:08,976][root][INFO] - Training Epoch: 1/2, step 6861/7134 completed (loss: 0.07145453244447708, acc: 0.9790209531784058)
[2024-12-17 02:17:09,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:09,266][root][INFO] - Training Epoch: 1/2, step 6862/7134 completed (loss: 0.14809371531009674, acc: 0.9848484992980957)
[2024-12-17 02:17:09,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:09,539][root][INFO] - Training Epoch: 1/2, step 6863/7134 completed (loss: 0.1430588811635971, acc: 0.9647058844566345)
[2024-12-17 02:17:09,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:09,820][root][INFO] - Training Epoch: 1/2, step 6864/7134 completed (loss: 0.08521285653114319, acc: 0.9858155846595764)
[2024-12-17 02:17:09,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:10,097][root][INFO] - Training Epoch: 1/2, step 6865/7134 completed (loss: 0.17727969586849213, acc: 0.9593495726585388)
[2024-12-17 02:17:10,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:10,360][root][INFO] - Training Epoch: 1/2, step 6866/7134 completed (loss: 0.09173128008842468, acc: 0.9803921580314636)
[2024-12-17 02:17:10,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:10,633][root][INFO] - Training Epoch: 1/2, step 6867/7134 completed (loss: 0.029346801340579987, acc: 0.9924812316894531)
[2024-12-17 02:17:10,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:10,861][root][INFO] - Training Epoch: 1/2, step 6868/7134 completed (loss: 0.05447160452604294, acc: 0.987500011920929)
[2024-12-17 02:17:10,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:11,111][root][INFO] - Training Epoch: 1/2, step 6869/7134 completed (loss: 0.12706954777240753, acc: 0.963302731513977)
[2024-12-17 02:17:11,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:11,395][root][INFO] - Training Epoch: 1/2, step 6870/7134 completed (loss: 0.20299342274665833, acc: 0.9556962251663208)
[2024-12-17 02:17:11,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:11,711][root][INFO] - Training Epoch: 1/2, step 6871/7134 completed (loss: 0.1159486398100853, acc: 0.9682539701461792)
[2024-12-17 02:17:11,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:11,984][root][INFO] - Training Epoch: 1/2, step 6872/7134 completed (loss: 0.1192789152264595, acc: 0.9772727489471436)
[2024-12-17 02:17:12,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:12,262][root][INFO] - Training Epoch: 1/2, step 6873/7134 completed (loss: 0.12041343003511429, acc: 0.9647058844566345)
[2024-12-17 02:17:12,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:12,526][root][INFO] - Training Epoch: 1/2, step 6874/7134 completed (loss: 0.061780210584402084, acc: 0.9921875)
[2024-12-17 02:17:12,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:12,806][root][INFO] - Training Epoch: 1/2, step 6875/7134 completed (loss: 0.3015330135822296, acc: 0.9194630980491638)
[2024-12-17 02:17:12,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:13,072][root][INFO] - Training Epoch: 1/2, step 6876/7134 completed (loss: 0.18436290323734283, acc: 0.9541984796524048)
[2024-12-17 02:17:13,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:13,353][root][INFO] - Training Epoch: 1/2, step 6877/7134 completed (loss: 0.16006259620189667, acc: 0.9529411792755127)
[2024-12-17 02:17:13,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:13,632][root][INFO] - Training Epoch: 1/2, step 6878/7134 completed (loss: 0.23260031640529633, acc: 0.9411764740943909)
[2024-12-17 02:17:13,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:13,871][root][INFO] - Training Epoch: 1/2, step 6879/7134 completed (loss: 0.31073758006095886, acc: 0.9051724076271057)
[2024-12-17 02:17:13,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:14,166][root][INFO] - Training Epoch: 1/2, step 6880/7134 completed (loss: 0.10032753646373749, acc: 0.9796954393386841)
[2024-12-17 02:17:14,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:14,453][root][INFO] - Training Epoch: 1/2, step 6881/7134 completed (loss: 0.25190815329551697, acc: 0.9414893388748169)
[2024-12-17 02:17:14,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:14,719][root][INFO] - Training Epoch: 1/2, step 6882/7134 completed (loss: 0.42899954319000244, acc: 0.8802816867828369)
[2024-12-17 02:17:14,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:15,002][root][INFO] - Training Epoch: 1/2, step 6883/7134 completed (loss: 0.20295588672161102, acc: 0.9558823704719543)
[2024-12-17 02:17:15,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:15,287][root][INFO] - Training Epoch: 1/2, step 6884/7134 completed (loss: 0.22845426201820374, acc: 0.9488636255264282)
[2024-12-17 02:17:15,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:15,565][root][INFO] - Training Epoch: 1/2, step 6885/7134 completed (loss: 0.15841995179653168, acc: 0.9626168012619019)
[2024-12-17 02:17:15,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:15,854][root][INFO] - Training Epoch: 1/2, step 6886/7134 completed (loss: 0.22537726163864136, acc: 0.9527027010917664)
[2024-12-17 02:17:15,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:16,161][root][INFO] - Training Epoch: 1/2, step 6887/7134 completed (loss: 0.28900831937789917, acc: 0.904347836971283)
[2024-12-17 02:17:16,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:16,448][root][INFO] - Training Epoch: 1/2, step 6888/7134 completed (loss: 0.20589707791805267, acc: 0.9266666769981384)
[2024-12-17 02:17:16,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:16,725][root][INFO] - Training Epoch: 1/2, step 6889/7134 completed (loss: 0.12409184128046036, acc: 0.9738562107086182)
[2024-12-17 02:17:16,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:17,003][root][INFO] - Training Epoch: 1/2, step 6890/7134 completed (loss: 0.3027624785900116, acc: 0.9301075339317322)
[2024-12-17 02:17:17,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:17,275][root][INFO] - Training Epoch: 1/2, step 6891/7134 completed (loss: 0.14548686146736145, acc: 0.9567901492118835)
[2024-12-17 02:17:17,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:17,553][root][INFO] - Training Epoch: 1/2, step 6892/7134 completed (loss: 0.28243160247802734, acc: 0.9139785170555115)
[2024-12-17 02:17:17,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:17,831][root][INFO] - Training Epoch: 1/2, step 6893/7134 completed (loss: 0.3359065055847168, acc: 0.9038461446762085)
[2024-12-17 02:17:17,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:18,116][root][INFO] - Training Epoch: 1/2, step 6894/7134 completed (loss: 0.2735636830329895, acc: 0.9322916865348816)
[2024-12-17 02:17:18,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:18,401][root][INFO] - Training Epoch: 1/2, step 6895/7134 completed (loss: 0.2615785002708435, acc: 0.935960590839386)
[2024-12-17 02:17:18,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:18,660][root][INFO] - Training Epoch: 1/2, step 6896/7134 completed (loss: 0.32322239875793457, acc: 0.9190751314163208)
[2024-12-17 02:17:18,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:18,937][root][INFO] - Training Epoch: 1/2, step 6897/7134 completed (loss: 0.16859500110149384, acc: 0.9653465151786804)
[2024-12-17 02:17:19,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:19,205][root][INFO] - Training Epoch: 1/2, step 6898/7134 completed (loss: 0.2901076674461365, acc: 0.9306358098983765)
[2024-12-17 02:17:19,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:19,482][root][INFO] - Training Epoch: 1/2, step 6899/7134 completed (loss: 0.21616517007350922, acc: 0.9521276354789734)
[2024-12-17 02:17:19,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:19,756][root][INFO] - Training Epoch: 1/2, step 6900/7134 completed (loss: 0.3869040310382843, acc: 0.9190751314163208)
[2024-12-17 02:17:19,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:20,037][root][INFO] - Training Epoch: 1/2, step 6901/7134 completed (loss: 0.317190945148468, acc: 0.9243243336677551)
[2024-12-17 02:17:20,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:20,327][root][INFO] - Training Epoch: 1/2, step 6902/7134 completed (loss: 0.09650396555662155, acc: 0.9775280952453613)
[2024-12-17 02:17:20,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:20,606][root][INFO] - Training Epoch: 1/2, step 6903/7134 completed (loss: 0.18419532477855682, acc: 0.9512194991111755)
[2024-12-17 02:17:20,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:20,890][root][INFO] - Training Epoch: 1/2, step 6904/7134 completed (loss: 0.1345544159412384, acc: 0.9585492014884949)
[2024-12-17 02:17:21,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:21,180][root][INFO] - Training Epoch: 1/2, step 6905/7134 completed (loss: 0.2091245949268341, acc: 0.9402984976768494)
[2024-12-17 02:17:21,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:21,471][root][INFO] - Training Epoch: 1/2, step 6906/7134 completed (loss: 0.24535620212554932, acc: 0.9411764740943909)
[2024-12-17 02:17:21,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:21,758][root][INFO] - Training Epoch: 1/2, step 6907/7134 completed (loss: 0.15815094113349915, acc: 0.9689119458198547)
[2024-12-17 02:17:21,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:22,037][root][INFO] - Training Epoch: 1/2, step 6908/7134 completed (loss: 0.2662009000778198, acc: 0.9476190209388733)
[2024-12-17 02:17:22,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:22,315][root][INFO] - Training Epoch: 1/2, step 6909/7134 completed (loss: 0.1438412368297577, acc: 0.9672130942344666)
[2024-12-17 02:17:22,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:22,594][root][INFO] - Training Epoch: 1/2, step 6910/7134 completed (loss: 0.19658617675304413, acc: 0.9427083134651184)
[2024-12-17 02:17:22,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:22,850][root][INFO] - Training Epoch: 1/2, step 6911/7134 completed (loss: 0.44532808661460876, acc: 0.9337016344070435)
[2024-12-17 02:17:22,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:23,130][root][INFO] - Training Epoch: 1/2, step 6912/7134 completed (loss: 0.3211897015571594, acc: 0.9317073225975037)
[2024-12-17 02:17:23,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:23,461][root][INFO] - Training Epoch: 1/2, step 6913/7134 completed (loss: 0.2495822012424469, acc: 0.9516907930374146)
[2024-12-17 02:17:23,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:23,727][root][INFO] - Training Epoch: 1/2, step 6914/7134 completed (loss: 0.3829808831214905, acc: 0.8954248428344727)
[2024-12-17 02:17:23,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:24,007][root][INFO] - Training Epoch: 1/2, step 6915/7134 completed (loss: 0.19916115701198578, acc: 0.9675675630569458)
[2024-12-17 02:17:24,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:24,288][root][INFO] - Training Epoch: 1/2, step 6916/7134 completed (loss: 0.2591097950935364, acc: 0.9414634108543396)
[2024-12-17 02:17:24,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:24,585][root][INFO] - Training Epoch: 1/2, step 6917/7134 completed (loss: 0.2602277994155884, acc: 0.9587628841400146)
[2024-12-17 02:17:24,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:24,850][root][INFO] - Training Epoch: 1/2, step 6918/7134 completed (loss: 0.2499854564666748, acc: 0.9175257682800293)
[2024-12-17 02:17:24,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:25,134][root][INFO] - Training Epoch: 1/2, step 6919/7134 completed (loss: 0.30977171659469604, acc: 0.9187816977500916)
[2024-12-17 02:17:25,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:25,403][root][INFO] - Training Epoch: 1/2, step 6920/7134 completed (loss: 0.1614426225423813, acc: 0.9640718698501587)
[2024-12-17 02:17:25,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:25,696][root][INFO] - Training Epoch: 1/2, step 6921/7134 completed (loss: 0.24876455962657928, acc: 0.9656862616539001)
[2024-12-17 02:17:25,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:25,961][root][INFO] - Training Epoch: 1/2, step 6922/7134 completed (loss: 0.2631663680076599, acc: 0.942307710647583)
[2024-12-17 02:17:26,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:26,257][root][INFO] - Training Epoch: 1/2, step 6923/7134 completed (loss: 0.2313995659351349, acc: 0.9385964870452881)
[2024-12-17 02:17:26,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:26,537][root][INFO] - Training Epoch: 1/2, step 6924/7134 completed (loss: 0.3098393380641937, acc: 0.9151515364646912)
[2024-12-17 02:17:26,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:26,819][root][INFO] - Training Epoch: 1/2, step 6925/7134 completed (loss: 0.2958303987979889, acc: 0.9176470637321472)
[2024-12-17 02:17:26,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:27,102][root][INFO] - Training Epoch: 1/2, step 6926/7134 completed (loss: 0.3852050304412842, acc: 0.8809523582458496)
[2024-12-17 02:17:27,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:27,389][root][INFO] - Training Epoch: 1/2, step 6927/7134 completed (loss: 0.28443750739097595, acc: 0.9257425665855408)
[2024-12-17 02:17:27,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:27,650][root][INFO] - Training Epoch: 1/2, step 6928/7134 completed (loss: 0.4093933403491974, acc: 0.90625)
[2024-12-17 02:17:27,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:27,948][root][INFO] - Training Epoch: 1/2, step 6929/7134 completed (loss: 0.17550796270370483, acc: 0.9545454382896423)
[2024-12-17 02:17:28,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:28,227][root][INFO] - Training Epoch: 1/2, step 6930/7134 completed (loss: 0.22951608896255493, acc: 0.9479166865348816)
[2024-12-17 02:17:28,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:28,525][root][INFO] - Training Epoch: 1/2, step 6931/7134 completed (loss: 0.14420287311077118, acc: 0.9735449552536011)
[2024-12-17 02:17:28,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:28,812][root][INFO] - Training Epoch: 1/2, step 6932/7134 completed (loss: 0.2590579688549042, acc: 0.940119743347168)
[2024-12-17 02:17:28,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:29,080][root][INFO] - Training Epoch: 1/2, step 6933/7134 completed (loss: 0.4138239920139313, acc: 0.9341317415237427)
[2024-12-17 02:17:29,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:29,376][root][INFO] - Training Epoch: 1/2, step 6934/7134 completed (loss: 0.32153335213661194, acc: 0.9230769276618958)
[2024-12-17 02:17:29,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:29,663][root][INFO] - Training Epoch: 1/2, step 6935/7134 completed (loss: 0.18403366208076477, acc: 0.9521276354789734)
[2024-12-17 02:17:29,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:29,961][root][INFO] - Training Epoch: 1/2, step 6936/7134 completed (loss: 0.13637031614780426, acc: 0.9677419066429138)
[2024-12-17 02:17:30,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:30,263][root][INFO] - Training Epoch: 1/2, step 6937/7134 completed (loss: 0.35025763511657715, acc: 0.9246575236320496)
[2024-12-17 02:17:30,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:30,563][root][INFO] - Training Epoch: 1/2, step 6938/7134 completed (loss: 0.5415394306182861, acc: 0.8735632300376892)
[2024-12-17 02:17:30,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:30,866][root][INFO] - Training Epoch: 1/2, step 6939/7134 completed (loss: 0.3432464301586151, acc: 0.8928571343421936)
[2024-12-17 02:17:31,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:31,158][root][INFO] - Training Epoch: 1/2, step 6940/7134 completed (loss: 0.4906168580055237, acc: 0.9034482836723328)
[2024-12-17 02:17:31,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:31,432][root][INFO] - Training Epoch: 1/2, step 6941/7134 completed (loss: 0.15811508893966675, acc: 0.9632353186607361)
[2024-12-17 02:17:31,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:31,734][root][INFO] - Training Epoch: 1/2, step 6942/7134 completed (loss: 0.33465227484703064, acc: 0.9171974658966064)
[2024-12-17 02:17:31,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:32,050][root][INFO] - Training Epoch: 1/2, step 6943/7134 completed (loss: 0.2571723163127899, acc: 0.9203540086746216)
[2024-12-17 02:17:32,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:32,364][root][INFO] - Training Epoch: 1/2, step 6944/7134 completed (loss: 0.24380414187908173, acc: 0.9724137783050537)
[2024-12-17 02:17:32,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:32,645][root][INFO] - Training Epoch: 1/2, step 6945/7134 completed (loss: 0.3553517758846283, acc: 0.953125)
[2024-12-17 02:17:32,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:32,935][root][INFO] - Training Epoch: 1/2, step 6946/7134 completed (loss: 0.44192397594451904, acc: 0.8924731016159058)
[2024-12-17 02:17:33,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:33,213][root][INFO] - Training Epoch: 1/2, step 6947/7134 completed (loss: 0.28799790143966675, acc: 0.9469026327133179)
[2024-12-17 02:17:33,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:33,504][root][INFO] - Training Epoch: 1/2, step 6948/7134 completed (loss: 0.46740439534187317, acc: 0.8785714507102966)
[2024-12-17 02:17:33,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:33,782][root][INFO] - Training Epoch: 1/2, step 6949/7134 completed (loss: 0.29651618003845215, acc: 0.9304347634315491)
[2024-12-17 02:17:33,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:34,056][root][INFO] - Training Epoch: 1/2, step 6950/7134 completed (loss: 0.1983090341091156, acc: 0.9367088675498962)
[2024-12-17 02:17:34,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:34,346][root][INFO] - Training Epoch: 1/2, step 6951/7134 completed (loss: 0.30938634276390076, acc: 0.9305555820465088)
[2024-12-17 02:17:34,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:34,620][root][INFO] - Training Epoch: 1/2, step 6952/7134 completed (loss: 0.3489677309989929, acc: 0.9047619104385376)
[2024-12-17 02:17:34,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:34,929][root][INFO] - Training Epoch: 1/2, step 6953/7134 completed (loss: 0.2503831684589386, acc: 0.9172932505607605)
[2024-12-17 02:17:35,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:35,212][root][INFO] - Training Epoch: 1/2, step 6954/7134 completed (loss: 0.4155139625072479, acc: 0.9224137663841248)
[2024-12-17 02:17:35,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:35,496][root][INFO] - Training Epoch: 1/2, step 6955/7134 completed (loss: 0.20498590171337128, acc: 0.9125000238418579)
[2024-12-17 02:17:35,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:35,791][root][INFO] - Training Epoch: 1/2, step 6956/7134 completed (loss: 0.15793569386005402, acc: 0.9489051103591919)
[2024-12-17 02:17:35,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:36,076][root][INFO] - Training Epoch: 1/2, step 6957/7134 completed (loss: 0.23893651366233826, acc: 0.9359999895095825)
[2024-12-17 02:17:36,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:36,353][root][INFO] - Training Epoch: 1/2, step 6958/7134 completed (loss: 0.4488357901573181, acc: 0.9230769276618958)
[2024-12-17 02:17:36,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:36,636][root][INFO] - Training Epoch: 1/2, step 6959/7134 completed (loss: 0.4868079125881195, acc: 0.8899082541465759)
[2024-12-17 02:17:36,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:36,919][root][INFO] - Training Epoch: 1/2, step 6960/7134 completed (loss: 0.2838069796562195, acc: 0.9166666865348816)
[2024-12-17 02:17:37,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:37,196][root][INFO] - Training Epoch: 1/2, step 6961/7134 completed (loss: 0.21262045204639435, acc: 0.94017094373703)
[2024-12-17 02:17:37,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:37,484][root][INFO] - Training Epoch: 1/2, step 6962/7134 completed (loss: 0.2091314047574997, acc: 0.9420289993286133)
[2024-12-17 02:17:37,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:37,787][root][INFO] - Training Epoch: 1/2, step 6963/7134 completed (loss: 0.2821342349052429, acc: 0.9271523356437683)
[2024-12-17 02:17:37,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:38,073][root][INFO] - Training Epoch: 1/2, step 6964/7134 completed (loss: 0.09502554684877396, acc: 0.9772727489471436)
[2024-12-17 02:17:38,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:38,366][root][INFO] - Training Epoch: 1/2, step 6965/7134 completed (loss: 0.07542934268712997, acc: 0.9784172773361206)
[2024-12-17 02:17:38,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:38,644][root][INFO] - Training Epoch: 1/2, step 6966/7134 completed (loss: 0.20865176618099213, acc: 0.9523809552192688)
[2024-12-17 02:17:38,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:38,922][root][INFO] - Training Epoch: 1/2, step 6967/7134 completed (loss: 0.14095856249332428, acc: 0.9795918464660645)
[2024-12-17 02:17:39,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:39,216][root][INFO] - Training Epoch: 1/2, step 6968/7134 completed (loss: 0.2421266883611679, acc: 0.9395973086357117)
[2024-12-17 02:17:39,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:39,500][root][INFO] - Training Epoch: 1/2, step 6969/7134 completed (loss: 0.3510042726993561, acc: 0.9032257795333862)
[2024-12-17 02:17:39,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:39,788][root][INFO] - Training Epoch: 1/2, step 6970/7134 completed (loss: 0.4260517358779907, acc: 0.8965517282485962)
[2024-12-17 02:17:39,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:40,083][root][INFO] - Training Epoch: 1/2, step 6971/7134 completed (loss: 0.3421967923641205, acc: 0.9166666865348816)
[2024-12-17 02:17:40,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:40,375][root][INFO] - Training Epoch: 1/2, step 6972/7134 completed (loss: 0.2602996528148651, acc: 0.9534883499145508)
[2024-12-17 02:17:40,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:40,645][root][INFO] - Training Epoch: 1/2, step 6973/7134 completed (loss: 0.2840305268764496, acc: 0.9568965435028076)
[2024-12-17 02:17:40,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:40,929][root][INFO] - Training Epoch: 1/2, step 6974/7134 completed (loss: 0.43363380432128906, acc: 0.8888888955116272)
[2024-12-17 02:17:41,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:41,196][root][INFO] - Training Epoch: 1/2, step 6975/7134 completed (loss: 0.22616106271743774, acc: 0.9572649598121643)
[2024-12-17 02:17:41,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:41,476][root][INFO] - Training Epoch: 1/2, step 6976/7134 completed (loss: 0.2632741928100586, acc: 0.9357143044471741)
[2024-12-17 02:17:41,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:41,751][root][INFO] - Training Epoch: 1/2, step 6977/7134 completed (loss: 0.3000454008579254, acc: 0.9083969593048096)
[2024-12-17 02:17:41,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:42,041][root][INFO] - Training Epoch: 1/2, step 6978/7134 completed (loss: 0.26253095269203186, acc: 0.9303797483444214)
[2024-12-17 02:17:42,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:42,339][root][INFO] - Training Epoch: 1/2, step 6979/7134 completed (loss: 0.32244789600372314, acc: 0.9072847962379456)
[2024-12-17 02:17:42,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:42,618][root][INFO] - Training Epoch: 1/2, step 6980/7134 completed (loss: 0.7534865736961365, acc: 0.8192090392112732)
[2024-12-17 02:17:42,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:42,910][root][INFO] - Training Epoch: 1/2, step 6981/7134 completed (loss: 0.56607985496521, acc: 0.8556700944900513)
[2024-12-17 02:17:43,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:43,203][root][INFO] - Training Epoch: 1/2, step 6982/7134 completed (loss: 0.4675440490245819, acc: 0.9109947681427002)
[2024-12-17 02:17:43,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:43,511][root][INFO] - Training Epoch: 1/2, step 6983/7134 completed (loss: 0.6304250359535217, acc: 0.8717948794364929)
[2024-12-17 02:17:43,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:43,800][root][INFO] - Training Epoch: 1/2, step 6984/7134 completed (loss: 0.3035616874694824, acc: 0.930232584476471)
[2024-12-17 02:17:43,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:44,108][root][INFO] - Training Epoch: 1/2, step 6985/7134 completed (loss: 0.4718405604362488, acc: 0.8798283338546753)
[2024-12-17 02:17:44,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:44,401][root][INFO] - Training Epoch: 1/2, step 6986/7134 completed (loss: 0.3493780195713043, acc: 0.895061731338501)
[2024-12-17 02:17:44,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:44,697][root][INFO] - Training Epoch: 1/2, step 6987/7134 completed (loss: 0.36219146847724915, acc: 0.8966942429542542)
[2024-12-17 02:17:44,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:44,967][root][INFO] - Training Epoch: 1/2, step 6988/7134 completed (loss: 0.2935670018196106, acc: 0.913385808467865)
[2024-12-17 02:17:45,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:45,251][root][INFO] - Training Epoch: 1/2, step 6989/7134 completed (loss: 0.5344007015228271, acc: 0.8648648858070374)
[2024-12-17 02:17:45,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:45,533][root][INFO] - Training Epoch: 1/2, step 6990/7134 completed (loss: 0.14894676208496094, acc: 0.9814814925193787)
[2024-12-17 02:17:45,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:45,803][root][INFO] - Training Epoch: 1/2, step 6991/7134 completed (loss: 0.4004065990447998, acc: 0.9207921028137207)
[2024-12-17 02:17:45,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:46,089][root][INFO] - Training Epoch: 1/2, step 6992/7134 completed (loss: 0.3597148656845093, acc: 0.8918918967247009)
[2024-12-17 02:17:46,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:46,361][root][INFO] - Training Epoch: 1/2, step 6993/7134 completed (loss: 0.3962262272834778, acc: 0.8789808750152588)
[2024-12-17 02:17:46,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:46,652][root][INFO] - Training Epoch: 1/2, step 6994/7134 completed (loss: 0.5171319842338562, acc: 0.8999999761581421)
[2024-12-17 02:17:46,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:46,940][root][INFO] - Training Epoch: 1/2, step 6995/7134 completed (loss: 0.27433454990386963, acc: 0.9244186282157898)
[2024-12-17 02:17:47,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:47,229][root][INFO] - Training Epoch: 1/2, step 6996/7134 completed (loss: 0.2463340014219284, acc: 0.9383561611175537)
[2024-12-17 02:17:47,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:47,508][root][INFO] - Training Epoch: 1/2, step 6997/7134 completed (loss: 0.22079351544380188, acc: 0.9354838728904724)
[2024-12-17 02:17:47,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:47,776][root][INFO] - Training Epoch: 1/2, step 6998/7134 completed (loss: 0.46280425786972046, acc: 0.8842105269432068)
[2024-12-17 02:17:47,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:48,059][root][INFO] - Training Epoch: 1/2, step 6999/7134 completed (loss: 0.21277783811092377, acc: 0.9378530979156494)
[2024-12-17 02:17:48,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:48,336][root][INFO] - Training Epoch: 1/2, step 7000/7134 completed (loss: 0.3319554626941681, acc: 0.9272727370262146)
[2024-12-17 02:17:48,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:48,619][root][INFO] - Training Epoch: 1/2, step 7001/7134 completed (loss: 0.4152299761772156, acc: 0.9675324559211731)
[2024-12-17 02:17:48,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:48,902][root][INFO] - Training Epoch: 1/2, step 7002/7134 completed (loss: 0.17781813442707062, acc: 0.9495798349380493)
[2024-12-17 02:17:49,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:49,177][root][INFO] - Training Epoch: 1/2, step 7003/7134 completed (loss: 0.15192237496376038, acc: 0.9585492014884949)
[2024-12-17 02:17:49,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:49,473][root][INFO] - Training Epoch: 1/2, step 7004/7134 completed (loss: 0.29815807938575745, acc: 0.9268292784690857)
[2024-12-17 02:17:49,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:49,767][root][INFO] - Training Epoch: 1/2, step 7005/7134 completed (loss: 0.24639837443828583, acc: 0.9518072009086609)
[2024-12-17 02:17:49,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:50,053][root][INFO] - Training Epoch: 1/2, step 7006/7134 completed (loss: 0.1899072825908661, acc: 0.9378882050514221)
[2024-12-17 02:17:50,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:50,331][root][INFO] - Training Epoch: 1/2, step 7007/7134 completed (loss: 0.25007307529449463, acc: 0.948387086391449)
[2024-12-17 02:17:50,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:50,606][root][INFO] - Training Epoch: 1/2, step 7008/7134 completed (loss: 0.17474456131458282, acc: 0.9613259434700012)
[2024-12-17 02:17:50,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:50,892][root][INFO] - Training Epoch: 1/2, step 7009/7134 completed (loss: 0.24232828617095947, acc: 0.921875)
[2024-12-17 02:17:51,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:51,174][root][INFO] - Training Epoch: 1/2, step 7010/7134 completed (loss: 0.19456465542316437, acc: 0.9225806593894958)
[2024-12-17 02:17:51,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:51,455][root][INFO] - Training Epoch: 1/2, step 7011/7134 completed (loss: 0.31129369139671326, acc: 0.9371727705001831)
[2024-12-17 02:17:51,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:51,732][root][INFO] - Training Epoch: 1/2, step 7012/7134 completed (loss: 0.2434777170419693, acc: 0.9518072009086609)
[2024-12-17 02:17:51,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:52,025][root][INFO] - Training Epoch: 1/2, step 7013/7134 completed (loss: 0.11159688979387283, acc: 0.9681528806686401)
[2024-12-17 02:17:52,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:52,309][root][INFO] - Training Epoch: 1/2, step 7014/7134 completed (loss: 0.3424924910068512, acc: 0.9391891956329346)
[2024-12-17 02:17:52,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:52,598][root][INFO] - Training Epoch: 1/2, step 7015/7134 completed (loss: 0.19198383390903473, acc: 0.9477611780166626)
[2024-12-17 02:17:52,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:52,904][root][INFO] - Training Epoch: 1/2, step 7016/7134 completed (loss: 0.3043144941329956, acc: 0.9358974099159241)
[2024-12-17 02:17:53,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:53,192][root][INFO] - Training Epoch: 1/2, step 7017/7134 completed (loss: 0.37348631024360657, acc: 0.9026548862457275)
[2024-12-17 02:17:53,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:53,481][root][INFO] - Training Epoch: 1/2, step 7018/7134 completed (loss: 0.30286458134651184, acc: 0.9444444179534912)
[2024-12-17 02:17:53,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:53,760][root][INFO] - Training Epoch: 1/2, step 7019/7134 completed (loss: 0.5132836699485779, acc: 0.8987341523170471)
[2024-12-17 02:17:53,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:54,068][root][INFO] - Training Epoch: 1/2, step 7020/7134 completed (loss: 0.1647917777299881, acc: 0.9578313231468201)
[2024-12-17 02:17:54,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:54,400][root][INFO] - Training Epoch: 1/2, step 7021/7134 completed (loss: 0.16524887084960938, acc: 0.970370352268219)
[2024-12-17 02:17:54,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:54,666][root][INFO] - Training Epoch: 1/2, step 7022/7134 completed (loss: 0.518561065196991, acc: 0.8888888955116272)
[2024-12-17 02:17:54,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:54,956][root][INFO] - Training Epoch: 1/2, step 7023/7134 completed (loss: 0.4350992739200592, acc: 0.8554216623306274)
[2024-12-17 02:17:55,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:55,225][root][INFO] - Training Epoch: 1/2, step 7024/7134 completed (loss: 0.4004494547843933, acc: 0.8985507488250732)
[2024-12-17 02:17:55,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:55,524][root][INFO] - Training Epoch: 1/2, step 7025/7134 completed (loss: 0.48203280568122864, acc: 0.8857142925262451)
[2024-12-17 02:17:55,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:55,806][root][INFO] - Training Epoch: 1/2, step 7026/7134 completed (loss: 0.727210283279419, acc: 0.84375)
[2024-12-17 02:17:55,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:56,098][root][INFO] - Training Epoch: 1/2, step 7027/7134 completed (loss: 0.4480705261230469, acc: 0.8591549396514893)
[2024-12-17 02:17:56,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:56,386][root][INFO] - Training Epoch: 1/2, step 7028/7134 completed (loss: 0.18207409977912903, acc: 0.9560439586639404)
[2024-12-17 02:17:56,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:56,656][root][INFO] - Training Epoch: 1/2, step 7029/7134 completed (loss: 0.21576441824436188, acc: 0.9438202381134033)
[2024-12-17 02:17:56,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:56,939][root][INFO] - Training Epoch: 1/2, step 7030/7134 completed (loss: 0.433477520942688, acc: 0.8695651888847351)
[2024-12-17 02:17:57,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:57,234][root][INFO] - Training Epoch: 1/2, step 7031/7134 completed (loss: 0.5169168710708618, acc: 0.8518518805503845)
[2024-12-17 02:17:57,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:57,513][root][INFO] - Training Epoch: 1/2, step 7032/7134 completed (loss: 0.6215535402297974, acc: 0.8235294222831726)
[2024-12-17 02:17:57,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:57,786][root][INFO] - Training Epoch: 1/2, step 7033/7134 completed (loss: 0.5223490595817566, acc: 0.8518518805503845)
[2024-12-17 02:17:57,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:58,054][root][INFO] - Training Epoch: 1/2, step 7034/7134 completed (loss: 0.45353078842163086, acc: 0.890625)
[2024-12-17 02:17:58,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:58,358][root][INFO] - Training Epoch: 1/2, step 7035/7134 completed (loss: 0.4187146723270416, acc: 0.8888888955116272)
[2024-12-17 02:17:58,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:58,645][root][INFO] - Training Epoch: 1/2, step 7036/7134 completed (loss: 0.3968805968761444, acc: 0.8888888955116272)
[2024-12-17 02:17:58,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:58,918][root][INFO] - Training Epoch: 1/2, step 7037/7134 completed (loss: 0.12071868777275085, acc: 0.9850746393203735)
[2024-12-17 02:17:59,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:59,197][root][INFO] - Training Epoch: 1/2, step 7038/7134 completed (loss: 0.6478866338729858, acc: 0.8101266026496887)
[2024-12-17 02:17:59,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:59,476][root][INFO] - Training Epoch: 1/2, step 7039/7134 completed (loss: 0.4244459867477417, acc: 0.9555555582046509)
[2024-12-17 02:17:59,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:59,743][root][INFO] - Training Epoch: 1/2, step 7040/7134 completed (loss: 0.6073786020278931, acc: 0.8666666746139526)
[2024-12-17 02:17:59,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:00,023][root][INFO] - Training Epoch: 1/2, step 7041/7134 completed (loss: 0.4794006943702698, acc: 0.887499988079071)
[2024-12-17 02:18:00,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:00,292][root][INFO] - Training Epoch: 1/2, step 7042/7134 completed (loss: 0.5470946431159973, acc: 0.8591549396514893)
[2024-12-17 02:18:00,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:00,582][root][INFO] - Training Epoch: 1/2, step 7043/7134 completed (loss: 0.5645911693572998, acc: 0.8266666531562805)
[2024-12-17 02:18:00,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:00,845][root][INFO] - Training Epoch: 1/2, step 7044/7134 completed (loss: 0.5748245716094971, acc: 0.8450704216957092)
[2024-12-17 02:18:00,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:01,148][root][INFO] - Training Epoch: 1/2, step 7045/7134 completed (loss: 0.3137168288230896, acc: 0.9172413945198059)
[2024-12-17 02:18:01,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:01,442][root][INFO] - Training Epoch: 1/2, step 7046/7134 completed (loss: 0.45065948367118835, acc: 0.9221556782722473)
[2024-12-17 02:18:01,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:01,732][root][INFO] - Training Epoch: 1/2, step 7047/7134 completed (loss: 0.4986221194267273, acc: 0.9061033129692078)
[2024-12-17 02:18:01,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:02,018][root][INFO] - Training Epoch: 1/2, step 7048/7134 completed (loss: 0.10265229642391205, acc: 0.969072163105011)
[2024-12-17 02:18:02,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:02,289][root][INFO] - Training Epoch: 1/2, step 7049/7134 completed (loss: 0.32394659519195557, acc: 0.9248554706573486)
[2024-12-17 02:18:02,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:02,582][root][INFO] - Training Epoch: 1/2, step 7050/7134 completed (loss: 0.1988409161567688, acc: 0.954285740852356)
[2024-12-17 02:18:02,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:02,885][root][INFO] - Training Epoch: 1/2, step 7051/7134 completed (loss: 0.2796686291694641, acc: 0.9347826242446899)
[2024-12-17 02:18:02,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:03,171][root][INFO] - Training Epoch: 1/2, step 7052/7134 completed (loss: 0.1630483865737915, acc: 0.9479768872261047)
[2024-12-17 02:18:03,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:03,451][root][INFO] - Training Epoch: 1/2, step 7053/7134 completed (loss: 0.12493342161178589, acc: 0.9726775884628296)
[2024-12-17 02:18:03,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:03,737][root][INFO] - Training Epoch: 1/2, step 7054/7134 completed (loss: 0.28794345259666443, acc: 0.9548386931419373)
[2024-12-17 02:18:03,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:04,025][root][INFO] - Training Epoch: 1/2, step 7055/7134 completed (loss: 0.2632216513156891, acc: 0.9450549483299255)
[2024-12-17 02:18:04,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:04,324][root][INFO] - Training Epoch: 1/2, step 7056/7134 completed (loss: 0.22190283238887787, acc: 0.9444444179534912)
[2024-12-17 02:18:04,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:04,639][root][INFO] - Training Epoch: 1/2, step 7057/7134 completed (loss: 0.704590380191803, acc: 0.8784530162811279)
[2024-12-17 02:18:04,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:04,934][root][INFO] - Training Epoch: 1/2, step 7058/7134 completed (loss: 0.3455637991428375, acc: 0.8914728760719299)
[2024-12-17 02:18:05,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:05,220][root][INFO] - Training Epoch: 1/2, step 7059/7134 completed (loss: 0.2544400990009308, acc: 0.942307710647583)
[2024-12-17 02:18:05,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:05,503][root][INFO] - Training Epoch: 1/2, step 7060/7134 completed (loss: 0.405987948179245, acc: 0.9154929518699646)
[2024-12-17 02:18:05,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:05,812][root][INFO] - Training Epoch: 1/2, step 7061/7134 completed (loss: 0.36963722109794617, acc: 0.9032257795333862)
[2024-12-17 02:18:05,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:06,100][root][INFO] - Training Epoch: 1/2, step 7062/7134 completed (loss: 0.32686617970466614, acc: 0.9152542352676392)
[2024-12-17 02:18:06,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:06,401][root][INFO] - Training Epoch: 1/2, step 7063/7134 completed (loss: 0.420884907245636, acc: 0.9027026891708374)
[2024-12-17 02:18:06,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:06,704][root][INFO] - Training Epoch: 1/2, step 7064/7134 completed (loss: 0.31217217445373535, acc: 0.9457831382751465)
[2024-12-17 02:18:06,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:06,989][root][INFO] - Training Epoch: 1/2, step 7065/7134 completed (loss: 0.18262305855751038, acc: 0.9848484992980957)
[2024-12-17 02:18:07,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:07,270][root][INFO] - Training Epoch: 1/2, step 7066/7134 completed (loss: 0.27712446451187134, acc: 0.9528796076774597)
[2024-12-17 02:18:07,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:07,550][root][INFO] - Training Epoch: 1/2, step 7067/7134 completed (loss: 0.22307813167572021, acc: 0.9576719403266907)
[2024-12-17 02:18:07,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:07,852][root][INFO] - Training Epoch: 1/2, step 7068/7134 completed (loss: 0.14449475705623627, acc: 0.9609755873680115)
[2024-12-17 02:18:08,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:08,167][root][INFO] - Training Epoch: 1/2, step 7069/7134 completed (loss: 0.18928691744804382, acc: 0.9783549904823303)
[2024-12-17 02:18:08,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:08,461][root][INFO] - Training Epoch: 1/2, step 7070/7134 completed (loss: 0.22736899554729462, acc: 0.9537572264671326)
[2024-12-17 02:18:08,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:08,761][root][INFO] - Training Epoch: 1/2, step 7071/7134 completed (loss: 0.20703455805778503, acc: 0.9495798349380493)
[2024-12-17 02:18:08,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:09,048][root][INFO] - Training Epoch: 1/2, step 7072/7134 completed (loss: 0.21427321434020996, acc: 0.9494949579238892)
[2024-12-17 02:18:09,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:09,357][root][INFO] - Training Epoch: 1/2, step 7073/7134 completed (loss: 0.18127307295799255, acc: 0.9648241400718689)
[2024-12-17 02:18:09,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:09,630][root][INFO] - Training Epoch: 1/2, step 7074/7134 completed (loss: 0.6976041793823242, acc: 0.8536585569381714)
[2024-12-17 02:18:09,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:09,920][root][INFO] - Training Epoch: 1/2, step 7075/7134 completed (loss: 0.39573439955711365, acc: 0.9171974658966064)
[2024-12-17 02:18:10,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:10,215][root][INFO] - Training Epoch: 1/2, step 7076/7134 completed (loss: 0.38051289319992065, acc: 0.8876404762268066)
[2024-12-17 02:18:10,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:10,492][root][INFO] - Training Epoch: 1/2, step 7077/7134 completed (loss: 0.35187703371047974, acc: 0.8972602486610413)
[2024-12-17 02:18:10,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:10,795][root][INFO] - Training Epoch: 1/2, step 7078/7134 completed (loss: 0.22187787294387817, acc: 0.9655172228813171)
[2024-12-17 02:18:10,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:11,074][root][INFO] - Training Epoch: 1/2, step 7079/7134 completed (loss: 0.1500149667263031, acc: 0.9539473652839661)
[2024-12-17 02:18:11,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:11,353][root][INFO] - Training Epoch: 1/2, step 7080/7134 completed (loss: 0.33918648958206177, acc: 0.8911564350128174)
[2024-12-17 02:18:11,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:11,650][root][INFO] - Training Epoch: 1/2, step 7081/7134 completed (loss: 0.18572767078876495, acc: 0.9306358098983765)
[2024-12-17 02:18:11,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:11,956][root][INFO] - Training Epoch: 1/2, step 7082/7134 completed (loss: 0.3658278286457062, acc: 0.9144737124443054)
[2024-12-17 02:18:12,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:12,248][root][INFO] - Training Epoch: 1/2, step 7083/7134 completed (loss: 0.14919690787792206, acc: 0.9645389914512634)
[2024-12-17 02:18:12,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:12,559][root][INFO] - Training Epoch: 1/2, step 7084/7134 completed (loss: 0.2845101058483124, acc: 0.9137930870056152)
[2024-12-17 02:18:12,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:12,835][root][INFO] - Training Epoch: 1/2, step 7085/7134 completed (loss: 0.2960197925567627, acc: 0.9333333373069763)
[2024-12-17 02:18:12,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:13,135][root][INFO] - Training Epoch: 1/2, step 7086/7134 completed (loss: 0.27578264474868774, acc: 0.9354838728904724)
[2024-12-17 02:18:13,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:13,413][root][INFO] - Training Epoch: 1/2, step 7087/7134 completed (loss: 0.34800752997398376, acc: 0.9147287011146545)
[2024-12-17 02:18:13,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:13,695][root][INFO] - Training Epoch: 1/2, step 7088/7134 completed (loss: 0.27778851985931396, acc: 0.9290780425071716)
[2024-12-17 02:18:13,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:13,971][root][INFO] - Training Epoch: 1/2, step 7089/7134 completed (loss: 0.36574262380599976, acc: 0.9161290526390076)
[2024-12-17 02:18:14,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:14,266][root][INFO] - Training Epoch: 1/2, step 7090/7134 completed (loss: 0.23842504620552063, acc: 0.9583333134651184)
[2024-12-17 02:18:14,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:14,567][root][INFO] - Training Epoch: 1/2, step 7091/7134 completed (loss: 0.12820370495319366, acc: 0.9696969985961914)
[2024-12-17 02:18:14,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:14,859][root][INFO] - Training Epoch: 1/2, step 7092/7134 completed (loss: 0.3443358540534973, acc: 0.9248120188713074)
[2024-12-17 02:18:14,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:15,136][root][INFO] - Training Epoch: 1/2, step 7093/7134 completed (loss: 0.4363393187522888, acc: 0.8974359035491943)
[2024-12-17 02:18:15,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:15,405][root][INFO] - Training Epoch: 1/2, step 7094/7134 completed (loss: 0.24694044888019562, acc: 0.9479166865348816)
[2024-12-17 02:18:15,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:15,713][root][INFO] - Training Epoch: 1/2, step 7095/7134 completed (loss: 0.27035462856292725, acc: 0.9152542352676392)
[2024-12-17 02:18:15,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:16,005][root][INFO] - Training Epoch: 1/2, step 7096/7134 completed (loss: 0.20166276395320892, acc: 0.9436619877815247)
[2024-12-17 02:18:16,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:16,293][root][INFO] - Training Epoch: 1/2, step 7097/7134 completed (loss: 0.3623780310153961, acc: 0.8974359035491943)
[2024-12-17 02:18:16,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:16,572][root][INFO] - Training Epoch: 1/2, step 7098/7134 completed (loss: 0.16685393452644348, acc: 0.9370629191398621)
[2024-12-17 02:18:16,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:16,839][root][INFO] - Training Epoch: 1/2, step 7099/7134 completed (loss: 0.37003961205482483, acc: 0.9130434989929199)
[2024-12-17 02:18:16,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:17,135][root][INFO] - Training Epoch: 1/2, step 7100/7134 completed (loss: 0.32140079140663147, acc: 0.916167676448822)
[2024-12-17 02:18:17,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:17,418][root][INFO] - Training Epoch: 1/2, step 7101/7134 completed (loss: 0.24434807896614075, acc: 0.9496402740478516)
[2024-12-17 02:18:17,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:17,712][root][INFO] - Training Epoch: 1/2, step 7102/7134 completed (loss: 0.28794074058532715, acc: 0.9576271176338196)
[2024-12-17 02:18:17,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:17,998][root][INFO] - Training Epoch: 1/2, step 7103/7134 completed (loss: 0.22192950546741486, acc: 0.96875)
[2024-12-17 02:18:18,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:18,274][root][INFO] - Training Epoch: 1/2, step 7104/7134 completed (loss: 0.20636160671710968, acc: 0.9561403393745422)
[2024-12-17 02:18:18,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:18,578][root][INFO] - Training Epoch: 1/2, step 7105/7134 completed (loss: 0.16557468473911285, acc: 0.9513888955116272)
[2024-12-17 02:18:18,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:18,832][root][INFO] - Training Epoch: 1/2, step 7106/7134 completed (loss: 0.12771566212177277, acc: 0.970370352268219)
[2024-12-17 02:18:18,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:19,123][root][INFO] - Training Epoch: 1/2, step 7107/7134 completed (loss: 0.09927235543727875, acc: 0.9627329111099243)
[2024-12-17 02:18:19,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:19,416][root][INFO] - Training Epoch: 1/2, step 7108/7134 completed (loss: 0.1428450644016266, acc: 0.970802903175354)
[2024-12-17 02:18:19,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:19,699][root][INFO] - Training Epoch: 1/2, step 7109/7134 completed (loss: 0.40251973271369934, acc: 0.9185185432434082)
[2024-12-17 02:18:19,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:19,985][root][INFO] - Training Epoch: 1/2, step 7110/7134 completed (loss: 0.1554316133260727, acc: 0.9548872113227844)
[2024-12-17 02:18:20,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:20,242][root][INFO] - Training Epoch: 1/2, step 7111/7134 completed (loss: 0.29173558950424194, acc: 0.9351851940155029)
[2024-12-17 02:18:20,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:20,517][root][INFO] - Training Epoch: 1/2, step 7112/7134 completed (loss: 0.3398144245147705, acc: 0.9279279112815857)
[2024-12-17 02:18:20,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:20,814][root][INFO] - Training Epoch: 1/2, step 7113/7134 completed (loss: 0.32077810168266296, acc: 0.9108280539512634)
[2024-12-17 02:18:20,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:21,112][root][INFO] - Training Epoch: 1/2, step 7114/7134 completed (loss: 0.232647106051445, acc: 0.9449541568756104)
[2024-12-17 02:18:21,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:21,386][root][INFO] - Training Epoch: 1/2, step 7115/7134 completed (loss: 0.2653612792491913, acc: 0.9389312863349915)
[2024-12-17 02:18:21,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:21,675][root][INFO] - Training Epoch: 1/2, step 7116/7134 completed (loss: 0.41432616114616394, acc: 0.9264705777168274)
[2024-12-17 02:18:21,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:21,953][root][INFO] - Training Epoch: 1/2, step 7117/7134 completed (loss: 0.3877807557582855, acc: 0.9291338324546814)
[2024-12-17 02:18:22,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:22,241][root][INFO] - Training Epoch: 1/2, step 7118/7134 completed (loss: 0.4146512448787689, acc: 0.8857142925262451)
[2024-12-17 02:18:22,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:22,524][root][INFO] - Training Epoch: 1/2, step 7119/7134 completed (loss: 0.2303011417388916, acc: 0.9448275566101074)
[2024-12-17 02:18:22,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:22,808][root][INFO] - Training Epoch: 1/2, step 7120/7134 completed (loss: 0.2927165627479553, acc: 0.9417475461959839)
[2024-12-17 02:18:22,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:23,090][root][INFO] - Training Epoch: 1/2, step 7121/7134 completed (loss: 0.056884076446294785, acc: 0.9923076629638672)
[2024-12-17 02:18:23,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:23,364][root][INFO] - Training Epoch: 1/2, step 7122/7134 completed (loss: 0.32614409923553467, acc: 0.9139785170555115)
[2024-12-17 02:18:23,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:23,637][root][INFO] - Training Epoch: 1/2, step 7123/7134 completed (loss: 0.19676564633846283, acc: 0.9696969985961914)
[2024-12-17 02:18:23,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:23,936][root][INFO] - Training Epoch: 1/2, step 7124/7134 completed (loss: 0.41243666410446167, acc: 0.8852459192276001)
[2024-12-17 02:18:24,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:24,230][root][INFO] - Training Epoch: 1/2, step 7125/7134 completed (loss: 0.27432024478912354, acc: 0.9465649127960205)
[2024-12-17 02:18:24,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:24,534][root][INFO] - Training Epoch: 1/2, step 7126/7134 completed (loss: 0.5514664649963379, acc: 0.8905109763145447)
[2024-12-17 02:18:24,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:24,814][root][INFO] - Training Epoch: 1/2, step 7127/7134 completed (loss: 0.2272707223892212, acc: 0.9629629850387573)
[2024-12-17 02:18:24,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:25,082][root][INFO] - Training Epoch: 1/2, step 7128/7134 completed (loss: 0.31342053413391113, acc: 0.9109588861465454)
[2024-12-17 02:18:25,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:25,381][root][INFO] - Training Epoch: 1/2, step 7129/7134 completed (loss: 0.8854363560676575, acc: 0.8139534592628479)
[2024-12-17 02:18:25,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:25,703][root][INFO] - Training Epoch: 1/2, step 7130/7134 completed (loss: 1.028320550918579, acc: 0.7799999713897705)
[2024-12-17 02:18:25,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:25,986][root][INFO] - Training Epoch: 1/2, step 7131/7134 completed (loss: 0.35384297370910645, acc: 0.9056603908538818)
[2024-12-17 02:18:26,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:26,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:27,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:27,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:27,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:28,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:28,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:28,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:28,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:29,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:29,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:29,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:29,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:30,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:30,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:30,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:30,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:31,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:31,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:31,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:32,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:32,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:32,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:32,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:33,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:33,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:33,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:33,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:34,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:34,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:34,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:35,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:35,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:35,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:36,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:36,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:36,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:36,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:36,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:37,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:37,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:37,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:38,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:38,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:38,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:39,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:39,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:39,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:40,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:40,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:40,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:41,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:41,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:41,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:42,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:42,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:42,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:42,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:43,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:43,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:43,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:44,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:44,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:44,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:45,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:45,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:45,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:45,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:46,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:46,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:46,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:47,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:47,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:47,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:47,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:48,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:48,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:48,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:49,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:49,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:50,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:50,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:50,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:50,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:51,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:51,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:51,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:52,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:52,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:52,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:53,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:53,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:53,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:53,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:54,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:54,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:55,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:55,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:55,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:55,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:56,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:56,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:56,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:57,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:57,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:57,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:58,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:58,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:58,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:59,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:59,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:59,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:00,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:00,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:00,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:00,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:01,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:01,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:01,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:01,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:02,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:02,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:02,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:02,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:03,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:03,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:03,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:04,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:04,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:04,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:04,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:05,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:05,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:05,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:06,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:06,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:06,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:07,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:07,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:07,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:08,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:08,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:08,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:08,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:09,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:09,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:09,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:09,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:10,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:10,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:10,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:10,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:11,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:11,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:11,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:12,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:12,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:12,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:12,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:13,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:13,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:13,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:14,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:14,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:14,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:15,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:15,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:15,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:16,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:16,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:16,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:17,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:17,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:17,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:17,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:18,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:18,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:18,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:19,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:19,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:19,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:19,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:20,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:20,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:21,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:21,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:21,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:22,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:22,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:22,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:23,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:23,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:23,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:24,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:24,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:24,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:25,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:25,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:25,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:25,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:26,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:26,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:26,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:27,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:27,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:27,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:27,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:28,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:28,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:28,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:29,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:29,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:29,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:30,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:30,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:30,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:30,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:31,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:31,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:31,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:32,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:32,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:32,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:33,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:33,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:33,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:33,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:34,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:34,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:34,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:35,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:35,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:35,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:36,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:36,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:36,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:36,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:37,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:37,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:37,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:38,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:38,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:38,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:39,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:39,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:39,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:40,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:40,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:41,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:41,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:41,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:41,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:42,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:42,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:42,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:43,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:43,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:43,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:44,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:44,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:44,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:45,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:45,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:45,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:46,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:46,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:46,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:47,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:47,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:47,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:47,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:48,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:48,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:48,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:49,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:49,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:49,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:49,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:50,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:50,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:50,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:51,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:51,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:52,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:52,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:52,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:53,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:53,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:53,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:54,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:54,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:54,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:55,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:55,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:55,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:56,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:56,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:56,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:57,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:57,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:57,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:57,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:58,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:58,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:58,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:59,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:59,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:59,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:59,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:00,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:00,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:01,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:01,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:01,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:02,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:02,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:02,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:03,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:03,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:03,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:04,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:04,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:04,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:05,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:05,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:05,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:06,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:06,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:06,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:07,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:07,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:07,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:08,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:08,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:08,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:09,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:09,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:09,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:10,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:10,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:10,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:11,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:11,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:11,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:12,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:12,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:12,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:13,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:13,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:13,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:14,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:14,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:14,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:15,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:15,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:15,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:15,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:16,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:16,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:16,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:17,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:17,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:18,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:18,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:19,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:19,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:19,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:20,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:20,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:20,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:20,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:21,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:21,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:21,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:22,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:22,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:22,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:23,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:23,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:23,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:23,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:24,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:24,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:24,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:25,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:25,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:25,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:26,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:26,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:26,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:27,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:27,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:27,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:27,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:28,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:28,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:28,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:29,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:29,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:29,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:29,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:30,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:30,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:30,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:31,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:31,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:31,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:31,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:32,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:32,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:32,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:33,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:33,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:33,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:33,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:34,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:34,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:34,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:35,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:35,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:35,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:35,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:36,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:36,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:36,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:37,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:37,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:37,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:37,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:38,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:38,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:38,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:39,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:39,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:39,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:39,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:40,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:40,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:40,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:41,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:41,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:41,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:42,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:42,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:42,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:42,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:43,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:43,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:43,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:43,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:44,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:44,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:44,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:44,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:45,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:45,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:45,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:46,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:46,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:46,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:46,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:47,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:47,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:47,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:48,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:48,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:48,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:48,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:49,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:49,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:49,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:49,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:50,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:50,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:50,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:50,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:51,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:51,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:51,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:52,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:52,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:53,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:53,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:53,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:53,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:54,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:54,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:54,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:55,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:55,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:55,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:56,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:56,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:56,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:57,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:57,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:57,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:58,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:58,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:58,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:59,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:59,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:00,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:00,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:00,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:00,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:01,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:01,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:01,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:02,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:02,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:03,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:03,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:03,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:03,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:04,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:04,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:04,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:05,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:05,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:05,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:05,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:06,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:06,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:06,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:07,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:07,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:07,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:08,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:08,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:08,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:09,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:09,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:09,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:09,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:10,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:10,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:10,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:11,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:11,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:11,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:12,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:12,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:12,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:13,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:13,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:13,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:13,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:14,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:14,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:14,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:15,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:15,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:15,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:16,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:16,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:16,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:16,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:17,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:17,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:17,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:18,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:18,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:18,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:18,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:19,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:19,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:19,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:19,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:20,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:20,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:20,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:20,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:21,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:21,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:21,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:22,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:22,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:22,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:23,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:23,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:23,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:24,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:24,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:24,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:25,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:25,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:25,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:25,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:26,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:26,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:26,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:27,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:27,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:27,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:27,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:28,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:28,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:28,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:29,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:29,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:29,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:29,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:30,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:30,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:30,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:30,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:31,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:31,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:31,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:31,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:32,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:32,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:32,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:32,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:33,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:33,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:33,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:34,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:34,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:34,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:34,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:35,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:35,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:35,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:36,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:36,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:37,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:37,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:38,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:38,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:38,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:39,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:39,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:39,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:40,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:40,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:40,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:41,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:41,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:41,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:42,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:42,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:43,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:43,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:43,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:44,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:44,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:44,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:45,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:45,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:45,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:46,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:46,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:46,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:47,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:47,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:47,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:47,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:48,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:48,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:48,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:49,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:49,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:49,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:50,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:50,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:50,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:51,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:51,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:51,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:52,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:52,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:52,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:52,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:53,531][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.3492, device='cuda:0') eval_epoch_loss=tensor(0.2995, device='cuda:0') eval_epoch_acc=tensor(0.9288, device='cuda:0')
[2024-12-17 02:21:53,534][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-12-17 02:21:53,534][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 02:21:53,724][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_1_step_7132_loss_0.29954302310943604/model.pt
[2024-12-17 02:21:53,728][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 0.29954302310943604
[2024-12-17 02:21:53,729][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.9287700653076172
[2024-12-17 02:21:53,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:53,993][root][INFO] - Training Epoch: 1/2, step 7132/7134 completed (loss: 0.19994139671325684, acc: 0.9117646813392639)
[2024-12-17 02:21:54,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:54,263][root][INFO] - Training Epoch: 1/2, step 7133/7134 completed (loss: 0.19719815254211426, acc: 0.9398496150970459)
[2024-12-17 02:21:54,845][slam_llm.utils.train_utils][INFO] - Epoch 1: train_perplexity=9.0583, train_epoch_loss=2.2037, epoch time 2903.792117521167s
[2024-12-17 02:21:54,845][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 11 GB
[2024-12-17 02:21:54,845][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 21 GB
[2024-12-17 02:21:54,846][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 11 GB
[2024-12-17 02:21:54,846][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 0
[2024-12-17 02:21:54,846][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 7 GB
[2024-12-17 02:21:55,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:55,629][root][INFO] - Training Epoch: 2/2, step 0/7134 completed (loss: 0.3006308972835541, acc: 0.9294871687889099)
[2024-12-17 02:21:55,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:55,928][root][INFO] - Training Epoch: 2/2, step 1/7134 completed (loss: 0.2442343384027481, acc: 0.9235668778419495)
[2024-12-17 02:21:56,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:56,231][root][INFO] - Training Epoch: 2/2, step 2/7134 completed (loss: 0.19354309141635895, acc: 0.9545454382896423)
[2024-12-17 02:21:56,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:56,519][root][INFO] - Training Epoch: 2/2, step 3/7134 completed (loss: 0.19518838822841644, acc: 0.9476743936538696)
[2024-12-17 02:21:56,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:56,851][root][INFO] - Training Epoch: 2/2, step 4/7134 completed (loss: 0.23959115147590637, acc: 0.9622641801834106)
[2024-12-17 02:21:57,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:57,164][root][INFO] - Training Epoch: 2/2, step 5/7134 completed (loss: 0.11292925477027893, acc: 0.9664804339408875)
[2024-12-17 02:21:57,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:57,446][root][INFO] - Training Epoch: 2/2, step 6/7134 completed (loss: 0.0893649011850357, acc: 0.9647887349128723)
[2024-12-17 02:21:57,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:57,724][root][INFO] - Training Epoch: 2/2, step 7/7134 completed (loss: 0.1401001662015915, acc: 0.9623655676841736)
[2024-12-17 02:21:57,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:58,013][root][INFO] - Training Epoch: 2/2, step 8/7134 completed (loss: 0.23535078763961792, acc: 0.9512194991111755)
[2024-12-17 02:21:58,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:58,286][root][INFO] - Training Epoch: 2/2, step 9/7134 completed (loss: 0.09026598930358887, acc: 0.9801324605941772)
[2024-12-17 02:21:58,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:58,675][root][INFO] - Training Epoch: 2/2, step 10/7134 completed (loss: 0.1946437507867813, acc: 0.9467455744743347)
[2024-12-17 02:21:58,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:58,963][root][INFO] - Training Epoch: 2/2, step 11/7134 completed (loss: 0.1618693768978119, acc: 0.949999988079071)
[2024-12-17 02:21:59,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:59,250][root][INFO] - Training Epoch: 2/2, step 12/7134 completed (loss: 0.09864208102226257, acc: 0.9768785834312439)
[2024-12-17 02:21:59,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:59,523][root][INFO] - Training Epoch: 2/2, step 13/7134 completed (loss: 0.12203571945428848, acc: 0.9719101190567017)
[2024-12-17 02:21:59,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:59,817][root][INFO] - Training Epoch: 2/2, step 14/7134 completed (loss: 0.05497387424111366, acc: 0.9797297120094299)
[2024-12-17 02:21:59,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:00,093][root][INFO] - Training Epoch: 2/2, step 15/7134 completed (loss: 0.050219111144542694, acc: 1.0)
[2024-12-17 02:22:00,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:00,366][root][INFO] - Training Epoch: 2/2, step 16/7134 completed (loss: 0.035543277859687805, acc: 0.9912280440330505)
[2024-12-17 02:22:00,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:00,636][root][INFO] - Training Epoch: 2/2, step 17/7134 completed (loss: 0.19817762076854706, acc: 0.957446813583374)
[2024-12-17 02:22:00,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:00,921][root][INFO] - Training Epoch: 2/2, step 18/7134 completed (loss: 0.030267244204878807, acc: 0.9939758777618408)
[2024-12-17 02:22:01,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:01,203][root][INFO] - Training Epoch: 2/2, step 19/7134 completed (loss: 0.09756442159414291, acc: 0.9710982441902161)
[2024-12-17 02:22:01,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:01,496][root][INFO] - Training Epoch: 2/2, step 20/7134 completed (loss: 0.08425826579332352, acc: 0.9715909361839294)
[2024-12-17 02:22:01,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:01,798][root][INFO] - Training Epoch: 2/2, step 21/7134 completed (loss: 0.16327053308486938, acc: 0.9659090638160706)
[2024-12-17 02:22:01,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:02,073][root][INFO] - Training Epoch: 2/2, step 22/7134 completed (loss: 0.01159876212477684, acc: 1.0)
[2024-12-17 02:22:02,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:02,343][root][INFO] - Training Epoch: 2/2, step 23/7134 completed (loss: 0.053304143249988556, acc: 0.9887005686759949)
[2024-12-17 02:22:02,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:02,627][root][INFO] - Training Epoch: 2/2, step 24/7134 completed (loss: 0.05071718990802765, acc: 0.9944444298744202)
[2024-12-17 02:22:02,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:02,919][root][INFO] - Training Epoch: 2/2, step 25/7134 completed (loss: 0.06800655275583267, acc: 0.9881656765937805)
[2024-12-17 02:22:03,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:03,204][root][INFO] - Training Epoch: 2/2, step 26/7134 completed (loss: 0.21051493287086487, acc: 0.9325153231620789)
[2024-12-17 02:22:03,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:03,473][root][INFO] - Training Epoch: 2/2, step 27/7134 completed (loss: 0.038540881127119064, acc: 0.9871794581413269)
[2024-12-17 02:22:03,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:03,762][root][INFO] - Training Epoch: 2/2, step 28/7134 completed (loss: 0.27151408791542053, acc: 0.9390863180160522)
[2024-12-17 02:22:03,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:04,040][root][INFO] - Training Epoch: 2/2, step 29/7134 completed (loss: 0.2441004514694214, acc: 0.9585798978805542)
[2024-12-17 02:22:04,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:04,328][root][INFO] - Training Epoch: 2/2, step 30/7134 completed (loss: 0.20292125642299652, acc: 0.9323671460151672)
[2024-12-17 02:22:04,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:04,601][root][INFO] - Training Epoch: 2/2, step 31/7134 completed (loss: 0.2636972665786743, acc: 0.9581395387649536)
[2024-12-17 02:22:04,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:04,877][root][INFO] - Training Epoch: 2/2, step 32/7134 completed (loss: 0.40044891834259033, acc: 0.91847825050354)
[2024-12-17 02:22:04,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:05,141][root][INFO] - Training Epoch: 2/2, step 33/7134 completed (loss: 0.26936209201812744, acc: 0.9461538195610046)
[2024-12-17 02:22:05,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:05,436][root][INFO] - Training Epoch: 2/2, step 34/7134 completed (loss: 0.21963481605052948, acc: 0.9523809552192688)
[2024-12-17 02:22:05,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:05,741][root][INFO] - Training Epoch: 2/2, step 35/7134 completed (loss: 0.319906622171402, acc: 0.9215686321258545)
[2024-12-17 02:22:05,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:06,030][root][INFO] - Training Epoch: 2/2, step 36/7134 completed (loss: 0.24442274868488312, acc: 0.9447004795074463)
[2024-12-17 02:22:06,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:06,319][root][INFO] - Training Epoch: 2/2, step 37/7134 completed (loss: 0.2515774071216583, acc: 0.9259259104728699)
[2024-12-17 02:22:06,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:06,593][root][INFO] - Training Epoch: 2/2, step 38/7134 completed (loss: 0.19824069738388062, acc: 0.9433962106704712)
[2024-12-17 02:22:06,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:06,890][root][INFO] - Training Epoch: 2/2, step 39/7134 completed (loss: 0.07416140288114548, acc: 0.9824561476707458)
[2024-12-17 02:22:07,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:07,164][root][INFO] - Training Epoch: 2/2, step 40/7134 completed (loss: 0.11969078332185745, acc: 0.9910714030265808)
[2024-12-17 02:22:07,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:07,439][root][INFO] - Training Epoch: 2/2, step 41/7134 completed (loss: 0.19297660887241364, acc: 0.9680851101875305)
[2024-12-17 02:22:07,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:07,714][root][INFO] - Training Epoch: 2/2, step 42/7134 completed (loss: 0.18807202577590942, acc: 0.9629629850387573)
[2024-12-17 02:22:07,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:07,966][root][INFO] - Training Epoch: 2/2, step 43/7134 completed (loss: 0.04446151480078697, acc: 0.994413435459137)
[2024-12-17 02:22:08,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:08,249][root][INFO] - Training Epoch: 2/2, step 44/7134 completed (loss: 0.15373210608959198, acc: 0.9679144620895386)
[2024-12-17 02:22:08,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:08,543][root][INFO] - Training Epoch: 2/2, step 45/7134 completed (loss: 0.20291036367416382, acc: 0.9528301954269409)
[2024-12-17 02:22:08,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:08,817][root][INFO] - Training Epoch: 2/2, step 46/7134 completed (loss: 0.21563497185707092, acc: 0.9593023061752319)
[2024-12-17 02:22:08,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:09,116][root][INFO] - Training Epoch: 2/2, step 47/7134 completed (loss: 0.13908879458904266, acc: 0.9608938694000244)
[2024-12-17 02:22:09,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:09,420][root][INFO] - Training Epoch: 2/2, step 48/7134 completed (loss: 0.12420916557312012, acc: 0.9710144996643066)
[2024-12-17 02:22:09,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:09,714][root][INFO] - Training Epoch: 2/2, step 49/7134 completed (loss: 0.19947168231010437, acc: 0.9588235020637512)
[2024-12-17 02:22:09,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:10,022][root][INFO] - Training Epoch: 2/2, step 50/7134 completed (loss: 0.12328094244003296, acc: 0.9660193920135498)
[2024-12-17 02:22:10,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:10,323][root][INFO] - Training Epoch: 2/2, step 51/7134 completed (loss: 0.17173877358436584, acc: 0.9642857313156128)
[2024-12-17 02:22:10,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:10,575][root][INFO] - Training Epoch: 2/2, step 52/7134 completed (loss: 0.056039582937955856, acc: 1.0)
[2024-12-17 02:22:10,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:10,840][root][INFO] - Training Epoch: 2/2, step 53/7134 completed (loss: 0.17311252653598785, acc: 0.9729729890823364)
[2024-12-17 02:22:10,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:11,126][root][INFO] - Training Epoch: 2/2, step 54/7134 completed (loss: 0.0886620506644249, acc: 0.9857142567634583)
[2024-12-17 02:22:11,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:11,430][root][INFO] - Training Epoch: 2/2, step 55/7134 completed (loss: 0.26639941334724426, acc: 0.945652186870575)
[2024-12-17 02:22:11,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:11,728][root][INFO] - Training Epoch: 2/2, step 56/7134 completed (loss: 0.08875378966331482, acc: 0.9769230484962463)
[2024-12-17 02:22:11,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:12,027][root][INFO] - Training Epoch: 2/2, step 57/7134 completed (loss: 0.4084174931049347, acc: 0.9120879173278809)
[2024-12-17 02:22:12,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:12,322][root][INFO] - Training Epoch: 2/2, step 58/7134 completed (loss: 0.2079261839389801, acc: 0.9497206807136536)
[2024-12-17 02:22:12,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:12,614][root][INFO] - Training Epoch: 2/2, step 59/7134 completed (loss: 0.11782100796699524, acc: 0.9786096215248108)
[2024-12-17 02:22:12,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:12,916][root][INFO] - Training Epoch: 2/2, step 60/7134 completed (loss: 0.22080177068710327, acc: 0.9367088675498962)
[2024-12-17 02:22:13,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:13,192][root][INFO] - Training Epoch: 2/2, step 61/7134 completed (loss: 0.22806484997272491, acc: 0.9608938694000244)
[2024-12-17 02:22:13,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:13,481][root][INFO] - Training Epoch: 2/2, step 62/7134 completed (loss: 0.33263131976127625, acc: 0.9213483333587646)
[2024-12-17 02:22:13,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:13,769][root][INFO] - Training Epoch: 2/2, step 63/7134 completed (loss: 0.28269708156585693, acc: 0.9285714030265808)
[2024-12-17 02:22:13,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:14,060][root][INFO] - Training Epoch: 2/2, step 64/7134 completed (loss: 0.3299552798271179, acc: 0.9176470637321472)
[2024-12-17 02:22:14,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:14,377][root][INFO] - Training Epoch: 2/2, step 65/7134 completed (loss: 0.43615487217903137, acc: 0.8776595592498779)
[2024-12-17 02:22:14,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:14,688][root][INFO] - Training Epoch: 2/2, step 66/7134 completed (loss: 0.3416515290737152, acc: 0.9242424368858337)
[2024-12-17 02:22:14,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:15,002][root][INFO] - Training Epoch: 2/2, step 67/7134 completed (loss: 0.300250381231308, acc: 0.9080459475517273)
[2024-12-17 02:22:15,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:15,295][root][INFO] - Training Epoch: 2/2, step 68/7134 completed (loss: 0.36594340205192566, acc: 0.9213483333587646)
[2024-12-17 02:22:15,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:15,584][root][INFO] - Training Epoch: 2/2, step 69/7134 completed (loss: 0.2973904609680176, acc: 0.920634925365448)
[2024-12-17 02:22:15,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:15,864][root][INFO] - Training Epoch: 2/2, step 70/7134 completed (loss: 0.2700406014919281, acc: 0.9453125)
[2024-12-17 02:22:15,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:16,140][root][INFO] - Training Epoch: 2/2, step 71/7134 completed (loss: 0.2491276115179062, acc: 0.9454545378684998)
[2024-12-17 02:22:16,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:16,428][root][INFO] - Training Epoch: 2/2, step 72/7134 completed (loss: 0.14222821593284607, acc: 0.9704142212867737)
[2024-12-17 02:22:16,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:16,720][root][INFO] - Training Epoch: 2/2, step 73/7134 completed (loss: 0.13657626509666443, acc: 0.9710982441902161)
[2024-12-17 02:22:16,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:17,010][root][INFO] - Training Epoch: 2/2, step 74/7134 completed (loss: 0.12849198281764984, acc: 0.9709302186965942)
[2024-12-17 02:22:17,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:17,304][root][INFO] - Training Epoch: 2/2, step 75/7134 completed (loss: 0.3739287257194519, acc: 0.9285714030265808)
[2024-12-17 02:22:17,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:17,581][root][INFO] - Training Epoch: 2/2, step 76/7134 completed (loss: 0.2762586772441864, acc: 0.945652186870575)
[2024-12-17 02:22:17,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:17,862][root][INFO] - Training Epoch: 2/2, step 77/7134 completed (loss: 0.29110491275787354, acc: 0.9558011293411255)
[2024-12-17 02:22:18,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:18,160][root][INFO] - Training Epoch: 2/2, step 78/7134 completed (loss: 0.3628798723220825, acc: 0.9139072895050049)
[2024-12-17 02:22:18,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:18,442][root][INFO] - Training Epoch: 2/2, step 79/7134 completed (loss: 0.4371330142021179, acc: 0.9200000166893005)
[2024-12-17 02:22:18,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:18,726][root][INFO] - Training Epoch: 2/2, step 80/7134 completed (loss: 0.24079181253910065, acc: 0.9550561904907227)
[2024-12-17 02:22:18,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:19,010][root][INFO] - Training Epoch: 2/2, step 81/7134 completed (loss: 0.22802114486694336, acc: 0.9470899701118469)
[2024-12-17 02:22:19,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:19,305][root][INFO] - Training Epoch: 2/2, step 82/7134 completed (loss: 0.2119280993938446, acc: 0.9457831382751465)
[2024-12-17 02:22:19,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:19,592][root][INFO] - Training Epoch: 2/2, step 83/7134 completed (loss: 0.19883021712303162, acc: 0.9627659320831299)
[2024-12-17 02:22:19,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:19,882][root][INFO] - Training Epoch: 2/2, step 84/7134 completed (loss: 0.33592739701271057, acc: 0.9064748287200928)
[2024-12-17 02:22:20,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:20,195][root][INFO] - Training Epoch: 2/2, step 85/7134 completed (loss: 0.5942327380180359, acc: 0.8799999952316284)
[2024-12-17 02:22:20,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:20,475][root][INFO] - Training Epoch: 2/2, step 86/7134 completed (loss: 0.404608815908432, acc: 0.8660714030265808)
[2024-12-17 02:22:20,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:20,767][root][INFO] - Training Epoch: 2/2, step 87/7134 completed (loss: 0.5723311901092529, acc: 0.8961039185523987)
[2024-12-17 02:22:20,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:21,061][root][INFO] - Training Epoch: 2/2, step 88/7134 completed (loss: 0.394279420375824, acc: 0.9096385836601257)
[2024-12-17 02:22:21,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:21,348][root][INFO] - Training Epoch: 2/2, step 89/7134 completed (loss: 0.31402164697647095, acc: 0.9371428489685059)
[2024-12-17 02:22:21,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:21,626][root][INFO] - Training Epoch: 2/2, step 90/7134 completed (loss: 0.3382534980773926, acc: 0.9075630307197571)
[2024-12-17 02:22:21,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:21,910][root][INFO] - Training Epoch: 2/2, step 91/7134 completed (loss: 0.29318979382514954, acc: 0.9173553586006165)
[2024-12-17 02:22:22,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:22,204][root][INFO] - Training Epoch: 2/2, step 92/7134 completed (loss: 0.23160146176815033, acc: 0.9415584206581116)
[2024-12-17 02:22:22,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:22,484][root][INFO] - Training Epoch: 2/2, step 93/7134 completed (loss: 0.2354380339384079, acc: 0.9428571462631226)
[2024-12-17 02:22:22,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:22,767][root][INFO] - Training Epoch: 2/2, step 94/7134 completed (loss: 0.33783432841300964, acc: 0.9245283007621765)
[2024-12-17 02:22:22,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:23,063][root][INFO] - Training Epoch: 2/2, step 95/7134 completed (loss: 0.20808158814907074, acc: 0.9390243887901306)
[2024-12-17 02:22:23,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:23,337][root][INFO] - Training Epoch: 2/2, step 96/7134 completed (loss: 0.15109233558177948, acc: 0.9532710313796997)
[2024-12-17 02:22:23,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:23,571][root][INFO] - Training Epoch: 2/2, step 97/7134 completed (loss: 1.2102936506271362, acc: 0.761904776096344)
[2024-12-17 02:22:23,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:23,856][root][INFO] - Training Epoch: 2/2, step 98/7134 completed (loss: 0.4699181020259857, acc: 0.8873239159584045)
[2024-12-17 02:22:23,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:24,130][root][INFO] - Training Epoch: 2/2, step 99/7134 completed (loss: 0.3758905827999115, acc: 0.8999999761581421)
[2024-12-17 02:22:24,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:24,428][root][INFO] - Training Epoch: 2/2, step 100/7134 completed (loss: 0.3838964104652405, acc: 0.90055251121521)
[2024-12-17 02:22:24,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:24,693][root][INFO] - Training Epoch: 2/2, step 101/7134 completed (loss: 0.3527127504348755, acc: 0.921875)
[2024-12-17 02:22:24,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:24,977][root][INFO] - Training Epoch: 2/2, step 102/7134 completed (loss: 0.18298685550689697, acc: 0.9453551769256592)
[2024-12-17 02:22:25,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:25,242][root][INFO] - Training Epoch: 2/2, step 103/7134 completed (loss: 0.2929147183895111, acc: 0.9178082346916199)
[2024-12-17 02:22:25,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:25,520][root][INFO] - Training Epoch: 2/2, step 104/7134 completed (loss: 0.10219307243824005, acc: 0.9733333587646484)
[2024-12-17 02:22:25,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:25,801][root][INFO] - Training Epoch: 2/2, step 105/7134 completed (loss: 0.11573738604784012, acc: 0.9701492786407471)
[2024-12-17 02:22:25,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:26,080][root][INFO] - Training Epoch: 2/2, step 106/7134 completed (loss: 0.16548193991184235, acc: 0.95652174949646)
[2024-12-17 02:22:26,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:26,360][root][INFO] - Training Epoch: 2/2, step 107/7134 completed (loss: 0.6147308945655823, acc: 0.8430232405662537)
[2024-12-17 02:22:26,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:26,665][root][INFO] - Training Epoch: 2/2, step 108/7134 completed (loss: 0.22648200392723083, acc: 0.9513513445854187)
[2024-12-17 02:22:26,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:26,920][root][INFO] - Training Epoch: 2/2, step 109/7134 completed (loss: 0.36926475167274475, acc: 0.9126983880996704)
[2024-12-17 02:22:27,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:27,212][root][INFO] - Training Epoch: 2/2, step 110/7134 completed (loss: 0.2195192277431488, acc: 0.9497206807136536)
[2024-12-17 02:22:27,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:27,477][root][INFO] - Training Epoch: 2/2, step 111/7134 completed (loss: 0.43240582942962646, acc: 0.9242424368858337)
[2024-12-17 02:22:27,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:27,734][root][INFO] - Training Epoch: 2/2, step 112/7134 completed (loss: 0.31532084941864014, acc: 0.9097222089767456)
[2024-12-17 02:22:27,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:28,010][root][INFO] - Training Epoch: 2/2, step 113/7134 completed (loss: 0.10609599202871323, acc: 0.9720670580863953)
[2024-12-17 02:22:28,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:28,282][root][INFO] - Training Epoch: 2/2, step 114/7134 completed (loss: 0.2617010176181793, acc: 0.9085714221000671)
[2024-12-17 02:22:28,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:28,543][root][INFO] - Training Epoch: 2/2, step 115/7134 completed (loss: 0.4869847297668457, acc: 0.8811880946159363)
[2024-12-17 02:22:28,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:28,839][root][INFO] - Training Epoch: 2/2, step 116/7134 completed (loss: 0.36348727345466614, acc: 0.9022988677024841)
[2024-12-17 02:22:28,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:29,128][root][INFO] - Training Epoch: 2/2, step 117/7134 completed (loss: 0.1928202360868454, acc: 0.9333333373069763)
[2024-12-17 02:22:29,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:29,460][root][INFO] - Training Epoch: 2/2, step 118/7134 completed (loss: 0.3110458254814148, acc: 0.9277777671813965)
[2024-12-17 02:22:29,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:29,741][root][INFO] - Training Epoch: 2/2, step 119/7134 completed (loss: 0.24834132194519043, acc: 0.9308510422706604)
[2024-12-17 02:22:29,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:30,022][root][INFO] - Training Epoch: 2/2, step 120/7134 completed (loss: 0.17604458332061768, acc: 0.9464285969734192)
[2024-12-17 02:22:30,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:30,296][root][INFO] - Training Epoch: 2/2, step 121/7134 completed (loss: 0.17058993875980377, acc: 0.9385474920272827)
[2024-12-17 02:22:30,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:30,589][root][INFO] - Training Epoch: 2/2, step 122/7134 completed (loss: 0.1138928160071373, acc: 0.9670329689979553)
[2024-12-17 02:22:30,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:30,848][root][INFO] - Training Epoch: 2/2, step 123/7134 completed (loss: 0.2515460252761841, acc: 0.955974817276001)
[2024-12-17 02:22:30,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:31,130][root][INFO] - Training Epoch: 2/2, step 124/7134 completed (loss: 0.31469500064849854, acc: 0.9305555820465088)
[2024-12-17 02:22:31,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:31,426][root][INFO] - Training Epoch: 2/2, step 125/7134 completed (loss: 0.3645908236503601, acc: 0.9019607901573181)
[2024-12-17 02:22:31,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:31,702][root][INFO] - Training Epoch: 2/2, step 126/7134 completed (loss: 0.24226132035255432, acc: 0.9202127456665039)
[2024-12-17 02:22:31,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:32,000][root][INFO] - Training Epoch: 2/2, step 127/7134 completed (loss: 0.3139866292476654, acc: 0.9114583134651184)
[2024-12-17 02:22:32,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:32,305][root][INFO] - Training Epoch: 2/2, step 128/7134 completed (loss: 0.27630576491355896, acc: 0.9473684430122375)
[2024-12-17 02:22:32,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:32,593][root][INFO] - Training Epoch: 2/2, step 129/7134 completed (loss: 0.2871978282928467, acc: 0.9217877388000488)
[2024-12-17 02:22:32,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:32,869][root][INFO] - Training Epoch: 2/2, step 130/7134 completed (loss: 0.22047416865825653, acc: 0.9235293865203857)
[2024-12-17 02:22:33,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:33,147][root][INFO] - Training Epoch: 2/2, step 131/7134 completed (loss: 0.11808896064758301, acc: 0.9707602262496948)
[2024-12-17 02:22:33,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:33,431][root][INFO] - Training Epoch: 2/2, step 132/7134 completed (loss: 0.3656240403652191, acc: 0.9056603908538818)
[2024-12-17 02:22:33,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:33,703][root][INFO] - Training Epoch: 2/2, step 133/7134 completed (loss: 0.24841201305389404, acc: 0.9485294222831726)
[2024-12-17 02:22:33,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:33,980][root][INFO] - Training Epoch: 2/2, step 134/7134 completed (loss: 0.13275422155857086, acc: 0.969924807548523)
[2024-12-17 02:22:34,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:34,270][root][INFO] - Training Epoch: 2/2, step 135/7134 completed (loss: 0.27795976400375366, acc: 0.9259259104728699)
[2024-12-17 02:22:34,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:34,551][root][INFO] - Training Epoch: 2/2, step 136/7134 completed (loss: 0.21564897894859314, acc: 0.9402173757553101)
[2024-12-17 02:22:34,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:34,833][root][INFO] - Training Epoch: 2/2, step 137/7134 completed (loss: 0.2414880096912384, acc: 0.9447236061096191)
[2024-12-17 02:22:34,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:35,115][root][INFO] - Training Epoch: 2/2, step 138/7134 completed (loss: 0.25897276401519775, acc: 0.9193548560142517)
[2024-12-17 02:22:35,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:35,413][root][INFO] - Training Epoch: 2/2, step 139/7134 completed (loss: 0.20331309735774994, acc: 0.9521276354789734)
[2024-12-17 02:22:35,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:35,711][root][INFO] - Training Epoch: 2/2, step 140/7134 completed (loss: 0.17756183445453644, acc: 0.9509202241897583)
[2024-12-17 02:22:35,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:36,015][root][INFO] - Training Epoch: 2/2, step 141/7134 completed (loss: 0.17410944402217865, acc: 0.9549999833106995)
[2024-12-17 02:22:36,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:36,302][root][INFO] - Training Epoch: 2/2, step 142/7134 completed (loss: 0.3287632167339325, acc: 0.9209039807319641)
[2024-12-17 02:22:36,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:36,581][root][INFO] - Training Epoch: 2/2, step 143/7134 completed (loss: 0.3124745488166809, acc: 0.9116021990776062)
[2024-12-17 02:22:36,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:36,865][root][INFO] - Training Epoch: 2/2, step 144/7134 completed (loss: 0.40608277916908264, acc: 0.8986486196517944)
[2024-12-17 02:22:36,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:37,131][root][INFO] - Training Epoch: 2/2, step 145/7134 completed (loss: 0.5818400382995605, acc: 0.8445596098899841)
[2024-12-17 02:22:37,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:37,410][root][INFO] - Training Epoch: 2/2, step 146/7134 completed (loss: 0.41920194029808044, acc: 0.903954803943634)
[2024-12-17 02:22:37,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:37,665][root][INFO] - Training Epoch: 2/2, step 147/7134 completed (loss: 0.49271777272224426, acc: 0.9034482836723328)
[2024-12-17 02:22:37,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:37,947][root][INFO] - Training Epoch: 2/2, step 148/7134 completed (loss: 0.762776792049408, acc: 0.7983871102333069)
[2024-12-17 02:22:38,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:38,227][root][INFO] - Training Epoch: 2/2, step 149/7134 completed (loss: 0.5619238615036011, acc: 0.8832487463951111)
[2024-12-17 02:22:38,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:38,516][root][INFO] - Training Epoch: 2/2, step 150/7134 completed (loss: 0.5732117295265198, acc: 0.8952879309654236)
[2024-12-17 02:22:38,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:38,796][root][INFO] - Training Epoch: 2/2, step 151/7134 completed (loss: 0.3678743541240692, acc: 0.9032257795333862)
[2024-12-17 02:22:38,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:39,075][root][INFO] - Training Epoch: 2/2, step 152/7134 completed (loss: 0.30400168895721436, acc: 0.9473684430122375)
[2024-12-17 02:22:39,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:39,353][root][INFO] - Training Epoch: 2/2, step 153/7134 completed (loss: 0.535886824131012, acc: 0.8839778900146484)
[2024-12-17 02:22:39,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:39,622][root][INFO] - Training Epoch: 2/2, step 154/7134 completed (loss: 0.4817977547645569, acc: 0.8888888955116272)
[2024-12-17 02:22:39,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:39,907][root][INFO] - Training Epoch: 2/2, step 155/7134 completed (loss: 0.4119108021259308, acc: 0.9125683307647705)
[2024-12-17 02:22:40,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:40,197][root][INFO] - Training Epoch: 2/2, step 156/7134 completed (loss: 0.22503523528575897, acc: 0.931034505367279)
[2024-12-17 02:22:40,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:40,490][root][INFO] - Training Epoch: 2/2, step 157/7134 completed (loss: 0.5770963430404663, acc: 0.8888888955116272)
[2024-12-17 02:22:40,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:40,795][root][INFO] - Training Epoch: 2/2, step 158/7134 completed (loss: 0.2651538848876953, acc: 0.9298245906829834)
[2024-12-17 02:22:40,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:41,089][root][INFO] - Training Epoch: 2/2, step 159/7134 completed (loss: 0.3673495054244995, acc: 0.9364162087440491)
[2024-12-17 02:22:41,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:41,386][root][INFO] - Training Epoch: 2/2, step 160/7134 completed (loss: 0.3388665020465851, acc: 0.8983050584793091)
[2024-12-17 02:22:41,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:41,663][root][INFO] - Training Epoch: 2/2, step 161/7134 completed (loss: 0.09170369058847427, acc: 0.9729729890823364)
[2024-12-17 02:22:41,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:41,969][root][INFO] - Training Epoch: 2/2, step 162/7134 completed (loss: 0.12064684182405472, acc: 0.9506173133850098)
[2024-12-17 02:22:42,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:42,269][root][INFO] - Training Epoch: 2/2, step 163/7134 completed (loss: 0.13174518942832947, acc: 0.9568345546722412)
[2024-12-17 02:22:42,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:42,558][root][INFO] - Training Epoch: 2/2, step 164/7134 completed (loss: 0.35898357629776, acc: 0.9494949579238892)
[2024-12-17 02:22:42,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:42,822][root][INFO] - Training Epoch: 2/2, step 165/7134 completed (loss: 0.1540910005569458, acc: 0.9599999785423279)
[2024-12-17 02:22:42,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:43,082][root][INFO] - Training Epoch: 2/2, step 166/7134 completed (loss: 0.14906108379364014, acc: 0.9868420958518982)
[2024-12-17 02:22:43,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:43,360][root][INFO] - Training Epoch: 2/2, step 167/7134 completed (loss: 1.6872942447662354, acc: 0.6746987700462341)
[2024-12-17 02:22:43,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:43,650][root][INFO] - Training Epoch: 2/2, step 168/7134 completed (loss: 3.079578399658203, acc: 0.38181817531585693)
[2024-12-17 02:22:43,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:43,907][root][INFO] - Training Epoch: 2/2, step 169/7134 completed (loss: 2.7237050533294678, acc: 0.5078125)
[2024-12-17 02:22:44,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:44,186][root][INFO] - Training Epoch: 2/2, step 170/7134 completed (loss: 1.8389580249786377, acc: 0.6428571343421936)
[2024-12-17 02:22:44,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:44,454][root][INFO] - Training Epoch: 2/2, step 171/7134 completed (loss: 2.0642855167388916, acc: 0.6534653306007385)
[2024-12-17 02:22:44,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:44,740][root][INFO] - Training Epoch: 2/2, step 172/7134 completed (loss: 0.7751198410987854, acc: 0.8449612259864807)
[2024-12-17 02:22:44,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:45,032][root][INFO] - Training Epoch: 2/2, step 173/7134 completed (loss: 0.8223190307617188, acc: 0.7680000066757202)
[2024-12-17 02:22:45,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:45,318][root][INFO] - Training Epoch: 2/2, step 174/7134 completed (loss: 1.0531091690063477, acc: 0.7631579041481018)
[2024-12-17 02:22:45,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:45,598][root][INFO] - Training Epoch: 2/2, step 175/7134 completed (loss: 0.7124965190887451, acc: 0.7880794405937195)
[2024-12-17 02:22:45,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:45,893][root][INFO] - Training Epoch: 2/2, step 176/7134 completed (loss: 0.7924376726150513, acc: 0.7704917788505554)
[2024-12-17 02:22:46,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:46,166][root][INFO] - Training Epoch: 2/2, step 177/7134 completed (loss: 0.9145062565803528, acc: 0.8143712282180786)
[2024-12-17 02:22:46,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:46,436][root][INFO] - Training Epoch: 2/2, step 178/7134 completed (loss: 0.6592411994934082, acc: 0.8701298832893372)
[2024-12-17 02:22:46,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:46,711][root][INFO] - Training Epoch: 2/2, step 179/7134 completed (loss: 0.2911975383758545, acc: 0.9270073175430298)
[2024-12-17 02:22:46,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:46,994][root][INFO] - Training Epoch: 2/2, step 180/7134 completed (loss: 0.37092164158821106, acc: 0.9328858852386475)
[2024-12-17 02:22:47,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:47,282][root][INFO] - Training Epoch: 2/2, step 181/7134 completed (loss: 0.1795773059129715, acc: 0.9655172228813171)
[2024-12-17 02:22:47,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:47,576][root][INFO] - Training Epoch: 2/2, step 182/7134 completed (loss: 0.19963639974594116, acc: 0.9440993666648865)
[2024-12-17 02:22:47,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:47,860][root][INFO] - Training Epoch: 2/2, step 183/7134 completed (loss: 0.19514673948287964, acc: 0.9383561611175537)
[2024-12-17 02:22:47,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:48,134][root][INFO] - Training Epoch: 2/2, step 184/7134 completed (loss: 0.3083660304546356, acc: 0.921875)
[2024-12-17 02:22:48,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:48,419][root][INFO] - Training Epoch: 2/2, step 185/7134 completed (loss: 0.19559510052204132, acc: 0.9455782175064087)
[2024-12-17 02:22:48,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:48,699][root][INFO] - Training Epoch: 2/2, step 186/7134 completed (loss: 0.363494336605072, acc: 0.9179104566574097)
[2024-12-17 02:22:48,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:48,978][root][INFO] - Training Epoch: 2/2, step 187/7134 completed (loss: 0.28316736221313477, acc: 0.9281045794487)
[2024-12-17 02:22:49,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:49,263][root][INFO] - Training Epoch: 2/2, step 188/7134 completed (loss: 0.41086074709892273, acc: 0.8780487775802612)
[2024-12-17 02:22:49,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:49,526][root][INFO] - Training Epoch: 2/2, step 189/7134 completed (loss: 0.3862675130367279, acc: 0.9098360538482666)
[2024-12-17 02:22:49,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:49,826][root][INFO] - Training Epoch: 2/2, step 190/7134 completed (loss: 0.5418409109115601, acc: 0.858208954334259)
[2024-12-17 02:22:49,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:50,097][root][INFO] - Training Epoch: 2/2, step 191/7134 completed (loss: 0.40051284432411194, acc: 0.9134615659713745)
[2024-12-17 02:22:50,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:50,411][root][INFO] - Training Epoch: 2/2, step 192/7134 completed (loss: 0.1717837005853653, acc: 0.9534883499145508)
[2024-12-17 02:22:50,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:50,725][root][INFO] - Training Epoch: 2/2, step 193/7134 completed (loss: 0.31840208172798157, acc: 0.916167676448822)
[2024-12-17 02:22:50,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:51,027][root][INFO] - Training Epoch: 2/2, step 194/7134 completed (loss: 0.5986538529396057, acc: 0.8742138147354126)
[2024-12-17 02:22:51,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:51,332][root][INFO] - Training Epoch: 2/2, step 195/7134 completed (loss: 0.40566930174827576, acc: 0.90625)
[2024-12-17 02:22:51,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:51,626][root][INFO] - Training Epoch: 2/2, step 196/7134 completed (loss: 0.49186971783638, acc: 0.8770949840545654)
[2024-12-17 02:22:51,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:51,926][root][INFO] - Training Epoch: 2/2, step 197/7134 completed (loss: 0.24552245438098907, acc: 0.9527027010917664)
[2024-12-17 02:22:52,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:52,229][root][INFO] - Training Epoch: 2/2, step 198/7134 completed (loss: 0.2381952404975891, acc: 0.9299362897872925)
[2024-12-17 02:22:52,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:52,530][root][INFO] - Training Epoch: 2/2, step 199/7134 completed (loss: 0.46064528822898865, acc: 0.904411792755127)
[2024-12-17 02:22:52,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:52,842][root][INFO] - Training Epoch: 2/2, step 200/7134 completed (loss: 0.19835105538368225, acc: 0.9523809552192688)
[2024-12-17 02:22:52,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:53,167][root][INFO] - Training Epoch: 2/2, step 201/7134 completed (loss: 0.10933578759431839, acc: 0.9858155846595764)
[2024-12-17 02:22:53,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:53,455][root][INFO] - Training Epoch: 2/2, step 202/7134 completed (loss: 0.3532373011112213, acc: 0.9096774458885193)
[2024-12-17 02:22:53,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:53,738][root][INFO] - Training Epoch: 2/2, step 203/7134 completed (loss: 0.41967466473579407, acc: 0.8994082808494568)
[2024-12-17 02:22:53,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:54,010][root][INFO] - Training Epoch: 2/2, step 204/7134 completed (loss: 0.47598400712013245, acc: 0.8616352081298828)
[2024-12-17 02:22:54,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:54,290][root][INFO] - Training Epoch: 2/2, step 205/7134 completed (loss: 0.4480482041835785, acc: 0.8949999809265137)
[2024-12-17 02:22:54,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:54,589][root][INFO] - Training Epoch: 2/2, step 206/7134 completed (loss: 0.32691678404808044, acc: 0.9166666865348816)
[2024-12-17 02:22:54,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:54,860][root][INFO] - Training Epoch: 2/2, step 207/7134 completed (loss: 0.3851637840270996, acc: 0.918367326259613)
[2024-12-17 02:22:54,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:55,139][root][INFO] - Training Epoch: 2/2, step 208/7134 completed (loss: 0.7794344425201416, acc: 0.8642857074737549)
[2024-12-17 02:22:55,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:55,417][root][INFO] - Training Epoch: 2/2, step 209/7134 completed (loss: 0.8268514275550842, acc: 0.8156424760818481)
[2024-12-17 02:22:55,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:55,729][root][INFO] - Training Epoch: 2/2, step 210/7134 completed (loss: 0.5828139781951904, acc: 0.8678414225578308)
[2024-12-17 02:22:55,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:56,003][root][INFO] - Training Epoch: 2/2, step 211/7134 completed (loss: 0.5325571894645691, acc: 0.8918918967247009)
[2024-12-17 02:22:56,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:56,277][root][INFO] - Training Epoch: 2/2, step 212/7134 completed (loss: 0.7183576822280884, acc: 0.8347107172012329)
[2024-12-17 02:22:56,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:56,547][root][INFO] - Training Epoch: 2/2, step 213/7134 completed (loss: 0.6539922952651978, acc: 0.846666693687439)
[2024-12-17 02:22:56,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:56,823][root][INFO] - Training Epoch: 2/2, step 214/7134 completed (loss: 0.250678688287735, acc: 0.9405940771102905)
[2024-12-17 02:22:56,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:57,096][root][INFO] - Training Epoch: 2/2, step 215/7134 completed (loss: 0.3796772360801697, acc: 0.9142857193946838)
[2024-12-17 02:22:57,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:57,365][root][INFO] - Training Epoch: 2/2, step 216/7134 completed (loss: 0.23426364362239838, acc: 0.9213483333587646)
[2024-12-17 02:22:57,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:57,649][root][INFO] - Training Epoch: 2/2, step 217/7134 completed (loss: 0.32466360926628113, acc: 0.9270833134651184)
[2024-12-17 02:22:57,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:57,924][root][INFO] - Training Epoch: 2/2, step 218/7134 completed (loss: 0.20414146780967712, acc: 0.9465240836143494)
[2024-12-17 02:22:58,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:58,204][root][INFO] - Training Epoch: 2/2, step 219/7134 completed (loss: 0.16925707459449768, acc: 0.9561403393745422)
[2024-12-17 02:22:58,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:58,467][root][INFO] - Training Epoch: 2/2, step 220/7134 completed (loss: 0.17887376248836517, acc: 0.9652174115180969)
[2024-12-17 02:22:58,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:58,748][root][INFO] - Training Epoch: 2/2, step 221/7134 completed (loss: 0.2136070430278778, acc: 0.956250011920929)
[2024-12-17 02:22:58,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:59,048][root][INFO] - Training Epoch: 2/2, step 222/7134 completed (loss: 0.25431543588638306, acc: 0.9479768872261047)
[2024-12-17 02:22:59,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:59,330][root][INFO] - Training Epoch: 2/2, step 223/7134 completed (loss: 0.4026426672935486, acc: 0.9027026891708374)
[2024-12-17 02:22:59,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:59,603][root][INFO] - Training Epoch: 2/2, step 224/7134 completed (loss: 0.517479658126831, acc: 0.8882681727409363)
[2024-12-17 02:22:59,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:59,880][root][INFO] - Training Epoch: 2/2, step 225/7134 completed (loss: 0.4707547128200531, acc: 0.88165682554245)
[2024-12-17 02:22:59,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:00,158][root][INFO] - Training Epoch: 2/2, step 226/7134 completed (loss: 0.23977410793304443, acc: 0.9485714435577393)
[2024-12-17 02:23:00,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:00,432][root][INFO] - Training Epoch: 2/2, step 227/7134 completed (loss: 0.4459899365901947, acc: 0.8936170339584351)
[2024-12-17 02:23:00,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:00,722][root][INFO] - Training Epoch: 2/2, step 228/7134 completed (loss: 0.45876356959342957, acc: 0.8802395462989807)
[2024-12-17 02:23:00,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:00,998][root][INFO] - Training Epoch: 2/2, step 229/7134 completed (loss: 0.46529707312583923, acc: 0.8742856979370117)
[2024-12-17 02:23:01,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:01,278][root][INFO] - Training Epoch: 2/2, step 230/7134 completed (loss: 0.25591596961021423, acc: 0.9281768202781677)
[2024-12-17 02:23:01,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:01,556][root][INFO] - Training Epoch: 2/2, step 231/7134 completed (loss: 0.30676230788230896, acc: 0.9473684430122375)
[2024-12-17 02:23:01,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:01,847][root][INFO] - Training Epoch: 2/2, step 232/7134 completed (loss: 0.3243851065635681, acc: 0.9370629191398621)
[2024-12-17 02:23:01,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:02,133][root][INFO] - Training Epoch: 2/2, step 233/7134 completed (loss: 0.26231861114501953, acc: 0.9343065619468689)
[2024-12-17 02:23:02,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:02,415][root][INFO] - Training Epoch: 2/2, step 234/7134 completed (loss: 0.3080368936061859, acc: 0.922535240650177)
[2024-12-17 02:23:02,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:02,703][root][INFO] - Training Epoch: 2/2, step 235/7134 completed (loss: 0.362586110830307, acc: 0.9207317233085632)
[2024-12-17 02:23:02,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:02,982][root][INFO] - Training Epoch: 2/2, step 236/7134 completed (loss: 0.23124302923679352, acc: 0.9337748289108276)
[2024-12-17 02:23:03,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:03,262][root][INFO] - Training Epoch: 2/2, step 237/7134 completed (loss: 0.37876588106155396, acc: 0.8980891704559326)
[2024-12-17 02:23:03,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:03,522][root][INFO] - Training Epoch: 2/2, step 238/7134 completed (loss: 0.5575360059738159, acc: 0.9083969593048096)
[2024-12-17 02:23:03,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:03,779][root][INFO] - Training Epoch: 2/2, step 239/7134 completed (loss: 0.2947234809398651, acc: 0.9433962106704712)
[2024-12-17 02:23:03,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:04,051][root][INFO] - Training Epoch: 2/2, step 240/7134 completed (loss: 0.27963075041770935, acc: 0.9514563083648682)
[2024-12-17 02:23:04,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:04,330][root][INFO] - Training Epoch: 2/2, step 241/7134 completed (loss: 0.5730897784233093, acc: 0.8656716346740723)
[2024-12-17 02:23:04,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:04,589][root][INFO] - Training Epoch: 2/2, step 242/7134 completed (loss: 0.6476394534111023, acc: 0.8724831938743591)
[2024-12-17 02:23:04,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:04,854][root][INFO] - Training Epoch: 2/2, step 243/7134 completed (loss: 0.9144369959831238, acc: 0.8068965673446655)
[2024-12-17 02:23:04,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:05,112][root][INFO] - Training Epoch: 2/2, step 244/7134 completed (loss: 0.258011132478714, acc: 0.935251772403717)
[2024-12-17 02:23:05,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:05,384][root][INFO] - Training Epoch: 2/2, step 245/7134 completed (loss: 0.3670218586921692, acc: 0.9180327653884888)
[2024-12-17 02:23:05,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:05,653][root][INFO] - Training Epoch: 2/2, step 246/7134 completed (loss: 0.2603137791156769, acc: 0.9347826242446899)
[2024-12-17 02:23:05,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:05,927][root][INFO] - Training Epoch: 2/2, step 247/7134 completed (loss: 0.29869014024734497, acc: 0.9285714030265808)
[2024-12-17 02:23:06,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:06,216][root][INFO] - Training Epoch: 2/2, step 248/7134 completed (loss: 0.2984713912010193, acc: 0.9186992049217224)
[2024-12-17 02:23:06,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:06,461][root][INFO] - Training Epoch: 2/2, step 249/7134 completed (loss: 0.25323012471199036, acc: 0.9130434989929199)
[2024-12-17 02:23:06,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:06,734][root][INFO] - Training Epoch: 2/2, step 250/7134 completed (loss: 0.3307264447212219, acc: 0.9337748289108276)
[2024-12-17 02:23:06,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:07,008][root][INFO] - Training Epoch: 2/2, step 251/7134 completed (loss: 0.3541475236415863, acc: 0.935251772403717)
[2024-12-17 02:23:07,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:07,291][root][INFO] - Training Epoch: 2/2, step 252/7134 completed (loss: 0.13101337850093842, acc: 0.9784172773361206)
[2024-12-17 02:23:07,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:07,579][root][INFO] - Training Epoch: 2/2, step 253/7134 completed (loss: 0.1380886733531952, acc: 0.9679999947547913)
[2024-12-17 02:23:07,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:07,858][root][INFO] - Training Epoch: 2/2, step 254/7134 completed (loss: 0.2196432203054428, acc: 0.9473684430122375)
[2024-12-17 02:23:07,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:08,115][root][INFO] - Training Epoch: 2/2, step 255/7134 completed (loss: 0.16265201568603516, acc: 0.9615384340286255)
[2024-12-17 02:23:08,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:08,378][root][INFO] - Training Epoch: 2/2, step 256/7134 completed (loss: 0.6226921081542969, acc: 0.8648648858070374)
[2024-12-17 02:23:08,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:08,663][root][INFO] - Training Epoch: 2/2, step 257/7134 completed (loss: 0.43776679039001465, acc: 0.8780487775802612)
[2024-12-17 02:23:08,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:08,924][root][INFO] - Training Epoch: 2/2, step 258/7134 completed (loss: 0.2053648829460144, acc: 0.9274193644523621)
[2024-12-17 02:23:09,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:09,204][root][INFO] - Training Epoch: 2/2, step 259/7134 completed (loss: 0.23262333869934082, acc: 0.9469696879386902)
[2024-12-17 02:23:09,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:09,484][root][INFO] - Training Epoch: 2/2, step 260/7134 completed (loss: 0.190254807472229, acc: 0.9398496150970459)
[2024-12-17 02:23:09,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:09,738][root][INFO] - Training Epoch: 2/2, step 261/7134 completed (loss: 0.3310503661632538, acc: 0.9351851940155029)
[2024-12-17 02:23:09,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:09,986][root][INFO] - Training Epoch: 2/2, step 262/7134 completed (loss: 0.08964954316616058, acc: 0.9918699264526367)
[2024-12-17 02:23:10,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:10,252][root][INFO] - Training Epoch: 2/2, step 263/7134 completed (loss: 0.14690065383911133, acc: 0.9691358208656311)
[2024-12-17 02:23:10,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:10,531][root][INFO] - Training Epoch: 2/2, step 264/7134 completed (loss: 0.1682143658399582, acc: 0.9764705896377563)
[2024-12-17 02:23:10,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:10,808][root][INFO] - Training Epoch: 2/2, step 265/7134 completed (loss: 0.32259106636047363, acc: 0.9213483333587646)
[2024-12-17 02:23:10,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:11,084][root][INFO] - Training Epoch: 2/2, step 266/7134 completed (loss: 0.2056238055229187, acc: 0.9583333134651184)
[2024-12-17 02:23:11,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:11,376][root][INFO] - Training Epoch: 2/2, step 267/7134 completed (loss: 0.2985827326774597, acc: 0.936170220375061)
[2024-12-17 02:23:11,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:11,668][root][INFO] - Training Epoch: 2/2, step 268/7134 completed (loss: 0.24783174693584442, acc: 0.9333333373069763)
[2024-12-17 02:23:11,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:11,955][root][INFO] - Training Epoch: 2/2, step 269/7134 completed (loss: 0.3229595720767975, acc: 0.9345238208770752)
[2024-12-17 02:23:12,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:12,226][root][INFO] - Training Epoch: 2/2, step 270/7134 completed (loss: 0.31675320863723755, acc: 0.918749988079071)
[2024-12-17 02:23:12,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:12,510][root][INFO] - Training Epoch: 2/2, step 271/7134 completed (loss: 0.32105928659439087, acc: 0.9611111283302307)
[2024-12-17 02:23:12,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:12,781][root][INFO] - Training Epoch: 2/2, step 272/7134 completed (loss: 0.3019920885562897, acc: 0.916201114654541)
[2024-12-17 02:23:12,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:13,048][root][INFO] - Training Epoch: 2/2, step 273/7134 completed (loss: 0.2565751075744629, acc: 0.9414893388748169)
[2024-12-17 02:23:13,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:13,295][root][INFO] - Training Epoch: 2/2, step 274/7134 completed (loss: 0.3647844195365906, acc: 0.9181286692619324)
[2024-12-17 02:23:13,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:13,577][root][INFO] - Training Epoch: 2/2, step 275/7134 completed (loss: 0.14252957701683044, acc: 0.9644669890403748)
[2024-12-17 02:23:13,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:13,874][root][INFO] - Training Epoch: 2/2, step 276/7134 completed (loss: 0.2422133982181549, acc: 0.9432989954948425)
[2024-12-17 02:23:14,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:14,152][root][INFO] - Training Epoch: 2/2, step 277/7134 completed (loss: 0.3663848340511322, acc: 0.9135135412216187)
[2024-12-17 02:23:14,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:14,444][root][INFO] - Training Epoch: 2/2, step 278/7134 completed (loss: 0.3213946521282196, acc: 0.9114583134651184)
[2024-12-17 02:23:14,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:14,731][root][INFO] - Training Epoch: 2/2, step 279/7134 completed (loss: 0.24407614767551422, acc: 0.9459459185600281)
[2024-12-17 02:23:14,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:14,993][root][INFO] - Training Epoch: 2/2, step 280/7134 completed (loss: 0.4031360447406769, acc: 0.8960000276565552)
[2024-12-17 02:23:15,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:15,268][root][INFO] - Training Epoch: 2/2, step 281/7134 completed (loss: 0.28810179233551025, acc: 0.8983050584793091)
[2024-12-17 02:23:15,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:15,552][root][INFO] - Training Epoch: 2/2, step 282/7134 completed (loss: 0.44338512420654297, acc: 0.8607594966888428)
[2024-12-17 02:23:15,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:15,838][root][INFO] - Training Epoch: 2/2, step 283/7134 completed (loss: 0.27282172441482544, acc: 0.9236640930175781)
[2024-12-17 02:23:15,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:16,104][root][INFO] - Training Epoch: 2/2, step 284/7134 completed (loss: 0.1756361573934555, acc: 0.9370629191398621)
[2024-12-17 02:23:16,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:16,374][root][INFO] - Training Epoch: 2/2, step 285/7134 completed (loss: 0.38440901041030884, acc: 0.9037036895751953)
[2024-12-17 02:23:16,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:16,642][root][INFO] - Training Epoch: 2/2, step 286/7134 completed (loss: 0.24056071043014526, acc: 0.9236111044883728)
[2024-12-17 02:23:16,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:16,927][root][INFO] - Training Epoch: 2/2, step 287/7134 completed (loss: 0.4178619086742401, acc: 0.9127516746520996)
[2024-12-17 02:23:17,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:17,211][root][INFO] - Training Epoch: 2/2, step 288/7134 completed (loss: 0.21849769353866577, acc: 0.960629940032959)
[2024-12-17 02:23:17,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:17,492][root][INFO] - Training Epoch: 2/2, step 289/7134 completed (loss: 0.18273814022541046, acc: 0.9534883499145508)
[2024-12-17 02:23:17,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:17,754][root][INFO] - Training Epoch: 2/2, step 290/7134 completed (loss: 0.35491204261779785, acc: 0.9090909361839294)
[2024-12-17 02:23:17,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:18,038][root][INFO] - Training Epoch: 2/2, step 291/7134 completed (loss: 0.3342466950416565, acc: 0.918367326259613)
[2024-12-17 02:23:18,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:18,322][root][INFO] - Training Epoch: 2/2, step 292/7134 completed (loss: 0.6229650974273682, acc: 0.8888888955116272)
[2024-12-17 02:23:18,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:18,584][root][INFO] - Training Epoch: 2/2, step 293/7134 completed (loss: 0.3998718857765198, acc: 0.9203540086746216)
[2024-12-17 02:23:18,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:18,868][root][INFO] - Training Epoch: 2/2, step 294/7134 completed (loss: 0.2779059410095215, acc: 0.9237288236618042)
[2024-12-17 02:23:18,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:19,161][root][INFO] - Training Epoch: 2/2, step 295/7134 completed (loss: 0.5583183765411377, acc: 0.8717948794364929)
[2024-12-17 02:23:19,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:19,443][root][INFO] - Training Epoch: 2/2, step 296/7134 completed (loss: 0.21592773497104645, acc: 0.939393937587738)
[2024-12-17 02:23:19,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:19,758][root][INFO] - Training Epoch: 2/2, step 297/7134 completed (loss: 0.26970425248146057, acc: 0.9008264541625977)
[2024-12-17 02:23:19,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:20,069][root][INFO] - Training Epoch: 2/2, step 298/7134 completed (loss: 0.1299893707036972, acc: 0.9846153855323792)
[2024-12-17 02:23:20,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:20,363][root][INFO] - Training Epoch: 2/2, step 299/7134 completed (loss: 0.18931442499160767, acc: 0.956204354763031)
[2024-12-17 02:23:20,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:20,661][root][INFO] - Training Epoch: 2/2, step 300/7134 completed (loss: 0.09540701657533646, acc: 0.9710144996643066)
[2024-12-17 02:23:20,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:20,967][root][INFO] - Training Epoch: 2/2, step 301/7134 completed (loss: 0.21555820107460022, acc: 0.9370629191398621)
[2024-12-17 02:23:21,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:21,251][root][INFO] - Training Epoch: 2/2, step 302/7134 completed (loss: 0.22631794214248657, acc: 0.9603960514068604)
[2024-12-17 02:23:21,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:21,519][root][INFO] - Training Epoch: 2/2, step 303/7134 completed (loss: 0.21996060013771057, acc: 0.9459459185600281)
[2024-12-17 02:23:21,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:21,801][root][INFO] - Training Epoch: 2/2, step 304/7134 completed (loss: 0.1741209626197815, acc: 0.9702970385551453)
[2024-12-17 02:23:21,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:22,103][root][INFO] - Training Epoch: 2/2, step 305/7134 completed (loss: 0.24032969772815704, acc: 0.953125)
[2024-12-17 02:23:22,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:22,392][root][INFO] - Training Epoch: 2/2, step 306/7134 completed (loss: 0.1192580983042717, acc: 0.9739130139350891)
[2024-12-17 02:23:22,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:22,682][root][INFO] - Training Epoch: 2/2, step 307/7134 completed (loss: 0.28880026936531067, acc: 0.9252336621284485)
[2024-12-17 02:23:22,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:22,956][root][INFO] - Training Epoch: 2/2, step 308/7134 completed (loss: 0.09710702300071716, acc: 0.9685039520263672)
[2024-12-17 02:23:23,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:23,236][root][INFO] - Training Epoch: 2/2, step 309/7134 completed (loss: 0.1177302747964859, acc: 0.9734513163566589)
[2024-12-17 02:23:23,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:23,532][root][INFO] - Training Epoch: 2/2, step 310/7134 completed (loss: 0.1834767460823059, acc: 0.9457364082336426)
[2024-12-17 02:23:23,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:23,809][root][INFO] - Training Epoch: 2/2, step 311/7134 completed (loss: 0.1518295705318451, acc: 0.969924807548523)
[2024-12-17 02:23:23,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:24,073][root][INFO] - Training Epoch: 2/2, step 312/7134 completed (loss: 0.10188362747430801, acc: 0.9754098653793335)
[2024-12-17 02:23:24,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:24,360][root][INFO] - Training Epoch: 2/2, step 313/7134 completed (loss: 0.1075972244143486, acc: 0.9760000109672546)
[2024-12-17 02:23:24,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:24,632][root][INFO] - Training Epoch: 2/2, step 314/7134 completed (loss: 0.14314113557338715, acc: 0.970370352268219)
[2024-12-17 02:23:24,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:24,904][root][INFO] - Training Epoch: 2/2, step 315/7134 completed (loss: 0.31996336579322815, acc: 0.925000011920929)
[2024-12-17 02:23:25,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:25,202][root][INFO] - Training Epoch: 2/2, step 316/7134 completed (loss: 0.22543556988239288, acc: 0.9459459185600281)
[2024-12-17 02:23:25,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:25,488][root][INFO] - Training Epoch: 2/2, step 317/7134 completed (loss: 0.11665838956832886, acc: 0.9683544039726257)
[2024-12-17 02:23:25,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:25,778][root][INFO] - Training Epoch: 2/2, step 318/7134 completed (loss: 0.24783673882484436, acc: 0.9247311949729919)
[2024-12-17 02:23:25,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:26,053][root][INFO] - Training Epoch: 2/2, step 319/7134 completed (loss: 0.2661803364753723, acc: 0.9378882050514221)
[2024-12-17 02:23:26,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:26,334][root][INFO] - Training Epoch: 2/2, step 320/7134 completed (loss: 0.28871336579322815, acc: 0.9166666865348816)
[2024-12-17 02:23:26,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:26,647][root][INFO] - Training Epoch: 2/2, step 321/7134 completed (loss: 0.2684631645679474, acc: 0.9137930870056152)
[2024-12-17 02:23:26,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:26,936][root][INFO] - Training Epoch: 2/2, step 322/7134 completed (loss: 0.1943381130695343, acc: 0.9477124214172363)
[2024-12-17 02:23:27,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:27,241][root][INFO] - Training Epoch: 2/2, step 323/7134 completed (loss: 0.41381144523620605, acc: 0.9132652878761292)
[2024-12-17 02:23:27,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:27,525][root][INFO] - Training Epoch: 2/2, step 324/7134 completed (loss: 0.3596401810646057, acc: 0.9259259104728699)
[2024-12-17 02:23:27,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:27,803][root][INFO] - Training Epoch: 2/2, step 325/7134 completed (loss: 0.251891165971756, acc: 0.9488636255264282)
[2024-12-17 02:23:27,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:28,091][root][INFO] - Training Epoch: 2/2, step 326/7134 completed (loss: 0.15592703223228455, acc: 0.9719101190567017)
[2024-12-17 02:23:28,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:28,380][root][INFO] - Training Epoch: 2/2, step 327/7134 completed (loss: 0.19872736930847168, acc: 0.9646464586257935)
[2024-12-17 02:23:28,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:28,676][root][INFO] - Training Epoch: 2/2, step 328/7134 completed (loss: 0.2635876536369324, acc: 0.9375)
[2024-12-17 02:23:28,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:28,969][root][INFO] - Training Epoch: 2/2, step 329/7134 completed (loss: 0.12508352100849152, acc: 0.9751243591308594)
[2024-12-17 02:23:29,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:29,259][root][INFO] - Training Epoch: 2/2, step 330/7134 completed (loss: 0.11957290768623352, acc: 0.9736841917037964)
[2024-12-17 02:23:29,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:29,539][root][INFO] - Training Epoch: 2/2, step 331/7134 completed (loss: 0.16363972425460815, acc: 0.953125)
[2024-12-17 02:23:29,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:29,827][root][INFO] - Training Epoch: 2/2, step 332/7134 completed (loss: 0.04922370985150337, acc: 0.9850746393203735)
[2024-12-17 02:23:29,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:30,097][root][INFO] - Training Epoch: 2/2, step 333/7134 completed (loss: 0.2284744828939438, acc: 0.9301075339317322)
[2024-12-17 02:23:30,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:30,380][root][INFO] - Training Epoch: 2/2, step 334/7134 completed (loss: 0.3008626401424408, acc: 0.9450549483299255)
[2024-12-17 02:23:30,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:30,666][root][INFO] - Training Epoch: 2/2, step 335/7134 completed (loss: 0.2327781319618225, acc: 0.9594594836235046)
[2024-12-17 02:23:30,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:30,948][root][INFO] - Training Epoch: 2/2, step 336/7134 completed (loss: 0.29215651750564575, acc: 0.9222797751426697)
[2024-12-17 02:23:31,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:31,225][root][INFO] - Training Epoch: 2/2, step 337/7134 completed (loss: 0.2119782418012619, acc: 0.9316770434379578)
[2024-12-17 02:23:31,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:31,503][root][INFO] - Training Epoch: 2/2, step 338/7134 completed (loss: 0.2930435538291931, acc: 0.9109947681427002)
[2024-12-17 02:23:31,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:31,797][root][INFO] - Training Epoch: 2/2, step 339/7134 completed (loss: 0.21933753788471222, acc: 0.9411764740943909)
[2024-12-17 02:23:31,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:32,073][root][INFO] - Training Epoch: 2/2, step 340/7134 completed (loss: 0.19716164469718933, acc: 0.9494949579238892)
[2024-12-17 02:23:32,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:32,352][root][INFO] - Training Epoch: 2/2, step 341/7134 completed (loss: 0.14714692533016205, acc: 0.9591836929321289)
[2024-12-17 02:23:32,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:32,637][root][INFO] - Training Epoch: 2/2, step 342/7134 completed (loss: 0.1913873702287674, acc: 0.9685534834861755)
[2024-12-17 02:23:32,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:32,938][root][INFO] - Training Epoch: 2/2, step 343/7134 completed (loss: 0.2450956255197525, acc: 0.9615384340286255)
[2024-12-17 02:23:33,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:33,200][root][INFO] - Training Epoch: 2/2, step 344/7134 completed (loss: 0.19536495208740234, acc: 0.9457364082336426)
[2024-12-17 02:23:33,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:33,484][root][INFO] - Training Epoch: 2/2, step 345/7134 completed (loss: 0.1900292932987213, acc: 0.9503546357154846)
[2024-12-17 02:23:33,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:33,766][root][INFO] - Training Epoch: 2/2, step 346/7134 completed (loss: 0.12054212391376495, acc: 0.9736841917037964)
[2024-12-17 02:23:33,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:34,049][root][INFO] - Training Epoch: 2/2, step 347/7134 completed (loss: 0.29677268862724304, acc: 0.9125000238418579)
[2024-12-17 02:23:34,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:34,337][root][INFO] - Training Epoch: 2/2, step 348/7134 completed (loss: 0.15153199434280396, acc: 0.9585798978805542)
[2024-12-17 02:23:34,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:34,611][root][INFO] - Training Epoch: 2/2, step 349/7134 completed (loss: 0.2843422293663025, acc: 0.9467455744743347)
[2024-12-17 02:23:34,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:34,940][root][INFO] - Training Epoch: 2/2, step 350/7134 completed (loss: 0.18943879008293152, acc: 0.942105233669281)
[2024-12-17 02:23:35,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:35,236][root][INFO] - Training Epoch: 2/2, step 351/7134 completed (loss: 0.24970726668834686, acc: 0.9402173757553101)
[2024-12-17 02:23:35,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:35,510][root][INFO] - Training Epoch: 2/2, step 352/7134 completed (loss: 0.23671169579029083, acc: 0.9473684430122375)
[2024-12-17 02:23:35,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:35,799][root][INFO] - Training Epoch: 2/2, step 353/7134 completed (loss: 0.26268744468688965, acc: 0.9447852969169617)
[2024-12-17 02:23:35,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:36,090][root][INFO] - Training Epoch: 2/2, step 354/7134 completed (loss: 0.18775011599063873, acc: 0.9547738432884216)
[2024-12-17 02:23:36,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:36,369][root][INFO] - Training Epoch: 2/2, step 355/7134 completed (loss: 0.23980063199996948, acc: 0.9467455744743347)
[2024-12-17 02:23:36,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:36,661][root][INFO] - Training Epoch: 2/2, step 356/7134 completed (loss: 0.18985043466091156, acc: 0.9341317415237427)
[2024-12-17 02:23:36,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:37,010][root][INFO] - Training Epoch: 2/2, step 357/7134 completed (loss: 0.10696375370025635, acc: 0.9767441749572754)
[2024-12-17 02:23:37,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:37,293][root][INFO] - Training Epoch: 2/2, step 358/7134 completed (loss: 0.10238280892372131, acc: 0.9715909361839294)
[2024-12-17 02:23:37,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:37,581][root][INFO] - Training Epoch: 2/2, step 359/7134 completed (loss: 0.3261963427066803, acc: 0.9411764740943909)
[2024-12-17 02:23:37,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:37,857][root][INFO] - Training Epoch: 2/2, step 360/7134 completed (loss: 0.10021622478961945, acc: 0.9673202633857727)
[2024-12-17 02:23:38,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:38,154][root][INFO] - Training Epoch: 2/2, step 361/7134 completed (loss: 0.07217627763748169, acc: 0.9754601120948792)
[2024-12-17 02:23:38,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:38,430][root][INFO] - Training Epoch: 2/2, step 362/7134 completed (loss: 0.1479695737361908, acc: 0.9430379867553711)
[2024-12-17 02:23:38,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:38,720][root][INFO] - Training Epoch: 2/2, step 363/7134 completed (loss: 0.16611063480377197, acc: 0.9726775884628296)
[2024-12-17 02:23:38,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:38,974][root][INFO] - Training Epoch: 2/2, step 364/7134 completed (loss: 0.19156798720359802, acc: 0.9223300814628601)
[2024-12-17 02:23:39,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:39,261][root][INFO] - Training Epoch: 2/2, step 365/7134 completed (loss: 0.12234947085380554, acc: 0.9556962251663208)
[2024-12-17 02:23:39,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:39,549][root][INFO] - Training Epoch: 2/2, step 366/7134 completed (loss: 0.1629628986120224, acc: 0.9681528806686401)
[2024-12-17 02:23:39,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:39,842][root][INFO] - Training Epoch: 2/2, step 367/7134 completed (loss: 0.06250207126140594, acc: 0.9793814420700073)
[2024-12-17 02:23:39,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:40,122][root][INFO] - Training Epoch: 2/2, step 368/7134 completed (loss: 0.05179537832736969, acc: 0.9940828680992126)
[2024-12-17 02:23:40,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:40,390][root][INFO] - Training Epoch: 2/2, step 369/7134 completed (loss: 0.18069349229335785, acc: 0.9325153231620789)
[2024-12-17 02:23:40,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:40,674][root][INFO] - Training Epoch: 2/2, step 370/7134 completed (loss: 0.17495307326316833, acc: 0.9303797483444214)
[2024-12-17 02:23:40,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:40,942][root][INFO] - Training Epoch: 2/2, step 371/7134 completed (loss: 0.10352672636508942, acc: 0.9627329111099243)
[2024-12-17 02:23:41,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:41,222][root][INFO] - Training Epoch: 2/2, step 372/7134 completed (loss: 0.08977200090885162, acc: 0.9685534834861755)
[2024-12-17 02:23:41,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:41,498][root][INFO] - Training Epoch: 2/2, step 373/7134 completed (loss: 0.09037039428949356, acc: 0.9803921580314636)
[2024-12-17 02:23:41,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:41,770][root][INFO] - Training Epoch: 2/2, step 374/7134 completed (loss: 0.2550358772277832, acc: 0.9459459185600281)
[2024-12-17 02:23:41,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:42,026][root][INFO] - Training Epoch: 2/2, step 375/7134 completed (loss: 0.24351651966571808, acc: 0.9414893388748169)
[2024-12-17 02:23:42,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:42,305][root][INFO] - Training Epoch: 2/2, step 376/7134 completed (loss: 0.47698774933815, acc: 0.8999999761581421)
[2024-12-17 02:23:42,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:42,577][root][INFO] - Training Epoch: 2/2, step 377/7134 completed (loss: 0.2327958643436432, acc: 0.9608938694000244)
[2024-12-17 02:23:42,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:42,837][root][INFO] - Training Epoch: 2/2, step 378/7134 completed (loss: 0.2913181781768799, acc: 0.9152542352676392)
[2024-12-17 02:23:42,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:43,111][root][INFO] - Training Epoch: 2/2, step 379/7134 completed (loss: 0.043502919375896454, acc: 0.9901960492134094)
[2024-12-17 02:23:43,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:43,392][root][INFO] - Training Epoch: 2/2, step 380/7134 completed (loss: 0.42142942547798157, acc: 0.8917526006698608)
[2024-12-17 02:23:43,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:43,682][root][INFO] - Training Epoch: 2/2, step 381/7134 completed (loss: 0.1784316599369049, acc: 0.9736841917037964)
[2024-12-17 02:23:43,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:43,953][root][INFO] - Training Epoch: 2/2, step 382/7134 completed (loss: 0.17639724910259247, acc: 0.9384615421295166)
[2024-12-17 02:23:44,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:44,242][root][INFO] - Training Epoch: 2/2, step 383/7134 completed (loss: 0.1321028620004654, acc: 0.9767441749572754)
[2024-12-17 02:23:44,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:44,504][root][INFO] - Training Epoch: 2/2, step 384/7134 completed (loss: 0.26268139481544495, acc: 0.950276255607605)
[2024-12-17 02:23:44,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:44,767][root][INFO] - Training Epoch: 2/2, step 385/7134 completed (loss: 0.1250653713941574, acc: 0.9673202633857727)
[2024-12-17 02:23:44,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:44,999][root][INFO] - Training Epoch: 2/2, step 386/7134 completed (loss: 0.13931231200695038, acc: 0.9729729890823364)
[2024-12-17 02:23:45,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:45,281][root][INFO] - Training Epoch: 2/2, step 387/7134 completed (loss: 0.19553928077220917, acc: 0.9526627063751221)
[2024-12-17 02:23:45,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:45,558][root][INFO] - Training Epoch: 2/2, step 388/7134 completed (loss: 0.10182579606771469, acc: 0.9665071964263916)
[2024-12-17 02:23:45,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:45,836][root][INFO] - Training Epoch: 2/2, step 389/7134 completed (loss: 0.24451732635498047, acc: 0.9200000166893005)
[2024-12-17 02:23:45,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:46,086][root][INFO] - Training Epoch: 2/2, step 390/7134 completed (loss: 0.15206678211688995, acc: 0.9594594836235046)
[2024-12-17 02:23:46,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:46,353][root][INFO] - Training Epoch: 2/2, step 391/7134 completed (loss: 0.1787559688091278, acc: 0.9466666579246521)
[2024-12-17 02:23:46,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:46,632][root][INFO] - Training Epoch: 2/2, step 392/7134 completed (loss: 0.16937914490699768, acc: 0.9476743936538696)
[2024-12-17 02:23:46,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:46,894][root][INFO] - Training Epoch: 2/2, step 393/7134 completed (loss: 0.17147943377494812, acc: 0.9411764740943909)
[2024-12-17 02:23:46,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:47,143][root][INFO] - Training Epoch: 2/2, step 394/7134 completed (loss: 0.1789938509464264, acc: 0.9312977194786072)
[2024-12-17 02:23:47,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:47,405][root][INFO] - Training Epoch: 2/2, step 395/7134 completed (loss: 0.280474454164505, acc: 0.9468085169792175)
[2024-12-17 02:23:47,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:47,672][root][INFO] - Training Epoch: 2/2, step 396/7134 completed (loss: 0.21515946090221405, acc: 0.9482758641242981)
[2024-12-17 02:23:47,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:47,963][root][INFO] - Training Epoch: 2/2, step 397/7134 completed (loss: 0.32283487915992737, acc: 0.9402173757553101)
[2024-12-17 02:23:48,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:48,239][root][INFO] - Training Epoch: 2/2, step 398/7134 completed (loss: 0.2231956571340561, acc: 0.9444444179534912)
[2024-12-17 02:23:48,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:48,509][root][INFO] - Training Epoch: 2/2, step 399/7134 completed (loss: 0.2559642791748047, acc: 0.9430379867553711)
[2024-12-17 02:23:48,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:48,793][root][INFO] - Training Epoch: 2/2, step 400/7134 completed (loss: 0.4095686972141266, acc: 0.892405092716217)
[2024-12-17 02:23:48,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:49,066][root][INFO] - Training Epoch: 2/2, step 401/7134 completed (loss: 0.19777293503284454, acc: 0.9460784196853638)
[2024-12-17 02:23:49,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:49,347][root][INFO] - Training Epoch: 2/2, step 402/7134 completed (loss: 0.205268993973732, acc: 0.9447236061096191)
[2024-12-17 02:23:49,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:49,646][root][INFO] - Training Epoch: 2/2, step 403/7134 completed (loss: 0.1595756709575653, acc: 0.9519650936126709)
[2024-12-17 02:23:49,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:49,912][root][INFO] - Training Epoch: 2/2, step 404/7134 completed (loss: 0.1712290197610855, acc: 0.9516128897666931)
[2024-12-17 02:23:50,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:50,185][root][INFO] - Training Epoch: 2/2, step 405/7134 completed (loss: 0.3484666049480438, acc: 0.9244186282157898)
[2024-12-17 02:23:50,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:50,461][root][INFO] - Training Epoch: 2/2, step 406/7134 completed (loss: 0.46750685572624207, acc: 0.9027026891708374)
[2024-12-17 02:23:50,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:50,710][root][INFO] - Training Epoch: 2/2, step 407/7134 completed (loss: 0.6158074140548706, acc: 0.8917197585105896)
[2024-12-17 02:23:50,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:50,970][root][INFO] - Training Epoch: 2/2, step 408/7134 completed (loss: 0.39781326055526733, acc: 0.916201114654541)
[2024-12-17 02:23:51,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:51,237][root][INFO] - Training Epoch: 2/2, step 409/7134 completed (loss: 0.3366452157497406, acc: 0.9315789341926575)
[2024-12-17 02:23:51,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:51,525][root][INFO] - Training Epoch: 2/2, step 410/7134 completed (loss: 0.39080238342285156, acc: 0.9090909361839294)
[2024-12-17 02:23:51,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:51,834][root][INFO] - Training Epoch: 2/2, step 411/7134 completed (loss: 0.17485132813453674, acc: 0.9594594836235046)
[2024-12-17 02:23:51,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:52,132][root][INFO] - Training Epoch: 2/2, step 412/7134 completed (loss: 0.22412411868572235, acc: 0.9327354431152344)
[2024-12-17 02:23:52,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:52,433][root][INFO] - Training Epoch: 2/2, step 413/7134 completed (loss: 0.4764111042022705, acc: 0.8795811533927917)
[2024-12-17 02:23:52,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:52,707][root][INFO] - Training Epoch: 2/2, step 414/7134 completed (loss: 0.19290202856063843, acc: 0.9421965479850769)
[2024-12-17 02:23:52,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:52,984][root][INFO] - Training Epoch: 2/2, step 415/7134 completed (loss: 0.26278746128082275, acc: 0.9428571462631226)
[2024-12-17 02:23:53,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:53,280][root][INFO] - Training Epoch: 2/2, step 416/7134 completed (loss: 0.15051084756851196, acc: 0.9567307829856873)
[2024-12-17 02:23:53,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:53,560][root][INFO] - Training Epoch: 2/2, step 417/7134 completed (loss: 0.2219623178243637, acc: 0.9230769276618958)
[2024-12-17 02:23:53,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:53,852][root][INFO] - Training Epoch: 2/2, step 418/7134 completed (loss: 0.20588374137878418, acc: 0.9420289993286133)
[2024-12-17 02:23:53,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:54,140][root][INFO] - Training Epoch: 2/2, step 419/7134 completed (loss: 0.19099466502666473, acc: 0.9504950642585754)
[2024-12-17 02:23:54,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:54,403][root][INFO] - Training Epoch: 2/2, step 420/7134 completed (loss: 0.28917351365089417, acc: 0.9285714030265808)
[2024-12-17 02:23:54,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:54,687][root][INFO] - Training Epoch: 2/2, step 421/7134 completed (loss: 0.2676718533039093, acc: 0.9371069073677063)
[2024-12-17 02:23:54,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:54,969][root][INFO] - Training Epoch: 2/2, step 422/7134 completed (loss: 0.26577165722846985, acc: 0.9289940595626831)
[2024-12-17 02:23:55,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:55,258][root][INFO] - Training Epoch: 2/2, step 423/7134 completed (loss: 0.10641550272703171, acc: 0.9775280952453613)
[2024-12-17 02:23:55,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:55,526][root][INFO] - Training Epoch: 2/2, step 424/7134 completed (loss: 0.21428991854190826, acc: 0.9567901492118835)
[2024-12-17 02:23:55,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:55,813][root][INFO] - Training Epoch: 2/2, step 425/7134 completed (loss: 0.11253556609153748, acc: 0.9772727489471436)
[2024-12-17 02:23:55,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:56,092][root][INFO] - Training Epoch: 2/2, step 426/7134 completed (loss: 0.109727643430233, acc: 0.9764705896377563)
[2024-12-17 02:23:56,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:56,364][root][INFO] - Training Epoch: 2/2, step 427/7134 completed (loss: 0.07330301403999329, acc: 0.9811320900917053)
[2024-12-17 02:23:56,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:56,644][root][INFO] - Training Epoch: 2/2, step 428/7134 completed (loss: 0.1665230691432953, acc: 0.9640718698501587)
[2024-12-17 02:23:56,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:56,915][root][INFO] - Training Epoch: 2/2, step 429/7134 completed (loss: 0.36801663041114807, acc: 0.9276315569877625)
[2024-12-17 02:23:57,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:57,184][root][INFO] - Training Epoch: 2/2, step 430/7134 completed (loss: 0.13717250525951385, acc: 0.9647058844566345)
[2024-12-17 02:23:57,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:57,446][root][INFO] - Training Epoch: 2/2, step 431/7134 completed (loss: 0.07211664319038391, acc: 0.9881656765937805)
[2024-12-17 02:23:57,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:57,717][root][INFO] - Training Epoch: 2/2, step 432/7134 completed (loss: 0.1953212022781372, acc: 0.9469696879386902)
[2024-12-17 02:23:57,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:58,006][root][INFO] - Training Epoch: 2/2, step 433/7134 completed (loss: 0.2419213503599167, acc: 0.957446813583374)
[2024-12-17 02:23:58,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:58,284][root][INFO] - Training Epoch: 2/2, step 434/7134 completed (loss: 0.141229510307312, acc: 0.9629629850387573)
[2024-12-17 02:23:58,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:58,580][root][INFO] - Training Epoch: 2/2, step 435/7134 completed (loss: 0.16771793365478516, acc: 0.9555555582046509)
[2024-12-17 02:23:58,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:58,847][root][INFO] - Training Epoch: 2/2, step 436/7134 completed (loss: 0.19854187965393066, acc: 0.9513888955116272)
[2024-12-17 02:23:58,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:59,140][root][INFO] - Training Epoch: 2/2, step 437/7134 completed (loss: 0.2542196810245514, acc: 0.9507042169570923)
[2024-12-17 02:23:59,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:59,419][root][INFO] - Training Epoch: 2/2, step 438/7134 completed (loss: 0.10857868194580078, acc: 0.9685039520263672)
[2024-12-17 02:23:59,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:59,710][root][INFO] - Training Epoch: 2/2, step 439/7134 completed (loss: 0.18736961483955383, acc: 0.9425287246704102)
[2024-12-17 02:23:59,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:59,973][root][INFO] - Training Epoch: 2/2, step 440/7134 completed (loss: 0.1124708279967308, acc: 0.9692307710647583)
[2024-12-17 02:24:00,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:00,250][root][INFO] - Training Epoch: 2/2, step 441/7134 completed (loss: 0.09644356369972229, acc: 0.9726027250289917)
[2024-12-17 02:24:00,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:00,527][root][INFO] - Training Epoch: 2/2, step 442/7134 completed (loss: 0.1817389577627182, acc: 0.9689922332763672)
[2024-12-17 02:24:00,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:00,804][root][INFO] - Training Epoch: 2/2, step 443/7134 completed (loss: 0.05040889233350754, acc: 0.9931972622871399)
[2024-12-17 02:24:00,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:01,067][root][INFO] - Training Epoch: 2/2, step 444/7134 completed (loss: 0.06430434435606003, acc: 0.9922480583190918)
[2024-12-17 02:24:01,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:01,349][root][INFO] - Training Epoch: 2/2, step 445/7134 completed (loss: 0.19191348552703857, acc: 0.9496855139732361)
[2024-12-17 02:24:01,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:01,635][root][INFO] - Training Epoch: 2/2, step 446/7134 completed (loss: 0.10505831986665726, acc: 0.9585798978805542)
[2024-12-17 02:24:01,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:01,900][root][INFO] - Training Epoch: 2/2, step 447/7134 completed (loss: 0.12029959261417389, acc: 0.9754601120948792)
[2024-12-17 02:24:02,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:02,183][root][INFO] - Training Epoch: 2/2, step 448/7134 completed (loss: 0.2891159951686859, acc: 0.9470899701118469)
[2024-12-17 02:24:02,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:02,466][root][INFO] - Training Epoch: 2/2, step 449/7134 completed (loss: 0.31501075625419617, acc: 0.9308510422706604)
[2024-12-17 02:24:02,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:02,750][root][INFO] - Training Epoch: 2/2, step 450/7134 completed (loss: 0.2760201692581177, acc: 0.9339622855186462)
[2024-12-17 02:24:02,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:03,034][root][INFO] - Training Epoch: 2/2, step 451/7134 completed (loss: 0.5651789903640747, acc: 0.9025423526763916)
[2024-12-17 02:24:03,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:03,316][root][INFO] - Training Epoch: 2/2, step 452/7134 completed (loss: 0.5287703275680542, acc: 0.898876428604126)
[2024-12-17 02:24:03,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:03,558][root][INFO] - Training Epoch: 2/2, step 453/7134 completed (loss: 0.2451702207326889, acc: 0.9219858050346375)
[2024-12-17 02:24:03,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:03,850][root][INFO] - Training Epoch: 2/2, step 454/7134 completed (loss: 0.38748887181282043, acc: 0.9113923907279968)
[2024-12-17 02:24:03,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:04,133][root][INFO] - Training Epoch: 2/2, step 455/7134 completed (loss: 0.339470773935318, acc: 0.9128205180168152)
[2024-12-17 02:24:04,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:04,402][root][INFO] - Training Epoch: 2/2, step 456/7134 completed (loss: 0.23814129829406738, acc: 0.9509202241897583)
[2024-12-17 02:24:04,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:04,676][root][INFO] - Training Epoch: 2/2, step 457/7134 completed (loss: 0.48293763399124146, acc: 0.9103448390960693)
[2024-12-17 02:24:04,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:04,924][root][INFO] - Training Epoch: 2/2, step 458/7134 completed (loss: 0.24131040275096893, acc: 0.9516128897666931)
[2024-12-17 02:24:05,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:05,179][root][INFO] - Training Epoch: 2/2, step 459/7134 completed (loss: 0.3899502158164978, acc: 0.891566276550293)
[2024-12-17 02:24:05,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:05,433][root][INFO] - Training Epoch: 2/2, step 460/7134 completed (loss: 0.25540247559547424, acc: 0.9266666769981384)
[2024-12-17 02:24:05,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:05,710][root][INFO] - Training Epoch: 2/2, step 461/7134 completed (loss: 0.2784101963043213, acc: 0.9470587968826294)
[2024-12-17 02:24:05,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:06,022][root][INFO] - Training Epoch: 2/2, step 462/7134 completed (loss: 0.270313024520874, acc: 0.9259259104728699)
[2024-12-17 02:24:06,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:06,313][root][INFO] - Training Epoch: 2/2, step 463/7134 completed (loss: 0.43361178040504456, acc: 0.9154228568077087)
[2024-12-17 02:24:06,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:06,618][root][INFO] - Training Epoch: 2/2, step 464/7134 completed (loss: 0.2740958333015442, acc: 0.9375)
[2024-12-17 02:24:06,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:06,880][root][INFO] - Training Epoch: 2/2, step 465/7134 completed (loss: 0.32381471991539, acc: 0.9497206807136536)
[2024-12-17 02:24:06,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:07,146][root][INFO] - Training Epoch: 2/2, step 466/7134 completed (loss: 0.3559424877166748, acc: 0.9005848169326782)
[2024-12-17 02:24:07,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:07,406][root][INFO] - Training Epoch: 2/2, step 467/7134 completed (loss: 0.35764607787132263, acc: 0.9100528955459595)
[2024-12-17 02:24:07,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:07,643][root][INFO] - Training Epoch: 2/2, step 468/7134 completed (loss: 0.3985235095024109, acc: 0.8933333158493042)
[2024-12-17 02:24:07,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:07,912][root][INFO] - Training Epoch: 2/2, step 469/7134 completed (loss: 0.27867934107780457, acc: 0.9166666865348816)
[2024-12-17 02:24:08,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:08,182][root][INFO] - Training Epoch: 2/2, step 470/7134 completed (loss: 0.3449791669845581, acc: 0.9256756901741028)
[2024-12-17 02:24:08,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:08,445][root][INFO] - Training Epoch: 2/2, step 471/7134 completed (loss: 0.4108687937259674, acc: 0.901098906993866)
[2024-12-17 02:24:08,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:08,713][root][INFO] - Training Epoch: 2/2, step 472/7134 completed (loss: 0.2975078225135803, acc: 0.9466666579246521)
[2024-12-17 02:24:08,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:08,985][root][INFO] - Training Epoch: 2/2, step 473/7134 completed (loss: 0.2854035198688507, acc: 0.9318181872367859)
[2024-12-17 02:24:09,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:09,265][root][INFO] - Training Epoch: 2/2, step 474/7134 completed (loss: 0.37308722734451294, acc: 0.9272727370262146)
[2024-12-17 02:24:09,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:09,527][root][INFO] - Training Epoch: 2/2, step 475/7134 completed (loss: 0.42278656363487244, acc: 0.9020978808403015)
[2024-12-17 02:24:09,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:09,813][root][INFO] - Training Epoch: 2/2, step 476/7134 completed (loss: 0.4110393524169922, acc: 0.887499988079071)
[2024-12-17 02:24:09,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:10,117][root][INFO] - Training Epoch: 2/2, step 477/7134 completed (loss: 0.31337451934814453, acc: 0.9358288645744324)
[2024-12-17 02:24:10,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:10,393][root][INFO] - Training Epoch: 2/2, step 478/7134 completed (loss: 0.532568633556366, acc: 0.886956512928009)
[2024-12-17 02:24:10,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:10,652][root][INFO] - Training Epoch: 2/2, step 479/7134 completed (loss: 0.4072604775428772, acc: 0.9205297827720642)
[2024-12-17 02:24:10,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:10,943][root][INFO] - Training Epoch: 2/2, step 480/7134 completed (loss: 0.281792014837265, acc: 0.9375)
[2024-12-17 02:24:11,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:11,242][root][INFO] - Training Epoch: 2/2, step 481/7134 completed (loss: 0.2763558030128479, acc: 0.9378882050514221)
[2024-12-17 02:24:11,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:11,512][root][INFO] - Training Epoch: 2/2, step 482/7134 completed (loss: 0.16851748526096344, acc: 0.9496855139732361)
[2024-12-17 02:24:11,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:11,816][root][INFO] - Training Epoch: 2/2, step 483/7134 completed (loss: 0.18619470298290253, acc: 0.9450549483299255)
[2024-12-17 02:24:11,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:12,108][root][INFO] - Training Epoch: 2/2, step 484/7134 completed (loss: 0.4172217845916748, acc: 0.8928571343421936)
[2024-12-17 02:24:12,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:12,397][root][INFO] - Training Epoch: 2/2, step 485/7134 completed (loss: 0.5204964876174927, acc: 0.888198733329773)
[2024-12-17 02:24:12,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:12,694][root][INFO] - Training Epoch: 2/2, step 486/7134 completed (loss: 0.4934208393096924, acc: 0.8645161390304565)
[2024-12-17 02:24:12,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:12,990][root][INFO] - Training Epoch: 2/2, step 487/7134 completed (loss: 0.18503515422344208, acc: 0.9629629850387573)
[2024-12-17 02:24:13,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:13,267][root][INFO] - Training Epoch: 2/2, step 488/7134 completed (loss: 0.5080731511116028, acc: 0.9179104566574097)
[2024-12-17 02:24:13,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:13,559][root][INFO] - Training Epoch: 2/2, step 489/7134 completed (loss: 0.5629817247390747, acc: 0.9064748287200928)
[2024-12-17 02:24:13,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:13,851][root][INFO] - Training Epoch: 2/2, step 490/7134 completed (loss: 0.227908656001091, acc: 0.9367088675498962)
[2024-12-17 02:24:13,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:14,112][root][INFO] - Training Epoch: 2/2, step 491/7134 completed (loss: 0.2055606245994568, acc: 0.9375)
[2024-12-17 02:24:14,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:14,382][root][INFO] - Training Epoch: 2/2, step 492/7134 completed (loss: 0.1025509461760521, acc: 0.9806451797485352)
[2024-12-17 02:24:14,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:14,680][root][INFO] - Training Epoch: 2/2, step 493/7134 completed (loss: 0.15572603046894073, acc: 0.9644970297813416)
[2024-12-17 02:24:14,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:14,977][root][INFO] - Training Epoch: 2/2, step 494/7134 completed (loss: 0.1362379491329193, acc: 0.9666666388511658)
[2024-12-17 02:24:15,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:15,277][root][INFO] - Training Epoch: 2/2, step 495/7134 completed (loss: 0.1521790772676468, acc: 0.9669421315193176)
[2024-12-17 02:24:15,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:15,573][root][INFO] - Training Epoch: 2/2, step 496/7134 completed (loss: 0.2822803556919098, acc: 0.9157894849777222)
[2024-12-17 02:24:15,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:15,864][root][INFO] - Training Epoch: 2/2, step 497/7134 completed (loss: 0.16720859706401825, acc: 0.9461538195610046)
[2024-12-17 02:24:16,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:16,158][root][INFO] - Training Epoch: 2/2, step 498/7134 completed (loss: 0.16795280575752258, acc: 0.9597315192222595)
[2024-12-17 02:24:16,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:16,469][root][INFO] - Training Epoch: 2/2, step 499/7134 completed (loss: 0.11466840654611588, acc: 0.9647058844566345)
[2024-12-17 02:24:16,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:16,750][root][INFO] - Training Epoch: 2/2, step 500/7134 completed (loss: 0.15811215341091156, acc: 0.9709302186965942)
[2024-12-17 02:24:16,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:17,041][root][INFO] - Training Epoch: 2/2, step 501/7134 completed (loss: 0.111320860683918, acc: 0.9768785834312439)
[2024-12-17 02:24:17,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:17,305][root][INFO] - Training Epoch: 2/2, step 502/7134 completed (loss: 0.07468543946743011, acc: 0.9935064911842346)
[2024-12-17 02:24:17,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:17,577][root][INFO] - Training Epoch: 2/2, step 503/7134 completed (loss: 0.1937984973192215, acc: 0.9375)
[2024-12-17 02:24:17,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:17,868][root][INFO] - Training Epoch: 2/2, step 504/7134 completed (loss: 0.12951044738292694, acc: 0.9689440727233887)
[2024-12-17 02:24:17,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:18,145][root][INFO] - Training Epoch: 2/2, step 505/7134 completed (loss: 0.15970727801322937, acc: 0.9642857313156128)
[2024-12-17 02:24:18,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:18,435][root][INFO] - Training Epoch: 2/2, step 506/7134 completed (loss: 0.17806127667427063, acc: 0.9545454382896423)
[2024-12-17 02:24:18,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:18,725][root][INFO] - Training Epoch: 2/2, step 507/7134 completed (loss: 0.16113734245300293, acc: 0.9672130942344666)
[2024-12-17 02:24:18,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:19,015][root][INFO] - Training Epoch: 2/2, step 508/7134 completed (loss: 0.2239535003900528, acc: 0.9470587968826294)
[2024-12-17 02:24:19,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:19,319][root][INFO] - Training Epoch: 2/2, step 509/7134 completed (loss: 0.1974218636751175, acc: 0.9594594836235046)
[2024-12-17 02:24:19,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:19,619][root][INFO] - Training Epoch: 2/2, step 510/7134 completed (loss: 0.5655989050865173, acc: 0.8943089246749878)
[2024-12-17 02:24:19,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:19,887][root][INFO] - Training Epoch: 2/2, step 511/7134 completed (loss: 0.33607205748558044, acc: 0.9047619104385376)
[2024-12-17 02:24:20,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:20,160][root][INFO] - Training Epoch: 2/2, step 512/7134 completed (loss: 0.3558961749076843, acc: 0.9465649127960205)
[2024-12-17 02:24:20,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:20,441][root][INFO] - Training Epoch: 2/2, step 513/7134 completed (loss: 0.3805595636367798, acc: 0.9127516746520996)
[2024-12-17 02:24:20,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:20,720][root][INFO] - Training Epoch: 2/2, step 514/7134 completed (loss: 0.5333420634269714, acc: 0.8796296119689941)
[2024-12-17 02:24:20,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:21,030][root][INFO] - Training Epoch: 2/2, step 515/7134 completed (loss: 0.2821943163871765, acc: 0.9285714030265808)
[2024-12-17 02:24:21,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:21,283][root][INFO] - Training Epoch: 2/2, step 516/7134 completed (loss: 0.22147616744041443, acc: 0.9406779408454895)
[2024-12-17 02:24:21,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:21,568][root][INFO] - Training Epoch: 2/2, step 517/7134 completed (loss: 0.356646329164505, acc: 0.9130434989929199)
[2024-12-17 02:24:21,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:21,855][root][INFO] - Training Epoch: 2/2, step 518/7134 completed (loss: 0.2430749088525772, acc: 0.9735099077224731)
[2024-12-17 02:24:21,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:22,141][root][INFO] - Training Epoch: 2/2, step 519/7134 completed (loss: 0.17275141179561615, acc: 0.9826086759567261)
[2024-12-17 02:24:22,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:22,442][root][INFO] - Training Epoch: 2/2, step 520/7134 completed (loss: 0.1574791669845581, acc: 0.9407894611358643)
[2024-12-17 02:24:22,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:22,750][root][INFO] - Training Epoch: 2/2, step 521/7134 completed (loss: 0.262635201215744, acc: 0.9415204524993896)
[2024-12-17 02:24:22,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:23,063][root][INFO] - Training Epoch: 2/2, step 522/7134 completed (loss: 0.26425090432167053, acc: 0.949438214302063)
[2024-12-17 02:24:23,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:23,375][root][INFO] - Training Epoch: 2/2, step 523/7134 completed (loss: 0.2220969945192337, acc: 0.9534883499145508)
[2024-12-17 02:24:23,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:23,673][root][INFO] - Training Epoch: 2/2, step 524/7134 completed (loss: 0.1670459657907486, acc: 0.9604519605636597)
[2024-12-17 02:24:23,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:23,968][root][INFO] - Training Epoch: 2/2, step 525/7134 completed (loss: 0.28355520963668823, acc: 0.9325153231620789)
[2024-12-17 02:24:24,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:24,249][root][INFO] - Training Epoch: 2/2, step 526/7134 completed (loss: 0.22261548042297363, acc: 0.9488636255264282)
[2024-12-17 02:24:24,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:24,528][root][INFO] - Training Epoch: 2/2, step 527/7134 completed (loss: 0.1817152053117752, acc: 0.9609375)
[2024-12-17 02:24:24,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:24,826][root][INFO] - Training Epoch: 2/2, step 528/7134 completed (loss: 0.13072413206100464, acc: 0.9655172228813171)
[2024-12-17 02:24:24,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:25,145][root][INFO] - Training Epoch: 2/2, step 529/7134 completed (loss: 0.32669597864151, acc: 0.9108280539512634)
[2024-12-17 02:24:25,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:25,466][root][INFO] - Training Epoch: 2/2, step 530/7134 completed (loss: 0.2290874421596527, acc: 0.9384615421295166)
[2024-12-17 02:24:25,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:25,755][root][INFO] - Training Epoch: 2/2, step 531/7134 completed (loss: 0.3577830195426941, acc: 0.9109588861465454)
[2024-12-17 02:24:25,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:26,057][root][INFO] - Training Epoch: 2/2, step 532/7134 completed (loss: 0.1274513155221939, acc: 0.9557521939277649)
[2024-12-17 02:24:26,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:26,360][root][INFO] - Training Epoch: 2/2, step 533/7134 completed (loss: 0.44573652744293213, acc: 0.8979591727256775)
[2024-12-17 02:24:26,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:26,655][root][INFO] - Training Epoch: 2/2, step 534/7134 completed (loss: 0.1293381005525589, acc: 0.970059871673584)
[2024-12-17 02:24:26,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:26,956][root][INFO] - Training Epoch: 2/2, step 535/7134 completed (loss: 0.23191367089748383, acc: 0.9489051103591919)
[2024-12-17 02:24:27,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:27,243][root][INFO] - Training Epoch: 2/2, step 536/7134 completed (loss: 0.17039762437343597, acc: 0.9512194991111755)
[2024-12-17 02:24:27,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:27,518][root][INFO] - Training Epoch: 2/2, step 537/7134 completed (loss: 0.1869763433933258, acc: 0.9537572264671326)
[2024-12-17 02:24:27,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:27,792][root][INFO] - Training Epoch: 2/2, step 538/7134 completed (loss: 0.22588513791561127, acc: 0.9457831382751465)
[2024-12-17 02:24:27,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:28,071][root][INFO] - Training Epoch: 2/2, step 539/7134 completed (loss: 0.24666237831115723, acc: 0.9541984796524048)
[2024-12-17 02:24:28,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:28,340][root][INFO] - Training Epoch: 2/2, step 540/7134 completed (loss: 0.16923247277736664, acc: 0.9622641801834106)
[2024-12-17 02:24:28,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:28,628][root][INFO] - Training Epoch: 2/2, step 541/7134 completed (loss: 0.2933655381202698, acc: 0.9345238208770752)
[2024-12-17 02:24:28,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:28,874][root][INFO] - Training Epoch: 2/2, step 542/7134 completed (loss: 0.5490049719810486, acc: 0.8600000143051147)
[2024-12-17 02:24:28,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:29,148][root][INFO] - Training Epoch: 2/2, step 543/7134 completed (loss: 0.3870280981063843, acc: 0.9013158082962036)
[2024-12-17 02:24:29,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:29,441][root][INFO] - Training Epoch: 2/2, step 544/7134 completed (loss: 0.33433303236961365, acc: 0.9214285612106323)
[2024-12-17 02:24:29,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:29,729][root][INFO] - Training Epoch: 2/2, step 545/7134 completed (loss: 0.49233779311180115, acc: 0.8947368264198303)
[2024-12-17 02:24:29,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:30,050][root][INFO] - Training Epoch: 2/2, step 546/7134 completed (loss: 0.4631624221801758, acc: 0.8703703880310059)
[2024-12-17 02:24:30,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:30,351][root][INFO] - Training Epoch: 2/2, step 547/7134 completed (loss: 0.28389987349510193, acc: 0.9337748289108276)
[2024-12-17 02:24:30,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:30,637][root][INFO] - Training Epoch: 2/2, step 548/7134 completed (loss: 0.24118347465991974, acc: 0.9671052694320679)
[2024-12-17 02:24:30,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:30,925][root][INFO] - Training Epoch: 2/2, step 549/7134 completed (loss: 0.5195753574371338, acc: 0.9142857193946838)
[2024-12-17 02:24:31,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:31,229][root][INFO] - Training Epoch: 2/2, step 550/7134 completed (loss: 0.3415576219558716, acc: 0.8976377844810486)
[2024-12-17 02:24:31,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:31,502][root][INFO] - Training Epoch: 2/2, step 551/7134 completed (loss: 0.40902450680732727, acc: 0.9140625)
[2024-12-17 02:24:31,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:31,774][root][INFO] - Training Epoch: 2/2, step 552/7134 completed (loss: 0.21122269332408905, acc: 0.9387755393981934)
[2024-12-17 02:24:31,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:32,068][root][INFO] - Training Epoch: 2/2, step 553/7134 completed (loss: 0.37640684843063354, acc: 0.9263157844543457)
[2024-12-17 02:24:32,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:32,386][root][INFO] - Training Epoch: 2/2, step 554/7134 completed (loss: 0.3864991068840027, acc: 0.9235668778419495)
[2024-12-17 02:24:32,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:32,693][root][INFO] - Training Epoch: 2/2, step 555/7134 completed (loss: 0.44867295026779175, acc: 0.8961039185523987)
[2024-12-17 02:24:32,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:32,968][root][INFO] - Training Epoch: 2/2, step 556/7134 completed (loss: 0.1776355803012848, acc: 0.9312499761581421)
[2024-12-17 02:24:33,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:33,251][root][INFO] - Training Epoch: 2/2, step 557/7134 completed (loss: 0.354885071516037, acc: 0.9007092118263245)
[2024-12-17 02:24:33,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:33,534][root][INFO] - Training Epoch: 2/2, step 558/7134 completed (loss: 0.3500468134880066, acc: 0.9166666865348816)
[2024-12-17 02:24:33,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:33,809][root][INFO] - Training Epoch: 2/2, step 559/7134 completed (loss: 0.3596343398094177, acc: 0.9127516746520996)
[2024-12-17 02:24:33,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:34,086][root][INFO] - Training Epoch: 2/2, step 560/7134 completed (loss: 0.17969314754009247, acc: 0.9512194991111755)
[2024-12-17 02:24:34,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:34,378][root][INFO] - Training Epoch: 2/2, step 561/7134 completed (loss: 0.27240684628486633, acc: 0.949999988079071)
[2024-12-17 02:24:34,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:34,645][root][INFO] - Training Epoch: 2/2, step 562/7134 completed (loss: 0.23734526336193085, acc: 0.9285714030265808)
[2024-12-17 02:24:34,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:34,915][root][INFO] - Training Epoch: 2/2, step 563/7134 completed (loss: 0.5250948667526245, acc: 0.8881118893623352)
[2024-12-17 02:24:35,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:35,198][root][INFO] - Training Epoch: 2/2, step 564/7134 completed (loss: 0.3450104594230652, acc: 0.9122806787490845)
[2024-12-17 02:24:35,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:35,458][root][INFO] - Training Epoch: 2/2, step 565/7134 completed (loss: 0.2663692831993103, acc: 0.9370078444480896)
[2024-12-17 02:24:35,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:35,746][root][INFO] - Training Epoch: 2/2, step 566/7134 completed (loss: 0.2837997376918793, acc: 0.9099099040031433)
[2024-12-17 02:24:35,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:36,031][root][INFO] - Training Epoch: 2/2, step 567/7134 completed (loss: 0.358856737613678, acc: 0.886227548122406)
[2024-12-17 02:24:36,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:36,310][root][INFO] - Training Epoch: 2/2, step 568/7134 completed (loss: 0.27521198987960815, acc: 0.9210526347160339)
[2024-12-17 02:24:36,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:36,593][root][INFO] - Training Epoch: 2/2, step 569/7134 completed (loss: 0.19004008173942566, acc: 0.9497206807136536)
[2024-12-17 02:24:36,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:36,905][root][INFO] - Training Epoch: 2/2, step 570/7134 completed (loss: 0.2824171185493469, acc: 0.9154228568077087)
[2024-12-17 02:24:37,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:37,210][root][INFO] - Training Epoch: 2/2, step 571/7134 completed (loss: 0.19839535653591156, acc: 0.9560439586639404)
[2024-12-17 02:24:37,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:37,500][root][INFO] - Training Epoch: 2/2, step 572/7134 completed (loss: 0.14282484352588654, acc: 0.954285740852356)
[2024-12-17 02:24:37,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:37,806][root][INFO] - Training Epoch: 2/2, step 573/7134 completed (loss: 0.20715968310832977, acc: 0.939393937587738)
[2024-12-17 02:24:37,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:38,097][root][INFO] - Training Epoch: 2/2, step 574/7134 completed (loss: 0.19439437985420227, acc: 0.9408283829689026)
[2024-12-17 02:24:38,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:38,420][root][INFO] - Training Epoch: 2/2, step 575/7134 completed (loss: 0.20507210493087769, acc: 0.9590643048286438)
[2024-12-17 02:24:38,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:38,705][root][INFO] - Training Epoch: 2/2, step 576/7134 completed (loss: 0.1572239100933075, acc: 0.9516128897666931)
[2024-12-17 02:24:38,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:39,010][root][INFO] - Training Epoch: 2/2, step 577/7134 completed (loss: 0.31927669048309326, acc: 0.9333333373069763)
[2024-12-17 02:24:39,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:39,317][root][INFO] - Training Epoch: 2/2, step 578/7134 completed (loss: 0.23649929463863373, acc: 0.9452736377716064)
[2024-12-17 02:24:39,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:39,591][root][INFO] - Training Epoch: 2/2, step 579/7134 completed (loss: 0.3643873333930969, acc: 0.9193548560142517)
[2024-12-17 02:24:39,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:39,872][root][INFO] - Training Epoch: 2/2, step 580/7134 completed (loss: 0.5353559851646423, acc: 0.8999999761581421)
[2024-12-17 02:24:40,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:40,169][root][INFO] - Training Epoch: 2/2, step 581/7134 completed (loss: 0.16497530043125153, acc: 0.9473684430122375)
[2024-12-17 02:24:40,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:40,453][root][INFO] - Training Epoch: 2/2, step 582/7134 completed (loss: 0.20217035710811615, acc: 0.945652186870575)
[2024-12-17 02:24:40,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:40,736][root][INFO] - Training Epoch: 2/2, step 583/7134 completed (loss: 0.13937245309352875, acc: 0.970059871673584)
[2024-12-17 02:24:40,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:41,018][root][INFO] - Training Epoch: 2/2, step 584/7134 completed (loss: 0.13552479445934296, acc: 0.9508196711540222)
[2024-12-17 02:24:41,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:41,295][root][INFO] - Training Epoch: 2/2, step 585/7134 completed (loss: 0.1767064481973648, acc: 0.9513513445854187)
[2024-12-17 02:24:41,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:41,587][root][INFO] - Training Epoch: 2/2, step 586/7134 completed (loss: 0.1511693000793457, acc: 0.957446813583374)
[2024-12-17 02:24:41,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:41,867][root][INFO] - Training Epoch: 2/2, step 587/7134 completed (loss: 0.15321402251720428, acc: 0.9613259434700012)
[2024-12-17 02:24:42,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:42,161][root][INFO] - Training Epoch: 2/2, step 588/7134 completed (loss: 0.14398840069770813, acc: 0.9662162065505981)
[2024-12-17 02:24:42,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:42,448][root][INFO] - Training Epoch: 2/2, step 589/7134 completed (loss: 0.15212607383728027, acc: 0.9631901979446411)
[2024-12-17 02:24:42,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:42,737][root][INFO] - Training Epoch: 2/2, step 590/7134 completed (loss: 0.2009347528219223, acc: 0.940397322177887)
[2024-12-17 02:24:42,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:43,013][root][INFO] - Training Epoch: 2/2, step 591/7134 completed (loss: 0.1858115792274475, acc: 0.9604519605636597)
[2024-12-17 02:24:43,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:43,291][root][INFO] - Training Epoch: 2/2, step 592/7134 completed (loss: 0.13080978393554688, acc: 0.9659090638160706)
[2024-12-17 02:24:43,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:43,569][root][INFO] - Training Epoch: 2/2, step 593/7134 completed (loss: 0.26224836707115173, acc: 0.9415204524993896)
[2024-12-17 02:24:43,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:43,850][root][INFO] - Training Epoch: 2/2, step 594/7134 completed (loss: 0.3454325795173645, acc: 0.9341317415237427)
[2024-12-17 02:24:43,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:44,145][root][INFO] - Training Epoch: 2/2, step 595/7134 completed (loss: 0.16441529989242554, acc: 0.9731183052062988)
[2024-12-17 02:24:44,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:44,421][root][INFO] - Training Epoch: 2/2, step 596/7134 completed (loss: 0.20216408371925354, acc: 0.9555555582046509)
[2024-12-17 02:24:44,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:44,711][root][INFO] - Training Epoch: 2/2, step 597/7134 completed (loss: 0.28145813941955566, acc: 0.9273743033409119)
[2024-12-17 02:24:44,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:44,993][root][INFO] - Training Epoch: 2/2, step 598/7134 completed (loss: 0.4261677861213684, acc: 0.9130434989929199)
[2024-12-17 02:24:45,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:45,275][root][INFO] - Training Epoch: 2/2, step 599/7134 completed (loss: 0.21066835522651672, acc: 0.9569892287254333)
[2024-12-17 02:24:45,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:45,559][root][INFO] - Training Epoch: 2/2, step 600/7134 completed (loss: 0.18976335227489471, acc: 0.9562841653823853)
[2024-12-17 02:24:45,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:45,851][root][INFO] - Training Epoch: 2/2, step 601/7134 completed (loss: 0.33318307995796204, acc: 0.9204545617103577)
[2024-12-17 02:24:45,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:46,133][root][INFO] - Training Epoch: 2/2, step 602/7134 completed (loss: 0.26478004455566406, acc: 0.9351351261138916)
[2024-12-17 02:24:46,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:46,414][root][INFO] - Training Epoch: 2/2, step 603/7134 completed (loss: 0.3058607280254364, acc: 0.9365079402923584)
[2024-12-17 02:24:46,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:46,676][root][INFO] - Training Epoch: 2/2, step 604/7134 completed (loss: 0.2770058810710907, acc: 0.939393937587738)
[2024-12-17 02:24:46,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:46,957][root][INFO] - Training Epoch: 2/2, step 605/7134 completed (loss: 0.21250799298286438, acc: 0.9625668525695801)
[2024-12-17 02:24:47,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:47,253][root][INFO] - Training Epoch: 2/2, step 606/7134 completed (loss: 0.20970076322555542, acc: 0.9549999833106995)
[2024-12-17 02:24:47,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:47,535][root][INFO] - Training Epoch: 2/2, step 607/7134 completed (loss: 0.16452261805534363, acc: 0.954023003578186)
[2024-12-17 02:24:47,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:47,828][root][INFO] - Training Epoch: 2/2, step 608/7134 completed (loss: 0.1747548133134842, acc: 0.9459459185600281)
[2024-12-17 02:24:47,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:48,126][root][INFO] - Training Epoch: 2/2, step 609/7134 completed (loss: 0.2433321624994278, acc: 0.9589743614196777)
[2024-12-17 02:24:48,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:48,431][root][INFO] - Training Epoch: 2/2, step 610/7134 completed (loss: 0.24036942422389984, acc: 0.9605911374092102)
[2024-12-17 02:24:48,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:48,707][root][INFO] - Training Epoch: 2/2, step 611/7134 completed (loss: 0.21372711658477783, acc: 0.9491525292396545)
[2024-12-17 02:24:48,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:48,994][root][INFO] - Training Epoch: 2/2, step 612/7134 completed (loss: 0.2468821108341217, acc: 0.95652174949646)
[2024-12-17 02:24:49,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:49,283][root][INFO] - Training Epoch: 2/2, step 613/7134 completed (loss: 0.1684972196817398, acc: 0.9494949579238892)
[2024-12-17 02:24:49,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:49,572][root][INFO] - Training Epoch: 2/2, step 614/7134 completed (loss: 0.12086574733257294, acc: 0.967391312122345)
[2024-12-17 02:24:49,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:49,853][root][INFO] - Training Epoch: 2/2, step 615/7134 completed (loss: 0.12201927602291107, acc: 0.9789473414421082)
[2024-12-17 02:24:50,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:50,154][root][INFO] - Training Epoch: 2/2, step 616/7134 completed (loss: 0.19085225462913513, acc: 0.9539170265197754)
[2024-12-17 02:24:50,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:50,441][root][INFO] - Training Epoch: 2/2, step 617/7134 completed (loss: 0.26649075746536255, acc: 0.9377990365028381)
[2024-12-17 02:24:50,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:50,735][root][INFO] - Training Epoch: 2/2, step 618/7134 completed (loss: 0.13875152170658112, acc: 0.9732620120048523)
[2024-12-17 02:24:50,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:51,015][root][INFO] - Training Epoch: 2/2, step 619/7134 completed (loss: 0.20997634530067444, acc: 0.9754098653793335)
[2024-12-17 02:24:51,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:51,301][root][INFO] - Training Epoch: 2/2, step 620/7134 completed (loss: 0.24050500988960266, acc: 0.9246575236320496)
[2024-12-17 02:24:51,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:51,620][root][INFO] - Training Epoch: 2/2, step 621/7134 completed (loss: 0.164869025349617, acc: 0.9666666388511658)
[2024-12-17 02:24:51,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:51,911][root][INFO] - Training Epoch: 2/2, step 622/7134 completed (loss: 0.28574132919311523, acc: 0.9473684430122375)
[2024-12-17 02:24:52,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:52,163][root][INFO] - Training Epoch: 2/2, step 623/7134 completed (loss: 0.4579816162586212, acc: 0.8992805480957031)
[2024-12-17 02:24:52,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:52,443][root][INFO] - Training Epoch: 2/2, step 624/7134 completed (loss: 0.2175045907497406, acc: 0.956204354763031)
[2024-12-17 02:24:52,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:52,728][root][INFO] - Training Epoch: 2/2, step 625/7134 completed (loss: 0.24930045008659363, acc: 0.9375)
[2024-12-17 02:24:52,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:53,003][root][INFO] - Training Epoch: 2/2, step 626/7134 completed (loss: 0.20110008120536804, acc: 0.9520000219345093)
[2024-12-17 02:24:53,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:53,279][root][INFO] - Training Epoch: 2/2, step 627/7134 completed (loss: 0.19426202774047852, acc: 0.9591836929321289)
[2024-12-17 02:24:53,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:53,554][root][INFO] - Training Epoch: 2/2, step 628/7134 completed (loss: 0.18825672566890717, acc: 0.9319728016853333)
[2024-12-17 02:24:53,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:53,822][root][INFO] - Training Epoch: 2/2, step 629/7134 completed (loss: 0.3373563885688782, acc: 0.914893627166748)
[2024-12-17 02:24:53,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:54,116][root][INFO] - Training Epoch: 2/2, step 630/7134 completed (loss: 0.35266217589378357, acc: 0.8789808750152588)
[2024-12-17 02:24:54,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:54,372][root][INFO] - Training Epoch: 2/2, step 631/7134 completed (loss: 0.2159496396780014, acc: 0.9285714030265808)
[2024-12-17 02:24:54,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:54,662][root][INFO] - Training Epoch: 2/2, step 632/7134 completed (loss: 0.09293791651725769, acc: 0.9929577708244324)
[2024-12-17 02:24:54,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:54,939][root][INFO] - Training Epoch: 2/2, step 633/7134 completed (loss: 0.21264202892780304, acc: 0.949999988079071)
[2024-12-17 02:24:55,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:55,217][root][INFO] - Training Epoch: 2/2, step 634/7134 completed (loss: 0.3261364698410034, acc: 0.9220778942108154)
[2024-12-17 02:24:55,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:55,509][root][INFO] - Training Epoch: 2/2, step 635/7134 completed (loss: 0.23070932924747467, acc: 0.9415584206581116)
[2024-12-17 02:24:55,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:55,792][root][INFO] - Training Epoch: 2/2, step 636/7134 completed (loss: 0.2429375946521759, acc: 0.9520958065986633)
[2024-12-17 02:24:55,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:56,064][root][INFO] - Training Epoch: 2/2, step 637/7134 completed (loss: 0.23560687899589539, acc: 0.9424460530281067)
[2024-12-17 02:24:56,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:56,332][root][INFO] - Training Epoch: 2/2, step 638/7134 completed (loss: 0.1422378122806549, acc: 0.9798657894134521)
[2024-12-17 02:24:56,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:56,607][root][INFO] - Training Epoch: 2/2, step 639/7134 completed (loss: 0.15119299292564392, acc: 0.9571428298950195)
[2024-12-17 02:24:56,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:56,878][root][INFO] - Training Epoch: 2/2, step 640/7134 completed (loss: 0.2875448167324066, acc: 0.9202898740768433)
[2024-12-17 02:24:57,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:57,149][root][INFO] - Training Epoch: 2/2, step 641/7134 completed (loss: 0.18872790038585663, acc: 0.9637681245803833)
[2024-12-17 02:24:57,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:57,431][root][INFO] - Training Epoch: 2/2, step 642/7134 completed (loss: 0.20648866891860962, acc: 0.9558823704719543)
[2024-12-17 02:24:57,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:57,736][root][INFO] - Training Epoch: 2/2, step 643/7134 completed (loss: 0.17431634664535522, acc: 0.932584285736084)
[2024-12-17 02:24:57,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:58,014][root][INFO] - Training Epoch: 2/2, step 644/7134 completed (loss: 0.11715751886367798, acc: 0.9609375)
[2024-12-17 02:24:58,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:58,306][root][INFO] - Training Epoch: 2/2, step 645/7134 completed (loss: 0.10222914814949036, acc: 0.9724137783050537)
[2024-12-17 02:24:58,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:58,587][root][INFO] - Training Epoch: 2/2, step 646/7134 completed (loss: 0.18646375834941864, acc: 0.9303797483444214)
[2024-12-17 02:24:58,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:58,893][root][INFO] - Training Epoch: 2/2, step 647/7134 completed (loss: 0.09206171333789825, acc: 0.970370352268219)
[2024-12-17 02:24:59,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:59,172][root][INFO] - Training Epoch: 2/2, step 648/7134 completed (loss: 0.5964600443840027, acc: 0.8461538553237915)
[2024-12-17 02:24:59,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:59,449][root][INFO] - Training Epoch: 2/2, step 649/7134 completed (loss: 0.372027188539505, acc: 0.8864864706993103)
[2024-12-17 02:24:59,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:59,738][root][INFO] - Training Epoch: 2/2, step 650/7134 completed (loss: 0.41873329877853394, acc: 0.9041095972061157)
[2024-12-17 02:24:59,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:00,073][root][INFO] - Training Epoch: 2/2, step 651/7134 completed (loss: 0.4993517994880676, acc: 0.9025974273681641)
[2024-12-17 02:25:00,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:00,358][root][INFO] - Training Epoch: 2/2, step 652/7134 completed (loss: 0.27539655566215515, acc: 0.9436619877815247)
[2024-12-17 02:25:00,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:00,639][root][INFO] - Training Epoch: 2/2, step 653/7134 completed (loss: 0.23852603137493134, acc: 0.9636363387107849)
[2024-12-17 02:25:00,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:00,907][root][INFO] - Training Epoch: 2/2, step 654/7134 completed (loss: 0.5724858641624451, acc: 0.8796992301940918)
[2024-12-17 02:25:01,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:01,195][root][INFO] - Training Epoch: 2/2, step 655/7134 completed (loss: 0.3486623466014862, acc: 0.9051724076271057)
[2024-12-17 02:25:01,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:01,477][root][INFO] - Training Epoch: 2/2, step 656/7134 completed (loss: 0.27950647473335266, acc: 0.9292929172515869)
[2024-12-17 02:25:01,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:01,763][root][INFO] - Training Epoch: 2/2, step 657/7134 completed (loss: 0.40229636430740356, acc: 0.9014084339141846)
[2024-12-17 02:25:01,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:02,053][root][INFO] - Training Epoch: 2/2, step 658/7134 completed (loss: 0.2085890918970108, acc: 0.9491525292396545)
[2024-12-17 02:25:02,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:02,343][root][INFO] - Training Epoch: 2/2, step 659/7134 completed (loss: 0.10647419840097427, acc: 0.970059871673584)
[2024-12-17 02:25:02,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:02,626][root][INFO] - Training Epoch: 2/2, step 660/7134 completed (loss: 0.19787833094596863, acc: 0.9588235020637512)
[2024-12-17 02:25:02,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:02,918][root][INFO] - Training Epoch: 2/2, step 661/7134 completed (loss: 0.28487080335617065, acc: 0.9194915294647217)
[2024-12-17 02:25:03,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:03,211][root][INFO] - Training Epoch: 2/2, step 662/7134 completed (loss: 0.23262077569961548, acc: 0.9444444179534912)
[2024-12-17 02:25:03,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:03,508][root][INFO] - Training Epoch: 2/2, step 663/7134 completed (loss: 0.1871814727783203, acc: 0.9563106894493103)
[2024-12-17 02:25:03,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:03,779][root][INFO] - Training Epoch: 2/2, step 664/7134 completed (loss: 0.24323417246341705, acc: 0.9300699234008789)
[2024-12-17 02:25:03,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:04,067][root][INFO] - Training Epoch: 2/2, step 665/7134 completed (loss: 0.39316266775131226, acc: 0.9398906826972961)
[2024-12-17 02:25:04,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:04,362][root][INFO] - Training Epoch: 2/2, step 666/7134 completed (loss: 0.2841052711009979, acc: 0.9257143139839172)
[2024-12-17 02:25:04,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:04,642][root][INFO] - Training Epoch: 2/2, step 667/7134 completed (loss: 0.4105393588542938, acc: 0.9221556782722473)
[2024-12-17 02:25:04,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:04,921][root][INFO] - Training Epoch: 2/2, step 668/7134 completed (loss: 0.20730003714561462, acc: 0.9562841653823853)
[2024-12-17 02:25:05,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:05,224][root][INFO] - Training Epoch: 2/2, step 669/7134 completed (loss: 0.19246584177017212, acc: 0.9720670580863953)
[2024-12-17 02:25:05,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:05,531][root][INFO] - Training Epoch: 2/2, step 670/7134 completed (loss: 0.22036121785640717, acc: 0.9452054500579834)
[2024-12-17 02:25:05,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:05,831][root][INFO] - Training Epoch: 2/2, step 671/7134 completed (loss: 0.2088286578655243, acc: 0.959276020526886)
[2024-12-17 02:25:05,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:06,111][root][INFO] - Training Epoch: 2/2, step 672/7134 completed (loss: 0.24834415316581726, acc: 0.949999988079071)
[2024-12-17 02:25:06,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:06,390][root][INFO] - Training Epoch: 2/2, step 673/7134 completed (loss: 0.2981985807418823, acc: 0.9353233575820923)
[2024-12-17 02:25:06,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:06,664][root][INFO] - Training Epoch: 2/2, step 674/7134 completed (loss: 0.1622585654258728, acc: 0.9512194991111755)
[2024-12-17 02:25:06,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:06,939][root][INFO] - Training Epoch: 2/2, step 675/7134 completed (loss: 0.19932855665683746, acc: 0.950276255607605)
[2024-12-17 02:25:07,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:07,206][root][INFO] - Training Epoch: 2/2, step 676/7134 completed (loss: 0.12655708193778992, acc: 0.9619565010070801)
[2024-12-17 02:25:07,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:07,485][root][INFO] - Training Epoch: 2/2, step 677/7134 completed (loss: 0.10134246945381165, acc: 0.9841269850730896)
[2024-12-17 02:25:07,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:07,764][root][INFO] - Training Epoch: 2/2, step 678/7134 completed (loss: 0.2981295883655548, acc: 0.9268292784690857)
[2024-12-17 02:25:07,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:08,016][root][INFO] - Training Epoch: 2/2, step 679/7134 completed (loss: 0.2783602178096771, acc: 0.9172932505607605)
[2024-12-17 02:25:08,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:08,298][root][INFO] - Training Epoch: 2/2, step 680/7134 completed (loss: 0.2804080843925476, acc: 0.9447236061096191)
[2024-12-17 02:25:08,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:08,585][root][INFO] - Training Epoch: 2/2, step 681/7134 completed (loss: 0.2729649245738983, acc: 0.942105233669281)
[2024-12-17 02:25:08,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:08,855][root][INFO] - Training Epoch: 2/2, step 682/7134 completed (loss: 0.11582987755537033, acc: 0.9717513918876648)
[2024-12-17 02:25:08,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:09,149][root][INFO] - Training Epoch: 2/2, step 683/7134 completed (loss: 0.21748307347297668, acc: 0.9243243336677551)
[2024-12-17 02:25:09,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:09,438][root][INFO] - Training Epoch: 2/2, step 684/7134 completed (loss: 0.2764855623245239, acc: 0.9277777671813965)
[2024-12-17 02:25:09,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:09,724][root][INFO] - Training Epoch: 2/2, step 685/7134 completed (loss: 0.1824643909931183, acc: 0.9497487545013428)
[2024-12-17 02:25:09,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:10,008][root][INFO] - Training Epoch: 2/2, step 686/7134 completed (loss: 0.1261238306760788, acc: 0.9617486596107483)
[2024-12-17 02:25:10,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:10,306][root][INFO] - Training Epoch: 2/2, step 687/7134 completed (loss: 0.23869766294956207, acc: 0.8976377844810486)
[2024-12-17 02:25:10,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:10,591][root][INFO] - Training Epoch: 2/2, step 688/7134 completed (loss: 0.09448690712451935, acc: 0.9683544039726257)
[2024-12-17 02:25:10,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:10,848][root][INFO] - Training Epoch: 2/2, step 689/7134 completed (loss: 0.20784127712249756, acc: 0.9259259104728699)
[2024-12-17 02:25:10,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:11,134][root][INFO] - Training Epoch: 2/2, step 690/7134 completed (loss: 0.30752575397491455, acc: 0.9225806593894958)
[2024-12-17 02:25:11,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:11,431][root][INFO] - Training Epoch: 2/2, step 691/7134 completed (loss: 0.3356655538082123, acc: 0.9220778942108154)
[2024-12-17 02:25:11,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:11,729][root][INFO] - Training Epoch: 2/2, step 692/7134 completed (loss: 0.42510560154914856, acc: 0.9238578677177429)
[2024-12-17 02:25:11,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:12,010][root][INFO] - Training Epoch: 2/2, step 693/7134 completed (loss: 0.28110024333000183, acc: 0.9219858050346375)
[2024-12-17 02:25:12,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:12,306][root][INFO] - Training Epoch: 2/2, step 694/7134 completed (loss: 0.3861636221408844, acc: 0.9090909361839294)
[2024-12-17 02:25:12,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:12,586][root][INFO] - Training Epoch: 2/2, step 695/7134 completed (loss: 0.4412267506122589, acc: 0.89552241563797)
[2024-12-17 02:25:12,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:12,859][root][INFO] - Training Epoch: 2/2, step 696/7134 completed (loss: 0.4399568438529968, acc: 0.893081784248352)
[2024-12-17 02:25:12,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:13,136][root][INFO] - Training Epoch: 2/2, step 697/7134 completed (loss: 0.24916449189186096, acc: 0.9239130616188049)
[2024-12-17 02:25:13,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:13,411][root][INFO] - Training Epoch: 2/2, step 698/7134 completed (loss: 0.1849597841501236, acc: 0.9696969985961914)
[2024-12-17 02:25:13,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:13,713][root][INFO] - Training Epoch: 2/2, step 699/7134 completed (loss: 0.16079868376255035, acc: 0.965753436088562)
[2024-12-17 02:25:13,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:13,990][root][INFO] - Training Epoch: 2/2, step 700/7134 completed (loss: 0.42194056510925293, acc: 0.9039999842643738)
[2024-12-17 02:25:14,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:14,246][root][INFO] - Training Epoch: 2/2, step 701/7134 completed (loss: 0.4378252327442169, acc: 0.8695651888847351)
[2024-12-17 02:25:14,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:14,546][root][INFO] - Training Epoch: 2/2, step 702/7134 completed (loss: 0.3984015882015228, acc: 0.9271523356437683)
[2024-12-17 02:25:14,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:14,826][root][INFO] - Training Epoch: 2/2, step 703/7134 completed (loss: 0.286357581615448, acc: 0.912162184715271)
[2024-12-17 02:25:14,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:15,108][root][INFO] - Training Epoch: 2/2, step 704/7134 completed (loss: 0.31548547744750977, acc: 0.9415584206581116)
[2024-12-17 02:25:15,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:15,405][root][INFO] - Training Epoch: 2/2, step 705/7134 completed (loss: 0.36643627285957336, acc: 0.9128440618515015)
[2024-12-17 02:25:15,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:15,685][root][INFO] - Training Epoch: 2/2, step 706/7134 completed (loss: 0.15321271121501923, acc: 0.9528301954269409)
[2024-12-17 02:25:15,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:15,959][root][INFO] - Training Epoch: 2/2, step 707/7134 completed (loss: 0.22026179730892181, acc: 0.9405940771102905)
[2024-12-17 02:25:16,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:16,249][root][INFO] - Training Epoch: 2/2, step 708/7134 completed (loss: 0.1874726116657257, acc: 0.9775280952453613)
[2024-12-17 02:25:16,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:16,532][root][INFO] - Training Epoch: 2/2, step 709/7134 completed (loss: 0.16891230642795563, acc: 0.977142870426178)
[2024-12-17 02:25:16,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:16,818][root][INFO] - Training Epoch: 2/2, step 710/7134 completed (loss: 0.1932566910982132, acc: 0.953125)
[2024-12-17 02:25:16,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:17,091][root][INFO] - Training Epoch: 2/2, step 711/7134 completed (loss: 0.30181869864463806, acc: 0.9264705777168274)
[2024-12-17 02:25:17,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:17,354][root][INFO] - Training Epoch: 2/2, step 712/7134 completed (loss: 0.08751031011343002, acc: 0.984375)
[2024-12-17 02:25:17,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:17,633][root][INFO] - Training Epoch: 2/2, step 713/7134 completed (loss: 0.1243574470281601, acc: 0.9648241400718689)
[2024-12-17 02:25:17,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:17,882][root][INFO] - Training Epoch: 2/2, step 714/7134 completed (loss: 0.22402454912662506, acc: 0.9200000166893005)
[2024-12-17 02:25:17,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:18,185][root][INFO] - Training Epoch: 2/2, step 715/7134 completed (loss: 0.07639071345329285, acc: 0.9728260636329651)
[2024-12-17 02:25:18,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:18,466][root][INFO] - Training Epoch: 2/2, step 716/7134 completed (loss: 0.08537929505109787, acc: 0.9852941036224365)
[2024-12-17 02:25:18,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:18,736][root][INFO] - Training Epoch: 2/2, step 717/7134 completed (loss: 0.17936210334300995, acc: 0.9518716335296631)
[2024-12-17 02:25:18,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:19,026][root][INFO] - Training Epoch: 2/2, step 718/7134 completed (loss: 0.12628746032714844, acc: 0.9629629850387573)
[2024-12-17 02:25:19,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:19,289][root][INFO] - Training Epoch: 2/2, step 719/7134 completed (loss: 0.08076328784227371, acc: 0.9858155846595764)
[2024-12-17 02:25:19,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:19,584][root][INFO] - Training Epoch: 2/2, step 720/7134 completed (loss: 0.11772341281175613, acc: 0.9675675630569458)
[2024-12-17 02:25:19,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:19,881][root][INFO] - Training Epoch: 2/2, step 721/7134 completed (loss: 0.14676064252853394, acc: 0.9736841917037964)
[2024-12-17 02:25:19,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:20,193][root][INFO] - Training Epoch: 2/2, step 722/7134 completed (loss: 0.1445496529340744, acc: 0.9646464586257935)
[2024-12-17 02:25:20,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:20,493][root][INFO] - Training Epoch: 2/2, step 723/7134 completed (loss: 0.09436803311109543, acc: 0.9619565010070801)
[2024-12-17 02:25:20,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:20,767][root][INFO] - Training Epoch: 2/2, step 724/7134 completed (loss: 0.20138688385486603, acc: 0.9496855139732361)
[2024-12-17 02:25:20,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:21,049][root][INFO] - Training Epoch: 2/2, step 725/7134 completed (loss: 0.09492028504610062, acc: 0.9702380895614624)
[2024-12-17 02:25:21,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:21,330][root][INFO] - Training Epoch: 2/2, step 726/7134 completed (loss: 0.06284254789352417, acc: 0.9720670580863953)
[2024-12-17 02:25:21,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:21,611][root][INFO] - Training Epoch: 2/2, step 727/7134 completed (loss: 0.21930158138275146, acc: 0.9653179049491882)
[2024-12-17 02:25:21,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:21,897][root][INFO] - Training Epoch: 2/2, step 728/7134 completed (loss: 0.07648267596960068, acc: 0.977142870426178)
[2024-12-17 02:25:22,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:22,166][root][INFO] - Training Epoch: 2/2, step 729/7134 completed (loss: 0.06853488087654114, acc: 0.9936708807945251)
[2024-12-17 02:25:22,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:22,441][root][INFO] - Training Epoch: 2/2, step 730/7134 completed (loss: 0.08438000082969666, acc: 0.9840425252914429)
[2024-12-17 02:25:22,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:22,725][root][INFO] - Training Epoch: 2/2, step 731/7134 completed (loss: 0.05533144623041153, acc: 0.9830508232116699)
[2024-12-17 02:25:22,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:23,011][root][INFO] - Training Epoch: 2/2, step 732/7134 completed (loss: 0.23523899912834167, acc: 0.9426229596138)
[2024-12-17 02:25:23,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:23,271][root][INFO] - Training Epoch: 2/2, step 733/7134 completed (loss: 0.14862090349197388, acc: 0.9615384340286255)
[2024-12-17 02:25:23,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:23,552][root][INFO] - Training Epoch: 2/2, step 734/7134 completed (loss: 0.1770680844783783, acc: 0.9516128897666931)
[2024-12-17 02:25:23,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:23,830][root][INFO] - Training Epoch: 2/2, step 735/7134 completed (loss: 0.12264285236597061, acc: 0.9718309640884399)
[2024-12-17 02:25:23,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:24,099][root][INFO] - Training Epoch: 2/2, step 736/7134 completed (loss: 0.535316526889801, acc: 0.8910890817642212)
[2024-12-17 02:25:24,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:24,385][root][INFO] - Training Epoch: 2/2, step 737/7134 completed (loss: 0.3002297580242157, acc: 0.9152542352676392)
[2024-12-17 02:25:24,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:24,656][root][INFO] - Training Epoch: 2/2, step 738/7134 completed (loss: 0.05402417108416557, acc: 0.9905660152435303)
[2024-12-17 02:25:24,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:24,938][root][INFO] - Training Epoch: 2/2, step 739/7134 completed (loss: 0.1415121853351593, acc: 0.947826087474823)
[2024-12-17 02:25:25,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:25,205][root][INFO] - Training Epoch: 2/2, step 740/7134 completed (loss: 0.056939803063869476, acc: 0.9837398529052734)
[2024-12-17 02:25:25,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:25,484][root][INFO] - Training Epoch: 2/2, step 741/7134 completed (loss: 0.21331138908863068, acc: 0.9481481313705444)
[2024-12-17 02:25:25,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:25,768][root][INFO] - Training Epoch: 2/2, step 742/7134 completed (loss: 0.14620526134967804, acc: 0.9473684430122375)
[2024-12-17 02:25:25,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:26,064][root][INFO] - Training Epoch: 2/2, step 743/7134 completed (loss: 0.2951836884021759, acc: 0.9387755393981934)
[2024-12-17 02:25:26,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:26,325][root][INFO] - Training Epoch: 2/2, step 744/7134 completed (loss: 0.07001305371522903, acc: 0.9800000190734863)
[2024-12-17 02:25:26,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:26,626][root][INFO] - Training Epoch: 2/2, step 745/7134 completed (loss: 0.1874053031206131, acc: 0.9558823704719543)
[2024-12-17 02:25:26,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:26,914][root][INFO] - Training Epoch: 2/2, step 746/7134 completed (loss: 0.19030901789665222, acc: 0.9541984796524048)
[2024-12-17 02:25:27,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:27,174][root][INFO] - Training Epoch: 2/2, step 747/7134 completed (loss: 0.27312707901000977, acc: 0.9370078444480896)
[2024-12-17 02:25:27,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:27,468][root][INFO] - Training Epoch: 2/2, step 748/7134 completed (loss: 0.22912044823169708, acc: 0.9477611780166626)
[2024-12-17 02:25:27,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:27,759][root][INFO] - Training Epoch: 2/2, step 749/7134 completed (loss: 0.15695150196552277, acc: 0.9642857313156128)
[2024-12-17 02:25:27,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:28,117][root][INFO] - Training Epoch: 2/2, step 750/7134 completed (loss: 0.1117277517914772, acc: 0.9834710955619812)
[2024-12-17 02:25:28,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:28,391][root][INFO] - Training Epoch: 2/2, step 751/7134 completed (loss: 0.25549688935279846, acc: 0.9520000219345093)
[2024-12-17 02:25:28,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:28,656][root][INFO] - Training Epoch: 2/2, step 752/7134 completed (loss: 0.3336089253425598, acc: 0.9594594836235046)
[2024-12-17 02:25:28,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:28,932][root][INFO] - Training Epoch: 2/2, step 753/7134 completed (loss: 0.13801506161689758, acc: 0.9765625)
[2024-12-17 02:25:29,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:29,212][root][INFO] - Training Epoch: 2/2, step 754/7134 completed (loss: 0.14357712864875793, acc: 0.9710144996643066)
[2024-12-17 02:25:29,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:29,504][root][INFO] - Training Epoch: 2/2, step 755/7134 completed (loss: 0.24227969348430634, acc: 0.9599999785423279)
[2024-12-17 02:25:29,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:29,817][root][INFO] - Training Epoch: 2/2, step 756/7134 completed (loss: 0.12995082139968872, acc: 0.9821428656578064)
[2024-12-17 02:25:29,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:30,110][root][INFO] - Training Epoch: 2/2, step 757/7134 completed (loss: 0.07861507683992386, acc: 0.9903846383094788)
[2024-12-17 02:25:30,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:30,382][root][INFO] - Training Epoch: 2/2, step 758/7134 completed (loss: 0.19843322038650513, acc: 0.9729729890823364)
[2024-12-17 02:25:30,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:30,647][root][INFO] - Training Epoch: 2/2, step 759/7134 completed (loss: 0.18564562499523163, acc: 0.9639639854431152)
[2024-12-17 02:25:30,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:30,914][root][INFO] - Training Epoch: 2/2, step 760/7134 completed (loss: 0.19103337824344635, acc: 0.9469696879386902)
[2024-12-17 02:25:31,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:31,187][root][INFO] - Training Epoch: 2/2, step 761/7134 completed (loss: 0.16063208878040314, acc: 0.946107804775238)
[2024-12-17 02:25:31,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:31,455][root][INFO] - Training Epoch: 2/2, step 762/7134 completed (loss: 0.14213284850120544, acc: 0.9637681245803833)
[2024-12-17 02:25:31,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:31,721][root][INFO] - Training Epoch: 2/2, step 763/7134 completed (loss: 0.26477041840553284, acc: 0.9210526347160339)
[2024-12-17 02:25:31,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:32,003][root][INFO] - Training Epoch: 2/2, step 764/7134 completed (loss: 0.06673939526081085, acc: 0.9881656765937805)
[2024-12-17 02:25:32,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:32,313][root][INFO] - Training Epoch: 2/2, step 765/7134 completed (loss: 0.06747878342866898, acc: 0.9811320900917053)
[2024-12-17 02:25:32,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:32,622][root][INFO] - Training Epoch: 2/2, step 766/7134 completed (loss: 0.11049799621105194, acc: 0.96875)
[2024-12-17 02:25:32,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:32,913][root][INFO] - Training Epoch: 2/2, step 767/7134 completed (loss: 0.1764778345823288, acc: 0.9404761791229248)
[2024-12-17 02:25:33,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:33,192][root][INFO] - Training Epoch: 2/2, step 768/7134 completed (loss: 0.403044730424881, acc: 0.9453551769256592)
[2024-12-17 02:25:33,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:33,479][root][INFO] - Training Epoch: 2/2, step 769/7134 completed (loss: 0.1398269534111023, acc: 0.9689440727233887)
[2024-12-17 02:25:33,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:33,747][root][INFO] - Training Epoch: 2/2, step 770/7134 completed (loss: 0.14306923747062683, acc: 0.9691358208656311)
[2024-12-17 02:25:33,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:34,050][root][INFO] - Training Epoch: 2/2, step 771/7134 completed (loss: 0.12097227573394775, acc: 0.9635036587715149)
[2024-12-17 02:25:34,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:34,325][root][INFO] - Training Epoch: 2/2, step 772/7134 completed (loss: 0.13464249670505524, acc: 0.9591836929321289)
[2024-12-17 02:25:34,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:34,630][root][INFO] - Training Epoch: 2/2, step 773/7134 completed (loss: 0.23666921257972717, acc: 0.9368420839309692)
[2024-12-17 02:25:34,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:34,903][root][INFO] - Training Epoch: 2/2, step 774/7134 completed (loss: 0.415367990732193, acc: 0.9154929518699646)
[2024-12-17 02:25:35,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:35,196][root][INFO] - Training Epoch: 2/2, step 775/7134 completed (loss: 0.26606228947639465, acc: 0.9414893388748169)
[2024-12-17 02:25:35,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:35,476][root][INFO] - Training Epoch: 2/2, step 776/7134 completed (loss: 0.14229781925678253, acc: 0.9617834687232971)
[2024-12-17 02:25:35,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:35,759][root][INFO] - Training Epoch: 2/2, step 777/7134 completed (loss: 0.09206195920705795, acc: 0.9666666388511658)
[2024-12-17 02:25:35,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:36,051][root][INFO] - Training Epoch: 2/2, step 778/7134 completed (loss: 0.19623254239559174, acc: 0.9433962106704712)
[2024-12-17 02:25:36,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:36,333][root][INFO] - Training Epoch: 2/2, step 779/7134 completed (loss: 0.2506416141986847, acc: 0.9298245906829834)
[2024-12-17 02:25:36,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:36,599][root][INFO] - Training Epoch: 2/2, step 780/7134 completed (loss: 0.2704005241394043, acc: 0.9405405521392822)
[2024-12-17 02:25:36,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:36,903][root][INFO] - Training Epoch: 2/2, step 781/7134 completed (loss: 0.30892711877822876, acc: 0.9264705777168274)
[2024-12-17 02:25:37,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:37,158][root][INFO] - Training Epoch: 2/2, step 782/7134 completed (loss: 0.2750120759010315, acc: 0.9303797483444214)
[2024-12-17 02:25:37,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:37,448][root][INFO] - Training Epoch: 2/2, step 783/7134 completed (loss: 0.2212720811367035, acc: 0.9252336621284485)
[2024-12-17 02:25:37,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:37,728][root][INFO] - Training Epoch: 2/2, step 784/7134 completed (loss: 0.13401347398757935, acc: 0.9701492786407471)
[2024-12-17 02:25:37,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:38,010][root][INFO] - Training Epoch: 2/2, step 785/7134 completed (loss: 0.4046628475189209, acc: 0.9133333563804626)
[2024-12-17 02:25:38,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:38,286][root][INFO] - Training Epoch: 2/2, step 786/7134 completed (loss: 0.26574188470840454, acc: 0.9328358173370361)
[2024-12-17 02:25:38,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:38,567][root][INFO] - Training Epoch: 2/2, step 787/7134 completed (loss: 0.10846809297800064, acc: 0.969924807548523)
[2024-12-17 02:25:38,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:38,843][root][INFO] - Training Epoch: 2/2, step 788/7134 completed (loss: 0.27137187123298645, acc: 0.9329608678817749)
[2024-12-17 02:25:38,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:39,123][root][INFO] - Training Epoch: 2/2, step 789/7134 completed (loss: 0.20191162824630737, acc: 0.942307710647583)
[2024-12-17 02:25:39,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:39,394][root][INFO] - Training Epoch: 2/2, step 790/7134 completed (loss: 0.27730023860931396, acc: 0.9324324131011963)
[2024-12-17 02:25:39,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:39,673][root][INFO] - Training Epoch: 2/2, step 791/7134 completed (loss: 0.3252266049385071, acc: 0.9268292784690857)
[2024-12-17 02:25:39,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:39,961][root][INFO] - Training Epoch: 2/2, step 792/7134 completed (loss: 0.24482794106006622, acc: 0.9367088675498962)
[2024-12-17 02:25:40,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:40,242][root][INFO] - Training Epoch: 2/2, step 793/7134 completed (loss: 0.12008136510848999, acc: 0.9624999761581421)
[2024-12-17 02:25:40,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:40,532][root][INFO] - Training Epoch: 2/2, step 794/7134 completed (loss: 0.16570140421390533, acc: 0.9396551847457886)
[2024-12-17 02:25:40,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:40,800][root][INFO] - Training Epoch: 2/2, step 795/7134 completed (loss: 0.27262482047080994, acc: 0.9620253443717957)
[2024-12-17 02:25:40,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:41,071][root][INFO] - Training Epoch: 2/2, step 796/7134 completed (loss: 0.1705436408519745, acc: 0.9523809552192688)
[2024-12-17 02:25:41,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:41,349][root][INFO] - Training Epoch: 2/2, step 797/7134 completed (loss: 0.20860502123832703, acc: 0.9527559280395508)
[2024-12-17 02:25:41,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:41,632][root][INFO] - Training Epoch: 2/2, step 798/7134 completed (loss: 0.08666693419218063, acc: 0.9797979593276978)
[2024-12-17 02:25:41,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:41,931][root][INFO] - Training Epoch: 2/2, step 799/7134 completed (loss: 0.12251017242670059, acc: 0.9586777091026306)
[2024-12-17 02:25:42,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:42,203][root][INFO] - Training Epoch: 2/2, step 800/7134 completed (loss: 0.28649574518203735, acc: 0.9259259104728699)
[2024-12-17 02:25:42,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:42,491][root][INFO] - Training Epoch: 2/2, step 801/7134 completed (loss: 0.391985684633255, acc: 0.9096774458885193)
[2024-12-17 02:25:42,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:42,770][root][INFO] - Training Epoch: 2/2, step 802/7134 completed (loss: 0.15469013154506683, acc: 0.957446813583374)
[2024-12-17 02:25:42,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:43,046][root][INFO] - Training Epoch: 2/2, step 803/7134 completed (loss: 0.1671237051486969, acc: 0.9420289993286133)
[2024-12-17 02:25:43,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:43,314][root][INFO] - Training Epoch: 2/2, step 804/7134 completed (loss: 0.4010520577430725, acc: 0.8759689927101135)
[2024-12-17 02:25:43,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:43,601][root][INFO] - Training Epoch: 2/2, step 805/7134 completed (loss: 0.34063437581062317, acc: 0.881118893623352)
[2024-12-17 02:25:43,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:43,874][root][INFO] - Training Epoch: 2/2, step 806/7134 completed (loss: 0.1753145158290863, acc: 0.9629629850387573)
[2024-12-17 02:25:44,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:44,179][root][INFO] - Training Epoch: 2/2, step 807/7134 completed (loss: 0.27962350845336914, acc: 0.9200000166893005)
[2024-12-17 02:25:44,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:44,478][root][INFO] - Training Epoch: 2/2, step 808/7134 completed (loss: 0.1455257087945938, acc: 0.9695431590080261)
[2024-12-17 02:25:44,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:44,760][root][INFO] - Training Epoch: 2/2, step 809/7134 completed (loss: 0.10700196772813797, acc: 0.9733333587646484)
[2024-12-17 02:25:44,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:45,043][root][INFO] - Training Epoch: 2/2, step 810/7134 completed (loss: 0.3032851815223694, acc: 0.9417989253997803)
[2024-12-17 02:25:45,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:45,324][root][INFO] - Training Epoch: 2/2, step 811/7134 completed (loss: 0.3328802287578583, acc: 0.9034482836723328)
[2024-12-17 02:25:45,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:45,617][root][INFO] - Training Epoch: 2/2, step 812/7134 completed (loss: 0.2009008675813675, acc: 0.9473684430122375)
[2024-12-17 02:25:45,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:45,892][root][INFO] - Training Epoch: 2/2, step 813/7134 completed (loss: 0.2833830714225769, acc: 0.929411768913269)
[2024-12-17 02:25:45,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:46,175][root][INFO] - Training Epoch: 2/2, step 814/7134 completed (loss: 0.1867193728685379, acc: 0.9548022747039795)
[2024-12-17 02:25:46,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:46,456][root][INFO] - Training Epoch: 2/2, step 815/7134 completed (loss: 0.16130322217941284, acc: 0.9551281929016113)
[2024-12-17 02:25:46,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:46,736][root][INFO] - Training Epoch: 2/2, step 816/7134 completed (loss: 0.2847966253757477, acc: 0.9219858050346375)
[2024-12-17 02:25:46,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:47,028][root][INFO] - Training Epoch: 2/2, step 817/7134 completed (loss: 0.3462662994861603, acc: 0.8992805480957031)
[2024-12-17 02:25:47,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:47,304][root][INFO] - Training Epoch: 2/2, step 818/7134 completed (loss: 0.4035712778568268, acc: 0.9084967374801636)
[2024-12-17 02:25:47,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:47,579][root][INFO] - Training Epoch: 2/2, step 819/7134 completed (loss: 0.382219135761261, acc: 0.9041095972061157)
[2024-12-17 02:25:47,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:47,876][root][INFO] - Training Epoch: 2/2, step 820/7134 completed (loss: 0.2675161063671112, acc: 0.9285714030265808)
[2024-12-17 02:25:47,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:48,169][root][INFO] - Training Epoch: 2/2, step 821/7134 completed (loss: 0.13789407908916473, acc: 0.9653179049491882)
[2024-12-17 02:25:48,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:48,444][root][INFO] - Training Epoch: 2/2, step 822/7134 completed (loss: 0.21731434762477875, acc: 0.9430379867553711)
[2024-12-17 02:25:48,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:48,722][root][INFO] - Training Epoch: 2/2, step 823/7134 completed (loss: 0.14240466058254242, acc: 0.9430894255638123)
[2024-12-17 02:25:48,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:49,002][root][INFO] - Training Epoch: 2/2, step 824/7134 completed (loss: 0.2434610277414322, acc: 0.939393937587738)
[2024-12-17 02:25:49,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:49,297][root][INFO] - Training Epoch: 2/2, step 825/7134 completed (loss: 0.1738029569387436, acc: 0.9659090638160706)
[2024-12-17 02:25:49,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:49,591][root][INFO] - Training Epoch: 2/2, step 826/7134 completed (loss: 0.15096662938594818, acc: 0.9590643048286438)
[2024-12-17 02:25:49,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:49,876][root][INFO] - Training Epoch: 2/2, step 827/7134 completed (loss: 0.22713375091552734, acc: 0.9356725215911865)
[2024-12-17 02:25:49,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:50,133][root][INFO] - Training Epoch: 2/2, step 828/7134 completed (loss: 0.1711825728416443, acc: 0.948051929473877)
[2024-12-17 02:25:50,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:50,415][root][INFO] - Training Epoch: 2/2, step 829/7134 completed (loss: 0.31859996914863586, acc: 0.8942307829856873)
[2024-12-17 02:25:50,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:50,709][root][INFO] - Training Epoch: 2/2, step 830/7134 completed (loss: 0.17415106296539307, acc: 0.971222996711731)
[2024-12-17 02:25:50,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:51,001][root][INFO] - Training Epoch: 2/2, step 831/7134 completed (loss: 0.13137000799179077, acc: 0.9698795080184937)
[2024-12-17 02:25:51,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:51,288][root][INFO] - Training Epoch: 2/2, step 832/7134 completed (loss: 0.31397703289985657, acc: 0.9251700639724731)
[2024-12-17 02:25:51,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:51,573][root][INFO] - Training Epoch: 2/2, step 833/7134 completed (loss: 0.09299840033054352, acc: 0.976190447807312)
[2024-12-17 02:25:51,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:51,885][root][INFO] - Training Epoch: 2/2, step 834/7134 completed (loss: 0.21236853301525116, acc: 0.9411764740943909)
[2024-12-17 02:25:52,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:52,179][root][INFO] - Training Epoch: 2/2, step 835/7134 completed (loss: 0.17037273943424225, acc: 0.9649122953414917)
[2024-12-17 02:25:52,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:52,478][root][INFO] - Training Epoch: 2/2, step 836/7134 completed (loss: 0.21595144271850586, acc: 0.9441624283790588)
[2024-12-17 02:25:52,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:52,761][root][INFO] - Training Epoch: 2/2, step 837/7134 completed (loss: 0.2737557590007782, acc: 0.9548022747039795)
[2024-12-17 02:25:52,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:53,046][root][INFO] - Training Epoch: 2/2, step 838/7134 completed (loss: 0.14086809754371643, acc: 0.9673202633857727)
[2024-12-17 02:25:53,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:53,335][root][INFO] - Training Epoch: 2/2, step 839/7134 completed (loss: 0.18979081511497498, acc: 0.9504950642585754)
[2024-12-17 02:25:53,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:53,610][root][INFO] - Training Epoch: 2/2, step 840/7134 completed (loss: 0.11101366579532623, acc: 0.9820359349250793)
[2024-12-17 02:25:53,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:53,898][root][INFO] - Training Epoch: 2/2, step 841/7134 completed (loss: 0.11783891916275024, acc: 0.9824561476707458)
[2024-12-17 02:25:54,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:54,226][root][INFO] - Training Epoch: 2/2, step 842/7134 completed (loss: 0.09540010243654251, acc: 0.9764705896377563)
[2024-12-17 02:25:54,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:54,533][root][INFO] - Training Epoch: 2/2, step 843/7134 completed (loss: 0.11829008162021637, acc: 0.9649122953414917)
[2024-12-17 02:25:54,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:54,833][root][INFO] - Training Epoch: 2/2, step 844/7134 completed (loss: 0.11350950598716736, acc: 0.9589040875434875)
[2024-12-17 02:25:54,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:55,145][root][INFO] - Training Epoch: 2/2, step 845/7134 completed (loss: 0.12351354211568832, acc: 0.970370352268219)
[2024-12-17 02:25:55,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:55,438][root][INFO] - Training Epoch: 2/2, step 846/7134 completed (loss: 0.17707060277462006, acc: 0.9589040875434875)
[2024-12-17 02:25:55,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:55,731][root][INFO] - Training Epoch: 2/2, step 847/7134 completed (loss: 0.2089749127626419, acc: 0.9580838084220886)
[2024-12-17 02:25:55,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:56,025][root][INFO] - Training Epoch: 2/2, step 848/7134 completed (loss: 0.27941709756851196, acc: 0.9298245906829834)
[2024-12-17 02:25:56,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:56,333][root][INFO] - Training Epoch: 2/2, step 849/7134 completed (loss: 0.13881707191467285, acc: 0.9451219439506531)
[2024-12-17 02:25:56,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:56,640][root][INFO] - Training Epoch: 2/2, step 850/7134 completed (loss: 0.12211273610591888, acc: 0.9731543660163879)
[2024-12-17 02:25:56,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:56,932][root][INFO] - Training Epoch: 2/2, step 851/7134 completed (loss: 0.20128431916236877, acc: 0.9418604373931885)
[2024-12-17 02:25:57,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:57,230][root][INFO] - Training Epoch: 2/2, step 852/7134 completed (loss: 0.13474392890930176, acc: 0.9685863852500916)
[2024-12-17 02:25:57,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:57,529][root][INFO] - Training Epoch: 2/2, step 853/7134 completed (loss: 0.19828632473945618, acc: 0.9685863852500916)
[2024-12-17 02:25:57,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:57,810][root][INFO] - Training Epoch: 2/2, step 854/7134 completed (loss: 0.13610795140266418, acc: 0.9756097793579102)
[2024-12-17 02:25:57,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:58,098][root][INFO] - Training Epoch: 2/2, step 855/7134 completed (loss: 0.14884832501411438, acc: 0.9595375657081604)
[2024-12-17 02:25:58,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:58,375][root][INFO] - Training Epoch: 2/2, step 856/7134 completed (loss: 0.079975925385952, acc: 0.9836065769195557)
[2024-12-17 02:25:58,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:58,645][root][INFO] - Training Epoch: 2/2, step 857/7134 completed (loss: 0.1321866512298584, acc: 0.949999988079071)
[2024-12-17 02:25:58,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:58,929][root][INFO] - Training Epoch: 2/2, step 858/7134 completed (loss: 0.24521449208259583, acc: 0.9345238208770752)
[2024-12-17 02:25:59,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:59,213][root][INFO] - Training Epoch: 2/2, step 859/7134 completed (loss: 0.4334371089935303, acc: 0.903954803943634)
[2024-12-17 02:25:59,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:59,500][root][INFO] - Training Epoch: 2/2, step 860/7134 completed (loss: 0.3841283619403839, acc: 0.9072847962379456)
[2024-12-17 02:25:59,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:59,791][root][INFO] - Training Epoch: 2/2, step 861/7134 completed (loss: 0.17750316858291626, acc: 0.9569892287254333)
[2024-12-17 02:25:59,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:00,071][root][INFO] - Training Epoch: 2/2, step 862/7134 completed (loss: 0.28475573658943176, acc: 0.9314285516738892)
[2024-12-17 02:26:00,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:00,356][root][INFO] - Training Epoch: 2/2, step 863/7134 completed (loss: 0.3301866054534912, acc: 0.8961748480796814)
[2024-12-17 02:26:00,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:00,663][root][INFO] - Training Epoch: 2/2, step 864/7134 completed (loss: 0.39869847893714905, acc: 0.89682537317276)
[2024-12-17 02:26:00,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:00,954][root][INFO] - Training Epoch: 2/2, step 865/7134 completed (loss: 0.4544336497783661, acc: 0.8837209343910217)
[2024-12-17 02:26:01,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:01,237][root][INFO] - Training Epoch: 2/2, step 866/7134 completed (loss: 0.3944922089576721, acc: 0.9071428775787354)
[2024-12-17 02:26:01,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:01,508][root][INFO] - Training Epoch: 2/2, step 867/7134 completed (loss: 0.3293246328830719, acc: 0.9437500238418579)
[2024-12-17 02:26:01,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:01,809][root][INFO] - Training Epoch: 2/2, step 868/7134 completed (loss: 0.529531717300415, acc: 0.9127907156944275)
[2024-12-17 02:26:01,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:02,097][root][INFO] - Training Epoch: 2/2, step 869/7134 completed (loss: 0.6235443949699402, acc: 0.8313252925872803)
[2024-12-17 02:26:02,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:02,386][root][INFO] - Training Epoch: 2/2, step 870/7134 completed (loss: 0.23325321078300476, acc: 0.9473684430122375)
[2024-12-17 02:26:02,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:02,667][root][INFO] - Training Epoch: 2/2, step 871/7134 completed (loss: 0.2688673138618469, acc: 0.9452054500579834)
[2024-12-17 02:26:02,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:02,960][root][INFO] - Training Epoch: 2/2, step 872/7134 completed (loss: 0.13127687573432922, acc: 0.9722222089767456)
[2024-12-17 02:26:03,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:03,255][root][INFO] - Training Epoch: 2/2, step 873/7134 completed (loss: 0.22266316413879395, acc: 0.9333333373069763)
[2024-12-17 02:26:03,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:03,561][root][INFO] - Training Epoch: 2/2, step 874/7134 completed (loss: 0.22283601760864258, acc: 0.9375)
[2024-12-17 02:26:03,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:03,861][root][INFO] - Training Epoch: 2/2, step 875/7134 completed (loss: 0.11565027385950089, acc: 0.971222996711731)
[2024-12-17 02:26:03,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:04,165][root][INFO] - Training Epoch: 2/2, step 876/7134 completed (loss: 0.1512065976858139, acc: 0.9473684430122375)
[2024-12-17 02:26:04,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:04,471][root][INFO] - Training Epoch: 2/2, step 877/7134 completed (loss: 0.31049713492393494, acc: 0.9263803958892822)
[2024-12-17 02:26:04,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:04,753][root][INFO] - Training Epoch: 2/2, step 878/7134 completed (loss: 0.21270671486854553, acc: 0.9437500238418579)
[2024-12-17 02:26:04,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:05,032][root][INFO] - Training Epoch: 2/2, step 879/7134 completed (loss: 0.2287648618221283, acc: 0.9554139971733093)
[2024-12-17 02:26:05,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:05,303][root][INFO] - Training Epoch: 2/2, step 880/7134 completed (loss: 0.196671262383461, acc: 0.9631901979446411)
[2024-12-17 02:26:05,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:05,572][root][INFO] - Training Epoch: 2/2, step 881/7134 completed (loss: 0.22093433141708374, acc: 0.9186992049217224)
[2024-12-17 02:26:05,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:05,850][root][INFO] - Training Epoch: 2/2, step 882/7134 completed (loss: 0.12308578193187714, acc: 0.9677419066429138)
[2024-12-17 02:26:05,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:06,111][root][INFO] - Training Epoch: 2/2, step 883/7134 completed (loss: 0.3284227252006531, acc: 0.9276315569877625)
[2024-12-17 02:26:06,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:06,376][root][INFO] - Training Epoch: 2/2, step 884/7134 completed (loss: 0.24943113327026367, acc: 0.9341317415237427)
[2024-12-17 02:26:06,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:06,648][root][INFO] - Training Epoch: 2/2, step 885/7134 completed (loss: 0.09461163729429245, acc: 0.9695122241973877)
[2024-12-17 02:26:06,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:06,925][root][INFO] - Training Epoch: 2/2, step 886/7134 completed (loss: 0.24287091195583344, acc: 0.9663865566253662)
[2024-12-17 02:26:07,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:07,191][root][INFO] - Training Epoch: 2/2, step 887/7134 completed (loss: 0.1299649327993393, acc: 0.9701492786407471)
[2024-12-17 02:26:07,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:07,469][root][INFO] - Training Epoch: 2/2, step 888/7134 completed (loss: 0.35241687297821045, acc: 0.9395973086357117)
[2024-12-17 02:26:07,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:07,736][root][INFO] - Training Epoch: 2/2, step 889/7134 completed (loss: 0.13622154295444489, acc: 0.9702970385551453)
[2024-12-17 02:26:07,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:08,020][root][INFO] - Training Epoch: 2/2, step 890/7134 completed (loss: 0.2990216910839081, acc: 0.9328858852386475)
[2024-12-17 02:26:08,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:08,300][root][INFO] - Training Epoch: 2/2, step 891/7134 completed (loss: 0.299530953168869, acc: 0.9385474920272827)
[2024-12-17 02:26:08,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:08,579][root][INFO] - Training Epoch: 2/2, step 892/7134 completed (loss: 0.21080970764160156, acc: 0.9523809552192688)
[2024-12-17 02:26:08,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:08,841][root][INFO] - Training Epoch: 2/2, step 893/7134 completed (loss: 0.25995033979415894, acc: 0.9346405267715454)
[2024-12-17 02:26:08,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:09,131][root][INFO] - Training Epoch: 2/2, step 894/7134 completed (loss: 0.17511549592018127, acc: 0.9604519605636597)
[2024-12-17 02:26:09,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:09,406][root][INFO] - Training Epoch: 2/2, step 895/7134 completed (loss: 0.15608082711696625, acc: 0.965753436088562)
[2024-12-17 02:26:09,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:09,674][root][INFO] - Training Epoch: 2/2, step 896/7134 completed (loss: 0.09789754450321198, acc: 0.9763779640197754)
[2024-12-17 02:26:09,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:09,963][root][INFO] - Training Epoch: 2/2, step 897/7134 completed (loss: 0.18324095010757446, acc: 0.9664804339408875)
[2024-12-17 02:26:10,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:10,261][root][INFO] - Training Epoch: 2/2, step 898/7134 completed (loss: 0.34056222438812256, acc: 0.9090909361839294)
[2024-12-17 02:26:10,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:10,533][root][INFO] - Training Epoch: 2/2, step 899/7134 completed (loss: 0.23298333585262299, acc: 0.9411764740943909)
[2024-12-17 02:26:10,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:10,802][root][INFO] - Training Epoch: 2/2, step 900/7134 completed (loss: 0.12458811700344086, acc: 0.9634146094322205)
[2024-12-17 02:26:10,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:11,089][root][INFO] - Training Epoch: 2/2, step 901/7134 completed (loss: 0.2752547860145569, acc: 0.9166666865348816)
[2024-12-17 02:26:11,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:11,348][root][INFO] - Training Epoch: 2/2, step 902/7134 completed (loss: 0.16633495688438416, acc: 0.9675324559211731)
[2024-12-17 02:26:11,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:11,635][root][INFO] - Training Epoch: 2/2, step 903/7134 completed (loss: 0.05769587308168411, acc: 0.9942196607589722)
[2024-12-17 02:26:11,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:11,926][root][INFO] - Training Epoch: 2/2, step 904/7134 completed (loss: 0.22298996150493622, acc: 0.9491525292396545)
[2024-12-17 02:26:12,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:12,231][root][INFO] - Training Epoch: 2/2, step 905/7134 completed (loss: 0.10687141120433807, acc: 0.9885057210922241)
[2024-12-17 02:26:12,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:12,506][root][INFO] - Training Epoch: 2/2, step 906/7134 completed (loss: 0.14639289677143097, acc: 0.950276255607605)
[2024-12-17 02:26:12,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:12,786][root][INFO] - Training Epoch: 2/2, step 907/7134 completed (loss: 0.15439558029174805, acc: 0.9569892287254333)
[2024-12-17 02:26:12,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:13,068][root][INFO] - Training Epoch: 2/2, step 908/7134 completed (loss: 0.1318519413471222, acc: 0.9722222089767456)
[2024-12-17 02:26:13,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:13,340][root][INFO] - Training Epoch: 2/2, step 909/7134 completed (loss: 0.15823206305503845, acc: 0.9539473652839661)
[2024-12-17 02:26:13,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:13,628][root][INFO] - Training Epoch: 2/2, step 910/7134 completed (loss: 0.20563673973083496, acc: 0.956250011920929)
[2024-12-17 02:26:13,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:13,908][root][INFO] - Training Epoch: 2/2, step 911/7134 completed (loss: 0.15564413368701935, acc: 0.9741935729980469)
[2024-12-17 02:26:14,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:14,195][root][INFO] - Training Epoch: 2/2, step 912/7134 completed (loss: 0.21071657538414001, acc: 0.9526315927505493)
[2024-12-17 02:26:14,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:14,486][root][INFO] - Training Epoch: 2/2, step 913/7134 completed (loss: 0.12220877408981323, acc: 0.9670329689979553)
[2024-12-17 02:26:14,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:14,766][root][INFO] - Training Epoch: 2/2, step 914/7134 completed (loss: 0.1231185793876648, acc: 0.9636363387107849)
[2024-12-17 02:26:14,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:15,036][root][INFO] - Training Epoch: 2/2, step 915/7134 completed (loss: 0.24098047614097595, acc: 0.9428571462631226)
[2024-12-17 02:26:15,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:15,316][root][INFO] - Training Epoch: 2/2, step 916/7134 completed (loss: 0.12166067957878113, acc: 0.9767441749572754)
[2024-12-17 02:26:15,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:15,587][root][INFO] - Training Epoch: 2/2, step 917/7134 completed (loss: 0.33392688632011414, acc: 0.9415584206581116)
[2024-12-17 02:26:15,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:15,868][root][INFO] - Training Epoch: 2/2, step 918/7134 completed (loss: 0.2780337929725647, acc: 0.9470198750495911)
[2024-12-17 02:26:15,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:16,131][root][INFO] - Training Epoch: 2/2, step 919/7134 completed (loss: 0.11132874339818954, acc: 0.9870129823684692)
[2024-12-17 02:26:16,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:16,422][root][INFO] - Training Epoch: 2/2, step 920/7134 completed (loss: 0.27858757972717285, acc: 0.9418604373931885)
[2024-12-17 02:26:16,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:16,689][root][INFO] - Training Epoch: 2/2, step 921/7134 completed (loss: 0.23370029032230377, acc: 0.9356725215911865)
[2024-12-17 02:26:16,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:16,955][root][INFO] - Training Epoch: 2/2, step 922/7134 completed (loss: 0.13926538825035095, acc: 0.9626865386962891)
[2024-12-17 02:26:17,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:17,226][root][INFO] - Training Epoch: 2/2, step 923/7134 completed (loss: 0.13967160880565643, acc: 0.9590643048286438)
[2024-12-17 02:26:17,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:17,531][root][INFO] - Training Epoch: 2/2, step 924/7134 completed (loss: 0.12361577898263931, acc: 0.9548022747039795)
[2024-12-17 02:26:17,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:17,828][root][INFO] - Training Epoch: 2/2, step 925/7134 completed (loss: 0.3577008545398712, acc: 0.9032257795333862)
[2024-12-17 02:26:17,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:18,147][root][INFO] - Training Epoch: 2/2, step 926/7134 completed (loss: 0.1528310924768448, acc: 0.9611111283302307)
[2024-12-17 02:26:18,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:18,450][root][INFO] - Training Epoch: 2/2, step 927/7134 completed (loss: 0.24669122695922852, acc: 0.935251772403717)
[2024-12-17 02:26:18,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:18,753][root][INFO] - Training Epoch: 2/2, step 928/7134 completed (loss: 0.04963827505707741, acc: 0.9908257126808167)
[2024-12-17 02:26:18,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:19,066][root][INFO] - Training Epoch: 2/2, step 929/7134 completed (loss: 0.14194151759147644, acc: 0.9473684430122375)
[2024-12-17 02:26:19,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:19,363][root][INFO] - Training Epoch: 2/2, step 930/7134 completed (loss: 0.2943781316280365, acc: 0.9193548560142517)
[2024-12-17 02:26:19,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:19,646][root][INFO] - Training Epoch: 2/2, step 931/7134 completed (loss: 0.18427571654319763, acc: 0.9411764740943909)
[2024-12-17 02:26:19,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:19,899][root][INFO] - Training Epoch: 2/2, step 932/7134 completed (loss: 0.16228985786437988, acc: 0.9404761791229248)
[2024-12-17 02:26:20,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:20,172][root][INFO] - Training Epoch: 2/2, step 933/7134 completed (loss: 0.25534600019454956, acc: 0.9341317415237427)
[2024-12-17 02:26:20,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:20,473][root][INFO] - Training Epoch: 2/2, step 934/7134 completed (loss: 0.14916233718395233, acc: 0.9476743936538696)
[2024-12-17 02:26:20,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:20,754][root][INFO] - Training Epoch: 2/2, step 935/7134 completed (loss: 0.07064235955476761, acc: 0.9767441749572754)
[2024-12-17 02:26:20,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:21,033][root][INFO] - Training Epoch: 2/2, step 936/7134 completed (loss: 0.1849435567855835, acc: 0.9448819160461426)
[2024-12-17 02:26:21,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:21,321][root][INFO] - Training Epoch: 2/2, step 937/7134 completed (loss: 0.2155904471874237, acc: 0.9430894255638123)
[2024-12-17 02:26:21,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:21,603][root][INFO] - Training Epoch: 2/2, step 938/7134 completed (loss: 0.1769748032093048, acc: 0.9615384340286255)
[2024-12-17 02:26:21,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:21,870][root][INFO] - Training Epoch: 2/2, step 939/7134 completed (loss: 0.2862204313278198, acc: 0.9268292784690857)
[2024-12-17 02:26:21,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:22,161][root][INFO] - Training Epoch: 2/2, step 940/7134 completed (loss: 0.16440171003341675, acc: 0.9595375657081604)
[2024-12-17 02:26:22,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:22,450][root][INFO] - Training Epoch: 2/2, step 941/7134 completed (loss: 0.15202248096466064, acc: 0.949438214302063)
[2024-12-17 02:26:22,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:22,735][root][INFO] - Training Epoch: 2/2, step 942/7134 completed (loss: 0.23047950863838196, acc: 0.9418604373931885)
[2024-12-17 02:26:22,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:23,023][root][INFO] - Training Epoch: 2/2, step 943/7134 completed (loss: 0.16676780581474304, acc: 0.9754601120948792)
[2024-12-17 02:26:23,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:23,291][root][INFO] - Training Epoch: 2/2, step 944/7134 completed (loss: 0.17292144894599915, acc: 0.9681528806686401)
[2024-12-17 02:26:23,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:23,560][root][INFO] - Training Epoch: 2/2, step 945/7134 completed (loss: 0.20016206800937653, acc: 0.9602649211883545)
[2024-12-17 02:26:23,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:23,866][root][INFO] - Training Epoch: 2/2, step 946/7134 completed (loss: 0.09669651836156845, acc: 0.9805825352668762)
[2024-12-17 02:26:23,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:24,145][root][INFO] - Training Epoch: 2/2, step 947/7134 completed (loss: 0.2342112511396408, acc: 0.9338235259056091)
[2024-12-17 02:26:24,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:24,425][root][INFO] - Training Epoch: 2/2, step 948/7134 completed (loss: 0.11338324844837189, acc: 0.9638554453849792)
[2024-12-17 02:26:24,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:24,727][root][INFO] - Training Epoch: 2/2, step 949/7134 completed (loss: 0.23006609082221985, acc: 0.9437500238418579)
[2024-12-17 02:26:24,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:25,027][root][INFO] - Training Epoch: 2/2, step 950/7134 completed (loss: 0.17110639810562134, acc: 0.9415584206581116)
[2024-12-17 02:26:25,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:25,281][root][INFO] - Training Epoch: 2/2, step 951/7134 completed (loss: 0.2104404866695404, acc: 0.9312977194786072)
[2024-12-17 02:26:25,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:25,530][root][INFO] - Training Epoch: 2/2, step 952/7134 completed (loss: 0.3498534858226776, acc: 0.9264705777168274)
[2024-12-17 02:26:25,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:25,812][root][INFO] - Training Epoch: 2/2, step 953/7134 completed (loss: 0.2514679431915283, acc: 0.9268292784690857)
[2024-12-17 02:26:25,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:26,103][root][INFO] - Training Epoch: 2/2, step 954/7134 completed (loss: 0.17946729063987732, acc: 0.9586206674575806)
[2024-12-17 02:26:26,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:26,392][root][INFO] - Training Epoch: 2/2, step 955/7134 completed (loss: 0.2661067843437195, acc: 0.9435028433799744)
[2024-12-17 02:26:26,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:26,656][root][INFO] - Training Epoch: 2/2, step 956/7134 completed (loss: 0.1743079125881195, acc: 0.9510869383811951)
[2024-12-17 02:26:26,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:26,946][root][INFO] - Training Epoch: 2/2, step 957/7134 completed (loss: 0.27209916710853577, acc: 0.9460784196853638)
[2024-12-17 02:26:27,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:27,208][root][INFO] - Training Epoch: 2/2, step 958/7134 completed (loss: 0.3147049844264984, acc: 0.9179104566574097)
[2024-12-17 02:26:27,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:27,490][root][INFO] - Training Epoch: 2/2, step 959/7134 completed (loss: 0.32248741388320923, acc: 0.9278350472450256)
[2024-12-17 02:26:27,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:27,767][root][INFO] - Training Epoch: 2/2, step 960/7134 completed (loss: 0.5328837633132935, acc: 0.89552241563797)
[2024-12-17 02:26:27,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:28,048][root][INFO] - Training Epoch: 2/2, step 961/7134 completed (loss: 0.3447009027004242, acc: 0.906593382358551)
[2024-12-17 02:26:28,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:28,335][root][INFO] - Training Epoch: 2/2, step 962/7134 completed (loss: 0.38622966408729553, acc: 0.9064327478408813)
[2024-12-17 02:26:28,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:28,612][root][INFO] - Training Epoch: 2/2, step 963/7134 completed (loss: 0.4308944046497345, acc: 0.8837209343910217)
[2024-12-17 02:26:28,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:28,884][root][INFO] - Training Epoch: 2/2, step 964/7134 completed (loss: 0.667088508605957, acc: 0.8658536672592163)
[2024-12-17 02:26:29,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:29,163][root][INFO] - Training Epoch: 2/2, step 965/7134 completed (loss: 0.43655940890312195, acc: 0.903743326663971)
[2024-12-17 02:26:29,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:29,432][root][INFO] - Training Epoch: 2/2, step 966/7134 completed (loss: 0.294710248708725, acc: 0.9325153231620789)
[2024-12-17 02:26:29,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:29,710][root][INFO] - Training Epoch: 2/2, step 967/7134 completed (loss: 0.25341665744781494, acc: 0.9414893388748169)
[2024-12-17 02:26:29,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:29,979][root][INFO] - Training Epoch: 2/2, step 968/7134 completed (loss: 0.3776450753211975, acc: 0.8872180581092834)
[2024-12-17 02:26:30,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:30,255][root][INFO] - Training Epoch: 2/2, step 969/7134 completed (loss: 0.2472468763589859, acc: 0.9371428489685059)
[2024-12-17 02:26:30,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:30,518][root][INFO] - Training Epoch: 2/2, step 970/7134 completed (loss: 0.3735082447528839, acc: 0.904411792755127)
[2024-12-17 02:26:30,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:30,797][root][INFO] - Training Epoch: 2/2, step 971/7134 completed (loss: 0.29922154545783997, acc: 0.9194312691688538)
[2024-12-17 02:26:30,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:31,086][root][INFO] - Training Epoch: 2/2, step 972/7134 completed (loss: 0.3282235562801361, acc: 0.8974359035491943)
[2024-12-17 02:26:31,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:31,359][root][INFO] - Training Epoch: 2/2, step 973/7134 completed (loss: 0.3696330487728119, acc: 0.9120879173278809)
[2024-12-17 02:26:31,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:31,649][root][INFO] - Training Epoch: 2/2, step 974/7134 completed (loss: 0.23054863512516022, acc: 0.9603960514068604)
[2024-12-17 02:26:31,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:31,919][root][INFO] - Training Epoch: 2/2, step 975/7134 completed (loss: 0.27521970868110657, acc: 0.9627659320831299)
[2024-12-17 02:26:32,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:32,207][root][INFO] - Training Epoch: 2/2, step 976/7134 completed (loss: 0.23215997219085693, acc: 0.9271523356437683)
[2024-12-17 02:26:32,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:32,491][root][INFO] - Training Epoch: 2/2, step 977/7134 completed (loss: 0.4843733310699463, acc: 0.8707864880561829)
[2024-12-17 02:26:32,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:32,755][root][INFO] - Training Epoch: 2/2, step 978/7134 completed (loss: 0.20411652326583862, acc: 0.9329897165298462)
[2024-12-17 02:26:32,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:33,033][root][INFO] - Training Epoch: 2/2, step 979/7134 completed (loss: 0.3185742497444153, acc: 0.9243243336677551)
[2024-12-17 02:26:33,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:33,326][root][INFO] - Training Epoch: 2/2, step 980/7134 completed (loss: 0.2837771475315094, acc: 0.9154929518699646)
[2024-12-17 02:26:33,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:33,580][root][INFO] - Training Epoch: 2/2, step 981/7134 completed (loss: 0.3912881314754486, acc: 0.9433962106704712)
[2024-12-17 02:26:33,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:33,859][root][INFO] - Training Epoch: 2/2, step 982/7134 completed (loss: 0.5370599627494812, acc: 0.8971428275108337)
[2024-12-17 02:26:33,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:34,147][root][INFO] - Training Epoch: 2/2, step 983/7134 completed (loss: 0.3321359157562256, acc: 0.9248120188713074)
[2024-12-17 02:26:34,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:34,431][root][INFO] - Training Epoch: 2/2, step 984/7134 completed (loss: 0.17848554253578186, acc: 0.978723406791687)
[2024-12-17 02:26:34,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:34,711][root][INFO] - Training Epoch: 2/2, step 985/7134 completed (loss: 0.20602889358997345, acc: 0.9555555582046509)
[2024-12-17 02:26:34,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:34,993][root][INFO] - Training Epoch: 2/2, step 986/7134 completed (loss: 0.08308051526546478, acc: 0.9776536226272583)
[2024-12-17 02:26:35,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:35,253][root][INFO] - Training Epoch: 2/2, step 987/7134 completed (loss: 0.11709970980882645, acc: 0.9731543660163879)
[2024-12-17 02:26:35,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:35,527][root][INFO] - Training Epoch: 2/2, step 988/7134 completed (loss: 0.4164842367172241, acc: 0.9209039807319641)
[2024-12-17 02:26:35,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:35,817][root][INFO] - Training Epoch: 2/2, step 989/7134 completed (loss: 0.34596356749534607, acc: 0.9202454090118408)
[2024-12-17 02:26:35,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:36,108][root][INFO] - Training Epoch: 2/2, step 990/7134 completed (loss: 0.2531369626522064, acc: 0.9395604133605957)
[2024-12-17 02:26:36,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:36,395][root][INFO] - Training Epoch: 2/2, step 991/7134 completed (loss: 0.6623862981796265, acc: 0.8679245114326477)
[2024-12-17 02:26:36,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:36,679][root][INFO] - Training Epoch: 2/2, step 992/7134 completed (loss: 0.2541603446006775, acc: 0.9190751314163208)
[2024-12-17 02:26:36,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:36,956][root][INFO] - Training Epoch: 2/2, step 993/7134 completed (loss: 0.22750553488731384, acc: 0.935251772403717)
[2024-12-17 02:26:37,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:37,261][root][INFO] - Training Epoch: 2/2, step 994/7134 completed (loss: 0.25267884135246277, acc: 0.9514563083648682)
[2024-12-17 02:26:37,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:37,549][root][INFO] - Training Epoch: 2/2, step 995/7134 completed (loss: 0.19537249207496643, acc: 0.9591836929321289)
[2024-12-17 02:26:37,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:37,833][root][INFO] - Training Epoch: 2/2, step 996/7134 completed (loss: 0.29376277327537537, acc: 0.9244186282157898)
[2024-12-17 02:26:37,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:38,137][root][INFO] - Training Epoch: 2/2, step 997/7134 completed (loss: 0.1644880324602127, acc: 0.9529411792755127)
[2024-12-17 02:26:38,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:38,430][root][INFO] - Training Epoch: 2/2, step 998/7134 completed (loss: 0.239351287484169, acc: 0.9341317415237427)
[2024-12-17 02:26:38,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:38,733][root][INFO] - Training Epoch: 2/2, step 999/7134 completed (loss: 0.2644003629684448, acc: 0.9384615421295166)
[2024-12-17 02:26:38,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:39,011][root][INFO] - Training Epoch: 2/2, step 1000/7134 completed (loss: 0.1789531111717224, acc: 0.9632353186607361)
[2024-12-17 02:26:39,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:39,286][root][INFO] - Training Epoch: 2/2, step 1001/7134 completed (loss: 0.12538471817970276, acc: 0.9818181991577148)
[2024-12-17 02:26:39,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:39,565][root][INFO] - Training Epoch: 2/2, step 1002/7134 completed (loss: 0.16496481001377106, acc: 0.9496855139732361)
[2024-12-17 02:26:39,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:39,840][root][INFO] - Training Epoch: 2/2, step 1003/7134 completed (loss: 0.10490462183952332, acc: 0.9930555820465088)
[2024-12-17 02:26:39,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:40,123][root][INFO] - Training Epoch: 2/2, step 1004/7134 completed (loss: 0.29971203207969666, acc: 0.9115044474601746)
[2024-12-17 02:26:40,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:40,413][root][INFO] - Training Epoch: 2/2, step 1005/7134 completed (loss: 0.2712492048740387, acc: 0.914893627166748)
[2024-12-17 02:26:40,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:40,691][root][INFO] - Training Epoch: 2/2, step 1006/7134 completed (loss: 0.2811073660850525, acc: 0.9426751732826233)
[2024-12-17 02:26:40,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:40,972][root][INFO] - Training Epoch: 2/2, step 1007/7134 completed (loss: 0.4323417544364929, acc: 0.8873239159584045)
[2024-12-17 02:26:41,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:41,244][root][INFO] - Training Epoch: 2/2, step 1008/7134 completed (loss: 0.20035427808761597, acc: 0.9506173133850098)
[2024-12-17 02:26:41,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:41,517][root][INFO] - Training Epoch: 2/2, step 1009/7134 completed (loss: 0.1873559057712555, acc: 0.961240291595459)
[2024-12-17 02:26:41,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:41,781][root][INFO] - Training Epoch: 2/2, step 1010/7134 completed (loss: 0.22384272515773773, acc: 0.94017094373703)
[2024-12-17 02:26:41,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:42,093][root][INFO] - Training Epoch: 2/2, step 1011/7134 completed (loss: 0.17904743552207947, acc: 0.9496855139732361)
[2024-12-17 02:26:42,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:42,384][root][INFO] - Training Epoch: 2/2, step 1012/7134 completed (loss: 0.4312823414802551, acc: 0.918749988079071)
[2024-12-17 02:26:42,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:42,667][root][INFO] - Training Epoch: 2/2, step 1013/7134 completed (loss: 0.35814088582992554, acc: 0.9397590160369873)
[2024-12-17 02:26:42,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:42,949][root][INFO] - Training Epoch: 2/2, step 1014/7134 completed (loss: 0.24509814381599426, acc: 0.9432623982429504)
[2024-12-17 02:26:43,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:43,229][root][INFO] - Training Epoch: 2/2, step 1015/7134 completed (loss: 0.1357683688402176, acc: 0.9735099077224731)
[2024-12-17 02:26:43,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:43,497][root][INFO] - Training Epoch: 2/2, step 1016/7134 completed (loss: 0.0739608108997345, acc: 0.9915966391563416)
[2024-12-17 02:26:43,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:43,788][root][INFO] - Training Epoch: 2/2, step 1017/7134 completed (loss: 0.08577658236026764, acc: 0.9828571677207947)
[2024-12-17 02:26:43,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:44,071][root][INFO] - Training Epoch: 2/2, step 1018/7134 completed (loss: 0.2648932635784149, acc: 0.9316770434379578)
[2024-12-17 02:26:44,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:44,349][root][INFO] - Training Epoch: 2/2, step 1019/7134 completed (loss: 0.19737455248832703, acc: 0.9415584206581116)
[2024-12-17 02:26:44,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:44,611][root][INFO] - Training Epoch: 2/2, step 1020/7134 completed (loss: 0.11393354088068008, acc: 0.9681528806686401)
[2024-12-17 02:26:44,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:44,882][root][INFO] - Training Epoch: 2/2, step 1021/7134 completed (loss: 0.07391456514596939, acc: 0.9803921580314636)
[2024-12-17 02:26:45,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:45,171][root][INFO] - Training Epoch: 2/2, step 1022/7134 completed (loss: 0.055421289056539536, acc: 0.9884393215179443)
[2024-12-17 02:26:45,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:45,454][root][INFO] - Training Epoch: 2/2, step 1023/7134 completed (loss: 0.17890900373458862, acc: 0.9832402467727661)
[2024-12-17 02:26:45,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:45,714][root][INFO] - Training Epoch: 2/2, step 1024/7134 completed (loss: 0.1849401891231537, acc: 0.9776119589805603)
[2024-12-17 02:26:45,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:45,991][root][INFO] - Training Epoch: 2/2, step 1025/7134 completed (loss: 0.12420772016048431, acc: 0.957446813583374)
[2024-12-17 02:26:46,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:46,282][root][INFO] - Training Epoch: 2/2, step 1026/7134 completed (loss: 0.2733118534088135, acc: 0.9557521939277649)
[2024-12-17 02:26:46,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:46,556][root][INFO] - Training Epoch: 2/2, step 1027/7134 completed (loss: 0.08555229753255844, acc: 0.9647058844566345)
[2024-12-17 02:26:46,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:46,849][root][INFO] - Training Epoch: 2/2, step 1028/7134 completed (loss: 0.049922119826078415, acc: 0.9874213933944702)
[2024-12-17 02:26:46,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:47,146][root][INFO] - Training Epoch: 2/2, step 1029/7134 completed (loss: 0.07867853343486786, acc: 0.9814814925193787)
[2024-12-17 02:26:47,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:47,443][root][INFO] - Training Epoch: 2/2, step 1030/7134 completed (loss: 0.037931960076093674, acc: 0.9942528605461121)
[2024-12-17 02:26:47,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:47,718][root][INFO] - Training Epoch: 2/2, step 1031/7134 completed (loss: 0.1721724569797516, acc: 0.95652174949646)
[2024-12-17 02:26:47,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:47,999][root][INFO] - Training Epoch: 2/2, step 1032/7134 completed (loss: 0.16157931089401245, acc: 0.9627659320831299)
[2024-12-17 02:26:48,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:48,303][root][INFO] - Training Epoch: 2/2, step 1033/7134 completed (loss: 0.06446054577827454, acc: 0.9863013625144958)
[2024-12-17 02:26:48,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:48,576][root][INFO] - Training Epoch: 2/2, step 1034/7134 completed (loss: 0.3661632239818573, acc: 0.9155844449996948)
[2024-12-17 02:26:48,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:48,855][root][INFO] - Training Epoch: 2/2, step 1035/7134 completed (loss: 0.7331022024154663, acc: 0.837837815284729)
[2024-12-17 02:26:48,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:49,134][root][INFO] - Training Epoch: 2/2, step 1036/7134 completed (loss: 0.8298726081848145, acc: 0.8559321761131287)
[2024-12-17 02:26:49,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:49,412][root][INFO] - Training Epoch: 2/2, step 1037/7134 completed (loss: 0.10042588412761688, acc: 0.9840425252914429)
[2024-12-17 02:26:49,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:49,687][root][INFO] - Training Epoch: 2/2, step 1038/7134 completed (loss: 0.1358424574136734, acc: 0.9520000219345093)
[2024-12-17 02:26:49,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:49,951][root][INFO] - Training Epoch: 2/2, step 1039/7134 completed (loss: 0.23149099946022034, acc: 0.9449541568756104)
[2024-12-17 02:26:50,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:50,270][root][INFO] - Training Epoch: 2/2, step 1040/7134 completed (loss: 0.07085133343935013, acc: 0.9927536249160767)
[2024-12-17 02:26:50,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:50,544][root][INFO] - Training Epoch: 2/2, step 1041/7134 completed (loss: 0.07603999227285385, acc: 0.9932885766029358)
[2024-12-17 02:26:50,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:50,826][root][INFO] - Training Epoch: 2/2, step 1042/7134 completed (loss: 0.23866617679595947, acc: 0.9385474920272827)
[2024-12-17 02:26:50,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:51,114][root][INFO] - Training Epoch: 2/2, step 1043/7134 completed (loss: 0.21871086955070496, acc: 0.9603960514068604)
[2024-12-17 02:26:51,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:51,384][root][INFO] - Training Epoch: 2/2, step 1044/7134 completed (loss: 0.10195136070251465, acc: 0.9627329111099243)
[2024-12-17 02:26:51,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:51,644][root][INFO] - Training Epoch: 2/2, step 1045/7134 completed (loss: 0.5126891732215881, acc: 0.888198733329773)
[2024-12-17 02:26:51,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:51,917][root][INFO] - Training Epoch: 2/2, step 1046/7134 completed (loss: 0.31443002820014954, acc: 0.9248120188713074)
[2024-12-17 02:26:52,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:52,204][root][INFO] - Training Epoch: 2/2, step 1047/7134 completed (loss: 0.45779550075531006, acc: 0.8914285898208618)
[2024-12-17 02:26:52,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:52,523][root][INFO] - Training Epoch: 2/2, step 1048/7134 completed (loss: 0.2714928686618805, acc: 0.9490445852279663)
[2024-12-17 02:26:52,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:52,795][root][INFO] - Training Epoch: 2/2, step 1049/7134 completed (loss: 0.261570006608963, acc: 0.9407894611358643)
[2024-12-17 02:26:52,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:53,093][root][INFO] - Training Epoch: 2/2, step 1050/7134 completed (loss: 0.36254382133483887, acc: 0.9010416865348816)
[2024-12-17 02:26:53,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:53,377][root][INFO] - Training Epoch: 2/2, step 1051/7134 completed (loss: 0.2004796862602234, acc: 0.9428571462631226)
[2024-12-17 02:26:53,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:53,646][root][INFO] - Training Epoch: 2/2, step 1052/7134 completed (loss: 0.39014291763305664, acc: 0.9036144614219666)
[2024-12-17 02:26:53,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:53,931][root][INFO] - Training Epoch: 2/2, step 1053/7134 completed (loss: 0.21036212146282196, acc: 0.9520958065986633)
[2024-12-17 02:26:54,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:54,231][root][INFO] - Training Epoch: 2/2, step 1054/7134 completed (loss: 0.21849726140499115, acc: 0.9375)
[2024-12-17 02:26:54,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:54,516][root][INFO] - Training Epoch: 2/2, step 1055/7134 completed (loss: 0.29623255133628845, acc: 0.9236640930175781)
[2024-12-17 02:26:54,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:54,803][root][INFO] - Training Epoch: 2/2, step 1056/7134 completed (loss: 0.4147585928440094, acc: 0.8895348906517029)
[2024-12-17 02:26:54,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:55,081][root][INFO] - Training Epoch: 2/2, step 1057/7134 completed (loss: 0.3481447398662567, acc: 0.9378238320350647)
[2024-12-17 02:26:55,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:55,372][root][INFO] - Training Epoch: 2/2, step 1058/7134 completed (loss: 0.24344739317893982, acc: 0.9526315927505493)
[2024-12-17 02:26:55,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:55,661][root][INFO] - Training Epoch: 2/2, step 1059/7134 completed (loss: 0.2062288075685501, acc: 0.9431279897689819)
[2024-12-17 02:26:55,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:55,939][root][INFO] - Training Epoch: 2/2, step 1060/7134 completed (loss: 0.16680718958377838, acc: 0.9679487347602844)
[2024-12-17 02:26:56,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:56,232][root][INFO] - Training Epoch: 2/2, step 1061/7134 completed (loss: 0.21293090283870697, acc: 0.9432989954948425)
[2024-12-17 02:26:56,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:56,496][root][INFO] - Training Epoch: 2/2, step 1062/7134 completed (loss: 0.24836140871047974, acc: 0.9457831382751465)
[2024-12-17 02:26:56,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:56,777][root][INFO] - Training Epoch: 2/2, step 1063/7134 completed (loss: 0.11133181303739548, acc: 0.970588207244873)
[2024-12-17 02:26:56,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:57,068][root][INFO] - Training Epoch: 2/2, step 1064/7134 completed (loss: 0.25341689586639404, acc: 0.9351351261138916)
[2024-12-17 02:26:57,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:57,368][root][INFO] - Training Epoch: 2/2, step 1065/7134 completed (loss: 0.2789493203163147, acc: 0.9447513818740845)
[2024-12-17 02:26:57,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:57,656][root][INFO] - Training Epoch: 2/2, step 1066/7134 completed (loss: 0.3468353748321533, acc: 0.9312977194786072)
[2024-12-17 02:26:57,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:57,954][root][INFO] - Training Epoch: 2/2, step 1067/7134 completed (loss: 0.13419649004936218, acc: 0.9607843160629272)
[2024-12-17 02:26:58,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:58,269][root][INFO] - Training Epoch: 2/2, step 1068/7134 completed (loss: 0.24336054921150208, acc: 0.9296875)
[2024-12-17 02:26:58,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:58,570][root][INFO] - Training Epoch: 2/2, step 1069/7134 completed (loss: 0.2544604241847992, acc: 0.9236111044883728)
[2024-12-17 02:26:58,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:58,842][root][INFO] - Training Epoch: 2/2, step 1070/7134 completed (loss: 0.24754942953586578, acc: 0.9383561611175537)
[2024-12-17 02:26:58,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:59,132][root][INFO] - Training Epoch: 2/2, step 1071/7134 completed (loss: 0.12829497456550598, acc: 0.981249988079071)
[2024-12-17 02:26:59,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:59,414][root][INFO] - Training Epoch: 2/2, step 1072/7134 completed (loss: 0.07370208948850632, acc: 0.9756097793579102)
[2024-12-17 02:26:59,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:59,698][root][INFO] - Training Epoch: 2/2, step 1073/7134 completed (loss: 0.14469589293003082, acc: 0.9813664555549622)
[2024-12-17 02:26:59,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:59,965][root][INFO] - Training Epoch: 2/2, step 1074/7134 completed (loss: 0.26178500056266785, acc: 0.9432623982429504)
[2024-12-17 02:27:00,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:00,244][root][INFO] - Training Epoch: 2/2, step 1075/7134 completed (loss: 0.4244111180305481, acc: 0.8978102207183838)
[2024-12-17 02:27:00,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:00,518][root][INFO] - Training Epoch: 2/2, step 1076/7134 completed (loss: 0.5019190907478333, acc: 0.8936170339584351)
[2024-12-17 02:27:00,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:00,784][root][INFO] - Training Epoch: 2/2, step 1077/7134 completed (loss: 0.44181492924690247, acc: 0.9115044474601746)
[2024-12-17 02:27:00,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:01,069][root][INFO] - Training Epoch: 2/2, step 1078/7134 completed (loss: 0.4751357436180115, acc: 0.8742138147354126)
[2024-12-17 02:27:01,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:01,345][root][INFO] - Training Epoch: 2/2, step 1079/7134 completed (loss: 0.20630960166454315, acc: 0.9447004795074463)
[2024-12-17 02:27:01,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:01,605][root][INFO] - Training Epoch: 2/2, step 1080/7134 completed (loss: 0.21762360632419586, acc: 0.961240291595459)
[2024-12-17 02:27:01,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:01,894][root][INFO] - Training Epoch: 2/2, step 1081/7134 completed (loss: 0.29585981369018555, acc: 0.9216867685317993)
[2024-12-17 02:27:02,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:02,193][root][INFO] - Training Epoch: 2/2, step 1082/7134 completed (loss: 0.05124007910490036, acc: 0.9910314083099365)
[2024-12-17 02:27:02,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:02,473][root][INFO] - Training Epoch: 2/2, step 1083/7134 completed (loss: 0.2304646223783493, acc: 0.9390863180160522)
[2024-12-17 02:27:02,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:02,763][root][INFO] - Training Epoch: 2/2, step 1084/7134 completed (loss: 0.15048576891422272, acc: 0.9627659320831299)
[2024-12-17 02:27:02,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:03,046][root][INFO] - Training Epoch: 2/2, step 1085/7134 completed (loss: 0.15783214569091797, acc: 0.9622641801834106)
[2024-12-17 02:27:03,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:03,313][root][INFO] - Training Epoch: 2/2, step 1086/7134 completed (loss: 0.3019987642765045, acc: 0.9193548560142517)
[2024-12-17 02:27:03,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:03,599][root][INFO] - Training Epoch: 2/2, step 1087/7134 completed (loss: 0.18408213555812836, acc: 0.9623655676841736)
[2024-12-17 02:27:03,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:03,891][root][INFO] - Training Epoch: 2/2, step 1088/7134 completed (loss: 0.1323200762271881, acc: 0.9602272510528564)
[2024-12-17 02:27:04,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:04,167][root][INFO] - Training Epoch: 2/2, step 1089/7134 completed (loss: 0.34382784366607666, acc: 0.9018405079841614)
[2024-12-17 02:27:04,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:04,452][root][INFO] - Training Epoch: 2/2, step 1090/7134 completed (loss: 0.32080113887786865, acc: 0.8928571343421936)
[2024-12-17 02:27:04,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:04,718][root][INFO] - Training Epoch: 2/2, step 1091/7134 completed (loss: 0.3477471172809601, acc: 0.9130434989929199)
[2024-12-17 02:27:04,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:04,998][root][INFO] - Training Epoch: 2/2, step 1092/7134 completed (loss: 0.17021876573562622, acc: 0.9640718698501587)
[2024-12-17 02:27:05,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:05,279][root][INFO] - Training Epoch: 2/2, step 1093/7134 completed (loss: 0.22475850582122803, acc: 0.9455782175064087)
[2024-12-17 02:27:05,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:05,560][root][INFO] - Training Epoch: 2/2, step 1094/7134 completed (loss: 0.43686342239379883, acc: 0.902255654335022)
[2024-12-17 02:27:05,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:05,862][root][INFO] - Training Epoch: 2/2, step 1095/7134 completed (loss: 0.1718890219926834, acc: 0.9470899701118469)
[2024-12-17 02:27:05,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:06,152][root][INFO] - Training Epoch: 2/2, step 1096/7134 completed (loss: 0.2998478412628174, acc: 0.9247311949729919)
[2024-12-17 02:27:06,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:06,438][root][INFO] - Training Epoch: 2/2, step 1097/7134 completed (loss: 0.3552246391773224, acc: 0.9289617538452148)
[2024-12-17 02:27:06,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:06,717][root][INFO] - Training Epoch: 2/2, step 1098/7134 completed (loss: 0.1489170640707016, acc: 0.949999988079071)
[2024-12-17 02:27:06,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:06,997][root][INFO] - Training Epoch: 2/2, step 1099/7134 completed (loss: 0.18308483064174652, acc: 0.9375)
[2024-12-17 02:27:07,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:07,288][root][INFO] - Training Epoch: 2/2, step 1100/7134 completed (loss: 0.17640863358974457, acc: 0.9473684430122375)
[2024-12-17 02:27:07,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:07,573][root][INFO] - Training Epoch: 2/2, step 1101/7134 completed (loss: 0.3528165817260742, acc: 0.928205132484436)
[2024-12-17 02:27:07,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:07,855][root][INFO] - Training Epoch: 2/2, step 1102/7134 completed (loss: 0.4574694037437439, acc: 0.875)
[2024-12-17 02:27:07,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:08,137][root][INFO] - Training Epoch: 2/2, step 1103/7134 completed (loss: 0.591735303401947, acc: 0.8690476417541504)
[2024-12-17 02:27:08,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:08,401][root][INFO] - Training Epoch: 2/2, step 1104/7134 completed (loss: 0.1850225031375885, acc: 0.9666666388511658)
[2024-12-17 02:27:08,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:08,677][root][INFO] - Training Epoch: 2/2, step 1105/7134 completed (loss: 0.24567881226539612, acc: 0.9259259104728699)
[2024-12-17 02:27:08,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:08,949][root][INFO] - Training Epoch: 2/2, step 1106/7134 completed (loss: 0.14092443883419037, acc: 0.9668874144554138)
[2024-12-17 02:27:09,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:09,241][root][INFO] - Training Epoch: 2/2, step 1107/7134 completed (loss: 0.10045122355222702, acc: 0.9666666388511658)
[2024-12-17 02:27:09,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:09,519][root][INFO] - Training Epoch: 2/2, step 1108/7134 completed (loss: 0.08838383108377457, acc: 0.9822485446929932)
[2024-12-17 02:27:09,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:09,806][root][INFO] - Training Epoch: 2/2, step 1109/7134 completed (loss: 0.24979597330093384, acc: 0.9421965479850769)
[2024-12-17 02:27:09,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:10,086][root][INFO] - Training Epoch: 2/2, step 1110/7134 completed (loss: 0.28525736927986145, acc: 0.9516128897666931)
[2024-12-17 02:27:10,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:10,365][root][INFO] - Training Epoch: 2/2, step 1111/7134 completed (loss: 0.2317691594362259, acc: 0.9312499761581421)
[2024-12-17 02:27:10,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:10,635][root][INFO] - Training Epoch: 2/2, step 1112/7134 completed (loss: 0.1613517552614212, acc: 0.9370629191398621)
[2024-12-17 02:27:10,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:10,920][root][INFO] - Training Epoch: 2/2, step 1113/7134 completed (loss: 0.18499596416950226, acc: 0.955974817276001)
[2024-12-17 02:27:11,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:11,201][root][INFO] - Training Epoch: 2/2, step 1114/7134 completed (loss: 0.25725752115249634, acc: 0.9470899701118469)
[2024-12-17 02:27:11,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:11,482][root][INFO] - Training Epoch: 2/2, step 1115/7134 completed (loss: 0.2041652947664261, acc: 0.9419354796409607)
[2024-12-17 02:27:11,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:11,771][root][INFO] - Training Epoch: 2/2, step 1116/7134 completed (loss: 0.2358369678258896, acc: 0.9512194991111755)
[2024-12-17 02:27:11,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:12,072][root][INFO] - Training Epoch: 2/2, step 1117/7134 completed (loss: 0.07014413923025131, acc: 0.9736841917037964)
[2024-12-17 02:27:12,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:12,361][root][INFO] - Training Epoch: 2/2, step 1118/7134 completed (loss: 0.09850940108299255, acc: 0.9694656729698181)
[2024-12-17 02:27:12,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:12,622][root][INFO] - Training Epoch: 2/2, step 1119/7134 completed (loss: 0.17900119721889496, acc: 0.9655172228813171)
[2024-12-17 02:27:12,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:12,896][root][INFO] - Training Epoch: 2/2, step 1120/7134 completed (loss: 0.2889034152030945, acc: 0.9160305261611938)
[2024-12-17 02:27:13,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:13,175][root][INFO] - Training Epoch: 2/2, step 1121/7134 completed (loss: 0.1845863163471222, acc: 0.9419354796409607)
[2024-12-17 02:27:13,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:13,445][root][INFO] - Training Epoch: 2/2, step 1122/7134 completed (loss: 0.05049698054790497, acc: 0.9846153855323792)
[2024-12-17 02:27:13,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:13,719][root][INFO] - Training Epoch: 2/2, step 1123/7134 completed (loss: 0.08190537244081497, acc: 0.9931034445762634)
[2024-12-17 02:27:13,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:14,002][root][INFO] - Training Epoch: 2/2, step 1124/7134 completed (loss: 0.17528963088989258, acc: 0.9594594836235046)
[2024-12-17 02:27:14,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:14,281][root][INFO] - Training Epoch: 2/2, step 1125/7134 completed (loss: 0.13194820284843445, acc: 0.9642857313156128)
[2024-12-17 02:27:14,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:14,557][root][INFO] - Training Epoch: 2/2, step 1126/7134 completed (loss: 0.18447573482990265, acc: 0.949438214302063)
[2024-12-17 02:27:14,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:14,838][root][INFO] - Training Epoch: 2/2, step 1127/7134 completed (loss: 0.16068647801876068, acc: 0.970588207244873)
[2024-12-17 02:27:14,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:15,122][root][INFO] - Training Epoch: 2/2, step 1128/7134 completed (loss: 0.18791811168193817, acc: 0.9770992398262024)
[2024-12-17 02:27:15,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:15,399][root][INFO] - Training Epoch: 2/2, step 1129/7134 completed (loss: 0.23787328600883484, acc: 0.9416666626930237)
[2024-12-17 02:27:15,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:15,674][root][INFO] - Training Epoch: 2/2, step 1130/7134 completed (loss: 0.09470377117395401, acc: 0.9640287756919861)
[2024-12-17 02:27:15,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:15,970][root][INFO] - Training Epoch: 2/2, step 1131/7134 completed (loss: 0.2164892852306366, acc: 0.9595959782600403)
[2024-12-17 02:27:16,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:16,267][root][INFO] - Training Epoch: 2/2, step 1132/7134 completed (loss: 0.4827352464199066, acc: 0.899328887462616)
[2024-12-17 02:27:16,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:16,593][root][INFO] - Training Epoch: 2/2, step 1133/7134 completed (loss: 0.300554096698761, acc: 0.9306358098983765)
[2024-12-17 02:27:16,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:16,887][root][INFO] - Training Epoch: 2/2, step 1134/7134 completed (loss: 0.2278740257024765, acc: 0.9285714030265808)
[2024-12-17 02:27:16,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:17,134][root][INFO] - Training Epoch: 2/2, step 1135/7134 completed (loss: 0.18617063760757446, acc: 0.9530201554298401)
[2024-12-17 02:27:17,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:17,436][root][INFO] - Training Epoch: 2/2, step 1136/7134 completed (loss: 0.39045220613479614, acc: 0.9132652878761292)
[2024-12-17 02:27:17,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:17,665][root][INFO] - Training Epoch: 2/2, step 1137/7134 completed (loss: 0.3264143168926239, acc: 0.9528301954269409)
[2024-12-17 02:27:17,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:17,969][root][INFO] - Training Epoch: 2/2, step 1138/7134 completed (loss: 0.26370862126350403, acc: 0.9399999976158142)
[2024-12-17 02:27:18,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:18,263][root][INFO] - Training Epoch: 2/2, step 1139/7134 completed (loss: 0.40359342098236084, acc: 0.9120879173278809)
[2024-12-17 02:27:18,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:18,549][root][INFO] - Training Epoch: 2/2, step 1140/7134 completed (loss: 0.24082890152931213, acc: 0.9473684430122375)
[2024-12-17 02:27:18,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:18,826][root][INFO] - Training Epoch: 2/2, step 1141/7134 completed (loss: 0.10259449481964111, acc: 0.9727272987365723)
[2024-12-17 02:27:18,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:19,100][root][INFO] - Training Epoch: 2/2, step 1142/7134 completed (loss: 0.13971839845180511, acc: 0.9666666388511658)
[2024-12-17 02:27:19,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:19,360][root][INFO] - Training Epoch: 2/2, step 1143/7134 completed (loss: 0.38951537013053894, acc: 0.9277108311653137)
[2024-12-17 02:27:19,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:19,634][root][INFO] - Training Epoch: 2/2, step 1144/7134 completed (loss: 0.3822644054889679, acc: 0.9345238208770752)
[2024-12-17 02:27:19,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:19,912][root][INFO] - Training Epoch: 2/2, step 1145/7134 completed (loss: 0.15135471522808075, acc: 0.9776536226272583)
[2024-12-17 02:27:20,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:20,178][root][INFO] - Training Epoch: 2/2, step 1146/7134 completed (loss: 0.045061200857162476, acc: 0.9924242496490479)
[2024-12-17 02:27:20,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:20,442][root][INFO] - Training Epoch: 2/2, step 1147/7134 completed (loss: 0.0507565476000309, acc: 0.9945945739746094)
[2024-12-17 02:27:20,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:20,713][root][INFO] - Training Epoch: 2/2, step 1148/7134 completed (loss: 0.11778385192155838, acc: 0.9640287756919861)
[2024-12-17 02:27:20,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:20,984][root][INFO] - Training Epoch: 2/2, step 1149/7134 completed (loss: 0.33448851108551025, acc: 0.9097222089767456)
[2024-12-17 02:27:21,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:21,261][root][INFO] - Training Epoch: 2/2, step 1150/7134 completed (loss: 0.15772627294063568, acc: 0.9607843160629272)
[2024-12-17 02:27:21,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:21,520][root][INFO] - Training Epoch: 2/2, step 1151/7134 completed (loss: 0.20535659790039062, acc: 0.9411764740943909)
[2024-12-17 02:27:21,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:21,792][root][INFO] - Training Epoch: 2/2, step 1152/7134 completed (loss: 0.1072864979505539, acc: 0.9838709831237793)
[2024-12-17 02:27:21,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:22,063][root][INFO] - Training Epoch: 2/2, step 1153/7134 completed (loss: 0.24064002931118011, acc: 0.9411764740943909)
[2024-12-17 02:27:22,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:22,325][root][INFO] - Training Epoch: 2/2, step 1154/7134 completed (loss: 0.135120689868927, acc: 0.96875)
[2024-12-17 02:27:22,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:22,600][root][INFO] - Training Epoch: 2/2, step 1155/7134 completed (loss: 0.343225359916687, acc: 0.9145299196243286)
[2024-12-17 02:27:22,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:22,878][root][INFO] - Training Epoch: 2/2, step 1156/7134 completed (loss: 0.10323023051023483, acc: 0.9772727489471436)
[2024-12-17 02:27:22,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:23,147][root][INFO] - Training Epoch: 2/2, step 1157/7134 completed (loss: 0.5142819285392761, acc: 0.8896551728248596)
[2024-12-17 02:27:23,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:23,413][root][INFO] - Training Epoch: 2/2, step 1158/7134 completed (loss: 0.46947333216667175, acc: 0.939130425453186)
[2024-12-17 02:27:23,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:23,692][root][INFO] - Training Epoch: 2/2, step 1159/7134 completed (loss: 0.25481897592544556, acc: 0.9341317415237427)
[2024-12-17 02:27:23,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:23,973][root][INFO] - Training Epoch: 2/2, step 1160/7134 completed (loss: 0.13275738060474396, acc: 0.9506173133850098)
[2024-12-17 02:27:24,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:24,248][root][INFO] - Training Epoch: 2/2, step 1161/7134 completed (loss: 0.2069064974784851, acc: 0.9492753744125366)
[2024-12-17 02:27:24,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:24,522][root][INFO] - Training Epoch: 2/2, step 1162/7134 completed (loss: 0.2128966897726059, acc: 0.9303797483444214)
[2024-12-17 02:27:24,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:24,798][root][INFO] - Training Epoch: 2/2, step 1163/7134 completed (loss: 0.1806158423423767, acc: 0.951724112033844)
[2024-12-17 02:27:24,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:25,077][root][INFO] - Training Epoch: 2/2, step 1164/7134 completed (loss: 0.1470922976732254, acc: 0.9613259434700012)
[2024-12-17 02:27:25,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:25,382][root][INFO] - Training Epoch: 2/2, step 1165/7134 completed (loss: 0.1497957855463028, acc: 0.9487179517745972)
[2024-12-17 02:27:25,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:25,677][root][INFO] - Training Epoch: 2/2, step 1166/7134 completed (loss: 0.16201245784759521, acc: 0.9734042286872864)
[2024-12-17 02:27:25,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:25,964][root][INFO] - Training Epoch: 2/2, step 1167/7134 completed (loss: 0.11788960546255112, acc: 0.9760000109672546)
[2024-12-17 02:27:26,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:26,263][root][INFO] - Training Epoch: 2/2, step 1168/7134 completed (loss: 0.1572112739086151, acc: 0.9682539701461792)
[2024-12-17 02:27:26,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:26,551][root][INFO] - Training Epoch: 2/2, step 1169/7134 completed (loss: 0.2587437927722931, acc: 0.936170220375061)
[2024-12-17 02:27:26,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:26,868][root][INFO] - Training Epoch: 2/2, step 1170/7134 completed (loss: 0.29002490639686584, acc: 0.9435028433799744)
[2024-12-17 02:27:26,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:27,142][root][INFO] - Training Epoch: 2/2, step 1171/7134 completed (loss: 0.22727134823799133, acc: 0.9333333373069763)
[2024-12-17 02:27:27,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:27,418][root][INFO] - Training Epoch: 2/2, step 1172/7134 completed (loss: 0.13285216689109802, acc: 0.9404761791229248)
[2024-12-17 02:27:27,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:27,698][root][INFO] - Training Epoch: 2/2, step 1173/7134 completed (loss: 0.16020053625106812, acc: 0.9576719403266907)
[2024-12-17 02:27:27,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:27,966][root][INFO] - Training Epoch: 2/2, step 1174/7134 completed (loss: 0.10786712914705276, acc: 0.9815950989723206)
[2024-12-17 02:27:28,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:28,258][root][INFO] - Training Epoch: 2/2, step 1175/7134 completed (loss: 0.14173179864883423, acc: 0.9588235020637512)
[2024-12-17 02:27:28,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:28,540][root][INFO] - Training Epoch: 2/2, step 1176/7134 completed (loss: 0.10559741407632828, acc: 0.9722222089767456)
[2024-12-17 02:27:28,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:28,817][root][INFO] - Training Epoch: 2/2, step 1177/7134 completed (loss: 0.04090823233127594, acc: 1.0)
[2024-12-17 02:27:28,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:29,083][root][INFO] - Training Epoch: 2/2, step 1178/7134 completed (loss: 0.13381245732307434, acc: 0.9711538553237915)
[2024-12-17 02:27:29,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:29,364][root][INFO] - Training Epoch: 2/2, step 1179/7134 completed (loss: 0.07264083623886108, acc: 0.9838709831237793)
[2024-12-17 02:27:29,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:29,659][root][INFO] - Training Epoch: 2/2, step 1180/7134 completed (loss: 0.0970221534371376, acc: 0.9662162065505981)
[2024-12-17 02:27:29,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:29,939][root][INFO] - Training Epoch: 2/2, step 1181/7134 completed (loss: 0.1648869514465332, acc: 0.9670329689979553)
[2024-12-17 02:27:30,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:30,196][root][INFO] - Training Epoch: 2/2, step 1182/7134 completed (loss: 0.10271070152521133, acc: 0.9727891087532043)
[2024-12-17 02:27:30,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:30,488][root][INFO] - Training Epoch: 2/2, step 1183/7134 completed (loss: 0.03171062469482422, acc: 0.9942196607589722)
[2024-12-17 02:27:30,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:30,773][root][INFO] - Training Epoch: 2/2, step 1184/7134 completed (loss: 0.15335330367088318, acc: 0.9537572264671326)
[2024-12-17 02:27:30,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:31,040][root][INFO] - Training Epoch: 2/2, step 1185/7134 completed (loss: 0.055799610912799835, acc: 0.9878787994384766)
[2024-12-17 02:27:31,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:31,316][root][INFO] - Training Epoch: 2/2, step 1186/7134 completed (loss: 0.09475861489772797, acc: 0.9836956262588501)
[2024-12-17 02:27:31,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:31,597][root][INFO] - Training Epoch: 2/2, step 1187/7134 completed (loss: 0.09187750518321991, acc: 0.9702380895614624)
[2024-12-17 02:27:31,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:31,889][root][INFO] - Training Epoch: 2/2, step 1188/7134 completed (loss: 0.0801009014248848, acc: 0.9838709831237793)
[2024-12-17 02:27:32,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:32,165][root][INFO] - Training Epoch: 2/2, step 1189/7134 completed (loss: 0.11300650984048843, acc: 0.9704142212867737)
[2024-12-17 02:27:32,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:32,439][root][INFO] - Training Epoch: 2/2, step 1190/7134 completed (loss: 0.10071644186973572, acc: 0.9777777791023254)
[2024-12-17 02:27:32,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:32,721][root][INFO] - Training Epoch: 2/2, step 1191/7134 completed (loss: 0.2923021614551544, acc: 0.9455782175064087)
[2024-12-17 02:27:32,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:33,030][root][INFO] - Training Epoch: 2/2, step 1192/7134 completed (loss: 0.09066056460142136, acc: 0.9924812316894531)
[2024-12-17 02:27:33,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:33,339][root][INFO] - Training Epoch: 2/2, step 1193/7134 completed (loss: 0.2222226858139038, acc: 0.9527559280395508)
[2024-12-17 02:27:33,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:33,626][root][INFO] - Training Epoch: 2/2, step 1194/7134 completed (loss: 0.11195965856313705, acc: 0.9798657894134521)
[2024-12-17 02:27:33,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:33,907][root][INFO] - Training Epoch: 2/2, step 1195/7134 completed (loss: 0.18097934126853943, acc: 0.9692307710647583)
[2024-12-17 02:27:34,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:34,226][root][INFO] - Training Epoch: 2/2, step 1196/7134 completed (loss: 0.23290255665779114, acc: 0.9432623982429504)
[2024-12-17 02:27:34,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:34,497][root][INFO] - Training Epoch: 2/2, step 1197/7134 completed (loss: 0.1645934283733368, acc: 0.9726027250289917)
[2024-12-17 02:27:34,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:34,777][root][INFO] - Training Epoch: 2/2, step 1198/7134 completed (loss: 0.22794398665428162, acc: 0.9375)
[2024-12-17 02:27:34,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:35,079][root][INFO] - Training Epoch: 2/2, step 1199/7134 completed (loss: 0.20703700184822083, acc: 0.9415584206581116)
[2024-12-17 02:27:35,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:35,384][root][INFO] - Training Epoch: 2/2, step 1200/7134 completed (loss: 0.07382548600435257, acc: 0.9719626307487488)
[2024-12-17 02:27:35,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:35,672][root][INFO] - Training Epoch: 2/2, step 1201/7134 completed (loss: 0.20425835251808167, acc: 0.9308176040649414)
[2024-12-17 02:27:35,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:35,970][root][INFO] - Training Epoch: 2/2, step 1202/7134 completed (loss: 0.27088087797164917, acc: 0.929347813129425)
[2024-12-17 02:27:36,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:36,238][root][INFO] - Training Epoch: 2/2, step 1203/7134 completed (loss: 0.14374610781669617, acc: 0.9599999785423279)
[2024-12-17 02:27:36,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:36,517][root][INFO] - Training Epoch: 2/2, step 1204/7134 completed (loss: 0.38151100277900696, acc: 0.9191176295280457)
[2024-12-17 02:27:36,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:36,810][root][INFO] - Training Epoch: 2/2, step 1205/7134 completed (loss: 0.498121976852417, acc: 0.8965517282485962)
[2024-12-17 02:27:36,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:37,099][root][INFO] - Training Epoch: 2/2, step 1206/7134 completed (loss: 0.3606233596801758, acc: 0.9145728349685669)
[2024-12-17 02:27:37,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:37,387][root][INFO] - Training Epoch: 2/2, step 1207/7134 completed (loss: 0.17382802069187164, acc: 0.9462365508079529)
[2024-12-17 02:27:37,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:37,672][root][INFO] - Training Epoch: 2/2, step 1208/7134 completed (loss: 0.3337141275405884, acc: 0.9160305261611938)
[2024-12-17 02:27:37,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:37,954][root][INFO] - Training Epoch: 2/2, step 1209/7134 completed (loss: 0.2739804983139038, acc: 0.9344262480735779)
[2024-12-17 02:27:38,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:38,234][root][INFO] - Training Epoch: 2/2, step 1210/7134 completed (loss: 0.37638142704963684, acc: 0.8999999761581421)
[2024-12-17 02:27:38,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:38,518][root][INFO] - Training Epoch: 2/2, step 1211/7134 completed (loss: 0.6401568055152893, acc: 0.8561151027679443)
[2024-12-17 02:27:38,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:38,785][root][INFO] - Training Epoch: 2/2, step 1212/7134 completed (loss: 0.4588117301464081, acc: 0.9051094651222229)
[2024-12-17 02:27:38,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:39,082][root][INFO] - Training Epoch: 2/2, step 1213/7134 completed (loss: 0.35407814383506775, acc: 0.9112426042556763)
[2024-12-17 02:27:39,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:39,366][root][INFO] - Training Epoch: 2/2, step 1214/7134 completed (loss: 0.3587823808193207, acc: 0.9133333563804626)
[2024-12-17 02:27:39,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:39,644][root][INFO] - Training Epoch: 2/2, step 1215/7134 completed (loss: 0.2960387170314789, acc: 0.9117646813392639)
[2024-12-17 02:27:39,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:39,930][root][INFO] - Training Epoch: 2/2, step 1216/7134 completed (loss: 0.1612054705619812, acc: 0.9536423683166504)
[2024-12-17 02:27:40,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:40,218][root][INFO] - Training Epoch: 2/2, step 1217/7134 completed (loss: 0.20796792209148407, acc: 0.9605262875556946)
[2024-12-17 02:27:40,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:40,498][root][INFO] - Training Epoch: 2/2, step 1218/7134 completed (loss: 0.3757413923740387, acc: 0.8812500238418579)
[2024-12-17 02:27:40,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:40,779][root][INFO] - Training Epoch: 2/2, step 1219/7134 completed (loss: 0.3793438673019409, acc: 0.9200000166893005)
[2024-12-17 02:27:40,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:41,076][root][INFO] - Training Epoch: 2/2, step 1220/7134 completed (loss: 0.36295974254608154, acc: 0.9123711585998535)
[2024-12-17 02:27:41,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:41,370][root][INFO] - Training Epoch: 2/2, step 1221/7134 completed (loss: 0.2684755027294159, acc: 0.9366515874862671)
[2024-12-17 02:27:41,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:41,667][root][INFO] - Training Epoch: 2/2, step 1222/7134 completed (loss: 0.38973093032836914, acc: 0.9320388436317444)
[2024-12-17 02:27:41,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:41,947][root][INFO] - Training Epoch: 2/2, step 1223/7134 completed (loss: 0.43608638644218445, acc: 0.9034090638160706)
[2024-12-17 02:27:42,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:42,230][root][INFO] - Training Epoch: 2/2, step 1224/7134 completed (loss: 0.2965455651283264, acc: 0.9056603908538818)
[2024-12-17 02:27:42,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:42,519][root][INFO] - Training Epoch: 2/2, step 1225/7134 completed (loss: 0.3233061134815216, acc: 0.9269406199455261)
[2024-12-17 02:27:42,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:42,799][root][INFO] - Training Epoch: 2/2, step 1226/7134 completed (loss: 0.480269193649292, acc: 0.9047619104385376)
[2024-12-17 02:27:42,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:43,097][root][INFO] - Training Epoch: 2/2, step 1227/7134 completed (loss: 0.8134221434593201, acc: 0.8659793734550476)
[2024-12-17 02:27:43,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:43,382][root][INFO] - Training Epoch: 2/2, step 1228/7134 completed (loss: 0.4351736605167389, acc: 0.9069767594337463)
[2024-12-17 02:27:43,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:43,664][root][INFO] - Training Epoch: 2/2, step 1229/7134 completed (loss: 0.35745880007743835, acc: 0.9306930899620056)
[2024-12-17 02:27:43,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:43,965][root][INFO] - Training Epoch: 2/2, step 1230/7134 completed (loss: 0.4756006896495819, acc: 0.900943398475647)
[2024-12-17 02:27:44,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:44,268][root][INFO] - Training Epoch: 2/2, step 1231/7134 completed (loss: 0.3892952501773834, acc: 0.8879310488700867)
[2024-12-17 02:27:44,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:44,571][root][INFO] - Training Epoch: 2/2, step 1232/7134 completed (loss: 0.4278165102005005, acc: 0.9013453125953674)
[2024-12-17 02:27:44,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:44,847][root][INFO] - Training Epoch: 2/2, step 1233/7134 completed (loss: 0.4545603394508362, acc: 0.877828061580658)
[2024-12-17 02:27:44,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:45,129][root][INFO] - Training Epoch: 2/2, step 1234/7134 completed (loss: 0.2772310972213745, acc: 0.9487179517745972)
[2024-12-17 02:27:45,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:45,421][root][INFO] - Training Epoch: 2/2, step 1235/7134 completed (loss: 0.31871455907821655, acc: 0.9234693646430969)
[2024-12-17 02:27:45,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:45,709][root][INFO] - Training Epoch: 2/2, step 1236/7134 completed (loss: 0.5747566819190979, acc: 0.8941176533699036)
[2024-12-17 02:27:45,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:46,006][root][INFO] - Training Epoch: 2/2, step 1237/7134 completed (loss: 0.4222998321056366, acc: 0.9139072895050049)
[2024-12-17 02:27:46,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:46,287][root][INFO] - Training Epoch: 2/2, step 1238/7134 completed (loss: 0.7649269104003906, acc: 0.8418604731559753)
[2024-12-17 02:27:46,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:46,589][root][INFO] - Training Epoch: 2/2, step 1239/7134 completed (loss: 0.49531280994415283, acc: 0.8841463327407837)
[2024-12-17 02:27:46,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:46,887][root][INFO] - Training Epoch: 2/2, step 1240/7134 completed (loss: 0.447327196598053, acc: 0.8895348906517029)
[2024-12-17 02:27:47,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:47,177][root][INFO] - Training Epoch: 2/2, step 1241/7134 completed (loss: 0.29805445671081543, acc: 0.9508196711540222)
[2024-12-17 02:27:47,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:47,468][root][INFO] - Training Epoch: 2/2, step 1242/7134 completed (loss: 0.326994925737381, acc: 0.926701545715332)
[2024-12-17 02:27:47,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:47,762][root][INFO] - Training Epoch: 2/2, step 1243/7134 completed (loss: 0.326151967048645, acc: 0.890350878238678)
[2024-12-17 02:27:47,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:48,043][root][INFO] - Training Epoch: 2/2, step 1244/7134 completed (loss: 0.3391057252883911, acc: 0.9154929518699646)
[2024-12-17 02:27:48,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:48,347][root][INFO] - Training Epoch: 2/2, step 1245/7134 completed (loss: 0.321302592754364, acc: 0.9292929172515869)
[2024-12-17 02:27:48,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:48,632][root][INFO] - Training Epoch: 2/2, step 1246/7134 completed (loss: 0.4020894765853882, acc: 0.8684210777282715)
[2024-12-17 02:27:48,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:48,910][root][INFO] - Training Epoch: 2/2, step 1247/7134 completed (loss: 0.21799927949905396, acc: 0.9457831382751465)
[2024-12-17 02:27:49,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:49,190][root][INFO] - Training Epoch: 2/2, step 1248/7134 completed (loss: 0.33759671449661255, acc: 0.9399999976158142)
[2024-12-17 02:27:49,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:49,455][root][INFO] - Training Epoch: 2/2, step 1249/7134 completed (loss: 0.1404586285352707, acc: 0.9568965435028076)
[2024-12-17 02:27:49,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:49,717][root][INFO] - Training Epoch: 2/2, step 1250/7134 completed (loss: 0.11496078222990036, acc: 0.9599999785423279)
[2024-12-17 02:27:49,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:49,999][root][INFO] - Training Epoch: 2/2, step 1251/7134 completed (loss: 0.22255735099315643, acc: 0.9333333373069763)
[2024-12-17 02:27:50,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:50,277][root][INFO] - Training Epoch: 2/2, step 1252/7134 completed (loss: 0.21895767748355865, acc: 0.9763779640197754)
[2024-12-17 02:27:50,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:50,559][root][INFO] - Training Epoch: 2/2, step 1253/7134 completed (loss: 0.3476009666919708, acc: 0.9316239356994629)
[2024-12-17 02:27:50,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:50,858][root][INFO] - Training Epoch: 2/2, step 1254/7134 completed (loss: 0.2557903528213501, acc: 0.9200000166893005)
[2024-12-17 02:27:50,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:51,136][root][INFO] - Training Epoch: 2/2, step 1255/7134 completed (loss: 0.2037089318037033, acc: 0.951724112033844)
[2024-12-17 02:27:51,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:51,407][root][INFO] - Training Epoch: 2/2, step 1256/7134 completed (loss: 0.2553543746471405, acc: 0.9007633328437805)
[2024-12-17 02:27:51,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:51,712][root][INFO] - Training Epoch: 2/2, step 1257/7134 completed (loss: 0.17137953639030457, acc: 0.9465649127960205)
[2024-12-17 02:27:51,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:51,997][root][INFO] - Training Epoch: 2/2, step 1258/7134 completed (loss: 0.2703271508216858, acc: 0.9523809552192688)
[2024-12-17 02:27:52,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:52,275][root][INFO] - Training Epoch: 2/2, step 1259/7134 completed (loss: 0.40921857953071594, acc: 0.9230769276618958)
[2024-12-17 02:27:52,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:52,558][root][INFO] - Training Epoch: 2/2, step 1260/7134 completed (loss: 0.1733863353729248, acc: 0.9395973086357117)
[2024-12-17 02:27:52,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:52,848][root][INFO] - Training Epoch: 2/2, step 1261/7134 completed (loss: 0.19184672832489014, acc: 0.9662162065505981)
[2024-12-17 02:27:52,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:53,115][root][INFO] - Training Epoch: 2/2, step 1262/7134 completed (loss: 0.16875727474689484, acc: 0.9767441749572754)
[2024-12-17 02:27:53,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:53,377][root][INFO] - Training Epoch: 2/2, step 1263/7134 completed (loss: 0.10449492931365967, acc: 0.9806451797485352)
[2024-12-17 02:27:53,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:53,654][root][INFO] - Training Epoch: 2/2, step 1264/7134 completed (loss: 0.14616894721984863, acc: 0.9629629850387573)
[2024-12-17 02:27:53,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:53,946][root][INFO] - Training Epoch: 2/2, step 1265/7134 completed (loss: 0.13158147037029266, acc: 0.954285740852356)
[2024-12-17 02:27:54,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:54,229][root][INFO] - Training Epoch: 2/2, step 1266/7134 completed (loss: 0.17583855986595154, acc: 0.9618320465087891)
[2024-12-17 02:27:54,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:54,504][root][INFO] - Training Epoch: 2/2, step 1267/7134 completed (loss: 0.146697998046875, acc: 0.948051929473877)
[2024-12-17 02:27:54,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:54,812][root][INFO] - Training Epoch: 2/2, step 1268/7134 completed (loss: 0.21517689526081085, acc: 0.9407407641410828)
[2024-12-17 02:27:54,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:55,096][root][INFO] - Training Epoch: 2/2, step 1269/7134 completed (loss: 0.3955734372138977, acc: 0.9090909361839294)
[2024-12-17 02:27:55,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:55,382][root][INFO] - Training Epoch: 2/2, step 1270/7134 completed (loss: 0.13765457272529602, acc: 0.9794520735740662)
[2024-12-17 02:27:55,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:55,643][root][INFO] - Training Epoch: 2/2, step 1271/7134 completed (loss: 0.23375087976455688, acc: 0.949999988079071)
[2024-12-17 02:27:55,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:55,939][root][INFO] - Training Epoch: 2/2, step 1272/7134 completed (loss: 0.12272335588932037, acc: 0.9622641801834106)
[2024-12-17 02:27:56,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:56,230][root][INFO] - Training Epoch: 2/2, step 1273/7134 completed (loss: 0.20150791108608246, acc: 0.9185185432434082)
[2024-12-17 02:27:56,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:56,511][root][INFO] - Training Epoch: 2/2, step 1274/7134 completed (loss: 0.06875640898942947, acc: 0.9917355179786682)
[2024-12-17 02:27:56,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:56,820][root][INFO] - Training Epoch: 2/2, step 1275/7134 completed (loss: 0.16723433136940002, acc: 0.9652174115180969)
[2024-12-17 02:27:56,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:57,089][root][INFO] - Training Epoch: 2/2, step 1276/7134 completed (loss: 0.12222800403833389, acc: 0.9696969985961914)
[2024-12-17 02:27:57,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:57,348][root][INFO] - Training Epoch: 2/2, step 1277/7134 completed (loss: 0.07388215512037277, acc: 0.9929577708244324)
[2024-12-17 02:27:57,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:57,627][root][INFO] - Training Epoch: 2/2, step 1278/7134 completed (loss: 0.34065359830856323, acc: 0.925000011920929)
[2024-12-17 02:27:57,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:57,917][root][INFO] - Training Epoch: 2/2, step 1279/7134 completed (loss: 0.1743166148662567, acc: 0.9510869383811951)
[2024-12-17 02:27:58,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:58,192][root][INFO] - Training Epoch: 2/2, step 1280/7134 completed (loss: 0.219479501247406, acc: 0.9465240836143494)
[2024-12-17 02:27:58,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:58,455][root][INFO] - Training Epoch: 2/2, step 1281/7134 completed (loss: 0.2796783745288849, acc: 0.9242424368858337)
[2024-12-17 02:27:58,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:58,750][root][INFO] - Training Epoch: 2/2, step 1282/7134 completed (loss: 0.5496801733970642, acc: 0.8907103538513184)
[2024-12-17 02:27:58,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:59,042][root][INFO] - Training Epoch: 2/2, step 1283/7134 completed (loss: 0.2000589221715927, acc: 0.9457364082336426)
[2024-12-17 02:27:59,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:59,351][root][INFO] - Training Epoch: 2/2, step 1284/7134 completed (loss: 0.3424214720726013, acc: 0.9281437397003174)
[2024-12-17 02:27:59,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:59,631][root][INFO] - Training Epoch: 2/2, step 1285/7134 completed (loss: 0.2658805251121521, acc: 0.96875)
[2024-12-17 02:27:59,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:59,921][root][INFO] - Training Epoch: 2/2, step 1286/7134 completed (loss: 0.2634890079498291, acc: 0.9512194991111755)
[2024-12-17 02:28:00,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:00,181][root][INFO] - Training Epoch: 2/2, step 1287/7134 completed (loss: 0.29886943101882935, acc: 0.9259259104728699)
[2024-12-17 02:28:00,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:00,447][root][INFO] - Training Epoch: 2/2, step 1288/7134 completed (loss: 0.19649243354797363, acc: 0.9481865167617798)
[2024-12-17 02:28:00,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:00,728][root][INFO] - Training Epoch: 2/2, step 1289/7134 completed (loss: 0.3699790835380554, acc: 0.9379310607910156)
[2024-12-17 02:28:00,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:01,005][root][INFO] - Training Epoch: 2/2, step 1290/7134 completed (loss: 0.16559267044067383, acc: 0.9580838084220886)
[2024-12-17 02:28:01,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:01,309][root][INFO] - Training Epoch: 2/2, step 1291/7134 completed (loss: 0.19983097910881042, acc: 0.9529411792755127)
[2024-12-17 02:28:01,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:01,588][root][INFO] - Training Epoch: 2/2, step 1292/7134 completed (loss: 0.15865051746368408, acc: 0.9395604133605957)
[2024-12-17 02:28:01,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:01,870][root][INFO] - Training Epoch: 2/2, step 1293/7134 completed (loss: 0.17639733850955963, acc: 0.964102566242218)
[2024-12-17 02:28:01,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:02,148][root][INFO] - Training Epoch: 2/2, step 1294/7134 completed (loss: 0.26295435428619385, acc: 0.9508196711540222)
[2024-12-17 02:28:02,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:02,433][root][INFO] - Training Epoch: 2/2, step 1295/7134 completed (loss: 0.20744352042675018, acc: 0.9402984976768494)
[2024-12-17 02:28:02,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:02,764][root][INFO] - Training Epoch: 2/2, step 1296/7134 completed (loss: 0.14850293099880219, acc: 0.9711538553237915)
[2024-12-17 02:28:02,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:03,024][root][INFO] - Training Epoch: 2/2, step 1297/7134 completed (loss: 0.21477945148944855, acc: 0.9375)
[2024-12-17 02:28:03,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:03,307][root][INFO] - Training Epoch: 2/2, step 1298/7134 completed (loss: 0.21225573122501373, acc: 0.9504132270812988)
[2024-12-17 02:28:03,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:03,579][root][INFO] - Training Epoch: 2/2, step 1299/7134 completed (loss: 0.18247544765472412, acc: 0.9277108311653137)
[2024-12-17 02:28:03,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:03,871][root][INFO] - Training Epoch: 2/2, step 1300/7134 completed (loss: 0.07434132695198059, acc: 0.9653465151786804)
[2024-12-17 02:28:04,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:04,147][root][INFO] - Training Epoch: 2/2, step 1301/7134 completed (loss: 0.17518314719200134, acc: 0.9407894611358643)
[2024-12-17 02:28:04,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:04,440][root][INFO] - Training Epoch: 2/2, step 1302/7134 completed (loss: 0.21693003177642822, acc: 0.9455445408821106)
[2024-12-17 02:28:04,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:04,728][root][INFO] - Training Epoch: 2/2, step 1303/7134 completed (loss: 0.38000357151031494, acc: 0.9100000262260437)
[2024-12-17 02:28:04,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:05,012][root][INFO] - Training Epoch: 2/2, step 1304/7134 completed (loss: 0.26716476678848267, acc: 0.9435028433799744)
[2024-12-17 02:28:05,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:05,308][root][INFO] - Training Epoch: 2/2, step 1305/7134 completed (loss: 0.2371397465467453, acc: 0.9536082744598389)
[2024-12-17 02:28:05,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:05,625][root][INFO] - Training Epoch: 2/2, step 1306/7134 completed (loss: 0.26682159304618835, acc: 0.9342105388641357)
[2024-12-17 02:28:05,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:05,902][root][INFO] - Training Epoch: 2/2, step 1307/7134 completed (loss: 0.12868978083133698, acc: 0.9568345546722412)
[2024-12-17 02:28:06,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:06,202][root][INFO] - Training Epoch: 2/2, step 1308/7134 completed (loss: 0.1328137069940567, acc: 0.9677419066429138)
[2024-12-17 02:28:06,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:06,484][root][INFO] - Training Epoch: 2/2, step 1309/7134 completed (loss: 0.17726066708564758, acc: 0.9516907930374146)
[2024-12-17 02:28:06,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:06,770][root][INFO] - Training Epoch: 2/2, step 1310/7134 completed (loss: 0.33829566836357117, acc: 0.8950276374816895)
[2024-12-17 02:28:06,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:07,038][root][INFO] - Training Epoch: 2/2, step 1311/7134 completed (loss: 0.18110813200473785, acc: 0.9519230723381042)
[2024-12-17 02:28:07,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:07,315][root][INFO] - Training Epoch: 2/2, step 1312/7134 completed (loss: 0.3403777480125427, acc: 0.9316770434379578)
[2024-12-17 02:28:07,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:07,607][root][INFO] - Training Epoch: 2/2, step 1313/7134 completed (loss: 0.36009681224823, acc: 0.9197530746459961)
[2024-12-17 02:28:07,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:07,889][root][INFO] - Training Epoch: 2/2, step 1314/7134 completed (loss: 0.1809469312429428, acc: 0.95652174949646)
[2024-12-17 02:28:08,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:08,171][root][INFO] - Training Epoch: 2/2, step 1315/7134 completed (loss: 0.4541081488132477, acc: 0.8810811042785645)
[2024-12-17 02:28:08,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:08,452][root][INFO] - Training Epoch: 2/2, step 1316/7134 completed (loss: 0.31412217020988464, acc: 0.9268292784690857)
[2024-12-17 02:28:08,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:08,736][root][INFO] - Training Epoch: 2/2, step 1317/7134 completed (loss: 0.4061805009841919, acc: 0.8805969953536987)
[2024-12-17 02:28:08,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:09,040][root][INFO] - Training Epoch: 2/2, step 1318/7134 completed (loss: 0.2257011979818344, acc: 0.9560439586639404)
[2024-12-17 02:28:09,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:09,327][root][INFO] - Training Epoch: 2/2, step 1319/7134 completed (loss: 0.30679357051849365, acc: 0.9363636374473572)
[2024-12-17 02:28:09,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:09,597][root][INFO] - Training Epoch: 2/2, step 1320/7134 completed (loss: 0.4331032335758209, acc: 0.9072847962379456)
[2024-12-17 02:28:09,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:09,886][root][INFO] - Training Epoch: 2/2, step 1321/7134 completed (loss: 0.2818082571029663, acc: 0.9222797751426697)
[2024-12-17 02:28:10,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:10,164][root][INFO] - Training Epoch: 2/2, step 1322/7134 completed (loss: 0.2898009717464447, acc: 0.9387755393981934)
[2024-12-17 02:28:10,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:10,436][root][INFO] - Training Epoch: 2/2, step 1323/7134 completed (loss: 0.36504101753234863, acc: 0.9154929518699646)
[2024-12-17 02:28:10,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:10,711][root][INFO] - Training Epoch: 2/2, step 1324/7134 completed (loss: 0.30057770013809204, acc: 0.9411764740943909)
[2024-12-17 02:28:10,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:11,005][root][INFO] - Training Epoch: 2/2, step 1325/7134 completed (loss: 0.20105743408203125, acc: 0.9611650705337524)
[2024-12-17 02:28:11,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:11,307][root][INFO] - Training Epoch: 2/2, step 1326/7134 completed (loss: 0.3361610472202301, acc: 0.9406392574310303)
[2024-12-17 02:28:11,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:11,599][root][INFO] - Training Epoch: 2/2, step 1327/7134 completed (loss: 0.23425574600696564, acc: 0.9526627063751221)
[2024-12-17 02:28:11,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:11,877][root][INFO] - Training Epoch: 2/2, step 1328/7134 completed (loss: 0.31827518343925476, acc: 0.9207921028137207)
[2024-12-17 02:28:12,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:12,159][root][INFO] - Training Epoch: 2/2, step 1329/7134 completed (loss: 0.26423054933547974, acc: 0.9599999785423279)
[2024-12-17 02:28:12,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:12,439][root][INFO] - Training Epoch: 2/2, step 1330/7134 completed (loss: 0.1974397599697113, acc: 0.9640287756919861)
[2024-12-17 02:28:12,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:12,725][root][INFO] - Training Epoch: 2/2, step 1331/7134 completed (loss: 0.08110892027616501, acc: 0.9718309640884399)
[2024-12-17 02:28:12,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:12,969][root][INFO] - Training Epoch: 2/2, step 1332/7134 completed (loss: 0.2101624310016632, acc: 0.9385964870452881)
[2024-12-17 02:28:13,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:13,256][root][INFO] - Training Epoch: 2/2, step 1333/7134 completed (loss: 0.29048529267311096, acc: 0.9210526347160339)
[2024-12-17 02:28:13,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:13,540][root][INFO] - Training Epoch: 2/2, step 1334/7134 completed (loss: 0.48434385657310486, acc: 0.8703703880310059)
[2024-12-17 02:28:13,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:13,818][root][INFO] - Training Epoch: 2/2, step 1335/7134 completed (loss: 0.43771255016326904, acc: 0.9162303805351257)
[2024-12-17 02:28:13,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:14,108][root][INFO] - Training Epoch: 2/2, step 1336/7134 completed (loss: 0.24893228709697723, acc: 0.9411764740943909)
[2024-12-17 02:28:14,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:14,411][root][INFO] - Training Epoch: 2/2, step 1337/7134 completed (loss: 0.1908722072839737, acc: 0.948387086391449)
[2024-12-17 02:28:14,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:14,705][root][INFO] - Training Epoch: 2/2, step 1338/7134 completed (loss: 0.39096593856811523, acc: 0.921875)
[2024-12-17 02:28:14,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:15,000][root][INFO] - Training Epoch: 2/2, step 1339/7134 completed (loss: 0.36828431487083435, acc: 0.8877550959587097)
[2024-12-17 02:28:15,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:15,266][root][INFO] - Training Epoch: 2/2, step 1340/7134 completed (loss: 0.27015578746795654, acc: 0.9415584206581116)
[2024-12-17 02:28:15,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:15,538][root][INFO] - Training Epoch: 2/2, step 1341/7134 completed (loss: 0.14411570131778717, acc: 0.9670329689979553)
[2024-12-17 02:28:15,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:15,818][root][INFO] - Training Epoch: 2/2, step 1342/7134 completed (loss: 0.11772710084915161, acc: 0.9602649211883545)
[2024-12-17 02:28:15,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:16,105][root][INFO] - Training Epoch: 2/2, step 1343/7134 completed (loss: 0.37383416295051575, acc: 0.9117646813392639)
[2024-12-17 02:28:16,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:16,378][root][INFO] - Training Epoch: 2/2, step 1344/7134 completed (loss: 0.17123354971408844, acc: 0.9541284441947937)
[2024-12-17 02:28:16,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:16,654][root][INFO] - Training Epoch: 2/2, step 1345/7134 completed (loss: 0.19941231608390808, acc: 0.9354838728904724)
[2024-12-17 02:28:16,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:16,963][root][INFO] - Training Epoch: 2/2, step 1346/7134 completed (loss: 0.14619535207748413, acc: 0.9781420826911926)
[2024-12-17 02:28:17,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:17,277][root][INFO] - Training Epoch: 2/2, step 1347/7134 completed (loss: 0.18101340532302856, acc: 0.9652777910232544)
[2024-12-17 02:28:17,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:17,553][root][INFO] - Training Epoch: 2/2, step 1348/7134 completed (loss: 0.09136907011270523, acc: 0.9779005646705627)
[2024-12-17 02:28:17,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:17,821][root][INFO] - Training Epoch: 2/2, step 1349/7134 completed (loss: 0.12051010131835938, acc: 0.978723406791687)
[2024-12-17 02:28:17,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:18,084][root][INFO] - Training Epoch: 2/2, step 1350/7134 completed (loss: 0.07023904472589493, acc: 0.9820359349250793)
[2024-12-17 02:28:18,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:18,341][root][INFO] - Training Epoch: 2/2, step 1351/7134 completed (loss: 0.04922129213809967, acc: 0.9916666746139526)
[2024-12-17 02:28:18,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:18,623][root][INFO] - Training Epoch: 2/2, step 1352/7134 completed (loss: 0.13648703694343567, acc: 0.9756097793579102)
[2024-12-17 02:28:18,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:18,895][root][INFO] - Training Epoch: 2/2, step 1353/7134 completed (loss: 0.09386606514453888, acc: 0.9916666746139526)
[2024-12-17 02:28:19,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:19,188][root][INFO] - Training Epoch: 2/2, step 1354/7134 completed (loss: 0.06255011260509491, acc: 0.9866666793823242)
[2024-12-17 02:28:19,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:19,446][root][INFO] - Training Epoch: 2/2, step 1355/7134 completed (loss: 0.022733498364686966, acc: 1.0)
[2024-12-17 02:28:19,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:19,732][root][INFO] - Training Epoch: 2/2, step 1356/7134 completed (loss: 0.08681240677833557, acc: 0.9651162624359131)
[2024-12-17 02:28:19,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:20,018][root][INFO] - Training Epoch: 2/2, step 1357/7134 completed (loss: 0.07163118571043015, acc: 0.9788359999656677)
[2024-12-17 02:28:20,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:20,303][root][INFO] - Training Epoch: 2/2, step 1358/7134 completed (loss: 0.1268773227930069, acc: 0.9602272510528564)
[2024-12-17 02:28:20,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:20,580][root][INFO] - Training Epoch: 2/2, step 1359/7134 completed (loss: 0.04643399640917778, acc: 1.0)
[2024-12-17 02:28:20,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:20,874][root][INFO] - Training Epoch: 2/2, step 1360/7134 completed (loss: 0.05236900970339775, acc: 0.9940476417541504)
[2024-12-17 02:28:21,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:21,180][root][INFO] - Training Epoch: 2/2, step 1361/7134 completed (loss: 0.10106206685304642, acc: 0.9822485446929932)
[2024-12-17 02:28:21,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:21,462][root][INFO] - Training Epoch: 2/2, step 1362/7134 completed (loss: 0.14427322149276733, acc: 0.9617486596107483)
[2024-12-17 02:28:21,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:21,750][root][INFO] - Training Epoch: 2/2, step 1363/7134 completed (loss: 0.1418152004480362, acc: 0.9712643623352051)
[2024-12-17 02:28:21,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:22,044][root][INFO] - Training Epoch: 2/2, step 1364/7134 completed (loss: 0.05565299466252327, acc: 0.9764705896377563)
[2024-12-17 02:28:22,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:22,318][root][INFO] - Training Epoch: 2/2, step 1365/7134 completed (loss: 0.04962553456425667, acc: 0.9851852059364319)
[2024-12-17 02:28:22,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:22,601][root][INFO] - Training Epoch: 2/2, step 1366/7134 completed (loss: 0.038484327495098114, acc: 1.0)
[2024-12-17 02:28:22,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:22,881][root][INFO] - Training Epoch: 2/2, step 1367/7134 completed (loss: 0.07888475060462952, acc: 0.9779411554336548)
[2024-12-17 02:28:23,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:23,188][root][INFO] - Training Epoch: 2/2, step 1368/7134 completed (loss: 0.1764598786830902, acc: 0.9367815852165222)
[2024-12-17 02:28:23,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:23,477][root][INFO] - Training Epoch: 2/2, step 1369/7134 completed (loss: 0.23530668020248413, acc: 0.9416058659553528)
[2024-12-17 02:28:23,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:23,759][root][INFO] - Training Epoch: 2/2, step 1370/7134 completed (loss: 0.24772760272026062, acc: 0.9438775777816772)
[2024-12-17 02:28:23,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:24,062][root][INFO] - Training Epoch: 2/2, step 1371/7134 completed (loss: 0.15665365755558014, acc: 0.9506173133850098)
[2024-12-17 02:28:24,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:24,370][root][INFO] - Training Epoch: 2/2, step 1372/7134 completed (loss: 0.20984745025634766, acc: 0.939393937587738)
[2024-12-17 02:28:24,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:24,656][root][INFO] - Training Epoch: 2/2, step 1373/7134 completed (loss: 0.1386803686618805, acc: 0.9457364082336426)
[2024-12-17 02:28:24,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:24,964][root][INFO] - Training Epoch: 2/2, step 1374/7134 completed (loss: 0.21564175188541412, acc: 0.9333333373069763)
[2024-12-17 02:28:25,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:25,238][root][INFO] - Training Epoch: 2/2, step 1375/7134 completed (loss: 0.15940546989440918, acc: 0.970588207244873)
[2024-12-17 02:28:25,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:25,515][root][INFO] - Training Epoch: 2/2, step 1376/7134 completed (loss: 0.3495619595050812, acc: 0.9285714030265808)
[2024-12-17 02:28:25,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:25,803][root][INFO] - Training Epoch: 2/2, step 1377/7134 completed (loss: 0.3676401674747467, acc: 0.9019607901573181)
[2024-12-17 02:28:25,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:26,061][root][INFO] - Training Epoch: 2/2, step 1378/7134 completed (loss: 0.3600025475025177, acc: 0.932692289352417)
[2024-12-17 02:28:26,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:26,325][root][INFO] - Training Epoch: 2/2, step 1379/7134 completed (loss: 0.37586814165115356, acc: 0.9108911156654358)
[2024-12-17 02:28:26,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:26,629][root][INFO] - Training Epoch: 2/2, step 1380/7134 completed (loss: 0.3002690076828003, acc: 0.9259259104728699)
[2024-12-17 02:28:26,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:26,928][root][INFO] - Training Epoch: 2/2, step 1381/7134 completed (loss: 0.08258606493473053, acc: 0.9855072498321533)
[2024-12-17 02:28:27,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:27,199][root][INFO] - Training Epoch: 2/2, step 1382/7134 completed (loss: 0.169563889503479, acc: 0.9461538195610046)
[2024-12-17 02:28:27,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:27,490][root][INFO] - Training Epoch: 2/2, step 1383/7134 completed (loss: 0.2754018008708954, acc: 0.9338235259056091)
[2024-12-17 02:28:27,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:27,773][root][INFO] - Training Epoch: 2/2, step 1384/7134 completed (loss: 0.4106689989566803, acc: 0.8865247964859009)
[2024-12-17 02:28:27,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:28,047][root][INFO] - Training Epoch: 2/2, step 1385/7134 completed (loss: 0.452664315700531, acc: 0.8960000276565552)
[2024-12-17 02:28:28,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:28,354][root][INFO] - Training Epoch: 2/2, step 1386/7134 completed (loss: 0.2776327133178711, acc: 0.922535240650177)
[2024-12-17 02:28:28,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:28,638][root][INFO] - Training Epoch: 2/2, step 1387/7134 completed (loss: 0.125563845038414, acc: 0.9790209531784058)
[2024-12-17 02:28:28,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:28,913][root][INFO] - Training Epoch: 2/2, step 1388/7134 completed (loss: 0.2771691083908081, acc: 0.9279999732971191)
[2024-12-17 02:28:29,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:29,194][root][INFO] - Training Epoch: 2/2, step 1389/7134 completed (loss: 0.2686525285243988, acc: 0.9402984976768494)
[2024-12-17 02:28:29,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:29,476][root][INFO] - Training Epoch: 2/2, step 1390/7134 completed (loss: 0.1857394129037857, acc: 0.9489051103591919)
[2024-12-17 02:28:29,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:29,791][root][INFO] - Training Epoch: 2/2, step 1391/7134 completed (loss: 0.41086018085479736, acc: 0.875)
[2024-12-17 02:28:29,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:30,104][root][INFO] - Training Epoch: 2/2, step 1392/7134 completed (loss: 0.33546993136405945, acc: 0.934959352016449)
[2024-12-17 02:28:30,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:30,384][root][INFO] - Training Epoch: 2/2, step 1393/7134 completed (loss: 0.33529233932495117, acc: 0.8645833134651184)
[2024-12-17 02:28:30,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:30,653][root][INFO] - Training Epoch: 2/2, step 1394/7134 completed (loss: 0.22085890173912048, acc: 0.9339622855186462)
[2024-12-17 02:28:30,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:30,924][root][INFO] - Training Epoch: 2/2, step 1395/7134 completed (loss: 0.26768434047698975, acc: 0.9453125)
[2024-12-17 02:28:31,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:31,202][root][INFO] - Training Epoch: 2/2, step 1396/7134 completed (loss: 0.09925089031457901, acc: 0.9919999837875366)
[2024-12-17 02:28:31,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:31,490][root][INFO] - Training Epoch: 2/2, step 1397/7134 completed (loss: 0.4073159098625183, acc: 0.8986486196517944)
[2024-12-17 02:28:31,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:31,752][root][INFO] - Training Epoch: 2/2, step 1398/7134 completed (loss: 0.1623726338148117, acc: 0.9306930899620056)
[2024-12-17 02:28:31,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:32,039][root][INFO] - Training Epoch: 2/2, step 1399/7134 completed (loss: 0.2815389931201935, acc: 0.9280575513839722)
[2024-12-17 02:28:32,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:32,325][root][INFO] - Training Epoch: 2/2, step 1400/7134 completed (loss: 0.13484375178813934, acc: 0.9855072498321533)
[2024-12-17 02:28:32,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:32,614][root][INFO] - Training Epoch: 2/2, step 1401/7134 completed (loss: 0.14819476008415222, acc: 0.9629629850387573)
[2024-12-17 02:28:32,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:32,880][root][INFO] - Training Epoch: 2/2, step 1402/7134 completed (loss: 0.11651858687400818, acc: 0.9626865386962891)
[2024-12-17 02:28:32,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:33,164][root][INFO] - Training Epoch: 2/2, step 1403/7134 completed (loss: 0.16543053090572357, acc: 0.9644970297813416)
[2024-12-17 02:28:33,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:33,446][root][INFO] - Training Epoch: 2/2, step 1404/7134 completed (loss: 0.10257573425769806, acc: 0.976190447807312)
[2024-12-17 02:28:33,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:33,717][root][INFO] - Training Epoch: 2/2, step 1405/7134 completed (loss: 0.11717484146356583, acc: 0.976190447807312)
[2024-12-17 02:28:33,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:34,016][root][INFO] - Training Epoch: 2/2, step 1406/7134 completed (loss: 0.050105780363082886, acc: 0.9813664555549622)
[2024-12-17 02:28:34,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:34,290][root][INFO] - Training Epoch: 2/2, step 1407/7134 completed (loss: 0.08979590982198715, acc: 0.9825581312179565)
[2024-12-17 02:28:34,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:34,586][root][INFO] - Training Epoch: 2/2, step 1408/7134 completed (loss: 0.09253297001123428, acc: 0.9862068891525269)
[2024-12-17 02:28:34,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:34,876][root][INFO] - Training Epoch: 2/2, step 1409/7134 completed (loss: 0.058032114058732986, acc: 0.9811320900917053)
[2024-12-17 02:28:35,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:35,176][root][INFO] - Training Epoch: 2/2, step 1410/7134 completed (loss: 0.12286807596683502, acc: 0.9834254384040833)
[2024-12-17 02:28:35,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:35,463][root][INFO] - Training Epoch: 2/2, step 1411/7134 completed (loss: 0.10011091083288193, acc: 0.977142870426178)
[2024-12-17 02:28:35,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:35,741][root][INFO] - Training Epoch: 2/2, step 1412/7134 completed (loss: 0.13107165694236755, acc: 0.9684210419654846)
[2024-12-17 02:28:35,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:36,017][root][INFO] - Training Epoch: 2/2, step 1413/7134 completed (loss: 0.11748689413070679, acc: 0.9640718698501587)
[2024-12-17 02:28:36,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:36,287][root][INFO] - Training Epoch: 2/2, step 1414/7134 completed (loss: 0.04386238381266594, acc: 0.9933775067329407)
[2024-12-17 02:28:36,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:36,686][root][INFO] - Training Epoch: 2/2, step 1415/7134 completed (loss: 0.14805950224399567, acc: 0.9635036587715149)
[2024-12-17 02:28:36,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:36,983][root][INFO] - Training Epoch: 2/2, step 1416/7134 completed (loss: 0.043977897614240646, acc: 0.9887005686759949)
[2024-12-17 02:28:37,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:37,263][root][INFO] - Training Epoch: 2/2, step 1417/7134 completed (loss: 0.08734474331140518, acc: 0.9861111044883728)
[2024-12-17 02:28:37,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:37,537][root][INFO] - Training Epoch: 2/2, step 1418/7134 completed (loss: 0.08074899762868881, acc: 0.9844961166381836)
[2024-12-17 02:28:37,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:37,826][root][INFO] - Training Epoch: 2/2, step 1419/7134 completed (loss: 0.13182653486728668, acc: 0.9715909361839294)
[2024-12-17 02:28:37,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:38,144][root][INFO] - Training Epoch: 2/2, step 1420/7134 completed (loss: 0.20142677426338196, acc: 0.9526315927505493)
[2024-12-17 02:28:38,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:38,436][root][INFO] - Training Epoch: 2/2, step 1421/7134 completed (loss: 0.07307307422161102, acc: 0.9798657894134521)
[2024-12-17 02:28:38,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:38,699][root][INFO] - Training Epoch: 2/2, step 1422/7134 completed (loss: 0.2063417136669159, acc: 0.9397590160369873)
[2024-12-17 02:28:38,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:39,034][root][INFO] - Training Epoch: 2/2, step 1423/7134 completed (loss: 0.4668318033218384, acc: 0.8625954389572144)
[2024-12-17 02:28:39,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:39,408][root][INFO] - Training Epoch: 2/2, step 1424/7134 completed (loss: 0.337400883436203, acc: 0.8943089246749878)
[2024-12-17 02:28:39,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:39,725][root][INFO] - Training Epoch: 2/2, step 1425/7134 completed (loss: 0.2337792068719864, acc: 0.9306358098983765)
[2024-12-17 02:28:39,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:40,018][root][INFO] - Training Epoch: 2/2, step 1426/7134 completed (loss: 0.1597774177789688, acc: 0.969072163105011)
[2024-12-17 02:28:40,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:40,307][root][INFO] - Training Epoch: 2/2, step 1427/7134 completed (loss: 0.3311965763568878, acc: 0.9152542352676392)
[2024-12-17 02:28:40,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:40,578][root][INFO] - Training Epoch: 2/2, step 1428/7134 completed (loss: 0.8210578560829163, acc: 0.7903226017951965)
[2024-12-17 02:28:40,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:40,885][root][INFO] - Training Epoch: 2/2, step 1429/7134 completed (loss: 0.25927701592445374, acc: 0.9444444179534912)
[2024-12-17 02:28:41,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:41,179][root][INFO] - Training Epoch: 2/2, step 1430/7134 completed (loss: 0.17288564145565033, acc: 0.9424460530281067)
[2024-12-17 02:28:41,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:41,470][root][INFO] - Training Epoch: 2/2, step 1431/7134 completed (loss: 0.11844608187675476, acc: 0.9623655676841736)
[2024-12-17 02:28:41,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:41,758][root][INFO] - Training Epoch: 2/2, step 1432/7134 completed (loss: 0.22730493545532227, acc: 0.9447236061096191)
[2024-12-17 02:28:41,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:42,056][root][INFO] - Training Epoch: 2/2, step 1433/7134 completed (loss: 0.248499795794487, acc: 0.9215686321258545)
[2024-12-17 02:28:42,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:42,333][root][INFO] - Training Epoch: 2/2, step 1434/7134 completed (loss: 0.2204931080341339, acc: 0.9104477763175964)
[2024-12-17 02:28:42,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:42,625][root][INFO] - Training Epoch: 2/2, step 1435/7134 completed (loss: 0.2529337406158447, acc: 0.9301075339317322)
[2024-12-17 02:28:42,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:42,916][root][INFO] - Training Epoch: 2/2, step 1436/7134 completed (loss: 0.24769914150238037, acc: 0.9351851940155029)
[2024-12-17 02:28:43,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:43,184][root][INFO] - Training Epoch: 2/2, step 1437/7134 completed (loss: 0.22415195405483246, acc: 0.9516128897666931)
[2024-12-17 02:28:43,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:43,468][root][INFO] - Training Epoch: 2/2, step 1438/7134 completed (loss: 0.1986967772245407, acc: 0.9636363387107849)
[2024-12-17 02:28:43,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:43,747][root][INFO] - Training Epoch: 2/2, step 1439/7134 completed (loss: 0.14177203178405762, acc: 0.9629629850387573)
[2024-12-17 02:28:43,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:44,016][root][INFO] - Training Epoch: 2/2, step 1440/7134 completed (loss: 0.2352176457643509, acc: 0.9440993666648865)
[2024-12-17 02:28:44,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:44,298][root][INFO] - Training Epoch: 2/2, step 1441/7134 completed (loss: 0.1131955161690712, acc: 0.982758641242981)
[2024-12-17 02:28:44,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:44,546][root][INFO] - Training Epoch: 2/2, step 1442/7134 completed (loss: 0.06112948805093765, acc: 0.9910714030265808)
[2024-12-17 02:28:44,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:44,835][root][INFO] - Training Epoch: 2/2, step 1443/7134 completed (loss: 0.31984344124794006, acc: 0.9382715821266174)
[2024-12-17 02:28:44,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:45,114][root][INFO] - Training Epoch: 2/2, step 1444/7134 completed (loss: 0.20730869472026825, acc: 0.9583333134651184)
[2024-12-17 02:28:45,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:45,396][root][INFO] - Training Epoch: 2/2, step 1445/7134 completed (loss: 0.17579765617847443, acc: 0.9554139971733093)
[2024-12-17 02:28:45,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:45,670][root][INFO] - Training Epoch: 2/2, step 1446/7134 completed (loss: 0.17795917391777039, acc: 0.9696969985961914)
[2024-12-17 02:28:45,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:45,948][root][INFO] - Training Epoch: 2/2, step 1447/7134 completed (loss: 0.14877130091190338, acc: 0.9677419066429138)
[2024-12-17 02:28:46,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:46,227][root][INFO] - Training Epoch: 2/2, step 1448/7134 completed (loss: 0.3804476261138916, acc: 0.9029850959777832)
[2024-12-17 02:28:46,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:46,522][root][INFO] - Training Epoch: 2/2, step 1449/7134 completed (loss: 0.32141831517219543, acc: 0.9289617538452148)
[2024-12-17 02:28:46,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:46,783][root][INFO] - Training Epoch: 2/2, step 1450/7134 completed (loss: 0.22574597597122192, acc: 0.9304812550544739)
[2024-12-17 02:28:46,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:47,050][root][INFO] - Training Epoch: 2/2, step 1451/7134 completed (loss: 0.19921213388442993, acc: 0.9424083828926086)
[2024-12-17 02:28:47,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:47,333][root][INFO] - Training Epoch: 2/2, step 1452/7134 completed (loss: 0.1692509651184082, acc: 0.9583333134651184)
[2024-12-17 02:28:47,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:47,597][root][INFO] - Training Epoch: 2/2, step 1453/7134 completed (loss: 0.5324544906616211, acc: 0.8779069781303406)
[2024-12-17 02:28:47,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:47,884][root][INFO] - Training Epoch: 2/2, step 1454/7134 completed (loss: 0.2617699205875397, acc: 0.9427083134651184)
[2024-12-17 02:28:47,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:48,153][root][INFO] - Training Epoch: 2/2, step 1455/7134 completed (loss: 0.4829951226711273, acc: 0.8965517282485962)
[2024-12-17 02:28:48,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:48,414][root][INFO] - Training Epoch: 2/2, step 1456/7134 completed (loss: 0.2563724219799042, acc: 0.942148745059967)
[2024-12-17 02:28:48,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:48,677][root][INFO] - Training Epoch: 2/2, step 1457/7134 completed (loss: 0.14095136523246765, acc: 0.9689440727233887)
[2024-12-17 02:28:48,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:48,947][root][INFO] - Training Epoch: 2/2, step 1458/7134 completed (loss: 0.11423774808645248, acc: 0.976331353187561)
[2024-12-17 02:28:49,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:49,219][root][INFO] - Training Epoch: 2/2, step 1459/7134 completed (loss: 0.10036393254995346, acc: 0.9777777791023254)
[2024-12-17 02:28:49,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:49,507][root][INFO] - Training Epoch: 2/2, step 1460/7134 completed (loss: 0.3116905987262726, acc: 0.9289940595626831)
[2024-12-17 02:28:49,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:49,769][root][INFO] - Training Epoch: 2/2, step 1461/7134 completed (loss: 0.2938639223575592, acc: 0.9072847962379456)
[2024-12-17 02:28:49,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:50,049][root][INFO] - Training Epoch: 2/2, step 1462/7134 completed (loss: 0.24743349850177765, acc: 0.9402984976768494)
[2024-12-17 02:28:50,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:50,330][root][INFO] - Training Epoch: 2/2, step 1463/7134 completed (loss: 0.2884913980960846, acc: 0.9019607901573181)
[2024-12-17 02:28:50,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:50,610][root][INFO] - Training Epoch: 2/2, step 1464/7134 completed (loss: 0.4087093770503998, acc: 0.9036144614219666)
[2024-12-17 02:28:50,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:50,894][root][INFO] - Training Epoch: 2/2, step 1465/7134 completed (loss: 0.25761905312538147, acc: 0.9551281929016113)
[2024-12-17 02:28:51,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:51,185][root][INFO] - Training Epoch: 2/2, step 1466/7134 completed (loss: 0.08507978171110153, acc: 0.9776536226272583)
[2024-12-17 02:28:51,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:51,464][root][INFO] - Training Epoch: 2/2, step 1467/7134 completed (loss: 0.06989657133817673, acc: 0.9878787994384766)
[2024-12-17 02:28:51,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:51,764][root][INFO] - Training Epoch: 2/2, step 1468/7134 completed (loss: 0.1201092079281807, acc: 0.966292142868042)
[2024-12-17 02:28:51,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:52,052][root][INFO] - Training Epoch: 2/2, step 1469/7134 completed (loss: 0.08968457579612732, acc: 0.9715909361839294)
[2024-12-17 02:28:52,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:52,350][root][INFO] - Training Epoch: 2/2, step 1470/7134 completed (loss: 0.22321820259094238, acc: 0.9171974658966064)
[2024-12-17 02:28:52,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:52,627][root][INFO] - Training Epoch: 2/2, step 1471/7134 completed (loss: 0.3668444752693176, acc: 0.9307692050933838)
[2024-12-17 02:28:52,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:52,907][root][INFO] - Training Epoch: 2/2, step 1472/7134 completed (loss: 0.09087833017110825, acc: 0.9824561476707458)
[2024-12-17 02:28:53,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:53,185][root][INFO] - Training Epoch: 2/2, step 1473/7134 completed (loss: 0.19057399034500122, acc: 0.9333333373069763)
[2024-12-17 02:28:53,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:53,452][root][INFO] - Training Epoch: 2/2, step 1474/7134 completed (loss: 0.2355191707611084, acc: 0.9241379499435425)
[2024-12-17 02:28:53,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:53,725][root][INFO] - Training Epoch: 2/2, step 1475/7134 completed (loss: 0.3469061851501465, acc: 0.939393937587738)
[2024-12-17 02:28:53,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:54,012][root][INFO] - Training Epoch: 2/2, step 1476/7134 completed (loss: 0.22581399977207184, acc: 0.9399999976158142)
[2024-12-17 02:28:54,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:54,271][root][INFO] - Training Epoch: 2/2, step 1477/7134 completed (loss: 0.1719653308391571, acc: 0.9655172228813171)
[2024-12-17 02:28:54,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:54,561][root][INFO] - Training Epoch: 2/2, step 1478/7134 completed (loss: 0.14206746220588684, acc: 0.9868420958518982)
[2024-12-17 02:28:54,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:54,857][root][INFO] - Training Epoch: 2/2, step 1479/7134 completed (loss: 0.06339246779680252, acc: 0.9885057210922241)
[2024-12-17 02:28:54,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:55,140][root][INFO] - Training Epoch: 2/2, step 1480/7134 completed (loss: 0.053557321429252625, acc: 0.988950252532959)
[2024-12-17 02:28:55,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:55,447][root][INFO] - Training Epoch: 2/2, step 1481/7134 completed (loss: 0.14182791113853455, acc: 0.9833333492279053)
[2024-12-17 02:28:55,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:55,747][root][INFO] - Training Epoch: 2/2, step 1482/7134 completed (loss: 0.22318652272224426, acc: 0.9408283829689026)
[2024-12-17 02:28:55,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:56,031][root][INFO] - Training Epoch: 2/2, step 1483/7134 completed (loss: 0.051925670355558395, acc: 0.9923664331436157)
[2024-12-17 02:28:56,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:56,337][root][INFO] - Training Epoch: 2/2, step 1484/7134 completed (loss: 0.25285735726356506, acc: 0.9397590160369873)
[2024-12-17 02:28:56,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:56,630][root][INFO] - Training Epoch: 2/2, step 1485/7134 completed (loss: 0.12948405742645264, acc: 0.9766082167625427)
[2024-12-17 02:28:56,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:56,915][root][INFO] - Training Epoch: 2/2, step 1486/7134 completed (loss: 0.10110119730234146, acc: 0.9748427867889404)
[2024-12-17 02:28:57,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:57,206][root][INFO] - Training Epoch: 2/2, step 1487/7134 completed (loss: 0.14146889746189117, acc: 0.9621621370315552)
[2024-12-17 02:28:57,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:57,496][root][INFO] - Training Epoch: 2/2, step 1488/7134 completed (loss: 0.1423361450433731, acc: 0.9534883499145508)
[2024-12-17 02:28:57,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:57,766][root][INFO] - Training Epoch: 2/2, step 1489/7134 completed (loss: 0.24854692816734314, acc: 0.9387755393981934)
[2024-12-17 02:28:57,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:58,053][root][INFO] - Training Epoch: 2/2, step 1490/7134 completed (loss: 0.16925303637981415, acc: 0.9513274431228638)
[2024-12-17 02:28:58,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:58,329][root][INFO] - Training Epoch: 2/2, step 1491/7134 completed (loss: 0.13492844998836517, acc: 0.961904764175415)
[2024-12-17 02:28:58,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:58,608][root][INFO] - Training Epoch: 2/2, step 1492/7134 completed (loss: 0.1493086963891983, acc: 0.9620853066444397)
[2024-12-17 02:28:58,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:58,884][root][INFO] - Training Epoch: 2/2, step 1493/7134 completed (loss: 0.13012877106666565, acc: 0.9719626307487488)
[2024-12-17 02:28:58,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:59,168][root][INFO] - Training Epoch: 2/2, step 1494/7134 completed (loss: 0.11545152962207794, acc: 0.9585492014884949)
[2024-12-17 02:28:59,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:59,449][root][INFO] - Training Epoch: 2/2, step 1495/7134 completed (loss: 0.1104113757610321, acc: 0.9707317352294922)
[2024-12-17 02:28:59,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:59,727][root][INFO] - Training Epoch: 2/2, step 1496/7134 completed (loss: 0.09074550867080688, acc: 0.981249988079071)
[2024-12-17 02:28:59,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:59,998][root][INFO] - Training Epoch: 2/2, step 1497/7134 completed (loss: 0.07071477174758911, acc: 0.9814814925193787)
[2024-12-17 02:29:00,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:00,252][root][INFO] - Training Epoch: 2/2, step 1498/7134 completed (loss: 0.17745397984981537, acc: 0.9513513445854187)
[2024-12-17 02:29:00,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:00,546][root][INFO] - Training Epoch: 2/2, step 1499/7134 completed (loss: 0.12723788619041443, acc: 0.9674418568611145)
[2024-12-17 02:29:00,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:00,780][root][INFO] - Training Epoch: 2/2, step 1500/7134 completed (loss: 0.24413231015205383, acc: 0.9178082346916199)
[2024-12-17 02:29:00,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:01,071][root][INFO] - Training Epoch: 2/2, step 1501/7134 completed (loss: 0.26963335275650024, acc: 0.9349112510681152)
[2024-12-17 02:29:01,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:01,350][root][INFO] - Training Epoch: 2/2, step 1502/7134 completed (loss: 0.15165096521377563, acc: 0.9545454382896423)
[2024-12-17 02:29:01,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:01,611][root][INFO] - Training Epoch: 2/2, step 1503/7134 completed (loss: 0.2472837120294571, acc: 0.9257143139839172)
[2024-12-17 02:29:01,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:01,878][root][INFO] - Training Epoch: 2/2, step 1504/7134 completed (loss: 0.09932038933038712, acc: 0.9841269850730896)
[2024-12-17 02:29:01,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:02,150][root][INFO] - Training Epoch: 2/2, step 1505/7134 completed (loss: 0.16427019238471985, acc: 0.9620253443717957)
[2024-12-17 02:29:02,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:02,423][root][INFO] - Training Epoch: 2/2, step 1506/7134 completed (loss: 0.27941179275512695, acc: 0.9245283007621765)
[2024-12-17 02:29:02,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:02,691][root][INFO] - Training Epoch: 2/2, step 1507/7134 completed (loss: 0.22154021263122559, acc: 0.9375)
[2024-12-17 02:29:02,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:02,970][root][INFO] - Training Epoch: 2/2, step 1508/7134 completed (loss: 0.09968046098947525, acc: 0.9719626307487488)
[2024-12-17 02:29:03,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:03,244][root][INFO] - Training Epoch: 2/2, step 1509/7134 completed (loss: 0.14588116109371185, acc: 0.9555555582046509)
[2024-12-17 02:29:03,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:03,528][root][INFO] - Training Epoch: 2/2, step 1510/7134 completed (loss: 0.28830021619796753, acc: 0.9225806593894958)
[2024-12-17 02:29:03,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:03,800][root][INFO] - Training Epoch: 2/2, step 1511/7134 completed (loss: 0.23394238948822021, acc: 0.9273743033409119)
[2024-12-17 02:29:03,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:04,080][root][INFO] - Training Epoch: 2/2, step 1512/7134 completed (loss: 0.09164047986268997, acc: 0.9866666793823242)
[2024-12-17 02:29:04,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:04,353][root][INFO] - Training Epoch: 2/2, step 1513/7134 completed (loss: 0.09059549868106842, acc: 0.9834254384040833)
[2024-12-17 02:29:04,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:04,625][root][INFO] - Training Epoch: 2/2, step 1514/7134 completed (loss: 0.19614483416080475, acc: 0.9430052042007446)
[2024-12-17 02:29:04,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:04,905][root][INFO] - Training Epoch: 2/2, step 1515/7134 completed (loss: 0.19400064647197723, acc: 0.9369369149208069)
[2024-12-17 02:29:04,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:05,132][root][INFO] - Training Epoch: 2/2, step 1516/7134 completed (loss: 0.21663852035999298, acc: 0.9624999761581421)
[2024-12-17 02:29:05,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:05,403][root][INFO] - Training Epoch: 2/2, step 1517/7134 completed (loss: 0.37860968708992004, acc: 0.9375)
[2024-12-17 02:29:05,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:05,675][root][INFO] - Training Epoch: 2/2, step 1518/7134 completed (loss: 0.15639106929302216, acc: 0.969072163105011)
[2024-12-17 02:29:05,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:05,956][root][INFO] - Training Epoch: 2/2, step 1519/7134 completed (loss: 0.14572973549365997, acc: 0.9611650705337524)
[2024-12-17 02:29:06,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:06,230][root][INFO] - Training Epoch: 2/2, step 1520/7134 completed (loss: 0.10017158091068268, acc: 0.9781022071838379)
[2024-12-17 02:29:06,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:06,515][root][INFO] - Training Epoch: 2/2, step 1521/7134 completed (loss: 0.7791955471038818, acc: 0.8014705777168274)
[2024-12-17 02:29:06,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:06,776][root][INFO] - Training Epoch: 2/2, step 1522/7134 completed (loss: 0.4447958767414093, acc: 0.8571428656578064)
[2024-12-17 02:29:06,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:07,042][root][INFO] - Training Epoch: 2/2, step 1523/7134 completed (loss: 0.6855397820472717, acc: 0.8552631735801697)
[2024-12-17 02:29:07,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:07,283][root][INFO] - Training Epoch: 2/2, step 1524/7134 completed (loss: 0.23768126964569092, acc: 0.9452054500579834)
[2024-12-17 02:29:07,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:07,556][root][INFO] - Training Epoch: 2/2, step 1525/7134 completed (loss: 0.3591887652873993, acc: 0.9399999976158142)
[2024-12-17 02:29:07,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:07,859][root][INFO] - Training Epoch: 2/2, step 1526/7134 completed (loss: 0.571328341960907, acc: 0.8571428656578064)
[2024-12-17 02:29:07,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:08,149][root][INFO] - Training Epoch: 2/2, step 1527/7134 completed (loss: 0.9484111666679382, acc: 0.8141592741012573)
[2024-12-17 02:29:08,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:08,444][root][INFO] - Training Epoch: 2/2, step 1528/7134 completed (loss: 0.44290632009506226, acc: 0.8985507488250732)
[2024-12-17 02:29:08,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:08,716][root][INFO] - Training Epoch: 2/2, step 1529/7134 completed (loss: 0.20330040156841278, acc: 0.957446813583374)
[2024-12-17 02:29:08,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:09,014][root][INFO] - Training Epoch: 2/2, step 1530/7134 completed (loss: 0.38883477449417114, acc: 0.8928571343421936)
[2024-12-17 02:29:09,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:09,289][root][INFO] - Training Epoch: 2/2, step 1531/7134 completed (loss: 0.821811318397522, acc: 0.8030303120613098)
[2024-12-17 02:29:09,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:09,583][root][INFO] - Training Epoch: 2/2, step 1532/7134 completed (loss: 0.20080552995204926, acc: 0.9435897469520569)
[2024-12-17 02:29:09,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:09,850][root][INFO] - Training Epoch: 2/2, step 1533/7134 completed (loss: 0.2945577800273895, acc: 0.9216867685317993)
[2024-12-17 02:29:09,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:10,126][root][INFO] - Training Epoch: 2/2, step 1534/7134 completed (loss: 0.3471694588661194, acc: 0.9208633303642273)
[2024-12-17 02:29:10,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:10,425][root][INFO] - Training Epoch: 2/2, step 1535/7134 completed (loss: 0.1518234759569168, acc: 0.9599999785423279)
[2024-12-17 02:29:10,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:10,721][root][INFO] - Training Epoch: 2/2, step 1536/7134 completed (loss: 0.171514093875885, acc: 0.9629629850387573)
[2024-12-17 02:29:10,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:11,004][root][INFO] - Training Epoch: 2/2, step 1537/7134 completed (loss: 0.24133147299289703, acc: 0.9415204524993896)
[2024-12-17 02:29:11,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:11,289][root][INFO] - Training Epoch: 2/2, step 1538/7134 completed (loss: 0.4159902036190033, acc: 0.9285714030265808)
[2024-12-17 02:29:11,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:11,567][root][INFO] - Training Epoch: 2/2, step 1539/7134 completed (loss: 0.20266760885715485, acc: 0.9333333373069763)
[2024-12-17 02:29:11,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:11,847][root][INFO] - Training Epoch: 2/2, step 1540/7134 completed (loss: 0.2662300765514374, acc: 0.9240506291389465)
[2024-12-17 02:29:11,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:12,119][root][INFO] - Training Epoch: 2/2, step 1541/7134 completed (loss: 0.2679968476295471, acc: 0.9526315927505493)
[2024-12-17 02:29:12,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:12,409][root][INFO] - Training Epoch: 2/2, step 1542/7134 completed (loss: 0.16316275298595428, acc: 0.966292142868042)
[2024-12-17 02:29:12,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:12,688][root][INFO] - Training Epoch: 2/2, step 1543/7134 completed (loss: 0.19722865521907806, acc: 0.9523809552192688)
[2024-12-17 02:29:12,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:12,975][root][INFO] - Training Epoch: 2/2, step 1544/7134 completed (loss: 0.1586974561214447, acc: 0.9700000286102295)
[2024-12-17 02:29:13,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:13,238][root][INFO] - Training Epoch: 2/2, step 1545/7134 completed (loss: 0.2302478551864624, acc: 0.9285714030265808)
[2024-12-17 02:29:13,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:13,532][root][INFO] - Training Epoch: 2/2, step 1546/7134 completed (loss: 0.5479321479797363, acc: 0.8823529481887817)
[2024-12-17 02:29:13,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:13,814][root][INFO] - Training Epoch: 2/2, step 1547/7134 completed (loss: 0.3585420846939087, acc: 0.9197530746459961)
[2024-12-17 02:29:13,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:14,099][root][INFO] - Training Epoch: 2/2, step 1548/7134 completed (loss: 0.18087591230869293, acc: 0.942105233669281)
[2024-12-17 02:29:14,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:14,379][root][INFO] - Training Epoch: 2/2, step 1549/7134 completed (loss: 0.0860503688454628, acc: 0.977142870426178)
[2024-12-17 02:29:14,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:14,665][root][INFO] - Training Epoch: 2/2, step 1550/7134 completed (loss: 0.18840225040912628, acc: 0.9352940917015076)
[2024-12-17 02:29:14,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:14,933][root][INFO] - Training Epoch: 2/2, step 1551/7134 completed (loss: 0.13267941772937775, acc: 0.9801324605941772)
[2024-12-17 02:29:15,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:15,220][root][INFO] - Training Epoch: 2/2, step 1552/7134 completed (loss: 0.1153917908668518, acc: 0.9795918464660645)
[2024-12-17 02:29:15,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:15,504][root][INFO] - Training Epoch: 2/2, step 1553/7134 completed (loss: 0.15132901072502136, acc: 0.9610389471054077)
[2024-12-17 02:29:15,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:15,810][root][INFO] - Training Epoch: 2/2, step 1554/7134 completed (loss: 0.18675497174263, acc: 0.9479768872261047)
[2024-12-17 02:29:15,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:16,083][root][INFO] - Training Epoch: 2/2, step 1555/7134 completed (loss: 0.16596348583698273, acc: 0.956250011920929)
[2024-12-17 02:29:16,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:16,361][root][INFO] - Training Epoch: 2/2, step 1556/7134 completed (loss: 0.2099243700504303, acc: 0.9435028433799744)
[2024-12-17 02:29:16,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:16,668][root][INFO] - Training Epoch: 2/2, step 1557/7134 completed (loss: 0.2050347924232483, acc: 0.9277777671813965)
[2024-12-17 02:29:16,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:16,947][root][INFO] - Training Epoch: 2/2, step 1558/7134 completed (loss: 0.22853198647499084, acc: 0.9383561611175537)
[2024-12-17 02:29:17,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:17,212][root][INFO] - Training Epoch: 2/2, step 1559/7134 completed (loss: 0.2788255214691162, acc: 0.9200000166893005)
[2024-12-17 02:29:17,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:17,479][root][INFO] - Training Epoch: 2/2, step 1560/7134 completed (loss: 0.17968976497650146, acc: 0.9492385983467102)
[2024-12-17 02:29:17,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:17,753][root][INFO] - Training Epoch: 2/2, step 1561/7134 completed (loss: 0.3573947250843048, acc: 0.9267241358757019)
[2024-12-17 02:29:17,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:18,017][root][INFO] - Training Epoch: 2/2, step 1562/7134 completed (loss: 0.20701932907104492, acc: 0.9467455744743347)
[2024-12-17 02:29:18,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:18,281][root][INFO] - Training Epoch: 2/2, step 1563/7134 completed (loss: 0.2370823323726654, acc: 0.9264705777168274)
[2024-12-17 02:29:18,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:18,552][root][INFO] - Training Epoch: 2/2, step 1564/7134 completed (loss: 0.35816261172294617, acc: 0.905940592288971)
[2024-12-17 02:29:18,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:18,812][root][INFO] - Training Epoch: 2/2, step 1565/7134 completed (loss: 0.24899356067180634, acc: 0.9496855139732361)
[2024-12-17 02:29:18,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:19,080][root][INFO] - Training Epoch: 2/2, step 1566/7134 completed (loss: 0.2666437029838562, acc: 0.9447513818740845)
[2024-12-17 02:29:19,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:19,378][root][INFO] - Training Epoch: 2/2, step 1567/7134 completed (loss: 0.4174143075942993, acc: 0.9170731902122498)
[2024-12-17 02:29:19,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:19,646][root][INFO] - Training Epoch: 2/2, step 1568/7134 completed (loss: 0.37840938568115234, acc: 0.9134615659713745)
[2024-12-17 02:29:19,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:19,917][root][INFO] - Training Epoch: 2/2, step 1569/7134 completed (loss: 0.24133014678955078, acc: 0.9212121367454529)
[2024-12-17 02:29:20,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:20,199][root][INFO] - Training Epoch: 2/2, step 1570/7134 completed (loss: 0.5760641694068909, acc: 0.8826290965080261)
[2024-12-17 02:29:20,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:20,468][root][INFO] - Training Epoch: 2/2, step 1571/7134 completed (loss: 0.3429790735244751, acc: 0.9447004795074463)
[2024-12-17 02:29:20,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:20,753][root][INFO] - Training Epoch: 2/2, step 1572/7134 completed (loss: 0.417873352766037, acc: 0.9154929518699646)
[2024-12-17 02:29:20,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:21,011][root][INFO] - Training Epoch: 2/2, step 1573/7134 completed (loss: 0.14327681064605713, acc: 0.970059871673584)
[2024-12-17 02:29:21,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:21,292][root][INFO] - Training Epoch: 2/2, step 1574/7134 completed (loss: 0.30972617864608765, acc: 0.9282511472702026)
[2024-12-17 02:29:21,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:21,567][root][INFO] - Training Epoch: 2/2, step 1575/7134 completed (loss: 0.24975842237472534, acc: 0.9409090876579285)
[2024-12-17 02:29:21,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:21,848][root][INFO] - Training Epoch: 2/2, step 1576/7134 completed (loss: 0.15931877493858337, acc: 0.9577465057373047)
[2024-12-17 02:29:21,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:22,125][root][INFO] - Training Epoch: 2/2, step 1577/7134 completed (loss: 0.20884792506694794, acc: 0.9323671460151672)
[2024-12-17 02:29:22,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:22,396][root][INFO] - Training Epoch: 2/2, step 1578/7134 completed (loss: 0.23983238637447357, acc: 0.9261363744735718)
[2024-12-17 02:29:22,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:22,685][root][INFO] - Training Epoch: 2/2, step 1579/7134 completed (loss: 0.1108928993344307, acc: 0.9711538553237915)
[2024-12-17 02:29:22,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:22,963][root][INFO] - Training Epoch: 2/2, step 1580/7134 completed (loss: 0.4178551137447357, acc: 0.8937197923660278)
[2024-12-17 02:29:23,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:23,186][root][INFO] - Training Epoch: 2/2, step 1581/7134 completed (loss: 0.4516089856624603, acc: 0.886904776096344)
[2024-12-17 02:29:23,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:23,459][root][INFO] - Training Epoch: 2/2, step 1582/7134 completed (loss: 0.465181827545166, acc: 0.8799999952316284)
[2024-12-17 02:29:23,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:23,733][root][INFO] - Training Epoch: 2/2, step 1583/7134 completed (loss: 0.21744783222675323, acc: 0.9200000166893005)
[2024-12-17 02:29:23,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:24,027][root][INFO] - Training Epoch: 2/2, step 1584/7134 completed (loss: 0.25238052010536194, acc: 0.9504504799842834)
[2024-12-17 02:29:24,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:24,297][root][INFO] - Training Epoch: 2/2, step 1585/7134 completed (loss: 0.16452917456626892, acc: 0.9514563083648682)
[2024-12-17 02:29:24,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:24,564][root][INFO] - Training Epoch: 2/2, step 1586/7134 completed (loss: 0.30372095108032227, acc: 0.9178743958473206)
[2024-12-17 02:29:24,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:24,839][root][INFO] - Training Epoch: 2/2, step 1587/7134 completed (loss: 0.20598872005939484, acc: 0.9617834687232971)
[2024-12-17 02:29:24,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:25,117][root][INFO] - Training Epoch: 2/2, step 1588/7134 completed (loss: 0.11932174116373062, acc: 0.9617834687232971)
[2024-12-17 02:29:25,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:25,390][root][INFO] - Training Epoch: 2/2, step 1589/7134 completed (loss: 0.13776680827140808, acc: 0.9756097793579102)
[2024-12-17 02:29:25,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:25,649][root][INFO] - Training Epoch: 2/2, step 1590/7134 completed (loss: 0.1315605342388153, acc: 0.9714285731315613)
[2024-12-17 02:29:25,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:25,915][root][INFO] - Training Epoch: 2/2, step 1591/7134 completed (loss: 0.15818488597869873, acc: 0.9767441749572754)
[2024-12-17 02:29:26,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:26,208][root][INFO] - Training Epoch: 2/2, step 1592/7134 completed (loss: 0.2153361439704895, acc: 0.9675324559211731)
[2024-12-17 02:29:26,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:26,503][root][INFO] - Training Epoch: 2/2, step 1593/7134 completed (loss: 0.14352737367153168, acc: 0.9625668525695801)
[2024-12-17 02:29:26,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:26,786][root][INFO] - Training Epoch: 2/2, step 1594/7134 completed (loss: 0.10684898495674133, acc: 0.96875)
[2024-12-17 02:29:26,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:27,074][root][INFO] - Training Epoch: 2/2, step 1595/7134 completed (loss: 0.10967579483985901, acc: 0.9663865566253662)
[2024-12-17 02:29:27,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:27,351][root][INFO] - Training Epoch: 2/2, step 1596/7134 completed (loss: 0.28003981709480286, acc: 0.9375)
[2024-12-17 02:29:27,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:27,626][root][INFO] - Training Epoch: 2/2, step 1597/7134 completed (loss: 0.15411561727523804, acc: 0.9602649211883545)
[2024-12-17 02:29:27,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:27,882][root][INFO] - Training Epoch: 2/2, step 1598/7134 completed (loss: 0.25072893500328064, acc: 0.949999988079071)
[2024-12-17 02:29:27,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:28,156][root][INFO] - Training Epoch: 2/2, step 1599/7134 completed (loss: 0.2709892690181732, acc: 0.9103448390960693)
[2024-12-17 02:29:28,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:28,427][root][INFO] - Training Epoch: 2/2, step 1600/7134 completed (loss: 0.28519025444984436, acc: 0.9387755393981934)
[2024-12-17 02:29:28,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:28,715][root][INFO] - Training Epoch: 2/2, step 1601/7134 completed (loss: 0.16544772684574127, acc: 0.9575757384300232)
[2024-12-17 02:29:28,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:29,005][root][INFO] - Training Epoch: 2/2, step 1602/7134 completed (loss: 0.15230366587638855, acc: 0.9743589758872986)
[2024-12-17 02:29:29,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:29,237][root][INFO] - Training Epoch: 2/2, step 1603/7134 completed (loss: 0.3845215439796448, acc: 0.9397590160369873)
[2024-12-17 02:29:29,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:29,509][root][INFO] - Training Epoch: 2/2, step 1604/7134 completed (loss: 0.08413613587617874, acc: 0.9757575988769531)
[2024-12-17 02:29:29,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:29,785][root][INFO] - Training Epoch: 2/2, step 1605/7134 completed (loss: 0.1592300534248352, acc: 0.9588235020637512)
[2024-12-17 02:29:29,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:30,051][root][INFO] - Training Epoch: 2/2, step 1606/7134 completed (loss: 0.13981762528419495, acc: 0.9727891087532043)
[2024-12-17 02:29:30,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:30,303][root][INFO] - Training Epoch: 2/2, step 1607/7134 completed (loss: 0.08175630867481232, acc: 0.9818181991577148)
[2024-12-17 02:29:30,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:30,564][root][INFO] - Training Epoch: 2/2, step 1608/7134 completed (loss: 0.08895887434482574, acc: 0.9763779640197754)
[2024-12-17 02:29:30,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:30,843][root][INFO] - Training Epoch: 2/2, step 1609/7134 completed (loss: 0.22753697633743286, acc: 0.9375)
[2024-12-17 02:29:30,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:31,110][root][INFO] - Training Epoch: 2/2, step 1610/7134 completed (loss: 0.10001926869153976, acc: 0.9770992398262024)
[2024-12-17 02:29:31,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:31,383][root][INFO] - Training Epoch: 2/2, step 1611/7134 completed (loss: 0.19497716426849365, acc: 0.9506173133850098)
[2024-12-17 02:29:31,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:31,663][root][INFO] - Training Epoch: 2/2, step 1612/7134 completed (loss: 0.16096800565719604, acc: 0.9638554453849792)
[2024-12-17 02:29:31,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:31,943][root][INFO] - Training Epoch: 2/2, step 1613/7134 completed (loss: 0.1506224274635315, acc: 0.9689440727233887)
[2024-12-17 02:29:32,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:32,233][root][INFO] - Training Epoch: 2/2, step 1614/7134 completed (loss: 0.16634713113307953, acc: 0.9539473652839661)
[2024-12-17 02:29:32,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:32,532][root][INFO] - Training Epoch: 2/2, step 1615/7134 completed (loss: 0.13486002385616302, acc: 0.9698795080184937)
[2024-12-17 02:29:32,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:32,800][root][INFO] - Training Epoch: 2/2, step 1616/7134 completed (loss: 0.1121884360909462, acc: 0.9806451797485352)
[2024-12-17 02:29:32,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:33,074][root][INFO] - Training Epoch: 2/2, step 1617/7134 completed (loss: 0.07869568467140198, acc: 0.9784172773361206)
[2024-12-17 02:29:33,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:33,354][root][INFO] - Training Epoch: 2/2, step 1618/7134 completed (loss: 0.3975292146205902, acc: 0.9236640930175781)
[2024-12-17 02:29:33,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:33,655][root][INFO] - Training Epoch: 2/2, step 1619/7134 completed (loss: 0.24124598503112793, acc: 0.9512194991111755)
[2024-12-17 02:29:33,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:33,941][root][INFO] - Training Epoch: 2/2, step 1620/7134 completed (loss: 0.2918451130390167, acc: 0.9285714030265808)
[2024-12-17 02:29:34,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:34,251][root][INFO] - Training Epoch: 2/2, step 1621/7134 completed (loss: 0.2935211956501007, acc: 0.8954248428344727)
[2024-12-17 02:29:34,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:34,525][root][INFO] - Training Epoch: 2/2, step 1622/7134 completed (loss: 0.23774170875549316, acc: 0.9281045794487)
[2024-12-17 02:29:34,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:34,811][root][INFO] - Training Epoch: 2/2, step 1623/7134 completed (loss: 0.17715612053871155, acc: 0.9551281929016113)
[2024-12-17 02:29:34,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:35,102][root][INFO] - Training Epoch: 2/2, step 1624/7134 completed (loss: 0.24486538767814636, acc: 0.9545454382896423)
[2024-12-17 02:29:35,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:35,392][root][INFO] - Training Epoch: 2/2, step 1625/7134 completed (loss: 0.12235759198665619, acc: 0.956250011920929)
[2024-12-17 02:29:35,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:35,676][root][INFO] - Training Epoch: 2/2, step 1626/7134 completed (loss: 0.3146003186702728, acc: 0.9484536051750183)
[2024-12-17 02:29:35,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:35,948][root][INFO] - Training Epoch: 2/2, step 1627/7134 completed (loss: 0.20406098663806915, acc: 0.9430894255638123)
[2024-12-17 02:29:36,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:36,229][root][INFO] - Training Epoch: 2/2, step 1628/7134 completed (loss: 0.2017981857061386, acc: 0.9382715821266174)
[2024-12-17 02:29:36,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:36,518][root][INFO] - Training Epoch: 2/2, step 1629/7134 completed (loss: 0.17352285981178284, acc: 0.939393937587738)
[2024-12-17 02:29:36,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:36,807][root][INFO] - Training Epoch: 2/2, step 1630/7134 completed (loss: 0.1900964081287384, acc: 0.936170220375061)
[2024-12-17 02:29:36,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:37,099][root][INFO] - Training Epoch: 2/2, step 1631/7134 completed (loss: 0.27087047696113586, acc: 0.935251772403717)
[2024-12-17 02:29:37,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:37,366][root][INFO] - Training Epoch: 2/2, step 1632/7134 completed (loss: 0.1987019032239914, acc: 0.9477611780166626)
[2024-12-17 02:29:37,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:37,641][root][INFO] - Training Epoch: 2/2, step 1633/7134 completed (loss: 0.1946909874677658, acc: 0.949999988079071)
[2024-12-17 02:29:37,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:37,923][root][INFO] - Training Epoch: 2/2, step 1634/7134 completed (loss: 0.12323849648237228, acc: 0.955974817276001)
[2024-12-17 02:29:38,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:38,179][root][INFO] - Training Epoch: 2/2, step 1635/7134 completed (loss: 0.21045096218585968, acc: 0.9444444179534912)
[2024-12-17 02:29:38,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:38,452][root][INFO] - Training Epoch: 2/2, step 1636/7134 completed (loss: 0.29126718640327454, acc: 0.9357798099517822)
[2024-12-17 02:29:38,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:38,729][root][INFO] - Training Epoch: 2/2, step 1637/7134 completed (loss: 0.13171279430389404, acc: 0.9751552939414978)
[2024-12-17 02:29:38,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:39,023][root][INFO] - Training Epoch: 2/2, step 1638/7134 completed (loss: 0.508306086063385, acc: 0.8582677245140076)
[2024-12-17 02:29:39,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:39,305][root][INFO] - Training Epoch: 2/2, step 1639/7134 completed (loss: 0.6954115629196167, acc: 0.8333333134651184)
[2024-12-17 02:29:39,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:39,593][root][INFO] - Training Epoch: 2/2, step 1640/7134 completed (loss: 0.30736181139945984, acc: 0.8985507488250732)
[2024-12-17 02:29:39,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:39,869][root][INFO] - Training Epoch: 2/2, step 1641/7134 completed (loss: 0.26490870118141174, acc: 0.9210526347160339)
[2024-12-17 02:29:40,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:40,154][root][INFO] - Training Epoch: 2/2, step 1642/7134 completed (loss: 0.2733455002307892, acc: 0.9433962106704712)
[2024-12-17 02:29:40,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:40,429][root][INFO] - Training Epoch: 2/2, step 1643/7134 completed (loss: 0.520248293876648, acc: 0.8636363744735718)
[2024-12-17 02:29:40,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:40,716][root][INFO] - Training Epoch: 2/2, step 1644/7134 completed (loss: 0.30767717957496643, acc: 0.9182389974594116)
[2024-12-17 02:29:40,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:40,998][root][INFO] - Training Epoch: 2/2, step 1645/7134 completed (loss: 0.30626556277275085, acc: 0.931034505367279)
[2024-12-17 02:29:41,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:41,303][root][INFO] - Training Epoch: 2/2, step 1646/7134 completed (loss: 0.3177188038825989, acc: 0.9354838728904724)
[2024-12-17 02:29:41,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:41,582][root][INFO] - Training Epoch: 2/2, step 1647/7134 completed (loss: 0.23750995099544525, acc: 0.9389671087265015)
[2024-12-17 02:29:41,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:41,866][root][INFO] - Training Epoch: 2/2, step 1648/7134 completed (loss: 0.22884798049926758, acc: 0.9601989984512329)
[2024-12-17 02:29:42,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:42,146][root][INFO] - Training Epoch: 2/2, step 1649/7134 completed (loss: 0.173198401927948, acc: 0.9557521939277649)
[2024-12-17 02:29:42,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:42,438][root][INFO] - Training Epoch: 2/2, step 1650/7134 completed (loss: 0.22717143595218658, acc: 0.9396985173225403)
[2024-12-17 02:29:42,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:42,723][root][INFO] - Training Epoch: 2/2, step 1651/7134 completed (loss: 0.23623275756835938, acc: 0.9545454382896423)
[2024-12-17 02:29:42,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:43,022][root][INFO] - Training Epoch: 2/2, step 1652/7134 completed (loss: 0.23644469678401947, acc: 0.9316239356994629)
[2024-12-17 02:29:43,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:43,301][root][INFO] - Training Epoch: 2/2, step 1653/7134 completed (loss: 0.16447481513023376, acc: 0.9672130942344666)
[2024-12-17 02:29:43,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:43,614][root][INFO] - Training Epoch: 2/2, step 1654/7134 completed (loss: 0.15971916913986206, acc: 0.9442059993743896)
[2024-12-17 02:29:43,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:43,905][root][INFO] - Training Epoch: 2/2, step 1655/7134 completed (loss: 0.14102144539356232, acc: 0.9642857313156128)
[2024-12-17 02:29:44,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:44,178][root][INFO] - Training Epoch: 2/2, step 1656/7134 completed (loss: 0.25305619835853577, acc: 0.9461883306503296)
[2024-12-17 02:29:44,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:44,479][root][INFO] - Training Epoch: 2/2, step 1657/7134 completed (loss: 0.15179146826267242, acc: 0.961240291595459)
[2024-12-17 02:29:44,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:44,761][root][INFO] - Training Epoch: 2/2, step 1658/7134 completed (loss: 0.14611287415027618, acc: 0.9626556038856506)
[2024-12-17 02:29:44,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:45,040][root][INFO] - Training Epoch: 2/2, step 1659/7134 completed (loss: 0.19982460141181946, acc: 0.9440000057220459)
[2024-12-17 02:29:45,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:45,346][root][INFO] - Training Epoch: 2/2, step 1660/7134 completed (loss: 0.20286670327186584, acc: 0.9615384340286255)
[2024-12-17 02:29:45,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:45,654][root][INFO] - Training Epoch: 2/2, step 1661/7134 completed (loss: 0.21193420886993408, acc: 0.948051929473877)
[2024-12-17 02:29:45,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:45,954][root][INFO] - Training Epoch: 2/2, step 1662/7134 completed (loss: 0.09599707275629044, acc: 0.9668246507644653)
[2024-12-17 02:29:46,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:46,260][root][INFO] - Training Epoch: 2/2, step 1663/7134 completed (loss: 0.09693364799022675, acc: 0.9617021083831787)
[2024-12-17 02:29:46,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:46,541][root][INFO] - Training Epoch: 2/2, step 1664/7134 completed (loss: 0.17591004073619843, acc: 0.9449999928474426)
[2024-12-17 02:29:46,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:46,831][root][INFO] - Training Epoch: 2/2, step 1665/7134 completed (loss: 0.15844395756721497, acc: 0.9509202241897583)
[2024-12-17 02:29:46,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:47,139][root][INFO] - Training Epoch: 2/2, step 1666/7134 completed (loss: 0.08511479943990707, acc: 0.9789915680885315)
[2024-12-17 02:29:47,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:47,433][root][INFO] - Training Epoch: 2/2, step 1667/7134 completed (loss: 0.21643704175949097, acc: 0.939393937587738)
[2024-12-17 02:29:47,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:47,715][root][INFO] - Training Epoch: 2/2, step 1668/7134 completed (loss: 0.07436579465866089, acc: 0.9955157041549683)
[2024-12-17 02:29:47,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:48,022][root][INFO] - Training Epoch: 2/2, step 1669/7134 completed (loss: 0.12779442965984344, acc: 0.9694656729698181)
[2024-12-17 02:29:48,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:48,319][root][INFO] - Training Epoch: 2/2, step 1670/7134 completed (loss: 0.22626416385173798, acc: 0.9543726444244385)
[2024-12-17 02:29:48,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:48,604][root][INFO] - Training Epoch: 2/2, step 1671/7134 completed (loss: 0.15515486896038055, acc: 0.9693877696990967)
[2024-12-17 02:29:48,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:48,884][root][INFO] - Training Epoch: 2/2, step 1672/7134 completed (loss: 0.20587511360645294, acc: 0.9649122953414917)
[2024-12-17 02:29:48,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:49,177][root][INFO] - Training Epoch: 2/2, step 1673/7134 completed (loss: 0.26139363646507263, acc: 0.9751552939414978)
[2024-12-17 02:29:49,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:49,454][root][INFO] - Training Epoch: 2/2, step 1674/7134 completed (loss: 0.38927724957466125, acc: 0.9276315569877625)
[2024-12-17 02:29:49,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:49,741][root][INFO] - Training Epoch: 2/2, step 1675/7134 completed (loss: 0.27443644404411316, acc: 0.9452054500579834)
[2024-12-17 02:29:49,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:50,028][root][INFO] - Training Epoch: 2/2, step 1676/7134 completed (loss: 0.3027171194553375, acc: 0.9230769276618958)
[2024-12-17 02:29:50,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:50,306][root][INFO] - Training Epoch: 2/2, step 1677/7134 completed (loss: 0.3882916569709778, acc: 0.914893627166748)
[2024-12-17 02:29:50,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:50,598][root][INFO] - Training Epoch: 2/2, step 1678/7134 completed (loss: 0.27069535851478577, acc: 0.9520958065986633)
[2024-12-17 02:29:50,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:50,877][root][INFO] - Training Epoch: 2/2, step 1679/7134 completed (loss: 0.2912999093532562, acc: 0.9390243887901306)
[2024-12-17 02:29:51,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:51,175][root][INFO] - Training Epoch: 2/2, step 1680/7134 completed (loss: 0.19778819382190704, acc: 0.9352940917015076)
[2024-12-17 02:29:51,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:51,448][root][INFO] - Training Epoch: 2/2, step 1681/7134 completed (loss: 0.2763313353061676, acc: 0.9371069073677063)
[2024-12-17 02:29:51,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:51,726][root][INFO] - Training Epoch: 2/2, step 1682/7134 completed (loss: 0.2612397372722626, acc: 0.9520547986030579)
[2024-12-17 02:29:51,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:52,013][root][INFO] - Training Epoch: 2/2, step 1683/7134 completed (loss: 0.17607234418392181, acc: 0.9448275566101074)
[2024-12-17 02:29:52,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:52,298][root][INFO] - Training Epoch: 2/2, step 1684/7134 completed (loss: 0.11023519933223724, acc: 0.9716312289237976)
[2024-12-17 02:29:52,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:52,584][root][INFO] - Training Epoch: 2/2, step 1685/7134 completed (loss: 0.18637007474899292, acc: 0.9636363387107849)
[2024-12-17 02:29:52,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:52,886][root][INFO] - Training Epoch: 2/2, step 1686/7134 completed (loss: 0.13536378741264343, acc: 0.9624060392379761)
[2024-12-17 02:29:53,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:53,196][root][INFO] - Training Epoch: 2/2, step 1687/7134 completed (loss: 0.16591478884220123, acc: 0.9469026327133179)
[2024-12-17 02:29:53,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:53,481][root][INFO] - Training Epoch: 2/2, step 1688/7134 completed (loss: 0.12863768637180328, acc: 0.9726027250289917)
[2024-12-17 02:29:53,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:53,787][root][INFO] - Training Epoch: 2/2, step 1689/7134 completed (loss: 0.17062148451805115, acc: 0.948387086391449)
[2024-12-17 02:29:53,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:54,072][root][INFO] - Training Epoch: 2/2, step 1690/7134 completed (loss: 0.10388627648353577, acc: 0.9646017551422119)
[2024-12-17 02:29:54,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:54,354][root][INFO] - Training Epoch: 2/2, step 1691/7134 completed (loss: 0.18095025420188904, acc: 0.957446813583374)
[2024-12-17 02:29:54,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:54,631][root][INFO] - Training Epoch: 2/2, step 1692/7134 completed (loss: 0.14836205542087555, acc: 0.9430894255638123)
[2024-12-17 02:29:54,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:54,915][root][INFO] - Training Epoch: 2/2, step 1693/7134 completed (loss: 0.13950233161449432, acc: 0.9727891087532043)
[2024-12-17 02:29:55,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:55,203][root][INFO] - Training Epoch: 2/2, step 1694/7134 completed (loss: 0.34304600954055786, acc: 0.9241379499435425)
[2024-12-17 02:29:55,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:55,494][root][INFO] - Training Epoch: 2/2, step 1695/7134 completed (loss: 0.20164045691490173, acc: 0.9495798349380493)
[2024-12-17 02:29:55,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:55,770][root][INFO] - Training Epoch: 2/2, step 1696/7134 completed (loss: 0.324023962020874, acc: 0.932330846786499)
[2024-12-17 02:29:55,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:56,043][root][INFO] - Training Epoch: 2/2, step 1697/7134 completed (loss: 0.1401762068271637, acc: 0.9720279574394226)
[2024-12-17 02:29:56,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:56,339][root][INFO] - Training Epoch: 2/2, step 1698/7134 completed (loss: 0.05142328143119812, acc: 0.9860140085220337)
[2024-12-17 02:29:56,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:56,640][root][INFO] - Training Epoch: 2/2, step 1699/7134 completed (loss: 0.14841774106025696, acc: 0.9701492786407471)
[2024-12-17 02:29:56,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:56,934][root][INFO] - Training Epoch: 2/2, step 1700/7134 completed (loss: 0.2930218279361725, acc: 0.9179104566574097)
[2024-12-17 02:29:57,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:57,218][root][INFO] - Training Epoch: 2/2, step 1701/7134 completed (loss: 0.22830861806869507, acc: 0.9266666769981384)
[2024-12-17 02:29:57,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:57,514][root][INFO] - Training Epoch: 2/2, step 1702/7134 completed (loss: 0.2700260579586029, acc: 0.9341317415237427)
[2024-12-17 02:29:57,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:57,804][root][INFO] - Training Epoch: 2/2, step 1703/7134 completed (loss: 0.40910762548446655, acc: 0.9072847962379456)
[2024-12-17 02:29:57,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:58,094][root][INFO] - Training Epoch: 2/2, step 1704/7134 completed (loss: 0.48600468039512634, acc: 0.8902438879013062)
[2024-12-17 02:29:58,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:58,387][root][INFO] - Training Epoch: 2/2, step 1705/7134 completed (loss: 0.30317169427871704, acc: 0.9440000057220459)
[2024-12-17 02:29:58,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:58,655][root][INFO] - Training Epoch: 2/2, step 1706/7134 completed (loss: 0.21609632670879364, acc: 0.9571428298950195)
[2024-12-17 02:29:58,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:58,965][root][INFO] - Training Epoch: 2/2, step 1707/7134 completed (loss: 0.352384477853775, acc: 0.9568965435028076)
[2024-12-17 02:29:59,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:59,245][root][INFO] - Training Epoch: 2/2, step 1708/7134 completed (loss: 0.21648019552230835, acc: 0.9333333373069763)
[2024-12-17 02:29:59,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:59,512][root][INFO] - Training Epoch: 2/2, step 1709/7134 completed (loss: 0.29464441537857056, acc: 0.8866666555404663)
[2024-12-17 02:29:59,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:59,800][root][INFO] - Training Epoch: 2/2, step 1710/7134 completed (loss: 0.25725823640823364, acc: 0.9391891956329346)
[2024-12-17 02:29:59,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:00,076][root][INFO] - Training Epoch: 2/2, step 1711/7134 completed (loss: 0.2598462998867035, acc: 0.9354838728904724)
[2024-12-17 02:30:00,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:00,353][root][INFO] - Training Epoch: 2/2, step 1712/7134 completed (loss: 0.1765887439250946, acc: 0.9365079402923584)
[2024-12-17 02:30:00,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:00,621][root][INFO] - Training Epoch: 2/2, step 1713/7134 completed (loss: 0.16090109944343567, acc: 0.961904764175415)
[2024-12-17 02:30:00,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:00,909][root][INFO] - Training Epoch: 2/2, step 1714/7134 completed (loss: 0.20733028650283813, acc: 0.936170220375061)
[2024-12-17 02:30:01,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:01,185][root][INFO] - Training Epoch: 2/2, step 1715/7134 completed (loss: 0.20862354338169098, acc: 0.9528301954269409)
[2024-12-17 02:30:01,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:01,463][root][INFO] - Training Epoch: 2/2, step 1716/7134 completed (loss: 0.4109615981578827, acc: 0.9539473652839661)
[2024-12-17 02:30:01,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:01,741][root][INFO] - Training Epoch: 2/2, step 1717/7134 completed (loss: 0.25250133872032166, acc: 0.8992248177528381)
[2024-12-17 02:30:01,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:02,006][root][INFO] - Training Epoch: 2/2, step 1718/7134 completed (loss: 0.37302663922309875, acc: 0.9230769276618958)
[2024-12-17 02:30:02,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:02,293][root][INFO] - Training Epoch: 2/2, step 1719/7134 completed (loss: 0.24349893629550934, acc: 0.9644970297813416)
[2024-12-17 02:30:02,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:02,592][root][INFO] - Training Epoch: 2/2, step 1720/7134 completed (loss: 0.6036397814750671, acc: 0.8461538553237915)
[2024-12-17 02:30:02,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:02,844][root][INFO] - Training Epoch: 2/2, step 1721/7134 completed (loss: 0.22131556272506714, acc: 0.953125)
[2024-12-17 02:30:03,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:03,163][root][INFO] - Training Epoch: 2/2, step 1722/7134 completed (loss: 0.12837013602256775, acc: 0.9696969985961914)
[2024-12-17 02:30:03,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:03,441][root][INFO] - Training Epoch: 2/2, step 1723/7134 completed (loss: 0.3286064863204956, acc: 0.9197530746459961)
[2024-12-17 02:30:03,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:03,725][root][INFO] - Training Epoch: 2/2, step 1724/7134 completed (loss: 0.25250163674354553, acc: 0.9296875)
[2024-12-17 02:30:03,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:03,988][root][INFO] - Training Epoch: 2/2, step 1725/7134 completed (loss: 0.24446552991867065, acc: 0.9253731369972229)
[2024-12-17 02:30:04,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:04,259][root][INFO] - Training Epoch: 2/2, step 1726/7134 completed (loss: 0.1883593499660492, acc: 0.9462365508079529)
[2024-12-17 02:30:04,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:04,523][root][INFO] - Training Epoch: 2/2, step 1727/7134 completed (loss: 0.15083104372024536, acc: 0.9469026327133179)
[2024-12-17 02:30:04,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:04,806][root][INFO] - Training Epoch: 2/2, step 1728/7134 completed (loss: 0.14645852148532867, acc: 0.9615384340286255)
[2024-12-17 02:30:04,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:05,075][root][INFO] - Training Epoch: 2/2, step 1729/7134 completed (loss: 0.26083359122276306, acc: 0.9279279112815857)
[2024-12-17 02:30:05,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:05,370][root][INFO] - Training Epoch: 2/2, step 1730/7134 completed (loss: 0.14477986097335815, acc: 0.9532710313796997)
[2024-12-17 02:30:05,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:05,586][root][INFO] - Training Epoch: 2/2, step 1731/7134 completed (loss: 0.5369386076927185, acc: 0.891566276550293)
[2024-12-17 02:30:05,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:05,848][root][INFO] - Training Epoch: 2/2, step 1732/7134 completed (loss: 0.1422945261001587, acc: 0.9814814925193787)
[2024-12-17 02:30:06,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:06,148][root][INFO] - Training Epoch: 2/2, step 1733/7134 completed (loss: 0.274257630109787, acc: 0.9266055226325989)
[2024-12-17 02:30:06,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:06,442][root][INFO] - Training Epoch: 2/2, step 1734/7134 completed (loss: 0.2549367845058441, acc: 0.9216867685317993)
[2024-12-17 02:30:06,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:06,729][root][INFO] - Training Epoch: 2/2, step 1735/7134 completed (loss: 0.11046989262104034, acc: 0.9801324605941772)
[2024-12-17 02:30:06,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:07,027][root][INFO] - Training Epoch: 2/2, step 1736/7134 completed (loss: 0.22414617240428925, acc: 0.9556962251663208)
[2024-12-17 02:30:07,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:07,331][root][INFO] - Training Epoch: 2/2, step 1737/7134 completed (loss: 0.20222017168998718, acc: 0.9666666388511658)
[2024-12-17 02:30:07,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:07,611][root][INFO] - Training Epoch: 2/2, step 1738/7134 completed (loss: 0.09237007051706314, acc: 0.9664804339408875)
[2024-12-17 02:30:07,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:07,889][root][INFO] - Training Epoch: 2/2, step 1739/7134 completed (loss: 0.19159162044525146, acc: 0.9473684430122375)
[2024-12-17 02:30:08,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:08,183][root][INFO] - Training Epoch: 2/2, step 1740/7134 completed (loss: 0.13786891102790833, acc: 0.9662162065505981)
[2024-12-17 02:30:08,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:08,477][root][INFO] - Training Epoch: 2/2, step 1741/7134 completed (loss: 0.21864467859268188, acc: 0.9627329111099243)
[2024-12-17 02:30:08,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:08,760][root][INFO] - Training Epoch: 2/2, step 1742/7134 completed (loss: 0.24048766493797302, acc: 0.9470198750495911)
[2024-12-17 02:30:08,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:09,040][root][INFO] - Training Epoch: 2/2, step 1743/7134 completed (loss: 0.2211628556251526, acc: 0.9319728016853333)
[2024-12-17 02:30:09,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:09,325][root][INFO] - Training Epoch: 2/2, step 1744/7134 completed (loss: 0.17715825140476227, acc: 0.9624060392379761)
[2024-12-17 02:30:09,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:09,624][root][INFO] - Training Epoch: 2/2, step 1745/7134 completed (loss: 0.19271527230739594, acc: 0.9470587968826294)
[2024-12-17 02:30:09,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:09,925][root][INFO] - Training Epoch: 2/2, step 1746/7134 completed (loss: 0.12489003688097, acc: 0.957446813583374)
[2024-12-17 02:30:10,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:10,215][root][INFO] - Training Epoch: 2/2, step 1747/7134 completed (loss: 0.20830614864826202, acc: 0.9451219439506531)
[2024-12-17 02:30:10,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:10,508][root][INFO] - Training Epoch: 2/2, step 1748/7134 completed (loss: 0.16052652895450592, acc: 0.9588235020637512)
[2024-12-17 02:30:10,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:10,805][root][INFO] - Training Epoch: 2/2, step 1749/7134 completed (loss: 0.28351354598999023, acc: 0.9528796076774597)
[2024-12-17 02:30:10,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:11,101][root][INFO] - Training Epoch: 2/2, step 1750/7134 completed (loss: 0.2182915359735489, acc: 0.976331353187561)
[2024-12-17 02:30:11,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:11,387][root][INFO] - Training Epoch: 2/2, step 1751/7134 completed (loss: 0.30768656730651855, acc: 0.9464285969734192)
[2024-12-17 02:30:11,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:11,670][root][INFO] - Training Epoch: 2/2, step 1752/7134 completed (loss: 0.34288570284843445, acc: 0.9515151381492615)
[2024-12-17 02:30:11,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:11,939][root][INFO] - Training Epoch: 2/2, step 1753/7134 completed (loss: 0.2817537784576416, acc: 0.940397322177887)
[2024-12-17 02:30:12,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:12,208][root][INFO] - Training Epoch: 2/2, step 1754/7134 completed (loss: 0.30216026306152344, acc: 0.9084967374801636)
[2024-12-17 02:30:12,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:12,479][root][INFO] - Training Epoch: 2/2, step 1755/7134 completed (loss: 0.1395639032125473, acc: 0.9738562107086182)
[2024-12-17 02:30:12,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:12,750][root][INFO] - Training Epoch: 2/2, step 1756/7134 completed (loss: 0.2892952561378479, acc: 0.9266666769981384)
[2024-12-17 02:30:12,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:13,015][root][INFO] - Training Epoch: 2/2, step 1757/7134 completed (loss: 0.15087170898914337, acc: 0.9586777091026306)
[2024-12-17 02:30:13,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:13,300][root][INFO] - Training Epoch: 2/2, step 1758/7134 completed (loss: 0.07657317072153091, acc: 0.9764705896377563)
[2024-12-17 02:30:13,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:13,584][root][INFO] - Training Epoch: 2/2, step 1759/7134 completed (loss: 0.1278020143508911, acc: 0.9671052694320679)
[2024-12-17 02:30:13,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:13,853][root][INFO] - Training Epoch: 2/2, step 1760/7134 completed (loss: 0.08924420177936554, acc: 0.9836065769195557)
[2024-12-17 02:30:13,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:14,100][root][INFO] - Training Epoch: 2/2, step 1761/7134 completed (loss: 0.14903807640075684, acc: 0.9642857313156128)
[2024-12-17 02:30:14,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:14,368][root][INFO] - Training Epoch: 2/2, step 1762/7134 completed (loss: 0.1761808693408966, acc: 0.9611650705337524)
[2024-12-17 02:30:14,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:14,628][root][INFO] - Training Epoch: 2/2, step 1763/7134 completed (loss: 0.23395681381225586, acc: 0.9246575236320496)
[2024-12-17 02:30:14,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:14,893][root][INFO] - Training Epoch: 2/2, step 1764/7134 completed (loss: 0.2827342450618744, acc: 0.9435483813285828)
[2024-12-17 02:30:14,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:15,159][root][INFO] - Training Epoch: 2/2, step 1765/7134 completed (loss: 0.20316928625106812, acc: 0.9477124214172363)
[2024-12-17 02:30:15,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:15,421][root][INFO] - Training Epoch: 2/2, step 1766/7134 completed (loss: 0.2654552757740021, acc: 0.9350649118423462)
[2024-12-17 02:30:15,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:15,700][root][INFO] - Training Epoch: 2/2, step 1767/7134 completed (loss: 0.3195810914039612, acc: 0.887005627155304)
[2024-12-17 02:30:15,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:15,972][root][INFO] - Training Epoch: 2/2, step 1768/7134 completed (loss: 0.07076182216405869, acc: 0.9910714030265808)
[2024-12-17 02:30:16,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:16,263][root][INFO] - Training Epoch: 2/2, step 1769/7134 completed (loss: 0.2054884135723114, acc: 0.95333331823349)
[2024-12-17 02:30:16,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:16,545][root][INFO] - Training Epoch: 2/2, step 1770/7134 completed (loss: 0.28653857111930847, acc: 0.9589040875434875)
[2024-12-17 02:30:16,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:16,824][root][INFO] - Training Epoch: 2/2, step 1771/7134 completed (loss: 0.2614387571811676, acc: 0.9350649118423462)
[2024-12-17 02:30:16,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:17,087][root][INFO] - Training Epoch: 2/2, step 1772/7134 completed (loss: 0.21240141987800598, acc: 0.9357143044471741)
[2024-12-17 02:30:17,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:17,364][root][INFO] - Training Epoch: 2/2, step 1773/7134 completed (loss: 0.15000300109386444, acc: 0.9716312289237976)
[2024-12-17 02:30:17,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:17,620][root][INFO] - Training Epoch: 2/2, step 1774/7134 completed (loss: 0.06800578534603119, acc: 0.9924242496490479)
[2024-12-17 02:30:17,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:17,879][root][INFO] - Training Epoch: 2/2, step 1775/7134 completed (loss: 0.08021119982004166, acc: 0.9794520735740662)
[2024-12-17 02:30:17,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:18,146][root][INFO] - Training Epoch: 2/2, step 1776/7134 completed (loss: 0.13257522881031036, acc: 0.9724137783050537)
[2024-12-17 02:30:18,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:18,413][root][INFO] - Training Epoch: 2/2, step 1777/7134 completed (loss: 0.040192268788814545, acc: 0.993630588054657)
[2024-12-17 02:30:18,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:18,683][root][INFO] - Training Epoch: 2/2, step 1778/7134 completed (loss: 0.2963002026081085, acc: 0.9182389974594116)
[2024-12-17 02:30:18,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:18,940][root][INFO] - Training Epoch: 2/2, step 1779/7134 completed (loss: 0.2958214581012726, acc: 0.9469026327133179)
[2024-12-17 02:30:19,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:19,245][root][INFO] - Training Epoch: 2/2, step 1780/7134 completed (loss: 0.11425703763961792, acc: 0.970059871673584)
[2024-12-17 02:30:20,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:20,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:20,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:20,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:21,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:21,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:21,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:21,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:22,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:22,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:22,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:23,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:23,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:23,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:23,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:24,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:24,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:24,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:25,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:25,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:25,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:26,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:26,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:26,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:27,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:27,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:27,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:28,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:28,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:28,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:28,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:29,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:29,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:29,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:30,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:30,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:30,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:30,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:30,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:31,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:31,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:31,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:32,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:32,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:32,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:33,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:33,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:33,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:33,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:34,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:34,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:34,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:35,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:35,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:35,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:36,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:36,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:36,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:36,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:36,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:37,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:37,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:37,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:37,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:38,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:38,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:38,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:39,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:39,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:39,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:40,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:40,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:40,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:41,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:41,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:41,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:41,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:42,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:42,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:42,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:43,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:43,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:43,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:44,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:44,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:44,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:45,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:45,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:45,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:45,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:46,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:46,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:46,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:46,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:47,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:47,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:47,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:48,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:48,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:48,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:48,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:49,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:49,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:49,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:50,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:50,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:50,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:50,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:51,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:51,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:51,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:52,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:52,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:52,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:52,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:53,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:53,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:53,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:54,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:54,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:54,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:54,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:55,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:55,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:55,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:56,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:56,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:56,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:56,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:57,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:57,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:57,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:58,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:58,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:58,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:58,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:59,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:59,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:59,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:00,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:00,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:00,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:01,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:01,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:01,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:02,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:02,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:02,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:02,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:03,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:03,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:03,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:03,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:04,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:04,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:04,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:05,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:05,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:05,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:05,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:06,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:06,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:06,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:06,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:07,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:07,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:07,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:08,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:08,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:08,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:09,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:09,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:09,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:10,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:10,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:10,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:10,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:11,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:11,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:11,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:12,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:12,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:12,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:12,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:13,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:13,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:13,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:13,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:14,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:14,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:14,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:14,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:15,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:15,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:15,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:15,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:16,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:16,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:16,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:17,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:17,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:17,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:17,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:18,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:18,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:18,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:18,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:19,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:19,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:19,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:20,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:20,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:20,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:21,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:21,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:21,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:22,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:22,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:22,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:22,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:23,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:23,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:23,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:24,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:24,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:24,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:25,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:25,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:25,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:26,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:26,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:26,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:26,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:27,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:27,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:27,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:27,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:28,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:28,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:28,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:28,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:29,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:29,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:29,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:30,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:30,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:30,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:31,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:31,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:32,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:32,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:32,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:33,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:33,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:33,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:34,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:34,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:34,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:35,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:35,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:35,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:36,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:36,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:36,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:37,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:37,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:37,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:37,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:38,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:38,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:38,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:39,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:39,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:39,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:40,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:40,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:40,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:41,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:41,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:41,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:42,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:42,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:43,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:43,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:43,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:44,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:44,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:44,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:45,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:45,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:45,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:46,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:46,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:46,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:47,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:47,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:48,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:48,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:48,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:49,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:49,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:49,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:50,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:50,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:50,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:50,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:51,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:51,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:51,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:52,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:52,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:52,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:52,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:53,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:53,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:53,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:53,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:54,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:54,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:54,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:55,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:55,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:55,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:56,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:56,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:56,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:57,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:57,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:57,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:58,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:58,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:58,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:59,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:59,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:59,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:59,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:00,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:00,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:00,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:01,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:01,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:01,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:02,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:02,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:02,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:03,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:03,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:03,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:04,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:04,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:04,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:04,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:05,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:05,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:05,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:05,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:06,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:06,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:06,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:07,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:07,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:08,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:08,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:09,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:09,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:10,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:10,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:10,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:11,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:11,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:11,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:11,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:12,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:12,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:12,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:13,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:13,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:13,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:13,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:14,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:14,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:14,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:15,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:15,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:15,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:15,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:16,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:16,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:16,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:17,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:17,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:17,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:17,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:18,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:18,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:18,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:18,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:19,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:19,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:19,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:20,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:20,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:20,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:21,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:21,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:21,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:21,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:22,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:22,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:22,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:22,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:23,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:23,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:23,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:24,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:24,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:24,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:25,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:25,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:25,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:26,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:26,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:26,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:26,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:27,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:27,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:27,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:28,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:28,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:28,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:29,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:29,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:29,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:29,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:30,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:30,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:30,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:31,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:31,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:31,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:31,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:32,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:32,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:32,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:33,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:33,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:33,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:33,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:34,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:34,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:34,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:35,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:35,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:35,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:35,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:36,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:36,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:36,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:37,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:37,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:37,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:37,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:38,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:38,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:38,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:39,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:39,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:39,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:39,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:40,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:40,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:40,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:41,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:41,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:41,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:42,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:42,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:42,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:43,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:43,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:43,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:44,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:44,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:44,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:45,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:45,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:45,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:46,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:46,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:46,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:47,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:47,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:47,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:48,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:48,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:48,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:49,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:49,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:49,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:50,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:50,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:50,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:51,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:51,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:52,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:52,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:52,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:53,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:53,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:53,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:53,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:54,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:54,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:54,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:55,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:55,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:55,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:56,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:56,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:56,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:57,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:57,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:57,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:57,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:58,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:58,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:58,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:59,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:59,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:59,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:00,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:00,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:00,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:01,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:01,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:01,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:01,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:02,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:02,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:02,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:03,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:03,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:03,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:03,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:04,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:04,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:04,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:05,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:05,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:05,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:06,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:06,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:06,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:07,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:07,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:07,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:08,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:08,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:08,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:08,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:09,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:09,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:09,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:10,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:10,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:10,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:11,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:11,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:11,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:11,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:12,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:12,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:12,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:13,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:13,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:13,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:14,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:14,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:14,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:15,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:15,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:16,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:16,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:16,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:17,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:17,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:17,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:18,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:18,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:18,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:18,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:19,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:19,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:19,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:20,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:20,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:20,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:20,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:21,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:21,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:21,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:22,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:22,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:22,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:23,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:23,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:23,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:24,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:24,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:24,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:25,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:25,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:25,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:26,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:26,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:26,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:26,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:27,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:27,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:27,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:28,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:28,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:28,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:29,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:29,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:29,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:30,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:31,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:31,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:31,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:32,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:32,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:32,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:33,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:33,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:33,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:34,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:34,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:34,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:35,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:35,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:35,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:36,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:36,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:36,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:37,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:37,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:37,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:38,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:38,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:38,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:38,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:39,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:39,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:39,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:40,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:40,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:40,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:41,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:41,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:41,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:42,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:42,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:42,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:42,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:43,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:43,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:43,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:44,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:44,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:44,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:45,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:45,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:45,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:46,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:46,709][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.3218, device='cuda:0') eval_epoch_loss=tensor(0.2790, device='cuda:0') eval_epoch_acc=tensor(0.9334, device='cuda:0')
[2024-12-17 02:33:46,712][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-12-17 02:33:46,712][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 02:33:46,967][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_2_step_1781_loss_0.27899083495140076/model.pt
[2024-12-17 02:33:46,972][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 0.27899083495140076
[2024-12-17 02:33:46,972][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.9334174394607544
[2024-12-17 02:33:47,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:47,272][root][INFO] - Training Epoch: 2/2, step 1781/7134 completed (loss: 0.09567054361104965, acc: 0.9731543660163879)
[2024-12-17 02:33:47,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:47,538][root][INFO] - Training Epoch: 2/2, step 1782/7134 completed (loss: 0.0765373557806015, acc: 0.9807692170143127)
[2024-12-17 02:33:47,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:47,824][root][INFO] - Training Epoch: 2/2, step 1783/7134 completed (loss: 0.1516100913286209, acc: 0.9595375657081604)
[2024-12-17 02:33:47,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:48,115][root][INFO] - Training Epoch: 2/2, step 1784/7134 completed (loss: 0.12538008391857147, acc: 0.9935897588729858)
[2024-12-17 02:33:48,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:48,402][root][INFO] - Training Epoch: 2/2, step 1785/7134 completed (loss: 0.22221781313419342, acc: 0.9397590160369873)
[2024-12-17 02:33:48,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:48,682][root][INFO] - Training Epoch: 2/2, step 1786/7134 completed (loss: 0.09044265747070312, acc: 0.9741935729980469)
[2024-12-17 02:33:48,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:48,980][root][INFO] - Training Epoch: 2/2, step 1787/7134 completed (loss: 0.30485999584198, acc: 0.9402984976768494)
[2024-12-17 02:33:49,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:49,265][root][INFO] - Training Epoch: 2/2, step 1788/7134 completed (loss: 0.1713477373123169, acc: 0.9655172228813171)
[2024-12-17 02:33:49,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:49,555][root][INFO] - Training Epoch: 2/2, step 1789/7134 completed (loss: 0.17065681517124176, acc: 0.9539473652839661)
[2024-12-17 02:33:49,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:49,868][root][INFO] - Training Epoch: 2/2, step 1790/7134 completed (loss: 0.5148392915725708, acc: 0.896774172782898)
[2024-12-17 02:33:50,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:50,197][root][INFO] - Training Epoch: 2/2, step 1791/7134 completed (loss: 0.43925756216049194, acc: 0.9018405079841614)
[2024-12-17 02:33:50,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:50,486][root][INFO] - Training Epoch: 2/2, step 1792/7134 completed (loss: 0.8453026413917542, acc: 0.8659217953681946)
[2024-12-17 02:33:50,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:50,793][root][INFO] - Training Epoch: 2/2, step 1793/7134 completed (loss: 0.6816628575325012, acc: 0.8639053106307983)
[2024-12-17 02:33:50,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:51,088][root][INFO] - Training Epoch: 2/2, step 1794/7134 completed (loss: 0.3976875841617584, acc: 0.8815789222717285)
[2024-12-17 02:33:51,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:51,370][root][INFO] - Training Epoch: 2/2, step 1795/7134 completed (loss: 0.6929463148117065, acc: 0.84375)
[2024-12-17 02:33:51,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:51,646][root][INFO] - Training Epoch: 2/2, step 1796/7134 completed (loss: 0.561256468296051, acc: 0.8983050584793091)
[2024-12-17 02:33:51,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:51,925][root][INFO] - Training Epoch: 2/2, step 1797/7134 completed (loss: 0.4357241690158844, acc: 0.8971428275108337)
[2024-12-17 02:33:52,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:52,211][root][INFO] - Training Epoch: 2/2, step 1798/7134 completed (loss: 0.490803986787796, acc: 0.8759689927101135)
[2024-12-17 02:33:52,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:52,505][root][INFO] - Training Epoch: 2/2, step 1799/7134 completed (loss: 0.48577383160591125, acc: 0.8888888955116272)
[2024-12-17 02:33:52,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:52,823][root][INFO] - Training Epoch: 2/2, step 1800/7134 completed (loss: 0.3994259536266327, acc: 0.9142857193946838)
[2024-12-17 02:33:52,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:53,122][root][INFO] - Training Epoch: 2/2, step 1801/7134 completed (loss: 0.44669660925865173, acc: 0.8828828930854797)
[2024-12-17 02:33:53,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:53,403][root][INFO] - Training Epoch: 2/2, step 1802/7134 completed (loss: 0.33669692277908325, acc: 0.9095744490623474)
[2024-12-17 02:33:53,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:53,689][root][INFO] - Training Epoch: 2/2, step 1803/7134 completed (loss: 0.4044676125049591, acc: 0.8841463327407837)
[2024-12-17 02:33:53,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:53,974][root][INFO] - Training Epoch: 2/2, step 1804/7134 completed (loss: 0.17072877287864685, acc: 0.9576719403266907)
[2024-12-17 02:33:54,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:54,263][root][INFO] - Training Epoch: 2/2, step 1805/7134 completed (loss: 0.2004462629556656, acc: 0.9356725215911865)
[2024-12-17 02:33:54,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:54,533][root][INFO] - Training Epoch: 2/2, step 1806/7134 completed (loss: 0.24278534948825836, acc: 0.9398906826972961)
[2024-12-17 02:33:54,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:54,810][root][INFO] - Training Epoch: 2/2, step 1807/7134 completed (loss: 0.2458992898464203, acc: 0.9397590160369873)
[2024-12-17 02:33:54,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:55,075][root][INFO] - Training Epoch: 2/2, step 1808/7134 completed (loss: 0.15627549588680267, acc: 0.9491525292396545)
[2024-12-17 02:33:55,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:55,374][root][INFO] - Training Epoch: 2/2, step 1809/7134 completed (loss: 0.1845819056034088, acc: 0.9479768872261047)
[2024-12-17 02:33:55,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:55,673][root][INFO] - Training Epoch: 2/2, step 1810/7134 completed (loss: 0.15431024134159088, acc: 0.9560439586639404)
[2024-12-17 02:33:55,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:55,954][root][INFO] - Training Epoch: 2/2, step 1811/7134 completed (loss: 0.2978000044822693, acc: 0.9255319237709045)
[2024-12-17 02:33:56,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:56,238][root][INFO] - Training Epoch: 2/2, step 1812/7134 completed (loss: 0.23548154532909393, acc: 0.9774011373519897)
[2024-12-17 02:33:56,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:56,527][root][INFO] - Training Epoch: 2/2, step 1813/7134 completed (loss: 0.29785001277923584, acc: 0.9447513818740845)
[2024-12-17 02:33:56,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:56,811][root][INFO] - Training Epoch: 2/2, step 1814/7134 completed (loss: 0.16868649423122406, acc: 0.9613259434700012)
[2024-12-17 02:33:56,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:57,091][root][INFO] - Training Epoch: 2/2, step 1815/7134 completed (loss: 0.22961942851543427, acc: 0.9363057613372803)
[2024-12-17 02:33:57,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:57,364][root][INFO] - Training Epoch: 2/2, step 1816/7134 completed (loss: 0.37241196632385254, acc: 0.8888888955116272)
[2024-12-17 02:33:57,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:57,662][root][INFO] - Training Epoch: 2/2, step 1817/7134 completed (loss: 0.25614967942237854, acc: 0.9427083134651184)
[2024-12-17 02:33:57,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:57,961][root][INFO] - Training Epoch: 2/2, step 1818/7134 completed (loss: 0.14368300139904022, acc: 0.963350772857666)
[2024-12-17 02:33:58,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:58,254][root][INFO] - Training Epoch: 2/2, step 1819/7134 completed (loss: 0.14194291830062866, acc: 0.9593023061752319)
[2024-12-17 02:33:58,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:58,605][root][INFO] - Training Epoch: 2/2, step 1820/7134 completed (loss: 0.2286100685596466, acc: 0.9339622855186462)
[2024-12-17 02:33:58,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:58,877][root][INFO] - Training Epoch: 2/2, step 1821/7134 completed (loss: 0.15067197382450104, acc: 0.9719626307487488)
[2024-12-17 02:33:58,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:59,143][root][INFO] - Training Epoch: 2/2, step 1822/7134 completed (loss: 0.13367775082588196, acc: 0.9802631735801697)
[2024-12-17 02:33:59,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:59,415][root][INFO] - Training Epoch: 2/2, step 1823/7134 completed (loss: 0.22520960867404938, acc: 0.9418604373931885)
[2024-12-17 02:33:59,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:59,696][root][INFO] - Training Epoch: 2/2, step 1824/7134 completed (loss: 0.13886551558971405, acc: 0.9672130942344666)
[2024-12-17 02:33:59,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:00,005][root][INFO] - Training Epoch: 2/2, step 1825/7134 completed (loss: 0.1503407061100006, acc: 0.9719626307487488)
[2024-12-17 02:34:00,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:00,289][root][INFO] - Training Epoch: 2/2, step 1826/7134 completed (loss: 0.11446623504161835, acc: 0.9649122953414917)
[2024-12-17 02:34:00,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:00,596][root][INFO] - Training Epoch: 2/2, step 1827/7134 completed (loss: 0.18508698046207428, acc: 0.9620853066444397)
[2024-12-17 02:34:00,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:00,880][root][INFO] - Training Epoch: 2/2, step 1828/7134 completed (loss: 0.09042917937040329, acc: 0.9722222089767456)
[2024-12-17 02:34:01,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:01,159][root][INFO] - Training Epoch: 2/2, step 1829/7134 completed (loss: 0.1934707760810852, acc: 0.9516128897666931)
[2024-12-17 02:34:01,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:01,473][root][INFO] - Training Epoch: 2/2, step 1830/7134 completed (loss: 0.2153656929731369, acc: 0.9481865167617798)
[2024-12-17 02:34:01,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:01,753][root][INFO] - Training Epoch: 2/2, step 1831/7134 completed (loss: 0.07373324036598206, acc: 0.9848484992980957)
[2024-12-17 02:34:01,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:02,028][root][INFO] - Training Epoch: 2/2, step 1832/7134 completed (loss: 0.35799217224121094, acc: 0.9224806427955627)
[2024-12-17 02:34:02,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:02,328][root][INFO] - Training Epoch: 2/2, step 1833/7134 completed (loss: 0.6959821581840515, acc: 0.869918704032898)
[2024-12-17 02:34:02,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:02,622][root][INFO] - Training Epoch: 2/2, step 1834/7134 completed (loss: 0.17978182435035706, acc: 0.9615384340286255)
[2024-12-17 02:34:02,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:02,889][root][INFO] - Training Epoch: 2/2, step 1835/7134 completed (loss: 0.39555850625038147, acc: 0.9350649118423462)
[2024-12-17 02:34:02,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:03,166][root][INFO] - Training Epoch: 2/2, step 1836/7134 completed (loss: 0.25169989466667175, acc: 0.9304812550544739)
[2024-12-17 02:34:03,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:03,463][root][INFO] - Training Epoch: 2/2, step 1837/7134 completed (loss: 0.22956489026546478, acc: 0.9120879173278809)
[2024-12-17 02:34:03,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:03,744][root][INFO] - Training Epoch: 2/2, step 1838/7134 completed (loss: 0.17578235268592834, acc: 0.9541284441947937)
[2024-12-17 02:34:03,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:04,039][root][INFO] - Training Epoch: 2/2, step 1839/7134 completed (loss: 0.21410147845745087, acc: 0.9340659379959106)
[2024-12-17 02:34:04,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:04,334][root][INFO] - Training Epoch: 2/2, step 1840/7134 completed (loss: 0.36373984813690186, acc: 0.8860759735107422)
[2024-12-17 02:34:04,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:04,622][root][INFO] - Training Epoch: 2/2, step 1841/7134 completed (loss: 0.4328520894050598, acc: 0.8999999761581421)
[2024-12-17 02:34:04,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:04,933][root][INFO] - Training Epoch: 2/2, step 1842/7134 completed (loss: 0.2696392834186554, acc: 0.9390243887901306)
[2024-12-17 02:34:05,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:05,239][root][INFO] - Training Epoch: 2/2, step 1843/7134 completed (loss: 0.26399433612823486, acc: 0.9523809552192688)
[2024-12-17 02:34:05,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:05,549][root][INFO] - Training Epoch: 2/2, step 1844/7134 completed (loss: 0.1290903091430664, acc: 0.9716312289237976)
[2024-12-17 02:34:05,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:05,864][root][INFO] - Training Epoch: 2/2, step 1845/7134 completed (loss: 0.2503150701522827, acc: 0.9239130616188049)
[2024-12-17 02:34:05,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:06,148][root][INFO] - Training Epoch: 2/2, step 1846/7134 completed (loss: 0.3061211407184601, acc: 0.9294871687889099)
[2024-12-17 02:34:06,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:06,438][root][INFO] - Training Epoch: 2/2, step 1847/7134 completed (loss: 0.2742546796798706, acc: 0.9261363744735718)
[2024-12-17 02:34:06,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:06,738][root][INFO] - Training Epoch: 2/2, step 1848/7134 completed (loss: 0.3453863561153412, acc: 0.9042553305625916)
[2024-12-17 02:34:06,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:07,019][root][INFO] - Training Epoch: 2/2, step 1849/7134 completed (loss: 0.2010658085346222, acc: 0.9366196990013123)
[2024-12-17 02:34:07,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:07,303][root][INFO] - Training Epoch: 2/2, step 1850/7134 completed (loss: 0.35575175285339355, acc: 0.9175257682800293)
[2024-12-17 02:34:07,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:07,600][root][INFO] - Training Epoch: 2/2, step 1851/7134 completed (loss: 0.4009619653224945, acc: 0.928205132484436)
[2024-12-17 02:34:07,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:07,880][root][INFO] - Training Epoch: 2/2, step 1852/7134 completed (loss: 0.30638325214385986, acc: 0.9125000238418579)
[2024-12-17 02:34:08,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:08,168][root][INFO] - Training Epoch: 2/2, step 1853/7134 completed (loss: 0.22773736715316772, acc: 0.9396985173225403)
[2024-12-17 02:34:08,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:08,454][root][INFO] - Training Epoch: 2/2, step 1854/7134 completed (loss: 0.1931540071964264, acc: 0.9502262473106384)
[2024-12-17 02:34:08,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:08,746][root][INFO] - Training Epoch: 2/2, step 1855/7134 completed (loss: 0.2020455300807953, acc: 0.9431279897689819)
[2024-12-17 02:34:08,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:09,042][root][INFO] - Training Epoch: 2/2, step 1856/7134 completed (loss: 0.20145517587661743, acc: 0.954081654548645)
[2024-12-17 02:34:09,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:09,344][root][INFO] - Training Epoch: 2/2, step 1857/7134 completed (loss: 0.4272424578666687, acc: 0.8921568393707275)
[2024-12-17 02:34:09,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:09,634][root][INFO] - Training Epoch: 2/2, step 1858/7134 completed (loss: 0.18825475871562958, acc: 0.9489796161651611)
[2024-12-17 02:34:09,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:09,948][root][INFO] - Training Epoch: 2/2, step 1859/7134 completed (loss: 0.14284895360469818, acc: 0.9665071964263916)
[2024-12-17 02:34:10,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:10,284][root][INFO] - Training Epoch: 2/2, step 1860/7134 completed (loss: 0.17511487007141113, acc: 0.9453551769256592)
[2024-12-17 02:34:10,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:10,566][root][INFO] - Training Epoch: 2/2, step 1861/7134 completed (loss: 0.15830056369304657, acc: 0.9790576100349426)
[2024-12-17 02:34:10,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:10,856][root][INFO] - Training Epoch: 2/2, step 1862/7134 completed (loss: 0.1375865340232849, acc: 0.9629629850387573)
[2024-12-17 02:34:10,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:11,149][root][INFO] - Training Epoch: 2/2, step 1863/7134 completed (loss: 0.19049996137619019, acc: 0.9605911374092102)
[2024-12-17 02:34:11,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:11,456][root][INFO] - Training Epoch: 2/2, step 1864/7134 completed (loss: 0.6165531277656555, acc: 0.8883248567581177)
[2024-12-17 02:34:11,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:11,745][root][INFO] - Training Epoch: 2/2, step 1865/7134 completed (loss: 0.27437084913253784, acc: 0.9530201554298401)
[2024-12-17 02:34:11,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:12,020][root][INFO] - Training Epoch: 2/2, step 1866/7134 completed (loss: 0.11014457046985626, acc: 0.970588207244873)
[2024-12-17 02:34:12,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:12,308][root][INFO] - Training Epoch: 2/2, step 1867/7134 completed (loss: 0.10250843316316605, acc: 0.9829545617103577)
[2024-12-17 02:34:12,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:12,612][root][INFO] - Training Epoch: 2/2, step 1868/7134 completed (loss: 0.4011898934841156, acc: 0.9018405079841614)
[2024-12-17 02:34:12,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:12,894][root][INFO] - Training Epoch: 2/2, step 1869/7134 completed (loss: 0.25082626938819885, acc: 0.931506872177124)
[2024-12-17 02:34:13,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:13,173][root][INFO] - Training Epoch: 2/2, step 1870/7134 completed (loss: 0.1242414116859436, acc: 0.9675675630569458)
[2024-12-17 02:34:13,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:13,465][root][INFO] - Training Epoch: 2/2, step 1871/7134 completed (loss: 0.5017939209938049, acc: 0.9290322661399841)
[2024-12-17 02:34:13,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:13,749][root][INFO] - Training Epoch: 2/2, step 1872/7134 completed (loss: 2.270850658416748, acc: 0.5507246255874634)
[2024-12-17 02:34:13,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:14,043][root][INFO] - Training Epoch: 2/2, step 1873/7134 completed (loss: 0.7802688479423523, acc: 0.8677685856819153)
[2024-12-17 02:34:14,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:14,325][root][INFO] - Training Epoch: 2/2, step 1874/7134 completed (loss: 0.1675935685634613, acc: 0.9655172228813171)
[2024-12-17 02:34:14,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:14,588][root][INFO] - Training Epoch: 2/2, step 1875/7134 completed (loss: 0.12253917753696442, acc: 0.9464285969734192)
[2024-12-17 02:34:14,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:14,877][root][INFO] - Training Epoch: 2/2, step 1876/7134 completed (loss: 0.5934398174285889, acc: 0.8857142925262451)
[2024-12-17 02:34:15,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:15,161][root][INFO] - Training Epoch: 2/2, step 1877/7134 completed (loss: 0.2145499736070633, acc: 0.9378530979156494)
[2024-12-17 02:34:15,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:15,446][root][INFO] - Training Epoch: 2/2, step 1878/7134 completed (loss: 0.23978209495544434, acc: 0.9346405267715454)
[2024-12-17 02:34:15,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:15,726][root][INFO] - Training Epoch: 2/2, step 1879/7134 completed (loss: 0.6984348893165588, acc: 0.8395061492919922)
[2024-12-17 02:34:15,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:15,983][root][INFO] - Training Epoch: 2/2, step 1880/7134 completed (loss: 0.45161786675453186, acc: 0.9024389982223511)
[2024-12-17 02:34:16,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:16,269][root][INFO] - Training Epoch: 2/2, step 1881/7134 completed (loss: 0.46748125553131104, acc: 0.8661971688270569)
[2024-12-17 02:34:16,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:16,526][root][INFO] - Training Epoch: 2/2, step 1882/7134 completed (loss: 0.43577224016189575, acc: 0.9239130616188049)
[2024-12-17 02:34:16,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:16,803][root][INFO] - Training Epoch: 2/2, step 1883/7134 completed (loss: 0.30848100781440735, acc: 0.930232584476471)
[2024-12-17 02:34:16,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:17,075][root][INFO] - Training Epoch: 2/2, step 1884/7134 completed (loss: 0.3506383001804352, acc: 0.9054054021835327)
[2024-12-17 02:34:17,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:17,362][root][INFO] - Training Epoch: 2/2, step 1885/7134 completed (loss: 0.42161300778388977, acc: 0.8732394576072693)
[2024-12-17 02:34:17,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:17,651][root][INFO] - Training Epoch: 2/2, step 1886/7134 completed (loss: 0.5280858874320984, acc: 0.8888888955116272)
[2024-12-17 02:34:17,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:17,937][root][INFO] - Training Epoch: 2/2, step 1887/7134 completed (loss: 0.3991229236125946, acc: 0.9139072895050049)
[2024-12-17 02:34:18,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:18,237][root][INFO] - Training Epoch: 2/2, step 1888/7134 completed (loss: 0.28973880410194397, acc: 0.94017094373703)
[2024-12-17 02:34:18,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:18,570][root][INFO] - Training Epoch: 2/2, step 1889/7134 completed (loss: 0.22944281995296478, acc: 0.9590643048286438)
[2024-12-17 02:34:18,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:18,875][root][INFO] - Training Epoch: 2/2, step 1890/7134 completed (loss: 0.16511482000350952, acc: 0.9470198750495911)
[2024-12-17 02:34:19,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:19,174][root][INFO] - Training Epoch: 2/2, step 1891/7134 completed (loss: 0.4540148973464966, acc: 0.8779069781303406)
[2024-12-17 02:34:19,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:19,489][root][INFO] - Training Epoch: 2/2, step 1892/7134 completed (loss: 0.40272024273872375, acc: 0.8982036113739014)
[2024-12-17 02:34:19,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:19,779][root][INFO] - Training Epoch: 2/2, step 1893/7134 completed (loss: 0.33057352900505066, acc: 0.9012345671653748)
[2024-12-17 02:34:19,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:20,092][root][INFO] - Training Epoch: 2/2, step 1894/7134 completed (loss: 0.4051007926464081, acc: 0.8986486196517944)
[2024-12-17 02:34:20,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:20,366][root][INFO] - Training Epoch: 2/2, step 1895/7134 completed (loss: 1.2342103719711304, acc: 0.7865168452262878)
[2024-12-17 02:34:20,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:20,660][root][INFO] - Training Epoch: 2/2, step 1896/7134 completed (loss: 0.33304864168167114, acc: 0.8909090757369995)
[2024-12-17 02:34:20,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:20,958][root][INFO] - Training Epoch: 2/2, step 1897/7134 completed (loss: 0.30210596323013306, acc: 0.922535240650177)
[2024-12-17 02:34:21,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:21,240][root][INFO] - Training Epoch: 2/2, step 1898/7134 completed (loss: 0.30089452862739563, acc: 0.931034505367279)
[2024-12-17 02:34:21,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:21,515][root][INFO] - Training Epoch: 2/2, step 1899/7134 completed (loss: 0.24758757650852203, acc: 0.9545454382896423)
[2024-12-17 02:34:21,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:21,796][root][INFO] - Training Epoch: 2/2, step 1900/7134 completed (loss: 0.131678506731987, acc: 0.970588207244873)
[2024-12-17 02:34:21,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:22,089][root][INFO] - Training Epoch: 2/2, step 1901/7134 completed (loss: 0.3313596546649933, acc: 0.9280575513839722)
[2024-12-17 02:34:22,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:22,361][root][INFO] - Training Epoch: 2/2, step 1902/7134 completed (loss: 0.1633625626564026, acc: 0.9640287756919861)
[2024-12-17 02:34:22,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:22,655][root][INFO] - Training Epoch: 2/2, step 1903/7134 completed (loss: 0.1541706770658493, acc: 0.9607843160629272)
[2024-12-17 02:34:22,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:22,944][root][INFO] - Training Epoch: 2/2, step 1904/7134 completed (loss: 0.2599860429763794, acc: 0.9428571462631226)
[2024-12-17 02:34:23,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:23,228][root][INFO] - Training Epoch: 2/2, step 1905/7134 completed (loss: 0.41429373621940613, acc: 0.9290780425071716)
[2024-12-17 02:34:23,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:23,495][root][INFO] - Training Epoch: 2/2, step 1906/7134 completed (loss: 0.27332472801208496, acc: 0.9781022071838379)
[2024-12-17 02:34:23,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:23,782][root][INFO] - Training Epoch: 2/2, step 1907/7134 completed (loss: 0.34758034348487854, acc: 0.9319728016853333)
[2024-12-17 02:34:23,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:24,091][root][INFO] - Training Epoch: 2/2, step 1908/7134 completed (loss: 0.2049819678068161, acc: 0.9392523169517517)
[2024-12-17 02:34:24,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:24,383][root][INFO] - Training Epoch: 2/2, step 1909/7134 completed (loss: 0.2775743901729584, acc: 0.9234693646430969)
[2024-12-17 02:34:24,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:24,675][root][INFO] - Training Epoch: 2/2, step 1910/7134 completed (loss: 0.15492185950279236, acc: 0.9767441749572754)
[2024-12-17 02:34:24,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:24,963][root][INFO] - Training Epoch: 2/2, step 1911/7134 completed (loss: 0.11700282245874405, acc: 0.9695431590080261)
[2024-12-17 02:34:25,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:25,250][root][INFO] - Training Epoch: 2/2, step 1912/7134 completed (loss: 0.05467121675610542, acc: 0.9878787994384766)
[2024-12-17 02:34:25,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:25,526][root][INFO] - Training Epoch: 2/2, step 1913/7134 completed (loss: 0.3324417471885681, acc: 0.9370078444480896)
[2024-12-17 02:34:25,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:25,839][root][INFO] - Training Epoch: 2/2, step 1914/7134 completed (loss: 0.25654149055480957, acc: 0.9508196711540222)
[2024-12-17 02:34:25,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:26,124][root][INFO] - Training Epoch: 2/2, step 1915/7134 completed (loss: 0.16985376179218292, acc: 0.9720279574394226)
[2024-12-17 02:34:26,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:26,408][root][INFO] - Training Epoch: 2/2, step 1916/7134 completed (loss: 0.14030160009860992, acc: 0.9560439586639404)
[2024-12-17 02:34:26,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:26,695][root][INFO] - Training Epoch: 2/2, step 1917/7134 completed (loss: 0.2675573527812958, acc: 0.9515151381492615)
[2024-12-17 02:34:26,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:26,978][root][INFO] - Training Epoch: 2/2, step 1918/7134 completed (loss: 0.20915815234184265, acc: 0.9602649211883545)
[2024-12-17 02:34:27,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:27,278][root][INFO] - Training Epoch: 2/2, step 1919/7134 completed (loss: 0.16121862828731537, acc: 0.957317054271698)
[2024-12-17 02:34:27,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:27,550][root][INFO] - Training Epoch: 2/2, step 1920/7134 completed (loss: 0.17221282422542572, acc: 0.9591836929321289)
[2024-12-17 02:34:27,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:27,817][root][INFO] - Training Epoch: 2/2, step 1921/7134 completed (loss: 0.19002191722393036, acc: 0.9415204524993896)
[2024-12-17 02:34:27,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:28,108][root][INFO] - Training Epoch: 2/2, step 1922/7134 completed (loss: 0.10077152401208878, acc: 0.9754098653793335)
[2024-12-17 02:34:28,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:28,388][root][INFO] - Training Epoch: 2/2, step 1923/7134 completed (loss: 0.14228008687496185, acc: 0.9650349617004395)
[2024-12-17 02:34:28,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:28,664][root][INFO] - Training Epoch: 2/2, step 1924/7134 completed (loss: 0.22334684431552887, acc: 0.953125)
[2024-12-17 02:34:28,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:28,964][root][INFO] - Training Epoch: 2/2, step 1925/7134 completed (loss: 0.2935107946395874, acc: 0.9163179993629456)
[2024-12-17 02:34:29,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:29,252][root][INFO] - Training Epoch: 2/2, step 1926/7134 completed (loss: 0.05848117917776108, acc: 0.9821428656578064)
[2024-12-17 02:34:29,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:29,542][root][INFO] - Training Epoch: 2/2, step 1927/7134 completed (loss: 0.23629900813102722, acc: 0.9669811129570007)
[2024-12-17 02:34:29,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:29,835][root][INFO] - Training Epoch: 2/2, step 1928/7134 completed (loss: 0.23198752105236053, acc: 0.9285714030265808)
[2024-12-17 02:34:29,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:30,088][root][INFO] - Training Epoch: 2/2, step 1929/7134 completed (loss: 0.12116023898124695, acc: 0.9664804339408875)
[2024-12-17 02:34:30,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:30,381][root][INFO] - Training Epoch: 2/2, step 1930/7134 completed (loss: 0.41798773407936096, acc: 0.8743961453437805)
[2024-12-17 02:34:30,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:30,668][root][INFO] - Training Epoch: 2/2, step 1931/7134 completed (loss: 0.34509968757629395, acc: 0.9027777910232544)
[2024-12-17 02:34:30,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:30,962][root][INFO] - Training Epoch: 2/2, step 1932/7134 completed (loss: 0.31023865938186646, acc: 0.9273743033409119)
[2024-12-17 02:34:31,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:31,247][root][INFO] - Training Epoch: 2/2, step 1933/7134 completed (loss: 0.4222415089607239, acc: 0.8994975090026855)
[2024-12-17 02:34:31,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:31,524][root][INFO] - Training Epoch: 2/2, step 1934/7134 completed (loss: 0.2022668719291687, acc: 0.9314285516738892)
[2024-12-17 02:34:31,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:31,813][root][INFO] - Training Epoch: 2/2, step 1935/7134 completed (loss: 0.5261046290397644, acc: 0.8963414430618286)
[2024-12-17 02:34:31,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:32,109][root][INFO] - Training Epoch: 2/2, step 1936/7134 completed (loss: 0.11066733300685883, acc: 0.9607843160629272)
[2024-12-17 02:34:32,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:32,400][root][INFO] - Training Epoch: 2/2, step 1937/7134 completed (loss: 0.3147040009498596, acc: 0.9207317233085632)
[2024-12-17 02:34:32,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:32,702][root][INFO] - Training Epoch: 2/2, step 1938/7134 completed (loss: 0.5263717174530029, acc: 0.885869562625885)
[2024-12-17 02:34:32,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:33,003][root][INFO] - Training Epoch: 2/2, step 1939/7134 completed (loss: 0.1904015690088272, acc: 0.9396551847457886)
[2024-12-17 02:34:33,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:33,276][root][INFO] - Training Epoch: 2/2, step 1940/7134 completed (loss: 0.40530380606651306, acc: 0.916167676448822)
[2024-12-17 02:34:33,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:33,554][root][INFO] - Training Epoch: 2/2, step 1941/7134 completed (loss: 0.3315432369709015, acc: 0.8994082808494568)
[2024-12-17 02:34:33,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:33,833][root][INFO] - Training Epoch: 2/2, step 1942/7134 completed (loss: 0.2440221905708313, acc: 0.9444444179534912)
[2024-12-17 02:34:33,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:34,121][root][INFO] - Training Epoch: 2/2, step 1943/7134 completed (loss: 0.3979819416999817, acc: 0.8947368264198303)
[2024-12-17 02:34:34,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:34,397][root][INFO] - Training Epoch: 2/2, step 1944/7134 completed (loss: 0.23482251167297363, acc: 0.9262295365333557)
[2024-12-17 02:34:34,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:34,674][root][INFO] - Training Epoch: 2/2, step 1945/7134 completed (loss: 0.2430911511182785, acc: 0.9354838728904724)
[2024-12-17 02:34:34,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:34,954][root][INFO] - Training Epoch: 2/2, step 1946/7134 completed (loss: 0.21305689215660095, acc: 0.949999988079071)
[2024-12-17 02:34:35,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:35,235][root][INFO] - Training Epoch: 2/2, step 1947/7134 completed (loss: 0.2561887502670288, acc: 0.9364162087440491)
[2024-12-17 02:34:35,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:35,510][root][INFO] - Training Epoch: 2/2, step 1948/7134 completed (loss: 0.2051166445016861, acc: 0.9538461565971375)
[2024-12-17 02:34:35,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:35,821][root][INFO] - Training Epoch: 2/2, step 1949/7134 completed (loss: 0.22150549292564392, acc: 0.948051929473877)
[2024-12-17 02:34:35,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:36,130][root][INFO] - Training Epoch: 2/2, step 1950/7134 completed (loss: 0.14411771297454834, acc: 0.9637681245803833)
[2024-12-17 02:34:36,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:36,486][root][INFO] - Training Epoch: 2/2, step 1951/7134 completed (loss: 0.25249314308166504, acc: 0.9398496150970459)
[2024-12-17 02:34:36,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:36,782][root][INFO] - Training Epoch: 2/2, step 1952/7134 completed (loss: 0.25034600496292114, acc: 0.9397590160369873)
[2024-12-17 02:34:36,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:37,090][root][INFO] - Training Epoch: 2/2, step 1953/7134 completed (loss: 0.17729374766349792, acc: 0.9683544039726257)
[2024-12-17 02:34:37,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:37,392][root][INFO] - Training Epoch: 2/2, step 1954/7134 completed (loss: 0.08865642547607422, acc: 0.9901960492134094)
[2024-12-17 02:34:37,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:37,692][root][INFO] - Training Epoch: 2/2, step 1955/7134 completed (loss: 0.2786049544811249, acc: 0.9477611780166626)
[2024-12-17 02:34:37,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:37,991][root][INFO] - Training Epoch: 2/2, step 1956/7134 completed (loss: 0.09399255365133286, acc: 0.97826087474823)
[2024-12-17 02:34:38,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:38,295][root][INFO] - Training Epoch: 2/2, step 1957/7134 completed (loss: 0.24994944036006927, acc: 0.9248120188713074)
[2024-12-17 02:34:38,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:38,584][root][INFO] - Training Epoch: 2/2, step 1958/7134 completed (loss: 0.28618746995925903, acc: 0.9333333373069763)
[2024-12-17 02:34:38,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:38,862][root][INFO] - Training Epoch: 2/2, step 1959/7134 completed (loss: 0.3030095100402832, acc: 0.9196428656578064)
[2024-12-17 02:34:38,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:39,144][root][INFO] - Training Epoch: 2/2, step 1960/7134 completed (loss: 0.14750462770462036, acc: 0.9583333134651184)
[2024-12-17 02:34:39,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:39,434][root][INFO] - Training Epoch: 2/2, step 1961/7134 completed (loss: 0.26458340883255005, acc: 0.9113923907279968)
[2024-12-17 02:34:39,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:39,733][root][INFO] - Training Epoch: 2/2, step 1962/7134 completed (loss: 0.16830940544605255, acc: 0.954023003578186)
[2024-12-17 02:34:39,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:40,069][root][INFO] - Training Epoch: 2/2, step 1963/7134 completed (loss: 0.36852383613586426, acc: 0.9205297827720642)
[2024-12-17 02:34:40,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:40,361][root][INFO] - Training Epoch: 2/2, step 1964/7134 completed (loss: 0.33148327469825745, acc: 0.9343434572219849)
[2024-12-17 02:34:40,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:40,652][root][INFO] - Training Epoch: 2/2, step 1965/7134 completed (loss: 0.37037724256515503, acc: 0.9213483333587646)
[2024-12-17 02:34:40,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:40,944][root][INFO] - Training Epoch: 2/2, step 1966/7134 completed (loss: 0.3905104994773865, acc: 0.9108280539512634)
[2024-12-17 02:34:41,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:41,234][root][INFO] - Training Epoch: 2/2, step 1967/7134 completed (loss: 0.17836610972881317, acc: 0.942105233669281)
[2024-12-17 02:34:41,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:41,520][root][INFO] - Training Epoch: 2/2, step 1968/7134 completed (loss: 0.19072113931179047, acc: 0.9468085169792175)
[2024-12-17 02:34:41,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:41,796][root][INFO] - Training Epoch: 2/2, step 1969/7134 completed (loss: 0.20721200108528137, acc: 0.9322034120559692)
[2024-12-17 02:34:41,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:42,086][root][INFO] - Training Epoch: 2/2, step 1970/7134 completed (loss: 0.2844657301902771, acc: 0.9230769276618958)
[2024-12-17 02:34:42,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:42,362][root][INFO] - Training Epoch: 2/2, step 1971/7134 completed (loss: 0.454243928194046, acc: 0.9162303805351257)
[2024-12-17 02:34:42,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:42,684][root][INFO] - Training Epoch: 2/2, step 1972/7134 completed (loss: 0.8875241875648499, acc: 0.7894737124443054)
[2024-12-17 02:34:42,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:42,969][root][INFO] - Training Epoch: 2/2, step 1973/7134 completed (loss: 0.956547200679779, acc: 0.8194444179534912)
[2024-12-17 02:34:43,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:43,274][root][INFO] - Training Epoch: 2/2, step 1974/7134 completed (loss: 0.21227383613586426, acc: 0.9432989954948425)
[2024-12-17 02:34:43,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:43,575][root][INFO] - Training Epoch: 2/2, step 1975/7134 completed (loss: 0.17606155574321747, acc: 0.956250011920929)
[2024-12-17 02:34:43,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:43,893][root][INFO] - Training Epoch: 2/2, step 1976/7134 completed (loss: 0.38766512274742126, acc: 0.9182692170143127)
[2024-12-17 02:34:44,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:44,184][root][INFO] - Training Epoch: 2/2, step 1977/7134 completed (loss: 0.35248002409935, acc: 0.9221556782722473)
[2024-12-17 02:34:44,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:44,460][root][INFO] - Training Epoch: 2/2, step 1978/7134 completed (loss: 0.06381423771381378, acc: 0.9941860437393188)
[2024-12-17 02:34:44,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:44,750][root][INFO] - Training Epoch: 2/2, step 1979/7134 completed (loss: 0.20257341861724854, acc: 0.9395604133605957)
[2024-12-17 02:34:44,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:45,041][root][INFO] - Training Epoch: 2/2, step 1980/7134 completed (loss: 0.2280898243188858, acc: 0.9685863852500916)
[2024-12-17 02:34:45,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:45,332][root][INFO] - Training Epoch: 2/2, step 1981/7134 completed (loss: 0.16618776321411133, acc: 0.9725274443626404)
[2024-12-17 02:34:45,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:45,613][root][INFO] - Training Epoch: 2/2, step 1982/7134 completed (loss: 0.1861376315355301, acc: 0.9487179517745972)
[2024-12-17 02:34:45,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:45,904][root][INFO] - Training Epoch: 2/2, step 1983/7134 completed (loss: 0.1782691329717636, acc: 0.9731183052062988)
[2024-12-17 02:34:46,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:46,192][root][INFO] - Training Epoch: 2/2, step 1984/7134 completed (loss: 0.20727194845676422, acc: 0.9534883499145508)
[2024-12-17 02:34:46,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:46,461][root][INFO] - Training Epoch: 2/2, step 1985/7134 completed (loss: 0.31014615297317505, acc: 0.9254658222198486)
[2024-12-17 02:34:46,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:46,736][root][INFO] - Training Epoch: 2/2, step 1986/7134 completed (loss: 0.12479507923126221, acc: 0.9608938694000244)
[2024-12-17 02:34:46,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:47,025][root][INFO] - Training Epoch: 2/2, step 1987/7134 completed (loss: 0.14731517434120178, acc: 0.949438214302063)
[2024-12-17 02:34:47,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:47,322][root][INFO] - Training Epoch: 2/2, step 1988/7134 completed (loss: 0.18479101359844208, acc: 0.9696969985961914)
[2024-12-17 02:34:47,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:47,605][root][INFO] - Training Epoch: 2/2, step 1989/7134 completed (loss: 0.34252652525901794, acc: 0.9178082346916199)
[2024-12-17 02:34:47,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:47,891][root][INFO] - Training Epoch: 2/2, step 1990/7134 completed (loss: 0.20332030951976776, acc: 0.9558011293411255)
[2024-12-17 02:34:48,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:48,181][root][INFO] - Training Epoch: 2/2, step 1991/7134 completed (loss: 0.08695201575756073, acc: 0.9838709831237793)
[2024-12-17 02:34:48,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:48,467][root][INFO] - Training Epoch: 2/2, step 1992/7134 completed (loss: 0.3746241629123688, acc: 0.8695651888847351)
[2024-12-17 02:34:48,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:48,751][root][INFO] - Training Epoch: 2/2, step 1993/7134 completed (loss: 0.22753213346004486, acc: 0.95652174949646)
[2024-12-17 02:34:48,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:49,038][root][INFO] - Training Epoch: 2/2, step 1994/7134 completed (loss: 0.13465134799480438, acc: 0.9534883499145508)
[2024-12-17 02:34:49,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:49,326][root][INFO] - Training Epoch: 2/2, step 1995/7134 completed (loss: 0.10285796225070953, acc: 0.9793103337287903)
[2024-12-17 02:34:49,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:49,603][root][INFO] - Training Epoch: 2/2, step 1996/7134 completed (loss: 0.16767160594463348, acc: 0.9489051103591919)
[2024-12-17 02:34:49,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:49,890][root][INFO] - Training Epoch: 2/2, step 1997/7134 completed (loss: 0.23726820945739746, acc: 0.9428571462631226)
[2024-12-17 02:34:50,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:50,173][root][INFO] - Training Epoch: 2/2, step 1998/7134 completed (loss: 0.1691051870584488, acc: 0.9577465057373047)
[2024-12-17 02:34:50,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:50,478][root][INFO] - Training Epoch: 2/2, step 1999/7134 completed (loss: 0.1833869367837906, acc: 0.9580419659614563)
[2024-12-17 02:34:50,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:50,769][root][INFO] - Training Epoch: 2/2, step 2000/7134 completed (loss: 0.16496628522872925, acc: 0.9375)
[2024-12-17 02:34:50,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:51,032][root][INFO] - Training Epoch: 2/2, step 2001/7134 completed (loss: 0.11960110813379288, acc: 0.9862068891525269)
[2024-12-17 02:34:51,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:51,333][root][INFO] - Training Epoch: 2/2, step 2002/7134 completed (loss: 0.25106337666511536, acc: 0.9473684430122375)
[2024-12-17 02:34:51,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:51,633][root][INFO] - Training Epoch: 2/2, step 2003/7134 completed (loss: 0.1140066608786583, acc: 0.9824561476707458)
[2024-12-17 02:34:51,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:51,924][root][INFO] - Training Epoch: 2/2, step 2004/7134 completed (loss: 0.8580236434936523, acc: 0.8606557250022888)
[2024-12-17 02:34:52,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:52,283][root][INFO] - Training Epoch: 2/2, step 2005/7134 completed (loss: 0.5488682985305786, acc: 0.8877550959587097)
[2024-12-17 02:34:52,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:52,560][root][INFO] - Training Epoch: 2/2, step 2006/7134 completed (loss: 0.15925215184688568, acc: 0.9534883499145508)
[2024-12-17 02:34:52,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:52,841][root][INFO] - Training Epoch: 2/2, step 2007/7134 completed (loss: 0.08870326727628708, acc: 0.9663865566253662)
[2024-12-17 02:34:52,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:53,126][root][INFO] - Training Epoch: 2/2, step 2008/7134 completed (loss: 0.1928461343050003, acc: 0.9452054500579834)
[2024-12-17 02:34:53,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:53,419][root][INFO] - Training Epoch: 2/2, step 2009/7134 completed (loss: 0.15209829807281494, acc: 0.9407407641410828)
[2024-12-17 02:34:53,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:53,716][root][INFO] - Training Epoch: 2/2, step 2010/7134 completed (loss: 0.17313295602798462, acc: 0.9489051103591919)
[2024-12-17 02:34:53,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:53,982][root][INFO] - Training Epoch: 2/2, step 2011/7134 completed (loss: 0.09108920395374298, acc: 0.9841269850730896)
[2024-12-17 02:34:54,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:54,295][root][INFO] - Training Epoch: 2/2, step 2012/7134 completed (loss: 0.22683916985988617, acc: 0.9576271176338196)
[2024-12-17 02:34:54,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:54,610][root][INFO] - Training Epoch: 2/2, step 2013/7134 completed (loss: 0.18185065686702728, acc: 0.9508196711540222)
[2024-12-17 02:34:54,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:54,910][root][INFO] - Training Epoch: 2/2, step 2014/7134 completed (loss: 0.14061829447746277, acc: 0.9567901492118835)
[2024-12-17 02:34:55,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:55,197][root][INFO] - Training Epoch: 2/2, step 2015/7134 completed (loss: 0.07487387955188751, acc: 0.9750000238418579)
[2024-12-17 02:34:55,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:55,477][root][INFO] - Training Epoch: 2/2, step 2016/7134 completed (loss: 0.24932585656642914, acc: 0.9387755393981934)
[2024-12-17 02:34:55,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:55,758][root][INFO] - Training Epoch: 2/2, step 2017/7134 completed (loss: 0.2853543758392334, acc: 0.9139072895050049)
[2024-12-17 02:34:55,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:56,055][root][INFO] - Training Epoch: 2/2, step 2018/7134 completed (loss: 0.08320141583681107, acc: 0.9794520735740662)
[2024-12-17 02:34:56,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:56,341][root][INFO] - Training Epoch: 2/2, step 2019/7134 completed (loss: 0.1339317411184311, acc: 0.9668874144554138)
[2024-12-17 02:34:56,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:56,625][root][INFO] - Training Epoch: 2/2, step 2020/7134 completed (loss: 0.18795274198055267, acc: 0.9504132270812988)
[2024-12-17 02:34:56,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:56,922][root][INFO] - Training Epoch: 2/2, step 2021/7134 completed (loss: 0.27829092741012573, acc: 0.9243243336677551)
[2024-12-17 02:34:57,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:57,182][root][INFO] - Training Epoch: 2/2, step 2022/7134 completed (loss: 0.28873389959335327, acc: 0.9477611780166626)
[2024-12-17 02:34:57,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:57,458][root][INFO] - Training Epoch: 2/2, step 2023/7134 completed (loss: 0.14352351427078247, acc: 0.9447852969169617)
[2024-12-17 02:34:57,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:57,759][root][INFO] - Training Epoch: 2/2, step 2024/7134 completed (loss: 0.17708373069763184, acc: 0.9534883499145508)
[2024-12-17 02:34:57,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:58,054][root][INFO] - Training Epoch: 2/2, step 2025/7134 completed (loss: 0.17591296136379242, acc: 0.9707602262496948)
[2024-12-17 02:34:58,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:58,345][root][INFO] - Training Epoch: 2/2, step 2026/7134 completed (loss: 0.14961768686771393, acc: 0.9707602262496948)
[2024-12-17 02:34:58,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:58,628][root][INFO] - Training Epoch: 2/2, step 2027/7134 completed (loss: 0.16299386322498322, acc: 0.9624060392379761)
[2024-12-17 02:34:58,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:58,909][root][INFO] - Training Epoch: 2/2, step 2028/7134 completed (loss: 0.22705647349357605, acc: 0.9570552110671997)
[2024-12-17 02:34:59,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:59,187][root][INFO] - Training Epoch: 2/2, step 2029/7134 completed (loss: 0.22055621445178986, acc: 0.9235293865203857)
[2024-12-17 02:34:59,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:59,474][root][INFO] - Training Epoch: 2/2, step 2030/7134 completed (loss: 0.23691622912883759, acc: 0.9277108311653137)
[2024-12-17 02:34:59,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:59,780][root][INFO] - Training Epoch: 2/2, step 2031/7134 completed (loss: 0.11449246108531952, acc: 0.9779005646705627)
[2024-12-17 02:34:59,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:00,080][root][INFO] - Training Epoch: 2/2, step 2032/7134 completed (loss: 0.2683873176574707, acc: 0.9298245906829834)
[2024-12-17 02:35:00,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:00,380][root][INFO] - Training Epoch: 2/2, step 2033/7134 completed (loss: 0.1218888908624649, acc: 0.9694656729698181)
[2024-12-17 02:35:00,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:00,666][root][INFO] - Training Epoch: 2/2, step 2034/7134 completed (loss: 0.3792913854122162, acc: 0.9194630980491638)
[2024-12-17 02:35:00,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:00,959][root][INFO] - Training Epoch: 2/2, step 2035/7134 completed (loss: 0.14754602313041687, acc: 0.9569892287254333)
[2024-12-17 02:35:01,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:01,250][root][INFO] - Training Epoch: 2/2, step 2036/7134 completed (loss: 0.16431878507137299, acc: 0.9541984796524048)
[2024-12-17 02:35:01,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:01,540][root][INFO] - Training Epoch: 2/2, step 2037/7134 completed (loss: 0.12329968810081482, acc: 0.9570552110671997)
[2024-12-17 02:35:01,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:01,830][root][INFO] - Training Epoch: 2/2, step 2038/7134 completed (loss: 0.09132913500070572, acc: 0.9835164546966553)
[2024-12-17 02:35:01,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:02,138][root][INFO] - Training Epoch: 2/2, step 2039/7134 completed (loss: 0.1458764225244522, acc: 0.9489051103591919)
[2024-12-17 02:35:02,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:02,419][root][INFO] - Training Epoch: 2/2, step 2040/7134 completed (loss: 0.2374923676252365, acc: 0.9741379022598267)
[2024-12-17 02:35:02,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:02,700][root][INFO] - Training Epoch: 2/2, step 2041/7134 completed (loss: 0.1501431167125702, acc: 0.9636363387107849)
[2024-12-17 02:35:02,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:03,020][root][INFO] - Training Epoch: 2/2, step 2042/7134 completed (loss: 0.25729724764823914, acc: 0.9576271176338196)
[2024-12-17 02:35:03,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:03,321][root][INFO] - Training Epoch: 2/2, step 2043/7134 completed (loss: 0.0749063715338707, acc: 0.9865771532058716)
[2024-12-17 02:35:03,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:03,664][root][INFO] - Training Epoch: 2/2, step 2044/7134 completed (loss: 0.10899428278207779, acc: 0.9679999947547913)
[2024-12-17 02:35:03,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:03,940][root][INFO] - Training Epoch: 2/2, step 2045/7134 completed (loss: 0.1837165802717209, acc: 0.9583333134651184)
[2024-12-17 02:35:04,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:04,204][root][INFO] - Training Epoch: 2/2, step 2046/7134 completed (loss: 0.26945027709007263, acc: 0.9327731132507324)
[2024-12-17 02:35:04,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:04,498][root][INFO] - Training Epoch: 2/2, step 2047/7134 completed (loss: 0.2920578122138977, acc: 0.9034482836723328)
[2024-12-17 02:35:04,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:04,789][root][INFO] - Training Epoch: 2/2, step 2048/7134 completed (loss: 0.34205928444862366, acc: 0.9047619104385376)
[2024-12-17 02:35:04,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:05,067][root][INFO] - Training Epoch: 2/2, step 2049/7134 completed (loss: 0.3362049460411072, acc: 0.918181836605072)
[2024-12-17 02:35:05,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:05,335][root][INFO] - Training Epoch: 2/2, step 2050/7134 completed (loss: 0.24242907762527466, acc: 0.9383561611175537)
[2024-12-17 02:35:05,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:05,619][root][INFO] - Training Epoch: 2/2, step 2051/7134 completed (loss: 0.24183593690395355, acc: 0.9380530714988708)
[2024-12-17 02:35:05,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:05,909][root][INFO] - Training Epoch: 2/2, step 2052/7134 completed (loss: 0.4955335855484009, acc: 0.9166666865348816)
[2024-12-17 02:35:06,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:06,227][root][INFO] - Training Epoch: 2/2, step 2053/7134 completed (loss: 0.39270690083503723, acc: 0.9236640930175781)
[2024-12-17 02:35:06,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:06,529][root][INFO] - Training Epoch: 2/2, step 2054/7134 completed (loss: 0.4362960159778595, acc: 0.8974359035491943)
[2024-12-17 02:35:06,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:06,824][root][INFO] - Training Epoch: 2/2, step 2055/7134 completed (loss: 0.48041361570358276, acc: 0.8972602486610413)
[2024-12-17 02:35:06,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:07,124][root][INFO] - Training Epoch: 2/2, step 2056/7134 completed (loss: 0.36124226450920105, acc: 0.8983050584793091)
[2024-12-17 02:35:07,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:07,421][root][INFO] - Training Epoch: 2/2, step 2057/7134 completed (loss: 0.31873664259910583, acc: 0.9269663095474243)
[2024-12-17 02:35:07,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:07,707][root][INFO] - Training Epoch: 2/2, step 2058/7134 completed (loss: 0.4471818208694458, acc: 0.8901734352111816)
[2024-12-17 02:35:07,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:07,995][root][INFO] - Training Epoch: 2/2, step 2059/7134 completed (loss: 0.5944167971611023, acc: 0.8581560254096985)
[2024-12-17 02:35:08,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:08,288][root][INFO] - Training Epoch: 2/2, step 2060/7134 completed (loss: 0.283563494682312, acc: 0.9426751732826233)
[2024-12-17 02:35:08,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:08,582][root][INFO] - Training Epoch: 2/2, step 2061/7134 completed (loss: 0.3604958653450012, acc: 0.9047619104385376)
[2024-12-17 02:35:08,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:08,909][root][INFO] - Training Epoch: 2/2, step 2062/7134 completed (loss: 0.42292746901512146, acc: 0.8828125)
[2024-12-17 02:35:09,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:09,187][root][INFO] - Training Epoch: 2/2, step 2063/7134 completed (loss: 0.3025391697883606, acc: 0.9219858050346375)
[2024-12-17 02:35:09,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:09,478][root][INFO] - Training Epoch: 2/2, step 2064/7134 completed (loss: 0.27822649478912354, acc: 0.9558823704719543)
[2024-12-17 02:35:09,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:09,779][root][INFO] - Training Epoch: 2/2, step 2065/7134 completed (loss: 0.2621583342552185, acc: 0.9428571462631226)
[2024-12-17 02:35:09,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:10,076][root][INFO] - Training Epoch: 2/2, step 2066/7134 completed (loss: 0.1657206416130066, acc: 0.9512194991111755)
[2024-12-17 02:35:10,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:10,380][root][INFO] - Training Epoch: 2/2, step 2067/7134 completed (loss: 0.23261131346225739, acc: 0.9166666865348816)
[2024-12-17 02:35:10,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:10,683][root][INFO] - Training Epoch: 2/2, step 2068/7134 completed (loss: 0.30832982063293457, acc: 0.9117646813392639)
[2024-12-17 02:35:10,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:11,007][root][INFO] - Training Epoch: 2/2, step 2069/7134 completed (loss: 0.16736362874507904, acc: 0.9597315192222595)
[2024-12-17 02:35:11,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:11,313][root][INFO] - Training Epoch: 2/2, step 2070/7134 completed (loss: 0.11741533130407333, acc: 0.9655172228813171)
[2024-12-17 02:35:11,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:11,614][root][INFO] - Training Epoch: 2/2, step 2071/7134 completed (loss: 0.12243115156888962, acc: 0.9708737730979919)
[2024-12-17 02:35:11,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:11,881][root][INFO] - Training Epoch: 2/2, step 2072/7134 completed (loss: 0.19650566577911377, acc: 0.9509803652763367)
[2024-12-17 02:35:11,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:12,137][root][INFO] - Training Epoch: 2/2, step 2073/7134 completed (loss: 0.18910221755504608, acc: 0.9669421315193176)
[2024-12-17 02:35:12,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:12,433][root][INFO] - Training Epoch: 2/2, step 2074/7134 completed (loss: 0.28228986263275146, acc: 0.9371727705001831)
[2024-12-17 02:35:12,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:12,737][root][INFO] - Training Epoch: 2/2, step 2075/7134 completed (loss: 0.41465020179748535, acc: 0.8993710875511169)
[2024-12-17 02:35:12,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:13,022][root][INFO] - Training Epoch: 2/2, step 2076/7134 completed (loss: 0.14556656777858734, acc: 0.9795918464660645)
[2024-12-17 02:35:13,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:13,321][root][INFO] - Training Epoch: 2/2, step 2077/7134 completed (loss: 0.29161080718040466, acc: 0.9491525292396545)
[2024-12-17 02:35:13,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:13,615][root][INFO] - Training Epoch: 2/2, step 2078/7134 completed (loss: 0.2457905113697052, acc: 0.9796954393386841)
[2024-12-17 02:35:13,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:13,899][root][INFO] - Training Epoch: 2/2, step 2079/7134 completed (loss: 0.10081809759140015, acc: 0.9638554453849792)
[2024-12-17 02:35:14,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:14,174][root][INFO] - Training Epoch: 2/2, step 2080/7134 completed (loss: 0.22091144323349, acc: 0.9411764740943909)
[2024-12-17 02:35:14,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:14,458][root][INFO] - Training Epoch: 2/2, step 2081/7134 completed (loss: 0.11845041066408157, acc: 0.9745222926139832)
[2024-12-17 02:35:14,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:14,768][root][INFO] - Training Epoch: 2/2, step 2082/7134 completed (loss: 0.4473857283592224, acc: 0.8813559412956238)
[2024-12-17 02:35:14,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:15,048][root][INFO] - Training Epoch: 2/2, step 2083/7134 completed (loss: 0.20867832005023956, acc: 0.961240291595459)
[2024-12-17 02:35:15,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:15,356][root][INFO] - Training Epoch: 2/2, step 2084/7134 completed (loss: 0.17233309149742126, acc: 0.9333333373069763)
[2024-12-17 02:35:15,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:15,674][root][INFO] - Training Epoch: 2/2, step 2085/7134 completed (loss: 0.07508877664804459, acc: 0.9837398529052734)
[2024-12-17 02:35:15,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:15,941][root][INFO] - Training Epoch: 2/2, step 2086/7134 completed (loss: 0.141815647482872, acc: 0.970588207244873)
[2024-12-17 02:35:16,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:16,236][root][INFO] - Training Epoch: 2/2, step 2087/7134 completed (loss: 0.09566978365182877, acc: 0.9702380895614624)
[2024-12-17 02:35:16,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:16,520][root][INFO] - Training Epoch: 2/2, step 2088/7134 completed (loss: 0.2750346064567566, acc: 0.9526627063751221)
[2024-12-17 02:35:16,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:16,811][root][INFO] - Training Epoch: 2/2, step 2089/7134 completed (loss: 0.29582858085632324, acc: 0.9345238208770752)
[2024-12-17 02:35:16,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:17,075][root][INFO] - Training Epoch: 2/2, step 2090/7134 completed (loss: 0.1000923439860344, acc: 0.9803921580314636)
[2024-12-17 02:35:17,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:17,357][root][INFO] - Training Epoch: 2/2, step 2091/7134 completed (loss: 0.055781278759241104, acc: 0.9862068891525269)
[2024-12-17 02:35:17,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:17,672][root][INFO] - Training Epoch: 2/2, step 2092/7134 completed (loss: 0.09340939670801163, acc: 0.9801324605941772)
[2024-12-17 02:35:17,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:17,977][root][INFO] - Training Epoch: 2/2, step 2093/7134 completed (loss: 0.1452208012342453, acc: 0.9684210419654846)
[2024-12-17 02:35:18,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:18,262][root][INFO] - Training Epoch: 2/2, step 2094/7134 completed (loss: 0.16430450975894928, acc: 0.9477611780166626)
[2024-12-17 02:35:18,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:18,564][root][INFO] - Training Epoch: 2/2, step 2095/7134 completed (loss: 0.23018960654735565, acc: 0.9402984976768494)
[2024-12-17 02:35:18,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:18,844][root][INFO] - Training Epoch: 2/2, step 2096/7134 completed (loss: 0.12621714174747467, acc: 0.9580419659614563)
[2024-12-17 02:35:18,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:19,121][root][INFO] - Training Epoch: 2/2, step 2097/7134 completed (loss: 0.09487847238779068, acc: 0.9638554453849792)
[2024-12-17 02:35:19,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:19,398][root][INFO] - Training Epoch: 2/2, step 2098/7134 completed (loss: 0.1841944307088852, acc: 0.9473684430122375)
[2024-12-17 02:35:19,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:19,689][root][INFO] - Training Epoch: 2/2, step 2099/7134 completed (loss: 0.16527487337589264, acc: 0.96875)
[2024-12-17 02:35:19,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:19,987][root][INFO] - Training Epoch: 2/2, step 2100/7134 completed (loss: 0.20523475110530853, acc: 0.9599999785423279)
[2024-12-17 02:35:20,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:20,270][root][INFO] - Training Epoch: 2/2, step 2101/7134 completed (loss: 0.18050222098827362, acc: 0.9404761791229248)
[2024-12-17 02:35:20,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:20,554][root][INFO] - Training Epoch: 2/2, step 2102/7134 completed (loss: 0.13784755766391754, acc: 0.9675675630569458)
[2024-12-17 02:35:20,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:20,844][root][INFO] - Training Epoch: 2/2, step 2103/7134 completed (loss: 0.13926532864570618, acc: 0.9624999761581421)
[2024-12-17 02:35:20,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:21,137][root][INFO] - Training Epoch: 2/2, step 2104/7134 completed (loss: 0.08747651427984238, acc: 0.9714285731315613)
[2024-12-17 02:35:21,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:21,416][root][INFO] - Training Epoch: 2/2, step 2105/7134 completed (loss: 0.11047624796628952, acc: 0.978723406791687)
[2024-12-17 02:35:21,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:21,684][root][INFO] - Training Epoch: 2/2, step 2106/7134 completed (loss: 0.2048034518957138, acc: 0.9473684430122375)
[2024-12-17 02:35:21,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:21,969][root][INFO] - Training Epoch: 2/2, step 2107/7134 completed (loss: 0.17368337512016296, acc: 0.9668508172035217)
[2024-12-17 02:35:22,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:22,273][root][INFO] - Training Epoch: 2/2, step 2108/7134 completed (loss: 0.1988016963005066, acc: 0.9440993666648865)
[2024-12-17 02:35:22,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:22,557][root][INFO] - Training Epoch: 2/2, step 2109/7134 completed (loss: 0.18839871883392334, acc: 0.95652174949646)
[2024-12-17 02:35:22,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:22,884][root][INFO] - Training Epoch: 2/2, step 2110/7134 completed (loss: 0.2850817143917084, acc: 0.916167676448822)
[2024-12-17 02:35:23,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:23,208][root][INFO] - Training Epoch: 2/2, step 2111/7134 completed (loss: 0.30097129940986633, acc: 0.9378238320350647)
[2024-12-17 02:35:23,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:23,500][root][INFO] - Training Epoch: 2/2, step 2112/7134 completed (loss: 0.17022167146205902, acc: 0.9599999785423279)
[2024-12-17 02:35:23,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:23,805][root][INFO] - Training Epoch: 2/2, step 2113/7134 completed (loss: 0.17064237594604492, acc: 0.95333331823349)
[2024-12-17 02:35:23,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:24,109][root][INFO] - Training Epoch: 2/2, step 2114/7134 completed (loss: 0.21027453243732452, acc: 0.9526627063751221)
[2024-12-17 02:35:24,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:24,401][root][INFO] - Training Epoch: 2/2, step 2115/7134 completed (loss: 0.2468147724866867, acc: 0.9137930870056152)
[2024-12-17 02:35:24,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:24,693][root][INFO] - Training Epoch: 2/2, step 2116/7134 completed (loss: 0.2249005138874054, acc: 0.9455782175064087)
[2024-12-17 02:35:24,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:24,979][root][INFO] - Training Epoch: 2/2, step 2117/7134 completed (loss: 0.28611478209495544, acc: 0.9435028433799744)
[2024-12-17 02:35:25,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:25,261][root][INFO] - Training Epoch: 2/2, step 2118/7134 completed (loss: 0.15961863100528717, acc: 0.9467455744743347)
[2024-12-17 02:35:25,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:25,545][root][INFO] - Training Epoch: 2/2, step 2119/7134 completed (loss: 0.19022506475448608, acc: 0.9537572264671326)
[2024-12-17 02:35:25,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:25,817][root][INFO] - Training Epoch: 2/2, step 2120/7134 completed (loss: 0.18804658949375153, acc: 0.9444444179534912)
[2024-12-17 02:35:25,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:26,073][root][INFO] - Training Epoch: 2/2, step 2121/7134 completed (loss: 0.29783332347869873, acc: 0.9395973086357117)
[2024-12-17 02:35:26,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:26,370][root][INFO] - Training Epoch: 2/2, step 2122/7134 completed (loss: 0.18913820385932922, acc: 0.9548022747039795)
[2024-12-17 02:35:26,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:26,657][root][INFO] - Training Epoch: 2/2, step 2123/7134 completed (loss: 0.25342005491256714, acc: 0.9539473652839661)
[2024-12-17 02:35:26,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:26,933][root][INFO] - Training Epoch: 2/2, step 2124/7134 completed (loss: 0.18106934428215027, acc: 0.9324324131011963)
[2024-12-17 02:35:27,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:27,244][root][INFO] - Training Epoch: 2/2, step 2125/7134 completed (loss: 0.10234102606773376, acc: 0.9820359349250793)
[2024-12-17 02:35:27,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:27,535][root][INFO] - Training Epoch: 2/2, step 2126/7134 completed (loss: 0.24860753118991852, acc: 0.936170220375061)
[2024-12-17 02:35:27,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:27,813][root][INFO] - Training Epoch: 2/2, step 2127/7134 completed (loss: 0.1385582834482193, acc: 0.9578313231468201)
[2024-12-17 02:35:27,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:28,106][root][INFO] - Training Epoch: 2/2, step 2128/7134 completed (loss: 0.1354166716337204, acc: 0.9555555582046509)
[2024-12-17 02:35:28,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:28,395][root][INFO] - Training Epoch: 2/2, step 2129/7134 completed (loss: 0.20841063559055328, acc: 0.9526627063751221)
[2024-12-17 02:35:28,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:28,673][root][INFO] - Training Epoch: 2/2, step 2130/7134 completed (loss: 0.251038521528244, acc: 0.9324324131011963)
[2024-12-17 02:35:28,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:28,972][root][INFO] - Training Epoch: 2/2, step 2131/7134 completed (loss: 0.11341532319784164, acc: 0.9754601120948792)
[2024-12-17 02:35:29,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:29,251][root][INFO] - Training Epoch: 2/2, step 2132/7134 completed (loss: 0.0636100247502327, acc: 0.9878048896789551)
[2024-12-17 02:35:29,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:29,526][root][INFO] - Training Epoch: 2/2, step 2133/7134 completed (loss: 0.17862379550933838, acc: 0.9590643048286438)
[2024-12-17 02:35:29,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:29,812][root][INFO] - Training Epoch: 2/2, step 2134/7134 completed (loss: 0.15815627574920654, acc: 0.954023003578186)
[2024-12-17 02:35:29,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:30,096][root][INFO] - Training Epoch: 2/2, step 2135/7134 completed (loss: 0.06537804007530212, acc: 0.9933775067329407)
[2024-12-17 02:35:30,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:30,387][root][INFO] - Training Epoch: 2/2, step 2136/7134 completed (loss: 0.11784759908914566, acc: 0.9615384340286255)
[2024-12-17 02:35:30,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:30,678][root][INFO] - Training Epoch: 2/2, step 2137/7134 completed (loss: 0.18991906940937042, acc: 0.9521276354789734)
[2024-12-17 02:35:30,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:30,956][root][INFO] - Training Epoch: 2/2, step 2138/7134 completed (loss: 0.08343219012022018, acc: 0.9820359349250793)
[2024-12-17 02:35:31,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:31,244][root][INFO] - Training Epoch: 2/2, step 2139/7134 completed (loss: 0.09631479531526566, acc: 0.9767441749572754)
[2024-12-17 02:35:31,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:31,538][root][INFO] - Training Epoch: 2/2, step 2140/7134 completed (loss: 0.5286610126495361, acc: 0.8926553726196289)
[2024-12-17 02:35:31,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:31,812][root][INFO] - Training Epoch: 2/2, step 2141/7134 completed (loss: 0.49303656816482544, acc: 0.9042553305625916)
[2024-12-17 02:35:31,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:32,105][root][INFO] - Training Epoch: 2/2, step 2142/7134 completed (loss: 0.4780113399028778, acc: 0.9209039807319641)
[2024-12-17 02:35:32,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:32,401][root][INFO] - Training Epoch: 2/2, step 2143/7134 completed (loss: 0.11861614137887955, acc: 0.9862068891525269)
[2024-12-17 02:35:32,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:32,699][root][INFO] - Training Epoch: 2/2, step 2144/7134 completed (loss: 0.1288074105978012, acc: 0.9829545617103577)
[2024-12-17 02:35:32,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:32,986][root][INFO] - Training Epoch: 2/2, step 2145/7134 completed (loss: 0.27527257800102234, acc: 0.9244186282157898)
[2024-12-17 02:35:33,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:33,267][root][INFO] - Training Epoch: 2/2, step 2146/7134 completed (loss: 0.20027092099189758, acc: 0.9189189076423645)
[2024-12-17 02:35:33,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:33,564][root][INFO] - Training Epoch: 2/2, step 2147/7134 completed (loss: 0.2909892201423645, acc: 0.9191918969154358)
[2024-12-17 02:35:33,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:33,850][root][INFO] - Training Epoch: 2/2, step 2148/7134 completed (loss: 0.13833452761173248, acc: 0.9602272510528564)
[2024-12-17 02:35:33,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:34,150][root][INFO] - Training Epoch: 2/2, step 2149/7134 completed (loss: 0.07910129427909851, acc: 0.988304078578949)
[2024-12-17 02:35:34,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:34,449][root][INFO] - Training Epoch: 2/2, step 2150/7134 completed (loss: 0.14062346518039703, acc: 0.9548022747039795)
[2024-12-17 02:35:34,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:34,755][root][INFO] - Training Epoch: 2/2, step 2151/7134 completed (loss: 0.22693116962909698, acc: 0.9457831382751465)
[2024-12-17 02:35:34,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:35,047][root][INFO] - Training Epoch: 2/2, step 2152/7134 completed (loss: 0.32355421781539917, acc: 0.9096774458885193)
[2024-12-17 02:35:35,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:35,369][root][INFO] - Training Epoch: 2/2, step 2153/7134 completed (loss: 0.21480979025363922, acc: 0.9558823704719543)
[2024-12-17 02:35:35,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:35,681][root][INFO] - Training Epoch: 2/2, step 2154/7134 completed (loss: 0.22606854140758514, acc: 0.9425287246704102)
[2024-12-17 02:35:35,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:36,008][root][INFO] - Training Epoch: 2/2, step 2155/7134 completed (loss: 0.2823778986930847, acc: 0.9230769276618958)
[2024-12-17 02:35:36,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:36,274][root][INFO] - Training Epoch: 2/2, step 2156/7134 completed (loss: 0.18597401678562164, acc: 0.9632353186607361)
[2024-12-17 02:35:36,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:36,558][root][INFO] - Training Epoch: 2/2, step 2157/7134 completed (loss: 0.2547725439071655, acc: 0.939393937587738)
[2024-12-17 02:35:36,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:36,843][root][INFO] - Training Epoch: 2/2, step 2158/7134 completed (loss: 0.22746902704238892, acc: 0.9536082744598389)
[2024-12-17 02:35:36,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:37,124][root][INFO] - Training Epoch: 2/2, step 2159/7134 completed (loss: 0.07614206522703171, acc: 0.988095223903656)
[2024-12-17 02:35:37,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:37,419][root][INFO] - Training Epoch: 2/2, step 2160/7134 completed (loss: 0.13377197086811066, acc: 0.9634146094322205)
[2024-12-17 02:35:37,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:37,695][root][INFO] - Training Epoch: 2/2, step 2161/7134 completed (loss: 0.1379886418581009, acc: 0.9555555582046509)
[2024-12-17 02:35:37,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:37,983][root][INFO] - Training Epoch: 2/2, step 2162/7134 completed (loss: 0.15757860243320465, acc: 0.948387086391449)
[2024-12-17 02:35:38,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:38,275][root][INFO] - Training Epoch: 2/2, step 2163/7134 completed (loss: 0.2374732941389084, acc: 0.9266666769981384)
[2024-12-17 02:35:38,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:38,559][root][INFO] - Training Epoch: 2/2, step 2164/7134 completed (loss: 0.09957942366600037, acc: 0.9772727489471436)
[2024-12-17 02:35:38,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:38,845][root][INFO] - Training Epoch: 2/2, step 2165/7134 completed (loss: 0.12236183136701584, acc: 0.9756097793579102)
[2024-12-17 02:35:38,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:39,122][root][INFO] - Training Epoch: 2/2, step 2166/7134 completed (loss: 0.1245884969830513, acc: 0.9774011373519897)
[2024-12-17 02:35:39,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:39,429][root][INFO] - Training Epoch: 2/2, step 2167/7134 completed (loss: 0.24334996938705444, acc: 0.9708737730979919)
[2024-12-17 02:35:39,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:39,691][root][INFO] - Training Epoch: 2/2, step 2168/7134 completed (loss: 0.07553734630346298, acc: 0.9784172773361206)
[2024-12-17 02:35:39,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:39,986][root][INFO] - Training Epoch: 2/2, step 2169/7134 completed (loss: 0.12898734211921692, acc: 0.9597989916801453)
[2024-12-17 02:35:40,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:40,278][root][INFO] - Training Epoch: 2/2, step 2170/7134 completed (loss: 0.09908408671617508, acc: 0.9738562107086182)
[2024-12-17 02:35:40,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:40,587][root][INFO] - Training Epoch: 2/2, step 2171/7134 completed (loss: 0.21065258979797363, acc: 0.9405405521392822)
[2024-12-17 02:35:40,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:40,875][root][INFO] - Training Epoch: 2/2, step 2172/7134 completed (loss: 0.10291988402605057, acc: 0.9763033390045166)
[2024-12-17 02:35:40,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:41,155][root][INFO] - Training Epoch: 2/2, step 2173/7134 completed (loss: 0.21900492906570435, acc: 0.9589040875434875)
[2024-12-17 02:35:41,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:41,437][root][INFO] - Training Epoch: 2/2, step 2174/7134 completed (loss: 0.12079354375600815, acc: 0.976047933101654)
[2024-12-17 02:35:41,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:41,712][root][INFO] - Training Epoch: 2/2, step 2175/7134 completed (loss: 0.18827465176582336, acc: 0.9515151381492615)
[2024-12-17 02:35:41,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:42,007][root][INFO] - Training Epoch: 2/2, step 2176/7134 completed (loss: 0.12059572339057922, acc: 0.9728260636329651)
[2024-12-17 02:35:42,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:42,339][root][INFO] - Training Epoch: 2/2, step 2177/7134 completed (loss: 0.14941757917404175, acc: 0.9562841653823853)
[2024-12-17 02:35:42,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:42,636][root][INFO] - Training Epoch: 2/2, step 2178/7134 completed (loss: 0.10590296238660812, acc: 0.9635416865348816)
[2024-12-17 02:35:42,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:42,951][root][INFO] - Training Epoch: 2/2, step 2179/7134 completed (loss: 0.14365805685520172, acc: 0.9655172228813171)
[2024-12-17 02:35:43,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:43,257][root][INFO] - Training Epoch: 2/2, step 2180/7134 completed (loss: 0.15468959510326385, acc: 0.9835164546966553)
[2024-12-17 02:35:43,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:43,581][root][INFO] - Training Epoch: 2/2, step 2181/7134 completed (loss: 0.11467761546373367, acc: 0.9689440727233887)
[2024-12-17 02:35:43,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:43,900][root][INFO] - Training Epoch: 2/2, step 2182/7134 completed (loss: 0.17661742866039276, acc: 0.964102566242218)
[2024-12-17 02:35:44,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:44,223][root][INFO] - Training Epoch: 2/2, step 2183/7134 completed (loss: 0.1702965348958969, acc: 0.9668508172035217)
[2024-12-17 02:35:44,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:44,537][root][INFO] - Training Epoch: 2/2, step 2184/7134 completed (loss: 0.1950855851173401, acc: 0.9718309640884399)
[2024-12-17 02:35:44,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:44,816][root][INFO] - Training Epoch: 2/2, step 2185/7134 completed (loss: 0.32298457622528076, acc: 0.9245283007621765)
[2024-12-17 02:35:44,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:45,108][root][INFO] - Training Epoch: 2/2, step 2186/7134 completed (loss: 0.42416444420814514, acc: 0.9200000166893005)
[2024-12-17 02:35:45,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:45,401][root][INFO] - Training Epoch: 2/2, step 2187/7134 completed (loss: 0.27923527359962463, acc: 0.9208633303642273)
[2024-12-17 02:35:45,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:45,691][root][INFO] - Training Epoch: 2/2, step 2188/7134 completed (loss: 0.09533180296421051, acc: 0.9757575988769531)
[2024-12-17 02:35:45,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:45,968][root][INFO] - Training Epoch: 2/2, step 2189/7134 completed (loss: 0.3480219841003418, acc: 0.8961039185523987)
[2024-12-17 02:35:46,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:46,259][root][INFO] - Training Epoch: 2/2, step 2190/7134 completed (loss: 0.25524163246154785, acc: 0.9385474920272827)
[2024-12-17 02:35:46,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:46,538][root][INFO] - Training Epoch: 2/2, step 2191/7134 completed (loss: 0.23922854661941528, acc: 0.9368420839309692)
[2024-12-17 02:35:46,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:46,825][root][INFO] - Training Epoch: 2/2, step 2192/7134 completed (loss: 0.11021266132593155, acc: 0.970370352268219)
[2024-12-17 02:35:46,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:47,124][root][INFO] - Training Epoch: 2/2, step 2193/7134 completed (loss: 0.15871556103229523, acc: 0.9562841653823853)
[2024-12-17 02:35:47,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:47,411][root][INFO] - Training Epoch: 2/2, step 2194/7134 completed (loss: 0.1855061799287796, acc: 0.9473684430122375)
[2024-12-17 02:35:47,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:47,708][root][INFO] - Training Epoch: 2/2, step 2195/7134 completed (loss: 0.14540858566761017, acc: 0.9629629850387573)
[2024-12-17 02:35:47,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:48,000][root][INFO] - Training Epoch: 2/2, step 2196/7134 completed (loss: 0.16805367171764374, acc: 0.9505494236946106)
[2024-12-17 02:35:48,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:48,251][root][INFO] - Training Epoch: 2/2, step 2197/7134 completed (loss: 0.20050154626369476, acc: 0.9212598204612732)
[2024-12-17 02:35:48,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:48,540][root][INFO] - Training Epoch: 2/2, step 2198/7134 completed (loss: 0.14850236475467682, acc: 0.9712643623352051)
[2024-12-17 02:35:48,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:48,827][root][INFO] - Training Epoch: 2/2, step 2199/7134 completed (loss: 0.08009333908557892, acc: 0.9810126423835754)
[2024-12-17 02:35:48,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:49,113][root][INFO] - Training Epoch: 2/2, step 2200/7134 completed (loss: 0.10810188949108124, acc: 0.9763779640197754)
[2024-12-17 02:35:49,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:49,407][root][INFO] - Training Epoch: 2/2, step 2201/7134 completed (loss: 0.05495261028409004, acc: 0.9864864945411682)
[2024-12-17 02:35:49,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:49,707][root][INFO] - Training Epoch: 2/2, step 2202/7134 completed (loss: 0.10453125834465027, acc: 0.9781022071838379)
[2024-12-17 02:35:49,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:50,004][root][INFO] - Training Epoch: 2/2, step 2203/7134 completed (loss: 0.047812048345804214, acc: 0.9940119981765747)
[2024-12-17 02:35:50,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:50,298][root][INFO] - Training Epoch: 2/2, step 2204/7134 completed (loss: 0.1410493105649948, acc: 0.9712643623352051)
[2024-12-17 02:35:50,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:50,585][root][INFO] - Training Epoch: 2/2, step 2205/7134 completed (loss: 0.07295218855142593, acc: 0.9716312289237976)
[2024-12-17 02:35:50,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:50,891][root][INFO] - Training Epoch: 2/2, step 2206/7134 completed (loss: 0.14498239755630493, acc: 0.9731543660163879)
[2024-12-17 02:35:51,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:51,170][root][INFO] - Training Epoch: 2/2, step 2207/7134 completed (loss: 0.08875931054353714, acc: 0.9727891087532043)
[2024-12-17 02:35:51,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:51,446][root][INFO] - Training Epoch: 2/2, step 2208/7134 completed (loss: 0.0797925516963005, acc: 0.9806451797485352)
[2024-12-17 02:35:51,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:51,737][root][INFO] - Training Epoch: 2/2, step 2209/7134 completed (loss: 0.12397745251655579, acc: 0.9695122241973877)
[2024-12-17 02:35:51,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:52,021][root][INFO] - Training Epoch: 2/2, step 2210/7134 completed (loss: 0.13558536767959595, acc: 0.9329268336296082)
[2024-12-17 02:35:52,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:52,335][root][INFO] - Training Epoch: 2/2, step 2211/7134 completed (loss: 0.05201994627714157, acc: 0.9879518151283264)
[2024-12-17 02:35:52,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:52,626][root][INFO] - Training Epoch: 2/2, step 2212/7134 completed (loss: 0.06491150707006454, acc: 0.9885714054107666)
[2024-12-17 02:35:52,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:52,908][root][INFO] - Training Epoch: 2/2, step 2213/7134 completed (loss: 0.1314682960510254, acc: 0.9647058844566345)
[2024-12-17 02:35:53,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:53,184][root][INFO] - Training Epoch: 2/2, step 2214/7134 completed (loss: 0.16339638829231262, acc: 0.9729729890823364)
[2024-12-17 02:35:53,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:53,462][root][INFO] - Training Epoch: 2/2, step 2215/7134 completed (loss: 0.06890594959259033, acc: 0.9810126423835754)
[2024-12-17 02:35:53,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:53,738][root][INFO] - Training Epoch: 2/2, step 2216/7134 completed (loss: 0.13526661694049835, acc: 0.9532163739204407)
[2024-12-17 02:35:53,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:54,032][root][INFO] - Training Epoch: 2/2, step 2217/7134 completed (loss: 0.0638459324836731, acc: 0.9880239367485046)
[2024-12-17 02:35:54,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:54,319][root][INFO] - Training Epoch: 2/2, step 2218/7134 completed (loss: 0.2369372546672821, acc: 0.9506173133850098)
[2024-12-17 02:35:54,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:54,608][root][INFO] - Training Epoch: 2/2, step 2219/7134 completed (loss: 0.10395371913909912, acc: 0.9714285731315613)
[2024-12-17 02:35:54,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:54,884][root][INFO] - Training Epoch: 2/2, step 2220/7134 completed (loss: 0.1726864129304886, acc: 0.9555555582046509)
[2024-12-17 02:35:54,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:55,166][root][INFO] - Training Epoch: 2/2, step 2221/7134 completed (loss: 0.14315123856067657, acc: 0.9503105878829956)
[2024-12-17 02:35:55,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:55,438][root][INFO] - Training Epoch: 2/2, step 2222/7134 completed (loss: 0.22244477272033691, acc: 0.9383561611175537)
[2024-12-17 02:35:55,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:55,713][root][INFO] - Training Epoch: 2/2, step 2223/7134 completed (loss: 0.12131673097610474, acc: 0.9597315192222595)
[2024-12-17 02:35:55,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:56,007][root][INFO] - Training Epoch: 2/2, step 2224/7134 completed (loss: 0.3076843023300171, acc: 0.9240506291389465)
[2024-12-17 02:35:56,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:56,301][root][INFO] - Training Epoch: 2/2, step 2225/7134 completed (loss: 0.15582548081874847, acc: 0.9387755393981934)
[2024-12-17 02:35:56,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:56,583][root][INFO] - Training Epoch: 2/2, step 2226/7134 completed (loss: 0.12405557930469513, acc: 0.9597315192222595)
[2024-12-17 02:35:56,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:56,859][root][INFO] - Training Epoch: 2/2, step 2227/7134 completed (loss: 0.07807931303977966, acc: 0.9805194735527039)
[2024-12-17 02:35:56,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:57,124][root][INFO] - Training Epoch: 2/2, step 2228/7134 completed (loss: 0.0942399874329567, acc: 0.9922480583190918)
[2024-12-17 02:35:57,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:57,404][root][INFO] - Training Epoch: 2/2, step 2229/7134 completed (loss: 0.1182512566447258, acc: 0.9805825352668762)
[2024-12-17 02:35:57,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:57,686][root][INFO] - Training Epoch: 2/2, step 2230/7134 completed (loss: 0.08177360892295837, acc: 0.9640287756919861)
[2024-12-17 02:35:57,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:57,960][root][INFO] - Training Epoch: 2/2, step 2231/7134 completed (loss: 0.17458301782608032, acc: 0.9495798349380493)
[2024-12-17 02:35:58,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:58,248][root][INFO] - Training Epoch: 2/2, step 2232/7134 completed (loss: 0.12370641529560089, acc: 0.9655172228813171)
[2024-12-17 02:35:58,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:58,541][root][INFO] - Training Epoch: 2/2, step 2233/7134 completed (loss: 0.1370793730020523, acc: 0.9551281929016113)
[2024-12-17 02:35:58,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:58,837][root][INFO] - Training Epoch: 2/2, step 2234/7134 completed (loss: 0.045871470123529434, acc: 0.9870129823684692)
[2024-12-17 02:35:58,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:59,131][root][INFO] - Training Epoch: 2/2, step 2235/7134 completed (loss: 0.16751904785633087, acc: 0.9650349617004395)
[2024-12-17 02:35:59,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:59,409][root][INFO] - Training Epoch: 2/2, step 2236/7134 completed (loss: 0.11814085394144058, acc: 0.9733333587646484)
[2024-12-17 02:35:59,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:59,705][root][INFO] - Training Epoch: 2/2, step 2237/7134 completed (loss: 0.19448354840278625, acc: 0.95333331823349)
[2024-12-17 02:35:59,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:59,989][root][INFO] - Training Epoch: 2/2, step 2238/7134 completed (loss: 0.2699110209941864, acc: 0.9320987462997437)
[2024-12-17 02:36:00,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:00,269][root][INFO] - Training Epoch: 2/2, step 2239/7134 completed (loss: 0.45316988229751587, acc: 0.8983957171440125)
[2024-12-17 02:36:00,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:00,551][root][INFO] - Training Epoch: 2/2, step 2240/7134 completed (loss: 0.20179075002670288, acc: 0.9375)
[2024-12-17 02:36:00,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:00,805][root][INFO] - Training Epoch: 2/2, step 2241/7134 completed (loss: 0.2857663333415985, acc: 0.9270833134651184)
[2024-12-17 02:36:00,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:01,080][root][INFO] - Training Epoch: 2/2, step 2242/7134 completed (loss: 0.5993707180023193, acc: 0.8611111044883728)
[2024-12-17 02:36:01,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:01,383][root][INFO] - Training Epoch: 2/2, step 2243/7134 completed (loss: 0.5926638245582581, acc: 0.8580645322799683)
[2024-12-17 02:36:01,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:01,668][root][INFO] - Training Epoch: 2/2, step 2244/7134 completed (loss: 0.3180994689464569, acc: 0.9041095972061157)
[2024-12-17 02:36:01,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:01,928][root][INFO] - Training Epoch: 2/2, step 2245/7134 completed (loss: 0.4284035563468933, acc: 0.8954248428344727)
[2024-12-17 02:36:02,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:02,211][root][INFO] - Training Epoch: 2/2, step 2246/7134 completed (loss: 0.6593438982963562, acc: 0.8579235076904297)
[2024-12-17 02:36:02,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:02,493][root][INFO] - Training Epoch: 2/2, step 2247/7134 completed (loss: 0.4459545910358429, acc: 0.8728323578834534)
[2024-12-17 02:36:02,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:02,778][root][INFO] - Training Epoch: 2/2, step 2248/7134 completed (loss: 0.43371960520744324, acc: 0.8959537744522095)
[2024-12-17 02:36:02,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:03,070][root][INFO] - Training Epoch: 2/2, step 2249/7134 completed (loss: 0.3504881262779236, acc: 0.9226519465446472)
[2024-12-17 02:36:03,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:03,344][root][INFO] - Training Epoch: 2/2, step 2250/7134 completed (loss: 0.3328542411327362, acc: 0.8989361524581909)
[2024-12-17 02:36:03,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:03,625][root][INFO] - Training Epoch: 2/2, step 2251/7134 completed (loss: 0.16118241846561432, acc: 0.9508196711540222)
[2024-12-17 02:36:03,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:03,911][root][INFO] - Training Epoch: 2/2, step 2252/7134 completed (loss: 0.17044995725154877, acc: 0.9510869383811951)
[2024-12-17 02:36:04,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:04,198][root][INFO] - Training Epoch: 2/2, step 2253/7134 completed (loss: 0.2890337407588959, acc: 0.9363057613372803)
[2024-12-17 02:36:04,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:04,463][root][INFO] - Training Epoch: 2/2, step 2254/7134 completed (loss: 0.42203694581985474, acc: 0.8951612710952759)
[2024-12-17 02:36:04,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:04,745][root][INFO] - Training Epoch: 2/2, step 2255/7134 completed (loss: 0.15222682058811188, acc: 0.9685534834861755)
[2024-12-17 02:36:04,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:04,993][root][INFO] - Training Epoch: 2/2, step 2256/7134 completed (loss: 0.49903616309165955, acc: 0.8861788511276245)
[2024-12-17 02:36:05,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:05,286][root][INFO] - Training Epoch: 2/2, step 2257/7134 completed (loss: 0.17558591067790985, acc: 0.9691358208656311)
[2024-12-17 02:36:05,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:05,558][root][INFO] - Training Epoch: 2/2, step 2258/7134 completed (loss: 0.18381217122077942, acc: 0.9457364082336426)
[2024-12-17 02:36:05,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:05,827][root][INFO] - Training Epoch: 2/2, step 2259/7134 completed (loss: 0.25476986169815063, acc: 0.94017094373703)
[2024-12-17 02:36:05,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:06,090][root][INFO] - Training Epoch: 2/2, step 2260/7134 completed (loss: 0.35490334033966064, acc: 0.8896104097366333)
[2024-12-17 02:36:06,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:06,377][root][INFO] - Training Epoch: 2/2, step 2261/7134 completed (loss: 0.7744011878967285, acc: 0.845678985118866)
[2024-12-17 02:36:06,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:06,632][root][INFO] - Training Epoch: 2/2, step 2262/7134 completed (loss: 0.29962533712387085, acc: 0.9248120188713074)
[2024-12-17 02:36:06,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:06,902][root][INFO] - Training Epoch: 2/2, step 2263/7134 completed (loss: 0.42373356223106384, acc: 0.9097744226455688)
[2024-12-17 02:36:07,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:07,182][root][INFO] - Training Epoch: 2/2, step 2264/7134 completed (loss: 0.4226507246494293, acc: 0.908108115196228)
[2024-12-17 02:36:07,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:07,490][root][INFO] - Training Epoch: 2/2, step 2265/7134 completed (loss: 0.3483671247959137, acc: 0.9090909361839294)
[2024-12-17 02:36:07,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:07,796][root][INFO] - Training Epoch: 2/2, step 2266/7134 completed (loss: 0.2921740710735321, acc: 0.9171270728111267)
[2024-12-17 02:36:07,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:08,095][root][INFO] - Training Epoch: 2/2, step 2267/7134 completed (loss: 0.17635227739810944, acc: 0.9593495726585388)
[2024-12-17 02:36:08,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:08,383][root][INFO] - Training Epoch: 2/2, step 2268/7134 completed (loss: 0.15461261570453644, acc: 0.9589040875434875)
[2024-12-17 02:36:08,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:08,690][root][INFO] - Training Epoch: 2/2, step 2269/7134 completed (loss: 0.1404097080230713, acc: 0.9720670580863953)
[2024-12-17 02:36:08,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:09,006][root][INFO] - Training Epoch: 2/2, step 2270/7134 completed (loss: 0.30667442083358765, acc: 0.9296875)
[2024-12-17 02:36:09,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:09,318][root][INFO] - Training Epoch: 2/2, step 2271/7134 completed (loss: 0.40965765714645386, acc: 0.8918918967247009)
[2024-12-17 02:36:09,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:09,620][root][INFO] - Training Epoch: 2/2, step 2272/7134 completed (loss: 0.23589320480823517, acc: 0.9462365508079529)
[2024-12-17 02:36:09,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:09,913][root][INFO] - Training Epoch: 2/2, step 2273/7134 completed (loss: 0.08525533974170685, acc: 0.9777777791023254)
[2024-12-17 02:36:10,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:10,202][root][INFO] - Training Epoch: 2/2, step 2274/7134 completed (loss: 0.5907911062240601, acc: 0.9076923131942749)
[2024-12-17 02:36:10,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:10,502][root][INFO] - Training Epoch: 2/2, step 2275/7134 completed (loss: 0.13745024800300598, acc: 0.9656862616539001)
[2024-12-17 02:36:10,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:10,784][root][INFO] - Training Epoch: 2/2, step 2276/7134 completed (loss: 0.19480925798416138, acc: 0.9576719403266907)
[2024-12-17 02:36:10,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:11,094][root][INFO] - Training Epoch: 2/2, step 2277/7134 completed (loss: 0.35130709409713745, acc: 0.9230769276618958)
[2024-12-17 02:36:11,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:11,410][root][INFO] - Training Epoch: 2/2, step 2278/7134 completed (loss: 0.5161886811256409, acc: 0.9096774458885193)
[2024-12-17 02:36:11,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:11,713][root][INFO] - Training Epoch: 2/2, step 2279/7134 completed (loss: 0.1660701334476471, acc: 0.9746192693710327)
[2024-12-17 02:36:11,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:12,006][root][INFO] - Training Epoch: 2/2, step 2280/7134 completed (loss: 0.27040374279022217, acc: 0.9266055226325989)
[2024-12-17 02:36:12,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:12,274][root][INFO] - Training Epoch: 2/2, step 2281/7134 completed (loss: 0.45170798897743225, acc: 0.914893627166748)
[2024-12-17 02:36:12,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:12,555][root][INFO] - Training Epoch: 2/2, step 2282/7134 completed (loss: 0.06955847144126892, acc: 0.9842105507850647)
[2024-12-17 02:36:12,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:12,833][root][INFO] - Training Epoch: 2/2, step 2283/7134 completed (loss: 0.21280568838119507, acc: 0.932692289352417)
[2024-12-17 02:36:12,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:13,107][root][INFO] - Training Epoch: 2/2, step 2284/7134 completed (loss: 0.1785324513912201, acc: 0.9419354796409607)
[2024-12-17 02:36:13,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:13,405][root][INFO] - Training Epoch: 2/2, step 2285/7134 completed (loss: 0.11987311393022537, acc: 0.9700000286102295)
[2024-12-17 02:36:13,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:13,702][root][INFO] - Training Epoch: 2/2, step 2286/7134 completed (loss: 0.31143686175346375, acc: 0.9252873659133911)
[2024-12-17 02:36:13,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:13,995][root][INFO] - Training Epoch: 2/2, step 2287/7134 completed (loss: 0.16170616447925568, acc: 0.9570552110671997)
[2024-12-17 02:36:14,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:14,295][root][INFO] - Training Epoch: 2/2, step 2288/7134 completed (loss: 0.08301185071468353, acc: 0.9945054650306702)
[2024-12-17 02:36:14,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:14,582][root][INFO] - Training Epoch: 2/2, step 2289/7134 completed (loss: 0.17989800870418549, acc: 0.9518716335296631)
[2024-12-17 02:36:14,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:14,860][root][INFO] - Training Epoch: 2/2, step 2290/7134 completed (loss: 0.190296933054924, acc: 0.9462365508079529)
[2024-12-17 02:36:14,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:15,141][root][INFO] - Training Epoch: 2/2, step 2291/7134 completed (loss: 0.20904043316841125, acc: 0.939226508140564)
[2024-12-17 02:36:15,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:15,429][root][INFO] - Training Epoch: 2/2, step 2292/7134 completed (loss: 0.3492259085178375, acc: 0.8989899158477783)
[2024-12-17 02:36:15,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:15,731][root][INFO] - Training Epoch: 2/2, step 2293/7134 completed (loss: 0.2505187392234802, acc: 0.9360730648040771)
[2024-12-17 02:36:15,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:16,032][root][INFO] - Training Epoch: 2/2, step 2294/7134 completed (loss: 0.17456741631031036, acc: 0.9425837397575378)
[2024-12-17 02:36:16,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:16,337][root][INFO] - Training Epoch: 2/2, step 2295/7134 completed (loss: 0.1968717724084854, acc: 0.9453125)
[2024-12-17 02:36:16,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:16,618][root][INFO] - Training Epoch: 2/2, step 2296/7134 completed (loss: 0.15764161944389343, acc: 0.9567307829856873)
[2024-12-17 02:36:16,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:16,906][root][INFO] - Training Epoch: 2/2, step 2297/7134 completed (loss: 0.11346033960580826, acc: 0.9716981053352356)
[2024-12-17 02:36:17,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:17,191][root][INFO] - Training Epoch: 2/2, step 2298/7134 completed (loss: 0.17522630095481873, acc: 0.938095211982727)
[2024-12-17 02:36:17,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:17,502][root][INFO] - Training Epoch: 2/2, step 2299/7134 completed (loss: 0.27194270491600037, acc: 0.9516128897666931)
[2024-12-17 02:36:17,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:17,786][root][INFO] - Training Epoch: 2/2, step 2300/7134 completed (loss: 0.21756574511528015, acc: 0.9595959782600403)
[2024-12-17 02:36:17,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:18,058][root][INFO] - Training Epoch: 2/2, step 2301/7134 completed (loss: 0.2898818850517273, acc: 0.9130434989929199)
[2024-12-17 02:36:18,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:18,348][root][INFO] - Training Epoch: 2/2, step 2302/7134 completed (loss: 0.16397032141685486, acc: 0.9692307710647583)
[2024-12-17 02:36:18,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:18,617][root][INFO] - Training Epoch: 2/2, step 2303/7134 completed (loss: 0.26684170961380005, acc: 0.9308755993843079)
[2024-12-17 02:36:18,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:18,903][root][INFO] - Training Epoch: 2/2, step 2304/7134 completed (loss: 0.32688242197036743, acc: 0.9251101613044739)
[2024-12-17 02:36:19,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:19,191][root][INFO] - Training Epoch: 2/2, step 2305/7134 completed (loss: 0.18429723381996155, acc: 0.948113203048706)
[2024-12-17 02:36:19,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:19,474][root][INFO] - Training Epoch: 2/2, step 2306/7134 completed (loss: 0.1636030673980713, acc: 0.9441860318183899)
[2024-12-17 02:36:19,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:19,750][root][INFO] - Training Epoch: 2/2, step 2307/7134 completed (loss: 0.17058059573173523, acc: 0.9576271176338196)
[2024-12-17 02:36:19,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:20,033][root][INFO] - Training Epoch: 2/2, step 2308/7134 completed (loss: 0.18762381374835968, acc: 0.9515418410301208)
[2024-12-17 02:36:20,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:20,310][root][INFO] - Training Epoch: 2/2, step 2309/7134 completed (loss: 0.14954625070095062, acc: 0.9576719403266907)
[2024-12-17 02:36:20,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:20,593][root][INFO] - Training Epoch: 2/2, step 2310/7134 completed (loss: 0.1618068367242813, acc: 0.9523809552192688)
[2024-12-17 02:36:20,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:20,870][root][INFO] - Training Epoch: 2/2, step 2311/7134 completed (loss: 0.17187808454036713, acc: 0.9556650519371033)
[2024-12-17 02:36:21,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:21,167][root][INFO] - Training Epoch: 2/2, step 2312/7134 completed (loss: 0.19565367698669434, acc: 0.9577465057373047)
[2024-12-17 02:36:21,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:21,445][root][INFO] - Training Epoch: 2/2, step 2313/7134 completed (loss: 0.23723982274532318, acc: 0.9278846383094788)
[2024-12-17 02:36:21,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:21,744][root][INFO] - Training Epoch: 2/2, step 2314/7134 completed (loss: 0.16491208970546722, acc: 0.9587156176567078)
[2024-12-17 02:36:21,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:22,039][root][INFO] - Training Epoch: 2/2, step 2315/7134 completed (loss: 0.18569691479206085, acc: 0.9395349025726318)
[2024-12-17 02:36:22,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:22,315][root][INFO] - Training Epoch: 2/2, step 2316/7134 completed (loss: 0.08552824705839157, acc: 0.9788359999656677)
[2024-12-17 02:36:22,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:22,614][root][INFO] - Training Epoch: 2/2, step 2317/7134 completed (loss: 0.16117793321609497, acc: 0.9789915680885315)
[2024-12-17 02:36:22,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:22,909][root][INFO] - Training Epoch: 2/2, step 2318/7134 completed (loss: 0.07717987895011902, acc: 0.9868995547294617)
[2024-12-17 02:36:23,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:23,183][root][INFO] - Training Epoch: 2/2, step 2319/7134 completed (loss: 0.09511683881282806, acc: 0.977477490901947)
[2024-12-17 02:36:23,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:23,462][root][INFO] - Training Epoch: 2/2, step 2320/7134 completed (loss: 0.09253139048814774, acc: 0.9743589758872986)
[2024-12-17 02:36:23,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:23,742][root][INFO] - Training Epoch: 2/2, step 2321/7134 completed (loss: 0.07890193164348602, acc: 0.9823529124259949)
[2024-12-17 02:36:23,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:24,049][root][INFO] - Training Epoch: 2/2, step 2322/7134 completed (loss: 0.26537904143333435, acc: 0.9263803958892822)
[2024-12-17 02:36:24,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:24,355][root][INFO] - Training Epoch: 2/2, step 2323/7134 completed (loss: 0.27579888701438904, acc: 0.9171974658966064)
[2024-12-17 02:36:24,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:24,644][root][INFO] - Training Epoch: 2/2, step 2324/7134 completed (loss: 0.3580585718154907, acc: 0.9518072009086609)
[2024-12-17 02:36:24,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:24,938][root][INFO] - Training Epoch: 2/2, step 2325/7134 completed (loss: 0.2655138075351715, acc: 0.9285714030265808)
[2024-12-17 02:36:25,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:25,198][root][INFO] - Training Epoch: 2/2, step 2326/7134 completed (loss: 0.1334991306066513, acc: 0.9538461565971375)
[2024-12-17 02:36:25,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:25,486][root][INFO] - Training Epoch: 2/2, step 2327/7134 completed (loss: 0.20494666695594788, acc: 0.9395973086357117)
[2024-12-17 02:36:25,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:25,778][root][INFO] - Training Epoch: 2/2, step 2328/7134 completed (loss: 0.2768378257751465, acc: 0.9395973086357117)
[2024-12-17 02:36:25,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:26,081][root][INFO] - Training Epoch: 2/2, step 2329/7134 completed (loss: 0.25286558270454407, acc: 0.9346405267715454)
[2024-12-17 02:36:26,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:26,375][root][INFO] - Training Epoch: 2/2, step 2330/7134 completed (loss: 0.0957556664943695, acc: 0.9757575988769531)
[2024-12-17 02:36:26,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:26,656][root][INFO] - Training Epoch: 2/2, step 2331/7134 completed (loss: 0.04339096322655678, acc: 0.9870967864990234)
[2024-12-17 02:36:26,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:26,944][root][INFO] - Training Epoch: 2/2, step 2332/7134 completed (loss: 0.11333901435136795, acc: 0.9818181991577148)
[2024-12-17 02:36:27,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:27,224][root][INFO] - Training Epoch: 2/2, step 2333/7134 completed (loss: 0.1410449594259262, acc: 0.9695122241973877)
[2024-12-17 02:36:27,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:27,511][root][INFO] - Training Epoch: 2/2, step 2334/7134 completed (loss: 0.26105666160583496, acc: 0.9490445852279663)
[2024-12-17 02:36:27,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:27,805][root][INFO] - Training Epoch: 2/2, step 2335/7134 completed (loss: 0.1340920478105545, acc: 0.9683544039726257)
[2024-12-17 02:36:27,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:28,087][root][INFO] - Training Epoch: 2/2, step 2336/7134 completed (loss: 0.0937809944152832, acc: 0.9731543660163879)
[2024-12-17 02:36:28,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:28,376][root][INFO] - Training Epoch: 2/2, step 2337/7134 completed (loss: 0.05930943787097931, acc: 0.9791666865348816)
[2024-12-17 02:36:28,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:28,668][root][INFO] - Training Epoch: 2/2, step 2338/7134 completed (loss: 0.08021707832813263, acc: 0.9675324559211731)
[2024-12-17 02:36:28,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:28,952][root][INFO] - Training Epoch: 2/2, step 2339/7134 completed (loss: 0.1938793808221817, acc: 0.942307710647583)
[2024-12-17 02:36:29,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:29,237][root][INFO] - Training Epoch: 2/2, step 2340/7134 completed (loss: 0.0678088441491127, acc: 0.9740259647369385)
[2024-12-17 02:36:29,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:29,532][root][INFO] - Training Epoch: 2/2, step 2341/7134 completed (loss: 0.1302511841058731, acc: 0.9834710955619812)
[2024-12-17 02:36:29,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:29,797][root][INFO] - Training Epoch: 2/2, step 2342/7134 completed (loss: 0.07804866880178452, acc: 0.9821428656578064)
[2024-12-17 02:36:29,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:30,077][root][INFO] - Training Epoch: 2/2, step 2343/7134 completed (loss: 0.0701964795589447, acc: 0.981249988079071)
[2024-12-17 02:36:30,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:30,371][root][INFO] - Training Epoch: 2/2, step 2344/7134 completed (loss: 0.11376882344484329, acc: 0.9753086566925049)
[2024-12-17 02:36:30,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:30,661][root][INFO] - Training Epoch: 2/2, step 2345/7134 completed (loss: 0.13385862112045288, acc: 0.959770143032074)
[2024-12-17 02:36:30,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:30,951][root][INFO] - Training Epoch: 2/2, step 2346/7134 completed (loss: 0.0900241807103157, acc: 0.9779005646705627)
[2024-12-17 02:36:31,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:31,238][root][INFO] - Training Epoch: 2/2, step 2347/7134 completed (loss: 0.27629104256629944, acc: 0.9718309640884399)
[2024-12-17 02:36:31,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:31,524][root][INFO] - Training Epoch: 2/2, step 2348/7134 completed (loss: 0.43666714429855347, acc: 0.876288652420044)
[2024-12-17 02:36:31,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:31,840][root][INFO] - Training Epoch: 2/2, step 2349/7134 completed (loss: 0.41154447197914124, acc: 0.90625)
[2024-12-17 02:36:31,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:32,159][root][INFO] - Training Epoch: 2/2, step 2350/7134 completed (loss: 0.5189124345779419, acc: 0.8860759735107422)
[2024-12-17 02:36:32,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:32,449][root][INFO] - Training Epoch: 2/2, step 2351/7134 completed (loss: 0.3215181231498718, acc: 0.9180327653884888)
[2024-12-17 02:36:32,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:32,742][root][INFO] - Training Epoch: 2/2, step 2352/7134 completed (loss: 0.33480149507522583, acc: 0.9290322661399841)
[2024-12-17 02:36:32,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:33,063][root][INFO] - Training Epoch: 2/2, step 2353/7134 completed (loss: 0.30255231261253357, acc: 0.9290322661399841)
[2024-12-17 02:36:33,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:33,340][root][INFO] - Training Epoch: 2/2, step 2354/7134 completed (loss: 0.14023858308792114, acc: 0.9617486596107483)
[2024-12-17 02:36:33,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:33,632][root][INFO] - Training Epoch: 2/2, step 2355/7134 completed (loss: 0.31440308690071106, acc: 0.9447513818740845)
[2024-12-17 02:36:33,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:33,935][root][INFO] - Training Epoch: 2/2, step 2356/7134 completed (loss: 0.38170912861824036, acc: 0.9130434989929199)
[2024-12-17 02:36:34,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:34,205][root][INFO] - Training Epoch: 2/2, step 2357/7134 completed (loss: 0.31004348397254944, acc: 0.9047619104385376)
[2024-12-17 02:36:34,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:34,491][root][INFO] - Training Epoch: 2/2, step 2358/7134 completed (loss: 0.3456731140613556, acc: 0.918367326259613)
[2024-12-17 02:36:34,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:34,766][root][INFO] - Training Epoch: 2/2, step 2359/7134 completed (loss: 0.3315463066101074, acc: 0.9125000238418579)
[2024-12-17 02:36:34,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:35,076][root][INFO] - Training Epoch: 2/2, step 2360/7134 completed (loss: 0.1669473946094513, acc: 0.9556962251663208)
[2024-12-17 02:36:35,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:35,364][root][INFO] - Training Epoch: 2/2, step 2361/7134 completed (loss: 0.21009397506713867, acc: 0.9523809552192688)
[2024-12-17 02:36:35,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:35,603][root][INFO] - Training Epoch: 2/2, step 2362/7134 completed (loss: 0.43758535385131836, acc: 0.9189189076423645)
[2024-12-17 02:36:35,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:35,891][root][INFO] - Training Epoch: 2/2, step 2363/7134 completed (loss: 0.241624116897583, acc: 0.9424083828926086)
[2024-12-17 02:36:36,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:36,166][root][INFO] - Training Epoch: 2/2, step 2364/7134 completed (loss: 0.09785673022270203, acc: 0.9673202633857727)
[2024-12-17 02:36:36,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:36,439][root][INFO] - Training Epoch: 2/2, step 2365/7134 completed (loss: 0.14936213195323944, acc: 0.9476743936538696)
[2024-12-17 02:36:36,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:36,718][root][INFO] - Training Epoch: 2/2, step 2366/7134 completed (loss: 0.08461706340312958, acc: 0.9846153855323792)
[2024-12-17 02:36:36,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:37,009][root][INFO] - Training Epoch: 2/2, step 2367/7134 completed (loss: 0.23887337744235992, acc: 0.9545454382896423)
[2024-12-17 02:36:37,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:37,294][root][INFO] - Training Epoch: 2/2, step 2368/7134 completed (loss: 0.3468157649040222, acc: 0.929648220539093)
[2024-12-17 02:36:37,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:37,578][root][INFO] - Training Epoch: 2/2, step 2369/7134 completed (loss: 0.19899515807628632, acc: 0.9622641801834106)
[2024-12-17 02:36:37,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:37,817][root][INFO] - Training Epoch: 2/2, step 2370/7134 completed (loss: 0.34068620204925537, acc: 0.9200000166893005)
[2024-12-17 02:36:37,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:38,106][root][INFO] - Training Epoch: 2/2, step 2371/7134 completed (loss: 0.23695775866508484, acc: 0.9440993666648865)
[2024-12-17 02:36:38,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:38,381][root][INFO] - Training Epoch: 2/2, step 2372/7134 completed (loss: 0.09933549910783768, acc: 0.9750000238418579)
[2024-12-17 02:36:38,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:38,657][root][INFO] - Training Epoch: 2/2, step 2373/7134 completed (loss: 0.12178486585617065, acc: 0.9585492014884949)
[2024-12-17 02:36:38,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:38,931][root][INFO] - Training Epoch: 2/2, step 2374/7134 completed (loss: 0.11319197714328766, acc: 0.9668508172035217)
[2024-12-17 02:36:39,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:39,211][root][INFO] - Training Epoch: 2/2, step 2375/7134 completed (loss: 0.2634420096874237, acc: 0.9272727370262146)
[2024-12-17 02:36:39,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:39,494][root][INFO] - Training Epoch: 2/2, step 2376/7134 completed (loss: 0.2998080551624298, acc: 0.915032684803009)
[2024-12-17 02:36:39,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:39,797][root][INFO] - Training Epoch: 2/2, step 2377/7134 completed (loss: 0.20831872522830963, acc: 0.9392523169517517)
[2024-12-17 02:36:39,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:40,080][root][INFO] - Training Epoch: 2/2, step 2378/7134 completed (loss: 0.3056786358356476, acc: 0.9356435537338257)
[2024-12-17 02:36:40,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:40,365][root][INFO] - Training Epoch: 2/2, step 2379/7134 completed (loss: 0.47146445512771606, acc: 0.8673469424247742)
[2024-12-17 02:36:40,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:40,685][root][INFO] - Training Epoch: 2/2, step 2380/7134 completed (loss: 0.27637234330177307, acc: 0.91847825050354)
[2024-12-17 02:36:40,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:40,984][root][INFO] - Training Epoch: 2/2, step 2381/7134 completed (loss: 0.5949739217758179, acc: 0.8260869383811951)
[2024-12-17 02:36:41,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:41,271][root][INFO] - Training Epoch: 2/2, step 2382/7134 completed (loss: 0.24448241293430328, acc: 0.9259259104728699)
[2024-12-17 02:36:41,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:41,551][root][INFO] - Training Epoch: 2/2, step 2383/7134 completed (loss: 0.24362513422966003, acc: 0.9289617538452148)
[2024-12-17 02:36:41,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:41,847][root][INFO] - Training Epoch: 2/2, step 2384/7134 completed (loss: 0.3042472302913666, acc: 0.9252873659133911)
[2024-12-17 02:36:41,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:42,130][root][INFO] - Training Epoch: 2/2, step 2385/7134 completed (loss: 0.1871974617242813, acc: 0.9450549483299255)
[2024-12-17 02:36:42,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:42,404][root][INFO] - Training Epoch: 2/2, step 2386/7134 completed (loss: 0.27522170543670654, acc: 0.9365079402923584)
[2024-12-17 02:36:42,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:42,694][root][INFO] - Training Epoch: 2/2, step 2387/7134 completed (loss: 0.33212608098983765, acc: 0.938095211982727)
[2024-12-17 02:36:42,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:42,976][root][INFO] - Training Epoch: 2/2, step 2388/7134 completed (loss: 0.2916920781135559, acc: 0.932692289352417)
[2024-12-17 02:36:43,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:43,313][root][INFO] - Training Epoch: 2/2, step 2389/7134 completed (loss: 0.34812450408935547, acc: 0.8957346081733704)
[2024-12-17 02:36:43,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:43,597][root][INFO] - Training Epoch: 2/2, step 2390/7134 completed (loss: 0.3830258250236511, acc: 0.900473952293396)
[2024-12-17 02:36:43,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:43,866][root][INFO] - Training Epoch: 2/2, step 2391/7134 completed (loss: 0.2880505621433258, acc: 0.929729700088501)
[2024-12-17 02:36:43,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:44,146][root][INFO] - Training Epoch: 2/2, step 2392/7134 completed (loss: 0.27388402819633484, acc: 0.9344262480735779)
[2024-12-17 02:36:44,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:44,423][root][INFO] - Training Epoch: 2/2, step 2393/7134 completed (loss: 0.3058006763458252, acc: 0.9274611473083496)
[2024-12-17 02:36:44,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:44,719][root][INFO] - Training Epoch: 2/2, step 2394/7134 completed (loss: 0.230007603764534, acc: 0.9336734414100647)
[2024-12-17 02:36:44,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:45,023][root][INFO] - Training Epoch: 2/2, step 2395/7134 completed (loss: 0.6329708695411682, acc: 0.868571400642395)
[2024-12-17 02:36:45,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:45,346][root][INFO] - Training Epoch: 2/2, step 2396/7134 completed (loss: 0.6243425011634827, acc: 0.8333333134651184)
[2024-12-17 02:36:45,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:45,613][root][INFO] - Training Epoch: 2/2, step 2397/7134 completed (loss: 0.4453335404396057, acc: 0.9085366129875183)
[2024-12-17 02:36:45,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:45,913][root][INFO] - Training Epoch: 2/2, step 2398/7134 completed (loss: 0.1864214539527893, acc: 0.929729700088501)
[2024-12-17 02:36:46,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:46,214][root][INFO] - Training Epoch: 2/2, step 2399/7134 completed (loss: 0.5469443798065186, acc: 0.8549222946166992)
[2024-12-17 02:36:46,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:46,536][root][INFO] - Training Epoch: 2/2, step 2400/7134 completed (loss: 0.3783578872680664, acc: 0.909547746181488)
[2024-12-17 02:36:46,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:46,826][root][INFO] - Training Epoch: 2/2, step 2401/7134 completed (loss: 0.9212468862533569, acc: 0.75)
[2024-12-17 02:36:46,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:47,122][root][INFO] - Training Epoch: 2/2, step 2402/7134 completed (loss: 0.4009200632572174, acc: 0.8937197923660278)
[2024-12-17 02:36:47,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:47,407][root][INFO] - Training Epoch: 2/2, step 2403/7134 completed (loss: 0.32565242052078247, acc: 0.9281437397003174)
[2024-12-17 02:36:47,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:47,658][root][INFO] - Training Epoch: 2/2, step 2404/7134 completed (loss: 0.20006179809570312, acc: 0.9605262875556946)
[2024-12-17 02:36:47,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:47,948][root][INFO] - Training Epoch: 2/2, step 2405/7134 completed (loss: 0.3886832594871521, acc: 0.9108280539512634)
[2024-12-17 02:36:48,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:48,221][root][INFO] - Training Epoch: 2/2, step 2406/7134 completed (loss: 0.08459562808275223, acc: 0.9822485446929932)
[2024-12-17 02:36:48,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:48,502][root][INFO] - Training Epoch: 2/2, step 2407/7134 completed (loss: 0.14853931963443756, acc: 0.9803921580314636)
[2024-12-17 02:36:48,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:48,801][root][INFO] - Training Epoch: 2/2, step 2408/7134 completed (loss: 0.35789406299591064, acc: 0.9116021990776062)
[2024-12-17 02:36:48,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:49,088][root][INFO] - Training Epoch: 2/2, step 2409/7134 completed (loss: 0.24121694266796112, acc: 0.9312499761581421)
[2024-12-17 02:36:49,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:49,344][root][INFO] - Training Epoch: 2/2, step 2410/7134 completed (loss: 0.16663795709609985, acc: 0.9507042169570923)
[2024-12-17 02:36:49,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:49,642][root][INFO] - Training Epoch: 2/2, step 2411/7134 completed (loss: 0.08994845300912857, acc: 0.9723756909370422)
[2024-12-17 02:36:49,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:49,926][root][INFO] - Training Epoch: 2/2, step 2412/7134 completed (loss: 0.19708584249019623, acc: 0.9488636255264282)
[2024-12-17 02:36:50,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:50,211][root][INFO] - Training Epoch: 2/2, step 2413/7134 completed (loss: 0.09844100475311279, acc: 0.9675324559211731)
[2024-12-17 02:36:50,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:50,495][root][INFO] - Training Epoch: 2/2, step 2414/7134 completed (loss: 0.14272184669971466, acc: 0.9617486596107483)
[2024-12-17 02:36:50,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:50,789][root][INFO] - Training Epoch: 2/2, step 2415/7134 completed (loss: 0.4029417335987091, acc: 0.9207317233085632)
[2024-12-17 02:36:50,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:51,074][root][INFO] - Training Epoch: 2/2, step 2416/7134 completed (loss: 0.23247665166854858, acc: 0.9371069073677063)
[2024-12-17 02:36:51,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:51,376][root][INFO] - Training Epoch: 2/2, step 2417/7134 completed (loss: 0.2246304750442505, acc: 0.9463414549827576)
[2024-12-17 02:36:51,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:51,640][root][INFO] - Training Epoch: 2/2, step 2418/7134 completed (loss: 0.24571679532527924, acc: 0.9580419659614563)
[2024-12-17 02:36:51,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:51,935][root][INFO] - Training Epoch: 2/2, step 2419/7134 completed (loss: 0.1706922948360443, acc: 0.9570552110671997)
[2024-12-17 02:36:52,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:52,227][root][INFO] - Training Epoch: 2/2, step 2420/7134 completed (loss: 0.21050964295864105, acc: 0.9513888955116272)
[2024-12-17 02:36:52,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:52,510][root][INFO] - Training Epoch: 2/2, step 2421/7134 completed (loss: 0.19211015105247498, acc: 0.9621621370315552)
[2024-12-17 02:36:52,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:52,809][root][INFO] - Training Epoch: 2/2, step 2422/7134 completed (loss: 0.2672010660171509, acc: 0.9428571462631226)
[2024-12-17 02:36:52,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:53,093][root][INFO] - Training Epoch: 2/2, step 2423/7134 completed (loss: 0.18374499678611755, acc: 0.9642857313156128)
[2024-12-17 02:36:53,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:53,389][root][INFO] - Training Epoch: 2/2, step 2424/7134 completed (loss: 0.2132931351661682, acc: 0.9545454382896423)
[2024-12-17 02:36:53,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:53,667][root][INFO] - Training Epoch: 2/2, step 2425/7134 completed (loss: 0.18334780633449554, acc: 0.949438214302063)
[2024-12-17 02:36:53,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:53,953][root][INFO] - Training Epoch: 2/2, step 2426/7134 completed (loss: 0.15524788200855255, acc: 0.9655172228813171)
[2024-12-17 02:36:54,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:54,228][root][INFO] - Training Epoch: 2/2, step 2427/7134 completed (loss: 0.07566864043474197, acc: 0.984375)
[2024-12-17 02:36:54,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:54,520][root][INFO] - Training Epoch: 2/2, step 2428/7134 completed (loss: 0.12040101736783981, acc: 0.9789473414421082)
[2024-12-17 02:36:54,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:54,797][root][INFO] - Training Epoch: 2/2, step 2429/7134 completed (loss: 0.18747200071811676, acc: 0.9430379867553711)
[2024-12-17 02:36:54,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:55,068][root][INFO] - Training Epoch: 2/2, step 2430/7134 completed (loss: 0.13197863101959229, acc: 0.9666666388511658)
[2024-12-17 02:36:55,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:55,347][root][INFO] - Training Epoch: 2/2, step 2431/7134 completed (loss: 0.17680270969867706, acc: 0.9580419659614563)
[2024-12-17 02:36:55,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:55,631][root][INFO] - Training Epoch: 2/2, step 2432/7134 completed (loss: 0.4442457854747772, acc: 0.9008264541625977)
[2024-12-17 02:36:55,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:55,926][root][INFO] - Training Epoch: 2/2, step 2433/7134 completed (loss: 0.34686240553855896, acc: 0.9208633303642273)
[2024-12-17 02:36:56,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:56,209][root][INFO] - Training Epoch: 2/2, step 2434/7134 completed (loss: 0.4156992733478546, acc: 0.9060402512550354)
[2024-12-17 02:36:56,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:56,499][root][INFO] - Training Epoch: 2/2, step 2435/7134 completed (loss: 0.308083713054657, acc: 0.9337748289108276)
[2024-12-17 02:36:56,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:56,770][root][INFO] - Training Epoch: 2/2, step 2436/7134 completed (loss: 0.16123835742473602, acc: 0.9593908786773682)
[2024-12-17 02:36:56,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:57,038][root][INFO] - Training Epoch: 2/2, step 2437/7134 completed (loss: 0.23211057484149933, acc: 0.9436619877815247)
[2024-12-17 02:36:57,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:57,326][root][INFO] - Training Epoch: 2/2, step 2438/7134 completed (loss: 0.2302575558423996, acc: 0.9629629850387573)
[2024-12-17 02:36:57,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:57,610][root][INFO] - Training Epoch: 2/2, step 2439/7134 completed (loss: 0.18738800287246704, acc: 0.9411764740943909)
[2024-12-17 02:36:57,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:57,878][root][INFO] - Training Epoch: 2/2, step 2440/7134 completed (loss: 0.19185923039913177, acc: 0.9318181872367859)
[2024-12-17 02:36:58,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:58,145][root][INFO] - Training Epoch: 2/2, step 2441/7134 completed (loss: 0.6568459868431091, acc: 0.871999979019165)
[2024-12-17 02:36:58,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:58,432][root][INFO] - Training Epoch: 2/2, step 2442/7134 completed (loss: 0.35355672240257263, acc: 0.9230769276618958)
[2024-12-17 02:36:58,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:58,716][root][INFO] - Training Epoch: 2/2, step 2443/7134 completed (loss: 0.3079315721988678, acc: 0.9141104221343994)
[2024-12-17 02:36:58,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:58,988][root][INFO] - Training Epoch: 2/2, step 2444/7134 completed (loss: 0.3894590437412262, acc: 0.9069767594337463)
[2024-12-17 02:36:59,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:59,266][root][INFO] - Training Epoch: 2/2, step 2445/7134 completed (loss: 0.25797319412231445, acc: 0.9426751732826233)
[2024-12-17 02:36:59,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:59,565][root][INFO] - Training Epoch: 2/2, step 2446/7134 completed (loss: 0.3831263482570648, acc: 0.8896104097366333)
[2024-12-17 02:36:59,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:59,855][root][INFO] - Training Epoch: 2/2, step 2447/7134 completed (loss: 0.1467057317495346, acc: 0.966292142868042)
[2024-12-17 02:36:59,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:00,130][root][INFO] - Training Epoch: 2/2, step 2448/7134 completed (loss: 0.20997585356235504, acc: 0.9597315192222595)
[2024-12-17 02:37:00,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:00,393][root][INFO] - Training Epoch: 2/2, step 2449/7134 completed (loss: 0.4021230638027191, acc: 0.8837209343910217)
[2024-12-17 02:37:00,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:00,692][root][INFO] - Training Epoch: 2/2, step 2450/7134 completed (loss: 0.15705472230911255, acc: 0.9647058844566345)
[2024-12-17 02:37:00,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:00,960][root][INFO] - Training Epoch: 2/2, step 2451/7134 completed (loss: 0.15507252514362335, acc: 0.9679144620895386)
[2024-12-17 02:37:01,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:01,248][root][INFO] - Training Epoch: 2/2, step 2452/7134 completed (loss: 0.22396381199359894, acc: 0.9354838728904724)
[2024-12-17 02:37:01,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:01,545][root][INFO] - Training Epoch: 2/2, step 2453/7134 completed (loss: 0.2185467928647995, acc: 0.9378238320350647)
[2024-12-17 02:37:01,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:01,810][root][INFO] - Training Epoch: 2/2, step 2454/7134 completed (loss: 0.23104363679885864, acc: 0.9219858050346375)
[2024-12-17 02:37:01,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:02,143][root][INFO] - Training Epoch: 2/2, step 2455/7134 completed (loss: 0.08368724584579468, acc: 0.9815950989723206)
[2024-12-17 02:37:02,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:02,422][root][INFO] - Training Epoch: 2/2, step 2456/7134 completed (loss: 0.21601974964141846, acc: 0.9378238320350647)
[2024-12-17 02:37:02,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:02,717][root][INFO] - Training Epoch: 2/2, step 2457/7134 completed (loss: 0.30833885073661804, acc: 0.9084967374801636)
[2024-12-17 02:37:02,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:02,978][root][INFO] - Training Epoch: 2/2, step 2458/7134 completed (loss: 0.4064466953277588, acc: 0.9375)
[2024-12-17 02:37:03,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:03,281][root][INFO] - Training Epoch: 2/2, step 2459/7134 completed (loss: 0.15301160514354706, acc: 0.9707602262496948)
[2024-12-17 02:37:03,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:03,554][root][INFO] - Training Epoch: 2/2, step 2460/7134 completed (loss: 0.20242954790592194, acc: 0.9450549483299255)
[2024-12-17 02:37:03,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:03,826][root][INFO] - Training Epoch: 2/2, step 2461/7134 completed (loss: 0.06568143516778946, acc: 0.9811320900917053)
[2024-12-17 02:37:03,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:04,107][root][INFO] - Training Epoch: 2/2, step 2462/7134 completed (loss: 0.3145196735858917, acc: 0.9272727370262146)
[2024-12-17 02:37:04,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:04,395][root][INFO] - Training Epoch: 2/2, step 2463/7134 completed (loss: 0.06460734456777573, acc: 0.987500011920929)
[2024-12-17 02:37:04,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:04,660][root][INFO] - Training Epoch: 2/2, step 2464/7134 completed (loss: 0.2539438009262085, acc: 0.949999988079071)
[2024-12-17 02:37:04,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:04,948][root][INFO] - Training Epoch: 2/2, step 2465/7134 completed (loss: 0.15658149123191833, acc: 0.9553072452545166)
[2024-12-17 02:37:05,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:05,240][root][INFO] - Training Epoch: 2/2, step 2466/7134 completed (loss: 0.12954720854759216, acc: 0.9640718698501587)
[2024-12-17 02:37:05,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:05,525][root][INFO] - Training Epoch: 2/2, step 2467/7134 completed (loss: 0.3219223618507385, acc: 0.9213483333587646)
[2024-12-17 02:37:05,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:05,806][root][INFO] - Training Epoch: 2/2, step 2468/7134 completed (loss: 0.18034812808036804, acc: 0.9593023061752319)
[2024-12-17 02:37:05,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:06,099][root][INFO] - Training Epoch: 2/2, step 2469/7134 completed (loss: 0.03709707409143448, acc: 0.9825581312179565)
[2024-12-17 02:37:06,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:06,370][root][INFO] - Training Epoch: 2/2, step 2470/7134 completed (loss: 0.2600374221801758, acc: 0.9432623982429504)
[2024-12-17 02:37:06,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:06,647][root][INFO] - Training Epoch: 2/2, step 2471/7134 completed (loss: 0.30681905150413513, acc: 0.9503546357154846)
[2024-12-17 02:37:06,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:06,917][root][INFO] - Training Epoch: 2/2, step 2472/7134 completed (loss: 0.06940662860870361, acc: 0.9797297120094299)
[2024-12-17 02:37:07,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:07,201][root][INFO] - Training Epoch: 2/2, step 2473/7134 completed (loss: 0.14097757637500763, acc: 0.9439252614974976)
[2024-12-17 02:37:07,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:07,484][root][INFO] - Training Epoch: 2/2, step 2474/7134 completed (loss: 0.05537344142794609, acc: 0.9878787994384766)
[2024-12-17 02:37:07,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:07,752][root][INFO] - Training Epoch: 2/2, step 2475/7134 completed (loss: 0.11115767806768417, acc: 0.9754098653793335)
[2024-12-17 02:37:07,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:08,044][root][INFO] - Training Epoch: 2/2, step 2476/7134 completed (loss: 0.09908003360033035, acc: 0.9707602262496948)
[2024-12-17 02:37:08,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:08,324][root][INFO] - Training Epoch: 2/2, step 2477/7134 completed (loss: 0.10137208551168442, acc: 0.9753086566925049)
[2024-12-17 02:37:08,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:08,590][root][INFO] - Training Epoch: 2/2, step 2478/7134 completed (loss: 0.1048850491642952, acc: 0.9731543660163879)
[2024-12-17 02:37:08,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:08,857][root][INFO] - Training Epoch: 2/2, step 2479/7134 completed (loss: 0.40002211928367615, acc: 0.8979591727256775)
[2024-12-17 02:37:08,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:09,135][root][INFO] - Training Epoch: 2/2, step 2480/7134 completed (loss: 0.190995454788208, acc: 0.9519230723381042)
[2024-12-17 02:37:09,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:09,430][root][INFO] - Training Epoch: 2/2, step 2481/7134 completed (loss: 0.18453693389892578, acc: 0.9519230723381042)
[2024-12-17 02:37:09,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:09,728][root][INFO] - Training Epoch: 2/2, step 2482/7134 completed (loss: 0.18742062151432037, acc: 0.9415584206581116)
[2024-12-17 02:37:09,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:10,030][root][INFO] - Training Epoch: 2/2, step 2483/7134 completed (loss: 0.0748751312494278, acc: 0.9820359349250793)
[2024-12-17 02:37:10,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:10,319][root][INFO] - Training Epoch: 2/2, step 2484/7134 completed (loss: 0.18501102924346924, acc: 0.9578313231468201)
[2024-12-17 02:37:10,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:10,596][root][INFO] - Training Epoch: 2/2, step 2485/7134 completed (loss: 0.08770103752613068, acc: 0.9777777791023254)
[2024-12-17 02:37:10,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:10,880][root][INFO] - Training Epoch: 2/2, step 2486/7134 completed (loss: 0.17775999009609222, acc: 0.9794520735740662)
[2024-12-17 02:37:11,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:11,152][root][INFO] - Training Epoch: 2/2, step 2487/7134 completed (loss: 0.348747193813324, acc: 0.8958333134651184)
[2024-12-17 02:37:11,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:11,433][root][INFO] - Training Epoch: 2/2, step 2488/7134 completed (loss: 0.18906597793102264, acc: 0.9515151381492615)
[2024-12-17 02:37:11,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:11,698][root][INFO] - Training Epoch: 2/2, step 2489/7134 completed (loss: 0.11696501821279526, acc: 0.9585798978805542)
[2024-12-17 02:37:11,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:11,978][root][INFO] - Training Epoch: 2/2, step 2490/7134 completed (loss: 0.1366521120071411, acc: 0.9740259647369385)
[2024-12-17 02:37:12,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:12,255][root][INFO] - Training Epoch: 2/2, step 2491/7134 completed (loss: 0.313961386680603, acc: 0.9253731369972229)
[2024-12-17 02:37:12,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:12,521][root][INFO] - Training Epoch: 2/2, step 2492/7134 completed (loss: 0.1340893805027008, acc: 0.9748427867889404)
[2024-12-17 02:37:12,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:12,818][root][INFO] - Training Epoch: 2/2, step 2493/7134 completed (loss: 0.11401790380477905, acc: 0.9702380895614624)
[2024-12-17 02:37:12,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:13,081][root][INFO] - Training Epoch: 2/2, step 2494/7134 completed (loss: 0.11433493345975876, acc: 0.9506173133850098)
[2024-12-17 02:37:13,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:13,350][root][INFO] - Training Epoch: 2/2, step 2495/7134 completed (loss: 0.17777733504772186, acc: 0.970588207244873)
[2024-12-17 02:37:13,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:13,623][root][INFO] - Training Epoch: 2/2, step 2496/7134 completed (loss: 0.15678291022777557, acc: 0.9556962251663208)
[2024-12-17 02:37:13,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:13,911][root][INFO] - Training Epoch: 2/2, step 2497/7134 completed (loss: 0.1681777387857437, acc: 0.954023003578186)
[2024-12-17 02:37:14,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:14,200][root][INFO] - Training Epoch: 2/2, step 2498/7134 completed (loss: 0.12163583189249039, acc: 0.9714285731315613)
[2024-12-17 02:37:14,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:14,480][root][INFO] - Training Epoch: 2/2, step 2499/7134 completed (loss: 0.10477194935083389, acc: 0.9759036302566528)
[2024-12-17 02:37:14,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:14,751][root][INFO] - Training Epoch: 2/2, step 2500/7134 completed (loss: 0.1444874107837677, acc: 0.9594594836235046)
[2024-12-17 02:37:14,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:15,024][root][INFO] - Training Epoch: 2/2, step 2501/7134 completed (loss: 0.14593741297721863, acc: 0.9606741666793823)
[2024-12-17 02:37:15,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:15,305][root][INFO] - Training Epoch: 2/2, step 2502/7134 completed (loss: 0.107515849173069, acc: 0.9743589758872986)
[2024-12-17 02:37:15,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:15,562][root][INFO] - Training Epoch: 2/2, step 2503/7134 completed (loss: 0.1513305902481079, acc: 0.9637681245803833)
[2024-12-17 02:37:15,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:15,840][root][INFO] - Training Epoch: 2/2, step 2504/7134 completed (loss: 0.10646497458219528, acc: 0.9746835231781006)
[2024-12-17 02:37:15,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:16,138][root][INFO] - Training Epoch: 2/2, step 2505/7134 completed (loss: 0.09909951686859131, acc: 0.9767441749572754)
[2024-12-17 02:37:16,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:16,438][root][INFO] - Training Epoch: 2/2, step 2506/7134 completed (loss: 0.12075547128915787, acc: 0.9672130942344666)
[2024-12-17 02:37:16,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:16,720][root][INFO] - Training Epoch: 2/2, step 2507/7134 completed (loss: 0.0671587735414505, acc: 0.9944444298744202)
[2024-12-17 02:37:16,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:17,010][root][INFO] - Training Epoch: 2/2, step 2508/7134 completed (loss: 0.08610600233078003, acc: 0.9830508232116699)
[2024-12-17 02:37:17,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:17,298][root][INFO] - Training Epoch: 2/2, step 2509/7134 completed (loss: 0.05601276457309723, acc: 0.9882352948188782)
[2024-12-17 02:37:17,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:17,584][root][INFO] - Training Epoch: 2/2, step 2510/7134 completed (loss: 0.05042837932705879, acc: 0.9785714149475098)
[2024-12-17 02:37:17,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:17,859][root][INFO] - Training Epoch: 2/2, step 2511/7134 completed (loss: 0.2870420515537262, acc: 0.9453551769256592)
[2024-12-17 02:37:17,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:18,137][root][INFO] - Training Epoch: 2/2, step 2512/7134 completed (loss: 0.15785034000873566, acc: 0.9470587968826294)
[2024-12-17 02:37:18,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:18,425][root][INFO] - Training Epoch: 2/2, step 2513/7134 completed (loss: 0.11570718139410019, acc: 0.9623655676841736)
[2024-12-17 02:37:18,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:18,708][root][INFO] - Training Epoch: 2/2, step 2514/7134 completed (loss: 0.11443958431482315, acc: 0.9554139971733093)
[2024-12-17 02:37:18,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:18,998][root][INFO] - Training Epoch: 2/2, step 2515/7134 completed (loss: 0.09473336488008499, acc: 0.9740259647369385)
[2024-12-17 02:37:19,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:19,293][root][INFO] - Training Epoch: 2/2, step 2516/7134 completed (loss: 0.12943068146705627, acc: 0.9888268113136292)
[2024-12-17 02:37:19,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:19,577][root][INFO] - Training Epoch: 2/2, step 2517/7134 completed (loss: 0.1259864866733551, acc: 0.9722222089767456)
[2024-12-17 02:37:19,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:19,855][root][INFO] - Training Epoch: 2/2, step 2518/7134 completed (loss: 0.15293000638484955, acc: 0.9542483687400818)
[2024-12-17 02:37:19,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:20,147][root][INFO] - Training Epoch: 2/2, step 2519/7134 completed (loss: 0.04851781949400902, acc: 0.9870967864990234)
[2024-12-17 02:37:20,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:20,430][root][INFO] - Training Epoch: 2/2, step 2520/7134 completed (loss: 0.11413642019033432, acc: 0.9605262875556946)
[2024-12-17 02:37:20,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:20,713][root][INFO] - Training Epoch: 2/2, step 2521/7134 completed (loss: 0.22836802899837494, acc: 0.9670329689979553)
[2024-12-17 02:37:20,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:20,995][root][INFO] - Training Epoch: 2/2, step 2522/7134 completed (loss: 0.08445974439382553, acc: 0.9793103337287903)
[2024-12-17 02:37:21,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:21,278][root][INFO] - Training Epoch: 2/2, step 2523/7134 completed (loss: 0.15259501338005066, acc: 0.9693251252174377)
[2024-12-17 02:37:21,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:21,567][root][INFO] - Training Epoch: 2/2, step 2524/7134 completed (loss: 0.06973273307085037, acc: 0.9817073345184326)
[2024-12-17 02:37:21,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:21,841][root][INFO] - Training Epoch: 2/2, step 2525/7134 completed (loss: 0.12698374688625336, acc: 0.9589040875434875)
[2024-12-17 02:37:21,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:22,123][root][INFO] - Training Epoch: 2/2, step 2526/7134 completed (loss: 0.06028685346245766, acc: 0.9898989796638489)
[2024-12-17 02:37:22,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:22,426][root][INFO] - Training Epoch: 2/2, step 2527/7134 completed (loss: 0.08787350356578827, acc: 0.9781420826911926)
[2024-12-17 02:37:22,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:22,711][root][INFO] - Training Epoch: 2/2, step 2528/7134 completed (loss: 0.07701581716537476, acc: 0.9819276928901672)
[2024-12-17 02:37:22,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:23,001][root][INFO] - Training Epoch: 2/2, step 2529/7134 completed (loss: 0.09379157423973083, acc: 0.9702380895614624)
[2024-12-17 02:37:23,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:23,294][root][INFO] - Training Epoch: 2/2, step 2530/7134 completed (loss: 0.052176278084516525, acc: 0.983146071434021)
[2024-12-17 02:37:23,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:23,571][root][INFO] - Training Epoch: 2/2, step 2531/7134 completed (loss: 0.05965714901685715, acc: 0.9759036302566528)
[2024-12-17 02:37:23,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:23,846][root][INFO] - Training Epoch: 2/2, step 2532/7134 completed (loss: 0.06830844283103943, acc: 0.9800000190734863)
[2024-12-17 02:37:23,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:24,126][root][INFO] - Training Epoch: 2/2, step 2533/7134 completed (loss: 0.12015318125486374, acc: 0.9679487347602844)
[2024-12-17 02:37:24,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:24,417][root][INFO] - Training Epoch: 2/2, step 2534/7134 completed (loss: 0.09600753337144852, acc: 0.9720670580863953)
[2024-12-17 02:37:24,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:24,700][root][INFO] - Training Epoch: 2/2, step 2535/7134 completed (loss: 0.060048166662454605, acc: 0.9830508232116699)
[2024-12-17 02:37:24,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:24,987][root][INFO] - Training Epoch: 2/2, step 2536/7134 completed (loss: 0.25193384289741516, acc: 0.9170984625816345)
[2024-12-17 02:37:25,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:25,268][root][INFO] - Training Epoch: 2/2, step 2537/7134 completed (loss: 0.2091086208820343, acc: 0.9383561611175537)
[2024-12-17 02:37:25,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:25,550][root][INFO] - Training Epoch: 2/2, step 2538/7134 completed (loss: 0.29487931728363037, acc: 0.9425287246704102)
[2024-12-17 02:37:25,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:25,802][root][INFO] - Training Epoch: 2/2, step 2539/7134 completed (loss: 0.14153307676315308, acc: 0.9774436354637146)
[2024-12-17 02:37:25,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:26,084][root][INFO] - Training Epoch: 2/2, step 2540/7134 completed (loss: 0.20231765508651733, acc: 0.9271523356437683)
[2024-12-17 02:37:26,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:26,371][root][INFO] - Training Epoch: 2/2, step 2541/7134 completed (loss: 0.11218726634979248, acc: 0.970588207244873)
[2024-12-17 02:37:26,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:26,656][root][INFO] - Training Epoch: 2/2, step 2542/7134 completed (loss: 0.11326651275157928, acc: 0.9750000238418579)
[2024-12-17 02:37:26,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:26,975][root][INFO] - Training Epoch: 2/2, step 2543/7134 completed (loss: 0.2991366982460022, acc: 0.9308176040649414)
[2024-12-17 02:37:27,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:27,259][root][INFO] - Training Epoch: 2/2, step 2544/7134 completed (loss: 0.10296867042779922, acc: 0.9642857313156128)
[2024-12-17 02:37:27,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:27,546][root][INFO] - Training Epoch: 2/2, step 2545/7134 completed (loss: 0.09648282080888748, acc: 0.9776119589805603)
[2024-12-17 02:37:27,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:27,846][root][INFO] - Training Epoch: 2/2, step 2546/7134 completed (loss: 0.3695700764656067, acc: 0.918367326259613)
[2024-12-17 02:37:27,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:28,146][root][INFO] - Training Epoch: 2/2, step 2547/7134 completed (loss: 0.23733286559581757, acc: 0.9136690497398376)
[2024-12-17 02:37:28,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:28,431][root][INFO] - Training Epoch: 2/2, step 2548/7134 completed (loss: 0.10855498909950256, acc: 0.9734513163566589)
[2024-12-17 02:37:28,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:28,720][root][INFO] - Training Epoch: 2/2, step 2549/7134 completed (loss: 0.24268639087677002, acc: 0.9105691313743591)
[2024-12-17 02:37:28,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:29,038][root][INFO] - Training Epoch: 2/2, step 2550/7134 completed (loss: 0.09035705029964447, acc: 0.9794520735740662)
[2024-12-17 02:37:29,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:29,313][root][INFO] - Training Epoch: 2/2, step 2551/7134 completed (loss: 0.20532846450805664, acc: 0.95652174949646)
[2024-12-17 02:37:29,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:29,590][root][INFO] - Training Epoch: 2/2, step 2552/7134 completed (loss: 0.06474784761667252, acc: 0.9873417615890503)
[2024-12-17 02:37:29,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:29,831][root][INFO] - Training Epoch: 2/2, step 2553/7134 completed (loss: 0.24495109915733337, acc: 0.9473684430122375)
[2024-12-17 02:37:29,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:30,128][root][INFO] - Training Epoch: 2/2, step 2554/7134 completed (loss: 0.2191135585308075, acc: 0.9212598204612732)
[2024-12-17 02:37:30,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:30,404][root][INFO] - Training Epoch: 2/2, step 2555/7134 completed (loss: 0.1333467662334442, acc: 0.9639639854431152)
[2024-12-17 02:37:30,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:30,696][root][INFO] - Training Epoch: 2/2, step 2556/7134 completed (loss: 0.1798301339149475, acc: 0.949999988079071)
[2024-12-17 02:37:30,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:30,989][root][INFO] - Training Epoch: 2/2, step 2557/7134 completed (loss: 0.1580224335193634, acc: 0.9659863710403442)
[2024-12-17 02:37:31,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:31,260][root][INFO] - Training Epoch: 2/2, step 2558/7134 completed (loss: 0.09156813472509384, acc: 0.970802903175354)
[2024-12-17 02:37:31,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:31,543][root][INFO] - Training Epoch: 2/2, step 2559/7134 completed (loss: 0.09814818203449249, acc: 0.9750000238418579)
[2024-12-17 02:37:31,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:31,839][root][INFO] - Training Epoch: 2/2, step 2560/7134 completed (loss: 0.07862149178981781, acc: 0.9797297120094299)
[2024-12-17 02:37:31,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:32,121][root][INFO] - Training Epoch: 2/2, step 2561/7134 completed (loss: 0.10275676101446152, acc: 0.9791666865348816)
[2024-12-17 02:37:32,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:32,392][root][INFO] - Training Epoch: 2/2, step 2562/7134 completed (loss: 0.12845224142074585, acc: 0.9599999785423279)
[2024-12-17 02:37:32,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:32,682][root][INFO] - Training Epoch: 2/2, step 2563/7134 completed (loss: 0.12150196731090546, acc: 0.976331353187561)
[2024-12-17 02:37:32,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:32,962][root][INFO] - Training Epoch: 2/2, step 2564/7134 completed (loss: 0.472178190946579, acc: 0.9136690497398376)
[2024-12-17 02:37:33,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:33,251][root][INFO] - Training Epoch: 2/2, step 2565/7134 completed (loss: 0.08656533062458038, acc: 0.9856114983558655)
[2024-12-17 02:37:33,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:33,541][root][INFO] - Training Epoch: 2/2, step 2566/7134 completed (loss: 0.09941522777080536, acc: 0.9698795080184937)
[2024-12-17 02:37:33,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:33,796][root][INFO] - Training Epoch: 2/2, step 2567/7134 completed (loss: 0.09755151718854904, acc: 0.9624060392379761)
[2024-12-17 02:37:33,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:34,075][root][INFO] - Training Epoch: 2/2, step 2568/7134 completed (loss: 0.23229961097240448, acc: 0.942307710647583)
[2024-12-17 02:37:34,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:34,374][root][INFO] - Training Epoch: 2/2, step 2569/7134 completed (loss: 0.054645609110593796, acc: 0.9929577708244324)
[2024-12-17 02:37:34,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:34,653][root][INFO] - Training Epoch: 2/2, step 2570/7134 completed (loss: 0.12746767699718475, acc: 0.9668874144554138)
[2024-12-17 02:37:34,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:34,910][root][INFO] - Training Epoch: 2/2, step 2571/7134 completed (loss: 0.06823188066482544, acc: 0.9918032884597778)
[2024-12-17 02:37:35,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:35,191][root][INFO] - Training Epoch: 2/2, step 2572/7134 completed (loss: 0.1082301214337349, acc: 0.9659863710403442)
[2024-12-17 02:37:35,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:35,475][root][INFO] - Training Epoch: 2/2, step 2573/7134 completed (loss: 0.10773609578609467, acc: 0.9928057789802551)
[2024-12-17 02:37:35,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:35,750][root][INFO] - Training Epoch: 2/2, step 2574/7134 completed (loss: 0.13336458802223206, acc: 0.9696969985961914)
[2024-12-17 02:37:35,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:36,022][root][INFO] - Training Epoch: 2/2, step 2575/7134 completed (loss: 0.10418856889009476, acc: 0.9754098653793335)
[2024-12-17 02:37:36,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:36,292][root][INFO] - Training Epoch: 2/2, step 2576/7134 completed (loss: 0.06412718445062637, acc: 0.9918699264526367)
[2024-12-17 02:37:36,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:36,568][root][INFO] - Training Epoch: 2/2, step 2577/7134 completed (loss: 0.34174951910972595, acc: 0.960629940032959)
[2024-12-17 02:37:36,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:36,849][root][INFO] - Training Epoch: 2/2, step 2578/7134 completed (loss: 0.31627464294433594, acc: 0.9281045794487)
[2024-12-17 02:37:36,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:37,136][root][INFO] - Training Epoch: 2/2, step 2579/7134 completed (loss: 0.27886348962783813, acc: 0.9166666865348816)
[2024-12-17 02:37:37,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:37,424][root][INFO] - Training Epoch: 2/2, step 2580/7134 completed (loss: 0.3087175190448761, acc: 0.8959537744522095)
[2024-12-17 02:37:37,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:37,717][root][INFO] - Training Epoch: 2/2, step 2581/7134 completed (loss: 0.3544209897518158, acc: 0.9265536665916443)
[2024-12-17 02:37:37,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:38,003][root][INFO] - Training Epoch: 2/2, step 2582/7134 completed (loss: 0.22154854238033295, acc: 0.9435028433799744)
[2024-12-17 02:37:38,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:38,289][root][INFO] - Training Epoch: 2/2, step 2583/7134 completed (loss: 0.3000735640525818, acc: 0.9137930870056152)
[2024-12-17 02:37:38,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:38,578][root][INFO] - Training Epoch: 2/2, step 2584/7134 completed (loss: 0.3451874256134033, acc: 0.914893627166748)
[2024-12-17 02:37:38,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:38,867][root][INFO] - Training Epoch: 2/2, step 2585/7134 completed (loss: 0.2707732319831848, acc: 0.9470198750495911)
[2024-12-17 02:37:38,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:39,166][root][INFO] - Training Epoch: 2/2, step 2586/7134 completed (loss: 0.27263784408569336, acc: 0.9307692050933838)
[2024-12-17 02:37:39,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:39,452][root][INFO] - Training Epoch: 2/2, step 2587/7134 completed (loss: 0.13290081918239594, acc: 0.9750000238418579)
[2024-12-17 02:37:39,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:39,736][root][INFO] - Training Epoch: 2/2, step 2588/7134 completed (loss: 0.1528705358505249, acc: 0.9659863710403442)
[2024-12-17 02:37:39,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:40,006][root][INFO] - Training Epoch: 2/2, step 2589/7134 completed (loss: 0.3086221218109131, acc: 0.9126983880996704)
[2024-12-17 02:37:40,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:40,291][root][INFO] - Training Epoch: 2/2, step 2590/7134 completed (loss: 0.22309039533138275, acc: 0.9259259104728699)
[2024-12-17 02:37:40,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:40,562][root][INFO] - Training Epoch: 2/2, step 2591/7134 completed (loss: 0.37448057532310486, acc: 0.9005848169326782)
[2024-12-17 02:37:40,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:40,843][root][INFO] - Training Epoch: 2/2, step 2592/7134 completed (loss: 0.3575686514377594, acc: 0.9217877388000488)
[2024-12-17 02:37:40,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:41,127][root][INFO] - Training Epoch: 2/2, step 2593/7134 completed (loss: 0.16344484686851501, acc: 0.9817073345184326)
[2024-12-17 02:37:41,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:41,406][root][INFO] - Training Epoch: 2/2, step 2594/7134 completed (loss: 0.3832518756389618, acc: 0.9281045794487)
[2024-12-17 02:37:41,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:41,689][root][INFO] - Training Epoch: 2/2, step 2595/7134 completed (loss: 0.16893039643764496, acc: 0.957317054271698)
[2024-12-17 02:37:41,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:41,987][root][INFO] - Training Epoch: 2/2, step 2596/7134 completed (loss: 0.20080140233039856, acc: 0.9352940917015076)
[2024-12-17 02:37:42,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:42,263][root][INFO] - Training Epoch: 2/2, step 2597/7134 completed (loss: 0.26745927333831787, acc: 0.9265536665916443)
[2024-12-17 02:37:42,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:42,537][root][INFO] - Training Epoch: 2/2, step 2598/7134 completed (loss: 0.31366732716560364, acc: 0.9072847962379456)
[2024-12-17 02:37:42,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:42,811][root][INFO] - Training Epoch: 2/2, step 2599/7134 completed (loss: 0.026840923354029655, acc: 0.9937106966972351)
[2024-12-17 02:37:42,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:43,102][root][INFO] - Training Epoch: 2/2, step 2600/7134 completed (loss: 0.27261486649513245, acc: 0.9438202381134033)
[2024-12-17 02:37:43,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:43,383][root][INFO] - Training Epoch: 2/2, step 2601/7134 completed (loss: 0.28155142068862915, acc: 0.9354838728904724)
[2024-12-17 02:37:43,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:43,664][root][INFO] - Training Epoch: 2/2, step 2602/7134 completed (loss: 0.19332949817180634, acc: 0.9404761791229248)
[2024-12-17 02:37:43,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:43,979][root][INFO] - Training Epoch: 2/2, step 2603/7134 completed (loss: 0.2790433466434479, acc: 0.9215686321258545)
[2024-12-17 02:37:44,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:44,276][root][INFO] - Training Epoch: 2/2, step 2604/7134 completed (loss: 0.21831829845905304, acc: 0.9523809552192688)
[2024-12-17 02:37:44,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:44,546][root][INFO] - Training Epoch: 2/2, step 2605/7134 completed (loss: 0.2937833368778229, acc: 0.9203540086746216)
[2024-12-17 02:37:44,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:44,821][root][INFO] - Training Epoch: 2/2, step 2606/7134 completed (loss: 0.23459714651107788, acc: 0.9399999976158142)
[2024-12-17 02:37:44,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:45,098][root][INFO] - Training Epoch: 2/2, step 2607/7134 completed (loss: 0.2665414810180664, acc: 0.9382022619247437)
[2024-12-17 02:37:45,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:45,377][root][INFO] - Training Epoch: 2/2, step 2608/7134 completed (loss: 0.42193910479545593, acc: 0.8941798806190491)
[2024-12-17 02:37:45,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:45,658][root][INFO] - Training Epoch: 2/2, step 2609/7134 completed (loss: 0.3693395256996155, acc: 0.9281045794487)
[2024-12-17 02:37:45,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:45,913][root][INFO] - Training Epoch: 2/2, step 2610/7134 completed (loss: 0.2631172239780426, acc: 0.9568345546722412)
[2024-12-17 02:37:46,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:46,198][root][INFO] - Training Epoch: 2/2, step 2611/7134 completed (loss: 0.4143790900707245, acc: 0.9050279259681702)
[2024-12-17 02:37:46,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:46,489][root][INFO] - Training Epoch: 2/2, step 2612/7134 completed (loss: 0.33807262778282166, acc: 0.8799999952316284)
[2024-12-17 02:37:46,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:46,792][root][INFO] - Training Epoch: 2/2, step 2613/7134 completed (loss: 0.21314777433872223, acc: 0.9285714030265808)
[2024-12-17 02:37:46,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:47,079][root][INFO] - Training Epoch: 2/2, step 2614/7134 completed (loss: 0.4002566337585449, acc: 0.8936170339584351)
[2024-12-17 02:37:47,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:47,369][root][INFO] - Training Epoch: 2/2, step 2615/7134 completed (loss: 0.29269939661026, acc: 0.9438202381134033)
[2024-12-17 02:37:47,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:47,641][root][INFO] - Training Epoch: 2/2, step 2616/7134 completed (loss: 0.37241417169570923, acc: 0.9495798349380493)
[2024-12-17 02:37:47,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:47,991][root][INFO] - Training Epoch: 2/2, step 2617/7134 completed (loss: 0.4662961959838867, acc: 0.8629441857337952)
[2024-12-17 02:37:48,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:48,253][root][INFO] - Training Epoch: 2/2, step 2618/7134 completed (loss: 0.19126828014850616, acc: 0.9316239356994629)
[2024-12-17 02:37:48,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:48,526][root][INFO] - Training Epoch: 2/2, step 2619/7134 completed (loss: 0.2726953327655792, acc: 0.9057971239089966)
[2024-12-17 02:37:48,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:48,813][root][INFO] - Training Epoch: 2/2, step 2620/7134 completed (loss: 0.2906493842601776, acc: 0.920634925365448)
[2024-12-17 02:37:48,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:49,097][root][INFO] - Training Epoch: 2/2, step 2621/7134 completed (loss: 0.3806166648864746, acc: 0.8770053386688232)
[2024-12-17 02:37:49,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:49,398][root][INFO] - Training Epoch: 2/2, step 2622/7134 completed (loss: 0.24510560929775238, acc: 0.9383561611175537)
[2024-12-17 02:37:49,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:49,694][root][INFO] - Training Epoch: 2/2, step 2623/7134 completed (loss: 0.3246777653694153, acc: 0.8761467933654785)
[2024-12-17 02:37:49,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:49,975][root][INFO] - Training Epoch: 2/2, step 2624/7134 completed (loss: 0.44865235686302185, acc: 0.8666666746139526)
[2024-12-17 02:37:50,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:50,283][root][INFO] - Training Epoch: 2/2, step 2625/7134 completed (loss: 0.3305452764034271, acc: 0.9107142686843872)
[2024-12-17 02:37:50,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:50,573][root][INFO] - Training Epoch: 2/2, step 2626/7134 completed (loss: 0.25833359360694885, acc: 0.9425287246704102)
[2024-12-17 02:37:50,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:50,881][root][INFO] - Training Epoch: 2/2, step 2627/7134 completed (loss: 0.25304630398750305, acc: 0.9325153231620789)
[2024-12-17 02:37:51,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:51,174][root][INFO] - Training Epoch: 2/2, step 2628/7134 completed (loss: 0.34154602885246277, acc: 0.9277777671813965)
[2024-12-17 02:37:51,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:51,580][root][INFO] - Training Epoch: 2/2, step 2629/7134 completed (loss: 0.14750520884990692, acc: 0.9640718698501587)
[2024-12-17 02:37:51,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:51,882][root][INFO] - Training Epoch: 2/2, step 2630/7134 completed (loss: 0.26728880405426025, acc: 0.9275362491607666)
[2024-12-17 02:37:52,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:52,186][root][INFO] - Training Epoch: 2/2, step 2631/7134 completed (loss: 0.20801040530204773, acc: 0.9390863180160522)
[2024-12-17 02:37:52,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:52,477][root][INFO] - Training Epoch: 2/2, step 2632/7134 completed (loss: 0.14310091733932495, acc: 0.991304337978363)
[2024-12-17 02:37:52,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:52,757][root][INFO] - Training Epoch: 2/2, step 2633/7134 completed (loss: 0.36417511105537415, acc: 0.9175823926925659)
[2024-12-17 02:37:52,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:53,026][root][INFO] - Training Epoch: 2/2, step 2634/7134 completed (loss: 0.12842020392417908, acc: 0.9526627063751221)
[2024-12-17 02:37:53,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:53,327][root][INFO] - Training Epoch: 2/2, step 2635/7134 completed (loss: 0.4757731556892395, acc: 0.9166666865348816)
[2024-12-17 02:37:53,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:53,621][root][INFO] - Training Epoch: 2/2, step 2636/7134 completed (loss: 0.34686627984046936, acc: 0.9217877388000488)
[2024-12-17 02:37:53,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:53,902][root][INFO] - Training Epoch: 2/2, step 2637/7134 completed (loss: 0.6391088962554932, acc: 0.8650306463241577)
[2024-12-17 02:37:54,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:54,200][root][INFO] - Training Epoch: 2/2, step 2638/7134 completed (loss: 0.47268596291542053, acc: 0.8905472755432129)
[2024-12-17 02:37:54,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:54,472][root][INFO] - Training Epoch: 2/2, step 2639/7134 completed (loss: 0.6025347709655762, acc: 0.8646616339683533)
[2024-12-17 02:37:54,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:54,753][root][INFO] - Training Epoch: 2/2, step 2640/7134 completed (loss: 0.5459874868392944, acc: 0.8905472755432129)
[2024-12-17 02:37:54,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:55,036][root][INFO] - Training Epoch: 2/2, step 2641/7134 completed (loss: 0.3863716721534729, acc: 0.9371428489685059)
[2024-12-17 02:37:55,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:55,328][root][INFO] - Training Epoch: 2/2, step 2642/7134 completed (loss: 0.6817234754562378, acc: 0.8690476417541504)
[2024-12-17 02:37:55,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:55,619][root][INFO] - Training Epoch: 2/2, step 2643/7134 completed (loss: 0.5236743688583374, acc: 0.8779069781303406)
[2024-12-17 02:37:55,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:55,956][root][INFO] - Training Epoch: 2/2, step 2644/7134 completed (loss: 0.34342968463897705, acc: 0.9312169551849365)
[2024-12-17 02:37:56,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:56,237][root][INFO] - Training Epoch: 2/2, step 2645/7134 completed (loss: 0.28803256154060364, acc: 0.9314285516738892)
[2024-12-17 02:37:56,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:56,531][root][INFO] - Training Epoch: 2/2, step 2646/7134 completed (loss: 0.37617212533950806, acc: 0.9254658222198486)
[2024-12-17 02:37:56,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:56,832][root][INFO] - Training Epoch: 2/2, step 2647/7134 completed (loss: 0.2967406213283539, acc: 0.9130434989929199)
[2024-12-17 02:37:56,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:57,150][root][INFO] - Training Epoch: 2/2, step 2648/7134 completed (loss: 0.33095788955688477, acc: 0.9257425665855408)
[2024-12-17 02:37:57,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:57,446][root][INFO] - Training Epoch: 2/2, step 2649/7134 completed (loss: 0.5118376016616821, acc: 0.8270270228385925)
[2024-12-17 02:37:57,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:57,714][root][INFO] - Training Epoch: 2/2, step 2650/7134 completed (loss: 0.651570200920105, acc: 0.8529411554336548)
[2024-12-17 02:37:57,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:57,997][root][INFO] - Training Epoch: 2/2, step 2651/7134 completed (loss: 0.2018086314201355, acc: 0.9512194991111755)
[2024-12-17 02:37:58,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:58,285][root][INFO] - Training Epoch: 2/2, step 2652/7134 completed (loss: 0.3099534213542938, acc: 0.9438202381134033)
[2024-12-17 02:37:58,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:58,549][root][INFO] - Training Epoch: 2/2, step 2653/7134 completed (loss: 0.2588127851486206, acc: 0.9607843160629272)
[2024-12-17 02:37:58,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:58,827][root][INFO] - Training Epoch: 2/2, step 2654/7134 completed (loss: 0.21519538760185242, acc: 0.9642857313156128)
[2024-12-17 02:37:58,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:59,125][root][INFO] - Training Epoch: 2/2, step 2655/7134 completed (loss: 0.2037431001663208, acc: 0.9503105878829956)
[2024-12-17 02:37:59,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:59,420][root][INFO] - Training Epoch: 2/2, step 2656/7134 completed (loss: 0.32381683588027954, acc: 0.9418604373931885)
[2024-12-17 02:37:59,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:59,724][root][INFO] - Training Epoch: 2/2, step 2657/7134 completed (loss: 0.23289236426353455, acc: 0.9430379867553711)
[2024-12-17 02:37:59,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:00,038][root][INFO] - Training Epoch: 2/2, step 2658/7134 completed (loss: 0.3238522708415985, acc: 0.9343434572219849)
[2024-12-17 02:38:00,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:00,335][root][INFO] - Training Epoch: 2/2, step 2659/7134 completed (loss: 0.36974284052848816, acc: 0.9328358173370361)
[2024-12-17 02:38:00,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:00,640][root][INFO] - Training Epoch: 2/2, step 2660/7134 completed (loss: 0.42116084694862366, acc: 0.8803418874740601)
[2024-12-17 02:38:00,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:00,916][root][INFO] - Training Epoch: 2/2, step 2661/7134 completed (loss: 0.14965832233428955, acc: 0.9644970297813416)
[2024-12-17 02:38:01,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:01,197][root][INFO] - Training Epoch: 2/2, step 2662/7134 completed (loss: 0.20563936233520508, acc: 0.9444444179534912)
[2024-12-17 02:38:01,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:01,489][root][INFO] - Training Epoch: 2/2, step 2663/7134 completed (loss: 0.22173969447612762, acc: 0.9326424598693848)
[2024-12-17 02:38:01,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:01,775][root][INFO] - Training Epoch: 2/2, step 2664/7134 completed (loss: 0.2797233760356903, acc: 0.930232584476471)
[2024-12-17 02:38:01,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:02,050][root][INFO] - Training Epoch: 2/2, step 2665/7134 completed (loss: 0.09258882701396942, acc: 0.9819276928901672)
[2024-12-17 02:38:02,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:02,341][root][INFO] - Training Epoch: 2/2, step 2666/7134 completed (loss: 0.12051284313201904, acc: 0.9709302186965942)
[2024-12-17 02:38:02,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:02,622][root][INFO] - Training Epoch: 2/2, step 2667/7134 completed (loss: 0.05382358655333519, acc: 0.9873417615890503)
[2024-12-17 02:38:02,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:02,900][root][INFO] - Training Epoch: 2/2, step 2668/7134 completed (loss: 0.043115489184856415, acc: 0.9885714054107666)
[2024-12-17 02:38:03,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:03,191][root][INFO] - Training Epoch: 2/2, step 2669/7134 completed (loss: 0.061785612255334854, acc: 0.9850746393203735)
[2024-12-17 02:38:03,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:03,478][root][INFO] - Training Epoch: 2/2, step 2670/7134 completed (loss: 0.18260513246059418, acc: 0.9485714435577393)
[2024-12-17 02:38:03,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:03,760][root][INFO] - Training Epoch: 2/2, step 2671/7134 completed (loss: 0.16302593052387238, acc: 0.9428571462631226)
[2024-12-17 02:38:03,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:04,043][root][INFO] - Training Epoch: 2/2, step 2672/7134 completed (loss: 0.04555978998541832, acc: 0.9879518151283264)
[2024-12-17 02:38:04,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:04,362][root][INFO] - Training Epoch: 2/2, step 2673/7134 completed (loss: 0.06599487364292145, acc: 0.9944751262664795)
[2024-12-17 02:38:04,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:04,652][root][INFO] - Training Epoch: 2/2, step 2674/7134 completed (loss: 0.11696470528841019, acc: 0.9691358208656311)
[2024-12-17 02:38:04,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:04,963][root][INFO] - Training Epoch: 2/2, step 2675/7134 completed (loss: 0.04371393844485283, acc: 0.9878787994384766)
[2024-12-17 02:38:05,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:05,241][root][INFO] - Training Epoch: 2/2, step 2676/7134 completed (loss: 0.10164055973291397, acc: 0.9772727489471436)
[2024-12-17 02:38:05,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:05,530][root][INFO] - Training Epoch: 2/2, step 2677/7134 completed (loss: 0.08519790321588516, acc: 0.9754601120948792)
[2024-12-17 02:38:05,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:05,820][root][INFO] - Training Epoch: 2/2, step 2678/7134 completed (loss: 0.03644895553588867, acc: 0.9830508232116699)
[2024-12-17 02:38:05,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:06,111][root][INFO] - Training Epoch: 2/2, step 2679/7134 completed (loss: 0.04557221755385399, acc: 0.9848484992980957)
[2024-12-17 02:38:06,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:06,390][root][INFO] - Training Epoch: 2/2, step 2680/7134 completed (loss: 0.12380362302064896, acc: 0.9670329689979553)
[2024-12-17 02:38:06,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:06,658][root][INFO] - Training Epoch: 2/2, step 2681/7134 completed (loss: 0.04582405835390091, acc: 0.9936708807945251)
[2024-12-17 02:38:06,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:06,923][root][INFO] - Training Epoch: 2/2, step 2682/7134 completed (loss: 0.09937555342912674, acc: 0.9731543660163879)
[2024-12-17 02:38:07,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:07,183][root][INFO] - Training Epoch: 2/2, step 2683/7134 completed (loss: 0.05746036767959595, acc: 0.9867549538612366)
[2024-12-17 02:38:07,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:07,474][root][INFO] - Training Epoch: 2/2, step 2684/7134 completed (loss: 0.20671769976615906, acc: 0.9453125)
[2024-12-17 02:38:07,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:07,759][root][INFO] - Training Epoch: 2/2, step 2685/7134 completed (loss: 0.08782187849283218, acc: 0.9822485446929932)
[2024-12-17 02:38:07,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:08,050][root][INFO] - Training Epoch: 2/2, step 2686/7134 completed (loss: 0.2240758091211319, acc: 0.9399999976158142)
[2024-12-17 02:38:08,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:08,313][root][INFO] - Training Epoch: 2/2, step 2687/7134 completed (loss: 0.22977663576602936, acc: 0.9411764740943909)
[2024-12-17 02:38:08,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:08,584][root][INFO] - Training Epoch: 2/2, step 2688/7134 completed (loss: 0.23670190572738647, acc: 0.9473684430122375)
[2024-12-17 02:38:08,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:08,804][root][INFO] - Training Epoch: 2/2, step 2689/7134 completed (loss: 0.23655913770198822, acc: 0.9593495726585388)
[2024-12-17 02:38:08,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:09,070][root][INFO] - Training Epoch: 2/2, step 2690/7134 completed (loss: 0.20602910220623016, acc: 0.9424460530281067)
[2024-12-17 02:38:09,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:09,324][root][INFO] - Training Epoch: 2/2, step 2691/7134 completed (loss: 0.4002995193004608, acc: 0.9026548862457275)
[2024-12-17 02:38:09,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:09,593][root][INFO] - Training Epoch: 2/2, step 2692/7134 completed (loss: 0.5147621631622314, acc: 0.9090909361839294)
[2024-12-17 02:38:09,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:09,880][root][INFO] - Training Epoch: 2/2, step 2693/7134 completed (loss: 0.5912857055664062, acc: 0.8761062026023865)
[2024-12-17 02:38:09,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:10,139][root][INFO] - Training Epoch: 2/2, step 2694/7134 completed (loss: 0.34798672795295715, acc: 0.940397322177887)
[2024-12-17 02:38:10,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:10,420][root][INFO] - Training Epoch: 2/2, step 2695/7134 completed (loss: 0.2431875765323639, acc: 0.9259259104728699)
[2024-12-17 02:38:10,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:10,696][root][INFO] - Training Epoch: 2/2, step 2696/7134 completed (loss: 0.2637646198272705, acc: 0.9357143044471741)
[2024-12-17 02:38:10,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:10,955][root][INFO] - Training Epoch: 2/2, step 2697/7134 completed (loss: 0.432502806186676, acc: 0.9025974273681641)
[2024-12-17 02:38:11,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:11,235][root][INFO] - Training Epoch: 2/2, step 2698/7134 completed (loss: 0.264459490776062, acc: 0.9387755393981934)
[2024-12-17 02:38:11,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:11,517][root][INFO] - Training Epoch: 2/2, step 2699/7134 completed (loss: 0.2129085808992386, acc: 0.9568965435028076)
[2024-12-17 02:38:11,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:11,744][root][INFO] - Training Epoch: 2/2, step 2700/7134 completed (loss: 0.26266053318977356, acc: 0.9142857193946838)
[2024-12-17 02:38:11,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:11,997][root][INFO] - Training Epoch: 2/2, step 2701/7134 completed (loss: 0.21993765234947205, acc: 0.9473684430122375)
[2024-12-17 02:38:12,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:12,207][root][INFO] - Training Epoch: 2/2, step 2702/7134 completed (loss: 0.524634838104248, acc: 0.8888888955116272)
[2024-12-17 02:38:12,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:12,471][root][INFO] - Training Epoch: 2/2, step 2703/7134 completed (loss: 0.13192550837993622, acc: 0.9599999785423279)
[2024-12-17 02:38:12,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:12,754][root][INFO] - Training Epoch: 2/2, step 2704/7134 completed (loss: 0.2781082093715668, acc: 0.9285714030265808)
[2024-12-17 02:38:12,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:13,036][root][INFO] - Training Epoch: 2/2, step 2705/7134 completed (loss: 0.3727527856826782, acc: 0.908450722694397)
[2024-12-17 02:38:13,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:13,328][root][INFO] - Training Epoch: 2/2, step 2706/7134 completed (loss: 0.17283710837364197, acc: 0.965753436088562)
[2024-12-17 02:38:13,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:13,601][root][INFO] - Training Epoch: 2/2, step 2707/7134 completed (loss: 0.36761265993118286, acc: 0.9166666865348816)
[2024-12-17 02:38:13,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:13,887][root][INFO] - Training Epoch: 2/2, step 2708/7134 completed (loss: 0.2726711630821228, acc: 0.9257143139839172)
[2024-12-17 02:38:13,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:14,169][root][INFO] - Training Epoch: 2/2, step 2709/7134 completed (loss: 0.14592072367668152, acc: 0.9577465057373047)
[2024-12-17 02:38:14,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:14,449][root][INFO] - Training Epoch: 2/2, step 2710/7134 completed (loss: 0.3931303024291992, acc: 0.9100000262260437)
[2024-12-17 02:38:14,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:14,759][root][INFO] - Training Epoch: 2/2, step 2711/7134 completed (loss: 0.15433859825134277, acc: 0.969072163105011)
[2024-12-17 02:38:14,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:15,044][root][INFO] - Training Epoch: 2/2, step 2712/7134 completed (loss: 0.21279850602149963, acc: 0.914893627166748)
[2024-12-17 02:38:15,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:15,327][root][INFO] - Training Epoch: 2/2, step 2713/7134 completed (loss: 0.1764702945947647, acc: 0.9624999761581421)
[2024-12-17 02:38:15,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:15,594][root][INFO] - Training Epoch: 2/2, step 2714/7134 completed (loss: 0.07908941805362701, acc: 0.9779411554336548)
[2024-12-17 02:38:15,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:15,865][root][INFO] - Training Epoch: 2/2, step 2715/7134 completed (loss: 0.14014089107513428, acc: 0.9724137783050537)
[2024-12-17 02:38:15,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:16,137][root][INFO] - Training Epoch: 2/2, step 2716/7134 completed (loss: 0.15841566026210785, acc: 0.9476743936538696)
[2024-12-17 02:38:16,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:16,403][root][INFO] - Training Epoch: 2/2, step 2717/7134 completed (loss: 0.23150008916854858, acc: 0.9059829115867615)
[2024-12-17 02:38:16,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:16,678][root][INFO] - Training Epoch: 2/2, step 2718/7134 completed (loss: 0.37717142701148987, acc: 0.9166666865348816)
[2024-12-17 02:38:16,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:16,951][root][INFO] - Training Epoch: 2/2, step 2719/7134 completed (loss: 0.21774019300937653, acc: 0.9640287756919861)
[2024-12-17 02:38:17,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:17,219][root][INFO] - Training Epoch: 2/2, step 2720/7134 completed (loss: 0.3517298102378845, acc: 0.9051094651222229)
[2024-12-17 02:38:17,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:17,447][root][INFO] - Training Epoch: 2/2, step 2721/7134 completed (loss: 0.23876506090164185, acc: 0.9668874144554138)
[2024-12-17 02:38:17,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:17,672][root][INFO] - Training Epoch: 2/2, step 2722/7134 completed (loss: 0.20731645822525024, acc: 0.9468085169792175)
[2024-12-17 02:38:17,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:17,924][root][INFO] - Training Epoch: 2/2, step 2723/7134 completed (loss: 0.35544276237487793, acc: 0.916167676448822)
[2024-12-17 02:38:18,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:18,200][root][INFO] - Training Epoch: 2/2, step 2724/7134 completed (loss: 0.10974934697151184, acc: 0.9717513918876648)
[2024-12-17 02:38:18,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:18,481][root][INFO] - Training Epoch: 2/2, step 2725/7134 completed (loss: 0.14778253436088562, acc: 0.9701492786407471)
[2024-12-17 02:38:18,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:18,730][root][INFO] - Training Epoch: 2/2, step 2726/7134 completed (loss: 0.39707523584365845, acc: 0.9430894255638123)
[2024-12-17 02:38:18,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:19,028][root][INFO] - Training Epoch: 2/2, step 2727/7134 completed (loss: 0.12699364125728607, acc: 0.9736841917037964)
[2024-12-17 02:38:19,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:19,311][root][INFO] - Training Epoch: 2/2, step 2728/7134 completed (loss: 0.8856337666511536, acc: 0.7629629373550415)
[2024-12-17 02:38:19,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:19,564][root][INFO] - Training Epoch: 2/2, step 2729/7134 completed (loss: 0.5817663669586182, acc: 0.8714285492897034)
[2024-12-17 02:38:19,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:19,829][root][INFO] - Training Epoch: 2/2, step 2730/7134 completed (loss: 0.46103036403656006, acc: 0.8849557638168335)
[2024-12-17 02:38:19,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:20,083][root][INFO] - Training Epoch: 2/2, step 2731/7134 completed (loss: 0.5344629883766174, acc: 0.8834951519966125)
[2024-12-17 02:38:20,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:20,365][root][INFO] - Training Epoch: 2/2, step 2732/7134 completed (loss: 0.5640607476234436, acc: 0.8774510025978088)
[2024-12-17 02:38:20,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:20,664][root][INFO] - Training Epoch: 2/2, step 2733/7134 completed (loss: 0.3818768858909607, acc: 0.894444465637207)
[2024-12-17 02:38:20,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:20,938][root][INFO] - Training Epoch: 2/2, step 2734/7134 completed (loss: 0.5404285192489624, acc: 0.8925619721412659)
[2024-12-17 02:38:21,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:21,244][root][INFO] - Training Epoch: 2/2, step 2735/7134 completed (loss: 0.2772093415260315, acc: 0.9451219439506531)
[2024-12-17 02:38:21,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:21,510][root][INFO] - Training Epoch: 2/2, step 2736/7134 completed (loss: 0.5594750046730042, acc: 0.8742138147354126)
[2024-12-17 02:38:21,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:21,780][root][INFO] - Training Epoch: 2/2, step 2737/7134 completed (loss: 0.4597155451774597, acc: 0.8999999761581421)
[2024-12-17 02:38:21,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:22,052][root][INFO] - Training Epoch: 2/2, step 2738/7134 completed (loss: 0.3982338011264801, acc: 0.8922155499458313)
[2024-12-17 02:38:22,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:22,336][root][INFO] - Training Epoch: 2/2, step 2739/7134 completed (loss: 0.3210119307041168, acc: 0.9202898740768433)
[2024-12-17 02:38:22,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:22,605][root][INFO] - Training Epoch: 2/2, step 2740/7134 completed (loss: 0.23356197774410248, acc: 0.9319728016853333)
[2024-12-17 02:38:22,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:22,844][root][INFO] - Training Epoch: 2/2, step 2741/7134 completed (loss: 0.22199265658855438, acc: 0.9396551847457886)
[2024-12-17 02:38:22,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:23,120][root][INFO] - Training Epoch: 2/2, step 2742/7134 completed (loss: 0.2313881665468216, acc: 0.9495798349380493)
[2024-12-17 02:38:23,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:23,364][root][INFO] - Training Epoch: 2/2, step 2743/7134 completed (loss: 0.2279624193906784, acc: 0.914893627166748)
[2024-12-17 02:38:23,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:23,543][root][INFO] - Training Epoch: 2/2, step 2744/7134 completed (loss: 0.3239063620567322, acc: 0.9193548560142517)
[2024-12-17 02:38:23,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:23,784][root][INFO] - Training Epoch: 2/2, step 2745/7134 completed (loss: 0.6147292256355286, acc: 0.863095223903656)
[2024-12-17 02:38:23,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:24,021][root][INFO] - Training Epoch: 2/2, step 2746/7134 completed (loss: 0.4167359471321106, acc: 0.8977272510528564)
[2024-12-17 02:38:24,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:24,283][root][INFO] - Training Epoch: 2/2, step 2747/7134 completed (loss: 0.39127278327941895, acc: 0.9259259104728699)
[2024-12-17 02:38:24,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:24,539][root][INFO] - Training Epoch: 2/2, step 2748/7134 completed (loss: 0.14848187565803528, acc: 0.9740259647369385)
[2024-12-17 02:38:24,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:24,787][root][INFO] - Training Epoch: 2/2, step 2749/7134 completed (loss: 0.32026350498199463, acc: 0.9278350472450256)
[2024-12-17 02:38:24,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:25,052][root][INFO] - Training Epoch: 2/2, step 2750/7134 completed (loss: 0.2352486401796341, acc: 0.9457831382751465)
[2024-12-17 02:38:25,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:25,308][root][INFO] - Training Epoch: 2/2, step 2751/7134 completed (loss: 0.355719655752182, acc: 0.9099099040031433)
[2024-12-17 02:38:25,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:25,572][root][INFO] - Training Epoch: 2/2, step 2752/7134 completed (loss: 0.2774200439453125, acc: 0.9343065619468689)
[2024-12-17 02:38:25,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:25,843][root][INFO] - Training Epoch: 2/2, step 2753/7134 completed (loss: 0.43234458565711975, acc: 0.8991596698760986)
[2024-12-17 02:38:25,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:26,124][root][INFO] - Training Epoch: 2/2, step 2754/7134 completed (loss: 0.223263218998909, acc: 0.9583333134651184)
[2024-12-17 02:38:26,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:26,405][root][INFO] - Training Epoch: 2/2, step 2755/7134 completed (loss: 0.2845131754875183, acc: 0.9453125)
[2024-12-17 02:38:26,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:26,680][root][INFO] - Training Epoch: 2/2, step 2756/7134 completed (loss: 0.26354852318763733, acc: 0.9256756901741028)
[2024-12-17 02:38:26,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:26,909][root][INFO] - Training Epoch: 2/2, step 2757/7134 completed (loss: 0.2636992931365967, acc: 0.9347826242446899)
[2024-12-17 02:38:27,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:27,185][root][INFO] - Training Epoch: 2/2, step 2758/7134 completed (loss: 0.28985369205474854, acc: 0.9344262480735779)
[2024-12-17 02:38:27,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:27,487][root][INFO] - Training Epoch: 2/2, step 2759/7134 completed (loss: 0.21792569756507874, acc: 0.9142857193946838)
[2024-12-17 02:38:27,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:27,756][root][INFO] - Training Epoch: 2/2, step 2760/7134 completed (loss: 0.2862013876438141, acc: 0.9333333373069763)
[2024-12-17 02:38:27,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:28,028][root][INFO] - Training Epoch: 2/2, step 2761/7134 completed (loss: 0.4862847626209259, acc: 0.878947377204895)
[2024-12-17 02:38:28,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:28,316][root][INFO] - Training Epoch: 2/2, step 2762/7134 completed (loss: 0.34265437722206116, acc: 0.9211822748184204)
[2024-12-17 02:38:28,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:28,593][root][INFO] - Training Epoch: 2/2, step 2763/7134 completed (loss: 0.20207072794437408, acc: 0.9453551769256592)
[2024-12-17 02:38:28,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:28,875][root][INFO] - Training Epoch: 2/2, step 2764/7134 completed (loss: 0.27364596724510193, acc: 0.9270833134651184)
[2024-12-17 02:38:28,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:29,160][root][INFO] - Training Epoch: 2/2, step 2765/7134 completed (loss: 0.21591532230377197, acc: 0.9470587968826294)
[2024-12-17 02:38:29,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:29,458][root][INFO] - Training Epoch: 2/2, step 2766/7134 completed (loss: 0.2269067019224167, acc: 0.9681528806686401)
[2024-12-17 02:38:29,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:29,738][root][INFO] - Training Epoch: 2/2, step 2767/7134 completed (loss: 0.18729592859745026, acc: 0.9399999976158142)
[2024-12-17 02:38:29,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:30,007][root][INFO] - Training Epoch: 2/2, step 2768/7134 completed (loss: 0.15461133420467377, acc: 0.9638554453849792)
[2024-12-17 02:38:30,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:30,284][root][INFO] - Training Epoch: 2/2, step 2769/7134 completed (loss: 0.21173645555973053, acc: 0.9473684430122375)
[2024-12-17 02:38:30,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:30,568][root][INFO] - Training Epoch: 2/2, step 2770/7134 completed (loss: 0.11065378040075302, acc: 0.9629629850387573)
[2024-12-17 02:38:30,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:30,876][root][INFO] - Training Epoch: 2/2, step 2771/7134 completed (loss: 0.39028823375701904, acc: 0.9194312691688538)
[2024-12-17 02:38:30,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:31,171][root][INFO] - Training Epoch: 2/2, step 2772/7134 completed (loss: 0.2465166598558426, acc: 0.9300000071525574)
[2024-12-17 02:38:31,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:31,465][root][INFO] - Training Epoch: 2/2, step 2773/7134 completed (loss: 0.21308475732803345, acc: 0.929648220539093)
[2024-12-17 02:38:31,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:31,749][root][INFO] - Training Epoch: 2/2, step 2774/7134 completed (loss: 0.2838640809059143, acc: 0.9365853667259216)
[2024-12-17 02:38:31,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:32,024][root][INFO] - Training Epoch: 2/2, step 2775/7134 completed (loss: 0.19775480031967163, acc: 0.9453551769256592)
[2024-12-17 02:38:32,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:32,336][root][INFO] - Training Epoch: 2/2, step 2776/7134 completed (loss: 0.19909964501857758, acc: 0.948051929473877)
[2024-12-17 02:38:32,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:32,611][root][INFO] - Training Epoch: 2/2, step 2777/7134 completed (loss: 0.11600404977798462, acc: 0.9599999785423279)
[2024-12-17 02:38:32,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:32,901][root][INFO] - Training Epoch: 2/2, step 2778/7134 completed (loss: 0.28163036704063416, acc: 0.9343434572219849)
[2024-12-17 02:38:33,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:33,189][root][INFO] - Training Epoch: 2/2, step 2779/7134 completed (loss: 0.1983015090227127, acc: 0.931506872177124)
[2024-12-17 02:38:33,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:33,479][root][INFO] - Training Epoch: 2/2, step 2780/7134 completed (loss: 0.2377161979675293, acc: 0.9469026327133179)
[2024-12-17 02:38:33,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:33,767][root][INFO] - Training Epoch: 2/2, step 2781/7134 completed (loss: 0.17431077361106873, acc: 0.95652174949646)
[2024-12-17 02:38:33,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:34,052][root][INFO] - Training Epoch: 2/2, step 2782/7134 completed (loss: 0.11520491540431976, acc: 0.9642857313156128)
[2024-12-17 02:38:34,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:34,341][root][INFO] - Training Epoch: 2/2, step 2783/7134 completed (loss: 0.15412165224552155, acc: 0.9659863710403442)
[2024-12-17 02:38:34,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:34,626][root][INFO] - Training Epoch: 2/2, step 2784/7134 completed (loss: 0.15754981338977814, acc: 0.9758453965187073)
[2024-12-17 02:38:34,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:34,933][root][INFO] - Training Epoch: 2/2, step 2785/7134 completed (loss: 0.22168274223804474, acc: 0.946601927280426)
[2024-12-17 02:38:35,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:35,232][root][INFO] - Training Epoch: 2/2, step 2786/7134 completed (loss: 0.3367152214050293, acc: 0.9111111164093018)
[2024-12-17 02:38:35,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:35,525][root][INFO] - Training Epoch: 2/2, step 2787/7134 completed (loss: 0.22350375354290009, acc: 0.9190751314163208)
[2024-12-17 02:38:35,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:35,800][root][INFO] - Training Epoch: 2/2, step 2788/7134 completed (loss: 0.2413867563009262, acc: 0.9235668778419495)
[2024-12-17 02:38:35,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:36,084][root][INFO] - Training Epoch: 2/2, step 2789/7134 completed (loss: 1.6167675256729126, acc: 0.6952381134033203)
[2024-12-17 02:38:36,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:36,371][root][INFO] - Training Epoch: 2/2, step 2790/7134 completed (loss: 1.058593511581421, acc: 0.7333333492279053)
[2024-12-17 02:38:36,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:36,656][root][INFO] - Training Epoch: 2/2, step 2791/7134 completed (loss: 0.5223456025123596, acc: 0.8741722106933594)
[2024-12-17 02:38:36,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:36,947][root][INFO] - Training Epoch: 2/2, step 2792/7134 completed (loss: 0.2114158272743225, acc: 0.9534883499145508)
[2024-12-17 02:38:37,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:37,239][root][INFO] - Training Epoch: 2/2, step 2793/7134 completed (loss: 0.17593534290790558, acc: 0.9520958065986633)
[2024-12-17 02:38:37,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:37,493][root][INFO] - Training Epoch: 2/2, step 2794/7134 completed (loss: 0.1265304982662201, acc: 0.9696969985961914)
[2024-12-17 02:38:37,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:37,770][root][INFO] - Training Epoch: 2/2, step 2795/7134 completed (loss: 0.779946506023407, acc: 0.8148148059844971)
[2024-12-17 02:38:37,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:38,038][root][INFO] - Training Epoch: 2/2, step 2796/7134 completed (loss: 0.5039008259773254, acc: 0.8617886304855347)
[2024-12-17 02:38:38,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:38,274][root][INFO] - Training Epoch: 2/2, step 2797/7134 completed (loss: 0.5546093583106995, acc: 0.8292682766914368)
[2024-12-17 02:38:38,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:38,553][root][INFO] - Training Epoch: 2/2, step 2798/7134 completed (loss: 0.4242407977581024, acc: 0.8916666507720947)
[2024-12-17 02:38:38,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:38,803][root][INFO] - Training Epoch: 2/2, step 2799/7134 completed (loss: 0.4219273328781128, acc: 0.8828125)
[2024-12-17 02:38:38,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:39,043][root][INFO] - Training Epoch: 2/2, step 2800/7134 completed (loss: 0.22428779304027557, acc: 0.9489051103591919)
[2024-12-17 02:38:39,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:39,332][root][INFO] - Training Epoch: 2/2, step 2801/7134 completed (loss: 0.3431026339530945, acc: 0.9180327653884888)
[2024-12-17 02:38:39,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:39,620][root][INFO] - Training Epoch: 2/2, step 2802/7134 completed (loss: 0.338026225566864, acc: 0.9246231317520142)
[2024-12-17 02:38:39,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:39,904][root][INFO] - Training Epoch: 2/2, step 2803/7134 completed (loss: 0.08698111027479172, acc: 0.9814814925193787)
[2024-12-17 02:38:40,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:40,201][root][INFO] - Training Epoch: 2/2, step 2804/7134 completed (loss: 0.15604716539382935, acc: 0.9826589822769165)
[2024-12-17 02:38:40,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:40,477][root][INFO] - Training Epoch: 2/2, step 2805/7134 completed (loss: 0.09435415267944336, acc: 0.9825581312179565)
[2024-12-17 02:38:40,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:40,747][root][INFO] - Training Epoch: 2/2, step 2806/7134 completed (loss: 0.19375917315483093, acc: 0.970588207244873)
[2024-12-17 02:38:40,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:41,021][root][INFO] - Training Epoch: 2/2, step 2807/7134 completed (loss: 0.3256455957889557, acc: 0.9320388436317444)
[2024-12-17 02:38:41,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:41,333][root][INFO] - Training Epoch: 2/2, step 2808/7134 completed (loss: 0.19750890135765076, acc: 0.9447236061096191)
[2024-12-17 02:38:41,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:41,620][root][INFO] - Training Epoch: 2/2, step 2809/7134 completed (loss: 0.3097560703754425, acc: 0.9055117964744568)
[2024-12-17 02:38:41,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:41,926][root][INFO] - Training Epoch: 2/2, step 2810/7134 completed (loss: 0.08230177313089371, acc: 0.9836065769195557)
[2024-12-17 02:38:42,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:42,202][root][INFO] - Training Epoch: 2/2, step 2811/7134 completed (loss: 0.09185878187417984, acc: 0.9779005646705627)
[2024-12-17 02:38:42,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:42,480][root][INFO] - Training Epoch: 2/2, step 2812/7134 completed (loss: 0.08999129384756088, acc: 0.9735099077224731)
[2024-12-17 02:38:42,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:42,773][root][INFO] - Training Epoch: 2/2, step 2813/7134 completed (loss: 0.16173896193504333, acc: 0.9712643623352051)
[2024-12-17 02:38:42,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:43,044][root][INFO] - Training Epoch: 2/2, step 2814/7134 completed (loss: 0.2563135325908661, acc: 0.9186046719551086)
[2024-12-17 02:38:43,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:43,319][root][INFO] - Training Epoch: 2/2, step 2815/7134 completed (loss: 0.17111149430274963, acc: 0.9505494236946106)
[2024-12-17 02:38:43,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:43,609][root][INFO] - Training Epoch: 2/2, step 2816/7134 completed (loss: 0.1443801373243332, acc: 0.9673202633857727)
[2024-12-17 02:38:43,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:43,900][root][INFO] - Training Epoch: 2/2, step 2817/7134 completed (loss: 0.16965317726135254, acc: 0.9644669890403748)
[2024-12-17 02:38:44,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:44,191][root][INFO] - Training Epoch: 2/2, step 2818/7134 completed (loss: 0.16224215924739838, acc: 0.9468085169792175)
[2024-12-17 02:38:44,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:44,495][root][INFO] - Training Epoch: 2/2, step 2819/7134 completed (loss: 0.17033751308918, acc: 0.9452054500579834)
[2024-12-17 02:38:44,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:44,769][root][INFO] - Training Epoch: 2/2, step 2820/7134 completed (loss: 0.5227345824241638, acc: 0.8650306463241577)
[2024-12-17 02:38:44,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:45,059][root][INFO] - Training Epoch: 2/2, step 2821/7134 completed (loss: 0.3998110592365265, acc: 0.9067357778549194)
[2024-12-17 02:38:45,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:45,363][root][INFO] - Training Epoch: 2/2, step 2822/7134 completed (loss: 0.6560961604118347, acc: 0.8702702522277832)
[2024-12-17 02:38:45,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:45,684][root][INFO] - Training Epoch: 2/2, step 2823/7134 completed (loss: 0.3748045861721039, acc: 0.9130434989929199)
[2024-12-17 02:38:45,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:45,999][root][INFO] - Training Epoch: 2/2, step 2824/7134 completed (loss: 0.8647720217704773, acc: 0.8301886916160583)
[2024-12-17 02:38:46,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:46,287][root][INFO] - Training Epoch: 2/2, step 2825/7134 completed (loss: 0.19775961339473724, acc: 0.9444444179534912)
[2024-12-17 02:38:46,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:46,593][root][INFO] - Training Epoch: 2/2, step 2826/7134 completed (loss: 0.4085668921470642, acc: 0.9137930870056152)
[2024-12-17 02:38:46,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:46,882][root][INFO] - Training Epoch: 2/2, step 2827/7134 completed (loss: 0.25621864199638367, acc: 0.9665071964263916)
[2024-12-17 02:38:47,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:47,166][root][INFO] - Training Epoch: 2/2, step 2828/7134 completed (loss: 0.43559056520462036, acc: 0.8987341523170471)
[2024-12-17 02:38:47,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:47,452][root][INFO] - Training Epoch: 2/2, step 2829/7134 completed (loss: 0.20872433483600616, acc: 0.9583333134651184)
[2024-12-17 02:38:47,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:47,734][root][INFO] - Training Epoch: 2/2, step 2830/7134 completed (loss: 0.08038071542978287, acc: 0.9850746393203735)
[2024-12-17 02:38:47,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:48,019][root][INFO] - Training Epoch: 2/2, step 2831/7134 completed (loss: 0.14679262042045593, acc: 0.9662162065505981)
[2024-12-17 02:38:48,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:48,297][root][INFO] - Training Epoch: 2/2, step 2832/7134 completed (loss: 0.24609729647636414, acc: 0.9354838728904724)
[2024-12-17 02:38:48,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:48,580][root][INFO] - Training Epoch: 2/2, step 2833/7134 completed (loss: 0.20577821135520935, acc: 0.9629629850387573)
[2024-12-17 02:38:48,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:48,861][root][INFO] - Training Epoch: 2/2, step 2834/7134 completed (loss: 0.3073066771030426, acc: 0.9333333373069763)
[2024-12-17 02:38:48,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:49,142][root][INFO] - Training Epoch: 2/2, step 2835/7134 completed (loss: 0.22342795133590698, acc: 0.9407894611358643)
[2024-12-17 02:38:49,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:49,402][root][INFO] - Training Epoch: 2/2, step 2836/7134 completed (loss: 0.4061789810657501, acc: 0.9100000262260437)
[2024-12-17 02:38:49,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:49,688][root][INFO] - Training Epoch: 2/2, step 2837/7134 completed (loss: 0.2027330845594406, acc: 0.9415204524993896)
[2024-12-17 02:38:49,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:49,980][root][INFO] - Training Epoch: 2/2, step 2838/7134 completed (loss: 0.31450167298316956, acc: 0.931034505367279)
[2024-12-17 02:38:50,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:50,244][root][INFO] - Training Epoch: 2/2, step 2839/7134 completed (loss: 0.28236114978790283, acc: 0.9328358173370361)
[2024-12-17 02:38:50,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:50,535][root][INFO] - Training Epoch: 2/2, step 2840/7134 completed (loss: 0.15790453553199768, acc: 0.9588235020637512)
[2024-12-17 02:38:50,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:50,821][root][INFO] - Training Epoch: 2/2, step 2841/7134 completed (loss: 0.16882921755313873, acc: 0.9622641801834106)
[2024-12-17 02:38:50,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:51,114][root][INFO] - Training Epoch: 2/2, step 2842/7134 completed (loss: 0.3574311435222626, acc: 0.9322916865348816)
[2024-12-17 02:38:51,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:51,384][root][INFO] - Training Epoch: 2/2, step 2843/7134 completed (loss: 0.2342490702867508, acc: 0.9182389974594116)
[2024-12-17 02:38:51,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:51,664][root][INFO] - Training Epoch: 2/2, step 2844/7134 completed (loss: 0.4735911786556244, acc: 0.885869562625885)
[2024-12-17 02:38:51,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:51,933][root][INFO] - Training Epoch: 2/2, step 2845/7134 completed (loss: 0.30063092708587646, acc: 0.9256756901741028)
[2024-12-17 02:38:52,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:52,210][root][INFO] - Training Epoch: 2/2, step 2846/7134 completed (loss: 0.22558389604091644, acc: 0.9411764740943909)
[2024-12-17 02:38:52,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:52,511][root][INFO] - Training Epoch: 2/2, step 2847/7134 completed (loss: 0.21401920914649963, acc: 0.9681528806686401)
[2024-12-17 02:38:52,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:52,765][root][INFO] - Training Epoch: 2/2, step 2848/7134 completed (loss: 0.26061785221099854, acc: 0.9541284441947937)
[2024-12-17 02:38:52,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:53,032][root][INFO] - Training Epoch: 2/2, step 2849/7134 completed (loss: 0.2635670304298401, acc: 0.9371428489685059)
[2024-12-17 02:38:53,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:53,308][root][INFO] - Training Epoch: 2/2, step 2850/7134 completed (loss: 0.36894264817237854, acc: 0.8974359035491943)
[2024-12-17 02:38:53,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:53,585][root][INFO] - Training Epoch: 2/2, step 2851/7134 completed (loss: 0.25222375988960266, acc: 0.9185185432434082)
[2024-12-17 02:38:53,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:53,850][root][INFO] - Training Epoch: 2/2, step 2852/7134 completed (loss: 0.22646434605121613, acc: 0.9430894255638123)
[2024-12-17 02:38:53,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:54,096][root][INFO] - Training Epoch: 2/2, step 2853/7134 completed (loss: 0.13251209259033203, acc: 0.9591836929321289)
[2024-12-17 02:38:54,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:54,377][root][INFO] - Training Epoch: 2/2, step 2854/7134 completed (loss: 0.36861589550971985, acc: 0.9251700639724731)
[2024-12-17 02:38:54,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:54,648][root][INFO] - Training Epoch: 2/2, step 2855/7134 completed (loss: 0.1999242901802063, acc: 0.9391891956329346)
[2024-12-17 02:38:54,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:54,940][root][INFO] - Training Epoch: 2/2, step 2856/7134 completed (loss: 0.1995784193277359, acc: 0.9440993666648865)
[2024-12-17 02:38:55,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:55,228][root][INFO] - Training Epoch: 2/2, step 2857/7134 completed (loss: 0.23829972743988037, acc: 0.946107804775238)
[2024-12-17 02:38:55,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:55,515][root][INFO] - Training Epoch: 2/2, step 2858/7134 completed (loss: 0.12460296601057053, acc: 0.9545454382896423)
[2024-12-17 02:38:55,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:55,803][root][INFO] - Training Epoch: 2/2, step 2859/7134 completed (loss: 0.3538123667240143, acc: 0.9166666865348816)
[2024-12-17 02:38:55,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:56,077][root][INFO] - Training Epoch: 2/2, step 2860/7134 completed (loss: 0.25955528020858765, acc: 0.9453125)
[2024-12-17 02:38:56,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:56,351][root][INFO] - Training Epoch: 2/2, step 2861/7134 completed (loss: 0.1494216024875641, acc: 0.9375)
[2024-12-17 02:38:56,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:56,611][root][INFO] - Training Epoch: 2/2, step 2862/7134 completed (loss: 0.15460054576396942, acc: 0.9774436354637146)
[2024-12-17 02:38:56,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:56,902][root][INFO] - Training Epoch: 2/2, step 2863/7134 completed (loss: 0.1224072277545929, acc: 0.9668508172035217)
[2024-12-17 02:38:56,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:57,137][root][INFO] - Training Epoch: 2/2, step 2864/7134 completed (loss: 0.14591750502586365, acc: 0.9684210419654846)
[2024-12-17 02:38:57,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:57,428][root][INFO] - Training Epoch: 2/2, step 2865/7134 completed (loss: 0.10310544818639755, acc: 0.9739130139350891)
[2024-12-17 02:38:57,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:57,730][root][INFO] - Training Epoch: 2/2, step 2866/7134 completed (loss: 0.19172538816928864, acc: 0.9612902998924255)
[2024-12-17 02:38:57,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:57,989][root][INFO] - Training Epoch: 2/2, step 2867/7134 completed (loss: 0.1436646729707718, acc: 0.9506173133850098)
[2024-12-17 02:38:58,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:58,251][root][INFO] - Training Epoch: 2/2, step 2868/7134 completed (loss: 0.12842212617397308, acc: 0.9647058844566345)
[2024-12-17 02:38:58,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:58,505][root][INFO] - Training Epoch: 2/2, step 2869/7134 completed (loss: 0.2629522681236267, acc: 0.9724137783050537)
[2024-12-17 02:38:58,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:58,781][root][INFO] - Training Epoch: 2/2, step 2870/7134 completed (loss: 0.5981723666191101, acc: 0.918181836605072)
[2024-12-17 02:38:58,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:59,049][root][INFO] - Training Epoch: 2/2, step 2871/7134 completed (loss: 0.261870414018631, acc: 0.951724112033844)
[2024-12-17 02:38:59,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:59,325][root][INFO] - Training Epoch: 2/2, step 2872/7134 completed (loss: 0.06955887377262115, acc: 0.991150438785553)
[2024-12-17 02:38:59,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:59,589][root][INFO] - Training Epoch: 2/2, step 2873/7134 completed (loss: 0.08165568113327026, acc: 0.9767441749572754)
[2024-12-17 02:38:59,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:59,865][root][INFO] - Training Epoch: 2/2, step 2874/7134 completed (loss: 0.09706735610961914, acc: 0.9861111044883728)
[2024-12-17 02:38:59,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:00,151][root][INFO] - Training Epoch: 2/2, step 2875/7134 completed (loss: 0.20048969984054565, acc: 0.9523809552192688)
[2024-12-17 02:39:00,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:00,409][root][INFO] - Training Epoch: 2/2, step 2876/7134 completed (loss: 0.4047267436981201, acc: 0.9150943160057068)
[2024-12-17 02:39:00,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:00,683][root][INFO] - Training Epoch: 2/2, step 2877/7134 completed (loss: 0.1105179637670517, acc: 0.9743589758872986)
[2024-12-17 02:39:00,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:00,950][root][INFO] - Training Epoch: 2/2, step 2878/7134 completed (loss: 0.1466718316078186, acc: 0.9824561476707458)
[2024-12-17 02:39:01,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:01,207][root][INFO] - Training Epoch: 2/2, step 2879/7134 completed (loss: 0.0939488336443901, acc: 0.9795918464660645)
[2024-12-17 02:39:01,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:01,485][root][INFO] - Training Epoch: 2/2, step 2880/7134 completed (loss: 0.05346830561757088, acc: 0.9931507110595703)
[2024-12-17 02:39:01,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:01,741][root][INFO] - Training Epoch: 2/2, step 2881/7134 completed (loss: 0.16547729074954987, acc: 0.9444444179534912)
[2024-12-17 02:39:01,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:02,021][root][INFO] - Training Epoch: 2/2, step 2882/7134 completed (loss: 0.36744120717048645, acc: 0.9075144529342651)
[2024-12-17 02:39:02,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:02,300][root][INFO] - Training Epoch: 2/2, step 2883/7134 completed (loss: 0.3766859471797943, acc: 0.910179615020752)
[2024-12-17 02:39:02,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:02,560][root][INFO] - Training Epoch: 2/2, step 2884/7134 completed (loss: 0.3141709268093109, acc: 0.9272727370262146)
[2024-12-17 02:39:02,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:02,818][root][INFO] - Training Epoch: 2/2, step 2885/7134 completed (loss: 0.6264318823814392, acc: 0.8545454740524292)
[2024-12-17 02:39:02,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:03,089][root][INFO] - Training Epoch: 2/2, step 2886/7134 completed (loss: 0.4280475378036499, acc: 0.8882352709770203)
[2024-12-17 02:39:03,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:03,387][root][INFO] - Training Epoch: 2/2, step 2887/7134 completed (loss: 0.3428848683834076, acc: 0.943231463432312)
[2024-12-17 02:39:03,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:03,676][root][INFO] - Training Epoch: 2/2, step 2888/7134 completed (loss: 0.30494657158851624, acc: 0.9315789341926575)
[2024-12-17 02:39:03,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:03,952][root][INFO] - Training Epoch: 2/2, step 2889/7134 completed (loss: 0.25873884558677673, acc: 0.9385474920272827)
[2024-12-17 02:39:04,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:04,232][root][INFO] - Training Epoch: 2/2, step 2890/7134 completed (loss: 0.2304539978504181, acc: 0.9487179517745972)
[2024-12-17 02:39:04,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:04,519][root][INFO] - Training Epoch: 2/2, step 2891/7134 completed (loss: 0.3874359130859375, acc: 0.9111111164093018)
[2024-12-17 02:39:04,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:04,800][root][INFO] - Training Epoch: 2/2, step 2892/7134 completed (loss: 0.31304633617401123, acc: 0.9112426042556763)
[2024-12-17 02:39:04,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:05,092][root][INFO] - Training Epoch: 2/2, step 2893/7134 completed (loss: 0.28141066431999207, acc: 0.9180327653884888)
[2024-12-17 02:39:05,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:05,364][root][INFO] - Training Epoch: 2/2, step 2894/7134 completed (loss: 0.3280845880508423, acc: 0.9037036895751953)
[2024-12-17 02:39:05,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:05,602][root][INFO] - Training Epoch: 2/2, step 2895/7134 completed (loss: 0.07719098776578903, acc: 0.9830508232116699)
[2024-12-17 02:39:05,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:05,880][root][INFO] - Training Epoch: 2/2, step 2896/7134 completed (loss: 0.19662943482398987, acc: 0.9520958065986633)
[2024-12-17 02:39:05,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:06,138][root][INFO] - Training Epoch: 2/2, step 2897/7134 completed (loss: 0.4711940884590149, acc: 0.9172932505607605)
[2024-12-17 02:39:06,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:06,406][root][INFO] - Training Epoch: 2/2, step 2898/7134 completed (loss: 0.18057143688201904, acc: 0.95652174949646)
[2024-12-17 02:39:06,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:06,676][root][INFO] - Training Epoch: 2/2, step 2899/7134 completed (loss: 0.19435179233551025, acc: 0.9520958065986633)
[2024-12-17 02:39:06,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:06,956][root][INFO] - Training Epoch: 2/2, step 2900/7134 completed (loss: 0.20481041073799133, acc: 0.9627659320831299)
[2024-12-17 02:39:07,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:07,229][root][INFO] - Training Epoch: 2/2, step 2901/7134 completed (loss: 0.186667799949646, acc: 0.9459459185600281)
[2024-12-17 02:39:07,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:07,489][root][INFO] - Training Epoch: 2/2, step 2902/7134 completed (loss: 0.20328450202941895, acc: 0.9487179517745972)
[2024-12-17 02:39:07,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:07,785][root][INFO] - Training Epoch: 2/2, step 2903/7134 completed (loss: 0.13366568088531494, acc: 0.9606741666793823)
[2024-12-17 02:39:07,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:08,055][root][INFO] - Training Epoch: 2/2, step 2904/7134 completed (loss: 0.11630063503980637, acc: 0.9729729890823364)
[2024-12-17 02:39:08,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:08,346][root][INFO] - Training Epoch: 2/2, step 2905/7134 completed (loss: 0.20428720116615295, acc: 0.9304812550544739)
[2024-12-17 02:39:08,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:08,635][root][INFO] - Training Epoch: 2/2, step 2906/7134 completed (loss: 0.178678959608078, acc: 0.9581151604652405)
[2024-12-17 02:39:08,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:08,919][root][INFO] - Training Epoch: 2/2, step 2907/7134 completed (loss: 0.2116408497095108, acc: 0.9341317415237427)
[2024-12-17 02:39:09,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:09,196][root][INFO] - Training Epoch: 2/2, step 2908/7134 completed (loss: 0.19609154760837555, acc: 0.9655172228813171)
[2024-12-17 02:39:09,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:09,479][root][INFO] - Training Epoch: 2/2, step 2909/7134 completed (loss: 0.16314080357551575, acc: 0.9672130942344666)
[2024-12-17 02:39:09,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:09,761][root][INFO] - Training Epoch: 2/2, step 2910/7134 completed (loss: 0.18405970931053162, acc: 0.9518716335296631)
[2024-12-17 02:39:09,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:10,049][root][INFO] - Training Epoch: 2/2, step 2911/7134 completed (loss: 0.1842275708913803, acc: 0.9580419659614563)
[2024-12-17 02:39:10,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:10,339][root][INFO] - Training Epoch: 2/2, step 2912/7134 completed (loss: 0.1495702564716339, acc: 0.9520547986030579)
[2024-12-17 02:39:10,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:10,621][root][INFO] - Training Epoch: 2/2, step 2913/7134 completed (loss: 0.2647380530834198, acc: 0.9496402740478516)
[2024-12-17 02:39:10,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:10,909][root][INFO] - Training Epoch: 2/2, step 2914/7134 completed (loss: 0.1441265046596527, acc: 0.9575757384300232)
[2024-12-17 02:39:10,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:11,173][root][INFO] - Training Epoch: 2/2, step 2915/7134 completed (loss: 0.514797031879425, acc: 0.8965517282485962)
[2024-12-17 02:39:11,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:11,421][root][INFO] - Training Epoch: 2/2, step 2916/7134 completed (loss: 0.164370596408844, acc: 0.9473684430122375)
[2024-12-17 02:39:11,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:11,694][root][INFO] - Training Epoch: 2/2, step 2917/7134 completed (loss: 0.13661609590053558, acc: 0.9473684430122375)
[2024-12-17 02:39:11,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:11,950][root][INFO] - Training Epoch: 2/2, step 2918/7134 completed (loss: 0.19265709817409515, acc: 0.9473684430122375)
[2024-12-17 02:39:12,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:12,195][root][INFO] - Training Epoch: 2/2, step 2919/7134 completed (loss: 0.19729892909526825, acc: 0.9457831382751465)
[2024-12-17 02:39:12,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:12,489][root][INFO] - Training Epoch: 2/2, step 2920/7134 completed (loss: 0.19794602692127228, acc: 0.955974817276001)
[2024-12-17 02:39:12,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:12,764][root][INFO] - Training Epoch: 2/2, step 2921/7134 completed (loss: 0.09689401835203171, acc: 0.9785714149475098)
[2024-12-17 02:39:12,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:13,021][root][INFO] - Training Epoch: 2/2, step 2922/7134 completed (loss: 0.36051270365715027, acc: 0.907975435256958)
[2024-12-17 02:39:13,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:13,297][root][INFO] - Training Epoch: 2/2, step 2923/7134 completed (loss: 0.831829845905304, acc: 0.8873239159584045)
[2024-12-17 02:39:13,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:13,553][root][INFO] - Training Epoch: 2/2, step 2924/7134 completed (loss: 0.2501372992992401, acc: 0.957317054271698)
[2024-12-17 02:39:13,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:13,855][root][INFO] - Training Epoch: 2/2, step 2925/7134 completed (loss: 0.19829347729682922, acc: 0.9647058844566345)
[2024-12-17 02:39:13,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:14,155][root][INFO] - Training Epoch: 2/2, step 2926/7134 completed (loss: 0.4289320409297943, acc: 0.9447236061096191)
[2024-12-17 02:39:14,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:14,437][root][INFO] - Training Epoch: 2/2, step 2927/7134 completed (loss: 0.14493653178215027, acc: 0.9768785834312439)
[2024-12-17 02:39:14,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:14,712][root][INFO] - Training Epoch: 2/2, step 2928/7134 completed (loss: 0.3363724648952484, acc: 0.9444444179534912)
[2024-12-17 02:39:14,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:15,001][root][INFO] - Training Epoch: 2/2, step 2929/7134 completed (loss: 0.1158105656504631, acc: 0.9702380895614624)
[2024-12-17 02:39:15,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:15,284][root][INFO] - Training Epoch: 2/2, step 2930/7134 completed (loss: 0.35307762026786804, acc: 0.9251700639724731)
[2024-12-17 02:39:15,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:15,557][root][INFO] - Training Epoch: 2/2, step 2931/7134 completed (loss: 0.41329050064086914, acc: 0.8974359035491943)
[2024-12-17 02:39:15,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:15,826][root][INFO] - Training Epoch: 2/2, step 2932/7134 completed (loss: 0.18138553202152252, acc: 0.9572192430496216)
[2024-12-17 02:39:15,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:16,112][root][INFO] - Training Epoch: 2/2, step 2933/7134 completed (loss: 0.20994706451892853, acc: 0.9489051103591919)
[2024-12-17 02:39:16,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:16,411][root][INFO] - Training Epoch: 2/2, step 2934/7134 completed (loss: 0.09276784956455231, acc: 0.9857142567634583)
[2024-12-17 02:39:16,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:16,685][root][INFO] - Training Epoch: 2/2, step 2935/7134 completed (loss: 0.11079871654510498, acc: 0.9841269850730896)
[2024-12-17 02:39:16,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:16,975][root][INFO] - Training Epoch: 2/2, step 2936/7134 completed (loss: 0.24098113179206848, acc: 0.9601770043373108)
[2024-12-17 02:39:17,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:17,241][root][INFO] - Training Epoch: 2/2, step 2937/7134 completed (loss: 0.22857558727264404, acc: 0.9485294222831726)
[2024-12-17 02:39:17,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:17,503][root][INFO] - Training Epoch: 2/2, step 2938/7134 completed (loss: 0.24849765002727509, acc: 0.9562841653823853)
[2024-12-17 02:39:17,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:17,752][root][INFO] - Training Epoch: 2/2, step 2939/7134 completed (loss: 0.08882498741149902, acc: 0.9735099077224731)
[2024-12-17 02:39:17,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:18,030][root][INFO] - Training Epoch: 2/2, step 2940/7134 completed (loss: 0.16557158529758453, acc: 0.9617486596107483)
[2024-12-17 02:39:18,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:18,293][root][INFO] - Training Epoch: 2/2, step 2941/7134 completed (loss: 0.20946834981441498, acc: 0.9438202381134033)
[2024-12-17 02:39:18,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:18,538][root][INFO] - Training Epoch: 2/2, step 2942/7134 completed (loss: 0.1719292402267456, acc: 0.9636363387107849)
[2024-12-17 02:39:18,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:18,806][root][INFO] - Training Epoch: 2/2, step 2943/7134 completed (loss: 0.1808474063873291, acc: 0.9459459185600281)
[2024-12-17 02:39:18,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:19,090][root][INFO] - Training Epoch: 2/2, step 2944/7134 completed (loss: 0.19228105247020721, acc: 0.9397590160369873)
[2024-12-17 02:39:19,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:19,367][root][INFO] - Training Epoch: 2/2, step 2945/7134 completed (loss: 0.21737542748451233, acc: 0.926174521446228)
[2024-12-17 02:39:19,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:19,621][root][INFO] - Training Epoch: 2/2, step 2946/7134 completed (loss: 0.2832258343696594, acc: 0.9382715821266174)
[2024-12-17 02:39:19,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:19,900][root][INFO] - Training Epoch: 2/2, step 2947/7134 completed (loss: 0.3040650188922882, acc: 0.918749988079071)
[2024-12-17 02:39:20,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:20,171][root][INFO] - Training Epoch: 2/2, step 2948/7134 completed (loss: 0.2797989249229431, acc: 0.9236111044883728)
[2024-12-17 02:39:20,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:20,448][root][INFO] - Training Epoch: 2/2, step 2949/7134 completed (loss: 0.07898789644241333, acc: 0.9803921580314636)
[2024-12-17 02:39:20,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:20,735][root][INFO] - Training Epoch: 2/2, step 2950/7134 completed (loss: 0.19492438435554504, acc: 0.9553072452545166)
[2024-12-17 02:39:20,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:21,011][root][INFO] - Training Epoch: 2/2, step 2951/7134 completed (loss: 0.11896713823080063, acc: 0.9627329111099243)
[2024-12-17 02:39:21,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:21,286][root][INFO] - Training Epoch: 2/2, step 2952/7134 completed (loss: 0.1230548694729805, acc: 0.9681528806686401)
[2024-12-17 02:39:21,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:21,544][root][INFO] - Training Epoch: 2/2, step 2953/7134 completed (loss: 0.20547138154506683, acc: 0.9523809552192688)
[2024-12-17 02:39:21,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:21,820][root][INFO] - Training Epoch: 2/2, step 2954/7134 completed (loss: 0.17401205003261566, acc: 0.9536082744598389)
[2024-12-17 02:39:21,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:22,075][root][INFO] - Training Epoch: 2/2, step 2955/7134 completed (loss: 0.13014021515846252, acc: 0.9575757384300232)
[2024-12-17 02:39:22,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:22,360][root][INFO] - Training Epoch: 2/2, step 2956/7134 completed (loss: 0.12593446671962738, acc: 0.9693251252174377)
[2024-12-17 02:39:22,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:22,644][root][INFO] - Training Epoch: 2/2, step 2957/7134 completed (loss: 0.0797097384929657, acc: 0.9942528605461121)
[2024-12-17 02:39:22,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:22,920][root][INFO] - Training Epoch: 2/2, step 2958/7134 completed (loss: 0.12139084935188293, acc: 0.9722222089767456)
[2024-12-17 02:39:23,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:23,211][root][INFO] - Training Epoch: 2/2, step 2959/7134 completed (loss: 0.10017123073339462, acc: 0.9683544039726257)
[2024-12-17 02:39:23,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:23,497][root][INFO] - Training Epoch: 2/2, step 2960/7134 completed (loss: 0.1453728973865509, acc: 0.9725274443626404)
[2024-12-17 02:39:23,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:23,779][root][INFO] - Training Epoch: 2/2, step 2961/7134 completed (loss: 0.17147529125213623, acc: 0.9520958065986633)
[2024-12-17 02:39:23,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:24,047][root][INFO] - Training Epoch: 2/2, step 2962/7134 completed (loss: 0.09206581860780716, acc: 0.976190447807312)
[2024-12-17 02:39:24,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:24,331][root][INFO] - Training Epoch: 2/2, step 2963/7134 completed (loss: 0.17474916577339172, acc: 0.9553072452545166)
[2024-12-17 02:39:24,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:24,605][root][INFO] - Training Epoch: 2/2, step 2964/7134 completed (loss: 0.03967589884996414, acc: 0.9866666793823242)
[2024-12-17 02:39:24,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:24,901][root][INFO] - Training Epoch: 2/2, step 2965/7134 completed (loss: 0.24478234350681305, acc: 0.9261363744735718)
[2024-12-17 02:39:25,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:25,181][root][INFO] - Training Epoch: 2/2, step 2966/7134 completed (loss: 0.1191115528345108, acc: 0.9743589758872986)
[2024-12-17 02:39:25,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:25,487][root][INFO] - Training Epoch: 2/2, step 2967/7134 completed (loss: 0.3141286075115204, acc: 0.9289617538452148)
[2024-12-17 02:39:25,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:25,801][root][INFO] - Training Epoch: 2/2, step 2968/7134 completed (loss: 0.5283259749412537, acc: 0.8687499761581421)
[2024-12-17 02:39:25,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:26,098][root][INFO] - Training Epoch: 2/2, step 2969/7134 completed (loss: 1.4287137985229492, acc: 0.762135922908783)
[2024-12-17 02:39:26,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:26,381][root][INFO] - Training Epoch: 2/2, step 2970/7134 completed (loss: 1.272145390510559, acc: 0.746268630027771)
[2024-12-17 02:39:26,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:26,659][root][INFO] - Training Epoch: 2/2, step 2971/7134 completed (loss: 0.28953656554222107, acc: 0.9171270728111267)
[2024-12-17 02:39:26,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:26,937][root][INFO] - Training Epoch: 2/2, step 2972/7134 completed (loss: 0.3694387674331665, acc: 0.9133333563804626)
[2024-12-17 02:39:27,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:27,212][root][INFO] - Training Epoch: 2/2, step 2973/7134 completed (loss: 0.251775860786438, acc: 0.939393937587738)
[2024-12-17 02:39:27,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:27,491][root][INFO] - Training Epoch: 2/2, step 2974/7134 completed (loss: 0.295146107673645, acc: 0.9181286692619324)
[2024-12-17 02:39:27,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:27,772][root][INFO] - Training Epoch: 2/2, step 2975/7134 completed (loss: 0.2078200727701187, acc: 0.930232584476471)
[2024-12-17 02:39:27,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:28,065][root][INFO] - Training Epoch: 2/2, step 2976/7134 completed (loss: 0.16087673604488373, acc: 0.948113203048706)
[2024-12-17 02:39:28,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:28,330][root][INFO] - Training Epoch: 2/2, step 2977/7134 completed (loss: 0.2465912401676178, acc: 0.9379310607910156)
[2024-12-17 02:39:28,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:28,603][root][INFO] - Training Epoch: 2/2, step 2978/7134 completed (loss: 0.3089517056941986, acc: 0.9337349534034729)
[2024-12-17 02:39:28,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:28,864][root][INFO] - Training Epoch: 2/2, step 2979/7134 completed (loss: 0.183017298579216, acc: 0.9586206674575806)
[2024-12-17 02:39:29,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:29,154][root][INFO] - Training Epoch: 2/2, step 2980/7134 completed (loss: 0.32420188188552856, acc: 0.9200000166893005)
[2024-12-17 02:39:29,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:29,429][root][INFO] - Training Epoch: 2/2, step 2981/7134 completed (loss: 0.34134188294410706, acc: 0.9080459475517273)
[2024-12-17 02:39:29,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:29,701][root][INFO] - Training Epoch: 2/2, step 2982/7134 completed (loss: 0.39505746960639954, acc: 0.8956043720245361)
[2024-12-17 02:39:29,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:29,984][root][INFO] - Training Epoch: 2/2, step 2983/7134 completed (loss: 0.2734037935733795, acc: 0.907975435256958)
[2024-12-17 02:39:30,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:30,274][root][INFO] - Training Epoch: 2/2, step 2984/7134 completed (loss: 0.2718680500984192, acc: 0.9340659379959106)
[2024-12-17 02:39:30,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:30,565][root][INFO] - Training Epoch: 2/2, step 2985/7134 completed (loss: 0.14976999163627625, acc: 0.9756097793579102)
[2024-12-17 02:39:30,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:30,860][root][INFO] - Training Epoch: 2/2, step 2986/7134 completed (loss: 0.19359026849269867, acc: 0.9484536051750183)
[2024-12-17 02:39:30,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:31,137][root][INFO] - Training Epoch: 2/2, step 2987/7134 completed (loss: 0.16419821977615356, acc: 0.967391312122345)
[2024-12-17 02:39:31,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:31,414][root][INFO] - Training Epoch: 2/2, step 2988/7134 completed (loss: 0.24370592832565308, acc: 0.9189189076423645)
[2024-12-17 02:39:31,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:31,691][root][INFO] - Training Epoch: 2/2, step 2989/7134 completed (loss: 0.19973094761371613, acc: 0.9520958065986633)
[2024-12-17 02:39:31,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:31,954][root][INFO] - Training Epoch: 2/2, step 2990/7134 completed (loss: 0.418094664812088, acc: 0.912162184715271)
[2024-12-17 02:39:32,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:32,253][root][INFO] - Training Epoch: 2/2, step 2991/7134 completed (loss: 0.8325839638710022, acc: 0.8125)
[2024-12-17 02:39:32,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:32,528][root][INFO] - Training Epoch: 2/2, step 2992/7134 completed (loss: 0.42493098974227905, acc: 0.9245283007621765)
[2024-12-17 02:39:32,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:32,817][root][INFO] - Training Epoch: 2/2, step 2993/7134 completed (loss: 0.1774904578924179, acc: 0.9447236061096191)
[2024-12-17 02:39:32,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:33,079][root][INFO] - Training Epoch: 2/2, step 2994/7134 completed (loss: 0.23638935387134552, acc: 0.9603174328804016)
[2024-12-17 02:39:33,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:33,383][root][INFO] - Training Epoch: 2/2, step 2995/7134 completed (loss: 0.1608167290687561, acc: 0.9563106894493103)
[2024-12-17 02:39:33,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:33,669][root][INFO] - Training Epoch: 2/2, step 2996/7134 completed (loss: 0.22399748861789703, acc: 0.9484536051750183)
[2024-12-17 02:39:33,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:33,956][root][INFO] - Training Epoch: 2/2, step 2997/7134 completed (loss: 0.10011162608861923, acc: 0.9764150977134705)
[2024-12-17 02:39:34,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:34,240][root][INFO] - Training Epoch: 2/2, step 2998/7134 completed (loss: 0.18955658376216888, acc: 0.9702380895614624)
[2024-12-17 02:39:34,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:34,545][root][INFO] - Training Epoch: 2/2, step 2999/7134 completed (loss: 0.1241491436958313, acc: 0.9750000238418579)
[2024-12-17 02:39:34,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:34,830][root][INFO] - Training Epoch: 2/2, step 3000/7134 completed (loss: 0.3327811658382416, acc: 0.9074074029922485)
[2024-12-17 02:39:34,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:35,112][root][INFO] - Training Epoch: 2/2, step 3001/7134 completed (loss: 0.22179986536502838, acc: 0.9340101480484009)
[2024-12-17 02:39:35,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:35,394][root][INFO] - Training Epoch: 2/2, step 3002/7134 completed (loss: 0.2738488018512726, acc: 0.9262672662734985)
[2024-12-17 02:39:35,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:35,677][root][INFO] - Training Epoch: 2/2, step 3003/7134 completed (loss: 0.10307884961366653, acc: 0.9695431590080261)
[2024-12-17 02:39:35,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:35,954][root][INFO] - Training Epoch: 2/2, step 3004/7134 completed (loss: 0.08911405503749847, acc: 0.9900990128517151)
[2024-12-17 02:39:36,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:36,249][root][INFO] - Training Epoch: 2/2, step 3005/7134 completed (loss: 0.0391998291015625, acc: 0.9896373152732849)
[2024-12-17 02:39:36,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:36,537][root][INFO] - Training Epoch: 2/2, step 3006/7134 completed (loss: 0.05671203136444092, acc: 0.9885714054107666)
[2024-12-17 02:39:36,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:36,817][root][INFO] - Training Epoch: 2/2, step 3007/7134 completed (loss: 0.16275107860565186, acc: 0.9593023061752319)
[2024-12-17 02:39:36,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:37,093][root][INFO] - Training Epoch: 2/2, step 3008/7134 completed (loss: 0.25912049412727356, acc: 0.9387755393981934)
[2024-12-17 02:39:37,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:37,390][root][INFO] - Training Epoch: 2/2, step 3009/7134 completed (loss: 0.28509747982025146, acc: 0.9583333134651184)
[2024-12-17 02:39:37,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:37,667][root][INFO] - Training Epoch: 2/2, step 3010/7134 completed (loss: 0.21972009539604187, acc: 0.9485714435577393)
[2024-12-17 02:39:37,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:37,942][root][INFO] - Training Epoch: 2/2, step 3011/7134 completed (loss: 0.45830896496772766, acc: 0.903030276298523)
[2024-12-17 02:39:38,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:38,217][root][INFO] - Training Epoch: 2/2, step 3012/7134 completed (loss: 0.4367917776107788, acc: 0.9280575513839722)
[2024-12-17 02:39:38,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:38,513][root][INFO] - Training Epoch: 2/2, step 3013/7134 completed (loss: 0.094086654484272, acc: 0.9709302186965942)
[2024-12-17 02:39:38,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:38,802][root][INFO] - Training Epoch: 2/2, step 3014/7134 completed (loss: 0.12543286383152008, acc: 0.9746835231781006)
[2024-12-17 02:39:38,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:39,053][root][INFO] - Training Epoch: 2/2, step 3015/7134 completed (loss: 0.09804534912109375, acc: 0.9647887349128723)
[2024-12-17 02:39:39,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:39,344][root][INFO] - Training Epoch: 2/2, step 3016/7134 completed (loss: 0.11554324626922607, acc: 0.9726027250289917)
[2024-12-17 02:39:39,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:39,615][root][INFO] - Training Epoch: 2/2, step 3017/7134 completed (loss: 0.10870621353387833, acc: 0.9586777091026306)
[2024-12-17 02:39:39,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:39,868][root][INFO] - Training Epoch: 2/2, step 3018/7134 completed (loss: 0.11561836302280426, acc: 0.9847328066825867)
[2024-12-17 02:39:39,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:40,150][root][INFO] - Training Epoch: 2/2, step 3019/7134 completed (loss: 0.1431191861629486, acc: 0.9632353186607361)
[2024-12-17 02:39:40,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:40,429][root][INFO] - Training Epoch: 2/2, step 3020/7134 completed (loss: 0.13838931918144226, acc: 0.9784172773361206)
[2024-12-17 02:39:40,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:40,681][root][INFO] - Training Epoch: 2/2, step 3021/7134 completed (loss: 0.146097332239151, acc: 0.9545454382896423)
[2024-12-17 02:39:40,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:40,972][root][INFO] - Training Epoch: 2/2, step 3022/7134 completed (loss: 0.17769508063793182, acc: 0.9548872113227844)
[2024-12-17 02:39:41,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:41,240][root][INFO] - Training Epoch: 2/2, step 3023/7134 completed (loss: 0.18508794903755188, acc: 0.9538461565971375)
[2024-12-17 02:39:41,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:41,534][root][INFO] - Training Epoch: 2/2, step 3024/7134 completed (loss: 0.14868862926959991, acc: 0.9583333134651184)
[2024-12-17 02:39:41,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:41,812][root][INFO] - Training Epoch: 2/2, step 3025/7134 completed (loss: 0.22169409692287445, acc: 0.9538461565971375)
[2024-12-17 02:39:41,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:42,089][root][INFO] - Training Epoch: 2/2, step 3026/7134 completed (loss: 0.13116541504859924, acc: 0.9754098653793335)
[2024-12-17 02:39:42,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:42,359][root][INFO] - Training Epoch: 2/2, step 3027/7134 completed (loss: 0.22684913873672485, acc: 0.9583333134651184)
[2024-12-17 02:39:42,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:42,601][root][INFO] - Training Epoch: 2/2, step 3028/7134 completed (loss: 0.11808890104293823, acc: 0.969072163105011)
[2024-12-17 02:39:42,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:42,860][root][INFO] - Training Epoch: 2/2, step 3029/7134 completed (loss: 0.19685310125350952, acc: 0.965753436088562)
[2024-12-17 02:39:43,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:43,162][root][INFO] - Training Epoch: 2/2, step 3030/7134 completed (loss: 0.12632088363170624, acc: 0.9729729890823364)
[2024-12-17 02:39:43,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:43,421][root][INFO] - Training Epoch: 2/2, step 3031/7134 completed (loss: 0.09077490866184235, acc: 0.9696969985961914)
[2024-12-17 02:39:43,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:43,719][root][INFO] - Training Epoch: 2/2, step 3032/7134 completed (loss: 0.1868123710155487, acc: 0.9435483813285828)
[2024-12-17 02:39:43,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:44,015][root][INFO] - Training Epoch: 2/2, step 3033/7134 completed (loss: 0.14944133162498474, acc: 0.953125)
[2024-12-17 02:39:44,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:44,303][root][INFO] - Training Epoch: 2/2, step 3034/7134 completed (loss: 0.19820168614387512, acc: 0.9459459185600281)
[2024-12-17 02:39:44,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:44,559][root][INFO] - Training Epoch: 2/2, step 3035/7134 completed (loss: 0.1363864243030548, acc: 0.9727891087532043)
[2024-12-17 02:39:44,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:44,818][root][INFO] - Training Epoch: 2/2, step 3036/7134 completed (loss: 0.2694128751754761, acc: 0.9359999895095825)
[2024-12-17 02:39:44,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:45,103][root][INFO] - Training Epoch: 2/2, step 3037/7134 completed (loss: 0.1894882470369339, acc: 0.9530201554298401)
[2024-12-17 02:39:45,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:45,392][root][INFO] - Training Epoch: 2/2, step 3038/7134 completed (loss: 0.12609674036502838, acc: 0.9552238583564758)
[2024-12-17 02:39:45,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:45,669][root][INFO] - Training Epoch: 2/2, step 3039/7134 completed (loss: 0.21345534920692444, acc: 0.9662162065505981)
[2024-12-17 02:39:45,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:45,939][root][INFO] - Training Epoch: 2/2, step 3040/7134 completed (loss: 0.133799210190773, acc: 0.961240291595459)
[2024-12-17 02:39:46,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:46,235][root][INFO] - Training Epoch: 2/2, step 3041/7134 completed (loss: 0.2906734347343445, acc: 0.9357143044471741)
[2024-12-17 02:39:46,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:46,519][root][INFO] - Training Epoch: 2/2, step 3042/7134 completed (loss: 0.13574984669685364, acc: 0.9615384340286255)
[2024-12-17 02:39:46,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:46,791][root][INFO] - Training Epoch: 2/2, step 3043/7134 completed (loss: 0.10883194208145142, acc: 0.9642857313156128)
[2024-12-17 02:39:46,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:47,064][root][INFO] - Training Epoch: 2/2, step 3044/7134 completed (loss: 0.12404395639896393, acc: 0.9774436354637146)
[2024-12-17 02:39:47,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:47,349][root][INFO] - Training Epoch: 2/2, step 3045/7134 completed (loss: 0.07084930688142776, acc: 0.9844961166381836)
[2024-12-17 02:39:47,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:47,670][root][INFO] - Training Epoch: 2/2, step 3046/7134 completed (loss: 0.16315318644046783, acc: 0.9585798978805542)
[2024-12-17 02:39:47,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:47,955][root][INFO] - Training Epoch: 2/2, step 3047/7134 completed (loss: 0.15539972484111786, acc: 0.9604519605636597)
[2024-12-17 02:39:48,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:48,297][root][INFO] - Training Epoch: 2/2, step 3048/7134 completed (loss: 0.22145134210586548, acc: 0.9315789341926575)
[2024-12-17 02:39:48,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:48,589][root][INFO] - Training Epoch: 2/2, step 3049/7134 completed (loss: 0.2624937891960144, acc: 0.925000011920929)
[2024-12-17 02:39:48,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:48,876][root][INFO] - Training Epoch: 2/2, step 3050/7134 completed (loss: 0.22289076447486877, acc: 0.9340101480484009)
[2024-12-17 02:39:48,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:49,148][root][INFO] - Training Epoch: 2/2, step 3051/7134 completed (loss: 0.17603038251399994, acc: 0.9464285969734192)
[2024-12-17 02:39:49,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:49,424][root][INFO] - Training Epoch: 2/2, step 3052/7134 completed (loss: 0.12791655957698822, acc: 0.9675675630569458)
[2024-12-17 02:39:49,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:49,723][root][INFO] - Training Epoch: 2/2, step 3053/7134 completed (loss: 0.139815092086792, acc: 0.9502487778663635)
[2024-12-17 02:39:49,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:50,007][root][INFO] - Training Epoch: 2/2, step 3054/7134 completed (loss: 0.0637713149189949, acc: 0.9840425252914429)
[2024-12-17 02:39:50,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:50,299][root][INFO] - Training Epoch: 2/2, step 3055/7134 completed (loss: 0.14416202902793884, acc: 0.9662162065505981)
[2024-12-17 02:39:50,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:50,589][root][INFO] - Training Epoch: 2/2, step 3056/7134 completed (loss: 0.12490865588188171, acc: 0.9621621370315552)
[2024-12-17 02:39:50,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:50,883][root][INFO] - Training Epoch: 2/2, step 3057/7134 completed (loss: 0.12749691307544708, acc: 0.9693251252174377)
[2024-12-17 02:39:50,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:51,158][root][INFO] - Training Epoch: 2/2, step 3058/7134 completed (loss: 0.17727908492088318, acc: 0.9631578922271729)
[2024-12-17 02:39:51,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:51,441][root][INFO] - Training Epoch: 2/2, step 3059/7134 completed (loss: 0.05408152565360069, acc: 0.9942857027053833)
[2024-12-17 02:39:51,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:51,723][root][INFO] - Training Epoch: 2/2, step 3060/7134 completed (loss: 0.1628255844116211, acc: 0.9424083828926086)
[2024-12-17 02:39:51,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:51,975][root][INFO] - Training Epoch: 2/2, step 3061/7134 completed (loss: 0.10011663287878036, acc: 0.981249988079071)
[2024-12-17 02:39:52,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:52,260][root][INFO] - Training Epoch: 2/2, step 3062/7134 completed (loss: 0.10763288289308548, acc: 0.9685534834861755)
[2024-12-17 02:39:52,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:52,533][root][INFO] - Training Epoch: 2/2, step 3063/7134 completed (loss: 0.20052804052829742, acc: 0.9431818127632141)
[2024-12-17 02:39:52,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:52,821][root][INFO] - Training Epoch: 2/2, step 3064/7134 completed (loss: 0.1062668114900589, acc: 0.9644970297813416)
[2024-12-17 02:39:52,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:53,112][root][INFO] - Training Epoch: 2/2, step 3065/7134 completed (loss: 0.04170415177941322, acc: 0.9943820238113403)
[2024-12-17 02:39:53,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:53,415][root][INFO] - Training Epoch: 2/2, step 3066/7134 completed (loss: 0.09046848863363266, acc: 0.9933775067329407)
[2024-12-17 02:39:53,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:53,682][root][INFO] - Training Epoch: 2/2, step 3067/7134 completed (loss: 0.10709881782531738, acc: 0.9558823704719543)
[2024-12-17 02:39:53,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:53,970][root][INFO] - Training Epoch: 2/2, step 3068/7134 completed (loss: 0.17272944748401642, acc: 0.9553072452545166)
[2024-12-17 02:39:54,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:54,247][root][INFO] - Training Epoch: 2/2, step 3069/7134 completed (loss: 0.02702881209552288, acc: 1.0)
[2024-12-17 02:39:54,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:54,548][root][INFO] - Training Epoch: 2/2, step 3070/7134 completed (loss: 0.022523876279592514, acc: 1.0)
[2024-12-17 02:39:54,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:54,833][root][INFO] - Training Epoch: 2/2, step 3071/7134 completed (loss: 0.10182401537895203, acc: 0.9777777791023254)
[2024-12-17 02:39:54,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:55,117][root][INFO] - Training Epoch: 2/2, step 3072/7134 completed (loss: 0.07598558068275452, acc: 0.9765258431434631)
[2024-12-17 02:39:55,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:55,404][root][INFO] - Training Epoch: 2/2, step 3073/7134 completed (loss: 0.1466592252254486, acc: 0.9661017060279846)
[2024-12-17 02:39:55,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:55,682][root][INFO] - Training Epoch: 2/2, step 3074/7134 completed (loss: 0.04141256958246231, acc: 0.9933775067329407)
[2024-12-17 02:39:55,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:55,935][root][INFO] - Training Epoch: 2/2, step 3075/7134 completed (loss: 0.08616378158330917, acc: 0.9753086566925049)
[2024-12-17 02:39:56,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:56,206][root][INFO] - Training Epoch: 2/2, step 3076/7134 completed (loss: 0.09229348599910736, acc: 0.9623655676841736)
[2024-12-17 02:39:56,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:56,499][root][INFO] - Training Epoch: 2/2, step 3077/7134 completed (loss: 0.24313470721244812, acc: 0.9528796076774597)
[2024-12-17 02:39:56,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:56,783][root][INFO] - Training Epoch: 2/2, step 3078/7134 completed (loss: 0.15323367714881897, acc: 0.9635416865348816)
[2024-12-17 02:39:56,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:57,066][root][INFO] - Training Epoch: 2/2, step 3079/7134 completed (loss: 0.16232429444789886, acc: 0.9523809552192688)
[2024-12-17 02:39:57,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:57,355][root][INFO] - Training Epoch: 2/2, step 3080/7134 completed (loss: 0.2551474869251251, acc: 0.9351851940155029)
[2024-12-17 02:39:57,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:57,660][root][INFO] - Training Epoch: 2/2, step 3081/7134 completed (loss: 0.1367221176624298, acc: 0.9603960514068604)
[2024-12-17 02:39:57,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:57,938][root][INFO] - Training Epoch: 2/2, step 3082/7134 completed (loss: 0.38740697503089905, acc: 0.89552241563797)
[2024-12-17 02:39:58,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:58,244][root][INFO] - Training Epoch: 2/2, step 3083/7134 completed (loss: 0.19199855625629425, acc: 0.9351351261138916)
[2024-12-17 02:39:58,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:58,536][root][INFO] - Training Epoch: 2/2, step 3084/7134 completed (loss: 0.237300306558609, acc: 0.9319371581077576)
[2024-12-17 02:39:58,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:58,809][root][INFO] - Training Epoch: 2/2, step 3085/7134 completed (loss: 0.3159851133823395, acc: 0.9161290526390076)
[2024-12-17 02:39:58,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:59,104][root][INFO] - Training Epoch: 2/2, step 3086/7134 completed (loss: 0.23997658491134644, acc: 0.9406392574310303)
[2024-12-17 02:39:59,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:59,391][root][INFO] - Training Epoch: 2/2, step 3087/7134 completed (loss: 0.20467950403690338, acc: 0.9467455744743347)
[2024-12-17 02:39:59,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:59,676][root][INFO] - Training Epoch: 2/2, step 3088/7134 completed (loss: 0.220199316740036, acc: 0.9485981464385986)
[2024-12-17 02:39:59,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:59,978][root][INFO] - Training Epoch: 2/2, step 3089/7134 completed (loss: 0.1833464354276657, acc: 0.9488372206687927)
[2024-12-17 02:40:00,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:00,271][root][INFO] - Training Epoch: 2/2, step 3090/7134 completed (loss: 0.4323626458644867, acc: 0.8983050584793091)
[2024-12-17 02:40:00,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:00,570][root][INFO] - Training Epoch: 2/2, step 3091/7134 completed (loss: 0.4994221329689026, acc: 0.8583691120147705)
[2024-12-17 02:40:00,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:00,849][root][INFO] - Training Epoch: 2/2, step 3092/7134 completed (loss: 0.3850565254688263, acc: 0.9083969593048096)
[2024-12-17 02:40:00,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:01,144][root][INFO] - Training Epoch: 2/2, step 3093/7134 completed (loss: 0.29069381952285767, acc: 0.9295774698257446)
[2024-12-17 02:40:01,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:01,435][root][INFO] - Training Epoch: 2/2, step 3094/7134 completed (loss: 0.11809146404266357, acc: 0.9768785834312439)
[2024-12-17 02:40:01,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:01,709][root][INFO] - Training Epoch: 2/2, step 3095/7134 completed (loss: 0.284784197807312, acc: 0.949999988079071)
[2024-12-17 02:40:01,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:01,987][root][INFO] - Training Epoch: 2/2, step 3096/7134 completed (loss: 0.28322288393974304, acc: 0.9319371581077576)
[2024-12-17 02:40:02,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:02,265][root][INFO] - Training Epoch: 2/2, step 3097/7134 completed (loss: 0.2620234787464142, acc: 0.9329268336296082)
[2024-12-17 02:40:02,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:02,559][root][INFO] - Training Epoch: 2/2, step 3098/7134 completed (loss: 0.19650645554065704, acc: 0.9607843160629272)
[2024-12-17 02:40:02,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:02,814][root][INFO] - Training Epoch: 2/2, step 3099/7134 completed (loss: 0.1618937849998474, acc: 0.956204354763031)
[2024-12-17 02:40:02,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:03,100][root][INFO] - Training Epoch: 2/2, step 3100/7134 completed (loss: 0.1791667342185974, acc: 0.9641255736351013)
[2024-12-17 02:40:03,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:03,377][root][INFO] - Training Epoch: 2/2, step 3101/7134 completed (loss: 0.17489147186279297, acc: 0.9441624283790588)
[2024-12-17 02:40:03,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:03,676][root][INFO] - Training Epoch: 2/2, step 3102/7134 completed (loss: 0.11148576438426971, acc: 0.9631901979446411)
[2024-12-17 02:40:03,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:03,959][root][INFO] - Training Epoch: 2/2, step 3103/7134 completed (loss: 0.18209032714366913, acc: 0.9568965435028076)
[2024-12-17 02:40:04,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:04,206][root][INFO] - Training Epoch: 2/2, step 3104/7134 completed (loss: 0.09300971776247025, acc: 0.9767441749572754)
[2024-12-17 02:40:04,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:04,476][root][INFO] - Training Epoch: 2/2, step 3105/7134 completed (loss: 0.3311210572719574, acc: 0.9217391014099121)
[2024-12-17 02:40:04,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:04,743][root][INFO] - Training Epoch: 2/2, step 3106/7134 completed (loss: 0.16164039075374603, acc: 0.9530201554298401)
[2024-12-17 02:40:04,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:05,010][root][INFO] - Training Epoch: 2/2, step 3107/7134 completed (loss: 0.10111924260854721, acc: 0.9593023061752319)
[2024-12-17 02:40:05,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:05,284][root][INFO] - Training Epoch: 2/2, step 3108/7134 completed (loss: 0.1352889984846115, acc: 0.9659863710403442)
[2024-12-17 02:40:05,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:05,565][root][INFO] - Training Epoch: 2/2, step 3109/7134 completed (loss: 0.3093859851360321, acc: 0.9307692050933838)
[2024-12-17 02:40:05,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:05,851][root][INFO] - Training Epoch: 2/2, step 3110/7134 completed (loss: 0.19116279482841492, acc: 0.9223300814628601)
[2024-12-17 02:40:05,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:06,131][root][INFO] - Training Epoch: 2/2, step 3111/7134 completed (loss: 0.48255616426467896, acc: 0.8550724387168884)
[2024-12-17 02:40:06,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:06,394][root][INFO] - Training Epoch: 2/2, step 3112/7134 completed (loss: 0.3290439546108246, acc: 0.9270073175430298)
[2024-12-17 02:40:06,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:06,685][root][INFO] - Training Epoch: 2/2, step 3113/7134 completed (loss: 0.19555984437465668, acc: 0.9512194991111755)
[2024-12-17 02:40:06,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:06,962][root][INFO] - Training Epoch: 2/2, step 3114/7134 completed (loss: 0.18169008195400238, acc: 0.9473684430122375)
[2024-12-17 02:40:07,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:07,224][root][INFO] - Training Epoch: 2/2, step 3115/7134 completed (loss: 0.16968032717704773, acc: 0.9671052694320679)
[2024-12-17 02:40:07,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:07,515][root][INFO] - Training Epoch: 2/2, step 3116/7134 completed (loss: 0.23222161829471588, acc: 0.9265536665916443)
[2024-12-17 02:40:07,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:07,799][root][INFO] - Training Epoch: 2/2, step 3117/7134 completed (loss: 0.3289964199066162, acc: 0.932584285736084)
[2024-12-17 02:40:07,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:08,070][root][INFO] - Training Epoch: 2/2, step 3118/7134 completed (loss: 0.20590640604496002, acc: 0.9447513818740845)
[2024-12-17 02:40:08,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:08,348][root][INFO] - Training Epoch: 2/2, step 3119/7134 completed (loss: 0.24568454921245575, acc: 0.9259259104728699)
[2024-12-17 02:40:08,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:08,628][root][INFO] - Training Epoch: 2/2, step 3120/7134 completed (loss: 0.3432188332080841, acc: 0.9444444179534912)
[2024-12-17 02:40:08,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:08,905][root][INFO] - Training Epoch: 2/2, step 3121/7134 completed (loss: 0.12606795132160187, acc: 0.9602272510528564)
[2024-12-17 02:40:09,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:09,199][root][INFO] - Training Epoch: 2/2, step 3122/7134 completed (loss: 0.19817599654197693, acc: 0.9473684430122375)
[2024-12-17 02:40:09,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:09,484][root][INFO] - Training Epoch: 2/2, step 3123/7134 completed (loss: 0.1999671310186386, acc: 0.9621621370315552)
[2024-12-17 02:40:09,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:09,763][root][INFO] - Training Epoch: 2/2, step 3124/7134 completed (loss: 0.29779157042503357, acc: 0.9055555462837219)
[2024-12-17 02:40:09,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:10,033][root][INFO] - Training Epoch: 2/2, step 3125/7134 completed (loss: 0.10417421162128448, acc: 0.9727891087532043)
[2024-12-17 02:40:10,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:10,328][root][INFO] - Training Epoch: 2/2, step 3126/7134 completed (loss: 0.3549483120441437, acc: 0.9441340565681458)
[2024-12-17 02:40:10,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:10,606][root][INFO] - Training Epoch: 2/2, step 3127/7134 completed (loss: 0.22229580581188202, acc: 0.9483568072319031)
[2024-12-17 02:40:10,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:10,892][root][INFO] - Training Epoch: 2/2, step 3128/7134 completed (loss: 0.18434616923332214, acc: 0.9572192430496216)
[2024-12-17 02:40:11,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:11,180][root][INFO] - Training Epoch: 2/2, step 3129/7134 completed (loss: 0.169101744890213, acc: 0.9659090638160706)
[2024-12-17 02:40:11,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:11,501][root][INFO] - Training Epoch: 2/2, step 3130/7134 completed (loss: 0.07194289565086365, acc: 0.9746192693710327)
[2024-12-17 02:40:11,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:11,798][root][INFO] - Training Epoch: 2/2, step 3131/7134 completed (loss: 0.3054378032684326, acc: 0.9322034120559692)
[2024-12-17 02:40:11,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:12,067][root][INFO] - Training Epoch: 2/2, step 3132/7134 completed (loss: 0.11620581150054932, acc: 0.9734513163566589)
[2024-12-17 02:40:12,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:12,363][root][INFO] - Training Epoch: 2/2, step 3133/7134 completed (loss: 0.32766973972320557, acc: 0.9488636255264282)
[2024-12-17 02:40:12,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:12,652][root][INFO] - Training Epoch: 2/2, step 3134/7134 completed (loss: 0.2063950002193451, acc: 0.921875)
[2024-12-17 02:40:12,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:12,922][root][INFO] - Training Epoch: 2/2, step 3135/7134 completed (loss: 0.23972752690315247, acc: 0.938144326210022)
[2024-12-17 02:40:13,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:13,205][root][INFO] - Training Epoch: 2/2, step 3136/7134 completed (loss: 0.1828509420156479, acc: 0.9694656729698181)
[2024-12-17 02:40:13,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:13,488][root][INFO] - Training Epoch: 2/2, step 3137/7134 completed (loss: 0.3161921501159668, acc: 0.914893627166748)
[2024-12-17 02:40:13,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:13,751][root][INFO] - Training Epoch: 2/2, step 3138/7134 completed (loss: 0.3610733151435852, acc: 0.9333333373069763)
[2024-12-17 02:40:13,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:14,012][root][INFO] - Training Epoch: 2/2, step 3139/7134 completed (loss: 0.37263646721839905, acc: 0.9208633303642273)
[2024-12-17 02:40:14,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:14,277][root][INFO] - Training Epoch: 2/2, step 3140/7134 completed (loss: 0.2167438417673111, acc: 0.9589040875434875)
[2024-12-17 02:40:14,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:14,553][root][INFO] - Training Epoch: 2/2, step 3141/7134 completed (loss: 0.3100552558898926, acc: 0.9391891956329346)
[2024-12-17 02:40:14,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:14,820][root][INFO] - Training Epoch: 2/2, step 3142/7134 completed (loss: 0.10932759940624237, acc: 0.970059871673584)
[2024-12-17 02:40:14,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:15,099][root][INFO] - Training Epoch: 2/2, step 3143/7134 completed (loss: 0.2722393572330475, acc: 0.9419354796409607)
[2024-12-17 02:40:15,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:15,381][root][INFO] - Training Epoch: 2/2, step 3144/7134 completed (loss: 0.2997431755065918, acc: 0.9230769276618958)
[2024-12-17 02:40:15,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:15,670][root][INFO] - Training Epoch: 2/2, step 3145/7134 completed (loss: 0.1627642661333084, acc: 0.954954981803894)
[2024-12-17 02:40:15,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:15,948][root][INFO] - Training Epoch: 2/2, step 3146/7134 completed (loss: 0.3138904869556427, acc: 0.9444444179534912)
[2024-12-17 02:40:16,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:16,223][root][INFO] - Training Epoch: 2/2, step 3147/7134 completed (loss: 0.17161540687084198, acc: 0.9589040875434875)
[2024-12-17 02:40:16,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:16,506][root][INFO] - Training Epoch: 2/2, step 3148/7134 completed (loss: 0.16649657487869263, acc: 0.9497206807136536)
[2024-12-17 02:40:16,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:16,785][root][INFO] - Training Epoch: 2/2, step 3149/7134 completed (loss: 0.13049742579460144, acc: 0.9677419066429138)
[2024-12-17 02:40:16,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:17,067][root][INFO] - Training Epoch: 2/2, step 3150/7134 completed (loss: 0.8973257541656494, acc: 0.8071428537368774)
[2024-12-17 02:40:17,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:17,346][root][INFO] - Training Epoch: 2/2, step 3151/7134 completed (loss: 0.4697551131248474, acc: 0.8778625726699829)
[2024-12-17 02:40:17,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:17,602][root][INFO] - Training Epoch: 2/2, step 3152/7134 completed (loss: 0.17710790038108826, acc: 0.9718309640884399)
[2024-12-17 02:40:17,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:17,885][root][INFO] - Training Epoch: 2/2, step 3153/7134 completed (loss: 0.19695574045181274, acc: 0.9438202381134033)
[2024-12-17 02:40:17,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:18,159][root][INFO] - Training Epoch: 2/2, step 3154/7134 completed (loss: 0.3648861050605774, acc: 0.932330846786499)
[2024-12-17 02:40:18,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:18,429][root][INFO] - Training Epoch: 2/2, step 3155/7134 completed (loss: 0.6171358823776245, acc: 0.8872180581092834)
[2024-12-17 02:40:18,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:18,720][root][INFO] - Training Epoch: 2/2, step 3156/7134 completed (loss: 0.4465295672416687, acc: 0.9069767594337463)
[2024-12-17 02:40:18,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:18,992][root][INFO] - Training Epoch: 2/2, step 3157/7134 completed (loss: 0.3170437216758728, acc: 0.9304347634315491)
[2024-12-17 02:40:19,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:19,254][root][INFO] - Training Epoch: 2/2, step 3158/7134 completed (loss: 0.174001082777977, acc: 0.9503546357154846)
[2024-12-17 02:40:19,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:19,524][root][INFO] - Training Epoch: 2/2, step 3159/7134 completed (loss: 0.29663509130477905, acc: 0.9175257682800293)
[2024-12-17 02:40:19,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:19,812][root][INFO] - Training Epoch: 2/2, step 3160/7134 completed (loss: 0.11472772061824799, acc: 0.9807692170143127)
[2024-12-17 02:40:19,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:20,096][root][INFO] - Training Epoch: 2/2, step 3161/7134 completed (loss: 0.2057354748249054, acc: 0.9554139971733093)
[2024-12-17 02:40:20,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:20,376][root][INFO] - Training Epoch: 2/2, step 3162/7134 completed (loss: 0.13513347506523132, acc: 0.9589040875434875)
[2024-12-17 02:40:20,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:20,635][root][INFO] - Training Epoch: 2/2, step 3163/7134 completed (loss: 0.103589728474617, acc: 0.9836065769195557)
[2024-12-17 02:40:20,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:20,907][root][INFO] - Training Epoch: 2/2, step 3164/7134 completed (loss: 0.2409454882144928, acc: 0.9420289993286133)
[2024-12-17 02:40:21,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:21,184][root][INFO] - Training Epoch: 2/2, step 3165/7134 completed (loss: 0.24442824721336365, acc: 0.9370629191398621)
[2024-12-17 02:40:21,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:21,462][root][INFO] - Training Epoch: 2/2, step 3166/7134 completed (loss: 0.4112676680088043, acc: 0.8987341523170471)
[2024-12-17 02:40:21,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:21,752][root][INFO] - Training Epoch: 2/2, step 3167/7134 completed (loss: 0.41783297061920166, acc: 0.9197530746459961)
[2024-12-17 02:40:21,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:22,033][root][INFO] - Training Epoch: 2/2, step 3168/7134 completed (loss: 0.3409881293773651, acc: 0.9346405267715454)
[2024-12-17 02:40:22,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:22,311][root][INFO] - Training Epoch: 2/2, step 3169/7134 completed (loss: 0.45481857657432556, acc: 0.8852459192276001)
[2024-12-17 02:40:22,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:22,582][root][INFO] - Training Epoch: 2/2, step 3170/7134 completed (loss: 0.3569607734680176, acc: 0.8897058963775635)
[2024-12-17 02:40:22,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:22,857][root][INFO] - Training Epoch: 2/2, step 3171/7134 completed (loss: 0.21874581277370453, acc: 0.9450549483299255)
[2024-12-17 02:40:22,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:23,110][root][INFO] - Training Epoch: 2/2, step 3172/7134 completed (loss: 0.09884212166070938, acc: 0.9841269850730896)
[2024-12-17 02:40:23,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:23,369][root][INFO] - Training Epoch: 2/2, step 3173/7134 completed (loss: 0.2531428337097168, acc: 0.9292929172515869)
[2024-12-17 02:40:23,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:23,652][root][INFO] - Training Epoch: 2/2, step 3174/7134 completed (loss: 0.2920299768447876, acc: 0.9156626462936401)
[2024-12-17 02:40:23,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:23,962][root][INFO] - Training Epoch: 2/2, step 3175/7134 completed (loss: 0.1800287961959839, acc: 0.9534883499145508)
[2024-12-17 02:40:24,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:24,237][root][INFO] - Training Epoch: 2/2, step 3176/7134 completed (loss: 0.5182938575744629, acc: 0.8779069781303406)
[2024-12-17 02:40:24,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:24,506][root][INFO] - Training Epoch: 2/2, step 3177/7134 completed (loss: 0.5210335850715637, acc: 0.9135802388191223)
[2024-12-17 02:40:24,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:24,764][root][INFO] - Training Epoch: 2/2, step 3178/7134 completed (loss: 0.3212931454181671, acc: 0.9333333373069763)
[2024-12-17 02:40:24,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:25,059][root][INFO] - Training Epoch: 2/2, step 3179/7134 completed (loss: 0.49172359704971313, acc: 0.9166666865348816)
[2024-12-17 02:40:25,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:25,321][root][INFO] - Training Epoch: 2/2, step 3180/7134 completed (loss: 0.18926826119422913, acc: 0.9567901492118835)
[2024-12-17 02:40:25,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:25,606][root][INFO] - Training Epoch: 2/2, step 3181/7134 completed (loss: 0.43247997760772705, acc: 0.8950276374816895)
[2024-12-17 02:40:25,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:25,897][root][INFO] - Training Epoch: 2/2, step 3182/7134 completed (loss: 0.2226950079202652, acc: 0.9451219439506531)
[2024-12-17 02:40:26,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:26,163][root][INFO] - Training Epoch: 2/2, step 3183/7134 completed (loss: 0.32762229442596436, acc: 0.9343065619468689)
[2024-12-17 02:40:26,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:26,444][root][INFO] - Training Epoch: 2/2, step 3184/7134 completed (loss: 0.285711407661438, acc: 0.9437500238418579)
[2024-12-17 02:40:26,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:26,716][root][INFO] - Training Epoch: 2/2, step 3185/7134 completed (loss: 0.0728401467204094, acc: 0.9937106966972351)
[2024-12-17 02:40:26,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:26,993][root][INFO] - Training Epoch: 2/2, step 3186/7134 completed (loss: 0.1993182897567749, acc: 0.9551281929016113)
[2024-12-17 02:40:27,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:27,253][root][INFO] - Training Epoch: 2/2, step 3187/7134 completed (loss: 0.22980667650699615, acc: 0.9357143044471741)
[2024-12-17 02:40:27,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:27,523][root][INFO] - Training Epoch: 2/2, step 3188/7134 completed (loss: 0.19243818521499634, acc: 0.9497206807136536)
[2024-12-17 02:40:27,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:27,794][root][INFO] - Training Epoch: 2/2, step 3189/7134 completed (loss: 0.1567307710647583, acc: 0.9567901492118835)
[2024-12-17 02:40:27,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:28,077][root][INFO] - Training Epoch: 2/2, step 3190/7134 completed (loss: 0.1805032640695572, acc: 0.949999988079071)
[2024-12-17 02:40:28,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:28,343][root][INFO] - Training Epoch: 2/2, step 3191/7134 completed (loss: 0.10466049611568451, acc: 0.9875776171684265)
[2024-12-17 02:40:28,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:28,618][root][INFO] - Training Epoch: 2/2, step 3192/7134 completed (loss: 0.5334236025810242, acc: 0.8978102207183838)
[2024-12-17 02:40:28,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:28,911][root][INFO] - Training Epoch: 2/2, step 3193/7134 completed (loss: 0.3774047791957855, acc: 0.929729700088501)
[2024-12-17 02:40:29,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:29,198][root][INFO] - Training Epoch: 2/2, step 3194/7134 completed (loss: 0.1851787269115448, acc: 0.9333333373069763)
[2024-12-17 02:40:29,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:29,470][root][INFO] - Training Epoch: 2/2, step 3195/7134 completed (loss: 0.4525274336338043, acc: 0.8944099545478821)
[2024-12-17 02:40:29,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:29,737][root][INFO] - Training Epoch: 2/2, step 3196/7134 completed (loss: 0.2698099911212921, acc: 0.9637681245803833)
[2024-12-17 02:40:29,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:29,984][root][INFO] - Training Epoch: 2/2, step 3197/7134 completed (loss: 0.17166295647621155, acc: 0.9520958065986633)
[2024-12-17 02:40:30,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:30,262][root][INFO] - Training Epoch: 2/2, step 3198/7134 completed (loss: 0.2482972890138626, acc: 0.9312499761581421)
[2024-12-17 02:40:30,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:30,519][root][INFO] - Training Epoch: 2/2, step 3199/7134 completed (loss: 0.14362077414989471, acc: 0.9593023061752319)
[2024-12-17 02:40:30,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:30,780][root][INFO] - Training Epoch: 2/2, step 3200/7134 completed (loss: 0.1847486048936844, acc: 0.9716312289237976)
[2024-12-17 02:40:30,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:31,073][root][INFO] - Training Epoch: 2/2, step 3201/7134 completed (loss: 0.3621973693370819, acc: 0.9212598204612732)
[2024-12-17 02:40:31,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:31,353][root][INFO] - Training Epoch: 2/2, step 3202/7134 completed (loss: 0.15466050803661346, acc: 0.9606741666793823)
[2024-12-17 02:40:31,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:31,611][root][INFO] - Training Epoch: 2/2, step 3203/7134 completed (loss: 0.2075578272342682, acc: 0.9125000238418579)
[2024-12-17 02:40:31,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:31,867][root][INFO] - Training Epoch: 2/2, step 3204/7134 completed (loss: 0.16760048270225525, acc: 0.9589040875434875)
[2024-12-17 02:40:31,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:32,144][root][INFO] - Training Epoch: 2/2, step 3205/7134 completed (loss: 0.1578996628522873, acc: 0.9432623982429504)
[2024-12-17 02:40:32,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:32,433][root][INFO] - Training Epoch: 2/2, step 3206/7134 completed (loss: 0.1631496101617813, acc: 0.9333333373069763)
[2024-12-17 02:40:32,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:32,700][root][INFO] - Training Epoch: 2/2, step 3207/7134 completed (loss: 0.2509257197380066, acc: 0.9386503100395203)
[2024-12-17 02:40:32,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:32,989][root][INFO] - Training Epoch: 2/2, step 3208/7134 completed (loss: 0.15715335309505463, acc: 0.9568345546722412)
[2024-12-17 02:40:33,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:33,264][root][INFO] - Training Epoch: 2/2, step 3209/7134 completed (loss: 0.15349699556827545, acc: 0.956250011920929)
[2024-12-17 02:40:33,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:33,545][root][INFO] - Training Epoch: 2/2, step 3210/7134 completed (loss: 0.13543689250946045, acc: 0.9612902998924255)
[2024-12-17 02:40:33,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:33,804][root][INFO] - Training Epoch: 2/2, step 3211/7134 completed (loss: 0.18929390609264374, acc: 0.9579831957817078)
[2024-12-17 02:40:33,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:34,083][root][INFO] - Training Epoch: 2/2, step 3212/7134 completed (loss: 0.1776750534772873, acc: 0.9590643048286438)
[2024-12-17 02:40:34,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:34,369][root][INFO] - Training Epoch: 2/2, step 3213/7134 completed (loss: 0.19925855100154877, acc: 0.9404761791229248)
[2024-12-17 02:40:34,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:34,659][root][INFO] - Training Epoch: 2/2, step 3214/7134 completed (loss: 0.12133017182350159, acc: 0.9590643048286438)
[2024-12-17 02:40:34,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:34,945][root][INFO] - Training Epoch: 2/2, step 3215/7134 completed (loss: 0.1551700234413147, acc: 0.9585798978805542)
[2024-12-17 02:40:35,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:35,237][root][INFO] - Training Epoch: 2/2, step 3216/7134 completed (loss: 0.14807142317295074, acc: 0.9691358208656311)
[2024-12-17 02:40:35,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:35,530][root][INFO] - Training Epoch: 2/2, step 3217/7134 completed (loss: 0.11118646711111069, acc: 0.966292142868042)
[2024-12-17 02:40:35,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:35,803][root][INFO] - Training Epoch: 2/2, step 3218/7134 completed (loss: 0.1428869366645813, acc: 0.9548386931419373)
[2024-12-17 02:40:35,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:36,073][root][INFO] - Training Epoch: 2/2, step 3219/7134 completed (loss: 0.2026517540216446, acc: 0.9345238208770752)
[2024-12-17 02:40:36,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:36,346][root][INFO] - Training Epoch: 2/2, step 3220/7134 completed (loss: 0.18522003293037415, acc: 0.9378530979156494)
[2024-12-17 02:40:36,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:36,630][root][INFO] - Training Epoch: 2/2, step 3221/7134 completed (loss: 0.1406480073928833, acc: 0.9677419066429138)
[2024-12-17 02:40:36,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:36,902][root][INFO] - Training Epoch: 2/2, step 3222/7134 completed (loss: 0.33916157484054565, acc: 0.9154228568077087)
[2024-12-17 02:40:37,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:37,179][root][INFO] - Training Epoch: 2/2, step 3223/7134 completed (loss: 0.2929348051548004, acc: 0.9386503100395203)
[2024-12-17 02:40:37,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:37,462][root][INFO] - Training Epoch: 2/2, step 3224/7134 completed (loss: 0.4081231355667114, acc: 0.913294792175293)
[2024-12-17 02:40:37,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:37,747][root][INFO] - Training Epoch: 2/2, step 3225/7134 completed (loss: 0.16513492166996002, acc: 0.949999988079071)
[2024-12-17 02:40:37,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:38,013][root][INFO] - Training Epoch: 2/2, step 3226/7134 completed (loss: 0.3176400661468506, acc: 0.8940397500991821)
[2024-12-17 02:40:38,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:38,326][root][INFO] - Training Epoch: 2/2, step 3227/7134 completed (loss: 0.3225458264350891, acc: 0.9300411343574524)
[2024-12-17 02:40:38,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:38,619][root][INFO] - Training Epoch: 2/2, step 3228/7134 completed (loss: 0.2333066463470459, acc: 0.9343434572219849)
[2024-12-17 02:40:38,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:38,894][root][INFO] - Training Epoch: 2/2, step 3229/7134 completed (loss: 0.24866057932376862, acc: 0.9343434572219849)
[2024-12-17 02:40:38,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:39,162][root][INFO] - Training Epoch: 2/2, step 3230/7134 completed (loss: 0.26103100180625916, acc: 0.9437500238418579)
[2024-12-17 02:40:39,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:39,462][root][INFO] - Training Epoch: 2/2, step 3231/7134 completed (loss: 0.355657696723938, acc: 0.9175823926925659)
[2024-12-17 02:40:39,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:39,737][root][INFO] - Training Epoch: 2/2, step 3232/7134 completed (loss: 0.08852890133857727, acc: 0.9768518805503845)
[2024-12-17 02:40:39,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:40,010][root][INFO] - Training Epoch: 2/2, step 3233/7134 completed (loss: 0.24660219252109528, acc: 0.9527559280395508)
[2024-12-17 02:40:40,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:40,278][root][INFO] - Training Epoch: 2/2, step 3234/7134 completed (loss: 0.15237446129322052, acc: 0.9685534834861755)
[2024-12-17 02:40:40,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:40,562][root][INFO] - Training Epoch: 2/2, step 3235/7134 completed (loss: 0.2723521292209625, acc: 0.9219858050346375)
[2024-12-17 02:40:40,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:40,846][root][INFO] - Training Epoch: 2/2, step 3236/7134 completed (loss: 0.3173657953739166, acc: 0.909604549407959)
[2024-12-17 02:40:40,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:41,128][root][INFO] - Training Epoch: 2/2, step 3237/7134 completed (loss: 0.14926627278327942, acc: 0.9610389471054077)
[2024-12-17 02:40:41,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:41,410][root][INFO] - Training Epoch: 2/2, step 3238/7134 completed (loss: 0.22778044641017914, acc: 0.9333333373069763)
[2024-12-17 02:40:41,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:41,689][root][INFO] - Training Epoch: 2/2, step 3239/7134 completed (loss: 0.12342365831136703, acc: 0.957317054271698)
[2024-12-17 02:40:41,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:41,959][root][INFO] - Training Epoch: 2/2, step 3240/7134 completed (loss: 0.07673981785774231, acc: 0.9776536226272583)
[2024-12-17 02:40:42,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:42,236][root][INFO] - Training Epoch: 2/2, step 3241/7134 completed (loss: 0.0761050134897232, acc: 0.9764705896377563)
[2024-12-17 02:40:42,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:42,503][root][INFO] - Training Epoch: 2/2, step 3242/7134 completed (loss: 0.05998264625668526, acc: 0.9870129823684692)
[2024-12-17 02:40:42,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:42,793][root][INFO] - Training Epoch: 2/2, step 3243/7134 completed (loss: 0.10036167502403259, acc: 0.9732620120048523)
[2024-12-17 02:40:42,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:43,064][root][INFO] - Training Epoch: 2/2, step 3244/7134 completed (loss: 0.19538310170173645, acc: 0.9595375657081604)
[2024-12-17 02:40:43,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:43,349][root][INFO] - Training Epoch: 2/2, step 3245/7134 completed (loss: 0.1581985205411911, acc: 0.9743589758872986)
[2024-12-17 02:40:43,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:43,627][root][INFO] - Training Epoch: 2/2, step 3246/7134 completed (loss: 0.1767912209033966, acc: 0.9589743614196777)
[2024-12-17 02:40:43,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:43,908][root][INFO] - Training Epoch: 2/2, step 3247/7134 completed (loss: 0.15532813966274261, acc: 0.9551281929016113)
[2024-12-17 02:40:44,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:44,182][root][INFO] - Training Epoch: 2/2, step 3248/7134 completed (loss: 0.0934596061706543, acc: 0.9635036587715149)
[2024-12-17 02:40:44,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:44,458][root][INFO] - Training Epoch: 2/2, step 3249/7134 completed (loss: 0.07829153537750244, acc: 0.976331353187561)
[2024-12-17 02:40:44,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:44,751][root][INFO] - Training Epoch: 2/2, step 3250/7134 completed (loss: 0.19520273804664612, acc: 0.9341317415237427)
[2024-12-17 02:40:44,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:45,026][root][INFO] - Training Epoch: 2/2, step 3251/7134 completed (loss: 0.1621582806110382, acc: 0.9551281929016113)
[2024-12-17 02:40:45,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:45,340][root][INFO] - Training Epoch: 2/2, step 3252/7134 completed (loss: 0.03904080390930176, acc: 1.0)
[2024-12-17 02:40:45,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:45,633][root][INFO] - Training Epoch: 2/2, step 3253/7134 completed (loss: 0.1265854686498642, acc: 0.9605262875556946)
[2024-12-17 02:40:45,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:45,925][root][INFO] - Training Epoch: 2/2, step 3254/7134 completed (loss: 0.11278298497200012, acc: 0.9610389471054077)
[2024-12-17 02:40:46,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:46,203][root][INFO] - Training Epoch: 2/2, step 3255/7134 completed (loss: 0.16116349399089813, acc: 0.9659090638160706)
[2024-12-17 02:40:46,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:46,486][root][INFO] - Training Epoch: 2/2, step 3256/7134 completed (loss: 0.1294121891260147, acc: 0.9751552939414978)
[2024-12-17 02:40:46,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:46,763][root][INFO] - Training Epoch: 2/2, step 3257/7134 completed (loss: 0.3152942359447479, acc: 0.9333333373069763)
[2024-12-17 02:40:46,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:47,051][root][INFO] - Training Epoch: 2/2, step 3258/7134 completed (loss: 0.5180016756057739, acc: 0.8780487775802612)
[2024-12-17 02:40:47,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:47,349][root][INFO] - Training Epoch: 2/2, step 3259/7134 completed (loss: 0.20157618820667267, acc: 0.9503105878829956)
[2024-12-17 02:40:47,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:47,609][root][INFO] - Training Epoch: 2/2, step 3260/7134 completed (loss: 0.4144062399864197, acc: 0.931034505367279)
[2024-12-17 02:40:47,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:47,895][root][INFO] - Training Epoch: 2/2, step 3261/7134 completed (loss: 0.2760777771472931, acc: 0.9270073175430298)
[2024-12-17 02:40:48,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:48,198][root][INFO] - Training Epoch: 2/2, step 3262/7134 completed (loss: 0.2280438095331192, acc: 0.9382715821266174)
[2024-12-17 02:40:48,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:48,478][root][INFO] - Training Epoch: 2/2, step 3263/7134 completed (loss: 0.3429693281650543, acc: 0.9053254723548889)
[2024-12-17 02:40:48,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:48,737][root][INFO] - Training Epoch: 2/2, step 3264/7134 completed (loss: 0.2778659164905548, acc: 0.9207317233085632)
[2024-12-17 02:40:48,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:49,024][root][INFO] - Training Epoch: 2/2, step 3265/7134 completed (loss: 0.25723734498023987, acc: 0.9554139971733093)
[2024-12-17 02:40:49,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:49,306][root][INFO] - Training Epoch: 2/2, step 3266/7134 completed (loss: 0.18181158602237701, acc: 0.9586206674575806)
[2024-12-17 02:40:49,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:49,592][root][INFO] - Training Epoch: 2/2, step 3267/7134 completed (loss: 0.22282834351062775, acc: 0.9333333373069763)
[2024-12-17 02:40:49,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:49,858][root][INFO] - Training Epoch: 2/2, step 3268/7134 completed (loss: 0.21196210384368896, acc: 0.9452054500579834)
[2024-12-17 02:40:49,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:50,138][root][INFO] - Training Epoch: 2/2, step 3269/7134 completed (loss: 0.15053531527519226, acc: 0.9680851101875305)
[2024-12-17 02:40:50,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:50,421][root][INFO] - Training Epoch: 2/2, step 3270/7134 completed (loss: 0.10827759653329849, acc: 0.9621621370315552)
[2024-12-17 02:40:50,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:50,689][root][INFO] - Training Epoch: 2/2, step 3271/7134 completed (loss: 0.13643284142017365, acc: 0.98591548204422)
[2024-12-17 02:40:50,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:50,965][root][INFO] - Training Epoch: 2/2, step 3272/7134 completed (loss: 0.17939607799053192, acc: 0.95333331823349)
[2024-12-17 02:40:51,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:51,241][root][INFO] - Training Epoch: 2/2, step 3273/7134 completed (loss: 0.10890551656484604, acc: 0.954285740852356)
[2024-12-17 02:40:51,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:51,525][root][INFO] - Training Epoch: 2/2, step 3274/7134 completed (loss: 0.17285344004631042, acc: 0.9440993666648865)
[2024-12-17 02:40:51,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:51,818][root][INFO] - Training Epoch: 2/2, step 3275/7134 completed (loss: 0.5946702361106873, acc: 0.886227548122406)
[2024-12-17 02:40:51,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:52,094][root][INFO] - Training Epoch: 2/2, step 3276/7134 completed (loss: 0.15319404006004333, acc: 0.9673202633857727)
[2024-12-17 02:40:52,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:52,378][root][INFO] - Training Epoch: 2/2, step 3277/7134 completed (loss: 0.30441394448280334, acc: 0.9424460530281067)
[2024-12-17 02:40:52,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:52,654][root][INFO] - Training Epoch: 2/2, step 3278/7134 completed (loss: 0.25900524854660034, acc: 0.9354838728904724)
[2024-12-17 02:40:52,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:52,939][root][INFO] - Training Epoch: 2/2, step 3279/7134 completed (loss: 0.32759779691696167, acc: 0.9117646813392639)
[2024-12-17 02:40:53,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:53,210][root][INFO] - Training Epoch: 2/2, step 3280/7134 completed (loss: 0.48879989981651306, acc: 0.8653846383094788)
[2024-12-17 02:40:53,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:53,494][root][INFO] - Training Epoch: 2/2, step 3281/7134 completed (loss: 0.29061880707740784, acc: 0.9319728016853333)
[2024-12-17 02:40:53,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:53,783][root][INFO] - Training Epoch: 2/2, step 3282/7134 completed (loss: 0.15101659297943115, acc: 0.9618320465087891)
[2024-12-17 02:40:53,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:54,085][root][INFO] - Training Epoch: 2/2, step 3283/7134 completed (loss: 0.1591954529285431, acc: 0.9509803652763367)
[2024-12-17 02:40:54,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:54,367][root][INFO] - Training Epoch: 2/2, step 3284/7134 completed (loss: 0.22802391648292542, acc: 0.9586206674575806)
[2024-12-17 02:40:54,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:54,636][root][INFO] - Training Epoch: 2/2, step 3285/7134 completed (loss: 0.31757625937461853, acc: 0.9191176295280457)
[2024-12-17 02:40:54,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:54,910][root][INFO] - Training Epoch: 2/2, step 3286/7134 completed (loss: 0.2334052473306656, acc: 0.9692307710647583)
[2024-12-17 02:40:55,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:55,176][root][INFO] - Training Epoch: 2/2, step 3287/7134 completed (loss: 0.24336743354797363, acc: 0.9333333373069763)
[2024-12-17 02:40:55,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:55,459][root][INFO] - Training Epoch: 2/2, step 3288/7134 completed (loss: 0.24160997569561005, acc: 0.9640287756919861)
[2024-12-17 02:40:55,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:55,712][root][INFO] - Training Epoch: 2/2, step 3289/7134 completed (loss: 0.30448731780052185, acc: 0.9411764740943909)
[2024-12-17 02:40:55,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:55,979][root][INFO] - Training Epoch: 2/2, step 3290/7134 completed (loss: 0.2868174612522125, acc: 0.9327731132507324)
[2024-12-17 02:40:56,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:56,249][root][INFO] - Training Epoch: 2/2, step 3291/7134 completed (loss: 0.24665458500385284, acc: 0.9504950642585754)
[2024-12-17 02:40:56,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:56,518][root][INFO] - Training Epoch: 2/2, step 3292/7134 completed (loss: 0.22484466433525085, acc: 0.9495798349380493)
[2024-12-17 02:40:56,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:56,820][root][INFO] - Training Epoch: 2/2, step 3293/7134 completed (loss: 0.2113167643547058, acc: 0.939393937587738)
[2024-12-17 02:40:56,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:57,097][root][INFO] - Training Epoch: 2/2, step 3294/7134 completed (loss: 0.34477803111076355, acc: 0.9166666865348816)
[2024-12-17 02:40:57,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:57,346][root][INFO] - Training Epoch: 2/2, step 3295/7134 completed (loss: 0.05488358438014984, acc: 1.0)
[2024-12-17 02:40:57,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:57,611][root][INFO] - Training Epoch: 2/2, step 3296/7134 completed (loss: 0.2237839549779892, acc: 0.9230769276618958)
[2024-12-17 02:40:57,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:57,867][root][INFO] - Training Epoch: 2/2, step 3297/7134 completed (loss: 0.2768975496292114, acc: 0.9339622855186462)
[2024-12-17 02:40:57,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:58,125][root][INFO] - Training Epoch: 2/2, step 3298/7134 completed (loss: 0.3372251093387604, acc: 0.9473684430122375)
[2024-12-17 02:40:58,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:58,385][root][INFO] - Training Epoch: 2/2, step 3299/7134 completed (loss: 0.12395589798688889, acc: 0.9685039520263672)
[2024-12-17 02:40:58,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:58,642][root][INFO] - Training Epoch: 2/2, step 3300/7134 completed (loss: 0.2282024323940277, acc: 0.9473684430122375)
[2024-12-17 02:40:58,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:58,890][root][INFO] - Training Epoch: 2/2, step 3301/7134 completed (loss: 0.234170600771904, acc: 0.9417475461959839)
[2024-12-17 02:40:59,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:59,156][root][INFO] - Training Epoch: 2/2, step 3302/7134 completed (loss: 0.30985355377197266, acc: 0.9370629191398621)
[2024-12-17 02:40:59,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:59,417][root][INFO] - Training Epoch: 2/2, step 3303/7134 completed (loss: 0.35142815113067627, acc: 0.9306930899620056)
[2024-12-17 02:40:59,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:59,697][root][INFO] - Training Epoch: 2/2, step 3304/7134 completed (loss: 0.11307265609502792, acc: 0.9587156176567078)
[2024-12-17 02:40:59,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:59,998][root][INFO] - Training Epoch: 2/2, step 3305/7134 completed (loss: 0.22206084430217743, acc: 0.9433962106704712)
[2024-12-17 02:41:00,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:00,293][root][INFO] - Training Epoch: 2/2, step 3306/7134 completed (loss: 0.15694130957126617, acc: 0.954023003578186)
[2024-12-17 02:41:00,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:00,560][root][INFO] - Training Epoch: 2/2, step 3307/7134 completed (loss: 0.17745140194892883, acc: 0.9333333373069763)
[2024-12-17 02:41:00,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:00,842][root][INFO] - Training Epoch: 2/2, step 3308/7134 completed (loss: 0.2772361934185028, acc: 0.9352940917015076)
[2024-12-17 02:41:00,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:01,099][root][INFO] - Training Epoch: 2/2, step 3309/7134 completed (loss: 0.2722786068916321, acc: 0.942307710647583)
[2024-12-17 02:41:01,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:01,392][root][INFO] - Training Epoch: 2/2, step 3310/7134 completed (loss: 0.17862850427627563, acc: 0.9454545378684998)
[2024-12-17 02:41:01,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:01,658][root][INFO] - Training Epoch: 2/2, step 3311/7134 completed (loss: 0.2967038154602051, acc: 0.9207921028137207)
[2024-12-17 02:41:01,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:01,952][root][INFO] - Training Epoch: 2/2, step 3312/7134 completed (loss: 0.3629876673221588, acc: 0.9398496150970459)
[2024-12-17 02:41:02,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:02,235][root][INFO] - Training Epoch: 2/2, step 3313/7134 completed (loss: 0.3051927983760834, acc: 0.9387755393981934)
[2024-12-17 02:41:02,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:02,512][root][INFO] - Training Epoch: 2/2, step 3314/7134 completed (loss: 0.1694163680076599, acc: 0.9816513657569885)
[2024-12-17 02:41:02,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:02,804][root][INFO] - Training Epoch: 2/2, step 3315/7134 completed (loss: 0.20817705988883972, acc: 0.9585798978805542)
[2024-12-17 02:41:02,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:03,091][root][INFO] - Training Epoch: 2/2, step 3316/7134 completed (loss: 0.27864739298820496, acc: 0.9253731369972229)
[2024-12-17 02:41:03,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:03,377][root][INFO] - Training Epoch: 2/2, step 3317/7134 completed (loss: 0.39747899770736694, acc: 0.9008264541625977)
[2024-12-17 02:41:03,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:03,565][root][INFO] - Training Epoch: 2/2, step 3318/7134 completed (loss: 0.33284977078437805, acc: 0.8983050584793091)
[2024-12-17 02:41:03,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:03,847][root][INFO] - Training Epoch: 2/2, step 3319/7134 completed (loss: 0.24517673254013062, acc: 0.9347826242446899)
[2024-12-17 02:41:03,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:04,135][root][INFO] - Training Epoch: 2/2, step 3320/7134 completed (loss: 0.3056413531303406, acc: 0.9322034120559692)
[2024-12-17 02:41:04,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:04,412][root][INFO] - Training Epoch: 2/2, step 3321/7134 completed (loss: 0.3903086483478546, acc: 0.8999999761581421)
[2024-12-17 02:41:04,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:04,701][root][INFO] - Training Epoch: 2/2, step 3322/7134 completed (loss: 0.24471168220043182, acc: 0.9210526347160339)
[2024-12-17 02:41:04,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:04,979][root][INFO] - Training Epoch: 2/2, step 3323/7134 completed (loss: 0.2714044451713562, acc: 0.9064327478408813)
[2024-12-17 02:41:05,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:05,273][root][INFO] - Training Epoch: 2/2, step 3324/7134 completed (loss: 0.391531765460968, acc: 0.8808290362358093)
[2024-12-17 02:41:05,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:05,559][root][INFO] - Training Epoch: 2/2, step 3325/7134 completed (loss: 0.2601966857910156, acc: 0.9520958065986633)
[2024-12-17 02:41:05,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:05,844][root][INFO] - Training Epoch: 2/2, step 3326/7134 completed (loss: 0.2912999987602234, acc: 0.9333333373069763)
[2024-12-17 02:41:05,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:06,113][root][INFO] - Training Epoch: 2/2, step 3327/7134 completed (loss: 0.20072129368782043, acc: 0.950276255607605)
[2024-12-17 02:41:06,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:06,405][root][INFO] - Training Epoch: 2/2, step 3328/7134 completed (loss: 0.16666758060455322, acc: 0.9627659320831299)
[2024-12-17 02:41:06,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:06,695][root][INFO] - Training Epoch: 2/2, step 3329/7134 completed (loss: 0.24467284977436066, acc: 0.9427083134651184)
[2024-12-17 02:41:06,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:06,995][root][INFO] - Training Epoch: 2/2, step 3330/7134 completed (loss: 0.2189897745847702, acc: 0.9538461565971375)
[2024-12-17 02:41:07,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:07,289][root][INFO] - Training Epoch: 2/2, step 3331/7134 completed (loss: 0.5217602849006653, acc: 0.88165682554245)
[2024-12-17 02:41:07,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:07,617][root][INFO] - Training Epoch: 2/2, step 3332/7134 completed (loss: 0.381553590297699, acc: 0.9333333373069763)
[2024-12-17 02:41:07,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:07,891][root][INFO] - Training Epoch: 2/2, step 3333/7134 completed (loss: 0.384684681892395, acc: 0.904347836971283)
[2024-12-17 02:41:08,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:08,168][root][INFO] - Training Epoch: 2/2, step 3334/7134 completed (loss: 0.33557775616645813, acc: 0.91847825050354)
[2024-12-17 02:41:08,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:08,453][root][INFO] - Training Epoch: 2/2, step 3335/7134 completed (loss: 0.1515689492225647, acc: 0.9399999976158142)
[2024-12-17 02:41:08,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:08,732][root][INFO] - Training Epoch: 2/2, step 3336/7134 completed (loss: 0.1179393008351326, acc: 0.9640718698501587)
[2024-12-17 02:41:08,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:09,012][root][INFO] - Training Epoch: 2/2, step 3337/7134 completed (loss: 0.08332344889640808, acc: 0.9747899174690247)
[2024-12-17 02:41:09,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:09,319][root][INFO] - Training Epoch: 2/2, step 3338/7134 completed (loss: 0.10592924058437347, acc: 0.9740932583808899)
[2024-12-17 02:41:09,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:09,610][root][INFO] - Training Epoch: 2/2, step 3339/7134 completed (loss: 0.3049435019493103, acc: 0.9178743958473206)
[2024-12-17 02:41:09,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:09,888][root][INFO] - Training Epoch: 2/2, step 3340/7134 completed (loss: 0.31881585717201233, acc: 0.9404761791229248)
[2024-12-17 02:41:10,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:10,170][root][INFO] - Training Epoch: 2/2, step 3341/7134 completed (loss: 0.255155473947525, acc: 0.946107804775238)
[2024-12-17 02:41:10,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:10,458][root][INFO] - Training Epoch: 2/2, step 3342/7134 completed (loss: 0.2299519181251526, acc: 0.9520547986030579)
[2024-12-17 02:41:10,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:10,770][root][INFO] - Training Epoch: 2/2, step 3343/7134 completed (loss: 0.15076372027397156, acc: 0.9655172228813171)
[2024-12-17 02:41:10,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:11,049][root][INFO] - Training Epoch: 2/2, step 3344/7134 completed (loss: 0.18730099499225616, acc: 0.9485294222831726)
[2024-12-17 02:41:11,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:11,332][root][INFO] - Training Epoch: 2/2, step 3345/7134 completed (loss: 0.236442431807518, acc: 0.9370629191398621)
[2024-12-17 02:41:11,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:11,618][root][INFO] - Training Epoch: 2/2, step 3346/7134 completed (loss: 0.16574423015117645, acc: 0.957317054271698)
[2024-12-17 02:41:11,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:11,888][root][INFO] - Training Epoch: 2/2, step 3347/7134 completed (loss: 0.33797121047973633, acc: 0.9281045794487)
[2024-12-17 02:41:12,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:12,157][root][INFO] - Training Epoch: 2/2, step 3348/7134 completed (loss: 0.16914090514183044, acc: 0.9683544039726257)
[2024-12-17 02:41:12,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:12,414][root][INFO] - Training Epoch: 2/2, step 3349/7134 completed (loss: 0.19769026339054108, acc: 0.961240291595459)
[2024-12-17 02:41:12,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:12,687][root][INFO] - Training Epoch: 2/2, step 3350/7134 completed (loss: 0.20130136609077454, acc: 0.9586777091026306)
[2024-12-17 02:41:12,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:12,960][root][INFO] - Training Epoch: 2/2, step 3351/7134 completed (loss: 0.38944950699806213, acc: 0.8936170339584351)
[2024-12-17 02:41:13,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:13,227][root][INFO] - Training Epoch: 2/2, step 3352/7134 completed (loss: 0.18074530363082886, acc: 0.9481481313705444)
[2024-12-17 02:41:13,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:13,500][root][INFO] - Training Epoch: 2/2, step 3353/7134 completed (loss: 0.21747133135795593, acc: 0.9430894255638123)
[2024-12-17 02:41:13,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:13,774][root][INFO] - Training Epoch: 2/2, step 3354/7134 completed (loss: 0.12155327945947647, acc: 0.9683544039726257)
[2024-12-17 02:41:13,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:14,060][root][INFO] - Training Epoch: 2/2, step 3355/7134 completed (loss: 0.07554417103528976, acc: 0.9817073345184326)
[2024-12-17 02:41:14,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:14,342][root][INFO] - Training Epoch: 2/2, step 3356/7134 completed (loss: 0.04170025885105133, acc: 1.0)
[2024-12-17 02:41:14,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:14,624][root][INFO] - Training Epoch: 2/2, step 3357/7134 completed (loss: 0.10076945275068283, acc: 0.9820359349250793)
[2024-12-17 02:41:14,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:14,900][root][INFO] - Training Epoch: 2/2, step 3358/7134 completed (loss: 0.4461507499217987, acc: 0.8970588445663452)
[2024-12-17 02:41:15,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:15,177][root][INFO] - Training Epoch: 2/2, step 3359/7134 completed (loss: 0.1871660202741623, acc: 0.965753436088562)
[2024-12-17 02:41:15,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:15,467][root][INFO] - Training Epoch: 2/2, step 3360/7134 completed (loss: 0.37673866748809814, acc: 0.9304347634315491)
[2024-12-17 02:41:15,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:15,770][root][INFO] - Training Epoch: 2/2, step 3361/7134 completed (loss: 0.35832080245018005, acc: 0.9107142686843872)
[2024-12-17 02:41:15,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:16,046][root][INFO] - Training Epoch: 2/2, step 3362/7134 completed (loss: 0.44122114777565, acc: 0.918181836605072)
[2024-12-17 02:41:16,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:16,316][root][INFO] - Training Epoch: 2/2, step 3363/7134 completed (loss: 0.27130061388015747, acc: 0.9158878326416016)
[2024-12-17 02:41:16,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:16,599][root][INFO] - Training Epoch: 2/2, step 3364/7134 completed (loss: 0.3417659401893616, acc: 0.8888888955116272)
[2024-12-17 02:41:16,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:16,877][root][INFO] - Training Epoch: 2/2, step 3365/7134 completed (loss: 0.24472936987876892, acc: 0.9469026327133179)
[2024-12-17 02:41:16,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:17,153][root][INFO] - Training Epoch: 2/2, step 3366/7134 completed (loss: 0.13372951745986938, acc: 0.9629629850387573)
[2024-12-17 02:41:17,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:17,421][root][INFO] - Training Epoch: 2/2, step 3367/7134 completed (loss: 0.28721609711647034, acc: 0.9304812550544739)
[2024-12-17 02:41:17,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:17,702][root][INFO] - Training Epoch: 2/2, step 3368/7134 completed (loss: 0.2576603889465332, acc: 0.9192546606063843)
[2024-12-17 02:41:17,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:17,991][root][INFO] - Training Epoch: 2/2, step 3369/7134 completed (loss: 0.2634279727935791, acc: 0.9243243336677551)
[2024-12-17 02:41:18,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:18,265][root][INFO] - Training Epoch: 2/2, step 3370/7134 completed (loss: 0.19533929228782654, acc: 0.9509202241897583)
[2024-12-17 02:41:18,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:18,533][root][INFO] - Training Epoch: 2/2, step 3371/7134 completed (loss: 0.18716171383857727, acc: 0.9583333134651184)
[2024-12-17 02:41:18,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:18,812][root][INFO] - Training Epoch: 2/2, step 3372/7134 completed (loss: 0.18803398311138153, acc: 0.9659863710403442)
[2024-12-17 02:41:18,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:19,084][root][INFO] - Training Epoch: 2/2, step 3373/7134 completed (loss: 0.0986710861325264, acc: 0.9869281053543091)
[2024-12-17 02:41:19,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:19,377][root][INFO] - Training Epoch: 2/2, step 3374/7134 completed (loss: 0.1276860237121582, acc: 0.9657142758369446)
[2024-12-17 02:41:19,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:19,660][root][INFO] - Training Epoch: 2/2, step 3375/7134 completed (loss: 0.1381978988647461, acc: 0.970059871673584)
[2024-12-17 02:41:19,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:19,936][root][INFO] - Training Epoch: 2/2, step 3376/7134 completed (loss: 0.0386437363922596, acc: 0.9947090148925781)
[2024-12-17 02:41:20,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:20,235][root][INFO] - Training Epoch: 2/2, step 3377/7134 completed (loss: 0.1035003662109375, acc: 0.9748743772506714)
[2024-12-17 02:41:20,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:20,513][root][INFO] - Training Epoch: 2/2, step 3378/7134 completed (loss: 0.05695447325706482, acc: 0.9868420958518982)
[2024-12-17 02:41:20,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:20,786][root][INFO] - Training Epoch: 2/2, step 3379/7134 completed (loss: 0.1582622081041336, acc: 0.9594594836235046)
[2024-12-17 02:41:20,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:21,051][root][INFO] - Training Epoch: 2/2, step 3380/7134 completed (loss: 0.18484185636043549, acc: 0.95652174949646)
[2024-12-17 02:41:21,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:21,334][root][INFO] - Training Epoch: 2/2, step 3381/7134 completed (loss: 0.1576019823551178, acc: 0.9634146094322205)
[2024-12-17 02:41:21,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:21,619][root][INFO] - Training Epoch: 2/2, step 3382/7134 completed (loss: 0.11205562949180603, acc: 0.953125)
[2024-12-17 02:41:21,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:21,916][root][INFO] - Training Epoch: 2/2, step 3383/7134 completed (loss: 0.15673789381980896, acc: 0.9650349617004395)
[2024-12-17 02:41:22,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:22,195][root][INFO] - Training Epoch: 2/2, step 3384/7134 completed (loss: 0.25570592284202576, acc: 0.9489051103591919)
[2024-12-17 02:41:22,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:22,500][root][INFO] - Training Epoch: 2/2, step 3385/7134 completed (loss: 0.12181156128644943, acc: 0.9583333134651184)
[2024-12-17 02:41:22,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:22,783][root][INFO] - Training Epoch: 2/2, step 3386/7134 completed (loss: 0.08636815845966339, acc: 0.9822485446929932)
[2024-12-17 02:41:22,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:23,079][root][INFO] - Training Epoch: 2/2, step 3387/7134 completed (loss: 0.1982923150062561, acc: 0.9360465407371521)
[2024-12-17 02:41:23,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:23,358][root][INFO] - Training Epoch: 2/2, step 3388/7134 completed (loss: 0.12427640706300735, acc: 0.9572649598121643)
[2024-12-17 02:41:23,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:23,636][root][INFO] - Training Epoch: 2/2, step 3389/7134 completed (loss: 0.166676327586174, acc: 0.9562841653823853)
[2024-12-17 02:41:23,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:23,914][root][INFO] - Training Epoch: 2/2, step 3390/7134 completed (loss: 0.11864111572504044, acc: 0.9715909361839294)
[2024-12-17 02:41:24,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:24,170][root][INFO] - Training Epoch: 2/2, step 3391/7134 completed (loss: 0.09282980114221573, acc: 0.9817073345184326)
[2024-12-17 02:41:24,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:24,439][root][INFO] - Training Epoch: 2/2, step 3392/7134 completed (loss: 0.14854304492473602, acc: 0.9694656729698181)
[2024-12-17 02:41:24,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:24,703][root][INFO] - Training Epoch: 2/2, step 3393/7134 completed (loss: 0.22311590611934662, acc: 0.9370629191398621)
[2024-12-17 02:41:24,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:24,985][root][INFO] - Training Epoch: 2/2, step 3394/7134 completed (loss: 0.14602577686309814, acc: 0.9571428298950195)
[2024-12-17 02:41:25,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:25,241][root][INFO] - Training Epoch: 2/2, step 3395/7134 completed (loss: 0.2875728905200958, acc: 0.9276315569877625)
[2024-12-17 02:41:25,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:25,515][root][INFO] - Training Epoch: 2/2, step 3396/7134 completed (loss: 0.2103528082370758, acc: 0.9615384340286255)
[2024-12-17 02:41:25,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:25,805][root][INFO] - Training Epoch: 2/2, step 3397/7134 completed (loss: 0.0955442562699318, acc: 0.96517413854599)
[2024-12-17 02:41:25,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:26,092][root][INFO] - Training Epoch: 2/2, step 3398/7134 completed (loss: 0.21161462366580963, acc: 0.9420289993286133)
[2024-12-17 02:41:26,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:26,371][root][INFO] - Training Epoch: 2/2, step 3399/7134 completed (loss: 0.4468629062175751, acc: 0.9166666865348816)
[2024-12-17 02:41:26,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:26,653][root][INFO] - Training Epoch: 2/2, step 3400/7134 completed (loss: 0.25962963700294495, acc: 0.913385808467865)
[2024-12-17 02:41:26,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:26,934][root][INFO] - Training Epoch: 2/2, step 3401/7134 completed (loss: 0.17749106884002686, acc: 0.9591836929321289)
[2024-12-17 02:41:27,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:27,236][root][INFO] - Training Epoch: 2/2, step 3402/7134 completed (loss: 0.5228776931762695, acc: 0.8983957171440125)
[2024-12-17 02:41:27,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:27,532][root][INFO] - Training Epoch: 2/2, step 3403/7134 completed (loss: 0.41991135478019714, acc: 0.9090909361839294)
[2024-12-17 02:41:27,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:27,805][root][INFO] - Training Epoch: 2/2, step 3404/7134 completed (loss: 0.11675809323787689, acc: 0.9748427867889404)
[2024-12-17 02:41:27,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:28,087][root][INFO] - Training Epoch: 2/2, step 3405/7134 completed (loss: 0.3689267635345459, acc: 0.9191176295280457)
[2024-12-17 02:41:28,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:28,377][root][INFO] - Training Epoch: 2/2, step 3406/7134 completed (loss: 0.29062092304229736, acc: 0.9049999713897705)
[2024-12-17 02:41:28,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:28,641][root][INFO] - Training Epoch: 2/2, step 3407/7134 completed (loss: 0.18199563026428223, acc: 0.9386503100395203)
[2024-12-17 02:41:28,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:28,906][root][INFO] - Training Epoch: 2/2, step 3408/7134 completed (loss: 0.1769629567861557, acc: 0.9528301954269409)
[2024-12-17 02:41:29,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:29,197][root][INFO] - Training Epoch: 2/2, step 3409/7134 completed (loss: 0.19709904491901398, acc: 0.954023003578186)
[2024-12-17 02:41:29,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:29,470][root][INFO] - Training Epoch: 2/2, step 3410/7134 completed (loss: 0.23638547956943512, acc: 0.9634146094322205)
[2024-12-17 02:41:29,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:29,754][root][INFO] - Training Epoch: 2/2, step 3411/7134 completed (loss: 0.22302240133285522, acc: 0.9450549483299255)
[2024-12-17 02:41:29,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:30,019][root][INFO] - Training Epoch: 2/2, step 3412/7134 completed (loss: 0.3599834740161896, acc: 0.9083333611488342)
[2024-12-17 02:41:30,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:30,295][root][INFO] - Training Epoch: 2/2, step 3413/7134 completed (loss: 0.234434112906456, acc: 0.9572649598121643)
[2024-12-17 02:41:30,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:30,572][root][INFO] - Training Epoch: 2/2, step 3414/7134 completed (loss: 0.1675918698310852, acc: 0.9444444179534912)
[2024-12-17 02:41:30,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:30,862][root][INFO] - Training Epoch: 2/2, step 3415/7134 completed (loss: 0.18728166818618774, acc: 0.9571428298950195)
[2024-12-17 02:41:30,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:31,156][root][INFO] - Training Epoch: 2/2, step 3416/7134 completed (loss: 0.2125685214996338, acc: 0.9617486596107483)
[2024-12-17 02:41:31,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:31,433][root][INFO] - Training Epoch: 2/2, step 3417/7134 completed (loss: 0.09872957319021225, acc: 0.9880239367485046)
[2024-12-17 02:41:31,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:31,709][root][INFO] - Training Epoch: 2/2, step 3418/7134 completed (loss: 0.17083099484443665, acc: 0.9570552110671997)
[2024-12-17 02:41:31,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:31,979][root][INFO] - Training Epoch: 2/2, step 3419/7134 completed (loss: 0.15411294996738434, acc: 0.9578313231468201)
[2024-12-17 02:41:32,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:32,260][root][INFO] - Training Epoch: 2/2, step 3420/7134 completed (loss: 0.06772847473621368, acc: 0.9867549538612366)
[2024-12-17 02:41:32,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:32,550][root][INFO] - Training Epoch: 2/2, step 3421/7134 completed (loss: 0.16658125817775726, acc: 0.9679487347602844)
[2024-12-17 02:41:32,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:32,818][root][INFO] - Training Epoch: 2/2, step 3422/7134 completed (loss: 0.08892856538295746, acc: 0.9632353186607361)
[2024-12-17 02:41:32,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:33,101][root][INFO] - Training Epoch: 2/2, step 3423/7134 completed (loss: 0.05798334255814552, acc: 0.9802631735801697)
[2024-12-17 02:41:33,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:33,375][root][INFO] - Training Epoch: 2/2, step 3424/7134 completed (loss: 0.25531336665153503, acc: 0.9466666579246521)
[2024-12-17 02:41:33,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:33,652][root][INFO] - Training Epoch: 2/2, step 3425/7134 completed (loss: 0.30845117568969727, acc: 0.9368420839309692)
[2024-12-17 02:41:33,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:33,929][root][INFO] - Training Epoch: 2/2, step 3426/7134 completed (loss: 0.266953706741333, acc: 0.9702380895614624)
[2024-12-17 02:41:34,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:34,176][root][INFO] - Training Epoch: 2/2, step 3427/7134 completed (loss: 0.15741798281669617, acc: 0.9675324559211731)
[2024-12-17 02:41:34,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:34,456][root][INFO] - Training Epoch: 2/2, step 3428/7134 completed (loss: 0.09690633416175842, acc: 0.9764705896377563)
[2024-12-17 02:41:34,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:34,750][root][INFO] - Training Epoch: 2/2, step 3429/7134 completed (loss: 0.19447939097881317, acc: 0.9577465057373047)
[2024-12-17 02:41:34,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:35,029][root][INFO] - Training Epoch: 2/2, step 3430/7134 completed (loss: 0.2885795831680298, acc: 0.9452054500579834)
[2024-12-17 02:41:35,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:35,312][root][INFO] - Training Epoch: 2/2, step 3431/7134 completed (loss: 0.1617674082517624, acc: 0.9637681245803833)
[2024-12-17 02:41:35,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:35,631][root][INFO] - Training Epoch: 2/2, step 3432/7134 completed (loss: 0.17937003076076508, acc: 0.9631901979446411)
[2024-12-17 02:41:35,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:35,952][root][INFO] - Training Epoch: 2/2, step 3433/7134 completed (loss: 0.3379085958003998, acc: 0.9264705777168274)
[2024-12-17 02:41:36,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:36,265][root][INFO] - Training Epoch: 2/2, step 3434/7134 completed (loss: 0.29538899660110474, acc: 0.9357143044471741)
[2024-12-17 02:41:36,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:36,578][root][INFO] - Training Epoch: 2/2, step 3435/7134 completed (loss: 0.1856650412082672, acc: 0.9448275566101074)
[2024-12-17 02:41:36,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:36,865][root][INFO] - Training Epoch: 2/2, step 3436/7134 completed (loss: 0.2256566286087036, acc: 0.9343065619468689)
[2024-12-17 02:41:36,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:37,132][root][INFO] - Training Epoch: 2/2, step 3437/7134 completed (loss: 0.27512457966804504, acc: 0.93388432264328)
[2024-12-17 02:41:37,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:37,416][root][INFO] - Training Epoch: 2/2, step 3438/7134 completed (loss: 0.2688196003437042, acc: 0.9561403393745422)
[2024-12-17 02:41:37,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:37,674][root][INFO] - Training Epoch: 2/2, step 3439/7134 completed (loss: 0.3642807602882385, acc: 0.9126983880996704)
[2024-12-17 02:41:37,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:37,954][root][INFO] - Training Epoch: 2/2, step 3440/7134 completed (loss: 0.3732551634311676, acc: 0.8879310488700867)
[2024-12-17 02:41:38,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:38,257][root][INFO] - Training Epoch: 2/2, step 3441/7134 completed (loss: 0.3034135103225708, acc: 0.930232584476471)
[2024-12-17 02:41:38,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:38,543][root][INFO] - Training Epoch: 2/2, step 3442/7134 completed (loss: 0.144810289144516, acc: 0.9645389914512634)
[2024-12-17 02:41:38,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:38,811][root][INFO] - Training Epoch: 2/2, step 3443/7134 completed (loss: 0.3207179307937622, acc: 0.9438202381134033)
[2024-12-17 02:41:38,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:39,083][root][INFO] - Training Epoch: 2/2, step 3444/7134 completed (loss: 0.25755542516708374, acc: 0.9171974658966064)
[2024-12-17 02:41:39,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:39,340][root][INFO] - Training Epoch: 2/2, step 3445/7134 completed (loss: 0.4624652862548828, acc: 0.8872180581092834)
[2024-12-17 02:41:39,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:39,628][root][INFO] - Training Epoch: 2/2, step 3446/7134 completed (loss: 0.4032687246799469, acc: 0.8999999761581421)
[2024-12-17 02:41:39,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:39,928][root][INFO] - Training Epoch: 2/2, step 3447/7134 completed (loss: 0.4259141981601715, acc: 0.9074074029922485)
[2024-12-17 02:41:40,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:40,213][root][INFO] - Training Epoch: 2/2, step 3448/7134 completed (loss: 0.23388321697711945, acc: 0.9248554706573486)
[2024-12-17 02:41:40,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:40,485][root][INFO] - Training Epoch: 2/2, step 3449/7134 completed (loss: 0.1558903455734253, acc: 0.9702970385551453)
[2024-12-17 02:41:40,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:40,786][root][INFO] - Training Epoch: 2/2, step 3450/7134 completed (loss: 0.22863559424877167, acc: 0.9411764740943909)
[2024-12-17 02:41:40,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:41,068][root][INFO] - Training Epoch: 2/2, step 3451/7134 completed (loss: 0.3590957820415497, acc: 0.8936170339584351)
[2024-12-17 02:41:41,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:41,347][root][INFO] - Training Epoch: 2/2, step 3452/7134 completed (loss: 0.4719838500022888, acc: 0.8943089246749878)
[2024-12-17 02:41:41,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:41,605][root][INFO] - Training Epoch: 2/2, step 3453/7134 completed (loss: 0.23984044790267944, acc: 0.9375)
[2024-12-17 02:41:41,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:41,899][root][INFO] - Training Epoch: 2/2, step 3454/7134 completed (loss: 0.16834843158721924, acc: 0.9518072009086609)
[2024-12-17 02:41:42,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:42,180][root][INFO] - Training Epoch: 2/2, step 3455/7134 completed (loss: 0.12416115403175354, acc: 0.9751552939414978)
[2024-12-17 02:41:42,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:42,464][root][INFO] - Training Epoch: 2/2, step 3456/7134 completed (loss: 0.0777667760848999, acc: 0.979899525642395)
[2024-12-17 02:41:42,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:42,742][root][INFO] - Training Epoch: 2/2, step 3457/7134 completed (loss: 0.11699385195970535, acc: 0.9788732528686523)
[2024-12-17 02:41:42,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:43,037][root][INFO] - Training Epoch: 2/2, step 3458/7134 completed (loss: 0.2976517975330353, acc: 0.9340659379959106)
[2024-12-17 02:41:43,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:43,310][root][INFO] - Training Epoch: 2/2, step 3459/7134 completed (loss: 0.2702210545539856, acc: 0.9119496941566467)
[2024-12-17 02:41:43,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:43,574][root][INFO] - Training Epoch: 2/2, step 3460/7134 completed (loss: 0.8683990836143494, acc: 0.8282828330993652)
[2024-12-17 02:41:43,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:43,835][root][INFO] - Training Epoch: 2/2, step 3461/7134 completed (loss: 0.8643711805343628, acc: 0.800000011920929)
[2024-12-17 02:41:43,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:44,107][root][INFO] - Training Epoch: 2/2, step 3462/7134 completed (loss: 0.37130826711654663, acc: 0.9181286692619324)
[2024-12-17 02:41:44,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:44,397][root][INFO] - Training Epoch: 2/2, step 3463/7134 completed (loss: 0.11566870659589767, acc: 0.9691358208656311)
[2024-12-17 02:41:44,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:44,690][root][INFO] - Training Epoch: 2/2, step 3464/7134 completed (loss: 0.15243510901927948, acc: 0.966292142868042)
[2024-12-17 02:41:44,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:44,949][root][INFO] - Training Epoch: 2/2, step 3465/7134 completed (loss: 0.3245807886123657, acc: 0.9259259104728699)
[2024-12-17 02:41:45,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:45,222][root][INFO] - Training Epoch: 2/2, step 3466/7134 completed (loss: 0.17531688511371613, acc: 0.9382715821266174)
[2024-12-17 02:41:45,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:45,502][root][INFO] - Training Epoch: 2/2, step 3467/7134 completed (loss: 0.12256330996751785, acc: 0.9661017060279846)
[2024-12-17 02:41:45,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:45,777][root][INFO] - Training Epoch: 2/2, step 3468/7134 completed (loss: 0.04718366637825966, acc: 0.9934210777282715)
[2024-12-17 02:41:45,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:46,058][root][INFO] - Training Epoch: 2/2, step 3469/7134 completed (loss: 0.22261545062065125, acc: 0.932330846786499)
[2024-12-17 02:41:46,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:46,321][root][INFO] - Training Epoch: 2/2, step 3470/7134 completed (loss: 0.07973804324865341, acc: 0.9722222089767456)
[2024-12-17 02:41:46,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:46,583][root][INFO] - Training Epoch: 2/2, step 3471/7134 completed (loss: 0.18451756238937378, acc: 0.9666666388511658)
[2024-12-17 02:41:46,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:46,867][root][INFO] - Training Epoch: 2/2, step 3472/7134 completed (loss: 0.053321223706007004, acc: 0.987261176109314)
[2024-12-17 02:41:47,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:47,201][root][INFO] - Training Epoch: 2/2, step 3473/7134 completed (loss: 0.11028800159692764, acc: 0.9736841917037964)
[2024-12-17 02:41:47,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:47,459][root][INFO] - Training Epoch: 2/2, step 3474/7134 completed (loss: 0.18881741166114807, acc: 0.95652174949646)
[2024-12-17 02:41:47,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:47,723][root][INFO] - Training Epoch: 2/2, step 3475/7134 completed (loss: 0.09750980138778687, acc: 0.9772727489471436)
[2024-12-17 02:41:47,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:48,005][root][INFO] - Training Epoch: 2/2, step 3476/7134 completed (loss: 0.29841363430023193, acc: 0.931506872177124)
[2024-12-17 02:41:48,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:48,284][root][INFO] - Training Epoch: 2/2, step 3477/7134 completed (loss: 0.15957872569561005, acc: 0.9729729890823364)
[2024-12-17 02:41:48,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:48,557][root][INFO] - Training Epoch: 2/2, step 3478/7134 completed (loss: 0.0624714195728302, acc: 0.9880239367485046)
[2024-12-17 02:41:48,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:48,837][root][INFO] - Training Epoch: 2/2, step 3479/7134 completed (loss: 0.02795184962451458, acc: 1.0)
[2024-12-17 02:41:48,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:49,120][root][INFO] - Training Epoch: 2/2, step 3480/7134 completed (loss: 0.24510475993156433, acc: 0.9450549483299255)
[2024-12-17 02:41:49,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:49,392][root][INFO] - Training Epoch: 2/2, step 3481/7134 completed (loss: 0.0927380844950676, acc: 0.969924807548523)
[2024-12-17 02:41:49,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:49,655][root][INFO] - Training Epoch: 2/2, step 3482/7134 completed (loss: 0.020076934248209, acc: 0.9921875)
[2024-12-17 02:41:49,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:49,939][root][INFO] - Training Epoch: 2/2, step 3483/7134 completed (loss: 0.04621751233935356, acc: 1.0)
[2024-12-17 02:41:50,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:50,211][root][INFO] - Training Epoch: 2/2, step 3484/7134 completed (loss: 0.13626791536808014, acc: 0.976190447807312)
[2024-12-17 02:41:50,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:50,479][root][INFO] - Training Epoch: 2/2, step 3485/7134 completed (loss: 0.17673949897289276, acc: 0.9636363387107849)
[2024-12-17 02:41:50,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:50,754][root][INFO] - Training Epoch: 2/2, step 3486/7134 completed (loss: 0.3230662941932678, acc: 0.9316239356994629)
[2024-12-17 02:41:50,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:51,031][root][INFO] - Training Epoch: 2/2, step 3487/7134 completed (loss: 0.21175672113895416, acc: 0.9578313231468201)
[2024-12-17 02:41:51,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:51,310][root][INFO] - Training Epoch: 2/2, step 3488/7134 completed (loss: 0.21966154873371124, acc: 0.949999988079071)
[2024-12-17 02:41:51,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:51,568][root][INFO] - Training Epoch: 2/2, step 3489/7134 completed (loss: 0.21948009729385376, acc: 0.9259259104728699)
[2024-12-17 02:41:51,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:51,860][root][INFO] - Training Epoch: 2/2, step 3490/7134 completed (loss: 0.17808881402015686, acc: 0.9720279574394226)
[2024-12-17 02:41:51,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:52,131][root][INFO] - Training Epoch: 2/2, step 3491/7134 completed (loss: 0.21804575622081757, acc: 0.9363057613372803)
[2024-12-17 02:41:52,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:52,386][root][INFO] - Training Epoch: 2/2, step 3492/7134 completed (loss: 0.20307108759880066, acc: 0.9724770784378052)
[2024-12-17 02:41:52,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:52,676][root][INFO] - Training Epoch: 2/2, step 3493/7134 completed (loss: 0.12307427078485489, acc: 0.9691358208656311)
[2024-12-17 02:41:52,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:52,936][root][INFO] - Training Epoch: 2/2, step 3494/7134 completed (loss: 0.14351578056812286, acc: 0.9459459185600281)
[2024-12-17 02:41:53,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:53,207][root][INFO] - Training Epoch: 2/2, step 3495/7134 completed (loss: 0.09721832722425461, acc: 0.9793814420700073)
[2024-12-17 02:41:53,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:53,465][root][INFO] - Training Epoch: 2/2, step 3496/7134 completed (loss: 0.14420631527900696, acc: 0.9803921580314636)
[2024-12-17 02:41:53,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:53,730][root][INFO] - Training Epoch: 2/2, step 3497/7134 completed (loss: 0.17648616433143616, acc: 0.9620253443717957)
[2024-12-17 02:41:53,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:54,007][root][INFO] - Training Epoch: 2/2, step 3498/7134 completed (loss: 0.2389226257801056, acc: 0.9303797483444214)
[2024-12-17 02:41:54,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:54,292][root][INFO] - Training Epoch: 2/2, step 3499/7134 completed (loss: 0.13995060324668884, acc: 0.9542483687400818)
[2024-12-17 02:41:54,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:54,565][root][INFO] - Training Epoch: 2/2, step 3500/7134 completed (loss: 0.23698537051677704, acc: 0.9415204524993896)
[2024-12-17 02:41:54,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:54,838][root][INFO] - Training Epoch: 2/2, step 3501/7134 completed (loss: 0.23543083667755127, acc: 0.939393937587738)
[2024-12-17 02:41:54,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:55,110][root][INFO] - Training Epoch: 2/2, step 3502/7134 completed (loss: 0.4443908929824829, acc: 0.8986486196517944)
[2024-12-17 02:41:55,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:55,390][root][INFO] - Training Epoch: 2/2, step 3503/7134 completed (loss: 0.37505051493644714, acc: 0.8992805480957031)
[2024-12-17 02:41:55,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:55,668][root][INFO] - Training Epoch: 2/2, step 3504/7134 completed (loss: 0.03866022452712059, acc: 0.9866666793823242)
[2024-12-17 02:41:55,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:55,941][root][INFO] - Training Epoch: 2/2, step 3505/7134 completed (loss: 0.16295091807842255, acc: 0.9523809552192688)
[2024-12-17 02:41:56,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:56,186][root][INFO] - Training Epoch: 2/2, step 3506/7134 completed (loss: 0.15127979218959808, acc: 0.961240291595459)
[2024-12-17 02:41:56,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:56,469][root][INFO] - Training Epoch: 2/2, step 3507/7134 completed (loss: 0.08818352967500687, acc: 0.9791666865348816)
[2024-12-17 02:41:56,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:56,746][root][INFO] - Training Epoch: 2/2, step 3508/7134 completed (loss: 0.14285393059253693, acc: 0.9602649211883545)
[2024-12-17 02:41:56,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:57,030][root][INFO] - Training Epoch: 2/2, step 3509/7134 completed (loss: 0.22182925045490265, acc: 0.9570552110671997)
[2024-12-17 02:41:57,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:57,276][root][INFO] - Training Epoch: 2/2, step 3510/7134 completed (loss: 0.11614225804805756, acc: 0.969924807548523)
[2024-12-17 02:41:57,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:57,550][root][INFO] - Training Epoch: 2/2, step 3511/7134 completed (loss: 0.04819026589393616, acc: 0.9779411554336548)
[2024-12-17 02:41:57,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:57,826][root][INFO] - Training Epoch: 2/2, step 3512/7134 completed (loss: 0.23078590631484985, acc: 0.9487179517745972)
[2024-12-17 02:41:57,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:58,107][root][INFO] - Training Epoch: 2/2, step 3513/7134 completed (loss: 0.1136539950966835, acc: 0.9637681245803833)
[2024-12-17 02:41:58,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:58,386][root][INFO] - Training Epoch: 2/2, step 3514/7134 completed (loss: 0.07117892801761627, acc: 0.9760765433311462)
[2024-12-17 02:41:58,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:58,653][root][INFO] - Training Epoch: 2/2, step 3515/7134 completed (loss: 0.04412740096449852, acc: 0.994350254535675)
[2024-12-17 02:41:58,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:58,965][root][INFO] - Training Epoch: 2/2, step 3516/7134 completed (loss: 0.02994263730943203, acc: 0.9956140518188477)
[2024-12-17 02:41:59,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:59,247][root][INFO] - Training Epoch: 2/2, step 3517/7134 completed (loss: 0.1110614463686943, acc: 0.9646464586257935)
[2024-12-17 02:41:59,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:59,528][root][INFO] - Training Epoch: 2/2, step 3518/7134 completed (loss: 0.19310708343982697, acc: 0.9407407641410828)
[2024-12-17 02:41:59,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:59,808][root][INFO] - Training Epoch: 2/2, step 3519/7134 completed (loss: 0.10069431364536285, acc: 0.9733333587646484)
[2024-12-17 02:41:59,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:00,089][root][INFO] - Training Epoch: 2/2, step 3520/7134 completed (loss: 0.17630799114704132, acc: 0.9747474789619446)
[2024-12-17 02:42:00,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:00,366][root][INFO] - Training Epoch: 2/2, step 3521/7134 completed (loss: 0.07649078220129013, acc: 0.976047933101654)
[2024-12-17 02:42:00,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:00,620][root][INFO] - Training Epoch: 2/2, step 3522/7134 completed (loss: 0.030766984447836876, acc: 1.0)
[2024-12-17 02:42:00,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:00,914][root][INFO] - Training Epoch: 2/2, step 3523/7134 completed (loss: 0.019214121624827385, acc: 1.0)
[2024-12-17 02:42:01,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:01,194][root][INFO] - Training Epoch: 2/2, step 3524/7134 completed (loss: 0.0993306115269661, acc: 0.9725274443626404)
[2024-12-17 02:42:01,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:01,471][root][INFO] - Training Epoch: 2/2, step 3525/7134 completed (loss: 0.07731480896472931, acc: 0.9797297120094299)
[2024-12-17 02:42:01,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:01,749][root][INFO] - Training Epoch: 2/2, step 3526/7134 completed (loss: 0.14168104529380798, acc: 0.9595959782600403)
[2024-12-17 02:42:01,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:02,067][root][INFO] - Training Epoch: 2/2, step 3527/7134 completed (loss: 0.13358324766159058, acc: 0.9680851101875305)
[2024-12-17 02:42:02,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:02,344][root][INFO] - Training Epoch: 2/2, step 3528/7134 completed (loss: 0.03205417841672897, acc: 0.9903846383094788)
[2024-12-17 02:42:02,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:02,610][root][INFO] - Training Epoch: 2/2, step 3529/7134 completed (loss: 0.08296313136816025, acc: 0.9818181991577148)
[2024-12-17 02:42:02,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:02,909][root][INFO] - Training Epoch: 2/2, step 3530/7134 completed (loss: 0.20214492082595825, acc: 0.9292035102844238)
[2024-12-17 02:42:03,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:03,183][root][INFO] - Training Epoch: 2/2, step 3531/7134 completed (loss: 0.13632605969905853, acc: 0.949999988079071)
[2024-12-17 02:42:03,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:03,459][root][INFO] - Training Epoch: 2/2, step 3532/7134 completed (loss: 0.11787792295217514, acc: 0.9594594836235046)
[2024-12-17 02:42:03,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:03,735][root][INFO] - Training Epoch: 2/2, step 3533/7134 completed (loss: 0.1647648960351944, acc: 0.9466666579246521)
[2024-12-17 02:42:03,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:04,020][root][INFO] - Training Epoch: 2/2, step 3534/7134 completed (loss: 0.11113002896308899, acc: 0.9824561476707458)
[2024-12-17 02:42:04,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:04,299][root][INFO] - Training Epoch: 2/2, step 3535/7134 completed (loss: 0.09063564985990524, acc: 0.9856114983558655)
[2024-12-17 02:42:04,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:04,580][root][INFO] - Training Epoch: 2/2, step 3536/7134 completed (loss: 0.1172553077340126, acc: 0.9691358208656311)
[2024-12-17 02:42:04,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:04,837][root][INFO] - Training Epoch: 2/2, step 3537/7134 completed (loss: 0.20677539706230164, acc: 0.9453125)
[2024-12-17 02:42:04,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:05,098][root][INFO] - Training Epoch: 2/2, step 3538/7134 completed (loss: 0.0951700210571289, acc: 0.9663865566253662)
[2024-12-17 02:42:05,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:05,319][root][INFO] - Training Epoch: 2/2, step 3539/7134 completed (loss: 0.19780001044273376, acc: 0.9425287246704102)
[2024-12-17 02:42:05,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:05,571][root][INFO] - Training Epoch: 2/2, step 3540/7134 completed (loss: 0.17370252311229706, acc: 0.9461538195610046)
[2024-12-17 02:42:05,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:05,847][root][INFO] - Training Epoch: 2/2, step 3541/7134 completed (loss: 0.15681643784046173, acc: 0.9599999785423279)
[2024-12-17 02:42:05,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:06,120][root][INFO] - Training Epoch: 2/2, step 3542/7134 completed (loss: 0.05905799940228462, acc: 1.0)
[2024-12-17 02:42:06,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:06,376][root][INFO] - Training Epoch: 2/2, step 3543/7134 completed (loss: 0.19369356334209442, acc: 0.9295774698257446)
[2024-12-17 02:42:06,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:06,661][root][INFO] - Training Epoch: 2/2, step 3544/7134 completed (loss: 0.26602262258529663, acc: 0.9337748289108276)
[2024-12-17 02:42:06,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:06,953][root][INFO] - Training Epoch: 2/2, step 3545/7134 completed (loss: 0.09634692966938019, acc: 0.9722222089767456)
[2024-12-17 02:42:07,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:07,233][root][INFO] - Training Epoch: 2/2, step 3546/7134 completed (loss: 0.23671194911003113, acc: 0.935251772403717)
[2024-12-17 02:42:07,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:07,522][root][INFO] - Training Epoch: 2/2, step 3547/7134 completed (loss: 0.2988782823085785, acc: 0.9322034120559692)
[2024-12-17 02:42:07,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:07,804][root][INFO] - Training Epoch: 2/2, step 3548/7134 completed (loss: 0.1984609067440033, acc: 0.9357798099517822)
[2024-12-17 02:42:07,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:08,076][root][INFO] - Training Epoch: 2/2, step 3549/7134 completed (loss: 0.1913316547870636, acc: 0.969924807548523)
[2024-12-17 02:42:08,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:08,348][root][INFO] - Training Epoch: 2/2, step 3550/7134 completed (loss: 0.16399547457695007, acc: 0.956204354763031)
[2024-12-17 02:42:08,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:08,627][root][INFO] - Training Epoch: 2/2, step 3551/7134 completed (loss: 0.3715565502643585, acc: 0.8707482814788818)
[2024-12-17 02:42:08,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:08,916][root][INFO] - Training Epoch: 2/2, step 3552/7134 completed (loss: 0.2998565435409546, acc: 0.9291338324546814)
[2024-12-17 02:42:09,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:09,184][root][INFO] - Training Epoch: 2/2, step 3553/7134 completed (loss: 0.17329129576683044, acc: 0.9558823704719543)
[2024-12-17 02:42:09,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:09,469][root][INFO] - Training Epoch: 2/2, step 3554/7134 completed (loss: 0.3431781232357025, acc: 0.907975435256958)
[2024-12-17 02:42:09,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:09,743][root][INFO] - Training Epoch: 2/2, step 3555/7134 completed (loss: 0.46142563223838806, acc: 0.896774172782898)
[2024-12-17 02:42:09,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:09,991][root][INFO] - Training Epoch: 2/2, step 3556/7134 completed (loss: 0.27729493379592896, acc: 0.9242424368858337)
[2024-12-17 02:42:10,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:10,282][root][INFO] - Training Epoch: 2/2, step 3557/7134 completed (loss: 0.32662537693977356, acc: 0.9290780425071716)
[2024-12-17 02:42:10,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:10,562][root][INFO] - Training Epoch: 2/2, step 3558/7134 completed (loss: 0.3738047480583191, acc: 0.9120000004768372)
[2024-12-17 02:42:10,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:10,832][root][INFO] - Training Epoch: 2/2, step 3559/7134 completed (loss: 0.30209881067276, acc: 0.9166666865348816)
[2024-12-17 02:42:10,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:11,100][root][INFO] - Training Epoch: 2/2, step 3560/7134 completed (loss: 0.18433715403079987, acc: 0.9617486596107483)
[2024-12-17 02:42:11,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:11,383][root][INFO] - Training Epoch: 2/2, step 3561/7134 completed (loss: 0.1814996749162674, acc: 0.9491525292396545)
[2024-12-17 02:42:11,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:11,652][root][INFO] - Training Epoch: 2/2, step 3562/7134 completed (loss: 0.1392482966184616, acc: 0.9558823704719543)
[2024-12-17 02:42:11,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:11,912][root][INFO] - Training Epoch: 2/2, step 3563/7134 completed (loss: 0.16235601902008057, acc: 0.9503546357154846)
[2024-12-17 02:42:12,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:12,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:13,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:13,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:13,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:13,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:14,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:14,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:14,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:14,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:15,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:15,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:15,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:16,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:16,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:16,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:16,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:16,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:17,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:17,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:17,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:17,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:18,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:18,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:18,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:19,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:19,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:19,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:19,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:20,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:20,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:20,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:21,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:21,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:21,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:22,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:22,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:22,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:22,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:23,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:23,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:23,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:23,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:24,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:24,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:24,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:25,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:25,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:25,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:26,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:26,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:26,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:26,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:27,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:27,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:27,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:28,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:28,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:28,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:29,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:29,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:29,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:29,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:30,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:30,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:30,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:30,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:31,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:31,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:31,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:31,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:32,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:32,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:32,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:32,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:33,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:33,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:33,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:34,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:34,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:34,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:34,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:35,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:35,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:35,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:36,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:36,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:37,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:37,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:37,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:38,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:38,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:38,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:39,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:39,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:39,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:40,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:40,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:40,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:40,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:41,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:41,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:41,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:42,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:42,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:42,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:42,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:43,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:43,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:43,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:44,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:44,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:44,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:44,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:45,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:45,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:45,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:45,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:46,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:46,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:46,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:47,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:47,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:47,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:47,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:48,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:48,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:48,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:48,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:49,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:49,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:49,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:50,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:50,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:50,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:50,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:51,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:51,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:51,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:52,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:52,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:52,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:52,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:53,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:53,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:53,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:54,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:54,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:54,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:54,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:55,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:55,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:55,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:55,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:56,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:56,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:56,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:56,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:57,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:57,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:57,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:57,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:58,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:58,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:58,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:58,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:59,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:59,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:59,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:00,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:00,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:00,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:00,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:01,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:01,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:01,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:02,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:02,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:02,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:03,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:03,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:03,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:03,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:03,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:04,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:04,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:04,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:04,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:05,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:05,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:05,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:06,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:06,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:06,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:07,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:07,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:07,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:07,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:08,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:08,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:08,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:08,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:09,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:09,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:09,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:10,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:10,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:10,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:10,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:11,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:11,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:11,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:12,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:12,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:12,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:12,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:13,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:13,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:13,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:14,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:14,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:14,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:14,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:15,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:15,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:15,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:15,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:16,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:16,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:16,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:17,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:17,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:17,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:17,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:18,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:18,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:18,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:18,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:19,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:19,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:19,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:20,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:20,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:20,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:20,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:21,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:21,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:21,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:22,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:22,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:22,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:23,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:23,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:23,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:24,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:24,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:24,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:24,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:25,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:25,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:25,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:26,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:26,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:26,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:27,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:27,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:27,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:27,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:28,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:28,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:28,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:29,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:29,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:30,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:30,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:30,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:30,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:31,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:31,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:31,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:32,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:32,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:32,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:33,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:33,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:33,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:34,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:34,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:34,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:35,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:35,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:35,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:36,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:36,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:36,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:37,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:37,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:37,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:38,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:38,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:38,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:38,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:38,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:39,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:39,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:39,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:40,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:40,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:40,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:40,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:41,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:41,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:41,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:41,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:42,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:42,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:42,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:43,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:43,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:43,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:44,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:44,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:44,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:44,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:45,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:45,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:45,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:46,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:46,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:46,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:47,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:47,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:47,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:48,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:48,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:48,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:48,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:49,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:49,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:49,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:50,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:50,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:50,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:51,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:51,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:51,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:52,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:52,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:52,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:53,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:53,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:53,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:53,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:54,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:54,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:54,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:54,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:55,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:55,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:55,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:56,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:56,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:57,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:57,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:58,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:58,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:58,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:59,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:59,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:59,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:00,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:00,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:00,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:00,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:01,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:01,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:01,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:02,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:02,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:02,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:02,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:03,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:03,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:03,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:04,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:04,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:04,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:04,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:05,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:05,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:05,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:05,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:06,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:06,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:06,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:06,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:07,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:07,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:07,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:07,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:08,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:08,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:08,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:09,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:09,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:09,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:09,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:10,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:10,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:10,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:10,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:11,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:11,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:11,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:12,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:12,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:12,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:12,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:12,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:13,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:13,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:13,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:14,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:14,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:14,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:15,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:15,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:15,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:15,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:16,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:16,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:16,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:17,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:17,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:17,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:17,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:18,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:18,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:18,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:19,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:19,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:19,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:20,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:20,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:20,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:20,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:21,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:21,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:21,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:22,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:22,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:22,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:22,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:23,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:23,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:23,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:23,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:24,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:24,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:24,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:24,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:25,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:25,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:25,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:26,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:26,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:26,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:26,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:27,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:27,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:27,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:28,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:28,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:28,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:29,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:29,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:29,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:29,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:30,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:30,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:30,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:31,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:31,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:31,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:31,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:32,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:32,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:32,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:33,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:33,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:33,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:34,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:34,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:34,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:34,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:35,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:35,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:35,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:36,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:36,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:36,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:36,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:37,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:37,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:37,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:38,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:38,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:38,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:38,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:39,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:39,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:39,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:39,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:40,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:40,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:40,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:40,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:41,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:41,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:41,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:42,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:42,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:42,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:43,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:43,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:43,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:43,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:43,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:44,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:44,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:44,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:45,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:45,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:45,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:45,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:46,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:46,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:47,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:47,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:47,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:48,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:48,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:48,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:49,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:49,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:49,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:49,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:50,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:50,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:50,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:51,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:51,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:51,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:52,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:52,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:52,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:52,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:53,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:53,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:53,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:54,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:54,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:54,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:55,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:55,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:55,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:55,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:56,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:56,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:56,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:56,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:57,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:57,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:57,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:58,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:58,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:58,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:59,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:59,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:59,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:00,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:00,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:00,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:01,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:01,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:01,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:01,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:02,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:02,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:02,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:03,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:03,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:03,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:04,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:04,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:04,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:04,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:05,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:05,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:05,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:05,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:06,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:06,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:06,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:07,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:07,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:07,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:07,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:08,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:08,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:08,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:09,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:09,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:09,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:09,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:10,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:10,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:10,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:10,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:10,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:11,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:11,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:11,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:12,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:12,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:12,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:13,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:13,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:14,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:14,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:14,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:15,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:15,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:15,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:16,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:16,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:17,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:17,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:17,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:18,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:18,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:18,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:19,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:19,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:19,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:19,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:20,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:20,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:20,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:21,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:21,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:21,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:21,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:22,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:22,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:22,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:22,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:23,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:23,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:23,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:23,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:24,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:24,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:24,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:25,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:25,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:25,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:26,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:26,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:26,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:26,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:27,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:27,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:27,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:28,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:28,925][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.2732, device='cuda:0') eval_epoch_loss=tensor(0.2415, device='cuda:0') eval_epoch_acc=tensor(0.9411, device='cuda:0')
[2024-12-17 02:45:28,927][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-12-17 02:45:28,927][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 02:45:29,107][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_2_step_3564_loss_0.2415131777524948/model.pt
[2024-12-17 02:45:29,112][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 0.2415131777524948
[2024-12-17 02:45:29,112][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.9410837888717651
[2024-12-17 02:45:29,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:29,408][root][INFO] - Training Epoch: 2/2, step 3564/7134 completed (loss: 0.21118366718292236, acc: 0.9444444179534912)
[2024-12-17 02:45:29,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:29,687][root][INFO] - Training Epoch: 2/2, step 3565/7134 completed (loss: 0.26985907554626465, acc: 0.9191176295280457)
[2024-12-17 02:45:29,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:29,960][root][INFO] - Training Epoch: 2/2, step 3566/7134 completed (loss: 0.3399738371372223, acc: 0.9075630307197571)
[2024-12-17 02:45:30,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:30,223][root][INFO] - Training Epoch: 2/2, step 3567/7134 completed (loss: 0.17112933099269867, acc: 0.9719101190567017)
[2024-12-17 02:45:30,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:30,499][root][INFO] - Training Epoch: 2/2, step 3568/7134 completed (loss: 0.33297255635261536, acc: 0.914893627166748)
[2024-12-17 02:45:30,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:30,762][root][INFO] - Training Epoch: 2/2, step 3569/7134 completed (loss: 0.2129613757133484, acc: 0.9333333373069763)
[2024-12-17 02:45:30,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:31,026][root][INFO] - Training Epoch: 2/2, step 3570/7134 completed (loss: 0.36034855246543884, acc: 0.8897058963775635)
[2024-12-17 02:45:31,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:31,305][root][INFO] - Training Epoch: 2/2, step 3571/7134 completed (loss: 0.42327937483787537, acc: 0.9044944047927856)
[2024-12-17 02:45:31,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:31,588][root][INFO] - Training Epoch: 2/2, step 3572/7134 completed (loss: 0.1104883924126625, acc: 0.9702380895614624)
[2024-12-17 02:45:31,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:31,865][root][INFO] - Training Epoch: 2/2, step 3573/7134 completed (loss: 0.2471039742231369, acc: 0.9473684430122375)
[2024-12-17 02:45:31,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:32,131][root][INFO] - Training Epoch: 2/2, step 3574/7134 completed (loss: 0.27855879068374634, acc: 0.9256198406219482)
[2024-12-17 02:45:32,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:32,403][root][INFO] - Training Epoch: 2/2, step 3575/7134 completed (loss: 0.5133737325668335, acc: 0.8881579041481018)
[2024-12-17 02:45:32,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:32,662][root][INFO] - Training Epoch: 2/2, step 3576/7134 completed (loss: 0.27032560110092163, acc: 0.9402984976768494)
[2024-12-17 02:45:32,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:32,975][root][INFO] - Training Epoch: 2/2, step 3577/7134 completed (loss: 0.26415443420410156, acc: 0.938144326210022)
[2024-12-17 02:45:33,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:33,252][root][INFO] - Training Epoch: 2/2, step 3578/7134 completed (loss: 0.1438392549753189, acc: 0.9638554453849792)
[2024-12-17 02:45:33,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:33,533][root][INFO] - Training Epoch: 2/2, step 3579/7134 completed (loss: 0.23620595037937164, acc: 0.9360465407371521)
[2024-12-17 02:45:33,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:33,825][root][INFO] - Training Epoch: 2/2, step 3580/7134 completed (loss: 0.4251491129398346, acc: 0.9017341136932373)
[2024-12-17 02:45:33,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:34,114][root][INFO] - Training Epoch: 2/2, step 3581/7134 completed (loss: 0.42650699615478516, acc: 0.8588235378265381)
[2024-12-17 02:45:34,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:34,351][root][INFO] - Training Epoch: 2/2, step 3582/7134 completed (loss: 0.38992705941200256, acc: 0.8888888955116272)
[2024-12-17 02:45:34,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:34,637][root][INFO] - Training Epoch: 2/2, step 3583/7134 completed (loss: 0.2982964515686035, acc: 0.8982036113739014)
[2024-12-17 02:45:34,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:34,901][root][INFO] - Training Epoch: 2/2, step 3584/7134 completed (loss: 0.38549306988716125, acc: 0.914893627166748)
[2024-12-17 02:45:35,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:35,183][root][INFO] - Training Epoch: 2/2, step 3585/7134 completed (loss: 0.2972322404384613, acc: 0.9263803958892822)
[2024-12-17 02:45:35,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:35,455][root][INFO] - Training Epoch: 2/2, step 3586/7134 completed (loss: 0.32600709795951843, acc: 0.9363057613372803)
[2024-12-17 02:45:35,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:35,736][root][INFO] - Training Epoch: 2/2, step 3587/7134 completed (loss: 0.23844335973262787, acc: 0.9580419659614563)
[2024-12-17 02:45:35,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:36,030][root][INFO] - Training Epoch: 2/2, step 3588/7134 completed (loss: 0.22716054320335388, acc: 0.9595375657081604)
[2024-12-17 02:45:36,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:36,319][root][INFO] - Training Epoch: 2/2, step 3589/7134 completed (loss: 0.3025853931903839, acc: 0.9617486596107483)
[2024-12-17 02:45:36,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:36,599][root][INFO] - Training Epoch: 2/2, step 3590/7134 completed (loss: 0.10791996121406555, acc: 0.9833333492279053)
[2024-12-17 02:45:36,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:36,860][root][INFO] - Training Epoch: 2/2, step 3591/7134 completed (loss: 0.26025494933128357, acc: 0.9181286692619324)
[2024-12-17 02:45:36,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:37,141][root][INFO] - Training Epoch: 2/2, step 3592/7134 completed (loss: 0.10314087569713593, acc: 0.9714285731315613)
[2024-12-17 02:45:37,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:37,418][root][INFO] - Training Epoch: 2/2, step 3593/7134 completed (loss: 0.39797118306159973, acc: 0.9366196990013123)
[2024-12-17 02:45:37,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:37,694][root][INFO] - Training Epoch: 2/2, step 3594/7134 completed (loss: 0.17777800559997559, acc: 0.9536423683166504)
[2024-12-17 02:45:37,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:37,963][root][INFO] - Training Epoch: 2/2, step 3595/7134 completed (loss: 0.20224133133888245, acc: 0.9411764740943909)
[2024-12-17 02:45:38,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:38,230][root][INFO] - Training Epoch: 2/2, step 3596/7134 completed (loss: 0.23338910937309265, acc: 0.9411764740943909)
[2024-12-17 02:45:38,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:38,502][root][INFO] - Training Epoch: 2/2, step 3597/7134 completed (loss: 0.12666861712932587, acc: 0.9736841917037964)
[2024-12-17 02:45:38,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:38,800][root][INFO] - Training Epoch: 2/2, step 3598/7134 completed (loss: 0.27231547236442566, acc: 0.9241706132888794)
[2024-12-17 02:45:38,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:39,081][root][INFO] - Training Epoch: 2/2, step 3599/7134 completed (loss: 0.2531995475292206, acc: 0.9135135412216187)
[2024-12-17 02:45:39,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:39,359][root][INFO] - Training Epoch: 2/2, step 3600/7134 completed (loss: 0.2583875060081482, acc: 0.9274611473083496)
[2024-12-17 02:45:39,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:39,645][root][INFO] - Training Epoch: 2/2, step 3601/7134 completed (loss: 0.628869354724884, acc: 0.8539325594902039)
[2024-12-17 02:45:39,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:39,924][root][INFO] - Training Epoch: 2/2, step 3602/7134 completed (loss: 0.4497338533401489, acc: 0.8883720636367798)
[2024-12-17 02:45:40,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:40,190][root][INFO] - Training Epoch: 2/2, step 3603/7134 completed (loss: 0.34064120054244995, acc: 0.9119496941566467)
[2024-12-17 02:45:40,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:40,415][root][INFO] - Training Epoch: 2/2, step 3604/7134 completed (loss: 0.2647838294506073, acc: 0.9448819160461426)
[2024-12-17 02:45:40,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:40,713][root][INFO] - Training Epoch: 2/2, step 3605/7134 completed (loss: 0.25129780173301697, acc: 0.9282511472702026)
[2024-12-17 02:45:40,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:40,995][root][INFO] - Training Epoch: 2/2, step 3606/7134 completed (loss: 0.37314191460609436, acc: 0.9178082346916199)
[2024-12-17 02:45:41,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:41,261][root][INFO] - Training Epoch: 2/2, step 3607/7134 completed (loss: 0.18591709434986115, acc: 0.9589040875434875)
[2024-12-17 02:45:41,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:41,538][root][INFO] - Training Epoch: 2/2, step 3608/7134 completed (loss: 0.2711484432220459, acc: 0.9611650705337524)
[2024-12-17 02:45:41,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:41,817][root][INFO] - Training Epoch: 2/2, step 3609/7134 completed (loss: 0.14290957152843475, acc: 0.9526315927505493)
[2024-12-17 02:45:41,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:42,097][root][INFO] - Training Epoch: 2/2, step 3610/7134 completed (loss: 0.30923691391944885, acc: 0.9120879173278809)
[2024-12-17 02:45:42,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:42,377][root][INFO] - Training Epoch: 2/2, step 3611/7134 completed (loss: 0.3020806908607483, acc: 0.9314285516738892)
[2024-12-17 02:45:42,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:42,660][root][INFO] - Training Epoch: 2/2, step 3612/7134 completed (loss: 0.35389572381973267, acc: 0.9181034564971924)
[2024-12-17 02:45:42,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:42,938][root][INFO] - Training Epoch: 2/2, step 3613/7134 completed (loss: 0.2632068395614624, acc: 0.9289617538452148)
[2024-12-17 02:45:43,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:43,211][root][INFO] - Training Epoch: 2/2, step 3614/7134 completed (loss: 0.16209881007671356, acc: 0.9680851101875305)
[2024-12-17 02:45:43,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:43,484][root][INFO] - Training Epoch: 2/2, step 3615/7134 completed (loss: 0.1892014890909195, acc: 0.9729729890823364)
[2024-12-17 02:45:43,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:43,764][root][INFO] - Training Epoch: 2/2, step 3616/7134 completed (loss: 0.3072296679019928, acc: 0.9130434989929199)
[2024-12-17 02:45:43,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:44,046][root][INFO] - Training Epoch: 2/2, step 3617/7134 completed (loss: 0.1965775340795517, acc: 0.9243243336677551)
[2024-12-17 02:45:44,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:44,319][root][INFO] - Training Epoch: 2/2, step 3618/7134 completed (loss: 0.32452312111854553, acc: 0.9386503100395203)
[2024-12-17 02:45:44,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:44,600][root][INFO] - Training Epoch: 2/2, step 3619/7134 completed (loss: 0.37354427576065063, acc: 0.8995633125305176)
[2024-12-17 02:45:44,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:44,893][root][INFO] - Training Epoch: 2/2, step 3620/7134 completed (loss: 0.2081201821565628, acc: 0.946107804775238)
[2024-12-17 02:45:44,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:45,159][root][INFO] - Training Epoch: 2/2, step 3621/7134 completed (loss: 0.20212283730506897, acc: 0.9426751732826233)
[2024-12-17 02:45:45,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:45,447][root][INFO] - Training Epoch: 2/2, step 3622/7134 completed (loss: 0.16289690136909485, acc: 0.9350649118423462)
[2024-12-17 02:45:45,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:45,695][root][INFO] - Training Epoch: 2/2, step 3623/7134 completed (loss: 0.09009236097335815, acc: 0.9642857313156128)
[2024-12-17 02:45:45,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:45,975][root][INFO] - Training Epoch: 2/2, step 3624/7134 completed (loss: 0.2500356435775757, acc: 0.9424460530281067)
[2024-12-17 02:45:46,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:46,248][root][INFO] - Training Epoch: 2/2, step 3625/7134 completed (loss: 0.36586466431617737, acc: 0.8739495873451233)
[2024-12-17 02:45:46,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:46,504][root][INFO] - Training Epoch: 2/2, step 3626/7134 completed (loss: 0.3839292526245117, acc: 0.9101123809814453)
[2024-12-17 02:45:46,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:46,771][root][INFO] - Training Epoch: 2/2, step 3627/7134 completed (loss: 0.4136105179786682, acc: 0.9056603908538818)
[2024-12-17 02:45:46,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:47,037][root][INFO] - Training Epoch: 2/2, step 3628/7134 completed (loss: 0.3609575629234314, acc: 0.9142857193946838)
[2024-12-17 02:45:47,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:47,279][root][INFO] - Training Epoch: 2/2, step 3629/7134 completed (loss: 0.3775078356266022, acc: 0.9032257795333862)
[2024-12-17 02:45:47,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:47,540][root][INFO] - Training Epoch: 2/2, step 3630/7134 completed (loss: 0.2450588196516037, acc: 0.9354838728904724)
[2024-12-17 02:45:47,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:47,833][root][INFO] - Training Epoch: 2/2, step 3631/7134 completed (loss: 0.3866152763366699, acc: 0.8999999761581421)
[2024-12-17 02:45:47,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:48,115][root][INFO] - Training Epoch: 2/2, step 3632/7134 completed (loss: 0.2125096172094345, acc: 0.9426229596138)
[2024-12-17 02:45:48,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:48,389][root][INFO] - Training Epoch: 2/2, step 3633/7134 completed (loss: 0.26610201597213745, acc: 0.9490445852279663)
[2024-12-17 02:45:48,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:48,656][root][INFO] - Training Epoch: 2/2, step 3634/7134 completed (loss: 0.270695298910141, acc: 0.9345794320106506)
[2024-12-17 02:45:48,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:48,925][root][INFO] - Training Epoch: 2/2, step 3635/7134 completed (loss: 0.20632994174957275, acc: 0.9655172228813171)
[2024-12-17 02:45:49,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:49,218][root][INFO] - Training Epoch: 2/2, step 3636/7134 completed (loss: 0.12614960968494415, acc: 0.9622641801834106)
[2024-12-17 02:45:49,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:49,504][root][INFO] - Training Epoch: 2/2, step 3637/7134 completed (loss: 0.3619828224182129, acc: 0.918181836605072)
[2024-12-17 02:45:49,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:49,765][root][INFO] - Training Epoch: 2/2, step 3638/7134 completed (loss: 0.18583710491657257, acc: 0.9670329689979553)
[2024-12-17 02:45:49,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:50,035][root][INFO] - Training Epoch: 2/2, step 3639/7134 completed (loss: 0.2050909847021103, acc: 0.9680851101875305)
[2024-12-17 02:45:50,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:50,328][root][INFO] - Training Epoch: 2/2, step 3640/7134 completed (loss: 0.22861111164093018, acc: 0.9504132270812988)
[2024-12-17 02:45:50,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:50,611][root][INFO] - Training Epoch: 2/2, step 3641/7134 completed (loss: 0.12570412456989288, acc: 0.9677419066429138)
[2024-12-17 02:45:50,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:50,893][root][INFO] - Training Epoch: 2/2, step 3642/7134 completed (loss: 0.059145212173461914, acc: 0.9865771532058716)
[2024-12-17 02:45:50,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:51,160][root][INFO] - Training Epoch: 2/2, step 3643/7134 completed (loss: 0.21443170309066772, acc: 0.9609375)
[2024-12-17 02:45:51,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:51,435][root][INFO] - Training Epoch: 2/2, step 3644/7134 completed (loss: 0.24892757833003998, acc: 0.9459459185600281)
[2024-12-17 02:45:51,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:51,713][root][INFO] - Training Epoch: 2/2, step 3645/7134 completed (loss: 0.3304640054702759, acc: 0.9375)
[2024-12-17 02:45:51,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:51,975][root][INFO] - Training Epoch: 2/2, step 3646/7134 completed (loss: 0.5137320756912231, acc: 0.8939393758773804)
[2024-12-17 02:45:52,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:52,234][root][INFO] - Training Epoch: 2/2, step 3647/7134 completed (loss: 0.15643222630023956, acc: 0.9550561904907227)
[2024-12-17 02:45:52,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:52,521][root][INFO] - Training Epoch: 2/2, step 3648/7134 completed (loss: 0.262104332447052, acc: 0.9526627063751221)
[2024-12-17 02:45:52,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:52,794][root][INFO] - Training Epoch: 2/2, step 3649/7134 completed (loss: 0.31695857644081116, acc: 0.9395973086357117)
[2024-12-17 02:45:52,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:53,072][root][INFO] - Training Epoch: 2/2, step 3650/7134 completed (loss: 0.22684359550476074, acc: 0.9112426042556763)
[2024-12-17 02:45:53,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:53,350][root][INFO] - Training Epoch: 2/2, step 3651/7134 completed (loss: 0.2996748089790344, acc: 0.9156626462936401)
[2024-12-17 02:45:53,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:53,604][root][INFO] - Training Epoch: 2/2, step 3652/7134 completed (loss: 0.1940494179725647, acc: 0.9591836929321289)
[2024-12-17 02:45:53,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:53,884][root][INFO] - Training Epoch: 2/2, step 3653/7134 completed (loss: 0.38119274377822876, acc: 0.907975435256958)
[2024-12-17 02:45:53,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:54,165][root][INFO] - Training Epoch: 2/2, step 3654/7134 completed (loss: 0.08972198516130447, acc: 0.9679999947547913)
[2024-12-17 02:45:54,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:54,454][root][INFO] - Training Epoch: 2/2, step 3655/7134 completed (loss: 0.39375174045562744, acc: 0.9041916131973267)
[2024-12-17 02:45:54,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:54,733][root][INFO] - Training Epoch: 2/2, step 3656/7134 completed (loss: 0.4265022277832031, acc: 0.9130434989929199)
[2024-12-17 02:45:54,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:55,022][root][INFO] - Training Epoch: 2/2, step 3657/7134 completed (loss: 0.11192268133163452, acc: 0.9650349617004395)
[2024-12-17 02:45:55,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:55,322][root][INFO] - Training Epoch: 2/2, step 3658/7134 completed (loss: 0.2259981334209442, acc: 0.9513888955116272)
[2024-12-17 02:45:55,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:55,599][root][INFO] - Training Epoch: 2/2, step 3659/7134 completed (loss: 0.33106765151023865, acc: 0.918367326259613)
[2024-12-17 02:45:55,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:55,809][root][INFO] - Training Epoch: 2/2, step 3660/7134 completed (loss: 0.3522031307220459, acc: 0.8888888955116272)
[2024-12-17 02:45:55,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:56,105][root][INFO] - Training Epoch: 2/2, step 3661/7134 completed (loss: 0.21294550597667694, acc: 0.9142857193946838)
[2024-12-17 02:45:56,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:56,398][root][INFO] - Training Epoch: 2/2, step 3662/7134 completed (loss: 0.4777156710624695, acc: 0.888198733329773)
[2024-12-17 02:45:56,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:56,692][root][INFO] - Training Epoch: 2/2, step 3663/7134 completed (loss: 0.27425485849380493, acc: 0.9296875)
[2024-12-17 02:45:56,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:56,987][root][INFO] - Training Epoch: 2/2, step 3664/7134 completed (loss: 0.3941259980201721, acc: 0.9025974273681641)
[2024-12-17 02:45:57,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:57,263][root][INFO] - Training Epoch: 2/2, step 3665/7134 completed (loss: 0.1977790743112564, acc: 0.9459459185600281)
[2024-12-17 02:45:57,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:57,551][root][INFO] - Training Epoch: 2/2, step 3666/7134 completed (loss: 0.2674661874771118, acc: 0.9246575236320496)
[2024-12-17 02:45:57,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:57,849][root][INFO] - Training Epoch: 2/2, step 3667/7134 completed (loss: 0.4966154992580414, acc: 0.8837209343910217)
[2024-12-17 02:45:57,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:58,131][root][INFO] - Training Epoch: 2/2, step 3668/7134 completed (loss: 0.3733505308628082, acc: 0.9034482836723328)
[2024-12-17 02:45:58,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:58,400][root][INFO] - Training Epoch: 2/2, step 3669/7134 completed (loss: 0.08220715820789337, acc: 0.9752066135406494)
[2024-12-17 02:45:58,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:58,692][root][INFO] - Training Epoch: 2/2, step 3670/7134 completed (loss: 0.08160269260406494, acc: 0.9759036302566528)
[2024-12-17 02:45:58,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:58,990][root][INFO] - Training Epoch: 2/2, step 3671/7134 completed (loss: 0.09537409245967865, acc: 0.9746835231781006)
[2024-12-17 02:45:59,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:59,286][root][INFO] - Training Epoch: 2/2, step 3672/7134 completed (loss: 0.1334991753101349, acc: 0.9668508172035217)
[2024-12-17 02:45:59,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:59,564][root][INFO] - Training Epoch: 2/2, step 3673/7134 completed (loss: 0.1391090452671051, acc: 0.9793103337287903)
[2024-12-17 02:45:59,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:59,845][root][INFO] - Training Epoch: 2/2, step 3674/7134 completed (loss: 0.05718427151441574, acc: 0.9864864945411682)
[2024-12-17 02:45:59,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:00,125][root][INFO] - Training Epoch: 2/2, step 3675/7134 completed (loss: 0.2347061038017273, acc: 0.9779005646705627)
[2024-12-17 02:46:00,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:00,397][root][INFO] - Training Epoch: 2/2, step 3676/7134 completed (loss: 0.1410163938999176, acc: 0.9743589758872986)
[2024-12-17 02:46:00,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:00,695][root][INFO] - Training Epoch: 2/2, step 3677/7134 completed (loss: 0.2684239447116852, acc: 0.9204545617103577)
[2024-12-17 02:46:00,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:00,990][root][INFO] - Training Epoch: 2/2, step 3678/7134 completed (loss: 0.3405223786830902, acc: 0.9556962251663208)
[2024-12-17 02:46:01,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:01,279][root][INFO] - Training Epoch: 2/2, step 3679/7134 completed (loss: 0.11746454983949661, acc: 0.9692307710647583)
[2024-12-17 02:46:01,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:01,553][root][INFO] - Training Epoch: 2/2, step 3680/7134 completed (loss: 0.20798084139823914, acc: 0.9466666579246521)
[2024-12-17 02:46:01,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:01,826][root][INFO] - Training Epoch: 2/2, step 3681/7134 completed (loss: 0.11610003560781479, acc: 0.981249988079071)
[2024-12-17 02:46:01,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:02,106][root][INFO] - Training Epoch: 2/2, step 3682/7134 completed (loss: 0.09722016006708145, acc: 0.9821428656578064)
[2024-12-17 02:46:02,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:02,400][root][INFO] - Training Epoch: 2/2, step 3683/7134 completed (loss: 0.0937945693731308, acc: 0.9779411554336548)
[2024-12-17 02:46:02,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:02,663][root][INFO] - Training Epoch: 2/2, step 3684/7134 completed (loss: 0.05631319433450699, acc: 0.9934210777282715)
[2024-12-17 02:46:02,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:02,924][root][INFO] - Training Epoch: 2/2, step 3685/7134 completed (loss: 0.09819815307855606, acc: 0.9837398529052734)
[2024-12-17 02:46:03,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:03,184][root][INFO] - Training Epoch: 2/2, step 3686/7134 completed (loss: 0.1344269961118698, acc: 0.9577465057373047)
[2024-12-17 02:46:03,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:03,464][root][INFO] - Training Epoch: 2/2, step 3687/7134 completed (loss: 0.10729609429836273, acc: 0.9689440727233887)
[2024-12-17 02:46:03,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:03,741][root][INFO] - Training Epoch: 2/2, step 3688/7134 completed (loss: 0.09515083581209183, acc: 0.9833333492279053)
[2024-12-17 02:46:03,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:04,017][root][INFO] - Training Epoch: 2/2, step 3689/7134 completed (loss: 0.15602704882621765, acc: 0.9503546357154846)
[2024-12-17 02:46:04,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:04,302][root][INFO] - Training Epoch: 2/2, step 3690/7134 completed (loss: 0.07355947047472, acc: 0.9810126423835754)
[2024-12-17 02:46:04,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:04,572][root][INFO] - Training Epoch: 2/2, step 3691/7134 completed (loss: 0.12324440479278564, acc: 0.9603960514068604)
[2024-12-17 02:46:04,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:04,854][root][INFO] - Training Epoch: 2/2, step 3692/7134 completed (loss: 0.08551355451345444, acc: 0.9693251252174377)
[2024-12-17 02:46:04,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:05,137][root][INFO] - Training Epoch: 2/2, step 3693/7134 completed (loss: 0.06307265162467957, acc: 0.9772727489471436)
[2024-12-17 02:46:05,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:05,417][root][INFO] - Training Epoch: 2/2, step 3694/7134 completed (loss: 0.1233130693435669, acc: 0.96875)
[2024-12-17 02:46:05,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:05,696][root][INFO] - Training Epoch: 2/2, step 3695/7134 completed (loss: 0.11465789377689362, acc: 0.9681528806686401)
[2024-12-17 02:46:05,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:05,982][root][INFO] - Training Epoch: 2/2, step 3696/7134 completed (loss: 0.07234171777963638, acc: 0.982758641242981)
[2024-12-17 02:46:06,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:06,242][root][INFO] - Training Epoch: 2/2, step 3697/7134 completed (loss: 0.07591171562671661, acc: 0.9756097793579102)
[2024-12-17 02:46:06,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:06,506][root][INFO] - Training Epoch: 2/2, step 3698/7134 completed (loss: 0.0724525898694992, acc: 0.9793103337287903)
[2024-12-17 02:46:06,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:06,777][root][INFO] - Training Epoch: 2/2, step 3699/7134 completed (loss: 0.08956082910299301, acc: 0.9842519760131836)
[2024-12-17 02:46:06,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:07,057][root][INFO] - Training Epoch: 2/2, step 3700/7134 completed (loss: 0.07096637040376663, acc: 0.9874213933944702)
[2024-12-17 02:46:07,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:07,339][root][INFO] - Training Epoch: 2/2, step 3701/7134 completed (loss: 0.1697758585214615, acc: 0.9635036587715149)
[2024-12-17 02:46:07,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:07,608][root][INFO] - Training Epoch: 2/2, step 3702/7134 completed (loss: 0.12915371358394623, acc: 0.9636363387107849)
[2024-12-17 02:46:07,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:07,885][root][INFO] - Training Epoch: 2/2, step 3703/7134 completed (loss: 0.09982054680585861, acc: 0.9943181872367859)
[2024-12-17 02:46:07,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:08,142][root][INFO] - Training Epoch: 2/2, step 3704/7134 completed (loss: 0.06831139326095581, acc: 0.9801980257034302)
[2024-12-17 02:46:08,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:08,407][root][INFO] - Training Epoch: 2/2, step 3705/7134 completed (loss: 0.29858002066612244, acc: 0.9447852969169617)
[2024-12-17 02:46:08,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:08,676][root][INFO] - Training Epoch: 2/2, step 3706/7134 completed (loss: 0.26859650015830994, acc: 0.9455445408821106)
[2024-12-17 02:46:08,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:08,935][root][INFO] - Training Epoch: 2/2, step 3707/7134 completed (loss: 0.08545968681573868, acc: 0.9800000190734863)
[2024-12-17 02:46:09,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:09,222][root][INFO] - Training Epoch: 2/2, step 3708/7134 completed (loss: 0.24700269103050232, acc: 0.9384615421295166)
[2024-12-17 02:46:09,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:09,515][root][INFO] - Training Epoch: 2/2, step 3709/7134 completed (loss: 0.11610583961009979, acc: 0.9768518805503845)
[2024-12-17 02:46:09,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:09,802][root][INFO] - Training Epoch: 2/2, step 3710/7134 completed (loss: 0.1532679796218872, acc: 0.9537037014961243)
[2024-12-17 02:46:09,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:10,051][root][INFO] - Training Epoch: 2/2, step 3711/7134 completed (loss: 0.14023026823997498, acc: 0.9450549483299255)
[2024-12-17 02:46:10,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:10,335][root][INFO] - Training Epoch: 2/2, step 3712/7134 completed (loss: 0.21920664608478546, acc: 0.9239130616188049)
[2024-12-17 02:46:10,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:10,601][root][INFO] - Training Epoch: 2/2, step 3713/7134 completed (loss: 0.23071230947971344, acc: 0.935251772403717)
[2024-12-17 02:46:10,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:10,865][root][INFO] - Training Epoch: 2/2, step 3714/7134 completed (loss: 0.17033645510673523, acc: 0.9637305736541748)
[2024-12-17 02:46:10,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:11,150][root][INFO] - Training Epoch: 2/2, step 3715/7134 completed (loss: 0.11317193508148193, acc: 0.9734042286872864)
[2024-12-17 02:46:11,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:11,433][root][INFO] - Training Epoch: 2/2, step 3716/7134 completed (loss: 0.2500220239162445, acc: 0.9289340376853943)
[2024-12-17 02:46:11,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:11,709][root][INFO] - Training Epoch: 2/2, step 3717/7134 completed (loss: 0.17321009933948517, acc: 0.957317054271698)
[2024-12-17 02:46:11,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:12,004][root][INFO] - Training Epoch: 2/2, step 3718/7134 completed (loss: 0.22334249317646027, acc: 0.9583333134651184)
[2024-12-17 02:46:12,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:12,292][root][INFO] - Training Epoch: 2/2, step 3719/7134 completed (loss: 0.2175406515598297, acc: 0.9532163739204407)
[2024-12-17 02:46:12,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:12,535][root][INFO] - Training Epoch: 2/2, step 3720/7134 completed (loss: 0.05283629149198532, acc: 0.9936708807945251)
[2024-12-17 02:46:12,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:12,823][root][INFO] - Training Epoch: 2/2, step 3721/7134 completed (loss: 0.18037761747837067, acc: 0.9421965479850769)
[2024-12-17 02:46:12,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:13,101][root][INFO] - Training Epoch: 2/2, step 3722/7134 completed (loss: 0.15739326179027557, acc: 0.9533678889274597)
[2024-12-17 02:46:13,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:13,371][root][INFO] - Training Epoch: 2/2, step 3723/7134 completed (loss: 0.21751753985881805, acc: 0.948387086391449)
[2024-12-17 02:46:13,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:13,643][root][INFO] - Training Epoch: 2/2, step 3724/7134 completed (loss: 0.1264355182647705, acc: 0.9698795080184937)
[2024-12-17 02:46:13,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:13,925][root][INFO] - Training Epoch: 2/2, step 3725/7134 completed (loss: 0.3334924578666687, acc: 0.957317054271698)
[2024-12-17 02:46:14,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:14,206][root][INFO] - Training Epoch: 2/2, step 3726/7134 completed (loss: 0.13342906534671783, acc: 0.9648241400718689)
[2024-12-17 02:46:14,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:14,473][root][INFO] - Training Epoch: 2/2, step 3727/7134 completed (loss: 0.10630074143409729, acc: 0.9768785834312439)
[2024-12-17 02:46:14,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:14,750][root][INFO] - Training Epoch: 2/2, step 3728/7134 completed (loss: 0.09602004289627075, acc: 0.9704433679580688)
[2024-12-17 02:46:14,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:15,035][root][INFO] - Training Epoch: 2/2, step 3729/7134 completed (loss: 0.1325819045305252, acc: 0.9669811129570007)
[2024-12-17 02:46:15,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:15,312][root][INFO] - Training Epoch: 2/2, step 3730/7134 completed (loss: 0.12476108223199844, acc: 0.9757575988769531)
[2024-12-17 02:46:15,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:15,588][root][INFO] - Training Epoch: 2/2, step 3731/7134 completed (loss: 0.07535695284605026, acc: 0.9712643623352051)
[2024-12-17 02:46:15,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:15,867][root][INFO] - Training Epoch: 2/2, step 3732/7134 completed (loss: 0.09120181947946548, acc: 0.9794871807098389)
[2024-12-17 02:46:15,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:16,127][root][INFO] - Training Epoch: 2/2, step 3733/7134 completed (loss: 0.16225787997245789, acc: 0.9751552939414978)
[2024-12-17 02:46:16,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:16,398][root][INFO] - Training Epoch: 2/2, step 3734/7134 completed (loss: 0.22080925107002258, acc: 0.9230769276618958)
[2024-12-17 02:46:16,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:16,661][root][INFO] - Training Epoch: 2/2, step 3735/7134 completed (loss: 0.20309659838676453, acc: 0.9415584206581116)
[2024-12-17 02:46:16,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:16,940][root][INFO] - Training Epoch: 2/2, step 3736/7134 completed (loss: 0.15826912224292755, acc: 0.9558823704719543)
[2024-12-17 02:46:17,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:17,215][root][INFO] - Training Epoch: 2/2, step 3737/7134 completed (loss: 0.16700653731822968, acc: 0.9454545378684998)
[2024-12-17 02:46:17,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:17,493][root][INFO] - Training Epoch: 2/2, step 3738/7134 completed (loss: 0.09851129353046417, acc: 0.9791666865348816)
[2024-12-17 02:46:17,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:17,742][root][INFO] - Training Epoch: 2/2, step 3739/7134 completed (loss: 0.20338569581508636, acc: 0.914893627166748)
[2024-12-17 02:46:17,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:18,005][root][INFO] - Training Epoch: 2/2, step 3740/7134 completed (loss: 0.12000436335802078, acc: 0.9681528806686401)
[2024-12-17 02:46:18,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:18,285][root][INFO] - Training Epoch: 2/2, step 3741/7134 completed (loss: 0.1718359738588333, acc: 0.982758641242981)
[2024-12-17 02:46:18,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:18,537][root][INFO] - Training Epoch: 2/2, step 3742/7134 completed (loss: 0.17579510807991028, acc: 0.9659863710403442)
[2024-12-17 02:46:18,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:18,815][root][INFO] - Training Epoch: 2/2, step 3743/7134 completed (loss: 0.2437344789505005, acc: 0.9235293865203857)
[2024-12-17 02:46:18,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:19,108][root][INFO] - Training Epoch: 2/2, step 3744/7134 completed (loss: 0.2333878129720688, acc: 0.930232584476471)
[2024-12-17 02:46:19,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:19,355][root][INFO] - Training Epoch: 2/2, step 3745/7134 completed (loss: 0.30486661195755005, acc: 0.9333333373069763)
[2024-12-17 02:46:19,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:19,633][root][INFO] - Training Epoch: 2/2, step 3746/7134 completed (loss: 0.13467372953891754, acc: 0.9774011373519897)
[2024-12-17 02:46:19,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:19,929][root][INFO] - Training Epoch: 2/2, step 3747/7134 completed (loss: 0.1517132818698883, acc: 0.9555555582046509)
[2024-12-17 02:46:20,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:20,195][root][INFO] - Training Epoch: 2/2, step 3748/7134 completed (loss: 0.19639478623867035, acc: 0.9399999976158142)
[2024-12-17 02:46:20,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:20,475][root][INFO] - Training Epoch: 2/2, step 3749/7134 completed (loss: 0.2883510887622833, acc: 0.9345238208770752)
[2024-12-17 02:46:20,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:20,757][root][INFO] - Training Epoch: 2/2, step 3750/7134 completed (loss: 0.06724026799201965, acc: 0.9938650131225586)
[2024-12-17 02:46:20,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:21,039][root][INFO] - Training Epoch: 2/2, step 3751/7134 completed (loss: 0.1572524905204773, acc: 0.9518072009086609)
[2024-12-17 02:46:21,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:21,321][root][INFO] - Training Epoch: 2/2, step 3752/7134 completed (loss: 0.2995440661907196, acc: 0.9433962106704712)
[2024-12-17 02:46:21,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:21,599][root][INFO] - Training Epoch: 2/2, step 3753/7134 completed (loss: 0.34793373942375183, acc: 0.9202454090118408)
[2024-12-17 02:46:21,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:21,874][root][INFO] - Training Epoch: 2/2, step 3754/7134 completed (loss: 0.05550328642129898, acc: 0.9870967864990234)
[2024-12-17 02:46:22,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:22,152][root][INFO] - Training Epoch: 2/2, step 3755/7134 completed (loss: 0.17738784849643707, acc: 0.9504132270812988)
[2024-12-17 02:46:22,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:22,445][root][INFO] - Training Epoch: 2/2, step 3756/7134 completed (loss: 0.17561525106430054, acc: 0.9653179049491882)
[2024-12-17 02:46:22,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:22,740][root][INFO] - Training Epoch: 2/2, step 3757/7134 completed (loss: 0.28938618302345276, acc: 0.9415584206581116)
[2024-12-17 02:46:22,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:23,015][root][INFO] - Training Epoch: 2/2, step 3758/7134 completed (loss: 0.14911842346191406, acc: 0.960629940032959)
[2024-12-17 02:46:23,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:23,284][root][INFO] - Training Epoch: 2/2, step 3759/7134 completed (loss: 0.20151092112064362, acc: 0.9650349617004395)
[2024-12-17 02:46:23,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:23,569][root][INFO] - Training Epoch: 2/2, step 3760/7134 completed (loss: 0.2421993613243103, acc: 0.9451219439506531)
[2024-12-17 02:46:23,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:23,833][root][INFO] - Training Epoch: 2/2, step 3761/7134 completed (loss: 0.10246653854846954, acc: 0.9621211886405945)
[2024-12-17 02:46:23,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:24,104][root][INFO] - Training Epoch: 2/2, step 3762/7134 completed (loss: 0.1121247336268425, acc: 0.9736841917037964)
[2024-12-17 02:46:24,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:24,374][root][INFO] - Training Epoch: 2/2, step 3763/7134 completed (loss: 0.056418176740407944, acc: 0.9857142567634583)
[2024-12-17 02:46:24,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:24,655][root][INFO] - Training Epoch: 2/2, step 3764/7134 completed (loss: 0.13218414783477783, acc: 0.9580838084220886)
[2024-12-17 02:46:24,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:24,953][root][INFO] - Training Epoch: 2/2, step 3765/7134 completed (loss: 0.09501611441373825, acc: 0.9829545617103577)
[2024-12-17 02:46:25,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:25,199][root][INFO] - Training Epoch: 2/2, step 3766/7134 completed (loss: 0.15600578486919403, acc: 0.9530201554298401)
[2024-12-17 02:46:25,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:25,474][root][INFO] - Training Epoch: 2/2, step 3767/7134 completed (loss: 0.18521706759929657, acc: 0.9553072452545166)
[2024-12-17 02:46:25,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:25,745][root][INFO] - Training Epoch: 2/2, step 3768/7134 completed (loss: 0.2391696721315384, acc: 0.932692289352417)
[2024-12-17 02:46:25,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:26,029][root][INFO] - Training Epoch: 2/2, step 3769/7134 completed (loss: 0.17983484268188477, acc: 0.9352940917015076)
[2024-12-17 02:46:26,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:26,293][root][INFO] - Training Epoch: 2/2, step 3770/7134 completed (loss: 0.12620168924331665, acc: 0.9664429426193237)
[2024-12-17 02:46:26,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:26,570][root][INFO] - Training Epoch: 2/2, step 3771/7134 completed (loss: 0.05802297592163086, acc: 0.9934210777282715)
[2024-12-17 02:46:26,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:26,851][root][INFO] - Training Epoch: 2/2, step 3772/7134 completed (loss: 0.1213323175907135, acc: 0.9785714149475098)
[2024-12-17 02:46:26,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:27,130][root][INFO] - Training Epoch: 2/2, step 3773/7134 completed (loss: 0.11518262326717377, acc: 0.9840425252914429)
[2024-12-17 02:46:27,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:27,415][root][INFO] - Training Epoch: 2/2, step 3774/7134 completed (loss: 0.15867672860622406, acc: 0.9615384340286255)
[2024-12-17 02:46:27,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:27,716][root][INFO] - Training Epoch: 2/2, step 3775/7134 completed (loss: 0.13669165968894958, acc: 0.95652174949646)
[2024-12-17 02:46:27,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:28,009][root][INFO] - Training Epoch: 2/2, step 3776/7134 completed (loss: 0.15179003775119781, acc: 0.9679487347602844)
[2024-12-17 02:46:28,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:28,293][root][INFO] - Training Epoch: 2/2, step 3777/7134 completed (loss: 0.05723286420106888, acc: 0.9882352948188782)
[2024-12-17 02:46:28,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:28,587][root][INFO] - Training Epoch: 2/2, step 3778/7134 completed (loss: 0.2407434582710266, acc: 0.9476743936538696)
[2024-12-17 02:46:28,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:28,861][root][INFO] - Training Epoch: 2/2, step 3779/7134 completed (loss: 0.12397617101669312, acc: 0.96875)
[2024-12-17 02:46:28,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:29,142][root][INFO] - Training Epoch: 2/2, step 3780/7134 completed (loss: 0.06572993099689484, acc: 0.9818181991577148)
[2024-12-17 02:46:29,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:29,400][root][INFO] - Training Epoch: 2/2, step 3781/7134 completed (loss: 0.20670130848884583, acc: 0.9316770434379578)
[2024-12-17 02:46:29,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:29,648][root][INFO] - Training Epoch: 2/2, step 3782/7134 completed (loss: 0.1619185507297516, acc: 0.9496855139732361)
[2024-12-17 02:46:29,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:29,929][root][INFO] - Training Epoch: 2/2, step 3783/7134 completed (loss: 0.2013891488313675, acc: 0.9644970297813416)
[2024-12-17 02:46:30,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:30,194][root][INFO] - Training Epoch: 2/2, step 3784/7134 completed (loss: 0.19140012562274933, acc: 0.9463087320327759)
[2024-12-17 02:46:30,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:30,467][root][INFO] - Training Epoch: 2/2, step 3785/7134 completed (loss: 0.13843080401420593, acc: 0.9645389914512634)
[2024-12-17 02:46:30,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:30,732][root][INFO] - Training Epoch: 2/2, step 3786/7134 completed (loss: 0.07707146555185318, acc: 0.9940476417541504)
[2024-12-17 02:46:30,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:30,964][root][INFO] - Training Epoch: 2/2, step 3787/7134 completed (loss: 0.14441588521003723, acc: 0.9615384340286255)
[2024-12-17 02:46:31,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:31,248][root][INFO] - Training Epoch: 2/2, step 3788/7134 completed (loss: 0.19798250496387482, acc: 0.9509202241897583)
[2024-12-17 02:46:31,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:31,519][root][INFO] - Training Epoch: 2/2, step 3789/7134 completed (loss: 0.21647179126739502, acc: 0.9411764740943909)
[2024-12-17 02:46:31,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:31,806][root][INFO] - Training Epoch: 2/2, step 3790/7134 completed (loss: 0.3026669919490814, acc: 0.929411768913269)
[2024-12-17 02:46:31,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:32,063][root][INFO] - Training Epoch: 2/2, step 3791/7134 completed (loss: 0.10650280117988586, acc: 0.9768785834312439)
[2024-12-17 02:46:32,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:32,331][root][INFO] - Training Epoch: 2/2, step 3792/7134 completed (loss: 0.10956397652626038, acc: 0.9774436354637146)
[2024-12-17 02:46:32,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:32,600][root][INFO] - Training Epoch: 2/2, step 3793/7134 completed (loss: 0.15524324774742126, acc: 0.959770143032074)
[2024-12-17 02:46:32,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:32,870][root][INFO] - Training Epoch: 2/2, step 3794/7134 completed (loss: 0.3240647614002228, acc: 0.9333333373069763)
[2024-12-17 02:46:32,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:33,157][root][INFO] - Training Epoch: 2/2, step 3795/7134 completed (loss: 0.13367676734924316, acc: 0.9555555582046509)
[2024-12-17 02:46:33,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:33,430][root][INFO] - Training Epoch: 2/2, step 3796/7134 completed (loss: 0.16415107250213623, acc: 0.9590643048286438)
[2024-12-17 02:46:33,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:33,748][root][INFO] - Training Epoch: 2/2, step 3797/7134 completed (loss: 0.12974530458450317, acc: 0.9575757384300232)
[2024-12-17 02:46:33,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:34,030][root][INFO] - Training Epoch: 2/2, step 3798/7134 completed (loss: 0.3281756341457367, acc: 0.9245283007621765)
[2024-12-17 02:46:34,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:34,316][root][INFO] - Training Epoch: 2/2, step 3799/7134 completed (loss: 0.28725701570510864, acc: 0.9152542352676392)
[2024-12-17 02:46:34,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:34,594][root][INFO] - Training Epoch: 2/2, step 3800/7134 completed (loss: 0.26512518525123596, acc: 0.9379310607910156)
[2024-12-17 02:46:34,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:34,886][root][INFO] - Training Epoch: 2/2, step 3801/7134 completed (loss: 0.20122699439525604, acc: 0.9281768202781677)
[2024-12-17 02:46:34,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:35,167][root][INFO] - Training Epoch: 2/2, step 3802/7134 completed (loss: 0.20968617498874664, acc: 0.953125)
[2024-12-17 02:46:35,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:35,438][root][INFO] - Training Epoch: 2/2, step 3803/7134 completed (loss: 0.12300631403923035, acc: 0.9617834687232971)
[2024-12-17 02:46:35,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:35,725][root][INFO] - Training Epoch: 2/2, step 3804/7134 completed (loss: 0.2552644908428192, acc: 0.9366196990013123)
[2024-12-17 02:46:35,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:36,003][root][INFO] - Training Epoch: 2/2, step 3805/7134 completed (loss: 0.19416238367557526, acc: 0.9485714435577393)
[2024-12-17 02:46:36,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:36,264][root][INFO] - Training Epoch: 2/2, step 3806/7134 completed (loss: 0.1467960923910141, acc: 0.9444444179534912)
[2024-12-17 02:46:36,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:36,531][root][INFO] - Training Epoch: 2/2, step 3807/7134 completed (loss: 0.1397698074579239, acc: 0.9589040875434875)
[2024-12-17 02:46:36,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:36,826][root][INFO] - Training Epoch: 2/2, step 3808/7134 completed (loss: 0.18227405846118927, acc: 0.945652186870575)
[2024-12-17 02:46:36,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:37,097][root][INFO] - Training Epoch: 2/2, step 3809/7134 completed (loss: 0.17127664387226105, acc: 0.9593023061752319)
[2024-12-17 02:46:37,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:37,363][root][INFO] - Training Epoch: 2/2, step 3810/7134 completed (loss: 0.18955835700035095, acc: 0.9610389471054077)
[2024-12-17 02:46:37,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:37,636][root][INFO] - Training Epoch: 2/2, step 3811/7134 completed (loss: 0.2345711886882782, acc: 0.940119743347168)
[2024-12-17 02:46:37,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:37,922][root][INFO] - Training Epoch: 2/2, step 3812/7134 completed (loss: 0.4226948618888855, acc: 0.8979591727256775)
[2024-12-17 02:46:38,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:38,195][root][INFO] - Training Epoch: 2/2, step 3813/7134 completed (loss: 0.4242253005504608, acc: 0.9243243336677551)
[2024-12-17 02:46:38,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:38,472][root][INFO] - Training Epoch: 2/2, step 3814/7134 completed (loss: 0.11162061244249344, acc: 0.9657142758369446)
[2024-12-17 02:46:38,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:38,734][root][INFO] - Training Epoch: 2/2, step 3815/7134 completed (loss: 0.1963300108909607, acc: 0.9539473652839661)
[2024-12-17 02:46:38,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:39,022][root][INFO] - Training Epoch: 2/2, step 3816/7134 completed (loss: 0.09896910935640335, acc: 0.9776119589805603)
[2024-12-17 02:46:39,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:39,299][root][INFO] - Training Epoch: 2/2, step 3817/7134 completed (loss: 0.22477124631404877, acc: 0.9438202381134033)
[2024-12-17 02:46:39,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:39,562][root][INFO] - Training Epoch: 2/2, step 3818/7134 completed (loss: 0.24479001760482788, acc: 0.9473684430122375)
[2024-12-17 02:46:39,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:39,806][root][INFO] - Training Epoch: 2/2, step 3819/7134 completed (loss: 0.2562362253665924, acc: 0.9142857193946838)
[2024-12-17 02:46:39,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:40,080][root][INFO] - Training Epoch: 2/2, step 3820/7134 completed (loss: 0.32734063267707825, acc: 0.9074074029922485)
[2024-12-17 02:46:40,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:40,341][root][INFO] - Training Epoch: 2/2, step 3821/7134 completed (loss: 0.18065589666366577, acc: 0.9726027250289917)
[2024-12-17 02:46:40,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:40,593][root][INFO] - Training Epoch: 2/2, step 3822/7134 completed (loss: 0.1177496463060379, acc: 0.9622641801834106)
[2024-12-17 02:46:40,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:40,878][root][INFO] - Training Epoch: 2/2, step 3823/7134 completed (loss: 0.05763208121061325, acc: 0.9932885766029358)
[2024-12-17 02:46:41,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:41,158][root][INFO] - Training Epoch: 2/2, step 3824/7134 completed (loss: 0.1897772252559662, acc: 0.953125)
[2024-12-17 02:46:41,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:41,445][root][INFO] - Training Epoch: 2/2, step 3825/7134 completed (loss: 0.1780824512243271, acc: 0.9629629850387573)
[2024-12-17 02:46:41,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:41,732][root][INFO] - Training Epoch: 2/2, step 3826/7134 completed (loss: 0.1384226530790329, acc: 0.9788732528686523)
[2024-12-17 02:46:41,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:42,013][root][INFO] - Training Epoch: 2/2, step 3827/7134 completed (loss: 0.12179114669561386, acc: 0.9745222926139832)
[2024-12-17 02:46:42,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:42,286][root][INFO] - Training Epoch: 2/2, step 3828/7134 completed (loss: 0.1469818353652954, acc: 0.987500011920929)
[2024-12-17 02:46:42,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:42,579][root][INFO] - Training Epoch: 2/2, step 3829/7134 completed (loss: 0.19789308309555054, acc: 0.953125)
[2024-12-17 02:46:42,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:42,862][root][INFO] - Training Epoch: 2/2, step 3830/7134 completed (loss: 0.24124577641487122, acc: 0.9407407641410828)
[2024-12-17 02:46:42,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:43,132][root][INFO] - Training Epoch: 2/2, step 3831/7134 completed (loss: 0.21345515549182892, acc: 0.9539473652839661)
[2024-12-17 02:46:43,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:43,367][root][INFO] - Training Epoch: 2/2, step 3832/7134 completed (loss: 0.11399943381547928, acc: 0.9821428656578064)
[2024-12-17 02:46:43,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:43,666][root][INFO] - Training Epoch: 2/2, step 3833/7134 completed (loss: 0.08594512194395065, acc: 0.9726775884628296)
[2024-12-17 02:46:43,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:43,964][root][INFO] - Training Epoch: 2/2, step 3834/7134 completed (loss: 0.021929984912276268, acc: 1.0)
[2024-12-17 02:46:44,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:44,247][root][INFO] - Training Epoch: 2/2, step 3835/7134 completed (loss: 0.07922987639904022, acc: 0.9791666865348816)
[2024-12-17 02:46:44,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:44,536][root][INFO] - Training Epoch: 2/2, step 3836/7134 completed (loss: 0.25573477149009705, acc: 0.9629629850387573)
[2024-12-17 02:46:44,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:44,789][root][INFO] - Training Epoch: 2/2, step 3837/7134 completed (loss: 0.11150835454463959, acc: 0.987261176109314)
[2024-12-17 02:46:44,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:45,062][root][INFO] - Training Epoch: 2/2, step 3838/7134 completed (loss: 0.07170086354017258, acc: 0.983146071434021)
[2024-12-17 02:46:45,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:45,350][root][INFO] - Training Epoch: 2/2, step 3839/7134 completed (loss: 0.05975232645869255, acc: 0.9751552939414978)
[2024-12-17 02:46:45,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:45,613][root][INFO] - Training Epoch: 2/2, step 3840/7134 completed (loss: 0.081791453063488, acc: 0.9878787994384766)
[2024-12-17 02:46:45,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:45,903][root][INFO] - Training Epoch: 2/2, step 3841/7134 completed (loss: 0.15572859346866608, acc: 0.9648241400718689)
[2024-12-17 02:46:46,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:46,159][root][INFO] - Training Epoch: 2/2, step 3842/7134 completed (loss: 0.04907263070344925, acc: 0.9896907210350037)
[2024-12-17 02:46:46,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:46,457][root][INFO] - Training Epoch: 2/2, step 3843/7134 completed (loss: 0.16195103526115417, acc: 0.977477490901947)
[2024-12-17 02:46:46,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:46,738][root][INFO] - Training Epoch: 2/2, step 3844/7134 completed (loss: 0.29335883259773254, acc: 0.9319371581077576)
[2024-12-17 02:46:46,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:46,994][root][INFO] - Training Epoch: 2/2, step 3845/7134 completed (loss: 0.16588559746742249, acc: 0.9714285731315613)
[2024-12-17 02:46:47,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:47,241][root][INFO] - Training Epoch: 2/2, step 3846/7134 completed (loss: 0.07526858896017075, acc: 0.9781022071838379)
[2024-12-17 02:46:47,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:47,536][root][INFO] - Training Epoch: 2/2, step 3847/7134 completed (loss: 0.0835341364145279, acc: 0.9858155846595764)
[2024-12-17 02:46:47,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:47,818][root][INFO] - Training Epoch: 2/2, step 3848/7134 completed (loss: 0.11462140083312988, acc: 0.9772727489471436)
[2024-12-17 02:46:47,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:48,077][root][INFO] - Training Epoch: 2/2, step 3849/7134 completed (loss: 0.204204261302948, acc: 0.9407407641410828)
[2024-12-17 02:46:48,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:48,343][root][INFO] - Training Epoch: 2/2, step 3850/7134 completed (loss: 0.16657261550426483, acc: 0.9672130942344666)
[2024-12-17 02:46:48,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:48,651][root][INFO] - Training Epoch: 2/2, step 3851/7134 completed (loss: 0.2348647564649582, acc: 0.9285714030265808)
[2024-12-17 02:46:48,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:48,900][root][INFO] - Training Epoch: 2/2, step 3852/7134 completed (loss: 0.08863470703363419, acc: 0.9784172773361206)
[2024-12-17 02:46:49,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:49,172][root][INFO] - Training Epoch: 2/2, step 3853/7134 completed (loss: 0.22715026140213013, acc: 0.9385474920272827)
[2024-12-17 02:46:49,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:49,436][root][INFO] - Training Epoch: 2/2, step 3854/7134 completed (loss: 0.16246438026428223, acc: 0.9554139971733093)
[2024-12-17 02:46:49,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:49,727][root][INFO] - Training Epoch: 2/2, step 3855/7134 completed (loss: 0.2556628882884979, acc: 0.9341317415237427)
[2024-12-17 02:46:49,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:49,992][root][INFO] - Training Epoch: 2/2, step 3856/7134 completed (loss: 0.1707974523305893, acc: 0.9554139971733093)
[2024-12-17 02:46:50,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:50,267][root][INFO] - Training Epoch: 2/2, step 3857/7134 completed (loss: 0.23190075159072876, acc: 0.9189189076423645)
[2024-12-17 02:46:50,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:50,539][root][INFO] - Training Epoch: 2/2, step 3858/7134 completed (loss: 0.25693172216415405, acc: 0.9312499761581421)
[2024-12-17 02:46:50,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:50,818][root][INFO] - Training Epoch: 2/2, step 3859/7134 completed (loss: 0.19798576831817627, acc: 0.9378530979156494)
[2024-12-17 02:46:50,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:51,099][root][INFO] - Training Epoch: 2/2, step 3860/7134 completed (loss: 0.0982588455080986, acc: 0.9790576100349426)
[2024-12-17 02:46:51,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:51,373][root][INFO] - Training Epoch: 2/2, step 3861/7134 completed (loss: 0.1993809938430786, acc: 0.9542483687400818)
[2024-12-17 02:46:51,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:51,625][root][INFO] - Training Epoch: 2/2, step 3862/7134 completed (loss: 0.17546215653419495, acc: 0.9538461565971375)
[2024-12-17 02:46:51,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:51,913][root][INFO] - Training Epoch: 2/2, step 3863/7134 completed (loss: 0.11126989871263504, acc: 0.9651162624359131)
[2024-12-17 02:46:52,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:52,187][root][INFO] - Training Epoch: 2/2, step 3864/7134 completed (loss: 0.15878699719905853, acc: 0.9675324559211731)
[2024-12-17 02:46:52,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:52,461][root][INFO] - Training Epoch: 2/2, step 3865/7134 completed (loss: 0.21468235552310944, acc: 0.9464285969734192)
[2024-12-17 02:46:52,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:52,736][root][INFO] - Training Epoch: 2/2, step 3866/7134 completed (loss: 0.2067580223083496, acc: 0.9300000071525574)
[2024-12-17 02:46:52,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:53,009][root][INFO] - Training Epoch: 2/2, step 3867/7134 completed (loss: 0.12383832782506943, acc: 0.9727272987365723)
[2024-12-17 02:46:53,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:53,269][root][INFO] - Training Epoch: 2/2, step 3868/7134 completed (loss: 0.08626348525285721, acc: 0.9779411554336548)
[2024-12-17 02:46:53,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:53,539][root][INFO] - Training Epoch: 2/2, step 3869/7134 completed (loss: 0.1656370311975479, acc: 0.9580419659614563)
[2024-12-17 02:46:53,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:53,802][root][INFO] - Training Epoch: 2/2, step 3870/7134 completed (loss: 0.3098905086517334, acc: 0.9215686321258545)
[2024-12-17 02:46:53,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:54,068][root][INFO] - Training Epoch: 2/2, step 3871/7134 completed (loss: 0.1930464655160904, acc: 0.959770143032074)
[2024-12-17 02:46:54,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:54,349][root][INFO] - Training Epoch: 2/2, step 3872/7134 completed (loss: 0.15984214842319489, acc: 0.9646464586257935)
[2024-12-17 02:46:54,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:54,639][root][INFO] - Training Epoch: 2/2, step 3873/7134 completed (loss: 0.0943603590130806, acc: 0.9757575988769531)
[2024-12-17 02:46:54,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:54,900][root][INFO] - Training Epoch: 2/2, step 3874/7134 completed (loss: 0.161950021982193, acc: 0.9649122953414917)
[2024-12-17 02:46:55,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:55,183][root][INFO] - Training Epoch: 2/2, step 3875/7134 completed (loss: 0.15999560058116913, acc: 0.9367088675498962)
[2024-12-17 02:46:55,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:55,446][root][INFO] - Training Epoch: 2/2, step 3876/7134 completed (loss: 0.07615714520215988, acc: 0.984000027179718)
[2024-12-17 02:46:55,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:55,728][root][INFO] - Training Epoch: 2/2, step 3877/7134 completed (loss: 0.12022272497415543, acc: 0.9651162624359131)
[2024-12-17 02:46:55,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:55,994][root][INFO] - Training Epoch: 2/2, step 3878/7134 completed (loss: 0.4707929790019989, acc: 0.895348846912384)
[2024-12-17 02:46:56,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:56,274][root][INFO] - Training Epoch: 2/2, step 3879/7134 completed (loss: 0.15682677924633026, acc: 0.9701492786407471)
[2024-12-17 02:46:56,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:56,559][root][INFO] - Training Epoch: 2/2, step 3880/7134 completed (loss: 0.1737169325351715, acc: 0.9615384340286255)
[2024-12-17 02:46:56,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:56,844][root][INFO] - Training Epoch: 2/2, step 3881/7134 completed (loss: 0.3493850529193878, acc: 0.9197860956192017)
[2024-12-17 02:46:56,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:57,139][root][INFO] - Training Epoch: 2/2, step 3882/7134 completed (loss: 0.23713898658752441, acc: 0.9329897165298462)
[2024-12-17 02:46:57,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:57,426][root][INFO] - Training Epoch: 2/2, step 3883/7134 completed (loss: 0.21496696770191193, acc: 0.9542483687400818)
[2024-12-17 02:46:57,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:57,705][root][INFO] - Training Epoch: 2/2, step 3884/7134 completed (loss: 0.1145673468708992, acc: 0.9657142758369446)
[2024-12-17 02:46:57,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:57,967][root][INFO] - Training Epoch: 2/2, step 3885/7134 completed (loss: 0.07671893388032913, acc: 0.9745222926139832)
[2024-12-17 02:46:58,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:58,248][root][INFO] - Training Epoch: 2/2, step 3886/7134 completed (loss: 0.18613718450069427, acc: 0.9417989253997803)
[2024-12-17 02:46:58,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:58,519][root][INFO] - Training Epoch: 2/2, step 3887/7134 completed (loss: 0.1299617737531662, acc: 0.9811320900917053)
[2024-12-17 02:46:58,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:58,800][root][INFO] - Training Epoch: 2/2, step 3888/7134 completed (loss: 0.11730530858039856, acc: 0.9651162624359131)
[2024-12-17 02:46:58,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:59,092][root][INFO] - Training Epoch: 2/2, step 3889/7134 completed (loss: 0.050431568175554276, acc: 0.994350254535675)
[2024-12-17 02:46:59,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:59,377][root][INFO] - Training Epoch: 2/2, step 3890/7134 completed (loss: 0.07868141680955887, acc: 0.9793814420700073)
[2024-12-17 02:46:59,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:59,686][root][INFO] - Training Epoch: 2/2, step 3891/7134 completed (loss: 0.06610551476478577, acc: 0.9884393215179443)
[2024-12-17 02:46:59,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:59,966][root][INFO] - Training Epoch: 2/2, step 3892/7134 completed (loss: 0.2023209035396576, acc: 0.95333331823349)
[2024-12-17 02:47:00,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:00,249][root][INFO] - Training Epoch: 2/2, step 3893/7134 completed (loss: 0.23932334780693054, acc: 0.9484536051750183)
[2024-12-17 02:47:00,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:00,520][root][INFO] - Training Epoch: 2/2, step 3894/7134 completed (loss: 0.08248088508844376, acc: 0.9873417615890503)
[2024-12-17 02:47:00,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:00,801][root][INFO] - Training Epoch: 2/2, step 3895/7134 completed (loss: 0.1824754923582077, acc: 0.9723756909370422)
[2024-12-17 02:47:00,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:01,094][root][INFO] - Training Epoch: 2/2, step 3896/7134 completed (loss: 0.1476152092218399, acc: 0.9573459625244141)
[2024-12-17 02:47:01,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:01,388][root][INFO] - Training Epoch: 2/2, step 3897/7134 completed (loss: 0.31124773621559143, acc: 0.9534883499145508)
[2024-12-17 02:47:01,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:01,658][root][INFO] - Training Epoch: 2/2, step 3898/7134 completed (loss: 0.1434771716594696, acc: 0.9712643623352051)
[2024-12-17 02:47:01,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:01,947][root][INFO] - Training Epoch: 2/2, step 3899/7134 completed (loss: 0.2090768814086914, acc: 0.9479768872261047)
[2024-12-17 02:47:02,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:02,261][root][INFO] - Training Epoch: 2/2, step 3900/7134 completed (loss: 0.14198927581310272, acc: 0.969072163105011)
[2024-12-17 02:47:02,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:02,534][root][INFO] - Training Epoch: 2/2, step 3901/7134 completed (loss: 0.3951335549354553, acc: 0.9397590160369873)
[2024-12-17 02:47:02,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:02,831][root][INFO] - Training Epoch: 2/2, step 3902/7134 completed (loss: 0.2518066465854645, acc: 0.921875)
[2024-12-17 02:47:02,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:03,135][root][INFO] - Training Epoch: 2/2, step 3903/7134 completed (loss: 0.38623273372650146, acc: 0.8963730335235596)
[2024-12-17 02:47:03,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:03,414][root][INFO] - Training Epoch: 2/2, step 3904/7134 completed (loss: 0.24345757067203522, acc: 0.9181286692619324)
[2024-12-17 02:47:03,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:03,727][root][INFO] - Training Epoch: 2/2, step 3905/7134 completed (loss: 0.08877229690551758, acc: 0.9833333492279053)
[2024-12-17 02:47:03,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:04,015][root][INFO] - Training Epoch: 2/2, step 3906/7134 completed (loss: 0.10246814042329788, acc: 0.9550561904907227)
[2024-12-17 02:47:04,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:04,284][root][INFO] - Training Epoch: 2/2, step 3907/7134 completed (loss: 0.1454865038394928, acc: 0.9536082744598389)
[2024-12-17 02:47:04,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:04,567][root][INFO] - Training Epoch: 2/2, step 3908/7134 completed (loss: 0.3744809329509735, acc: 0.9017341136932373)
[2024-12-17 02:47:04,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:04,868][root][INFO] - Training Epoch: 2/2, step 3909/7134 completed (loss: 0.16476458311080933, acc: 0.955974817276001)
[2024-12-17 02:47:05,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:05,146][root][INFO] - Training Epoch: 2/2, step 3910/7134 completed (loss: 0.15976965427398682, acc: 0.9375)
[2024-12-17 02:47:05,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:05,434][root][INFO] - Training Epoch: 2/2, step 3911/7134 completed (loss: 0.18164345622062683, acc: 0.9748427867889404)
[2024-12-17 02:47:05,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:05,706][root][INFO] - Training Epoch: 2/2, step 3912/7134 completed (loss: 0.034989386796951294, acc: 0.9941176176071167)
[2024-12-17 02:47:05,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:06,003][root][INFO] - Training Epoch: 2/2, step 3913/7134 completed (loss: 0.12948733568191528, acc: 0.9747474789619446)
[2024-12-17 02:47:06,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:06,273][root][INFO] - Training Epoch: 2/2, step 3914/7134 completed (loss: 0.1275593489408493, acc: 0.9685534834861755)
[2024-12-17 02:47:06,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:06,549][root][INFO] - Training Epoch: 2/2, step 3915/7134 completed (loss: 0.14800840616226196, acc: 0.959770143032074)
[2024-12-17 02:47:06,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:06,855][root][INFO] - Training Epoch: 2/2, step 3916/7134 completed (loss: 0.13902264833450317, acc: 0.9693877696990967)
[2024-12-17 02:47:06,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:07,139][root][INFO] - Training Epoch: 2/2, step 3917/7134 completed (loss: 0.055687855929136276, acc: 0.9906976819038391)
[2024-12-17 02:47:07,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:07,434][root][INFO] - Training Epoch: 2/2, step 3918/7134 completed (loss: 0.16250477731227875, acc: 0.9666666388511658)
[2024-12-17 02:47:07,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:07,717][root][INFO] - Training Epoch: 2/2, step 3919/7134 completed (loss: 0.3053470253944397, acc: 0.9526627063751221)
[2024-12-17 02:47:07,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:07,991][root][INFO] - Training Epoch: 2/2, step 3920/7134 completed (loss: 0.3842826783657074, acc: 0.910179615020752)
[2024-12-17 02:47:08,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:08,281][root][INFO] - Training Epoch: 2/2, step 3921/7134 completed (loss: 0.2597786784172058, acc: 0.9366196990013123)
[2024-12-17 02:47:08,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:08,556][root][INFO] - Training Epoch: 2/2, step 3922/7134 completed (loss: 0.40899813175201416, acc: 0.9025974273681641)
[2024-12-17 02:47:08,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:08,881][root][INFO] - Training Epoch: 2/2, step 3923/7134 completed (loss: 0.47795408964157104, acc: 0.886904776096344)
[2024-12-17 02:47:09,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:09,169][root][INFO] - Training Epoch: 2/2, step 3924/7134 completed (loss: 0.29311662912368774, acc: 0.907216489315033)
[2024-12-17 02:47:09,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:09,436][root][INFO] - Training Epoch: 2/2, step 3925/7134 completed (loss: 0.19069886207580566, acc: 0.9558011293411255)
[2024-12-17 02:47:09,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:09,709][root][INFO] - Training Epoch: 2/2, step 3926/7134 completed (loss: 0.14662306010723114, acc: 0.9556962251663208)
[2024-12-17 02:47:09,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:10,000][root][INFO] - Training Epoch: 2/2, step 3927/7134 completed (loss: 0.15640807151794434, acc: 0.9636363387107849)
[2024-12-17 02:47:10,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:10,285][root][INFO] - Training Epoch: 2/2, step 3928/7134 completed (loss: 0.3230418264865875, acc: 0.9341317415237427)
[2024-12-17 02:47:10,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:10,555][root][INFO] - Training Epoch: 2/2, step 3929/7134 completed (loss: 0.15396201610565186, acc: 0.9545454382896423)
[2024-12-17 02:47:10,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:10,842][root][INFO] - Training Epoch: 2/2, step 3930/7134 completed (loss: 0.25028201937675476, acc: 0.9406779408454895)
[2024-12-17 02:47:10,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:11,115][root][INFO] - Training Epoch: 2/2, step 3931/7134 completed (loss: 0.10213125497102737, acc: 0.9620253443717957)
[2024-12-17 02:47:11,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:11,398][root][INFO] - Training Epoch: 2/2, step 3932/7134 completed (loss: 0.08249188959598541, acc: 0.9818181991577148)
[2024-12-17 02:47:11,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:11,678][root][INFO] - Training Epoch: 2/2, step 3933/7134 completed (loss: 0.04865775629878044, acc: 0.9857142567634583)
[2024-12-17 02:47:11,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:11,945][root][INFO] - Training Epoch: 2/2, step 3934/7134 completed (loss: 0.10862059146165848, acc: 0.9722222089767456)
[2024-12-17 02:47:12,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:12,228][root][INFO] - Training Epoch: 2/2, step 3935/7134 completed (loss: 0.07154395431280136, acc: 0.9726027250289917)
[2024-12-17 02:47:12,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:12,524][root][INFO] - Training Epoch: 2/2, step 3936/7134 completed (loss: 0.13133183121681213, acc: 0.9596773982048035)
[2024-12-17 02:47:12,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:12,799][root][INFO] - Training Epoch: 2/2, step 3937/7134 completed (loss: 0.3057560920715332, acc: 0.9322034120559692)
[2024-12-17 02:47:12,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:13,052][root][INFO] - Training Epoch: 2/2, step 3938/7134 completed (loss: 0.17351029813289642, acc: 0.954954981803894)
[2024-12-17 02:47:13,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:13,327][root][INFO] - Training Epoch: 2/2, step 3939/7134 completed (loss: 0.2592049539089203, acc: 0.9333333373069763)
[2024-12-17 02:47:13,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:13,576][root][INFO] - Training Epoch: 2/2, step 3940/7134 completed (loss: 0.21659129858016968, acc: 0.9239130616188049)
[2024-12-17 02:47:13,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:13,815][root][INFO] - Training Epoch: 2/2, step 3941/7134 completed (loss: 0.19088928401470184, acc: 0.9390243887901306)
[2024-12-17 02:47:13,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:14,079][root][INFO] - Training Epoch: 2/2, step 3942/7134 completed (loss: 0.16983376443386078, acc: 0.9599999785423279)
[2024-12-17 02:47:14,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:14,322][root][INFO] - Training Epoch: 2/2, step 3943/7134 completed (loss: 0.11055240780115128, acc: 0.9577465057373047)
[2024-12-17 02:47:14,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:14,590][root][INFO] - Training Epoch: 2/2, step 3944/7134 completed (loss: 0.19133658707141876, acc: 0.9477611780166626)
[2024-12-17 02:47:14,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:14,868][root][INFO] - Training Epoch: 2/2, step 3945/7134 completed (loss: 0.06985558569431305, acc: 0.9934210777282715)
[2024-12-17 02:47:14,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:15,122][root][INFO] - Training Epoch: 2/2, step 3946/7134 completed (loss: 0.06418628245592117, acc: 0.9910714030265808)
[2024-12-17 02:47:15,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:15,366][root][INFO] - Training Epoch: 2/2, step 3947/7134 completed (loss: 0.07634645700454712, acc: 0.9890109896659851)
[2024-12-17 02:47:15,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:15,635][root][INFO] - Training Epoch: 2/2, step 3948/7134 completed (loss: 0.05144264176487923, acc: 0.9800000190734863)
[2024-12-17 02:47:15,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:15,914][root][INFO] - Training Epoch: 2/2, step 3949/7134 completed (loss: 0.19620376825332642, acc: 0.9453125)
[2024-12-17 02:47:16,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:16,164][root][INFO] - Training Epoch: 2/2, step 3950/7134 completed (loss: 0.14452466368675232, acc: 0.9736841917037964)
[2024-12-17 02:47:16,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:16,436][root][INFO] - Training Epoch: 2/2, step 3951/7134 completed (loss: 0.05595465376973152, acc: 0.9896907210350037)
[2024-12-17 02:47:16,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:16,699][root][INFO] - Training Epoch: 2/2, step 3952/7134 completed (loss: 0.12387645244598389, acc: 0.9693877696990967)
[2024-12-17 02:47:16,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:16,965][root][INFO] - Training Epoch: 2/2, step 3953/7134 completed (loss: 0.07509920001029968, acc: 0.97826087474823)
[2024-12-17 02:47:17,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:17,219][root][INFO] - Training Epoch: 2/2, step 3954/7134 completed (loss: 0.042359739542007446, acc: 0.9896907210350037)
[2024-12-17 02:47:17,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:17,480][root][INFO] - Training Epoch: 2/2, step 3955/7134 completed (loss: 0.07758957892656326, acc: 0.9842519760131836)
[2024-12-17 02:47:17,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:17,746][root][INFO] - Training Epoch: 2/2, step 3956/7134 completed (loss: 0.13110746443271637, acc: 0.9673202633857727)
[2024-12-17 02:47:17,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:18,013][root][INFO] - Training Epoch: 2/2, step 3957/7134 completed (loss: 0.08923470973968506, acc: 0.9658119678497314)
[2024-12-17 02:47:18,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:18,279][root][INFO] - Training Epoch: 2/2, step 3958/7134 completed (loss: 0.12544481456279755, acc: 0.9642857313156128)
[2024-12-17 02:47:18,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:18,561][root][INFO] - Training Epoch: 2/2, step 3959/7134 completed (loss: 0.0526810958981514, acc: 0.9913793206214905)
[2024-12-17 02:47:18,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:18,845][root][INFO] - Training Epoch: 2/2, step 3960/7134 completed (loss: 0.12993474304676056, acc: 0.9497206807136536)
[2024-12-17 02:47:18,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:19,142][root][INFO] - Training Epoch: 2/2, step 3961/7134 completed (loss: 0.08183887600898743, acc: 0.9753086566925049)
[2024-12-17 02:47:19,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:19,420][root][INFO] - Training Epoch: 2/2, step 3962/7134 completed (loss: 0.12754440307617188, acc: 0.9597315192222595)
[2024-12-17 02:47:19,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:19,718][root][INFO] - Training Epoch: 2/2, step 3963/7134 completed (loss: 0.31093674898147583, acc: 0.929347813129425)
[2024-12-17 02:47:19,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:20,002][root][INFO] - Training Epoch: 2/2, step 3964/7134 completed (loss: 0.25639960169792175, acc: 0.9461538195610046)
[2024-12-17 02:47:20,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:20,280][root][INFO] - Training Epoch: 2/2, step 3965/7134 completed (loss: 0.17265838384628296, acc: 0.9696969985961914)
[2024-12-17 02:47:20,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:20,562][root][INFO] - Training Epoch: 2/2, step 3966/7134 completed (loss: 0.08367737382650375, acc: 0.9921875)
[2024-12-17 02:47:20,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:20,843][root][INFO] - Training Epoch: 2/2, step 3967/7134 completed (loss: 0.4081175923347473, acc: 0.9202898740768433)
[2024-12-17 02:47:20,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:21,128][root][INFO] - Training Epoch: 2/2, step 3968/7134 completed (loss: 0.06181396171450615, acc: 0.9832402467727661)
[2024-12-17 02:47:21,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:21,370][root][INFO] - Training Epoch: 2/2, step 3969/7134 completed (loss: 0.2618500292301178, acc: 0.9150943160057068)
[2024-12-17 02:47:21,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:21,645][root][INFO] - Training Epoch: 2/2, step 3970/7134 completed (loss: 0.27388685941696167, acc: 0.9537572264671326)
[2024-12-17 02:47:21,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:21,932][root][INFO] - Training Epoch: 2/2, step 3971/7134 completed (loss: 0.6603541374206543, acc: 0.8666666746139526)
[2024-12-17 02:47:22,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:22,214][root][INFO] - Training Epoch: 2/2, step 3972/7134 completed (loss: 0.8206750154495239, acc: 0.8269230723381042)
[2024-12-17 02:47:22,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:22,492][root][INFO] - Training Epoch: 2/2, step 3973/7134 completed (loss: 0.2682064175605774, acc: 0.9436619877815247)
[2024-12-17 02:47:22,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:22,774][root][INFO] - Training Epoch: 2/2, step 3974/7134 completed (loss: 0.36238035559654236, acc: 0.9025641083717346)
[2024-12-17 02:47:22,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:23,045][root][INFO] - Training Epoch: 2/2, step 3975/7134 completed (loss: 0.28206953406333923, acc: 0.9142857193946838)
[2024-12-17 02:47:23,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:23,328][root][INFO] - Training Epoch: 2/2, step 3976/7134 completed (loss: 0.48064014315605164, acc: 0.8855421543121338)
[2024-12-17 02:47:23,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:23,598][root][INFO] - Training Epoch: 2/2, step 3977/7134 completed (loss: 0.14473062753677368, acc: 0.95652174949646)
[2024-12-17 02:47:23,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:23,868][root][INFO] - Training Epoch: 2/2, step 3978/7134 completed (loss: 0.19623641669750214, acc: 0.96517413854599)
[2024-12-17 02:47:23,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:24,148][root][INFO] - Training Epoch: 2/2, step 3979/7134 completed (loss: 0.20663800835609436, acc: 0.9416058659553528)
[2024-12-17 02:47:24,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:24,430][root][INFO] - Training Epoch: 2/2, step 3980/7134 completed (loss: 0.1114913672208786, acc: 0.9677419066429138)
[2024-12-17 02:47:24,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:24,697][root][INFO] - Training Epoch: 2/2, step 3981/7134 completed (loss: 0.20872598886489868, acc: 0.9457831382751465)
[2024-12-17 02:47:24,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:24,978][root][INFO] - Training Epoch: 2/2, step 3982/7134 completed (loss: 0.4719301164150238, acc: 0.8895348906517029)
[2024-12-17 02:47:25,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:25,251][root][INFO] - Training Epoch: 2/2, step 3983/7134 completed (loss: 1.0832626819610596, acc: 0.7829457521438599)
[2024-12-17 02:47:25,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:25,537][root][INFO] - Training Epoch: 2/2, step 3984/7134 completed (loss: 0.4335937798023224, acc: 0.8989361524581909)
[2024-12-17 02:47:25,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:25,825][root][INFO] - Training Epoch: 2/2, step 3985/7134 completed (loss: 0.11247414350509644, acc: 0.9769230484962463)
[2024-12-17 02:47:25,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:26,106][root][INFO] - Training Epoch: 2/2, step 3986/7134 completed (loss: 0.656101644039154, acc: 0.8636363744735718)
[2024-12-17 02:47:26,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:26,377][root][INFO] - Training Epoch: 2/2, step 3987/7134 completed (loss: 0.35714012384414673, acc: 0.9047619104385376)
[2024-12-17 02:47:26,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:26,657][root][INFO] - Training Epoch: 2/2, step 3988/7134 completed (loss: 0.34723320603370667, acc: 0.9330143332481384)
[2024-12-17 02:47:26,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:26,908][root][INFO] - Training Epoch: 2/2, step 3989/7134 completed (loss: 0.446806401014328, acc: 0.8925619721412659)
[2024-12-17 02:47:27,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:27,201][root][INFO] - Training Epoch: 2/2, step 3990/7134 completed (loss: 0.3527544438838959, acc: 0.9139072895050049)
[2024-12-17 02:47:27,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:27,476][root][INFO] - Training Epoch: 2/2, step 3991/7134 completed (loss: 0.18218250572681427, acc: 0.9599999785423279)
[2024-12-17 02:47:27,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:27,751][root][INFO] - Training Epoch: 2/2, step 3992/7134 completed (loss: 0.20060178637504578, acc: 0.9560439586639404)
[2024-12-17 02:47:27,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:28,021][root][INFO] - Training Epoch: 2/2, step 3993/7134 completed (loss: 0.2863185703754425, acc: 0.9444444179534912)
[2024-12-17 02:47:28,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:28,290][root][INFO] - Training Epoch: 2/2, step 3994/7134 completed (loss: 0.2779618799686432, acc: 0.9411764740943909)
[2024-12-17 02:47:28,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:28,554][root][INFO] - Training Epoch: 2/2, step 3995/7134 completed (loss: 0.3914784789085388, acc: 0.8837209343910217)
[2024-12-17 02:47:28,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:28,815][root][INFO] - Training Epoch: 2/2, step 3996/7134 completed (loss: 0.30442357063293457, acc: 0.942148745059967)
[2024-12-17 02:47:28,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:29,088][root][INFO] - Training Epoch: 2/2, step 3997/7134 completed (loss: 0.3415559232234955, acc: 0.9051724076271057)
[2024-12-17 02:47:29,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:29,340][root][INFO] - Training Epoch: 2/2, step 3998/7134 completed (loss: 0.27953028678894043, acc: 0.9230769276618958)
[2024-12-17 02:47:29,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:29,641][root][INFO] - Training Epoch: 2/2, step 3999/7134 completed (loss: 0.2097529023885727, acc: 0.9435483813285828)
[2024-12-17 02:47:29,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:29,908][root][INFO] - Training Epoch: 2/2, step 4000/7134 completed (loss: 0.2021922618150711, acc: 0.9512194991111755)
[2024-12-17 02:47:30,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:30,180][root][INFO] - Training Epoch: 2/2, step 4001/7134 completed (loss: 0.37794381380081177, acc: 0.9032257795333862)
[2024-12-17 02:47:30,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:30,451][root][INFO] - Training Epoch: 2/2, step 4002/7134 completed (loss: 0.5171938538551331, acc: 0.9065420627593994)
[2024-12-17 02:47:30,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:30,743][root][INFO] - Training Epoch: 2/2, step 4003/7134 completed (loss: 0.3851355016231537, acc: 0.8947368264198303)
[2024-12-17 02:47:30,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:30,997][root][INFO] - Training Epoch: 2/2, step 4004/7134 completed (loss: 0.2660602629184723, acc: 0.9200000166893005)
[2024-12-17 02:47:31,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:31,255][root][INFO] - Training Epoch: 2/2, step 4005/7134 completed (loss: 0.11048250645399094, acc: 0.9738562107086182)
[2024-12-17 02:47:31,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:31,542][root][INFO] - Training Epoch: 2/2, step 4006/7134 completed (loss: 0.07408741861581802, acc: 0.9864864945411682)
[2024-12-17 02:47:31,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:31,815][root][INFO] - Training Epoch: 2/2, step 4007/7134 completed (loss: 0.13347271084785461, acc: 0.976190447807312)
[2024-12-17 02:47:31,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:32,118][root][INFO] - Training Epoch: 2/2, step 4008/7134 completed (loss: 0.08307980746030807, acc: 0.9820627570152283)
[2024-12-17 02:47:32,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:32,395][root][INFO] - Training Epoch: 2/2, step 4009/7134 completed (loss: 0.08800950646400452, acc: 0.9776536226272583)
[2024-12-17 02:47:32,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:32,676][root][INFO] - Training Epoch: 2/2, step 4010/7134 completed (loss: 0.09928255528211594, acc: 0.9712918400764465)
[2024-12-17 02:47:32,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:32,961][root][INFO] - Training Epoch: 2/2, step 4011/7134 completed (loss: 0.17177224159240723, acc: 0.9485714435577393)
[2024-12-17 02:47:33,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:33,220][root][INFO] - Training Epoch: 2/2, step 4012/7134 completed (loss: 0.08282846212387085, acc: 0.9819276928901672)
[2024-12-17 02:47:33,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:33,491][root][INFO] - Training Epoch: 2/2, step 4013/7134 completed (loss: 0.028366565704345703, acc: 1.0)
[2024-12-17 02:47:33,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:33,772][root][INFO] - Training Epoch: 2/2, step 4014/7134 completed (loss: 0.10703804343938828, acc: 0.9733333587646484)
[2024-12-17 02:47:33,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:34,049][root][INFO] - Training Epoch: 2/2, step 4015/7134 completed (loss: 0.04228264465928078, acc: 0.9862068891525269)
[2024-12-17 02:47:34,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:34,346][root][INFO] - Training Epoch: 2/2, step 4016/7134 completed (loss: 0.26011088490486145, acc: 0.9481865167617798)
[2024-12-17 02:47:34,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:34,630][root][INFO] - Training Epoch: 2/2, step 4017/7134 completed (loss: 0.16436144709587097, acc: 0.9536082744598389)
[2024-12-17 02:47:34,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:34,912][root][INFO] - Training Epoch: 2/2, step 4018/7134 completed (loss: 0.2028908133506775, acc: 0.9420289993286133)
[2024-12-17 02:47:35,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:35,200][root][INFO] - Training Epoch: 2/2, step 4019/7134 completed (loss: 0.10719344019889832, acc: 0.9722222089767456)
[2024-12-17 02:47:35,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:35,463][root][INFO] - Training Epoch: 2/2, step 4020/7134 completed (loss: 0.11282222718000412, acc: 0.9715909361839294)
[2024-12-17 02:47:35,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:35,705][root][INFO] - Training Epoch: 2/2, step 4021/7134 completed (loss: 0.05117075890302658, acc: 0.9852941036224365)
[2024-12-17 02:47:35,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:36,004][root][INFO] - Training Epoch: 2/2, step 4022/7134 completed (loss: 0.1185980960726738, acc: 0.9615384340286255)
[2024-12-17 02:47:36,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:36,297][root][INFO] - Training Epoch: 2/2, step 4023/7134 completed (loss: 0.15682053565979004, acc: 0.954285740852356)
[2024-12-17 02:47:36,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:36,569][root][INFO] - Training Epoch: 2/2, step 4024/7134 completed (loss: 0.15958257019519806, acc: 0.9367815852165222)
[2024-12-17 02:47:36,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:36,838][root][INFO] - Training Epoch: 2/2, step 4025/7134 completed (loss: 0.1925351768732071, acc: 0.9581151604652405)
[2024-12-17 02:47:36,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:37,110][root][INFO] - Training Epoch: 2/2, step 4026/7134 completed (loss: 0.2887307405471802, acc: 0.9440993666648865)
[2024-12-17 02:47:37,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:37,395][root][INFO] - Training Epoch: 2/2, step 4027/7134 completed (loss: 0.19440752267837524, acc: 0.9382022619247437)
[2024-12-17 02:47:37,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:37,667][root][INFO] - Training Epoch: 2/2, step 4028/7134 completed (loss: 0.2553388774394989, acc: 0.9055117964744568)
[2024-12-17 02:47:37,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:37,955][root][INFO] - Training Epoch: 2/2, step 4029/7134 completed (loss: 0.1352560967206955, acc: 0.9675675630569458)
[2024-12-17 02:47:38,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:38,221][root][INFO] - Training Epoch: 2/2, step 4030/7134 completed (loss: 0.1320364773273468, acc: 0.9519230723381042)
[2024-12-17 02:47:38,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:38,505][root][INFO] - Training Epoch: 2/2, step 4031/7134 completed (loss: 0.07221567630767822, acc: 0.9813664555549622)
[2024-12-17 02:47:38,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:38,775][root][INFO] - Training Epoch: 2/2, step 4032/7134 completed (loss: 0.1081271693110466, acc: 0.9534883499145508)
[2024-12-17 02:47:38,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:39,027][root][INFO] - Training Epoch: 2/2, step 4033/7134 completed (loss: 0.07865245640277863, acc: 0.9679144620895386)
[2024-12-17 02:47:39,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:39,296][root][INFO] - Training Epoch: 2/2, step 4034/7134 completed (loss: 0.0597195103764534, acc: 0.9846938848495483)
[2024-12-17 02:47:39,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:39,608][root][INFO] - Training Epoch: 2/2, step 4035/7134 completed (loss: 0.3594299256801605, acc: 0.9219512343406677)
[2024-12-17 02:47:39,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:39,871][root][INFO] - Training Epoch: 2/2, step 4036/7134 completed (loss: 0.16649432480335236, acc: 0.9538461565971375)
[2024-12-17 02:47:39,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:40,157][root][INFO] - Training Epoch: 2/2, step 4037/7134 completed (loss: 0.18549799919128418, acc: 0.9479166865348816)
[2024-12-17 02:47:40,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:40,427][root][INFO] - Training Epoch: 2/2, step 4038/7134 completed (loss: 0.2175953984260559, acc: 0.9431818127632141)
[2024-12-17 02:47:40,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:40,675][root][INFO] - Training Epoch: 2/2, step 4039/7134 completed (loss: 0.3190498948097229, acc: 0.9289940595626831)
[2024-12-17 02:47:40,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:40,945][root][INFO] - Training Epoch: 2/2, step 4040/7134 completed (loss: 0.09512408077716827, acc: 0.9890710115432739)
[2024-12-17 02:47:41,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:41,223][root][INFO] - Training Epoch: 2/2, step 4041/7134 completed (loss: 0.17663459479808807, acc: 0.9653179049491882)
[2024-12-17 02:47:41,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:41,492][root][INFO] - Training Epoch: 2/2, step 4042/7134 completed (loss: 0.15373890101909637, acc: 0.9729729890823364)
[2024-12-17 02:47:41,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:41,732][root][INFO] - Training Epoch: 2/2, step 4043/7134 completed (loss: 0.22192397713661194, acc: 0.9430379867553711)
[2024-12-17 02:47:41,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:41,997][root][INFO] - Training Epoch: 2/2, step 4044/7134 completed (loss: 0.12424839287996292, acc: 0.9780219793319702)
[2024-12-17 02:47:42,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:42,273][root][INFO] - Training Epoch: 2/2, step 4045/7134 completed (loss: 0.15076760947704315, acc: 0.9599999785423279)
[2024-12-17 02:47:42,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:42,548][root][INFO] - Training Epoch: 2/2, step 4046/7134 completed (loss: 0.21404163539409637, acc: 0.9415204524993896)
[2024-12-17 02:47:42,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:42,835][root][INFO] - Training Epoch: 2/2, step 4047/7134 completed (loss: 0.1597175896167755, acc: 0.9562841653823853)
[2024-12-17 02:47:42,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:43,118][root][INFO] - Training Epoch: 2/2, step 4048/7134 completed (loss: 0.0773937851190567, acc: 0.9847715497016907)
[2024-12-17 02:47:43,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:43,404][root][INFO] - Training Epoch: 2/2, step 4049/7134 completed (loss: 0.3012961745262146, acc: 0.93034827709198)
[2024-12-17 02:47:43,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:43,671][root][INFO] - Training Epoch: 2/2, step 4050/7134 completed (loss: 0.18306979537010193, acc: 0.949999988079071)
[2024-12-17 02:47:43,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:43,948][root][INFO] - Training Epoch: 2/2, step 4051/7134 completed (loss: 0.24416038393974304, acc: 0.9553072452545166)
[2024-12-17 02:47:44,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:44,195][root][INFO] - Training Epoch: 2/2, step 4052/7134 completed (loss: 0.1425991803407669, acc: 0.9548022747039795)
[2024-12-17 02:47:44,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:44,462][root][INFO] - Training Epoch: 2/2, step 4053/7134 completed (loss: 0.20407746732234955, acc: 0.9345238208770752)
[2024-12-17 02:47:44,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:44,742][root][INFO] - Training Epoch: 2/2, step 4054/7134 completed (loss: 0.28826281428337097, acc: 0.939130425453186)
[2024-12-17 02:47:44,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:45,023][root][INFO] - Training Epoch: 2/2, step 4055/7134 completed (loss: 0.12479136139154434, acc: 0.978723406791687)
[2024-12-17 02:47:45,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:45,307][root][INFO] - Training Epoch: 2/2, step 4056/7134 completed (loss: 0.11962810158729553, acc: 0.9842105507850647)
[2024-12-17 02:47:45,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:45,584][root][INFO] - Training Epoch: 2/2, step 4057/7134 completed (loss: 0.1870090663433075, acc: 0.9647058844566345)
[2024-12-17 02:47:45,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:45,837][root][INFO] - Training Epoch: 2/2, step 4058/7134 completed (loss: 0.2723407447338104, acc: 0.9166666865348816)
[2024-12-17 02:47:45,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:46,110][root][INFO] - Training Epoch: 2/2, step 4059/7134 completed (loss: 0.07101020961999893, acc: 0.9850746393203735)
[2024-12-17 02:47:46,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:46,371][root][INFO] - Training Epoch: 2/2, step 4060/7134 completed (loss: 0.05762935429811478, acc: 0.9932432174682617)
[2024-12-17 02:47:46,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:46,654][root][INFO] - Training Epoch: 2/2, step 4061/7134 completed (loss: 0.037503432482481, acc: 0.9883720874786377)
[2024-12-17 02:47:46,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:46,918][root][INFO] - Training Epoch: 2/2, step 4062/7134 completed (loss: 0.06303107738494873, acc: 0.9868420958518982)
[2024-12-17 02:47:47,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:47,169][root][INFO] - Training Epoch: 2/2, step 4063/7134 completed (loss: 0.08519092947244644, acc: 0.9774436354637146)
[2024-12-17 02:47:47,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:47,452][root][INFO] - Training Epoch: 2/2, step 4064/7134 completed (loss: 0.05841142311692238, acc: 0.9869281053543091)
[2024-12-17 02:47:47,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:47,738][root][INFO] - Training Epoch: 2/2, step 4065/7134 completed (loss: 0.07285214960575104, acc: 0.9741935729980469)
[2024-12-17 02:47:47,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:48,033][root][INFO] - Training Epoch: 2/2, step 4066/7134 completed (loss: 0.04576810449361801, acc: 0.9934640526771545)
[2024-12-17 02:47:48,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:48,310][root][INFO] - Training Epoch: 2/2, step 4067/7134 completed (loss: 0.12494915723800659, acc: 0.965753436088562)
[2024-12-17 02:47:48,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:48,586][root][INFO] - Training Epoch: 2/2, step 4068/7134 completed (loss: 0.2749301493167877, acc: 0.9173553586006165)
[2024-12-17 02:47:48,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:48,856][root][INFO] - Training Epoch: 2/2, step 4069/7134 completed (loss: 0.055575933307409286, acc: 0.9788732528686523)
[2024-12-17 02:47:48,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:49,131][root][INFO] - Training Epoch: 2/2, step 4070/7134 completed (loss: 0.15987591445446014, acc: 0.9470198750495911)
[2024-12-17 02:47:49,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:49,394][root][INFO] - Training Epoch: 2/2, step 4071/7134 completed (loss: 0.0570908822119236, acc: 0.9794520735740662)
[2024-12-17 02:47:49,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:49,695][root][INFO] - Training Epoch: 2/2, step 4072/7134 completed (loss: 0.10176956653594971, acc: 0.9756097793579102)
[2024-12-17 02:47:49,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:49,981][root][INFO] - Training Epoch: 2/2, step 4073/7134 completed (loss: 0.04754897207021713, acc: 0.9819276928901672)
[2024-12-17 02:47:50,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:50,263][root][INFO] - Training Epoch: 2/2, step 4074/7134 completed (loss: 0.06923976540565491, acc: 0.9867549538612366)
[2024-12-17 02:47:50,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:50,550][root][INFO] - Training Epoch: 2/2, step 4075/7134 completed (loss: 0.03219480812549591, acc: 0.9933333396911621)
[2024-12-17 02:47:50,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:50,834][root][INFO] - Training Epoch: 2/2, step 4076/7134 completed (loss: 0.05769052729010582, acc: 0.9878048896789551)
[2024-12-17 02:47:50,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:51,120][root][INFO] - Training Epoch: 2/2, step 4077/7134 completed (loss: 0.11622082442045212, acc: 0.9727891087532043)
[2024-12-17 02:47:51,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:51,402][root][INFO] - Training Epoch: 2/2, step 4078/7134 completed (loss: 0.11729405075311661, acc: 0.9748427867889404)
[2024-12-17 02:47:51,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:51,655][root][INFO] - Training Epoch: 2/2, step 4079/7134 completed (loss: 0.0985594242811203, acc: 0.9847328066825867)
[2024-12-17 02:47:51,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:51,909][root][INFO] - Training Epoch: 2/2, step 4080/7134 completed (loss: 0.03964778035879135, acc: 0.9931034445762634)
[2024-12-17 02:47:52,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:52,171][root][INFO] - Training Epoch: 2/2, step 4081/7134 completed (loss: 0.030423955991864204, acc: 0.9930555820465088)
[2024-12-17 02:47:52,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:52,441][root][INFO] - Training Epoch: 2/2, step 4082/7134 completed (loss: 0.30602145195007324, acc: 0.9342105388641357)
[2024-12-17 02:47:52,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:52,716][root][INFO] - Training Epoch: 2/2, step 4083/7134 completed (loss: 0.3581695258617401, acc: 0.9181286692619324)
[2024-12-17 02:47:52,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:52,987][root][INFO] - Training Epoch: 2/2, step 4084/7134 completed (loss: 0.38946887850761414, acc: 0.8859060406684875)
[2024-12-17 02:47:53,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:53,260][root][INFO] - Training Epoch: 2/2, step 4085/7134 completed (loss: 0.1516255885362625, acc: 0.9631578922271729)
[2024-12-17 02:47:53,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:53,536][root][INFO] - Training Epoch: 2/2, step 4086/7134 completed (loss: 0.3709198534488678, acc: 0.9230769276618958)
[2024-12-17 02:47:53,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:53,823][root][INFO] - Training Epoch: 2/2, step 4087/7134 completed (loss: 0.08937923610210419, acc: 0.9892473220825195)
[2024-12-17 02:47:53,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:54,103][root][INFO] - Training Epoch: 2/2, step 4088/7134 completed (loss: 0.2796003222465515, acc: 0.9238578677177429)
[2024-12-17 02:47:54,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:54,378][root][INFO] - Training Epoch: 2/2, step 4089/7134 completed (loss: 0.30374693870544434, acc: 0.9242424368858337)
[2024-12-17 02:47:54,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:54,652][root][INFO] - Training Epoch: 2/2, step 4090/7134 completed (loss: 0.49660930037498474, acc: 0.8947368264198303)
[2024-12-17 02:47:54,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:54,930][root][INFO] - Training Epoch: 2/2, step 4091/7134 completed (loss: 0.6288429498672485, acc: 0.8595505356788635)
[2024-12-17 02:47:55,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:55,213][root][INFO] - Training Epoch: 2/2, step 4092/7134 completed (loss: 0.17997601628303528, acc: 0.963350772857666)
[2024-12-17 02:47:55,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:55,474][root][INFO] - Training Epoch: 2/2, step 4093/7134 completed (loss: 0.12177377939224243, acc: 0.9599999785423279)
[2024-12-17 02:47:55,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:55,754][root][INFO] - Training Epoch: 2/2, step 4094/7134 completed (loss: 0.2953539490699768, acc: 0.9207317233085632)
[2024-12-17 02:47:55,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:56,049][root][INFO] - Training Epoch: 2/2, step 4095/7134 completed (loss: 0.11549258232116699, acc: 0.987261176109314)
[2024-12-17 02:47:56,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:56,312][root][INFO] - Training Epoch: 2/2, step 4096/7134 completed (loss: 0.29283031821250916, acc: 0.9090909361839294)
[2024-12-17 02:47:56,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:56,609][root][INFO] - Training Epoch: 2/2, step 4097/7134 completed (loss: 0.1730126291513443, acc: 0.9466666579246521)
[2024-12-17 02:47:56,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:56,888][root][INFO] - Training Epoch: 2/2, step 4098/7134 completed (loss: 0.1470964103937149, acc: 0.959770143032074)
[2024-12-17 02:47:57,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:57,168][root][INFO] - Training Epoch: 2/2, step 4099/7134 completed (loss: 0.15128391981124878, acc: 0.9696969985961914)
[2024-12-17 02:47:57,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:57,482][root][INFO] - Training Epoch: 2/2, step 4100/7134 completed (loss: 0.038559649139642715, acc: 0.9934640526771545)
[2024-12-17 02:47:57,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:57,754][root][INFO] - Training Epoch: 2/2, step 4101/7134 completed (loss: 0.14607317745685577, acc: 0.9599999785423279)
[2024-12-17 02:47:57,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:58,034][root][INFO] - Training Epoch: 2/2, step 4102/7134 completed (loss: 0.15283238887786865, acc: 0.9674796462059021)
[2024-12-17 02:47:58,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:58,314][root][INFO] - Training Epoch: 2/2, step 4103/7134 completed (loss: 0.08653020113706589, acc: 0.9673202633857727)
[2024-12-17 02:47:58,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:58,586][root][INFO] - Training Epoch: 2/2, step 4104/7134 completed (loss: 0.12726567685604095, acc: 0.9637681245803833)
[2024-12-17 02:47:58,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:58,868][root][INFO] - Training Epoch: 2/2, step 4105/7134 completed (loss: 0.07542264461517334, acc: 0.9866666793823242)
[2024-12-17 02:47:59,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:59,149][root][INFO] - Training Epoch: 2/2, step 4106/7134 completed (loss: 0.12524615228176117, acc: 0.9659863710403442)
[2024-12-17 02:47:59,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:59,417][root][INFO] - Training Epoch: 2/2, step 4107/7134 completed (loss: 0.18839362263679504, acc: 0.9338235259056091)
[2024-12-17 02:47:59,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:59,682][root][INFO] - Training Epoch: 2/2, step 4108/7134 completed (loss: 0.09324125200510025, acc: 0.9795918464660645)
[2024-12-17 02:47:59,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:59,958][root][INFO] - Training Epoch: 2/2, step 4109/7134 completed (loss: 0.07666771113872528, acc: 0.9795918464660645)
[2024-12-17 02:48:00,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:00,226][root][INFO] - Training Epoch: 2/2, step 4110/7134 completed (loss: 0.02707427367568016, acc: 1.0)
[2024-12-17 02:48:00,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:00,510][root][INFO] - Training Epoch: 2/2, step 4111/7134 completed (loss: 0.10064829885959625, acc: 0.9793103337287903)
[2024-12-17 02:48:00,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:00,794][root][INFO] - Training Epoch: 2/2, step 4112/7134 completed (loss: 0.12858936190605164, acc: 0.9689922332763672)
[2024-12-17 02:48:00,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:01,081][root][INFO] - Training Epoch: 2/2, step 4113/7134 completed (loss: 0.07707224786281586, acc: 0.9860140085220337)
[2024-12-17 02:48:01,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:01,348][root][INFO] - Training Epoch: 2/2, step 4114/7134 completed (loss: 0.43496742844581604, acc: 0.904347836971283)
[2024-12-17 02:48:01,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:01,617][root][INFO] - Training Epoch: 2/2, step 4115/7134 completed (loss: 0.28137603402137756, acc: 0.9152542352676392)
[2024-12-17 02:48:01,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:01,913][root][INFO] - Training Epoch: 2/2, step 4116/7134 completed (loss: 0.06658682227134705, acc: 0.9923664331436157)
[2024-12-17 02:48:02,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:02,190][root][INFO] - Training Epoch: 2/2, step 4117/7134 completed (loss: 0.04784996435046196, acc: 0.9861111044883728)
[2024-12-17 02:48:02,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:02,438][root][INFO] - Training Epoch: 2/2, step 4118/7134 completed (loss: 0.10590928047895432, acc: 0.96875)
[2024-12-17 02:48:02,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:02,708][root][INFO] - Training Epoch: 2/2, step 4119/7134 completed (loss: 0.16160368919372559, acc: 0.9662162065505981)
[2024-12-17 02:48:02,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:02,993][root][INFO] - Training Epoch: 2/2, step 4120/7134 completed (loss: 0.1122257262468338, acc: 0.9924812316894531)
[2024-12-17 02:48:03,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:03,271][root][INFO] - Training Epoch: 2/2, step 4121/7134 completed (loss: 0.08254008740186691, acc: 0.9756097793579102)
[2024-12-17 02:48:03,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:03,546][root][INFO] - Training Epoch: 2/2, step 4122/7134 completed (loss: 0.02823314070701599, acc: 0.9915966391563416)
[2024-12-17 02:48:03,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:03,820][root][INFO] - Training Epoch: 2/2, step 4123/7134 completed (loss: 0.07275230437517166, acc: 0.9805194735527039)
[2024-12-17 02:48:03,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:04,120][root][INFO] - Training Epoch: 2/2, step 4124/7134 completed (loss: 0.08373650163412094, acc: 0.981249988079071)
[2024-12-17 02:48:04,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:04,381][root][INFO] - Training Epoch: 2/2, step 4125/7134 completed (loss: 0.07828126102685928, acc: 0.9748427867889404)
[2024-12-17 02:48:04,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:04,663][root][INFO] - Training Epoch: 2/2, step 4126/7134 completed (loss: 0.11420464515686035, acc: 0.9736841917037964)
[2024-12-17 02:48:04,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:04,934][root][INFO] - Training Epoch: 2/2, step 4127/7134 completed (loss: 0.07560618966817856, acc: 0.9731543660163879)
[2024-12-17 02:48:05,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:05,202][root][INFO] - Training Epoch: 2/2, step 4128/7134 completed (loss: 0.08889873325824738, acc: 0.969924807548523)
[2024-12-17 02:48:05,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:05,494][root][INFO] - Training Epoch: 2/2, step 4129/7134 completed (loss: 0.03783510997891426, acc: 0.9932885766029358)
[2024-12-17 02:48:05,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:05,759][root][INFO] - Training Epoch: 2/2, step 4130/7134 completed (loss: 0.09290707856416702, acc: 0.9655172228813171)
[2024-12-17 02:48:05,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:06,039][root][INFO] - Training Epoch: 2/2, step 4131/7134 completed (loss: 0.1313343048095703, acc: 0.9555555582046509)
[2024-12-17 02:48:06,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:06,304][root][INFO] - Training Epoch: 2/2, step 4132/7134 completed (loss: 0.061308350414037704, acc: 0.9722222089767456)
[2024-12-17 02:48:06,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:06,566][root][INFO] - Training Epoch: 2/2, step 4133/7134 completed (loss: 0.19192111492156982, acc: 0.9370629191398621)
[2024-12-17 02:48:06,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:06,843][root][INFO] - Training Epoch: 2/2, step 4134/7134 completed (loss: 0.4012817144393921, acc: 0.9090909361839294)
[2024-12-17 02:48:06,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:07,116][root][INFO] - Training Epoch: 2/2, step 4135/7134 completed (loss: 0.04401320219039917, acc: 0.9928571581840515)
[2024-12-17 02:48:07,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:07,411][root][INFO] - Training Epoch: 2/2, step 4136/7134 completed (loss: 0.07173647731542587, acc: 0.969924807548523)
[2024-12-17 02:48:07,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:07,705][root][INFO] - Training Epoch: 2/2, step 4137/7134 completed (loss: 0.0644216239452362, acc: 0.9852941036224365)
[2024-12-17 02:48:07,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:07,988][root][INFO] - Training Epoch: 2/2, step 4138/7134 completed (loss: 0.19349712133407593, acc: 0.9346405267715454)
[2024-12-17 02:48:08,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:08,264][root][INFO] - Training Epoch: 2/2, step 4139/7134 completed (loss: 0.1185738816857338, acc: 0.9523809552192688)
[2024-12-17 02:48:08,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:08,545][root][INFO] - Training Epoch: 2/2, step 4140/7134 completed (loss: 0.44977492094039917, acc: 0.9209039807319641)
[2024-12-17 02:48:08,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:08,826][root][INFO] - Training Epoch: 2/2, step 4141/7134 completed (loss: 0.358438640832901, acc: 0.9166666865348816)
[2024-12-17 02:48:08,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:09,097][root][INFO] - Training Epoch: 2/2, step 4142/7134 completed (loss: 0.2883334457874298, acc: 0.9200000166893005)
[2024-12-17 02:48:09,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:09,381][root][INFO] - Training Epoch: 2/2, step 4143/7134 completed (loss: 0.25947538018226624, acc: 0.9519650936126709)
[2024-12-17 02:48:09,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:09,700][root][INFO] - Training Epoch: 2/2, step 4144/7134 completed (loss: 0.24381016194820404, acc: 0.9230769276618958)
[2024-12-17 02:48:09,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:10,008][root][INFO] - Training Epoch: 2/2, step 4145/7134 completed (loss: 0.3474734127521515, acc: 0.9152542352676392)
[2024-12-17 02:48:10,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:10,280][root][INFO] - Training Epoch: 2/2, step 4146/7134 completed (loss: 0.4825844466686249, acc: 0.8928571343421936)
[2024-12-17 02:48:10,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:10,556][root][INFO] - Training Epoch: 2/2, step 4147/7134 completed (loss: 0.5751547813415527, acc: 0.8728813529014587)
[2024-12-17 02:48:10,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:10,830][root][INFO] - Training Epoch: 2/2, step 4148/7134 completed (loss: 0.7326849102973938, acc: 0.8590604066848755)
[2024-12-17 02:48:10,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:11,117][root][INFO] - Training Epoch: 2/2, step 4149/7134 completed (loss: 0.5251510739326477, acc: 0.8837209343910217)
[2024-12-17 02:48:11,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:11,395][root][INFO] - Training Epoch: 2/2, step 4150/7134 completed (loss: 0.6608787178993225, acc: 0.8376068472862244)
[2024-12-17 02:48:11,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:11,691][root][INFO] - Training Epoch: 2/2, step 4151/7134 completed (loss: 0.29486432671546936, acc: 0.942148745059967)
[2024-12-17 02:48:11,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:11,978][root][INFO] - Training Epoch: 2/2, step 4152/7134 completed (loss: 0.2730617821216583, acc: 0.9115646481513977)
[2024-12-17 02:48:12,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:12,263][root][INFO] - Training Epoch: 2/2, step 4153/7134 completed (loss: 0.24218662083148956, acc: 0.9428571462631226)
[2024-12-17 02:48:12,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:12,559][root][INFO] - Training Epoch: 2/2, step 4154/7134 completed (loss: 0.23685985803604126, acc: 0.9186602830886841)
[2024-12-17 02:48:12,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:12,828][root][INFO] - Training Epoch: 2/2, step 4155/7134 completed (loss: 0.23274052143096924, acc: 0.9395973086357117)
[2024-12-17 02:48:12,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:13,113][root][INFO] - Training Epoch: 2/2, step 4156/7134 completed (loss: 0.23829954862594604, acc: 0.9239766001701355)
[2024-12-17 02:48:13,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:13,381][root][INFO] - Training Epoch: 2/2, step 4157/7134 completed (loss: 0.25131458044052124, acc: 0.9663865566253662)
[2024-12-17 02:48:13,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:13,630][root][INFO] - Training Epoch: 2/2, step 4158/7134 completed (loss: 0.4249345660209656, acc: 0.8791208863258362)
[2024-12-17 02:48:13,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:13,906][root][INFO] - Training Epoch: 2/2, step 4159/7134 completed (loss: 0.2531627118587494, acc: 0.9473684430122375)
[2024-12-17 02:48:14,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:14,186][root][INFO] - Training Epoch: 2/2, step 4160/7134 completed (loss: 0.26281222701072693, acc: 0.9579831957817078)
[2024-12-17 02:48:14,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:14,471][root][INFO] - Training Epoch: 2/2, step 4161/7134 completed (loss: 0.13006526231765747, acc: 0.9655172228813171)
[2024-12-17 02:48:14,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:14,762][root][INFO] - Training Epoch: 2/2, step 4162/7134 completed (loss: 0.19410714507102966, acc: 0.940119743347168)
[2024-12-17 02:48:14,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:15,052][root][INFO] - Training Epoch: 2/2, step 4163/7134 completed (loss: 0.248968705534935, acc: 0.9530201554298401)
[2024-12-17 02:48:15,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:15,331][root][INFO] - Training Epoch: 2/2, step 4164/7134 completed (loss: 0.22864465415477753, acc: 0.9378882050514221)
[2024-12-17 02:48:15,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:15,650][root][INFO] - Training Epoch: 2/2, step 4165/7134 completed (loss: 0.18212559819221497, acc: 0.9623655676841736)
[2024-12-17 02:48:15,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:15,944][root][INFO] - Training Epoch: 2/2, step 4166/7134 completed (loss: 0.2555384337902069, acc: 0.9166666865348816)
[2024-12-17 02:48:16,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:16,190][root][INFO] - Training Epoch: 2/2, step 4167/7134 completed (loss: 0.14578092098236084, acc: 0.9512194991111755)
[2024-12-17 02:48:16,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:16,468][root][INFO] - Training Epoch: 2/2, step 4168/7134 completed (loss: 0.16736002266407013, acc: 0.9624060392379761)
[2024-12-17 02:48:16,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:16,760][root][INFO] - Training Epoch: 2/2, step 4169/7134 completed (loss: 0.20922479033470154, acc: 0.9539170265197754)
[2024-12-17 02:48:16,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:17,075][root][INFO] - Training Epoch: 2/2, step 4170/7134 completed (loss: 0.24907487630844116, acc: 0.961904764175415)
[2024-12-17 02:48:17,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:17,372][root][INFO] - Training Epoch: 2/2, step 4171/7134 completed (loss: 0.1130434051156044, acc: 0.9655172228813171)
[2024-12-17 02:48:17,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:17,643][root][INFO] - Training Epoch: 2/2, step 4172/7134 completed (loss: 0.24776394665241241, acc: 0.9333333373069763)
[2024-12-17 02:48:17,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:17,961][root][INFO] - Training Epoch: 2/2, step 4173/7134 completed (loss: 0.10418052226305008, acc: 0.9814814925193787)
[2024-12-17 02:48:18,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:18,228][root][INFO] - Training Epoch: 2/2, step 4174/7134 completed (loss: 0.024553244933485985, acc: 1.0)
[2024-12-17 02:48:18,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:18,506][root][INFO] - Training Epoch: 2/2, step 4175/7134 completed (loss: 0.186173215508461, acc: 0.9295774698257446)
[2024-12-17 02:48:18,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:18,798][root][INFO] - Training Epoch: 2/2, step 4176/7134 completed (loss: 0.05802345275878906, acc: 0.9935483932495117)
[2024-12-17 02:48:18,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:19,099][root][INFO] - Training Epoch: 2/2, step 4177/7134 completed (loss: 0.07946962118148804, acc: 0.9707602262496948)
[2024-12-17 02:48:19,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:19,383][root][INFO] - Training Epoch: 2/2, step 4178/7134 completed (loss: 0.09941403567790985, acc: 0.9736841917037964)
[2024-12-17 02:48:19,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:19,696][root][INFO] - Training Epoch: 2/2, step 4179/7134 completed (loss: 0.03521530330181122, acc: 1.0)
[2024-12-17 02:48:19,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:19,981][root][INFO] - Training Epoch: 2/2, step 4180/7134 completed (loss: 0.0438019223511219, acc: 0.9937499761581421)
[2024-12-17 02:48:20,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:20,256][root][INFO] - Training Epoch: 2/2, step 4181/7134 completed (loss: 0.05654484033584595, acc: 0.97826087474823)
[2024-12-17 02:48:20,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:20,533][root][INFO] - Training Epoch: 2/2, step 4182/7134 completed (loss: 0.03837898001074791, acc: 0.9935064911842346)
[2024-12-17 02:48:20,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:20,823][root][INFO] - Training Epoch: 2/2, step 4183/7134 completed (loss: 0.08429072797298431, acc: 0.9693251252174377)
[2024-12-17 02:48:20,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:21,092][root][INFO] - Training Epoch: 2/2, step 4184/7134 completed (loss: 0.08316752314567566, acc: 0.970588207244873)
[2024-12-17 02:48:21,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:21,371][root][INFO] - Training Epoch: 2/2, step 4185/7134 completed (loss: 0.06882859021425247, acc: 0.9809523820877075)
[2024-12-17 02:48:21,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:21,662][root][INFO] - Training Epoch: 2/2, step 4186/7134 completed (loss: 0.13866320252418518, acc: 0.9742268323898315)
[2024-12-17 02:48:21,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:21,923][root][INFO] - Training Epoch: 2/2, step 4187/7134 completed (loss: 0.03727303817868233, acc: 1.0)
[2024-12-17 02:48:22,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:22,206][root][INFO] - Training Epoch: 2/2, step 4188/7134 completed (loss: 0.03597792237997055, acc: 0.9947368502616882)
[2024-12-17 02:48:22,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:22,485][root][INFO] - Training Epoch: 2/2, step 4189/7134 completed (loss: 0.10171272605657578, acc: 0.9820359349250793)
[2024-12-17 02:48:22,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:22,758][root][INFO] - Training Epoch: 2/2, step 4190/7134 completed (loss: 0.08917804807424545, acc: 0.9766082167625427)
[2024-12-17 02:48:22,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:22,990][root][INFO] - Training Epoch: 2/2, step 4191/7134 completed (loss: 0.1419222503900528, acc: 0.9615384340286255)
[2024-12-17 02:48:23,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:23,256][root][INFO] - Training Epoch: 2/2, step 4192/7134 completed (loss: 0.03763837739825249, acc: 0.9931507110595703)
[2024-12-17 02:48:23,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:23,538][root][INFO] - Training Epoch: 2/2, step 4193/7134 completed (loss: 0.08562272042036057, acc: 0.9832402467727661)
[2024-12-17 02:48:23,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:23,823][root][INFO] - Training Epoch: 2/2, step 4194/7134 completed (loss: 0.03115628845989704, acc: 0.9871794581413269)
[2024-12-17 02:48:23,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:24,103][root][INFO] - Training Epoch: 2/2, step 4195/7134 completed (loss: 0.14569111168384552, acc: 0.9657142758369446)
[2024-12-17 02:48:24,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:24,356][root][INFO] - Training Epoch: 2/2, step 4196/7134 completed (loss: 0.08672427386045456, acc: 0.9784172773361206)
[2024-12-17 02:48:24,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:24,636][root][INFO] - Training Epoch: 2/2, step 4197/7134 completed (loss: 0.11561962962150574, acc: 0.967391312122345)
[2024-12-17 02:48:24,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:24,909][root][INFO] - Training Epoch: 2/2, step 4198/7134 completed (loss: 0.10338743031024933, acc: 0.9828571677207947)
[2024-12-17 02:48:25,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:25,166][root][INFO] - Training Epoch: 2/2, step 4199/7134 completed (loss: 0.18753163516521454, acc: 0.9436619877815247)
[2024-12-17 02:48:25,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:25,440][root][INFO] - Training Epoch: 2/2, step 4200/7134 completed (loss: 0.15059594810009003, acc: 0.9448275566101074)
[2024-12-17 02:48:25,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:25,717][root][INFO] - Training Epoch: 2/2, step 4201/7134 completed (loss: 0.0357513390481472, acc: 0.9929078221321106)
[2024-12-17 02:48:25,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:26,013][root][INFO] - Training Epoch: 2/2, step 4202/7134 completed (loss: 0.11442660540342331, acc: 0.9473684430122375)
[2024-12-17 02:48:26,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:26,298][root][INFO] - Training Epoch: 2/2, step 4203/7134 completed (loss: 0.10587245970964432, acc: 0.9746835231781006)
[2024-12-17 02:48:26,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:26,570][root][INFO] - Training Epoch: 2/2, step 4204/7134 completed (loss: 0.25200068950653076, acc: 0.954285740852356)
[2024-12-17 02:48:26,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:26,860][root][INFO] - Training Epoch: 2/2, step 4205/7134 completed (loss: 0.17751014232635498, acc: 0.970588207244873)
[2024-12-17 02:48:26,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:27,152][root][INFO] - Training Epoch: 2/2, step 4206/7134 completed (loss: 0.18453474342823029, acc: 0.9569892287254333)
[2024-12-17 02:48:27,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:27,436][root][INFO] - Training Epoch: 2/2, step 4207/7134 completed (loss: 0.14688223600387573, acc: 0.9874213933944702)
[2024-12-17 02:48:27,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:27,702][root][INFO] - Training Epoch: 2/2, step 4208/7134 completed (loss: 0.2672029137611389, acc: 0.9367815852165222)
[2024-12-17 02:48:27,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:27,973][root][INFO] - Training Epoch: 2/2, step 4209/7134 completed (loss: 0.16786076128482819, acc: 0.9558011293411255)
[2024-12-17 02:48:28,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:28,243][root][INFO] - Training Epoch: 2/2, step 4210/7134 completed (loss: 0.09388106316328049, acc: 0.9561403393745422)
[2024-12-17 02:48:28,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:28,466][root][INFO] - Training Epoch: 2/2, step 4211/7134 completed (loss: 0.055741552263498306, acc: 0.9836065769195557)
[2024-12-17 02:48:28,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:28,740][root][INFO] - Training Epoch: 2/2, step 4212/7134 completed (loss: 0.1449594497680664, acc: 0.9741935729980469)
[2024-12-17 02:48:28,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:29,017][root][INFO] - Training Epoch: 2/2, step 4213/7134 completed (loss: 0.029077768325805664, acc: 1.0)
[2024-12-17 02:48:29,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:29,303][root][INFO] - Training Epoch: 2/2, step 4214/7134 completed (loss: 0.17445257306098938, acc: 0.9649122953414917)
[2024-12-17 02:48:29,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:29,547][root][INFO] - Training Epoch: 2/2, step 4215/7134 completed (loss: 0.15265226364135742, acc: 0.9685039520263672)
[2024-12-17 02:48:29,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:29,819][root][INFO] - Training Epoch: 2/2, step 4216/7134 completed (loss: 0.14442886412143707, acc: 0.9692307710647583)
[2024-12-17 02:48:29,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:30,086][root][INFO] - Training Epoch: 2/2, step 4217/7134 completed (loss: 0.06797206401824951, acc: 0.9777777791023254)
[2024-12-17 02:48:30,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:30,339][root][INFO] - Training Epoch: 2/2, step 4218/7134 completed (loss: 0.10474717617034912, acc: 0.9850746393203735)
[2024-12-17 02:48:30,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:30,563][root][INFO] - Training Epoch: 2/2, step 4219/7134 completed (loss: 0.10692180693149567, acc: 0.9710144996643066)
[2024-12-17 02:48:30,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:30,866][root][INFO] - Training Epoch: 2/2, step 4220/7134 completed (loss: 0.23573535680770874, acc: 0.9545454382896423)
[2024-12-17 02:48:30,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:31,154][root][INFO] - Training Epoch: 2/2, step 4221/7134 completed (loss: 0.13978427648544312, acc: 0.9729729890823364)
[2024-12-17 02:48:31,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:31,400][root][INFO] - Training Epoch: 2/2, step 4222/7134 completed (loss: 0.38994932174682617, acc: 0.9473684430122375)
[2024-12-17 02:48:31,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:31,668][root][INFO] - Training Epoch: 2/2, step 4223/7134 completed (loss: 0.32879987359046936, acc: 0.9246231317520142)
[2024-12-17 02:48:31,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:31,932][root][INFO] - Training Epoch: 2/2, step 4224/7134 completed (loss: 0.18314145505428314, acc: 0.9435483813285828)
[2024-12-17 02:48:32,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:32,218][root][INFO] - Training Epoch: 2/2, step 4225/7134 completed (loss: 0.3032398521900177, acc: 0.9166666865348816)
[2024-12-17 02:48:32,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:32,498][root][INFO] - Training Epoch: 2/2, step 4226/7134 completed (loss: 0.33480823040008545, acc: 0.9238578677177429)
[2024-12-17 02:48:32,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:32,757][root][INFO] - Training Epoch: 2/2, step 4227/7134 completed (loss: 0.4158759117126465, acc: 0.8773584961891174)
[2024-12-17 02:48:32,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:33,028][root][INFO] - Training Epoch: 2/2, step 4228/7134 completed (loss: 0.411885529756546, acc: 0.9102563858032227)
[2024-12-17 02:48:33,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:33,289][root][INFO] - Training Epoch: 2/2, step 4229/7134 completed (loss: 0.33615389466285706, acc: 0.9200000166893005)
[2024-12-17 02:48:33,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:33,575][root][INFO] - Training Epoch: 2/2, step 4230/7134 completed (loss: 0.3669983744621277, acc: 0.9186046719551086)
[2024-12-17 02:48:33,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:33,847][root][INFO] - Training Epoch: 2/2, step 4231/7134 completed (loss: 0.5550960898399353, acc: 0.899328887462616)
[2024-12-17 02:48:33,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:34,132][root][INFO] - Training Epoch: 2/2, step 4232/7134 completed (loss: 0.3658016324043274, acc: 0.8999999761581421)
[2024-12-17 02:48:34,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:34,416][root][INFO] - Training Epoch: 2/2, step 4233/7134 completed (loss: 0.23806968331336975, acc: 0.957446813583374)
[2024-12-17 02:48:34,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:34,693][root][INFO] - Training Epoch: 2/2, step 4234/7134 completed (loss: 0.11974740773439407, acc: 0.9716312289237976)
[2024-12-17 02:48:34,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:34,987][root][INFO] - Training Epoch: 2/2, step 4235/7134 completed (loss: 0.15882627665996552, acc: 0.9710144996643066)
[2024-12-17 02:48:35,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:35,242][root][INFO] - Training Epoch: 2/2, step 4236/7134 completed (loss: 0.09530165046453476, acc: 0.9892473220825195)
[2024-12-17 02:48:35,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:35,520][root][INFO] - Training Epoch: 2/2, step 4237/7134 completed (loss: 0.09679585695266724, acc: 0.9813084006309509)
[2024-12-17 02:48:35,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:35,804][root][INFO] - Training Epoch: 2/2, step 4238/7134 completed (loss: 0.17137998342514038, acc: 0.9692307710647583)
[2024-12-17 02:48:35,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:36,069][root][INFO] - Training Epoch: 2/2, step 4239/7134 completed (loss: 0.09224450588226318, acc: 0.984000027179718)
[2024-12-17 02:48:36,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:36,339][root][INFO] - Training Epoch: 2/2, step 4240/7134 completed (loss: 0.20936250686645508, acc: 0.9507042169570923)
[2024-12-17 02:48:36,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:36,643][root][INFO] - Training Epoch: 2/2, step 4241/7134 completed (loss: 0.06739779561758041, acc: 0.9900000095367432)
[2024-12-17 02:48:36,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:36,935][root][INFO] - Training Epoch: 2/2, step 4242/7134 completed (loss: 0.11210809648036957, acc: 0.9795918464660645)
[2024-12-17 02:48:37,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:37,230][root][INFO] - Training Epoch: 2/2, step 4243/7134 completed (loss: 0.18997296690940857, acc: 0.9752066135406494)
[2024-12-17 02:48:37,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:37,492][root][INFO] - Training Epoch: 2/2, step 4244/7134 completed (loss: 0.05309702828526497, acc: 1.0)
[2024-12-17 02:48:37,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:37,748][root][INFO] - Training Epoch: 2/2, step 4245/7134 completed (loss: 0.16241998970508575, acc: 0.9684210419654846)
[2024-12-17 02:48:37,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:38,044][root][INFO] - Training Epoch: 2/2, step 4246/7134 completed (loss: 0.14867003262043, acc: 0.965753436088562)
[2024-12-17 02:48:38,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:38,310][root][INFO] - Training Epoch: 2/2, step 4247/7134 completed (loss: 0.08222374320030212, acc: 0.9760000109672546)
[2024-12-17 02:48:38,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:38,611][root][INFO] - Training Epoch: 2/2, step 4248/7134 completed (loss: 0.22096550464630127, acc: 0.9520547986030579)
[2024-12-17 02:48:38,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:38,958][root][INFO] - Training Epoch: 2/2, step 4249/7134 completed (loss: 0.1805625706911087, acc: 0.970588207244873)
[2024-12-17 02:48:39,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:39,240][root][INFO] - Training Epoch: 2/2, step 4250/7134 completed (loss: 0.25413408875465393, acc: 0.9545454382896423)
[2024-12-17 02:48:39,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:39,511][root][INFO] - Training Epoch: 2/2, step 4251/7134 completed (loss: 0.0825021043419838, acc: 0.9624060392379761)
[2024-12-17 02:48:39,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:39,792][root][INFO] - Training Epoch: 2/2, step 4252/7134 completed (loss: 0.13589400053024292, acc: 0.9516128897666931)
[2024-12-17 02:48:39,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:40,063][root][INFO] - Training Epoch: 2/2, step 4253/7134 completed (loss: 0.14984408020973206, acc: 0.9652174115180969)
[2024-12-17 02:48:40,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:40,313][root][INFO] - Training Epoch: 2/2, step 4254/7134 completed (loss: 0.04415613412857056, acc: 0.9886363744735718)
[2024-12-17 02:48:40,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:40,615][root][INFO] - Training Epoch: 2/2, step 4255/7134 completed (loss: 0.18990522623062134, acc: 0.9384615421295166)
[2024-12-17 02:48:40,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:40,892][root][INFO] - Training Epoch: 2/2, step 4256/7134 completed (loss: 0.08386716991662979, acc: 0.9914529919624329)
[2024-12-17 02:48:40,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:41,176][root][INFO] - Training Epoch: 2/2, step 4257/7134 completed (loss: 0.06506624072790146, acc: 0.9848484992980957)
[2024-12-17 02:48:41,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:41,454][root][INFO] - Training Epoch: 2/2, step 4258/7134 completed (loss: 0.02999350056052208, acc: 1.0)
[2024-12-17 02:48:41,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:41,741][root][INFO] - Training Epoch: 2/2, step 4259/7134 completed (loss: 0.16580002009868622, acc: 0.9624999761581421)
[2024-12-17 02:48:41,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:42,033][root][INFO] - Training Epoch: 2/2, step 4260/7134 completed (loss: 0.1082814484834671, acc: 0.9541284441947937)
[2024-12-17 02:48:42,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:42,293][root][INFO] - Training Epoch: 2/2, step 4261/7134 completed (loss: 0.13764028251171112, acc: 0.95652174949646)
[2024-12-17 02:48:42,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:42,575][root][INFO] - Training Epoch: 2/2, step 4262/7134 completed (loss: 0.140874981880188, acc: 0.9650349617004395)
[2024-12-17 02:48:42,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:42,848][root][INFO] - Training Epoch: 2/2, step 4263/7134 completed (loss: 0.14229552447795868, acc: 0.970370352268219)
[2024-12-17 02:48:42,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:43,105][root][INFO] - Training Epoch: 2/2, step 4264/7134 completed (loss: 0.20931874215602875, acc: 0.949438214302063)
[2024-12-17 02:48:43,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:43,374][root][INFO] - Training Epoch: 2/2, step 4265/7134 completed (loss: 0.27295663952827454, acc: 0.9244186282157898)
[2024-12-17 02:48:43,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:43,669][root][INFO] - Training Epoch: 2/2, step 4266/7134 completed (loss: 0.08775211125612259, acc: 0.9685863852500916)
[2024-12-17 02:48:43,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:43,961][root][INFO] - Training Epoch: 2/2, step 4267/7134 completed (loss: 0.11507367342710495, acc: 0.9545454382896423)
[2024-12-17 02:48:44,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:44,245][root][INFO] - Training Epoch: 2/2, step 4268/7134 completed (loss: 0.2089582085609436, acc: 0.9512194991111755)
[2024-12-17 02:48:44,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:44,541][root][INFO] - Training Epoch: 2/2, step 4269/7134 completed (loss: 0.32148241996765137, acc: 0.9248554706573486)
[2024-12-17 02:48:44,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:44,833][root][INFO] - Training Epoch: 2/2, step 4270/7134 completed (loss: 0.18688605725765228, acc: 0.9479166865348816)
[2024-12-17 02:48:44,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:45,116][root][INFO] - Training Epoch: 2/2, step 4271/7134 completed (loss: 0.10178154706954956, acc: 0.9783783555030823)
[2024-12-17 02:48:45,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:45,403][root][INFO] - Training Epoch: 2/2, step 4272/7134 completed (loss: 0.14376185834407806, acc: 0.9601989984512329)
[2024-12-17 02:48:45,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:45,693][root][INFO] - Training Epoch: 2/2, step 4273/7134 completed (loss: 0.12472432106733322, acc: 0.9629629850387573)
[2024-12-17 02:48:45,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:45,981][root][INFO] - Training Epoch: 2/2, step 4274/7134 completed (loss: 0.22886650264263153, acc: 0.936274528503418)
[2024-12-17 02:48:46,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:46,253][root][INFO] - Training Epoch: 2/2, step 4275/7134 completed (loss: 0.12668675184249878, acc: 0.9608938694000244)
[2024-12-17 02:48:46,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:46,534][root][INFO] - Training Epoch: 2/2, step 4276/7134 completed (loss: 0.16957217454910278, acc: 0.9567567706108093)
[2024-12-17 02:48:46,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:46,793][root][INFO] - Training Epoch: 2/2, step 4277/7134 completed (loss: 0.05327024310827255, acc: 0.98591548204422)
[2024-12-17 02:48:46,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:47,070][root][INFO] - Training Epoch: 2/2, step 4278/7134 completed (loss: 0.1268240213394165, acc: 0.9744898080825806)
[2024-12-17 02:48:47,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:47,348][root][INFO] - Training Epoch: 2/2, step 4279/7134 completed (loss: 0.09481251239776611, acc: 0.9689440727233887)
[2024-12-17 02:48:47,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:47,630][root][INFO] - Training Epoch: 2/2, step 4280/7134 completed (loss: 0.02302410826086998, acc: 0.9929078221321106)
[2024-12-17 02:48:47,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:47,920][root][INFO] - Training Epoch: 2/2, step 4281/7134 completed (loss: 0.13593798875808716, acc: 0.9731183052062988)
[2024-12-17 02:48:48,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:48,217][root][INFO] - Training Epoch: 2/2, step 4282/7134 completed (loss: 0.0731830820441246, acc: 0.9913793206214905)
[2024-12-17 02:48:48,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:48,514][root][INFO] - Training Epoch: 2/2, step 4283/7134 completed (loss: 0.11439996212720871, acc: 0.9642857313156128)
[2024-12-17 02:48:48,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:48,770][root][INFO] - Training Epoch: 2/2, step 4284/7134 completed (loss: 0.2012079358100891, acc: 0.961240291595459)
[2024-12-17 02:48:48,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:49,056][root][INFO] - Training Epoch: 2/2, step 4285/7134 completed (loss: 0.11234299838542938, acc: 0.9457364082336426)
[2024-12-17 02:48:49,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:49,311][root][INFO] - Training Epoch: 2/2, step 4286/7134 completed (loss: 0.12209484726190567, acc: 0.9747899174690247)
[2024-12-17 02:48:49,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:49,590][root][INFO] - Training Epoch: 2/2, step 4287/7134 completed (loss: 0.20998796820640564, acc: 0.9619565010070801)
[2024-12-17 02:48:49,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:49,880][root][INFO] - Training Epoch: 2/2, step 4288/7134 completed (loss: 0.15077361464500427, acc: 0.9588235020637512)
[2024-12-17 02:48:50,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:50,173][root][INFO] - Training Epoch: 2/2, step 4289/7134 completed (loss: 0.17679227888584137, acc: 0.9570552110671997)
[2024-12-17 02:48:50,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:50,450][root][INFO] - Training Epoch: 2/2, step 4290/7134 completed (loss: 0.10222795605659485, acc: 0.9595375657081604)
[2024-12-17 02:48:50,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:50,727][root][INFO] - Training Epoch: 2/2, step 4291/7134 completed (loss: 0.04644254595041275, acc: 0.9884393215179443)
[2024-12-17 02:48:50,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:51,003][root][INFO] - Training Epoch: 2/2, step 4292/7134 completed (loss: 0.09001720696687698, acc: 0.9677419066429138)
[2024-12-17 02:48:51,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:51,284][root][INFO] - Training Epoch: 2/2, step 4293/7134 completed (loss: 0.10480780899524689, acc: 0.9916666746139526)
[2024-12-17 02:48:51,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:51,585][root][INFO] - Training Epoch: 2/2, step 4294/7134 completed (loss: 0.17908138036727905, acc: 0.9657142758369446)
[2024-12-17 02:48:51,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:51,892][root][INFO] - Training Epoch: 2/2, step 4295/7134 completed (loss: 0.1126842200756073, acc: 0.9714285731315613)
[2024-12-17 02:48:52,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:52,192][root][INFO] - Training Epoch: 2/2, step 4296/7134 completed (loss: 0.04253114014863968, acc: 0.9900990128517151)
[2024-12-17 02:48:52,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:52,473][root][INFO] - Training Epoch: 2/2, step 4297/7134 completed (loss: 0.03073427639901638, acc: 0.9904761910438538)
[2024-12-17 02:48:52,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:52,753][root][INFO] - Training Epoch: 2/2, step 4298/7134 completed (loss: 0.10535332560539246, acc: 0.9772727489471436)
[2024-12-17 02:48:52,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:53,018][root][INFO] - Training Epoch: 2/2, step 4299/7134 completed (loss: 0.138473242521286, acc: 0.9623655676841736)
[2024-12-17 02:48:53,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:53,277][root][INFO] - Training Epoch: 2/2, step 4300/7134 completed (loss: 0.25383707880973816, acc: 0.9411764740943909)
[2024-12-17 02:48:53,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:53,552][root][INFO] - Training Epoch: 2/2, step 4301/7134 completed (loss: 0.0943104550242424, acc: 0.98591548204422)
[2024-12-17 02:48:53,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:53,829][root][INFO] - Training Epoch: 2/2, step 4302/7134 completed (loss: 0.08760358393192291, acc: 0.987261176109314)
[2024-12-17 02:48:53,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:54,104][root][INFO] - Training Epoch: 2/2, step 4303/7134 completed (loss: 0.13735483586788177, acc: 0.9603960514068604)
[2024-12-17 02:48:54,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:54,392][root][INFO] - Training Epoch: 2/2, step 4304/7134 completed (loss: 0.12074871361255646, acc: 0.9585798978805542)
[2024-12-17 02:48:54,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:54,688][root][INFO] - Training Epoch: 2/2, step 4305/7134 completed (loss: 0.12365330755710602, acc: 0.9700000286102295)
[2024-12-17 02:48:54,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:54,979][root][INFO] - Training Epoch: 2/2, step 4306/7134 completed (loss: 0.1992066502571106, acc: 0.9528796076774597)
[2024-12-17 02:48:55,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:55,255][root][INFO] - Training Epoch: 2/2, step 4307/7134 completed (loss: 0.12120714038610458, acc: 0.9738562107086182)
[2024-12-17 02:48:55,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:55,543][root][INFO] - Training Epoch: 2/2, step 4308/7134 completed (loss: 0.17231795191764832, acc: 0.9518716335296631)
[2024-12-17 02:48:55,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:55,830][root][INFO] - Training Epoch: 2/2, step 4309/7134 completed (loss: 0.1449999213218689, acc: 0.9659090638160706)
[2024-12-17 02:48:55,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:56,108][root][INFO] - Training Epoch: 2/2, step 4310/7134 completed (loss: 0.11511582136154175, acc: 0.9593908786773682)
[2024-12-17 02:48:56,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:56,376][root][INFO] - Training Epoch: 2/2, step 4311/7134 completed (loss: 0.057217422872781754, acc: 0.9929078221321106)
[2024-12-17 02:48:56,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:56,643][root][INFO] - Training Epoch: 2/2, step 4312/7134 completed (loss: 0.13271695375442505, acc: 0.9631901979446411)
[2024-12-17 02:48:56,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:56,916][root][INFO] - Training Epoch: 2/2, step 4313/7134 completed (loss: 0.06701892614364624, acc: 0.9757575988769531)
[2024-12-17 02:48:57,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:57,192][root][INFO] - Training Epoch: 2/2, step 4314/7134 completed (loss: 0.06486085802316666, acc: 0.9803921580314636)
[2024-12-17 02:48:57,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:57,469][root][INFO] - Training Epoch: 2/2, step 4315/7134 completed (loss: 0.08692701905965805, acc: 0.9821428656578064)
[2024-12-17 02:48:57,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:57,745][root][INFO] - Training Epoch: 2/2, step 4316/7134 completed (loss: 0.11525148153305054, acc: 0.970059871673584)
[2024-12-17 02:48:57,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:58,026][root][INFO] - Training Epoch: 2/2, step 4317/7134 completed (loss: 0.0925498753786087, acc: 0.9767441749572754)
[2024-12-17 02:48:58,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:58,295][root][INFO] - Training Epoch: 2/2, step 4318/7134 completed (loss: 0.1594521701335907, acc: 0.9642857313156128)
[2024-12-17 02:48:58,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:58,600][root][INFO] - Training Epoch: 2/2, step 4319/7134 completed (loss: 0.08552875369787216, acc: 0.9753694534301758)
[2024-12-17 02:48:58,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:58,861][root][INFO] - Training Epoch: 2/2, step 4320/7134 completed (loss: 0.07103413343429565, acc: 0.9871794581413269)
[2024-12-17 02:48:58,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:59,114][root][INFO] - Training Epoch: 2/2, step 4321/7134 completed (loss: 0.2600950002670288, acc: 0.9603960514068604)
[2024-12-17 02:48:59,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:59,393][root][INFO] - Training Epoch: 2/2, step 4322/7134 completed (loss: 0.215868279337883, acc: 0.9245283007621765)
[2024-12-17 02:48:59,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:59,659][root][INFO] - Training Epoch: 2/2, step 4323/7134 completed (loss: 0.09552168101072311, acc: 0.9624060392379761)
[2024-12-17 02:48:59,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:59,912][root][INFO] - Training Epoch: 2/2, step 4324/7134 completed (loss: 0.1007109135389328, acc: 0.9826086759567261)
[2024-12-17 02:49:00,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:00,190][root][INFO] - Training Epoch: 2/2, step 4325/7134 completed (loss: 0.17780359089374542, acc: 0.965753436088562)
[2024-12-17 02:49:00,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:00,468][root][INFO] - Training Epoch: 2/2, step 4326/7134 completed (loss: 0.23857331275939941, acc: 0.9318181872367859)
[2024-12-17 02:49:00,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:00,735][root][INFO] - Training Epoch: 2/2, step 4327/7134 completed (loss: 0.1015683189034462, acc: 0.9781022071838379)
[2024-12-17 02:49:00,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:01,013][root][INFO] - Training Epoch: 2/2, step 4328/7134 completed (loss: 0.08488868176937103, acc: 0.984375)
[2024-12-17 02:49:01,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:01,306][root][INFO] - Training Epoch: 2/2, step 4329/7134 completed (loss: 0.17095604538917542, acc: 0.9649122953414917)
[2024-12-17 02:49:01,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:01,573][root][INFO] - Training Epoch: 2/2, step 4330/7134 completed (loss: 0.11284472793340683, acc: 0.9729729890823364)
[2024-12-17 02:49:01,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:01,854][root][INFO] - Training Epoch: 2/2, step 4331/7134 completed (loss: 0.04282541573047638, acc: 1.0)
[2024-12-17 02:49:01,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:02,133][root][INFO] - Training Epoch: 2/2, step 4332/7134 completed (loss: 0.15388146042823792, acc: 0.9523809552192688)
[2024-12-17 02:49:02,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:02,414][root][INFO] - Training Epoch: 2/2, step 4333/7134 completed (loss: 0.05087015777826309, acc: 0.987500011920929)
[2024-12-17 02:49:02,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:02,701][root][INFO] - Training Epoch: 2/2, step 4334/7134 completed (loss: 0.15503443777561188, acc: 0.9754601120948792)
[2024-12-17 02:49:02,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:02,979][root][INFO] - Training Epoch: 2/2, step 4335/7134 completed (loss: 0.1343284249305725, acc: 0.9834710955619812)
[2024-12-17 02:49:03,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:03,253][root][INFO] - Training Epoch: 2/2, step 4336/7134 completed (loss: 0.023966021835803986, acc: 1.0)
[2024-12-17 02:49:03,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:03,525][root][INFO] - Training Epoch: 2/2, step 4337/7134 completed (loss: 0.04970408231019974, acc: 0.9860140085220337)
[2024-12-17 02:49:03,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:03,795][root][INFO] - Training Epoch: 2/2, step 4338/7134 completed (loss: 0.10236037522554398, acc: 0.9636363387107849)
[2024-12-17 02:49:03,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:04,073][root][INFO] - Training Epoch: 2/2, step 4339/7134 completed (loss: 0.06599629670381546, acc: 0.9882352948188782)
[2024-12-17 02:49:04,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:04,377][root][INFO] - Training Epoch: 2/2, step 4340/7134 completed (loss: 0.12267690151929855, acc: 0.9655172228813171)
[2024-12-17 02:49:04,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:04,660][root][INFO] - Training Epoch: 2/2, step 4341/7134 completed (loss: 0.12969443202018738, acc: 0.9659863710403442)
[2024-12-17 02:49:04,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:04,969][root][INFO] - Training Epoch: 2/2, step 4342/7134 completed (loss: 0.17262756824493408, acc: 0.9536423683166504)
[2024-12-17 02:49:05,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:05,276][root][INFO] - Training Epoch: 2/2, step 4343/7134 completed (loss: 0.2037695199251175, acc: 0.9481481313705444)
[2024-12-17 02:49:05,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:05,564][root][INFO] - Training Epoch: 2/2, step 4344/7134 completed (loss: 0.19693505764007568, acc: 0.939130425453186)
[2024-12-17 02:49:05,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:05,840][root][INFO] - Training Epoch: 2/2, step 4345/7134 completed (loss: 0.0994320809841156, acc: 0.9639639854431152)
[2024-12-17 02:49:05,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:06,109][root][INFO] - Training Epoch: 2/2, step 4346/7134 completed (loss: 0.12294307351112366, acc: 0.9819819927215576)
[2024-12-17 02:49:06,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:06,376][root][INFO] - Training Epoch: 2/2, step 4347/7134 completed (loss: 0.23958280682563782, acc: 0.9467455744743347)
[2024-12-17 02:49:06,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:06,633][root][INFO] - Training Epoch: 2/2, step 4348/7134 completed (loss: 0.16790451109409332, acc: 0.9591836929321289)
[2024-12-17 02:49:06,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:06,946][root][INFO] - Training Epoch: 2/2, step 4349/7134 completed (loss: 0.08076032251119614, acc: 0.96875)
[2024-12-17 02:49:07,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:07,229][root][INFO] - Training Epoch: 2/2, step 4350/7134 completed (loss: 0.19728460907936096, acc: 0.9550561904907227)
[2024-12-17 02:49:07,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:07,502][root][INFO] - Training Epoch: 2/2, step 4351/7134 completed (loss: 0.12737524509429932, acc: 0.9743589758872986)
[2024-12-17 02:49:07,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:07,779][root][INFO] - Training Epoch: 2/2, step 4352/7134 completed (loss: 0.18483300507068634, acc: 0.95652174949646)
[2024-12-17 02:49:07,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:08,054][root][INFO] - Training Epoch: 2/2, step 4353/7134 completed (loss: 0.1667824238538742, acc: 0.9640718698501587)
[2024-12-17 02:49:08,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:08,337][root][INFO] - Training Epoch: 2/2, step 4354/7134 completed (loss: 0.13097594678401947, acc: 0.9631901979446411)
[2024-12-17 02:49:08,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:08,602][root][INFO] - Training Epoch: 2/2, step 4355/7134 completed (loss: 0.22660362720489502, acc: 0.9378882050514221)
[2024-12-17 02:49:08,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:08,878][root][INFO] - Training Epoch: 2/2, step 4356/7134 completed (loss: 0.08602847903966904, acc: 0.9825581312179565)
[2024-12-17 02:49:08,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:09,152][root][INFO] - Training Epoch: 2/2, step 4357/7134 completed (loss: 0.3432491421699524, acc: 0.926174521446228)
[2024-12-17 02:49:09,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:09,442][root][INFO] - Training Epoch: 2/2, step 4358/7134 completed (loss: 0.23517972230911255, acc: 0.9512194991111755)
[2024-12-17 02:49:09,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:09,721][root][INFO] - Training Epoch: 2/2, step 4359/7134 completed (loss: 0.14258547127246857, acc: 0.9682539701461792)
[2024-12-17 02:49:09,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:09,968][root][INFO] - Training Epoch: 2/2, step 4360/7134 completed (loss: 0.11950625479221344, acc: 0.9745222926139832)
[2024-12-17 02:49:10,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:10,238][root][INFO] - Training Epoch: 2/2, step 4361/7134 completed (loss: 0.09644486010074615, acc: 0.9602649211883545)
[2024-12-17 02:49:10,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:10,516][root][INFO] - Training Epoch: 2/2, step 4362/7134 completed (loss: 0.14728255569934845, acc: 0.95652174949646)
[2024-12-17 02:49:10,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:10,797][root][INFO] - Training Epoch: 2/2, step 4363/7134 completed (loss: 0.174756720662117, acc: 0.9469696879386902)
[2024-12-17 02:49:10,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:11,052][root][INFO] - Training Epoch: 2/2, step 4364/7134 completed (loss: 0.1396923065185547, acc: 0.961240291595459)
[2024-12-17 02:49:11,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:11,329][root][INFO] - Training Epoch: 2/2, step 4365/7134 completed (loss: 0.1274181604385376, acc: 0.971222996711731)
[2024-12-17 02:49:11,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:11,618][root][INFO] - Training Epoch: 2/2, step 4366/7134 completed (loss: 0.1342989206314087, acc: 0.9593023061752319)
[2024-12-17 02:49:11,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:11,897][root][INFO] - Training Epoch: 2/2, step 4367/7134 completed (loss: 0.26107165217399597, acc: 0.9597315192222595)
[2024-12-17 02:49:12,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:12,185][root][INFO] - Training Epoch: 2/2, step 4368/7134 completed (loss: 0.06491392850875854, acc: 0.9820359349250793)
[2024-12-17 02:49:12,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:12,460][root][INFO] - Training Epoch: 2/2, step 4369/7134 completed (loss: 0.09338372200727463, acc: 0.9756097793579102)
[2024-12-17 02:49:12,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:12,742][root][INFO] - Training Epoch: 2/2, step 4370/7134 completed (loss: 0.21024590730667114, acc: 0.9534883499145508)
[2024-12-17 02:49:12,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:13,020][root][INFO] - Training Epoch: 2/2, step 4371/7134 completed (loss: 0.13011294603347778, acc: 0.9634146094322205)
[2024-12-17 02:49:13,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:13,282][root][INFO] - Training Epoch: 2/2, step 4372/7134 completed (loss: 0.11745987087488174, acc: 0.9754098653793335)
[2024-12-17 02:49:13,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:13,551][root][INFO] - Training Epoch: 2/2, step 4373/7134 completed (loss: 0.12087628990411758, acc: 0.9668508172035217)
[2024-12-17 02:49:13,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:13,829][root][INFO] - Training Epoch: 2/2, step 4374/7134 completed (loss: 0.13574010133743286, acc: 0.9695122241973877)
[2024-12-17 02:49:13,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:14,107][root][INFO] - Training Epoch: 2/2, step 4375/7134 completed (loss: 0.1467554122209549, acc: 0.976190447807312)
[2024-12-17 02:49:14,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:14,366][root][INFO] - Training Epoch: 2/2, step 4376/7134 completed (loss: 0.11651680618524551, acc: 0.9583333134651184)
[2024-12-17 02:49:14,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:14,649][root][INFO] - Training Epoch: 2/2, step 4377/7134 completed (loss: 0.24006551504135132, acc: 0.970588207244873)
[2024-12-17 02:49:14,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:14,920][root][INFO] - Training Epoch: 2/2, step 4378/7134 completed (loss: 0.11575956642627716, acc: 0.9774436354637146)
[2024-12-17 02:49:15,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:15,212][root][INFO] - Training Epoch: 2/2, step 4379/7134 completed (loss: 0.3412492275238037, acc: 0.9264705777168274)
[2024-12-17 02:49:15,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:15,469][root][INFO] - Training Epoch: 2/2, step 4380/7134 completed (loss: 0.296537846326828, acc: 0.9300699234008789)
[2024-12-17 02:49:15,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:15,751][root][INFO] - Training Epoch: 2/2, step 4381/7134 completed (loss: 0.14412705600261688, acc: 0.9640718698501587)
[2024-12-17 02:49:15,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:16,014][root][INFO] - Training Epoch: 2/2, step 4382/7134 completed (loss: 0.1955185830593109, acc: 0.9548386931419373)
[2024-12-17 02:49:16,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:16,291][root][INFO] - Training Epoch: 2/2, step 4383/7134 completed (loss: 0.28094640374183655, acc: 0.9441624283790588)
[2024-12-17 02:49:16,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:16,553][root][INFO] - Training Epoch: 2/2, step 4384/7134 completed (loss: 0.08494967967271805, acc: 0.9829545617103577)
[2024-12-17 02:49:16,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:16,821][root][INFO] - Training Epoch: 2/2, step 4385/7134 completed (loss: 0.27121275663375854, acc: 0.9119170904159546)
[2024-12-17 02:49:16,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:17,100][root][INFO] - Training Epoch: 2/2, step 4386/7134 completed (loss: 0.20866014063358307, acc: 0.9417475461959839)
[2024-12-17 02:49:17,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:17,398][root][INFO] - Training Epoch: 2/2, step 4387/7134 completed (loss: 0.2576574981212616, acc: 0.9176470637321472)
[2024-12-17 02:49:17,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:17,670][root][INFO] - Training Epoch: 2/2, step 4388/7134 completed (loss: 0.21689575910568237, acc: 0.9220778942108154)
[2024-12-17 02:49:17,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:17,943][root][INFO] - Training Epoch: 2/2, step 4389/7134 completed (loss: 0.2762491703033447, acc: 0.9420289993286133)
[2024-12-17 02:49:18,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:18,225][root][INFO] - Training Epoch: 2/2, step 4390/7134 completed (loss: 0.3009602725505829, acc: 0.9447852969169617)
[2024-12-17 02:49:18,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:18,491][root][INFO] - Training Epoch: 2/2, step 4391/7134 completed (loss: 0.4902551770210266, acc: 0.8904109597206116)
[2024-12-17 02:49:18,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:18,756][root][INFO] - Training Epoch: 2/2, step 4392/7134 completed (loss: 0.1627877652645111, acc: 0.9682539701461792)
[2024-12-17 02:49:18,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:19,035][root][INFO] - Training Epoch: 2/2, step 4393/7134 completed (loss: 0.1498800665140152, acc: 0.9666666388511658)
[2024-12-17 02:49:19,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:19,316][root][INFO] - Training Epoch: 2/2, step 4394/7134 completed (loss: 0.1370818316936493, acc: 0.9664429426193237)
[2024-12-17 02:49:19,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:19,594][root][INFO] - Training Epoch: 2/2, step 4395/7134 completed (loss: 0.2713487148284912, acc: 0.9440993666648865)
[2024-12-17 02:49:19,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:19,857][root][INFO] - Training Epoch: 2/2, step 4396/7134 completed (loss: 0.4569762349128723, acc: 0.8994709253311157)
[2024-12-17 02:49:19,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:20,125][root][INFO] - Training Epoch: 2/2, step 4397/7134 completed (loss: 0.8049547076225281, acc: 0.8738738894462585)
[2024-12-17 02:49:20,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:20,390][root][INFO] - Training Epoch: 2/2, step 4398/7134 completed (loss: 0.28347253799438477, acc: 0.9555555582046509)
[2024-12-17 02:49:20,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:20,660][root][INFO] - Training Epoch: 2/2, step 4399/7134 completed (loss: 0.21957843005657196, acc: 0.9652777910232544)
[2024-12-17 02:49:20,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:20,943][root][INFO] - Training Epoch: 2/2, step 4400/7134 completed (loss: 0.1500002145767212, acc: 0.9736841917037964)
[2024-12-17 02:49:21,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:21,196][root][INFO] - Training Epoch: 2/2, step 4401/7134 completed (loss: 0.262570858001709, acc: 0.948387086391449)
[2024-12-17 02:49:21,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:21,463][root][INFO] - Training Epoch: 2/2, step 4402/7134 completed (loss: 0.34160614013671875, acc: 0.9197530746459961)
[2024-12-17 02:49:21,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:21,749][root][INFO] - Training Epoch: 2/2, step 4403/7134 completed (loss: 0.5553216934204102, acc: 0.8727272748947144)
[2024-12-17 02:49:21,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:22,034][root][INFO] - Training Epoch: 2/2, step 4404/7134 completed (loss: 0.44540032744407654, acc: 0.9226804375648499)
[2024-12-17 02:49:22,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:22,334][root][INFO] - Training Epoch: 2/2, step 4405/7134 completed (loss: 0.26436933875083923, acc: 0.9306930899620056)
[2024-12-17 02:49:22,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:22,634][root][INFO] - Training Epoch: 2/2, step 4406/7134 completed (loss: 0.16437838971614838, acc: 0.9609755873680115)
[2024-12-17 02:49:22,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:22,913][root][INFO] - Training Epoch: 2/2, step 4407/7134 completed (loss: 0.19758203625679016, acc: 0.954081654548645)
[2024-12-17 02:49:23,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:23,209][root][INFO] - Training Epoch: 2/2, step 4408/7134 completed (loss: 0.3366026282310486, acc: 0.8990384340286255)
[2024-12-17 02:49:23,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:23,511][root][INFO] - Training Epoch: 2/2, step 4409/7134 completed (loss: 0.19575218856334686, acc: 0.9375)
[2024-12-17 02:49:23,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:23,814][root][INFO] - Training Epoch: 2/2, step 4410/7134 completed (loss: 0.36339035630226135, acc: 0.9230769276618958)
[2024-12-17 02:49:23,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:24,082][root][INFO] - Training Epoch: 2/2, step 4411/7134 completed (loss: 0.35302436351776123, acc: 0.9193548560142517)
[2024-12-17 02:49:24,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:24,362][root][INFO] - Training Epoch: 2/2, step 4412/7134 completed (loss: 0.7579367756843567, acc: 0.8492462038993835)
[2024-12-17 02:49:24,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:24,641][root][INFO] - Training Epoch: 2/2, step 4413/7134 completed (loss: 0.5138891935348511, acc: 0.8860103487968445)
[2024-12-17 02:49:24,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:24,913][root][INFO] - Training Epoch: 2/2, step 4414/7134 completed (loss: 0.1571797877550125, acc: 0.9677419066429138)
[2024-12-17 02:49:25,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:25,201][root][INFO] - Training Epoch: 2/2, step 4415/7134 completed (loss: 0.2475980967283249, acc: 0.9213483333587646)
[2024-12-17 02:49:25,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:25,485][root][INFO] - Training Epoch: 2/2, step 4416/7134 completed (loss: 0.16394080221652985, acc: 0.9430052042007446)
[2024-12-17 02:49:25,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:25,767][root][INFO] - Training Epoch: 2/2, step 4417/7134 completed (loss: 0.3316969573497772, acc: 0.9090909361839294)
[2024-12-17 02:49:25,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:26,051][root][INFO] - Training Epoch: 2/2, step 4418/7134 completed (loss: 0.24607490003108978, acc: 0.91847825050354)
[2024-12-17 02:49:26,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:26,324][root][INFO] - Training Epoch: 2/2, step 4419/7134 completed (loss: 0.30044519901275635, acc: 0.9365853667259216)
[2024-12-17 02:49:26,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:26,609][root][INFO] - Training Epoch: 2/2, step 4420/7134 completed (loss: 0.27622348070144653, acc: 0.9378238320350647)
[2024-12-17 02:49:26,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:26,886][root][INFO] - Training Epoch: 2/2, step 4421/7134 completed (loss: 0.2489660382270813, acc: 0.9403669834136963)
[2024-12-17 02:49:27,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:27,164][root][INFO] - Training Epoch: 2/2, step 4422/7134 completed (loss: 0.26733511686325073, acc: 0.9221556782722473)
[2024-12-17 02:49:27,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:27,441][root][INFO] - Training Epoch: 2/2, step 4423/7134 completed (loss: 0.23178096115589142, acc: 0.9375)
[2024-12-17 02:49:27,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:27,736][root][INFO] - Training Epoch: 2/2, step 4424/7134 completed (loss: 0.12736791372299194, acc: 0.9829545617103577)
[2024-12-17 02:49:27,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:28,023][root][INFO] - Training Epoch: 2/2, step 4425/7134 completed (loss: 0.1300678700208664, acc: 0.9752475023269653)
[2024-12-17 02:49:28,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:28,323][root][INFO] - Training Epoch: 2/2, step 4426/7134 completed (loss: 0.2449013739824295, acc: 0.9319999814033508)
[2024-12-17 02:49:28,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:28,583][root][INFO] - Training Epoch: 2/2, step 4427/7134 completed (loss: 0.4805026650428772, acc: 0.8879310488700867)
[2024-12-17 02:49:28,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:28,875][root][INFO] - Training Epoch: 2/2, step 4428/7134 completed (loss: 0.14778822660446167, acc: 0.9710982441902161)
[2024-12-17 02:49:28,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:29,121][root][INFO] - Training Epoch: 2/2, step 4429/7134 completed (loss: 0.28209009766578674, acc: 0.9047619104385376)
[2024-12-17 02:49:29,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:29,415][root][INFO] - Training Epoch: 2/2, step 4430/7134 completed (loss: 0.2789795994758606, acc: 0.932584285736084)
[2024-12-17 02:49:29,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:29,685][root][INFO] - Training Epoch: 2/2, step 4431/7134 completed (loss: 0.2148764431476593, acc: 0.930232584476471)
[2024-12-17 02:49:29,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:29,937][root][INFO] - Training Epoch: 2/2, step 4432/7134 completed (loss: 0.2667090892791748, acc: 0.9554139971733093)
[2024-12-17 02:49:30,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:30,227][root][INFO] - Training Epoch: 2/2, step 4433/7134 completed (loss: 0.2100011706352234, acc: 0.961904764175415)
[2024-12-17 02:49:30,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:30,522][root][INFO] - Training Epoch: 2/2, step 4434/7134 completed (loss: 0.24122564494609833, acc: 0.9314285516738892)
[2024-12-17 02:49:30,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:30,819][root][INFO] - Training Epoch: 2/2, step 4435/7134 completed (loss: 0.23247286677360535, acc: 0.9375)
[2024-12-17 02:49:30,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:31,111][root][INFO] - Training Epoch: 2/2, step 4436/7134 completed (loss: 0.2404976636171341, acc: 0.9289940595626831)
[2024-12-17 02:49:31,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:31,390][root][INFO] - Training Epoch: 2/2, step 4437/7134 completed (loss: 0.05576275661587715, acc: 0.9836065769195557)
[2024-12-17 02:49:31,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:31,666][root][INFO] - Training Epoch: 2/2, step 4438/7134 completed (loss: 0.22794295847415924, acc: 0.9552238583564758)
[2024-12-17 02:49:31,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:31,967][root][INFO] - Training Epoch: 2/2, step 4439/7134 completed (loss: 0.05009733512997627, acc: 0.9858155846595764)
[2024-12-17 02:49:32,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:32,279][root][INFO] - Training Epoch: 2/2, step 4440/7134 completed (loss: 0.08757670968770981, acc: 0.9698795080184937)
[2024-12-17 02:49:32,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:32,601][root][INFO] - Training Epoch: 2/2, step 4441/7134 completed (loss: 0.12109652161598206, acc: 0.9622641801834106)
[2024-12-17 02:49:32,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:32,885][root][INFO] - Training Epoch: 2/2, step 4442/7134 completed (loss: 0.22234921157360077, acc: 0.9438202381134033)
[2024-12-17 02:49:33,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:33,180][root][INFO] - Training Epoch: 2/2, step 4443/7134 completed (loss: 0.17787475883960724, acc: 0.9588235020637512)
[2024-12-17 02:49:33,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:33,464][root][INFO] - Training Epoch: 2/2, step 4444/7134 completed (loss: 0.11258351802825928, acc: 0.9635036587715149)
[2024-12-17 02:49:33,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:33,742][root][INFO] - Training Epoch: 2/2, step 4445/7134 completed (loss: 0.3163042366504669, acc: 0.9289940595626831)
[2024-12-17 02:49:33,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:34,031][root][INFO] - Training Epoch: 2/2, step 4446/7134 completed (loss: 0.07769978791475296, acc: 0.9844961166381836)
[2024-12-17 02:49:34,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:34,334][root][INFO] - Training Epoch: 2/2, step 4447/7134 completed (loss: 0.09430564194917679, acc: 0.977011501789093)
[2024-12-17 02:49:34,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:34,645][root][INFO] - Training Epoch: 2/2, step 4448/7134 completed (loss: 0.19606003165245056, acc: 0.961240291595459)
[2024-12-17 02:49:34,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:34,899][root][INFO] - Training Epoch: 2/2, step 4449/7134 completed (loss: 0.19672374427318573, acc: 0.9576271176338196)
[2024-12-17 02:49:35,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:35,194][root][INFO] - Training Epoch: 2/2, step 4450/7134 completed (loss: 0.26117080450057983, acc: 0.9308510422706604)
[2024-12-17 02:49:35,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:35,471][root][INFO] - Training Epoch: 2/2, step 4451/7134 completed (loss: 0.4006095230579376, acc: 0.9235668778419495)
[2024-12-17 02:49:35,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:35,757][root][INFO] - Training Epoch: 2/2, step 4452/7134 completed (loss: 0.14577238261699677, acc: 0.970370352268219)
[2024-12-17 02:49:35,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:36,018][root][INFO] - Training Epoch: 2/2, step 4453/7134 completed (loss: 0.14013491570949554, acc: 0.9673202633857727)
[2024-12-17 02:49:36,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:36,294][root][INFO] - Training Epoch: 2/2, step 4454/7134 completed (loss: 0.2723120152950287, acc: 0.9440993666648865)
[2024-12-17 02:49:36,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:36,571][root][INFO] - Training Epoch: 2/2, step 4455/7134 completed (loss: 0.36897099018096924, acc: 0.9537037014961243)
[2024-12-17 02:49:36,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:36,847][root][INFO] - Training Epoch: 2/2, step 4456/7134 completed (loss: 0.041846826672554016, acc: 0.9939393997192383)
[2024-12-17 02:49:36,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:37,098][root][INFO] - Training Epoch: 2/2, step 4457/7134 completed (loss: 0.12298189848661423, acc: 0.9740259647369385)
[2024-12-17 02:49:37,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:37,378][root][INFO] - Training Epoch: 2/2, step 4458/7134 completed (loss: 0.04650219902396202, acc: 0.9860140085220337)
[2024-12-17 02:49:37,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:37,650][root][INFO] - Training Epoch: 2/2, step 4459/7134 completed (loss: 0.08890961855649948, acc: 0.9767441749572754)
[2024-12-17 02:49:37,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:37,921][root][INFO] - Training Epoch: 2/2, step 4460/7134 completed (loss: 0.11048413813114166, acc: 0.9605911374092102)
[2024-12-17 02:49:38,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:38,204][root][INFO] - Training Epoch: 2/2, step 4461/7134 completed (loss: 0.14483433961868286, acc: 0.9635416865348816)
[2024-12-17 02:49:38,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:38,479][root][INFO] - Training Epoch: 2/2, step 4462/7134 completed (loss: 0.07772272825241089, acc: 0.977142870426178)
[2024-12-17 02:49:38,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:38,780][root][INFO] - Training Epoch: 2/2, step 4463/7134 completed (loss: 0.07617378234863281, acc: 0.9735449552536011)
[2024-12-17 02:49:38,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:39,103][root][INFO] - Training Epoch: 2/2, step 4464/7134 completed (loss: 0.16293011605739594, acc: 0.9452054500579834)
[2024-12-17 02:49:39,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:39,396][root][INFO] - Training Epoch: 2/2, step 4465/7134 completed (loss: 0.10582142323255539, acc: 0.9797979593276978)
[2024-12-17 02:49:39,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:39,685][root][INFO] - Training Epoch: 2/2, step 4466/7134 completed (loss: 0.08849302679300308, acc: 0.9747474789619446)
[2024-12-17 02:49:39,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:39,972][root][INFO] - Training Epoch: 2/2, step 4467/7134 completed (loss: 0.08133227378129959, acc: 0.9732620120048523)
[2024-12-17 02:49:40,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:40,239][root][INFO] - Training Epoch: 2/2, step 4468/7134 completed (loss: 0.027529148384928703, acc: 0.9946523904800415)
[2024-12-17 02:49:40,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:40,527][root][INFO] - Training Epoch: 2/2, step 4469/7134 completed (loss: 0.05268976837396622, acc: 0.9900990128517151)
[2024-12-17 02:49:40,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:40,821][root][INFO] - Training Epoch: 2/2, step 4470/7134 completed (loss: 0.05869518220424652, acc: 0.9855769276618958)
[2024-12-17 02:49:40,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:41,101][root][INFO] - Training Epoch: 2/2, step 4471/7134 completed (loss: 0.04772288724780083, acc: 0.9898989796638489)
[2024-12-17 02:49:41,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:41,376][root][INFO] - Training Epoch: 2/2, step 4472/7134 completed (loss: 0.06632262468338013, acc: 0.9777777791023254)
[2024-12-17 02:49:41,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:41,654][root][INFO] - Training Epoch: 2/2, step 4473/7134 completed (loss: 0.14641173183918, acc: 0.9526627063751221)
[2024-12-17 02:49:41,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:41,926][root][INFO] - Training Epoch: 2/2, step 4474/7134 completed (loss: 0.18596521019935608, acc: 0.95652174949646)
[2024-12-17 02:49:42,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:42,204][root][INFO] - Training Epoch: 2/2, step 4475/7134 completed (loss: 0.31286948919296265, acc: 0.936170220375061)
[2024-12-17 02:49:42,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:42,499][root][INFO] - Training Epoch: 2/2, step 4476/7134 completed (loss: 0.17080025374889374, acc: 0.9560439586639404)
[2024-12-17 02:49:42,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:42,792][root][INFO] - Training Epoch: 2/2, step 4477/7134 completed (loss: 0.06182241067290306, acc: 0.9846938848495483)
[2024-12-17 02:49:42,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:43,086][root][INFO] - Training Epoch: 2/2, step 4478/7134 completed (loss: 0.09883983433246613, acc: 0.9738219976425171)
[2024-12-17 02:49:43,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:43,380][root][INFO] - Training Epoch: 2/2, step 4479/7134 completed (loss: 0.09436187893152237, acc: 0.9722222089767456)
[2024-12-17 02:49:43,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:43,679][root][INFO] - Training Epoch: 2/2, step 4480/7134 completed (loss: 0.1975897252559662, acc: 0.9554455280303955)
[2024-12-17 02:49:43,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:43,965][root][INFO] - Training Epoch: 2/2, step 4481/7134 completed (loss: 0.1093798279762268, acc: 0.9750000238418579)
[2024-12-17 02:49:44,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:44,262][root][INFO] - Training Epoch: 2/2, step 4482/7134 completed (loss: 0.06535360962152481, acc: 0.9752475023269653)
[2024-12-17 02:49:44,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:44,540][root][INFO] - Training Epoch: 2/2, step 4483/7134 completed (loss: 0.22973549365997314, acc: 0.95652174949646)
[2024-12-17 02:49:44,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:44,836][root][INFO] - Training Epoch: 2/2, step 4484/7134 completed (loss: 0.08295115828514099, acc: 0.9659090638160706)
[2024-12-17 02:49:44,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:45,111][root][INFO] - Training Epoch: 2/2, step 4485/7134 completed (loss: 0.041036348789930344, acc: 0.9934640526771545)
[2024-12-17 02:49:45,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:45,379][root][INFO] - Training Epoch: 2/2, step 4486/7134 completed (loss: 0.06428582221269608, acc: 0.9875776171684265)
[2024-12-17 02:49:45,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:45,663][root][INFO] - Training Epoch: 2/2, step 4487/7134 completed (loss: 0.12408023327589035, acc: 0.9815950989723206)
[2024-12-17 02:49:45,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:45,920][root][INFO] - Training Epoch: 2/2, step 4488/7134 completed (loss: 0.12878012657165527, acc: 0.9689922332763672)
[2024-12-17 02:49:46,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:46,207][root][INFO] - Training Epoch: 2/2, step 4489/7134 completed (loss: 0.10287293791770935, acc: 0.9655172228813171)
[2024-12-17 02:49:46,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:46,503][root][INFO] - Training Epoch: 2/2, step 4490/7134 completed (loss: 0.10892108082771301, acc: 0.9760000109672546)
[2024-12-17 02:49:46,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:46,785][root][INFO] - Training Epoch: 2/2, step 4491/7134 completed (loss: 0.07006177306175232, acc: 0.9770992398262024)
[2024-12-17 02:49:46,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:47,069][root][INFO] - Training Epoch: 2/2, step 4492/7134 completed (loss: 0.09145057201385498, acc: 0.9849624037742615)
[2024-12-17 02:49:47,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:47,345][root][INFO] - Training Epoch: 2/2, step 4493/7134 completed (loss: 0.06496379524469376, acc: 0.9883720874786377)
[2024-12-17 02:49:47,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:47,633][root][INFO] - Training Epoch: 2/2, step 4494/7134 completed (loss: 0.055605825036764145, acc: 0.9887640476226807)
[2024-12-17 02:49:47,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:47,913][root][INFO] - Training Epoch: 2/2, step 4495/7134 completed (loss: 0.06863243877887726, acc: 0.9896907210350037)
[2024-12-17 02:49:48,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:48,189][root][INFO] - Training Epoch: 2/2, step 4496/7134 completed (loss: 0.12858349084854126, acc: 0.9473684430122375)
[2024-12-17 02:49:48,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:48,460][root][INFO] - Training Epoch: 2/2, step 4497/7134 completed (loss: 0.0540662445127964, acc: 0.9841269850730896)
[2024-12-17 02:49:48,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:48,750][root][INFO] - Training Epoch: 2/2, step 4498/7134 completed (loss: 0.04695030674338341, acc: 0.9884393215179443)
[2024-12-17 02:49:48,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:49,001][root][INFO] - Training Epoch: 2/2, step 4499/7134 completed (loss: 0.10037019103765488, acc: 0.9716312289237976)
[2024-12-17 02:49:49,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:49,286][root][INFO] - Training Epoch: 2/2, step 4500/7134 completed (loss: 0.07698726654052734, acc: 0.9732620120048523)
[2024-12-17 02:49:49,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:49,566][root][INFO] - Training Epoch: 2/2, step 4501/7134 completed (loss: 0.03878914564847946, acc: 0.988950252532959)
[2024-12-17 02:49:49,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:49,824][root][INFO] - Training Epoch: 2/2, step 4502/7134 completed (loss: 0.04406290873885155, acc: 0.9882352948188782)
[2024-12-17 02:49:49,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:50,090][root][INFO] - Training Epoch: 2/2, step 4503/7134 completed (loss: 0.02672719582915306, acc: 1.0)
[2024-12-17 02:49:50,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:50,372][root][INFO] - Training Epoch: 2/2, step 4504/7134 completed (loss: 0.19392570853233337, acc: 0.95652174949646)
[2024-12-17 02:49:50,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:50,655][root][INFO] - Training Epoch: 2/2, step 4505/7134 completed (loss: 0.11997456848621368, acc: 0.9675675630569458)
[2024-12-17 02:49:50,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:50,932][root][INFO] - Training Epoch: 2/2, step 4506/7134 completed (loss: 0.1448553502559662, acc: 0.9447852969169617)
[2024-12-17 02:49:51,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:51,224][root][INFO] - Training Epoch: 2/2, step 4507/7134 completed (loss: 0.051231060177087784, acc: 0.9935064911842346)
[2024-12-17 02:49:51,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:51,501][root][INFO] - Training Epoch: 2/2, step 4508/7134 completed (loss: 0.1561446636915207, acc: 0.95652174949646)
[2024-12-17 02:49:51,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:51,789][root][INFO] - Training Epoch: 2/2, step 4509/7134 completed (loss: 0.0912872925400734, acc: 0.9757575988769531)
[2024-12-17 02:49:51,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:52,069][root][INFO] - Training Epoch: 2/2, step 4510/7134 completed (loss: 0.18936090171337128, acc: 0.9583333134651184)
[2024-12-17 02:49:52,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:52,363][root][INFO] - Training Epoch: 2/2, step 4511/7134 completed (loss: 0.1783166527748108, acc: 0.9545454382896423)
[2024-12-17 02:49:52,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:52,623][root][INFO] - Training Epoch: 2/2, step 4512/7134 completed (loss: 0.2134837955236435, acc: 0.9629629850387573)
[2024-12-17 02:49:52,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:52,908][root][INFO] - Training Epoch: 2/2, step 4513/7134 completed (loss: 0.14610961079597473, acc: 0.9707602262496948)
[2024-12-17 02:49:53,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:53,200][root][INFO] - Training Epoch: 2/2, step 4514/7134 completed (loss: 0.353027880191803, acc: 0.9248554706573486)
[2024-12-17 02:49:53,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:53,478][root][INFO] - Training Epoch: 2/2, step 4515/7134 completed (loss: 0.13602125644683838, acc: 0.9605262875556946)
[2024-12-17 02:49:53,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:53,776][root][INFO] - Training Epoch: 2/2, step 4516/7134 completed (loss: 0.11669526994228363, acc: 0.9679144620895386)
[2024-12-17 02:49:53,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:54,071][root][INFO] - Training Epoch: 2/2, step 4517/7134 completed (loss: 0.1706731915473938, acc: 0.9549999833106995)
[2024-12-17 02:49:54,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:54,365][root][INFO] - Training Epoch: 2/2, step 4518/7134 completed (loss: 0.1385485827922821, acc: 0.969072163105011)
[2024-12-17 02:49:54,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:54,660][root][INFO] - Training Epoch: 2/2, step 4519/7134 completed (loss: 0.06912659108638763, acc: 0.9950248599052429)
[2024-12-17 02:49:54,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:54,943][root][INFO] - Training Epoch: 2/2, step 4520/7134 completed (loss: 0.07926801592111588, acc: 0.9839572310447693)
[2024-12-17 02:49:55,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:55,230][root][INFO] - Training Epoch: 2/2, step 4521/7134 completed (loss: 0.18475796282291412, acc: 0.9449999928474426)
[2024-12-17 02:49:55,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:55,517][root][INFO] - Training Epoch: 2/2, step 4522/7134 completed (loss: 0.16314518451690674, acc: 0.9573459625244141)
[2024-12-17 02:49:55,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:55,800][root][INFO] - Training Epoch: 2/2, step 4523/7134 completed (loss: 0.1989588439464569, acc: 0.9577465057373047)
[2024-12-17 02:49:55,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:56,084][root][INFO] - Training Epoch: 2/2, step 4524/7134 completed (loss: 0.1520354002714157, acc: 0.9581151604652405)
[2024-12-17 02:49:56,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:56,349][root][INFO] - Training Epoch: 2/2, step 4525/7134 completed (loss: 0.16810555756092072, acc: 0.9507389068603516)
[2024-12-17 02:49:56,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:56,624][root][INFO] - Training Epoch: 2/2, step 4526/7134 completed (loss: 0.21138952672481537, acc: 0.9505494236946106)
[2024-12-17 02:49:56,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:56,911][root][INFO] - Training Epoch: 2/2, step 4527/7134 completed (loss: 0.168804332613945, acc: 0.9461883306503296)
[2024-12-17 02:49:57,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:57,184][root][INFO] - Training Epoch: 2/2, step 4528/7134 completed (loss: 0.23012542724609375, acc: 0.9458128213882446)
[2024-12-17 02:49:57,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:57,443][root][INFO] - Training Epoch: 2/2, step 4529/7134 completed (loss: 0.16960713267326355, acc: 0.9528796076774597)
[2024-12-17 02:49:57,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:57,701][root][INFO] - Training Epoch: 2/2, step 4530/7134 completed (loss: 0.05446946248412132, acc: 0.9939024448394775)
[2024-12-17 02:49:57,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:57,981][root][INFO] - Training Epoch: 2/2, step 4531/7134 completed (loss: 0.05141027271747589, acc: 0.9921875)
[2024-12-17 02:49:58,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:58,264][root][INFO] - Training Epoch: 2/2, step 4532/7134 completed (loss: 0.214914008975029, acc: 0.945147693157196)
[2024-12-17 02:49:58,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:58,536][root][INFO] - Training Epoch: 2/2, step 4533/7134 completed (loss: 0.06440285593271255, acc: 0.9861111044883728)
[2024-12-17 02:49:58,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:58,807][root][INFO] - Training Epoch: 2/2, step 4534/7134 completed (loss: 0.08319225162267685, acc: 0.9746192693710327)
[2024-12-17 02:49:58,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:59,076][root][INFO] - Training Epoch: 2/2, step 4535/7134 completed (loss: 0.10075867921113968, acc: 0.9711538553237915)
[2024-12-17 02:49:59,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:59,378][root][INFO] - Training Epoch: 2/2, step 4536/7134 completed (loss: 0.04509596899151802, acc: 0.9919678568840027)
[2024-12-17 02:49:59,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:59,660][root][INFO] - Training Epoch: 2/2, step 4537/7134 completed (loss: 0.05860093981027603, acc: 0.9819004535675049)
[2024-12-17 02:49:59,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:59,961][root][INFO] - Training Epoch: 2/2, step 4538/7134 completed (loss: 0.13433738052845, acc: 0.966183602809906)
[2024-12-17 02:50:00,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:00,256][root][INFO] - Training Epoch: 2/2, step 4539/7134 completed (loss: 0.11244089156389236, acc: 0.9577465057373047)
[2024-12-17 02:50:00,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:00,536][root][INFO] - Training Epoch: 2/2, step 4540/7134 completed (loss: 0.16402718424797058, acc: 0.9523809552192688)
[2024-12-17 02:50:00,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:00,808][root][INFO] - Training Epoch: 2/2, step 4541/7134 completed (loss: 0.15855617821216583, acc: 0.9590163826942444)
[2024-12-17 02:50:00,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:01,074][root][INFO] - Training Epoch: 2/2, step 4542/7134 completed (loss: 0.3297892212867737, acc: 0.9122806787490845)
[2024-12-17 02:50:01,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:01,339][root][INFO] - Training Epoch: 2/2, step 4543/7134 completed (loss: 0.3694790303707123, acc: 0.9220778942108154)
[2024-12-17 02:50:01,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:01,622][root][INFO] - Training Epoch: 2/2, step 4544/7134 completed (loss: 0.1367245763540268, acc: 0.9594594836235046)
[2024-12-17 02:50:01,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:01,894][root][INFO] - Training Epoch: 2/2, step 4545/7134 completed (loss: 0.12063473463058472, acc: 0.9537037014961243)
[2024-12-17 02:50:01,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:02,153][root][INFO] - Training Epoch: 2/2, step 4546/7134 completed (loss: 0.1809544712305069, acc: 0.9763779640197754)
[2024-12-17 02:50:02,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:02,413][root][INFO] - Training Epoch: 2/2, step 4547/7134 completed (loss: 0.14185909926891327, acc: 0.9745762944221497)
[2024-12-17 02:50:02,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:02,705][root][INFO] - Training Epoch: 2/2, step 4548/7134 completed (loss: 0.16109605133533478, acc: 0.960629940032959)
[2024-12-17 02:50:02,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:02,962][root][INFO] - Training Epoch: 2/2, step 4549/7134 completed (loss: 0.2452082335948944, acc: 0.9561403393745422)
[2024-12-17 02:50:03,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:03,277][root][INFO] - Training Epoch: 2/2, step 4550/7134 completed (loss: 0.19115810096263885, acc: 0.9624060392379761)
[2024-12-17 02:50:03,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:03,560][root][INFO] - Training Epoch: 2/2, step 4551/7134 completed (loss: 0.22603105008602142, acc: 0.9459459185600281)
[2024-12-17 02:50:03,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:03,825][root][INFO] - Training Epoch: 2/2, step 4552/7134 completed (loss: 0.12569330632686615, acc: 0.9736841917037964)
[2024-12-17 02:50:03,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:04,081][root][INFO] - Training Epoch: 2/2, step 4553/7134 completed (loss: 0.1028524860739708, acc: 0.9696969985961914)
[2024-12-17 02:50:04,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:04,341][root][INFO] - Training Epoch: 2/2, step 4554/7134 completed (loss: 0.14016930758953094, acc: 0.956204354763031)
[2024-12-17 02:50:04,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:04,643][root][INFO] - Training Epoch: 2/2, step 4555/7134 completed (loss: 0.18653975427150726, acc: 0.9583333134651184)
[2024-12-17 02:50:04,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:04,932][root][INFO] - Training Epoch: 2/2, step 4556/7134 completed (loss: 0.3151474595069885, acc: 0.9225806593894958)
[2024-12-17 02:50:05,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:05,170][root][INFO] - Training Epoch: 2/2, step 4557/7134 completed (loss: 0.083431176841259, acc: 0.9701492786407471)
[2024-12-17 02:50:05,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:05,424][root][INFO] - Training Epoch: 2/2, step 4558/7134 completed (loss: 0.21244235336780548, acc: 0.9379844665527344)
[2024-12-17 02:50:05,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:05,711][root][INFO] - Training Epoch: 2/2, step 4559/7134 completed (loss: 0.33415845036506653, acc: 0.9242424368858337)
[2024-12-17 02:50:05,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:05,981][root][INFO] - Training Epoch: 2/2, step 4560/7134 completed (loss: 0.087245412170887, acc: 0.975806474685669)
[2024-12-17 02:50:06,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:06,242][root][INFO] - Training Epoch: 2/2, step 4561/7134 completed (loss: 0.1756647676229477, acc: 0.9672130942344666)
[2024-12-17 02:50:06,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:06,493][root][INFO] - Training Epoch: 2/2, step 4562/7134 completed (loss: 0.20896819233894348, acc: 0.934959352016449)
[2024-12-17 02:50:06,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:06,784][root][INFO] - Training Epoch: 2/2, step 4563/7134 completed (loss: 0.12436158210039139, acc: 0.9858155846595764)
[2024-12-17 02:50:06,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:07,073][root][INFO] - Training Epoch: 2/2, step 4564/7134 completed (loss: 0.27279388904571533, acc: 0.9350649118423462)
[2024-12-17 02:50:07,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:07,330][root][INFO] - Training Epoch: 2/2, step 4565/7134 completed (loss: 0.14464199542999268, acc: 0.9557521939277649)
[2024-12-17 02:50:07,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:07,648][root][INFO] - Training Epoch: 2/2, step 4566/7134 completed (loss: 0.26081350445747375, acc: 0.932330846786499)
[2024-12-17 02:50:07,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:07,909][root][INFO] - Training Epoch: 2/2, step 4567/7134 completed (loss: 0.05608915165066719, acc: 0.9909909963607788)
[2024-12-17 02:50:08,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:08,184][root][INFO] - Training Epoch: 2/2, step 4568/7134 completed (loss: 0.1884777694940567, acc: 0.9684210419654846)
[2024-12-17 02:50:08,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:08,460][root][INFO] - Training Epoch: 2/2, step 4569/7134 completed (loss: 0.09276922047138214, acc: 0.9734513163566589)
[2024-12-17 02:50:08,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:08,739][root][INFO] - Training Epoch: 2/2, step 4570/7134 completed (loss: 0.15065866708755493, acc: 0.9610389471054077)
[2024-12-17 02:50:08,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:09,030][root][INFO] - Training Epoch: 2/2, step 4571/7134 completed (loss: 0.11577176302671432, acc: 0.959770143032074)
[2024-12-17 02:50:09,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:09,309][root][INFO] - Training Epoch: 2/2, step 4572/7134 completed (loss: 0.14946356415748596, acc: 0.9605262875556946)
[2024-12-17 02:50:09,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:09,597][root][INFO] - Training Epoch: 2/2, step 4573/7134 completed (loss: 0.11259288340806961, acc: 0.9679487347602844)
[2024-12-17 02:50:09,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:09,878][root][INFO] - Training Epoch: 2/2, step 4574/7134 completed (loss: 0.08411972969770432, acc: 0.9848484992980957)
[2024-12-17 02:50:10,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:10,168][root][INFO] - Training Epoch: 2/2, step 4575/7134 completed (loss: 0.11357437819242477, acc: 0.9723756909370422)
[2024-12-17 02:50:10,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:10,447][root][INFO] - Training Epoch: 2/2, step 4576/7134 completed (loss: 0.10872332751750946, acc: 0.977142870426178)
[2024-12-17 02:50:10,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:10,722][root][INFO] - Training Epoch: 2/2, step 4577/7134 completed (loss: 0.1860741674900055, acc: 0.9418604373931885)
[2024-12-17 02:50:10,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:10,998][root][INFO] - Training Epoch: 2/2, step 4578/7134 completed (loss: 0.0908106118440628, acc: 0.9757575988769531)
[2024-12-17 02:50:11,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:11,277][root][INFO] - Training Epoch: 2/2, step 4579/7134 completed (loss: 0.18703286349773407, acc: 0.9620253443717957)
[2024-12-17 02:50:11,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:11,554][root][INFO] - Training Epoch: 2/2, step 4580/7134 completed (loss: 0.12830018997192383, acc: 0.9556962251663208)
[2024-12-17 02:50:11,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:11,836][root][INFO] - Training Epoch: 2/2, step 4581/7134 completed (loss: 0.031117193400859833, acc: 0.9930070042610168)
[2024-12-17 02:50:11,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:12,123][root][INFO] - Training Epoch: 2/2, step 4582/7134 completed (loss: 0.11922037601470947, acc: 0.9722222089767456)
[2024-12-17 02:50:12,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:12,378][root][INFO] - Training Epoch: 2/2, step 4583/7134 completed (loss: 0.07048963010311127, acc: 0.9800000190734863)
[2024-12-17 02:50:12,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:12,662][root][INFO] - Training Epoch: 2/2, step 4584/7134 completed (loss: 0.059774044901132584, acc: 1.0)
[2024-12-17 02:50:12,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:12,951][root][INFO] - Training Epoch: 2/2, step 4585/7134 completed (loss: 0.05064895749092102, acc: 0.9871794581413269)
[2024-12-17 02:50:13,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:13,239][root][INFO] - Training Epoch: 2/2, step 4586/7134 completed (loss: 0.12535469233989716, acc: 0.9704142212867737)
[2024-12-17 02:50:13,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:13,527][root][INFO] - Training Epoch: 2/2, step 4587/7134 completed (loss: 0.32471582293510437, acc: 0.9534883499145508)
[2024-12-17 02:50:13,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:13,810][root][INFO] - Training Epoch: 2/2, step 4588/7134 completed (loss: 0.17126934230327606, acc: 0.956250011920929)
[2024-12-17 02:50:13,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:14,106][root][INFO] - Training Epoch: 2/2, step 4589/7134 completed (loss: 0.14573223888874054, acc: 0.9712643623352051)
[2024-12-17 02:50:14,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:14,396][root][INFO] - Training Epoch: 2/2, step 4590/7134 completed (loss: 0.1338341236114502, acc: 0.9702380895614624)
[2024-12-17 02:50:14,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:14,681][root][INFO] - Training Epoch: 2/2, step 4591/7134 completed (loss: 0.1979060173034668, acc: 0.9659090638160706)
[2024-12-17 02:50:14,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:14,947][root][INFO] - Training Epoch: 2/2, step 4592/7134 completed (loss: 0.11817692220211029, acc: 0.9695122241973877)
[2024-12-17 02:50:15,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:15,243][root][INFO] - Training Epoch: 2/2, step 4593/7134 completed (loss: 0.20315846800804138, acc: 0.9342105388641357)
[2024-12-17 02:50:15,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:15,538][root][INFO] - Training Epoch: 2/2, step 4594/7134 completed (loss: 0.30250024795532227, acc: 0.9259259104728699)
[2024-12-17 02:50:15,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:15,828][root][INFO] - Training Epoch: 2/2, step 4595/7134 completed (loss: 0.16914859414100647, acc: 0.9430379867553711)
[2024-12-17 02:50:15,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:16,109][root][INFO] - Training Epoch: 2/2, step 4596/7134 completed (loss: 0.13519427180290222, acc: 0.96875)
[2024-12-17 02:50:16,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:16,392][root][INFO] - Training Epoch: 2/2, step 4597/7134 completed (loss: 0.11583209782838821, acc: 0.9743589758872986)
[2024-12-17 02:50:16,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:16,682][root][INFO] - Training Epoch: 2/2, step 4598/7134 completed (loss: 0.21254470944404602, acc: 0.9405405521392822)
[2024-12-17 02:50:16,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:16,951][root][INFO] - Training Epoch: 2/2, step 4599/7134 completed (loss: 0.049306921660900116, acc: 1.0)
[2024-12-17 02:50:17,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:17,232][root][INFO] - Training Epoch: 2/2, step 4600/7134 completed (loss: 0.11458972841501236, acc: 0.9685534834861755)
[2024-12-17 02:50:17,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:17,526][root][INFO] - Training Epoch: 2/2, step 4601/7134 completed (loss: 0.0752730667591095, acc: 0.9774011373519897)
[2024-12-17 02:50:17,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:17,805][root][INFO] - Training Epoch: 2/2, step 4602/7134 completed (loss: 0.19066829979419708, acc: 0.949999988079071)
[2024-12-17 02:50:17,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:18,077][root][INFO] - Training Epoch: 2/2, step 4603/7134 completed (loss: 0.14678190648555756, acc: 0.9593023061752319)
[2024-12-17 02:50:18,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:18,348][root][INFO] - Training Epoch: 2/2, step 4604/7134 completed (loss: 0.15464143455028534, acc: 0.9510489702224731)
[2024-12-17 02:50:18,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:18,627][root][INFO] - Training Epoch: 2/2, step 4605/7134 completed (loss: 0.16479076445102692, acc: 0.9363636374473572)
[2024-12-17 02:50:18,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:18,912][root][INFO] - Training Epoch: 2/2, step 4606/7134 completed (loss: 0.08989810943603516, acc: 0.9748427867889404)
[2024-12-17 02:50:19,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:19,195][root][INFO] - Training Epoch: 2/2, step 4607/7134 completed (loss: 0.09800238162279129, acc: 0.9645389914512634)
[2024-12-17 02:50:19,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:19,477][root][INFO] - Training Epoch: 2/2, step 4608/7134 completed (loss: 0.1018570214509964, acc: 0.9824561476707458)
[2024-12-17 02:50:19,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:19,759][root][INFO] - Training Epoch: 2/2, step 4609/7134 completed (loss: 0.09273933619260788, acc: 0.9618320465087891)
[2024-12-17 02:50:19,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:20,043][root][INFO] - Training Epoch: 2/2, step 4610/7134 completed (loss: 0.053116101771593094, acc: 0.9832402467727661)
[2024-12-17 02:50:20,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:20,320][root][INFO] - Training Epoch: 2/2, step 4611/7134 completed (loss: 0.08543284982442856, acc: 0.9724137783050537)
[2024-12-17 02:50:20,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:20,607][root][INFO] - Training Epoch: 2/2, step 4612/7134 completed (loss: 0.13393063843250275, acc: 0.970370352268219)
[2024-12-17 02:50:20,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:20,878][root][INFO] - Training Epoch: 2/2, step 4613/7134 completed (loss: 0.12336014211177826, acc: 0.9814814925193787)
[2024-12-17 02:50:20,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:21,158][root][INFO] - Training Epoch: 2/2, step 4614/7134 completed (loss: 0.09490440040826797, acc: 0.9769230484962463)
[2024-12-17 02:50:21,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:21,447][root][INFO] - Training Epoch: 2/2, step 4615/7134 completed (loss: 0.18037192523479462, acc: 0.946107804775238)
[2024-12-17 02:50:21,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:21,735][root][INFO] - Training Epoch: 2/2, step 4616/7134 completed (loss: 0.21239235997200012, acc: 0.9360465407371521)
[2024-12-17 02:50:21,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:21,984][root][INFO] - Training Epoch: 2/2, step 4617/7134 completed (loss: 0.33278387784957886, acc: 0.9341317415237427)
[2024-12-17 02:50:22,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:22,249][root][INFO] - Training Epoch: 2/2, step 4618/7134 completed (loss: 0.2677590250968933, acc: 0.9147287011146545)
[2024-12-17 02:50:22,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:22,530][root][INFO] - Training Epoch: 2/2, step 4619/7134 completed (loss: 0.2583243250846863, acc: 0.9624999761581421)
[2024-12-17 02:50:22,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:22,819][root][INFO] - Training Epoch: 2/2, step 4620/7134 completed (loss: 0.05584527924656868, acc: 0.9941176176071167)
[2024-12-17 02:50:22,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:23,095][root][INFO] - Training Epoch: 2/2, step 4621/7134 completed (loss: 0.06909552216529846, acc: 0.9878048896789551)
[2024-12-17 02:50:23,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:23,361][root][INFO] - Training Epoch: 2/2, step 4622/7134 completed (loss: 0.09560465067625046, acc: 0.9833333492279053)
[2024-12-17 02:50:23,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:23,634][root][INFO] - Training Epoch: 2/2, step 4623/7134 completed (loss: 0.14591696858406067, acc: 0.9647058844566345)
[2024-12-17 02:50:23,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:23,996][root][INFO] - Training Epoch: 2/2, step 4624/7134 completed (loss: 0.23073746263980865, acc: 0.9176470637321472)
[2024-12-17 02:50:24,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:24,272][root][INFO] - Training Epoch: 2/2, step 4625/7134 completed (loss: 0.3366715610027313, acc: 0.9141104221343994)
[2024-12-17 02:50:24,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:24,552][root][INFO] - Training Epoch: 2/2, step 4626/7134 completed (loss: 0.3192010521888733, acc: 0.9239130616188049)
[2024-12-17 02:50:24,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:24,823][root][INFO] - Training Epoch: 2/2, step 4627/7134 completed (loss: 0.21644528210163116, acc: 0.948387086391449)
[2024-12-17 02:50:24,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:25,114][root][INFO] - Training Epoch: 2/2, step 4628/7134 completed (loss: 0.14593291282653809, acc: 0.9634146094322205)
[2024-12-17 02:50:25,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:25,387][root][INFO] - Training Epoch: 2/2, step 4629/7134 completed (loss: 0.23189115524291992, acc: 0.948051929473877)
[2024-12-17 02:50:25,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:25,677][root][INFO] - Training Epoch: 2/2, step 4630/7134 completed (loss: 0.17096777260303497, acc: 0.9722222089767456)
[2024-12-17 02:50:25,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:25,973][root][INFO] - Training Epoch: 2/2, step 4631/7134 completed (loss: 0.11794207990169525, acc: 0.9720930457115173)
[2024-12-17 02:50:26,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:26,276][root][INFO] - Training Epoch: 2/2, step 4632/7134 completed (loss: 0.1446276307106018, acc: 0.9759036302566528)
[2024-12-17 02:50:26,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:26,545][root][INFO] - Training Epoch: 2/2, step 4633/7134 completed (loss: 0.28035542368888855, acc: 0.9497717022895813)
[2024-12-17 02:50:26,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:26,818][root][INFO] - Training Epoch: 2/2, step 4634/7134 completed (loss: 0.18294861912727356, acc: 0.9481481313705444)
[2024-12-17 02:50:26,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:27,051][root][INFO] - Training Epoch: 2/2, step 4635/7134 completed (loss: 0.2819041609764099, acc: 0.9634146094322205)
[2024-12-17 02:50:27,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:27,295][root][INFO] - Training Epoch: 2/2, step 4636/7134 completed (loss: 0.0781550258398056, acc: 0.978723406791687)
[2024-12-17 02:50:27,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:27,576][root][INFO] - Training Epoch: 2/2, step 4637/7134 completed (loss: 0.15866142511367798, acc: 0.9682539701461792)
[2024-12-17 02:50:27,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:27,867][root][INFO] - Training Epoch: 2/2, step 4638/7134 completed (loss: 0.20461194217205048, acc: 0.9710982441902161)
[2024-12-17 02:50:28,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:28,153][root][INFO] - Training Epoch: 2/2, step 4639/7134 completed (loss: 0.10786698013544083, acc: 0.9783783555030823)
[2024-12-17 02:50:28,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:28,444][root][INFO] - Training Epoch: 2/2, step 4640/7134 completed (loss: 0.1866830438375473, acc: 0.9682539701461792)
[2024-12-17 02:50:28,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:28,709][root][INFO] - Training Epoch: 2/2, step 4641/7134 completed (loss: 0.15297479927539825, acc: 0.9652777910232544)
[2024-12-17 02:50:28,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:28,980][root][INFO] - Training Epoch: 2/2, step 4642/7134 completed (loss: 0.08093796670436859, acc: 0.9661017060279846)
[2024-12-17 02:50:29,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:29,270][root][INFO] - Training Epoch: 2/2, step 4643/7134 completed (loss: 0.08181316405534744, acc: 0.9853658676147461)
[2024-12-17 02:50:29,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:29,557][root][INFO] - Training Epoch: 2/2, step 4644/7134 completed (loss: 0.07092733681201935, acc: 0.9802955389022827)
[2024-12-17 02:50:29,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:29,836][root][INFO] - Training Epoch: 2/2, step 4645/7134 completed (loss: 0.04569477215409279, acc: 0.9817073345184326)
[2024-12-17 02:50:29,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:30,109][root][INFO] - Training Epoch: 2/2, step 4646/7134 completed (loss: 0.10646010935306549, acc: 0.9714285731315613)
[2024-12-17 02:50:30,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:30,395][root][INFO] - Training Epoch: 2/2, step 4647/7134 completed (loss: 0.23250161111354828, acc: 0.9508196711540222)
[2024-12-17 02:50:30,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:30,671][root][INFO] - Training Epoch: 2/2, step 4648/7134 completed (loss: 0.21429571509361267, acc: 0.9299362897872925)
[2024-12-17 02:50:30,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:30,950][root][INFO] - Training Epoch: 2/2, step 4649/7134 completed (loss: 0.17476055026054382, acc: 0.9430894255638123)
[2024-12-17 02:50:31,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:31,235][root][INFO] - Training Epoch: 2/2, step 4650/7134 completed (loss: 0.19719621539115906, acc: 0.9324324131011963)
[2024-12-17 02:50:31,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:31,503][root][INFO] - Training Epoch: 2/2, step 4651/7134 completed (loss: 0.25829729437828064, acc: 0.9329608678817749)
[2024-12-17 02:50:31,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:31,776][root][INFO] - Training Epoch: 2/2, step 4652/7134 completed (loss: 0.1190686896443367, acc: 0.9567901492118835)
[2024-12-17 02:50:31,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:32,069][root][INFO] - Training Epoch: 2/2, step 4653/7134 completed (loss: 0.13294930756092072, acc: 0.9613526463508606)
[2024-12-17 02:50:32,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:32,360][root][INFO] - Training Epoch: 2/2, step 4654/7134 completed (loss: 0.29342564940452576, acc: 0.9405405521392822)
[2024-12-17 02:50:32,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:32,655][root][INFO] - Training Epoch: 2/2, step 4655/7134 completed (loss: 0.2643422484397888, acc: 0.9371428489685059)
[2024-12-17 02:50:32,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:32,946][root][INFO] - Training Epoch: 2/2, step 4656/7134 completed (loss: 0.19305163621902466, acc: 0.9322034120559692)
[2024-12-17 02:50:33,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:33,220][root][INFO] - Training Epoch: 2/2, step 4657/7134 completed (loss: 0.17121969163417816, acc: 0.9425287246704102)
[2024-12-17 02:50:33,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:33,495][root][INFO] - Training Epoch: 2/2, step 4658/7134 completed (loss: 0.21453189849853516, acc: 0.9147727489471436)
[2024-12-17 02:50:33,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:33,784][root][INFO] - Training Epoch: 2/2, step 4659/7134 completed (loss: 0.16116522252559662, acc: 0.9629629850387573)
[2024-12-17 02:50:33,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:34,071][root][INFO] - Training Epoch: 2/2, step 4660/7134 completed (loss: 0.23541203141212463, acc: 0.942307710647583)
[2024-12-17 02:50:34,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:34,330][root][INFO] - Training Epoch: 2/2, step 4661/7134 completed (loss: 0.19168482720851898, acc: 0.9570552110671997)
[2024-12-17 02:50:34,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:34,596][root][INFO] - Training Epoch: 2/2, step 4662/7134 completed (loss: 0.2861126959323883, acc: 0.9503546357154846)
[2024-12-17 02:50:34,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:34,889][root][INFO] - Training Epoch: 2/2, step 4663/7134 completed (loss: 0.2194673866033554, acc: 0.9289617538452148)
[2024-12-17 02:50:35,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:35,182][root][INFO] - Training Epoch: 2/2, step 4664/7134 completed (loss: 0.16258488595485687, acc: 0.9621621370315552)
[2024-12-17 02:50:35,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:35,464][root][INFO] - Training Epoch: 2/2, step 4665/7134 completed (loss: 0.16887784004211426, acc: 0.9505494236946106)
[2024-12-17 02:50:35,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:35,761][root][INFO] - Training Epoch: 2/2, step 4666/7134 completed (loss: 0.2921905815601349, acc: 0.9326424598693848)
[2024-12-17 02:50:35,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:36,015][root][INFO] - Training Epoch: 2/2, step 4667/7134 completed (loss: 0.27394917607307434, acc: 0.9256756901741028)
[2024-12-17 02:50:36,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:36,283][root][INFO] - Training Epoch: 2/2, step 4668/7134 completed (loss: 0.09495984762907028, acc: 0.9798657894134521)
[2024-12-17 02:50:36,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:36,566][root][INFO] - Training Epoch: 2/2, step 4669/7134 completed (loss: 0.16809777915477753, acc: 0.9548022747039795)
[2024-12-17 02:50:36,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:36,837][root][INFO] - Training Epoch: 2/2, step 4670/7134 completed (loss: 0.15726611018180847, acc: 0.9552238583564758)
[2024-12-17 02:50:36,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:37,129][root][INFO] - Training Epoch: 2/2, step 4671/7134 completed (loss: 0.13632851839065552, acc: 0.9617486596107483)
[2024-12-17 02:50:37,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:37,408][root][INFO] - Training Epoch: 2/2, step 4672/7134 completed (loss: 0.12129596620798111, acc: 0.9655172228813171)
[2024-12-17 02:50:37,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:37,681][root][INFO] - Training Epoch: 2/2, step 4673/7134 completed (loss: 0.14462357759475708, acc: 0.9622641801834106)
[2024-12-17 02:50:37,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:37,954][root][INFO] - Training Epoch: 2/2, step 4674/7134 completed (loss: 0.1187298372387886, acc: 0.9675324559211731)
[2024-12-17 02:50:38,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:38,238][root][INFO] - Training Epoch: 2/2, step 4675/7134 completed (loss: 0.15703856945037842, acc: 0.964102566242218)
[2024-12-17 02:50:38,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:38,517][root][INFO] - Training Epoch: 2/2, step 4676/7134 completed (loss: 0.08266624063253403, acc: 0.9805194735527039)
[2024-12-17 02:50:38,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:38,777][root][INFO] - Training Epoch: 2/2, step 4677/7134 completed (loss: 0.14752601087093353, acc: 0.9579831957817078)
[2024-12-17 02:50:38,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:39,053][root][INFO] - Training Epoch: 2/2, step 4678/7134 completed (loss: 0.17329075932502747, acc: 0.970059871673584)
[2024-12-17 02:50:39,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:39,336][root][INFO] - Training Epoch: 2/2, step 4679/7134 completed (loss: 0.13879092037677765, acc: 0.9653179049491882)
[2024-12-17 02:50:39,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:39,593][root][INFO] - Training Epoch: 2/2, step 4680/7134 completed (loss: 0.26248249411582947, acc: 0.9545454382896423)
[2024-12-17 02:50:39,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:39,850][root][INFO] - Training Epoch: 2/2, step 4681/7134 completed (loss: 0.2423388957977295, acc: 0.9285714030265808)
[2024-12-17 02:50:39,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:40,143][root][INFO] - Training Epoch: 2/2, step 4682/7134 completed (loss: 0.1202043741941452, acc: 0.9558011293411255)
[2024-12-17 02:50:40,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:40,396][root][INFO] - Training Epoch: 2/2, step 4683/7134 completed (loss: 0.16225628554821014, acc: 0.9599999785423279)
[2024-12-17 02:50:40,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:40,680][root][INFO] - Training Epoch: 2/2, step 4684/7134 completed (loss: 0.1922491192817688, acc: 0.9432989954948425)
[2024-12-17 02:50:40,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:40,965][root][INFO] - Training Epoch: 2/2, step 4685/7134 completed (loss: 0.09058681130409241, acc: 0.9802955389022827)
[2024-12-17 02:50:41,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:41,251][root][INFO] - Training Epoch: 2/2, step 4686/7134 completed (loss: 0.09168888628482819, acc: 0.9894179701805115)
[2024-12-17 02:50:41,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:41,504][root][INFO] - Training Epoch: 2/2, step 4687/7134 completed (loss: 0.3944459557533264, acc: 0.9021739363670349)
[2024-12-17 02:50:41,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:41,784][root][INFO] - Training Epoch: 2/2, step 4688/7134 completed (loss: 0.7998352646827698, acc: 0.8671875)
[2024-12-17 02:50:41,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:42,079][root][INFO] - Training Epoch: 2/2, step 4689/7134 completed (loss: 0.48439863324165344, acc: 0.8735632300376892)
[2024-12-17 02:50:42,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:42,356][root][INFO] - Training Epoch: 2/2, step 4690/7134 completed (loss: 0.4247863292694092, acc: 0.9122806787490845)
[2024-12-17 02:50:42,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:42,607][root][INFO] - Training Epoch: 2/2, step 4691/7134 completed (loss: 0.16573466360569, acc: 0.964102566242218)
[2024-12-17 02:50:42,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:42,841][root][INFO] - Training Epoch: 2/2, step 4692/7134 completed (loss: 0.6003081202507019, acc: 0.8730158805847168)
[2024-12-17 02:50:42,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:43,147][root][INFO] - Training Epoch: 2/2, step 4693/7134 completed (loss: 0.6878153085708618, acc: 0.845714271068573)
[2024-12-17 02:50:43,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:43,405][root][INFO] - Training Epoch: 2/2, step 4694/7134 completed (loss: 0.46875882148742676, acc: 0.89682537317276)
[2024-12-17 02:50:43,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:43,688][root][INFO] - Training Epoch: 2/2, step 4695/7134 completed (loss: 0.4196139872074127, acc: 0.9266666769981384)
[2024-12-17 02:50:43,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:43,969][root][INFO] - Training Epoch: 2/2, step 4696/7134 completed (loss: 0.08425651490688324, acc: 0.9757575988769531)
[2024-12-17 02:50:44,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:44,239][root][INFO] - Training Epoch: 2/2, step 4697/7134 completed (loss: 0.1071493923664093, acc: 0.9603174328804016)
[2024-12-17 02:50:44,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:44,496][root][INFO] - Training Epoch: 2/2, step 4698/7134 completed (loss: 0.48311200737953186, acc: 0.8714285492897034)
[2024-12-17 02:50:44,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:44,776][root][INFO] - Training Epoch: 2/2, step 4699/7134 completed (loss: 0.3741942346096039, acc: 0.9136690497398376)
[2024-12-17 02:50:44,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:45,053][root][INFO] - Training Epoch: 2/2, step 4700/7134 completed (loss: 0.290885865688324, acc: 0.9289940595626831)
[2024-12-17 02:50:45,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:45,281][root][INFO] - Training Epoch: 2/2, step 4701/7134 completed (loss: 0.5995885133743286, acc: 0.862500011920929)
[2024-12-17 02:50:45,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:45,572][root][INFO] - Training Epoch: 2/2, step 4702/7134 completed (loss: 0.17874106764793396, acc: 0.948387086391449)
[2024-12-17 02:50:45,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:45,858][root][INFO] - Training Epoch: 2/2, step 4703/7134 completed (loss: 0.10118746757507324, acc: 0.9823529124259949)
[2024-12-17 02:50:45,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:46,147][root][INFO] - Training Epoch: 2/2, step 4704/7134 completed (loss: 0.11969301104545593, acc: 0.9846153855323792)
[2024-12-17 02:50:46,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:46,447][root][INFO] - Training Epoch: 2/2, step 4705/7134 completed (loss: 0.23667538166046143, acc: 0.931034505367279)
[2024-12-17 02:50:46,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:46,743][root][INFO] - Training Epoch: 2/2, step 4706/7134 completed (loss: 0.27032095193862915, acc: 0.9487179517745972)
[2024-12-17 02:50:46,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:47,024][root][INFO] - Training Epoch: 2/2, step 4707/7134 completed (loss: 0.8199313879013062, acc: 0.849056601524353)
[2024-12-17 02:50:47,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:47,295][root][INFO] - Training Epoch: 2/2, step 4708/7134 completed (loss: 0.19240282475948334, acc: 0.9346733689308167)
[2024-12-17 02:50:47,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:47,585][root][INFO] - Training Epoch: 2/2, step 4709/7134 completed (loss: 0.09403613209724426, acc: 0.9891892075538635)
[2024-12-17 02:50:47,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:47,870][root][INFO] - Training Epoch: 2/2, step 4710/7134 completed (loss: 0.1720944344997406, acc: 0.9454545378684998)
[2024-12-17 02:50:48,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:48,173][root][INFO] - Training Epoch: 2/2, step 4711/7134 completed (loss: 0.20909787714481354, acc: 0.9594594836235046)
[2024-12-17 02:50:48,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:48,451][root][INFO] - Training Epoch: 2/2, step 4712/7134 completed (loss: 0.45955803990364075, acc: 0.9084967374801636)
[2024-12-17 02:50:48,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:48,735][root][INFO] - Training Epoch: 2/2, step 4713/7134 completed (loss: 0.16111640632152557, acc: 0.9552238583564758)
[2024-12-17 02:50:48,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:49,002][root][INFO] - Training Epoch: 2/2, step 4714/7134 completed (loss: 0.2847597002983093, acc: 0.9312977194786072)
[2024-12-17 02:50:49,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:49,294][root][INFO] - Training Epoch: 2/2, step 4715/7134 completed (loss: 0.43624258041381836, acc: 0.9416666626930237)
[2024-12-17 02:50:49,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:49,557][root][INFO] - Training Epoch: 2/2, step 4716/7134 completed (loss: 0.10638643056154251, acc: 0.9741935729980469)
[2024-12-17 02:50:49,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:49,814][root][INFO] - Training Epoch: 2/2, step 4717/7134 completed (loss: 0.11359832435846329, acc: 0.9599999785423279)
[2024-12-17 02:50:49,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:50,083][root][INFO] - Training Epoch: 2/2, step 4718/7134 completed (loss: 0.0749475285410881, acc: 0.9784172773361206)
[2024-12-17 02:50:50,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:50,362][root][INFO] - Training Epoch: 2/2, step 4719/7134 completed (loss: 0.09479247033596039, acc: 0.9704142212867737)
[2024-12-17 02:50:50,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:50,647][root][INFO] - Training Epoch: 2/2, step 4720/7134 completed (loss: 0.03348013013601303, acc: 0.9937499761581421)
[2024-12-17 02:50:50,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:50,912][root][INFO] - Training Epoch: 2/2, step 4721/7134 completed (loss: 0.04210616648197174, acc: 0.9876543283462524)
[2024-12-17 02:50:51,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:51,184][root][INFO] - Training Epoch: 2/2, step 4722/7134 completed (loss: 0.16318558156490326, acc: 0.9622641801834106)
[2024-12-17 02:50:51,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:51,446][root][INFO] - Training Epoch: 2/2, step 4723/7134 completed (loss: 0.11084787547588348, acc: 0.9808917045593262)
[2024-12-17 02:50:51,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:51,741][root][INFO] - Training Epoch: 2/2, step 4724/7134 completed (loss: 0.14709530770778656, acc: 0.957317054271698)
[2024-12-17 02:50:51,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:52,013][root][INFO] - Training Epoch: 2/2, step 4725/7134 completed (loss: 0.17435508966445923, acc: 0.9476743936538696)
[2024-12-17 02:50:52,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:52,315][root][INFO] - Training Epoch: 2/2, step 4726/7134 completed (loss: 0.24934624135494232, acc: 0.931034505367279)
[2024-12-17 02:50:52,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:52,580][root][INFO] - Training Epoch: 2/2, step 4727/7134 completed (loss: 0.1396099179983139, acc: 0.9735099077224731)
[2024-12-17 02:50:52,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:52,865][root][INFO] - Training Epoch: 2/2, step 4728/7134 completed (loss: 0.20047074556350708, acc: 0.9337748289108276)
[2024-12-17 02:50:52,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:53,145][root][INFO] - Training Epoch: 2/2, step 4729/7134 completed (loss: 0.07287313044071198, acc: 0.9768785834312439)
[2024-12-17 02:50:53,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:53,432][root][INFO] - Training Epoch: 2/2, step 4730/7134 completed (loss: 0.17208288609981537, acc: 0.9649122953414917)
[2024-12-17 02:50:53,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:53,704][root][INFO] - Training Epoch: 2/2, step 4731/7134 completed (loss: 0.307265043258667, acc: 0.9379310607910156)
[2024-12-17 02:50:53,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:53,971][root][INFO] - Training Epoch: 2/2, step 4732/7134 completed (loss: 0.170857772231102, acc: 0.9411764740943909)
[2024-12-17 02:50:54,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:54,247][root][INFO] - Training Epoch: 2/2, step 4733/7134 completed (loss: 0.19766239821910858, acc: 0.9420289993286133)
[2024-12-17 02:50:54,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:54,527][root][INFO] - Training Epoch: 2/2, step 4734/7134 completed (loss: 0.4132062792778015, acc: 0.9308176040649414)
[2024-12-17 02:50:54,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:54,820][root][INFO] - Training Epoch: 2/2, step 4735/7134 completed (loss: 0.18523885309696198, acc: 0.9496855139732361)
[2024-12-17 02:50:54,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:55,095][root][INFO] - Training Epoch: 2/2, step 4736/7134 completed (loss: 0.37949660420417786, acc: 0.9416666626930237)
[2024-12-17 02:50:55,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:55,384][root][INFO] - Training Epoch: 2/2, step 4737/7134 completed (loss: 0.1830628663301468, acc: 0.9586206674575806)
[2024-12-17 02:50:55,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:55,660][root][INFO] - Training Epoch: 2/2, step 4738/7134 completed (loss: 0.17093342542648315, acc: 0.9750000238418579)
[2024-12-17 02:50:55,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:55,936][root][INFO] - Training Epoch: 2/2, step 4739/7134 completed (loss: 0.41225364804267883, acc: 0.898876428604126)
[2024-12-17 02:50:56,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:56,226][root][INFO] - Training Epoch: 2/2, step 4740/7134 completed (loss: 0.319696843624115, acc: 0.9333333373069763)
[2024-12-17 02:50:56,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:56,483][root][INFO] - Training Epoch: 2/2, step 4741/7134 completed (loss: 0.1738017499446869, acc: 0.9571428298950195)
[2024-12-17 02:50:56,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:56,757][root][INFO] - Training Epoch: 2/2, step 4742/7134 completed (loss: 0.47258010506629944, acc: 0.903030276298523)
[2024-12-17 02:50:56,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:57,041][root][INFO] - Training Epoch: 2/2, step 4743/7134 completed (loss: 0.29847925901412964, acc: 0.9210526347160339)
[2024-12-17 02:50:57,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:57,364][root][INFO] - Training Epoch: 2/2, step 4744/7134 completed (loss: 0.15933045744895935, acc: 0.9724770784378052)
[2024-12-17 02:50:57,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:57,617][root][INFO] - Training Epoch: 2/2, step 4745/7134 completed (loss: 0.3087184429168701, acc: 0.9583333134651184)
[2024-12-17 02:50:57,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:57,894][root][INFO] - Training Epoch: 2/2, step 4746/7134 completed (loss: 0.09035740792751312, acc: 0.9844961166381836)
[2024-12-17 02:50:58,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:58,187][root][INFO] - Training Epoch: 2/2, step 4747/7134 completed (loss: 0.11549767851829529, acc: 0.9651162624359131)
[2024-12-17 02:50:58,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:58,461][root][INFO] - Training Epoch: 2/2, step 4748/7134 completed (loss: 0.2896323800086975, acc: 0.9289940595626831)
[2024-12-17 02:50:58,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:58,735][root][INFO] - Training Epoch: 2/2, step 4749/7134 completed (loss: 0.10378077626228333, acc: 0.9767441749572754)
[2024-12-17 02:50:58,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:59,000][root][INFO] - Training Epoch: 2/2, step 4750/7134 completed (loss: 0.19304868578910828, acc: 0.9512194991111755)
[2024-12-17 02:50:59,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:59,280][root][INFO] - Training Epoch: 2/2, step 4751/7134 completed (loss: 0.08143099397420883, acc: 0.9817073345184326)
[2024-12-17 02:50:59,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:59,557][root][INFO] - Training Epoch: 2/2, step 4752/7134 completed (loss: 0.19428770244121552, acc: 0.9689440727233887)
[2024-12-17 02:50:59,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:59,823][root][INFO] - Training Epoch: 2/2, step 4753/7134 completed (loss: 0.24142207205295563, acc: 0.9467455744743347)
[2024-12-17 02:50:59,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:00,104][root][INFO] - Training Epoch: 2/2, step 4754/7134 completed (loss: 0.050393231213092804, acc: 0.9935064911842346)
[2024-12-17 02:51:00,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:00,391][root][INFO] - Training Epoch: 2/2, step 4755/7134 completed (loss: 0.1896497905254364, acc: 0.9450549483299255)
[2024-12-17 02:51:00,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:00,659][root][INFO] - Training Epoch: 2/2, step 4756/7134 completed (loss: 0.25130850076675415, acc: 0.9112903475761414)
[2024-12-17 02:51:00,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:00,957][root][INFO] - Training Epoch: 2/2, step 4757/7134 completed (loss: 0.0924767553806305, acc: 0.9750000238418579)
[2024-12-17 02:51:01,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:01,247][root][INFO] - Training Epoch: 2/2, step 4758/7134 completed (loss: 0.09924398362636566, acc: 0.9779005646705627)
[2024-12-17 02:51:01,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:01,519][root][INFO] - Training Epoch: 2/2, step 4759/7134 completed (loss: 0.03777996823191643, acc: 1.0)
[2024-12-17 02:51:01,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:01,777][root][INFO] - Training Epoch: 2/2, step 4760/7134 completed (loss: 0.14159588515758514, acc: 0.9747899174690247)
[2024-12-17 02:51:01,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:02,041][root][INFO] - Training Epoch: 2/2, step 4761/7134 completed (loss: 0.15946418046951294, acc: 0.9695122241973877)
[2024-12-17 02:51:02,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:02,309][root][INFO] - Training Epoch: 2/2, step 4762/7134 completed (loss: 0.2245831936597824, acc: 0.9505494236946106)
[2024-12-17 02:51:02,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:02,587][root][INFO] - Training Epoch: 2/2, step 4763/7134 completed (loss: 0.11934778094291687, acc: 0.9867549538612366)
[2024-12-17 02:51:02,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:02,867][root][INFO] - Training Epoch: 2/2, step 4764/7134 completed (loss: 0.21610279381275177, acc: 0.9536082744598389)
[2024-12-17 02:51:02,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:03,146][root][INFO] - Training Epoch: 2/2, step 4765/7134 completed (loss: 0.3277041018009186, acc: 0.9399999976158142)
[2024-12-17 02:51:03,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:03,425][root][INFO] - Training Epoch: 2/2, step 4766/7134 completed (loss: 0.15578320622444153, acc: 0.9611111283302307)
[2024-12-17 02:51:03,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:03,706][root][INFO] - Training Epoch: 2/2, step 4767/7134 completed (loss: 0.12918387353420258, acc: 0.9591836929321289)
[2024-12-17 02:51:03,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:04,000][root][INFO] - Training Epoch: 2/2, step 4768/7134 completed (loss: 0.131683349609375, acc: 0.9588235020637512)
[2024-12-17 02:51:04,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:04,271][root][INFO] - Training Epoch: 2/2, step 4769/7134 completed (loss: 0.1787305623292923, acc: 0.9473684430122375)
[2024-12-17 02:51:04,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:04,526][root][INFO] - Training Epoch: 2/2, step 4770/7134 completed (loss: 0.08888648450374603, acc: 0.984000027179718)
[2024-12-17 02:51:04,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:04,781][root][INFO] - Training Epoch: 2/2, step 4771/7134 completed (loss: 0.2451867163181305, acc: 0.9509202241897583)
[2024-12-17 02:51:04,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:05,053][root][INFO] - Training Epoch: 2/2, step 4772/7134 completed (loss: 0.1905139535665512, acc: 0.9419354796409607)
[2024-12-17 02:51:05,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:05,328][root][INFO] - Training Epoch: 2/2, step 4773/7134 completed (loss: 0.1263367235660553, acc: 0.942307710647583)
[2024-12-17 02:51:05,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:05,581][root][INFO] - Training Epoch: 2/2, step 4774/7134 completed (loss: 0.1358596533536911, acc: 0.9822485446929932)
[2024-12-17 02:51:05,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:05,850][root][INFO] - Training Epoch: 2/2, step 4775/7134 completed (loss: 0.19835105538368225, acc: 0.955974817276001)
[2024-12-17 02:51:05,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:06,142][root][INFO] - Training Epoch: 2/2, step 4776/7134 completed (loss: 0.2688647508621216, acc: 0.9295774698257446)
[2024-12-17 02:51:06,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:06,425][root][INFO] - Training Epoch: 2/2, step 4777/7134 completed (loss: 0.21249520778656006, acc: 0.931506872177124)
[2024-12-17 02:51:06,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:06,700][root][INFO] - Training Epoch: 2/2, step 4778/7134 completed (loss: 0.12940126657485962, acc: 0.9642857313156128)
[2024-12-17 02:51:06,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:06,986][root][INFO] - Training Epoch: 2/2, step 4779/7134 completed (loss: 0.12511485815048218, acc: 0.9629629850387573)
[2024-12-17 02:51:07,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:07,277][root][INFO] - Training Epoch: 2/2, step 4780/7134 completed (loss: 0.05859500914812088, acc: 0.9807692170143127)
[2024-12-17 02:51:07,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:07,558][root][INFO] - Training Epoch: 2/2, step 4781/7134 completed (loss: 0.15126383304595947, acc: 0.9516128897666931)
[2024-12-17 02:51:07,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:07,831][root][INFO] - Training Epoch: 2/2, step 4782/7134 completed (loss: 0.10227048397064209, acc: 0.981249988079071)
[2024-12-17 02:51:07,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:08,122][root][INFO] - Training Epoch: 2/2, step 4783/7134 completed (loss: 0.35682907700538635, acc: 0.9275362491607666)
[2024-12-17 02:51:08,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:08,411][root][INFO] - Training Epoch: 2/2, step 4784/7134 completed (loss: 0.12401660531759262, acc: 0.9611111283302307)
[2024-12-17 02:51:08,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:08,688][root][INFO] - Training Epoch: 2/2, step 4785/7134 completed (loss: 0.24694237112998962, acc: 0.9552238583564758)
[2024-12-17 02:51:08,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:08,972][root][INFO] - Training Epoch: 2/2, step 4786/7134 completed (loss: 0.08644279837608337, acc: 0.9629629850387573)
[2024-12-17 02:51:09,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:09,261][root][INFO] - Training Epoch: 2/2, step 4787/7134 completed (loss: 0.11725268512964249, acc: 0.9685534834861755)
[2024-12-17 02:51:09,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:09,544][root][INFO] - Training Epoch: 2/2, step 4788/7134 completed (loss: 0.06166945397853851, acc: 0.9692307710647583)
[2024-12-17 02:51:09,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:09,832][root][INFO] - Training Epoch: 2/2, step 4789/7134 completed (loss: 0.09732209891080856, acc: 0.9871794581413269)
[2024-12-17 02:51:09,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:10,116][root][INFO] - Training Epoch: 2/2, step 4790/7134 completed (loss: 0.12470042705535889, acc: 0.9719101190567017)
[2024-12-17 02:51:10,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:10,395][root][INFO] - Training Epoch: 2/2, step 4791/7134 completed (loss: 0.06975837796926498, acc: 0.9925373196601868)
[2024-12-17 02:51:10,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:10,681][root][INFO] - Training Epoch: 2/2, step 4792/7134 completed (loss: 0.08837803453207016, acc: 0.9797297120094299)
[2024-12-17 02:51:10,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:10,935][root][INFO] - Training Epoch: 2/2, step 4793/7134 completed (loss: 0.23224957287311554, acc: 0.9578947424888611)
[2024-12-17 02:51:11,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:11,221][root][INFO] - Training Epoch: 2/2, step 4794/7134 completed (loss: 0.31949955224990845, acc: 0.9078013896942139)
[2024-12-17 02:51:11,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:11,515][root][INFO] - Training Epoch: 2/2, step 4795/7134 completed (loss: 0.12617166340351105, acc: 0.9631901979446411)
[2024-12-17 02:51:11,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:11,783][root][INFO] - Training Epoch: 2/2, step 4796/7134 completed (loss: 0.21489998698234558, acc: 0.9276315569877625)
[2024-12-17 02:51:11,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:12,067][root][INFO] - Training Epoch: 2/2, step 4797/7134 completed (loss: 0.14030469954013824, acc: 0.9617486596107483)
[2024-12-17 02:51:12,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:12,343][root][INFO] - Training Epoch: 2/2, step 4798/7134 completed (loss: 0.12025829404592514, acc: 0.976047933101654)
[2024-12-17 02:51:12,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:12,630][root][INFO] - Training Epoch: 2/2, step 4799/7134 completed (loss: 0.2102317214012146, acc: 0.9545454382896423)
[2024-12-17 02:51:12,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:12,901][root][INFO] - Training Epoch: 2/2, step 4800/7134 completed (loss: 0.12488473206758499, acc: 0.9671052694320679)
[2024-12-17 02:51:13,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:13,183][root][INFO] - Training Epoch: 2/2, step 4801/7134 completed (loss: 0.08499649912118912, acc: 0.9693877696990967)
[2024-12-17 02:51:13,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:13,477][root][INFO] - Training Epoch: 2/2, step 4802/7134 completed (loss: 0.23085159063339233, acc: 0.9536082744598389)
[2024-12-17 02:51:13,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:13,741][root][INFO] - Training Epoch: 2/2, step 4803/7134 completed (loss: 0.2266196310520172, acc: 0.9515151381492615)
[2024-12-17 02:51:13,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:14,029][root][INFO] - Training Epoch: 2/2, step 4804/7134 completed (loss: 0.2323569506406784, acc: 0.9518072009086609)
[2024-12-17 02:51:14,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:14,306][root][INFO] - Training Epoch: 2/2, step 4805/7134 completed (loss: 0.1353687345981598, acc: 0.9735099077224731)
[2024-12-17 02:51:14,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:14,584][root][INFO] - Training Epoch: 2/2, step 4806/7134 completed (loss: 0.1815582811832428, acc: 0.9720279574394226)
[2024-12-17 02:51:14,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:14,846][root][INFO] - Training Epoch: 2/2, step 4807/7134 completed (loss: 0.14708729088306427, acc: 0.9746835231781006)
[2024-12-17 02:51:14,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:15,134][root][INFO] - Training Epoch: 2/2, step 4808/7134 completed (loss: 0.15497945249080658, acc: 0.9545454382896423)
[2024-12-17 02:51:15,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:15,399][root][INFO] - Training Epoch: 2/2, step 4809/7134 completed (loss: 0.11384240537881851, acc: 0.9655172228813171)
[2024-12-17 02:51:15,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:15,689][root][INFO] - Training Epoch: 2/2, step 4810/7134 completed (loss: 0.1789536327123642, acc: 0.9647058844566345)
[2024-12-17 02:51:15,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:15,949][root][INFO] - Training Epoch: 2/2, step 4811/7134 completed (loss: 0.11698205024003983, acc: 0.9754098653793335)
[2024-12-17 02:51:16,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:16,233][root][INFO] - Training Epoch: 2/2, step 4812/7134 completed (loss: 0.1687837392091751, acc: 0.9661017060279846)
[2024-12-17 02:51:16,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:16,459][root][INFO] - Training Epoch: 2/2, step 4813/7134 completed (loss: 0.04693255200982094, acc: 0.9895833134651184)
[2024-12-17 02:51:16,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:16,740][root][INFO] - Training Epoch: 2/2, step 4814/7134 completed (loss: 0.14660806953907013, acc: 0.967391312122345)
[2024-12-17 02:51:16,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:16,999][root][INFO] - Training Epoch: 2/2, step 4815/7134 completed (loss: 0.015035181306302547, acc: 1.0)
[2024-12-17 02:51:17,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:17,274][root][INFO] - Training Epoch: 2/2, step 4816/7134 completed (loss: 0.033186327666044235, acc: 0.9949748516082764)
[2024-12-17 02:51:17,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:17,534][root][INFO] - Training Epoch: 2/2, step 4817/7134 completed (loss: 0.08473721146583557, acc: 0.9696969985961914)
[2024-12-17 02:51:17,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:17,826][root][INFO] - Training Epoch: 2/2, step 4818/7134 completed (loss: 0.08418989926576614, acc: 0.9931972622871399)
[2024-12-17 02:51:17,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:18,091][root][INFO] - Training Epoch: 2/2, step 4819/7134 completed (loss: 0.04526021331548691, acc: 0.9916666746139526)
[2024-12-17 02:51:18,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:18,373][root][INFO] - Training Epoch: 2/2, step 4820/7134 completed (loss: 0.08984743058681488, acc: 0.9786096215248108)
[2024-12-17 02:51:18,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:18,649][root][INFO] - Training Epoch: 2/2, step 4821/7134 completed (loss: 0.09487859904766083, acc: 0.9826589822769165)
[2024-12-17 02:51:18,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:18,922][root][INFO] - Training Epoch: 2/2, step 4822/7134 completed (loss: 0.05848565697669983, acc: 0.9852941036224365)
[2024-12-17 02:51:19,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:19,202][root][INFO] - Training Epoch: 2/2, step 4823/7134 completed (loss: 0.16910414397716522, acc: 0.955974817276001)
[2024-12-17 02:51:19,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:19,441][root][INFO] - Training Epoch: 2/2, step 4824/7134 completed (loss: 0.1755412369966507, acc: 0.9406779408454895)
[2024-12-17 02:51:19,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:19,705][root][INFO] - Training Epoch: 2/2, step 4825/7134 completed (loss: 0.06327736377716064, acc: 0.9779411554336548)
[2024-12-17 02:51:19,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:20,002][root][INFO] - Training Epoch: 2/2, step 4826/7134 completed (loss: 0.08872611820697784, acc: 0.9917355179786682)
[2024-12-17 02:51:20,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:20,268][root][INFO] - Training Epoch: 2/2, step 4827/7134 completed (loss: 0.298151433467865, acc: 0.9225806593894958)
[2024-12-17 02:51:20,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:20,541][root][INFO] - Training Epoch: 2/2, step 4828/7134 completed (loss: 0.09522545337677002, acc: 0.9795918464660645)
[2024-12-17 02:51:20,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:20,832][root][INFO] - Training Epoch: 2/2, step 4829/7134 completed (loss: 0.03109326958656311, acc: 0.9950494766235352)
[2024-12-17 02:51:20,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:21,113][root][INFO] - Training Epoch: 2/2, step 4830/7134 completed (loss: 0.04324709251523018, acc: 0.9878787994384766)
[2024-12-17 02:51:21,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:21,390][root][INFO] - Training Epoch: 2/2, step 4831/7134 completed (loss: 0.02631981112062931, acc: 0.9885714054107666)
[2024-12-17 02:51:21,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:21,665][root][INFO] - Training Epoch: 2/2, step 4832/7134 completed (loss: 0.03814123943448067, acc: 0.9934640526771545)
[2024-12-17 02:51:21,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:21,952][root][INFO] - Training Epoch: 2/2, step 4833/7134 completed (loss: 0.06791090965270996, acc: 0.9796954393386841)
[2024-12-17 02:51:22,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:22,229][root][INFO] - Training Epoch: 2/2, step 4834/7134 completed (loss: 0.105068638920784, acc: 0.9813953638076782)
[2024-12-17 02:51:22,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:22,513][root][INFO] - Training Epoch: 2/2, step 4835/7134 completed (loss: 0.09898004680871964, acc: 0.9692307710647583)
[2024-12-17 02:51:22,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:22,802][root][INFO] - Training Epoch: 2/2, step 4836/7134 completed (loss: 0.06156138330698013, acc: 0.9876543283462524)
[2024-12-17 02:51:22,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:23,056][root][INFO] - Training Epoch: 2/2, step 4837/7134 completed (loss: 0.33311891555786133, acc: 0.9428571462631226)
[2024-12-17 02:51:23,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:23,325][root][INFO] - Training Epoch: 2/2, step 4838/7134 completed (loss: 0.28634756803512573, acc: 0.9640287756919861)
[2024-12-17 02:51:23,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:23,581][root][INFO] - Training Epoch: 2/2, step 4839/7134 completed (loss: 0.20668822526931763, acc: 0.9457364082336426)
[2024-12-17 02:51:23,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:23,860][root][INFO] - Training Epoch: 2/2, step 4840/7134 completed (loss: 0.1465681791305542, acc: 0.9342105388641357)
[2024-12-17 02:51:23,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:24,114][root][INFO] - Training Epoch: 2/2, step 4841/7134 completed (loss: 0.08874596655368805, acc: 0.9722222089767456)
[2024-12-17 02:51:24,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:24,400][root][INFO] - Training Epoch: 2/2, step 4842/7134 completed (loss: 0.16117265820503235, acc: 0.9722222089767456)
[2024-12-17 02:51:24,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:24,682][root][INFO] - Training Epoch: 2/2, step 4843/7134 completed (loss: 0.18678313493728638, acc: 0.955974817276001)
[2024-12-17 02:51:24,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:24,934][root][INFO] - Training Epoch: 2/2, step 4844/7134 completed (loss: 0.1314319223165512, acc: 0.9538461565971375)
[2024-12-17 02:51:25,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:25,215][root][INFO] - Training Epoch: 2/2, step 4845/7134 completed (loss: 0.1474454253911972, acc: 0.949999988079071)
[2024-12-17 02:51:25,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:25,489][root][INFO] - Training Epoch: 2/2, step 4846/7134 completed (loss: 0.18829886615276337, acc: 0.949999988079071)
[2024-12-17 02:51:25,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:25,754][root][INFO] - Training Epoch: 2/2, step 4847/7134 completed (loss: 0.08348200470209122, acc: 0.976331353187561)
[2024-12-17 02:51:25,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:26,020][root][INFO] - Training Epoch: 2/2, step 4848/7134 completed (loss: 0.16235509514808655, acc: 0.9629629850387573)
[2024-12-17 02:51:26,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:26,294][root][INFO] - Training Epoch: 2/2, step 4849/7134 completed (loss: 0.11615876108407974, acc: 0.9794520735740662)
[2024-12-17 02:51:26,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:26,571][root][INFO] - Training Epoch: 2/2, step 4850/7134 completed (loss: 0.15572039783000946, acc: 0.9553072452545166)
[2024-12-17 02:51:26,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:26,850][root][INFO] - Training Epoch: 2/2, step 4851/7134 completed (loss: 0.10191851109266281, acc: 0.9675675630569458)
[2024-12-17 02:51:26,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:27,128][root][INFO] - Training Epoch: 2/2, step 4852/7134 completed (loss: 0.31508898735046387, acc: 0.9244186282157898)
[2024-12-17 02:51:27,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:27,388][root][INFO] - Training Epoch: 2/2, step 4853/7134 completed (loss: 0.5633936524391174, acc: 0.8982036113739014)
[2024-12-17 02:51:27,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:27,641][root][INFO] - Training Epoch: 2/2, step 4854/7134 completed (loss: 0.10605432838201523, acc: 0.9731543660163879)
[2024-12-17 02:51:27,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:27,923][root][INFO] - Training Epoch: 2/2, step 4855/7134 completed (loss: 0.1262119561433792, acc: 0.982758641242981)
[2024-12-17 02:51:28,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:28,209][root][INFO] - Training Epoch: 2/2, step 4856/7134 completed (loss: 0.11736111342906952, acc: 0.976190447807312)
[2024-12-17 02:51:28,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:28,471][root][INFO] - Training Epoch: 2/2, step 4857/7134 completed (loss: 0.11073252558708191, acc: 0.9814814925193787)
[2024-12-17 02:51:28,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:28,761][root][INFO] - Training Epoch: 2/2, step 4858/7134 completed (loss: 0.26794055104255676, acc: 0.9259259104728699)
[2024-12-17 02:51:28,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:29,050][root][INFO] - Training Epoch: 2/2, step 4859/7134 completed (loss: 0.08162947744131088, acc: 0.988095223903656)
[2024-12-17 02:51:29,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:29,327][root][INFO] - Training Epoch: 2/2, step 4860/7134 completed (loss: 0.11616665869951248, acc: 0.9590643048286438)
[2024-12-17 02:51:29,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:29,600][root][INFO] - Training Epoch: 2/2, step 4861/7134 completed (loss: 0.08681293576955795, acc: 0.9822485446929932)
[2024-12-17 02:51:29,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:29,875][root][INFO] - Training Epoch: 2/2, step 4862/7134 completed (loss: 0.10158336162567139, acc: 0.9802631735801697)
[2024-12-17 02:51:30,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:30,160][root][INFO] - Training Epoch: 2/2, step 4863/7134 completed (loss: 0.16427290439605713, acc: 0.961240291595459)
[2024-12-17 02:51:30,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:30,444][root][INFO] - Training Epoch: 2/2, step 4864/7134 completed (loss: 0.09559811651706696, acc: 0.9808917045593262)
[2024-12-17 02:51:30,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:30,729][root][INFO] - Training Epoch: 2/2, step 4865/7134 completed (loss: 0.15245962142944336, acc: 0.9731183052062988)
[2024-12-17 02:51:30,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:31,015][root][INFO] - Training Epoch: 2/2, step 4866/7134 completed (loss: 0.14707522094249725, acc: 0.9593023061752319)
[2024-12-17 02:51:31,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:31,300][root][INFO] - Training Epoch: 2/2, step 4867/7134 completed (loss: 0.1872430443763733, acc: 0.9608938694000244)
[2024-12-17 02:51:31,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:31,578][root][INFO] - Training Epoch: 2/2, step 4868/7134 completed (loss: 0.1174379512667656, acc: 0.9579831957817078)
[2024-12-17 02:51:31,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:31,836][root][INFO] - Training Epoch: 2/2, step 4869/7134 completed (loss: 0.15802346169948578, acc: 0.9591836929321289)
[2024-12-17 02:51:31,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:32,116][root][INFO] - Training Epoch: 2/2, step 4870/7134 completed (loss: 0.07891173660755157, acc: 0.9783783555030823)
[2024-12-17 02:51:32,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:32,363][root][INFO] - Training Epoch: 2/2, step 4871/7134 completed (loss: 0.11078253388404846, acc: 0.9736841917037964)
[2024-12-17 02:51:32,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:32,640][root][INFO] - Training Epoch: 2/2, step 4872/7134 completed (loss: 0.046228207647800446, acc: 0.988095223903656)
[2024-12-17 02:51:32,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:32,927][root][INFO] - Training Epoch: 2/2, step 4873/7134 completed (loss: 0.14423571527004242, acc: 0.9672130942344666)
[2024-12-17 02:51:33,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:33,208][root][INFO] - Training Epoch: 2/2, step 4874/7134 completed (loss: 0.12624937295913696, acc: 0.9756097793579102)
[2024-12-17 02:51:33,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:33,503][root][INFO] - Training Epoch: 2/2, step 4875/7134 completed (loss: 0.058344338089227676, acc: 0.9813664555549622)
[2024-12-17 02:51:33,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:33,746][root][INFO] - Training Epoch: 2/2, step 4876/7134 completed (loss: 0.12261360138654709, acc: 0.9907407164573669)
[2024-12-17 02:51:33,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:34,023][root][INFO] - Training Epoch: 2/2, step 4877/7134 completed (loss: 0.1356029063463211, acc: 0.9743589758872986)
[2024-12-17 02:51:34,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:34,290][root][INFO] - Training Epoch: 2/2, step 4878/7134 completed (loss: 0.10231081396341324, acc: 0.9740259647369385)
[2024-12-17 02:51:34,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:34,573][root][INFO] - Training Epoch: 2/2, step 4879/7134 completed (loss: 0.0754658430814743, acc: 0.9807692170143127)
[2024-12-17 02:51:34,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:34,843][root][INFO] - Training Epoch: 2/2, step 4880/7134 completed (loss: 0.04111462086439133, acc: 0.9882352948188782)
[2024-12-17 02:51:34,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:35,118][root][INFO] - Training Epoch: 2/2, step 4881/7134 completed (loss: 0.21716903150081635, acc: 0.9530201554298401)
[2024-12-17 02:51:35,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:35,384][root][INFO] - Training Epoch: 2/2, step 4882/7134 completed (loss: 0.13480709493160248, acc: 0.9741935729980469)
[2024-12-17 02:51:35,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:35,666][root][INFO] - Training Epoch: 2/2, step 4883/7134 completed (loss: 0.12048593908548355, acc: 0.9466666579246521)
[2024-12-17 02:51:35,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:35,939][root][INFO] - Training Epoch: 2/2, step 4884/7134 completed (loss: 0.06318479776382446, acc: 0.9738562107086182)
[2024-12-17 02:51:36,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:36,234][root][INFO] - Training Epoch: 2/2, step 4885/7134 completed (loss: 0.13817571103572845, acc: 0.9569892287254333)
[2024-12-17 02:51:36,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:36,509][root][INFO] - Training Epoch: 2/2, step 4886/7134 completed (loss: 0.18644946813583374, acc: 0.9711538553237915)
[2024-12-17 02:51:36,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:36,800][root][INFO] - Training Epoch: 2/2, step 4887/7134 completed (loss: 0.08228659629821777, acc: 0.9738219976425171)
[2024-12-17 02:51:36,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:37,093][root][INFO] - Training Epoch: 2/2, step 4888/7134 completed (loss: 0.09740649908781052, acc: 0.9835164546966553)
[2024-12-17 02:51:37,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:37,383][root][INFO] - Training Epoch: 2/2, step 4889/7134 completed (loss: 0.05338965728878975, acc: 0.9893048405647278)
[2024-12-17 02:51:37,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:37,659][root][INFO] - Training Epoch: 2/2, step 4890/7134 completed (loss: 0.18440662324428558, acc: 0.9528301954269409)
[2024-12-17 02:51:37,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:37,938][root][INFO] - Training Epoch: 2/2, step 4891/7134 completed (loss: 0.1683618426322937, acc: 0.9489796161651611)
[2024-12-17 02:51:38,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:38,206][root][INFO] - Training Epoch: 2/2, step 4892/7134 completed (loss: 0.10071633011102676, acc: 0.9740259647369385)
[2024-12-17 02:51:38,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:38,499][root][INFO] - Training Epoch: 2/2, step 4893/7134 completed (loss: 0.5608731508255005, acc: 0.8879310488700867)
[2024-12-17 02:51:38,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:38,767][root][INFO] - Training Epoch: 2/2, step 4894/7134 completed (loss: 0.0834335908293724, acc: 0.9764705896377563)
[2024-12-17 02:51:38,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:39,049][root][INFO] - Training Epoch: 2/2, step 4895/7134 completed (loss: 0.0686139315366745, acc: 0.9795918464660645)
[2024-12-17 02:51:39,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:39,315][root][INFO] - Training Epoch: 2/2, step 4896/7134 completed (loss: 0.08572643250226974, acc: 0.9776536226272583)
[2024-12-17 02:51:39,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:39,594][root][INFO] - Training Epoch: 2/2, step 4897/7134 completed (loss: 0.0571417473256588, acc: 0.9852216839790344)
[2024-12-17 02:51:39,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:39,882][root][INFO] - Training Epoch: 2/2, step 4898/7134 completed (loss: 0.10316412150859833, acc: 0.9677419066429138)
[2024-12-17 02:51:39,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:40,169][root][INFO] - Training Epoch: 2/2, step 4899/7134 completed (loss: 0.05227163806557655, acc: 0.9878048896789551)
[2024-12-17 02:51:40,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:40,449][root][INFO] - Training Epoch: 2/2, step 4900/7134 completed (loss: 0.10781356692314148, acc: 0.9839572310447693)
[2024-12-17 02:51:40,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:40,724][root][INFO] - Training Epoch: 2/2, step 4901/7134 completed (loss: 0.07671704888343811, acc: 0.9634146094322205)
[2024-12-17 02:51:40,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:41,017][root][INFO] - Training Epoch: 2/2, step 4902/7134 completed (loss: 0.05738474428653717, acc: 0.9794871807098389)
[2024-12-17 02:51:41,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:41,302][root][INFO] - Training Epoch: 2/2, step 4903/7134 completed (loss: 0.07798003405332565, acc: 0.970802903175354)
[2024-12-17 02:51:41,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:41,580][root][INFO] - Training Epoch: 2/2, step 4904/7134 completed (loss: 0.04982823133468628, acc: 0.9882352948188782)
[2024-12-17 02:51:41,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:41,864][root][INFO] - Training Epoch: 2/2, step 4905/7134 completed (loss: 0.04587922245264053, acc: 0.9869281053543091)
[2024-12-17 02:51:41,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:42,148][root][INFO] - Training Epoch: 2/2, step 4906/7134 completed (loss: 0.11544866114854813, acc: 0.969924807548523)
[2024-12-17 02:51:42,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:42,430][root][INFO] - Training Epoch: 2/2, step 4907/7134 completed (loss: 0.08851596713066101, acc: 0.9795918464660645)
[2024-12-17 02:51:42,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:42,711][root][INFO] - Training Epoch: 2/2, step 4908/7134 completed (loss: 0.028896648436784744, acc: 0.9935064911842346)
[2024-12-17 02:51:42,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:42,996][root][INFO] - Training Epoch: 2/2, step 4909/7134 completed (loss: 0.04863004386425018, acc: 0.9798657894134521)
[2024-12-17 02:51:43,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:43,266][root][INFO] - Training Epoch: 2/2, step 4910/7134 completed (loss: 0.0800052285194397, acc: 0.9870967864990234)
[2024-12-17 02:51:43,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:43,545][root][INFO] - Training Epoch: 2/2, step 4911/7134 completed (loss: 0.056535109877586365, acc: 0.9893048405647278)
[2024-12-17 02:51:43,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:43,819][root][INFO] - Training Epoch: 2/2, step 4912/7134 completed (loss: 0.04332078993320465, acc: 0.9850746393203735)
[2024-12-17 02:51:43,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:44,098][root][INFO] - Training Epoch: 2/2, step 4913/7134 completed (loss: 0.12142802774906158, acc: 0.9790209531784058)
[2024-12-17 02:51:44,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:44,376][root][INFO] - Training Epoch: 2/2, step 4914/7134 completed (loss: 0.05695688724517822, acc: 0.9870967864990234)
[2024-12-17 02:51:44,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:44,666][root][INFO] - Training Epoch: 2/2, step 4915/7134 completed (loss: 0.025440698489546776, acc: 0.9876543283462524)
[2024-12-17 02:51:44,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:44,944][root][INFO] - Training Epoch: 2/2, step 4916/7134 completed (loss: 0.1732909381389618, acc: 0.95652174949646)
[2024-12-17 02:51:45,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:45,223][root][INFO] - Training Epoch: 2/2, step 4917/7134 completed (loss: 0.14631469547748566, acc: 0.9490445852279663)
[2024-12-17 02:51:45,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:45,494][root][INFO] - Training Epoch: 2/2, step 4918/7134 completed (loss: 0.03616061434149742, acc: 0.9938271641731262)
[2024-12-17 02:51:45,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:45,842][root][INFO] - Training Epoch: 2/2, step 4919/7134 completed (loss: 0.09246893972158432, acc: 0.9774011373519897)
[2024-12-17 02:51:45,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:46,130][root][INFO] - Training Epoch: 2/2, step 4920/7134 completed (loss: 0.18876364827156067, acc: 0.9751552939414978)
[2024-12-17 02:51:46,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:46,426][root][INFO] - Training Epoch: 2/2, step 4921/7134 completed (loss: 0.15613481402397156, acc: 0.970802903175354)
[2024-12-17 02:51:46,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:46,716][root][INFO] - Training Epoch: 2/2, step 4922/7134 completed (loss: 0.09869586676359177, acc: 0.9813664555549622)
[2024-12-17 02:51:46,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:47,014][root][INFO] - Training Epoch: 2/2, step 4923/7134 completed (loss: 0.05115322023630142, acc: 1.0)
[2024-12-17 02:51:47,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:47,282][root][INFO] - Training Epoch: 2/2, step 4924/7134 completed (loss: 0.06239490956068039, acc: 0.9902912378311157)
[2024-12-17 02:51:47,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:47,550][root][INFO] - Training Epoch: 2/2, step 4925/7134 completed (loss: 0.12512391805648804, acc: 0.9664429426193237)
[2024-12-17 02:51:47,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:47,824][root][INFO] - Training Epoch: 2/2, step 4926/7134 completed (loss: 0.04570590704679489, acc: 0.9865771532058716)
[2024-12-17 02:51:47,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:48,113][root][INFO] - Training Epoch: 2/2, step 4927/7134 completed (loss: 0.09168004989624023, acc: 0.9677419066429138)
[2024-12-17 02:51:48,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:48,383][root][INFO] - Training Epoch: 2/2, step 4928/7134 completed (loss: 0.05763041228055954, acc: 0.9842105507850647)
[2024-12-17 02:51:48,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:48,683][root][INFO] - Training Epoch: 2/2, step 4929/7134 completed (loss: 0.03833413124084473, acc: 0.9934210777282715)
[2024-12-17 02:51:48,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:48,945][root][INFO] - Training Epoch: 2/2, step 4930/7134 completed (loss: 0.0796627402305603, acc: 0.9797297120094299)
[2024-12-17 02:51:49,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:49,236][root][INFO] - Training Epoch: 2/2, step 4931/7134 completed (loss: 0.1327773779630661, acc: 0.9447852969169617)
[2024-12-17 02:51:49,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:49,516][root][INFO] - Training Epoch: 2/2, step 4932/7134 completed (loss: 0.07585218548774719, acc: 0.9823529124259949)
[2024-12-17 02:51:49,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:49,807][root][INFO] - Training Epoch: 2/2, step 4933/7134 completed (loss: 0.09664776921272278, acc: 0.9685863852500916)
[2024-12-17 02:51:49,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:50,089][root][INFO] - Training Epoch: 2/2, step 4934/7134 completed (loss: 0.07833585143089294, acc: 0.9823529124259949)
[2024-12-17 02:51:50,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:50,381][root][INFO] - Training Epoch: 2/2, step 4935/7134 completed (loss: 0.04742203280329704, acc: 0.9882352948188782)
[2024-12-17 02:51:50,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:50,655][root][INFO] - Training Epoch: 2/2, step 4936/7134 completed (loss: 0.055379997938871384, acc: 0.9931972622871399)
[2024-12-17 02:51:50,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:50,933][root][INFO] - Training Epoch: 2/2, step 4937/7134 completed (loss: 0.0954420268535614, acc: 0.9650349617004395)
[2024-12-17 02:51:51,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:51,212][root][INFO] - Training Epoch: 2/2, step 4938/7134 completed (loss: 0.04417324811220169, acc: 0.9814814925193787)
[2024-12-17 02:51:51,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:51,490][root][INFO] - Training Epoch: 2/2, step 4939/7134 completed (loss: 0.1025329977273941, acc: 0.9785714149475098)
[2024-12-17 02:51:51,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:51,786][root][INFO] - Training Epoch: 2/2, step 4940/7134 completed (loss: 0.1578885167837143, acc: 0.961240291595459)
[2024-12-17 02:51:51,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:52,086][root][INFO] - Training Epoch: 2/2, step 4941/7134 completed (loss: 0.1387290358543396, acc: 0.9640718698501587)
[2024-12-17 02:51:52,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:52,372][root][INFO] - Training Epoch: 2/2, step 4942/7134 completed (loss: 0.11624588817358017, acc: 0.9683544039726257)
[2024-12-17 02:51:52,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:52,653][root][INFO] - Training Epoch: 2/2, step 4943/7134 completed (loss: 0.14275476336479187, acc: 0.96875)
[2024-12-17 02:51:52,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:52,937][root][INFO] - Training Epoch: 2/2, step 4944/7134 completed (loss: 0.2892361283302307, acc: 0.9495798349380493)
[2024-12-17 02:51:53,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:53,216][root][INFO] - Training Epoch: 2/2, step 4945/7134 completed (loss: 0.29894769191741943, acc: 0.9166666865348816)
[2024-12-17 02:51:53,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:53,500][root][INFO] - Training Epoch: 2/2, step 4946/7134 completed (loss: 0.1345323771238327, acc: 0.96875)
[2024-12-17 02:51:53,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:53,784][root][INFO] - Training Epoch: 2/2, step 4947/7134 completed (loss: 0.12461835145950317, acc: 0.9739130139350891)
[2024-12-17 02:51:53,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:54,048][root][INFO] - Training Epoch: 2/2, step 4948/7134 completed (loss: 0.20049427449703217, acc: 0.9428571462631226)
[2024-12-17 02:51:54,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:54,317][root][INFO] - Training Epoch: 2/2, step 4949/7134 completed (loss: 0.10536691546440125, acc: 0.9629629850387573)
[2024-12-17 02:51:54,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:54,604][root][INFO] - Training Epoch: 2/2, step 4950/7134 completed (loss: 0.11007490754127502, acc: 0.9727891087532043)
[2024-12-17 02:51:54,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:54,915][root][INFO] - Training Epoch: 2/2, step 4951/7134 completed (loss: 0.1490298956632614, acc: 0.9550561904907227)
[2024-12-17 02:51:55,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:55,228][root][INFO] - Training Epoch: 2/2, step 4952/7134 completed (loss: 0.07742729038000107, acc: 0.9864864945411682)
[2024-12-17 02:51:55,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:55,479][root][INFO] - Training Epoch: 2/2, step 4953/7134 completed (loss: 0.12891289591789246, acc: 0.9639639854431152)
[2024-12-17 02:51:55,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:55,758][root][INFO] - Training Epoch: 2/2, step 4954/7134 completed (loss: 0.2414507418870926, acc: 0.9591836929321289)
[2024-12-17 02:51:55,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:56,010][root][INFO] - Training Epoch: 2/2, step 4955/7134 completed (loss: 0.16347424685955048, acc: 0.96875)
[2024-12-17 02:51:56,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:56,285][root][INFO] - Training Epoch: 2/2, step 4956/7134 completed (loss: 0.21247121691703796, acc: 0.9529411792755127)
[2024-12-17 02:51:56,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:56,549][root][INFO] - Training Epoch: 2/2, step 4957/7134 completed (loss: 0.14919282495975494, acc: 0.9645389914512634)
[2024-12-17 02:51:56,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:56,826][root][INFO] - Training Epoch: 2/2, step 4958/7134 completed (loss: 0.15199097990989685, acc: 0.9622641801834106)
[2024-12-17 02:51:56,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:57,108][root][INFO] - Training Epoch: 2/2, step 4959/7134 completed (loss: 0.19525358080863953, acc: 0.9698795080184937)
[2024-12-17 02:51:57,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:57,381][root][INFO] - Training Epoch: 2/2, step 4960/7134 completed (loss: 0.18953967094421387, acc: 0.9411764740943909)
[2024-12-17 02:51:57,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:57,659][root][INFO] - Training Epoch: 2/2, step 4961/7134 completed (loss: 0.14385025203227997, acc: 0.9609375)
[2024-12-17 02:51:57,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:57,942][root][INFO] - Training Epoch: 2/2, step 4962/7134 completed (loss: 0.06836522370576859, acc: 0.9878048896789551)
[2024-12-17 02:51:58,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:58,212][root][INFO] - Training Epoch: 2/2, step 4963/7134 completed (loss: 0.08950400352478027, acc: 0.9677419066429138)
[2024-12-17 02:51:58,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:58,486][root][INFO] - Training Epoch: 2/2, step 4964/7134 completed (loss: 0.2255140244960785, acc: 0.9568345546722412)
[2024-12-17 02:51:58,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:58,745][root][INFO] - Training Epoch: 2/2, step 4965/7134 completed (loss: 0.05055873841047287, acc: 0.9826086759567261)
[2024-12-17 02:51:58,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:59,016][root][INFO] - Training Epoch: 2/2, step 4966/7134 completed (loss: 0.1464836299419403, acc: 0.9780219793319702)
[2024-12-17 02:51:59,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:59,278][root][INFO] - Training Epoch: 2/2, step 4967/7134 completed (loss: 0.10554502159357071, acc: 0.9767441749572754)
[2024-12-17 02:51:59,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:59,564][root][INFO] - Training Epoch: 2/2, step 4968/7134 completed (loss: 0.296173632144928, acc: 0.9078013896942139)
[2024-12-17 02:51:59,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:59,865][root][INFO] - Training Epoch: 2/2, step 4969/7134 completed (loss: 0.1761377602815628, acc: 0.9655172228813171)
[2024-12-17 02:51:59,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:00,124][root][INFO] - Training Epoch: 2/2, step 4970/7134 completed (loss: 0.08039149641990662, acc: 0.9931034445762634)
[2024-12-17 02:52:00,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:00,396][root][INFO] - Training Epoch: 2/2, step 4971/7134 completed (loss: 0.10779893398284912, acc: 0.9668874144554138)
[2024-12-17 02:52:00,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:00,678][root][INFO] - Training Epoch: 2/2, step 4972/7134 completed (loss: 0.20342008769512177, acc: 0.956250011920929)
[2024-12-17 02:52:00,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:00,954][root][INFO] - Training Epoch: 2/2, step 4973/7134 completed (loss: 0.1228742003440857, acc: 0.9545454382896423)
[2024-12-17 02:52:01,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:01,222][root][INFO] - Training Epoch: 2/2, step 4974/7134 completed (loss: 0.1326061487197876, acc: 0.9696969985961914)
[2024-12-17 02:52:01,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:01,497][root][INFO] - Training Epoch: 2/2, step 4975/7134 completed (loss: 0.28285250067710876, acc: 0.9379310607910156)
[2024-12-17 02:52:01,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:01,755][root][INFO] - Training Epoch: 2/2, step 4976/7134 completed (loss: 0.12845394015312195, acc: 0.9684210419654846)
[2024-12-17 02:52:01,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:02,046][root][INFO] - Training Epoch: 2/2, step 4977/7134 completed (loss: 0.2341562658548355, acc: 0.9611650705337524)
[2024-12-17 02:52:02,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:02,334][root][INFO] - Training Epoch: 2/2, step 4978/7134 completed (loss: 0.06620009243488312, acc: 0.9885057210922241)
[2024-12-17 02:52:02,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:02,611][root][INFO] - Training Epoch: 2/2, step 4979/7134 completed (loss: 0.23575204610824585, acc: 0.9370629191398621)
[2024-12-17 02:52:02,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:02,902][root][INFO] - Training Epoch: 2/2, step 4980/7134 completed (loss: 0.31010115146636963, acc: 0.9357143044471741)
[2024-12-17 02:52:03,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:03,186][root][INFO] - Training Epoch: 2/2, step 4981/7134 completed (loss: 0.18592752516269684, acc: 0.9428571462631226)
[2024-12-17 02:52:03,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:03,460][root][INFO] - Training Epoch: 2/2, step 4982/7134 completed (loss: 0.13131825625896454, acc: 0.9639639854431152)
[2024-12-17 02:52:03,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:03,741][root][INFO] - Training Epoch: 2/2, step 4983/7134 completed (loss: 0.10894753783941269, acc: 0.9784172773361206)
[2024-12-17 02:52:03,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:03,968][root][INFO] - Training Epoch: 2/2, step 4984/7134 completed (loss: 0.24209915101528168, acc: 0.9433962106704712)
[2024-12-17 02:52:04,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:04,231][root][INFO] - Training Epoch: 2/2, step 4985/7134 completed (loss: 0.10240037739276886, acc: 0.9729729890823364)
[2024-12-17 02:52:04,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:04,500][root][INFO] - Training Epoch: 2/2, step 4986/7134 completed (loss: 0.0915176048874855, acc: 0.9860140085220337)
[2024-12-17 02:52:04,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:04,752][root][INFO] - Training Epoch: 2/2, step 4987/7134 completed (loss: 0.04845545068383217, acc: 0.9811320900917053)
[2024-12-17 02:52:04,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:05,019][root][INFO] - Training Epoch: 2/2, step 4988/7134 completed (loss: 0.06394702196121216, acc: 0.982758641242981)
[2024-12-17 02:52:05,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:05,296][root][INFO] - Training Epoch: 2/2, step 4989/7134 completed (loss: 0.06734438985586166, acc: 0.9882352948188782)
[2024-12-17 02:52:05,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:05,561][root][INFO] - Training Epoch: 2/2, step 4990/7134 completed (loss: 0.048433978110551834, acc: 0.9829059839248657)
[2024-12-17 02:52:05,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:05,836][root][INFO] - Training Epoch: 2/2, step 4991/7134 completed (loss: 0.06138451769948006, acc: 1.0)
[2024-12-17 02:52:05,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:06,120][root][INFO] - Training Epoch: 2/2, step 4992/7134 completed (loss: 0.1502026915550232, acc: 0.9568965435028076)
[2024-12-17 02:52:06,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:06,304][root][INFO] - Training Epoch: 2/2, step 4993/7134 completed (loss: 0.08086886256933212, acc: 0.9800000190734863)
[2024-12-17 02:52:06,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:06,587][root][INFO] - Training Epoch: 2/2, step 4994/7134 completed (loss: 0.05485003441572189, acc: 0.9933775067329407)
[2024-12-17 02:52:06,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:06,801][root][INFO] - Training Epoch: 2/2, step 4995/7134 completed (loss: 0.10335292667150497, acc: 0.9814814925193787)
[2024-12-17 02:52:06,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:07,060][root][INFO] - Training Epoch: 2/2, step 4996/7134 completed (loss: 0.11181964725255966, acc: 0.9750000238418579)
[2024-12-17 02:52:07,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:07,354][root][INFO] - Training Epoch: 2/2, step 4997/7134 completed (loss: 0.07213141024112701, acc: 0.9923664331436157)
[2024-12-17 02:52:07,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:07,568][root][INFO] - Training Epoch: 2/2, step 4998/7134 completed (loss: 0.20524753630161285, acc: 0.9466666579246521)
[2024-12-17 02:52:07,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:07,822][root][INFO] - Training Epoch: 2/2, step 4999/7134 completed (loss: 0.10084369778633118, acc: 0.9685039520263672)
[2024-12-17 02:52:07,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:08,085][root][INFO] - Training Epoch: 2/2, step 5000/7134 completed (loss: 0.09279030561447144, acc: 0.9793814420700073)
[2024-12-17 02:52:08,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:08,362][root][INFO] - Training Epoch: 2/2, step 5001/7134 completed (loss: 0.18775634467601776, acc: 0.9727891087532043)
[2024-12-17 02:52:08,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:08,687][root][INFO] - Training Epoch: 2/2, step 5002/7134 completed (loss: 0.10264617204666138, acc: 0.982300877571106)
[2024-12-17 02:52:08,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:08,980][root][INFO] - Training Epoch: 2/2, step 5003/7134 completed (loss: 0.0570903941988945, acc: 0.9925925731658936)
[2024-12-17 02:52:09,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:09,268][root][INFO] - Training Epoch: 2/2, step 5004/7134 completed (loss: 0.04164524003863335, acc: 0.9906542301177979)
[2024-12-17 02:52:09,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:09,566][root][INFO] - Training Epoch: 2/2, step 5005/7134 completed (loss: 0.13463939726352692, acc: 0.9890109896659851)
[2024-12-17 02:52:09,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:09,844][root][INFO] - Training Epoch: 2/2, step 5006/7134 completed (loss: 0.09049712121486664, acc: 0.9671052694320679)
[2024-12-17 02:52:09,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:10,100][root][INFO] - Training Epoch: 2/2, step 5007/7134 completed (loss: 0.04250982403755188, acc: 0.9876543283462524)
[2024-12-17 02:52:10,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:10,403][root][INFO] - Training Epoch: 2/2, step 5008/7134 completed (loss: 0.1699306070804596, acc: 0.9833333492279053)
[2024-12-17 02:52:10,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:10,701][root][INFO] - Training Epoch: 2/2, step 5009/7134 completed (loss: 0.2197461873292923, acc: 0.9587628841400146)
[2024-12-17 02:52:10,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:10,973][root][INFO] - Training Epoch: 2/2, step 5010/7134 completed (loss: 0.1574651449918747, acc: 0.9572649598121643)
[2024-12-17 02:52:11,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:11,301][root][INFO] - Training Epoch: 2/2, step 5011/7134 completed (loss: 0.11177030205726624, acc: 0.9724137783050537)
[2024-12-17 02:52:11,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:11,513][root][INFO] - Training Epoch: 2/2, step 5012/7134 completed (loss: 0.05751173570752144, acc: 0.987500011920929)
[2024-12-17 02:52:11,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:11,782][root][INFO] - Training Epoch: 2/2, step 5013/7134 completed (loss: 0.05209460109472275, acc: 0.9914529919624329)
[2024-12-17 02:52:11,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:12,077][root][INFO] - Training Epoch: 2/2, step 5014/7134 completed (loss: 0.09218008071184158, acc: 0.9903846383094788)
[2024-12-17 02:52:12,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:12,349][root][INFO] - Training Epoch: 2/2, step 5015/7134 completed (loss: 0.2678931653499603, acc: 0.9386503100395203)
[2024-12-17 02:52:12,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:12,593][root][INFO] - Training Epoch: 2/2, step 5016/7134 completed (loss: 0.30737221240997314, acc: 0.9541984796524048)
[2024-12-17 02:52:12,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:12,858][root][INFO] - Training Epoch: 2/2, step 5017/7134 completed (loss: 0.056028250604867935, acc: 0.9924242496490479)
[2024-12-17 02:52:12,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:13,134][root][INFO] - Training Epoch: 2/2, step 5018/7134 completed (loss: 0.16425636410713196, acc: 0.9548872113227844)
[2024-12-17 02:52:13,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:13,416][root][INFO] - Training Epoch: 2/2, step 5019/7134 completed (loss: 0.28853893280029297, acc: 0.9548022747039795)
[2024-12-17 02:52:13,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:13,705][root][INFO] - Training Epoch: 2/2, step 5020/7134 completed (loss: 0.31425440311431885, acc: 0.9100528955459595)
[2024-12-17 02:52:13,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:13,975][root][INFO] - Training Epoch: 2/2, step 5021/7134 completed (loss: 0.11504455655813217, acc: 0.9904761910438538)
[2024-12-17 02:52:14,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:14,262][root][INFO] - Training Epoch: 2/2, step 5022/7134 completed (loss: 0.08468002080917358, acc: 0.9855072498321533)
[2024-12-17 02:52:14,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:14,557][root][INFO] - Training Epoch: 2/2, step 5023/7134 completed (loss: 0.058444902300834656, acc: 0.9806451797485352)
[2024-12-17 02:52:14,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:14,858][root][INFO] - Training Epoch: 2/2, step 5024/7134 completed (loss: 0.0803050845861435, acc: 0.9819276928901672)
[2024-12-17 02:52:14,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:15,144][root][INFO] - Training Epoch: 2/2, step 5025/7134 completed (loss: 0.19716811180114746, acc: 0.9538461565971375)
[2024-12-17 02:52:15,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:15,415][root][INFO] - Training Epoch: 2/2, step 5026/7134 completed (loss: 0.11855312436819077, acc: 0.9770992398262024)
[2024-12-17 02:52:15,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:15,676][root][INFO] - Training Epoch: 2/2, step 5027/7134 completed (loss: 0.06670140475034714, acc: 0.9844961166381836)
[2024-12-17 02:52:15,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:15,964][root][INFO] - Training Epoch: 2/2, step 5028/7134 completed (loss: 0.10636474192142487, acc: 0.9647887349128723)
[2024-12-17 02:52:16,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:16,238][root][INFO] - Training Epoch: 2/2, step 5029/7134 completed (loss: 0.09262797236442566, acc: 0.9769230484962463)
[2024-12-17 02:52:16,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:16,532][root][INFO] - Training Epoch: 2/2, step 5030/7134 completed (loss: 0.09633040428161621, acc: 0.970059871673584)
[2024-12-17 02:52:16,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:16,807][root][INFO] - Training Epoch: 2/2, step 5031/7134 completed (loss: 0.43303969502449036, acc: 0.9420289993286133)
[2024-12-17 02:52:16,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:17,077][root][INFO] - Training Epoch: 2/2, step 5032/7134 completed (loss: 0.10040841996669769, acc: 0.9929577708244324)
[2024-12-17 02:52:17,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:17,346][root][INFO] - Training Epoch: 2/2, step 5033/7134 completed (loss: 0.05162808671593666, acc: 0.9788732528686523)
[2024-12-17 02:52:17,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:17,613][root][INFO] - Training Epoch: 2/2, step 5034/7134 completed (loss: 0.03840630128979683, acc: 0.9924812316894531)
[2024-12-17 02:52:17,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:17,888][root][INFO] - Training Epoch: 2/2, step 5035/7134 completed (loss: 0.017388923093676567, acc: 1.0)
[2024-12-17 02:52:17,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:18,171][root][INFO] - Training Epoch: 2/2, step 5036/7134 completed (loss: 0.17172187566757202, acc: 0.9807692170143127)
[2024-12-17 02:52:18,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:18,448][root][INFO] - Training Epoch: 2/2, step 5037/7134 completed (loss: 0.13996489346027374, acc: 0.9764705896377563)
[2024-12-17 02:52:18,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:18,685][root][INFO] - Training Epoch: 2/2, step 5038/7134 completed (loss: 0.3362249732017517, acc: 0.904347836971283)
[2024-12-17 02:52:18,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:18,943][root][INFO] - Training Epoch: 2/2, step 5039/7134 completed (loss: 0.09244882315397263, acc: 0.9716312289237976)
[2024-12-17 02:52:19,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:19,203][root][INFO] - Training Epoch: 2/2, step 5040/7134 completed (loss: 0.06794503331184387, acc: 0.9916666746139526)
[2024-12-17 02:52:19,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:19,490][root][INFO] - Training Epoch: 2/2, step 5041/7134 completed (loss: 0.021718494594097137, acc: 0.9941860437393188)
[2024-12-17 02:52:19,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:19,776][root][INFO] - Training Epoch: 2/2, step 5042/7134 completed (loss: 0.20913924276828766, acc: 0.9708737730979919)
[2024-12-17 02:52:19,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:20,043][root][INFO] - Training Epoch: 2/2, step 5043/7134 completed (loss: 0.0911312848329544, acc: 0.982300877571106)
[2024-12-17 02:52:20,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:20,328][root][INFO] - Training Epoch: 2/2, step 5044/7134 completed (loss: 0.059399113059043884, acc: 0.993630588054657)
[2024-12-17 02:52:20,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:20,611][root][INFO] - Training Epoch: 2/2, step 5045/7134 completed (loss: 0.0904456302523613, acc: 0.9783783555030823)
[2024-12-17 02:52:20,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:20,863][root][INFO] - Training Epoch: 2/2, step 5046/7134 completed (loss: 0.216965451836586, acc: 0.9274193644523621)
[2024-12-17 02:52:20,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:21,108][root][INFO] - Training Epoch: 2/2, step 5047/7134 completed (loss: 0.1575007289648056, acc: 0.956204354763031)
[2024-12-17 02:52:21,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:21,392][root][INFO] - Training Epoch: 2/2, step 5048/7134 completed (loss: 0.11095830798149109, acc: 0.9857142567634583)
[2024-12-17 02:52:21,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:21,652][root][INFO] - Training Epoch: 2/2, step 5049/7134 completed (loss: 0.14868159592151642, acc: 0.9617834687232971)
[2024-12-17 02:52:21,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:21,933][root][INFO] - Training Epoch: 2/2, step 5050/7134 completed (loss: 0.1981402337551117, acc: 0.96875)
[2024-12-17 02:52:22,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:22,213][root][INFO] - Training Epoch: 2/2, step 5051/7134 completed (loss: 0.2205611765384674, acc: 0.9319728016853333)
[2024-12-17 02:52:22,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:22,483][root][INFO] - Training Epoch: 2/2, step 5052/7134 completed (loss: 0.1738232523202896, acc: 0.9358974099159241)
[2024-12-17 02:52:22,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:22,756][root][INFO] - Training Epoch: 2/2, step 5053/7134 completed (loss: 0.2790471911430359, acc: 0.9333333373069763)
[2024-12-17 02:52:22,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:23,045][root][INFO] - Training Epoch: 2/2, step 5054/7134 completed (loss: 0.26438844203948975, acc: 0.9333333373069763)
[2024-12-17 02:52:23,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:23,333][root][INFO] - Training Epoch: 2/2, step 5055/7134 completed (loss: 0.2768528461456299, acc: 0.9557521939277649)
[2024-12-17 02:52:23,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:23,618][root][INFO] - Training Epoch: 2/2, step 5056/7134 completed (loss: 0.18937507271766663, acc: 0.9328858852386475)
[2024-12-17 02:52:23,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:23,898][root][INFO] - Training Epoch: 2/2, step 5057/7134 completed (loss: 0.2914371192455292, acc: 0.9426751732826233)
[2024-12-17 02:52:24,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:24,171][root][INFO] - Training Epoch: 2/2, step 5058/7134 completed (loss: 0.17833317816257477, acc: 0.9634146094322205)
[2024-12-17 02:52:24,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:24,452][root][INFO] - Training Epoch: 2/2, step 5059/7134 completed (loss: 0.07085803896188736, acc: 0.9880239367485046)
[2024-12-17 02:52:24,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:24,727][root][INFO] - Training Epoch: 2/2, step 5060/7134 completed (loss: 0.13910605013370514, acc: 0.9666666388511658)
[2024-12-17 02:52:24,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:24,979][root][INFO] - Training Epoch: 2/2, step 5061/7134 completed (loss: 0.2015795260667801, acc: 0.9523809552192688)
[2024-12-17 02:52:25,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:25,259][root][INFO] - Training Epoch: 2/2, step 5062/7134 completed (loss: 0.09459549188613892, acc: 0.970370352268219)
[2024-12-17 02:52:25,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:25,546][root][INFO] - Training Epoch: 2/2, step 5063/7134 completed (loss: 0.11038461327552795, acc: 0.9650349617004395)
[2024-12-17 02:52:25,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:25,834][root][INFO] - Training Epoch: 2/2, step 5064/7134 completed (loss: 0.1174592673778534, acc: 0.9714285731315613)
[2024-12-17 02:52:25,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:26,126][root][INFO] - Training Epoch: 2/2, step 5065/7134 completed (loss: 0.16575796902179718, acc: 0.9622641801834106)
[2024-12-17 02:52:26,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:26,404][root][INFO] - Training Epoch: 2/2, step 5066/7134 completed (loss: 0.17397399246692657, acc: 0.9586206674575806)
[2024-12-17 02:52:26,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:26,684][root][INFO] - Training Epoch: 2/2, step 5067/7134 completed (loss: 0.05804924666881561, acc: 0.9836065769195557)
[2024-12-17 02:52:26,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:26,941][root][INFO] - Training Epoch: 2/2, step 5068/7134 completed (loss: 0.1338280886411667, acc: 0.9366196990013123)
[2024-12-17 02:52:27,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:27,236][root][INFO] - Training Epoch: 2/2, step 5069/7134 completed (loss: 0.05880201235413551, acc: 0.9864864945411682)
[2024-12-17 02:52:27,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:27,514][root][INFO] - Training Epoch: 2/2, step 5070/7134 completed (loss: 0.03616008907556534, acc: 1.0)
[2024-12-17 02:52:27,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:27,796][root][INFO] - Training Epoch: 2/2, step 5071/7134 completed (loss: 0.12958534061908722, acc: 0.9764705896377563)
[2024-12-17 02:52:27,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:28,069][root][INFO] - Training Epoch: 2/2, step 5072/7134 completed (loss: 0.1983194202184677, acc: 0.9560439586639404)
[2024-12-17 02:52:28,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:28,340][root][INFO] - Training Epoch: 2/2, step 5073/7134 completed (loss: 0.16131491959095, acc: 0.9465649127960205)
[2024-12-17 02:52:28,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:28,625][root][INFO] - Training Epoch: 2/2, step 5074/7134 completed (loss: 0.21695299446582794, acc: 0.9534883499145508)
[2024-12-17 02:52:28,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:28,889][root][INFO] - Training Epoch: 2/2, step 5075/7134 completed (loss: 0.17123953998088837, acc: 0.9739130139350891)
[2024-12-17 02:52:29,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:29,175][root][INFO] - Training Epoch: 2/2, step 5076/7134 completed (loss: 0.1293761134147644, acc: 0.9623655676841736)
[2024-12-17 02:52:29,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:29,452][root][INFO] - Training Epoch: 2/2, step 5077/7134 completed (loss: 0.09270475804805756, acc: 0.970588207244873)
[2024-12-17 02:52:29,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:29,721][root][INFO] - Training Epoch: 2/2, step 5078/7134 completed (loss: 0.3067082464694977, acc: 0.925000011920929)
[2024-12-17 02:52:29,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:29,994][root][INFO] - Training Epoch: 2/2, step 5079/7134 completed (loss: 0.10854224115610123, acc: 0.9611111283302307)
[2024-12-17 02:52:30,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:30,285][root][INFO] - Training Epoch: 2/2, step 5080/7134 completed (loss: 0.06563404202461243, acc: 0.9852941036224365)
[2024-12-17 02:52:30,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:30,560][root][INFO] - Training Epoch: 2/2, step 5081/7134 completed (loss: 0.08079781383275986, acc: 0.9768785834312439)
[2024-12-17 02:52:30,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:30,863][root][INFO] - Training Epoch: 2/2, step 5082/7134 completed (loss: 0.07375462353229523, acc: 0.9862068891525269)
[2024-12-17 02:52:31,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:31,153][root][INFO] - Training Epoch: 2/2, step 5083/7134 completed (loss: 0.1871262490749359, acc: 0.9467455744743347)
[2024-12-17 02:52:31,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:31,453][root][INFO] - Training Epoch: 2/2, step 5084/7134 completed (loss: 0.0888376533985138, acc: 0.9702970385551453)
[2024-12-17 02:52:31,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:31,747][root][INFO] - Training Epoch: 2/2, step 5085/7134 completed (loss: 0.09823298454284668, acc: 0.9742268323898315)
[2024-12-17 02:52:31,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:32,035][root][INFO] - Training Epoch: 2/2, step 5086/7134 completed (loss: 0.06428448855876923, acc: 0.9779005646705627)
[2024-12-17 02:52:32,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:32,319][root][INFO] - Training Epoch: 2/2, step 5087/7134 completed (loss: 0.05114125460386276, acc: 0.9837837815284729)
[2024-12-17 02:52:32,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:32,600][root][INFO] - Training Epoch: 2/2, step 5088/7134 completed (loss: 0.020753711462020874, acc: 0.9940828680992126)
[2024-12-17 02:52:32,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:32,873][root][INFO] - Training Epoch: 2/2, step 5089/7134 completed (loss: 0.08782679587602615, acc: 0.9795918464660645)
[2024-12-17 02:52:32,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:33,159][root][INFO] - Training Epoch: 2/2, step 5090/7134 completed (loss: 0.04606978967785835, acc: 0.9902912378311157)
[2024-12-17 02:52:33,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:33,433][root][INFO] - Training Epoch: 2/2, step 5091/7134 completed (loss: 0.05655137822031975, acc: 0.9945054650306702)
[2024-12-17 02:52:33,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:33,711][root][INFO] - Training Epoch: 2/2, step 5092/7134 completed (loss: 0.09416836500167847, acc: 0.967391312122345)
[2024-12-17 02:52:33,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:33,990][root][INFO] - Training Epoch: 2/2, step 5093/7134 completed (loss: 0.06895676255226135, acc: 0.9886363744735718)
[2024-12-17 02:52:34,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:34,268][root][INFO] - Training Epoch: 2/2, step 5094/7134 completed (loss: 0.05143929272890091, acc: 0.9923076629638672)
[2024-12-17 02:52:34,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:34,537][root][INFO] - Training Epoch: 2/2, step 5095/7134 completed (loss: 0.25713834166526794, acc: 0.9426751732826233)
[2024-12-17 02:52:34,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:34,830][root][INFO] - Training Epoch: 2/2, step 5096/7134 completed (loss: 0.16232141852378845, acc: 0.9680851101875305)
[2024-12-17 02:52:34,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:35,142][root][INFO] - Training Epoch: 2/2, step 5097/7134 completed (loss: 0.08351857215166092, acc: 0.9839572310447693)
[2024-12-17 02:52:35,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:35,434][root][INFO] - Training Epoch: 2/2, step 5098/7134 completed (loss: 0.1201697438955307, acc: 0.9744898080825806)
[2024-12-17 02:52:35,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:35,728][root][INFO] - Training Epoch: 2/2, step 5099/7134 completed (loss: 0.1301635503768921, acc: 0.9629629850387573)
[2024-12-17 02:52:35,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:36,031][root][INFO] - Training Epoch: 2/2, step 5100/7134 completed (loss: 0.11252116411924362, acc: 0.9656862616539001)
[2024-12-17 02:52:36,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:36,312][root][INFO] - Training Epoch: 2/2, step 5101/7134 completed (loss: 0.06505314260721207, acc: 0.9842932224273682)
[2024-12-17 02:52:36,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:36,580][root][INFO] - Training Epoch: 2/2, step 5102/7134 completed (loss: 0.11353051662445068, acc: 0.9756097793579102)
[2024-12-17 02:52:36,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:36,874][root][INFO] - Training Epoch: 2/2, step 5103/7134 completed (loss: 0.11055807024240494, acc: 0.9714285731315613)
[2024-12-17 02:52:36,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:37,160][root][INFO] - Training Epoch: 2/2, step 5104/7134 completed (loss: 0.08527256548404694, acc: 0.9684210419654846)
[2024-12-17 02:52:37,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:37,423][root][INFO] - Training Epoch: 2/2, step 5105/7134 completed (loss: 0.13576741516590118, acc: 0.9602649211883545)
[2024-12-17 02:52:37,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:37,697][root][INFO] - Training Epoch: 2/2, step 5106/7134 completed (loss: 0.1528903692960739, acc: 0.965753436088562)
[2024-12-17 02:52:37,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:37,976][root][INFO] - Training Epoch: 2/2, step 5107/7134 completed (loss: 0.26413628458976746, acc: 0.9523809552192688)
[2024-12-17 02:52:38,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:38,267][root][INFO] - Training Epoch: 2/2, step 5108/7134 completed (loss: 0.4097060561180115, acc: 0.914893627166748)
[2024-12-17 02:52:38,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:38,557][root][INFO] - Training Epoch: 2/2, step 5109/7134 completed (loss: 0.3674927055835724, acc: 0.9346733689308167)
[2024-12-17 02:52:38,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:38,835][root][INFO] - Training Epoch: 2/2, step 5110/7134 completed (loss: 0.26125821471214294, acc: 0.9505494236946106)
[2024-12-17 02:52:38,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:39,117][root][INFO] - Training Epoch: 2/2, step 5111/7134 completed (loss: 0.1292227953672409, acc: 0.959770143032074)
[2024-12-17 02:52:39,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:39,425][root][INFO] - Training Epoch: 2/2, step 5112/7134 completed (loss: 0.22544097900390625, acc: 0.9405405521392822)
[2024-12-17 02:52:39,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:39,709][root][INFO] - Training Epoch: 2/2, step 5113/7134 completed (loss: 0.2305184155702591, acc: 0.9271523356437683)
[2024-12-17 02:52:39,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:40,002][root][INFO] - Training Epoch: 2/2, step 5114/7134 completed (loss: 0.13814391195774078, acc: 0.9602649211883545)
[2024-12-17 02:52:40,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:40,301][root][INFO] - Training Epoch: 2/2, step 5115/7134 completed (loss: 0.08294286578893661, acc: 0.9735449552536011)
[2024-12-17 02:52:40,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:40,595][root][INFO] - Training Epoch: 2/2, step 5116/7134 completed (loss: 0.08904235810041428, acc: 0.9682539701461792)
[2024-12-17 02:52:40,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:40,875][root][INFO] - Training Epoch: 2/2, step 5117/7134 completed (loss: 0.09062206745147705, acc: 0.9834254384040833)
[2024-12-17 02:52:40,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:41,128][root][INFO] - Training Epoch: 2/2, step 5118/7134 completed (loss: 0.18361453711986542, acc: 0.9457831382751465)
[2024-12-17 02:52:41,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:41,400][root][INFO] - Training Epoch: 2/2, step 5119/7134 completed (loss: 0.10955614596605301, acc: 0.9712643623352051)
[2024-12-17 02:52:41,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:41,681][root][INFO] - Training Epoch: 2/2, step 5120/7134 completed (loss: 0.11907704919576645, acc: 0.9682539701461792)
[2024-12-17 02:52:41,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:41,964][root][INFO] - Training Epoch: 2/2, step 5121/7134 completed (loss: 0.03900004178285599, acc: 0.9939393997192383)
[2024-12-17 02:52:42,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:42,244][root][INFO] - Training Epoch: 2/2, step 5122/7134 completed (loss: 0.22096937894821167, acc: 0.9360465407371521)
[2024-12-17 02:52:42,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:42,527][root][INFO] - Training Epoch: 2/2, step 5123/7134 completed (loss: 0.112861268222332, acc: 0.9851484894752502)
[2024-12-17 02:52:42,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:42,804][root][INFO] - Training Epoch: 2/2, step 5124/7134 completed (loss: 0.17889507114887238, acc: 0.9458128213882446)
[2024-12-17 02:52:42,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:43,093][root][INFO] - Training Epoch: 2/2, step 5125/7134 completed (loss: 0.06626191735267639, acc: 0.9803921580314636)
[2024-12-17 02:52:43,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:43,381][root][INFO] - Training Epoch: 2/2, step 5126/7134 completed (loss: 0.12969501316547394, acc: 0.9724137783050537)
[2024-12-17 02:52:43,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:43,653][root][INFO] - Training Epoch: 2/2, step 5127/7134 completed (loss: 0.18215784430503845, acc: 0.9655172228813171)
[2024-12-17 02:52:43,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:43,943][root][INFO] - Training Epoch: 2/2, step 5128/7134 completed (loss: 0.08909829705953598, acc: 0.982758641242981)
[2024-12-17 02:52:44,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:44,226][root][INFO] - Training Epoch: 2/2, step 5129/7134 completed (loss: 0.1950368881225586, acc: 0.961240291595459)
[2024-12-17 02:52:44,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:44,506][root][INFO] - Training Epoch: 2/2, step 5130/7134 completed (loss: 0.04345916211605072, acc: 0.9870129823684692)
[2024-12-17 02:52:44,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:44,791][root][INFO] - Training Epoch: 2/2, step 5131/7134 completed (loss: 0.21789315342903137, acc: 0.9487179517745972)
[2024-12-17 02:52:44,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:45,060][root][INFO] - Training Epoch: 2/2, step 5132/7134 completed (loss: 0.12208735197782516, acc: 0.9765625)
[2024-12-17 02:52:45,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:45,329][root][INFO] - Training Epoch: 2/2, step 5133/7134 completed (loss: 0.21361549198627472, acc: 0.957317054271698)
[2024-12-17 02:52:45,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:45,606][root][INFO] - Training Epoch: 2/2, step 5134/7134 completed (loss: 0.09316029399633408, acc: 0.97826087474823)
[2024-12-17 02:52:45,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:45,894][root][INFO] - Training Epoch: 2/2, step 5135/7134 completed (loss: 0.22751356661319733, acc: 0.9710982441902161)
[2024-12-17 02:52:46,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:46,173][root][INFO] - Training Epoch: 2/2, step 5136/7134 completed (loss: 0.10004100948572159, acc: 0.9677419066429138)
[2024-12-17 02:52:46,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:46,439][root][INFO] - Training Epoch: 2/2, step 5137/7134 completed (loss: 0.2300707846879959, acc: 0.9420289993286133)
[2024-12-17 02:52:46,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:46,716][root][INFO] - Training Epoch: 2/2, step 5138/7134 completed (loss: 0.22419984638690948, acc: 0.9468085169792175)
[2024-12-17 02:52:46,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:46,984][root][INFO] - Training Epoch: 2/2, step 5139/7134 completed (loss: 0.1510075032711029, acc: 0.970588207244873)
[2024-12-17 02:52:47,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:47,261][root][INFO] - Training Epoch: 2/2, step 5140/7134 completed (loss: 0.22310291230678558, acc: 0.925000011920929)
[2024-12-17 02:52:47,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:47,518][root][INFO] - Training Epoch: 2/2, step 5141/7134 completed (loss: 0.12958970665931702, acc: 0.9672130942344666)
[2024-12-17 02:52:47,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:47,797][root][INFO] - Training Epoch: 2/2, step 5142/7134 completed (loss: 0.09162934869527817, acc: 0.96517413854599)
[2024-12-17 02:52:47,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:48,073][root][INFO] - Training Epoch: 2/2, step 5143/7134 completed (loss: 0.11800780892372131, acc: 0.9552238583564758)
[2024-12-17 02:52:48,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:48,351][root][INFO] - Training Epoch: 2/2, step 5144/7134 completed (loss: 0.0711277574300766, acc: 0.9788359999656677)
[2024-12-17 02:52:48,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:48,635][root][INFO] - Training Epoch: 2/2, step 5145/7134 completed (loss: 0.12784363329410553, acc: 0.9791666865348816)
[2024-12-17 02:52:48,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:48,919][root][INFO] - Training Epoch: 2/2, step 5146/7134 completed (loss: 0.2040349394083023, acc: 0.9398906826972961)
[2024-12-17 02:52:49,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:49,177][root][INFO] - Training Epoch: 2/2, step 5147/7134 completed (loss: 0.09153735637664795, acc: 0.9679487347602844)
[2024-12-17 02:52:49,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:49,441][root][INFO] - Training Epoch: 2/2, step 5148/7134 completed (loss: 0.21790042519569397, acc: 0.949999988079071)
[2024-12-17 02:52:49,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:49,735][root][INFO] - Training Epoch: 2/2, step 5149/7134 completed (loss: 0.11699055135250092, acc: 0.9728506803512573)
[2024-12-17 02:52:49,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:50,015][root][INFO] - Training Epoch: 2/2, step 5150/7134 completed (loss: 0.2284812182188034, acc: 0.9520958065986633)
[2024-12-17 02:52:50,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:50,295][root][INFO] - Training Epoch: 2/2, step 5151/7134 completed (loss: 0.2536914050579071, acc: 0.9428571462631226)
[2024-12-17 02:52:50,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:50,572][root][INFO] - Training Epoch: 2/2, step 5152/7134 completed (loss: 0.12512286007404327, acc: 0.970588207244873)
[2024-12-17 02:52:50,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:50,857][root][INFO] - Training Epoch: 2/2, step 5153/7134 completed (loss: 0.1229625791311264, acc: 0.9542483687400818)
[2024-12-17 02:52:51,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:51,154][root][INFO] - Training Epoch: 2/2, step 5154/7134 completed (loss: 0.052767060697078705, acc: 0.9900000095367432)
[2024-12-17 02:52:51,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:51,443][root][INFO] - Training Epoch: 2/2, step 5155/7134 completed (loss: 0.1954498589038849, acc: 0.9416058659553528)
[2024-12-17 02:52:51,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:51,735][root][INFO] - Training Epoch: 2/2, step 5156/7134 completed (loss: 0.10788021236658096, acc: 0.9768518805503845)
[2024-12-17 02:52:51,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:52,013][root][INFO] - Training Epoch: 2/2, step 5157/7134 completed (loss: 0.10405199229717255, acc: 0.9715909361839294)
[2024-12-17 02:52:52,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:52,280][root][INFO] - Training Epoch: 2/2, step 5158/7134 completed (loss: 0.18669818341732025, acc: 0.942307710647583)
[2024-12-17 02:52:52,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:52,566][root][INFO] - Training Epoch: 2/2, step 5159/7134 completed (loss: 0.13969196379184723, acc: 0.9747474789619446)
[2024-12-17 02:52:52,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:52,844][root][INFO] - Training Epoch: 2/2, step 5160/7134 completed (loss: 0.16807018220424652, acc: 0.949999988079071)
[2024-12-17 02:52:52,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:53,131][root][INFO] - Training Epoch: 2/2, step 5161/7134 completed (loss: 0.20809341967105865, acc: 0.9354838728904724)
[2024-12-17 02:52:53,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:53,427][root][INFO] - Training Epoch: 2/2, step 5162/7134 completed (loss: 0.14922261238098145, acc: 0.9599999785423279)
[2024-12-17 02:52:53,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:53,699][root][INFO] - Training Epoch: 2/2, step 5163/7134 completed (loss: 0.13078665733337402, acc: 0.9623655676841736)
[2024-12-17 02:52:53,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:53,971][root][INFO] - Training Epoch: 2/2, step 5164/7134 completed (loss: 0.07686375081539154, acc: 0.9806451797485352)
[2024-12-17 02:52:54,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:54,255][root][INFO] - Training Epoch: 2/2, step 5165/7134 completed (loss: 0.1275159865617752, acc: 0.9636363387107849)
[2024-12-17 02:52:54,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:54,529][root][INFO] - Training Epoch: 2/2, step 5166/7134 completed (loss: 0.14182353019714355, acc: 0.9506173133850098)
[2024-12-17 02:52:54,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:54,802][root][INFO] - Training Epoch: 2/2, step 5167/7134 completed (loss: 0.16635075211524963, acc: 0.9558011293411255)
[2024-12-17 02:52:54,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:55,077][root][INFO] - Training Epoch: 2/2, step 5168/7134 completed (loss: 0.2899494469165802, acc: 0.9418604373931885)
[2024-12-17 02:52:55,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:55,350][root][INFO] - Training Epoch: 2/2, step 5169/7134 completed (loss: 0.21838116645812988, acc: 0.957317054271698)
[2024-12-17 02:52:55,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:55,627][root][INFO] - Training Epoch: 2/2, step 5170/7134 completed (loss: 0.2625611424446106, acc: 0.9481865167617798)
[2024-12-17 02:52:55,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:55,881][root][INFO] - Training Epoch: 2/2, step 5171/7134 completed (loss: 0.12870532274246216, acc: 0.9593495726585388)
[2024-12-17 02:52:55,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:56,164][root][INFO] - Training Epoch: 2/2, step 5172/7134 completed (loss: 0.4293110966682434, acc: 0.9024389982223511)
[2024-12-17 02:52:56,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:56,430][root][INFO] - Training Epoch: 2/2, step 5173/7134 completed (loss: 0.21249686181545258, acc: 0.9509202241897583)
[2024-12-17 02:52:56,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:56,712][root][INFO] - Training Epoch: 2/2, step 5174/7134 completed (loss: 0.10598353296518326, acc: 0.9653179049491882)
[2024-12-17 02:52:56,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:57,018][root][INFO] - Training Epoch: 2/2, step 5175/7134 completed (loss: 0.09980592131614685, acc: 0.9820359349250793)
[2024-12-17 02:52:57,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:57,303][root][INFO] - Training Epoch: 2/2, step 5176/7134 completed (loss: 0.1061793863773346, acc: 0.9736841917037964)
[2024-12-17 02:52:57,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:57,604][root][INFO] - Training Epoch: 2/2, step 5177/7134 completed (loss: 0.23319204151630402, acc: 0.95333331823349)
[2024-12-17 02:52:57,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:57,912][root][INFO] - Training Epoch: 2/2, step 5178/7134 completed (loss: 0.3247469663619995, acc: 0.9466666579246521)
[2024-12-17 02:52:58,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:58,198][root][INFO] - Training Epoch: 2/2, step 5179/7134 completed (loss: 0.18213880062103271, acc: 0.9404761791229248)
[2024-12-17 02:52:58,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:58,473][root][INFO] - Training Epoch: 2/2, step 5180/7134 completed (loss: 0.29327860474586487, acc: 0.914893627166748)
[2024-12-17 02:52:58,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:58,702][root][INFO] - Training Epoch: 2/2, step 5181/7134 completed (loss: 0.3783871829509735, acc: 0.9101123809814453)
[2024-12-17 02:52:58,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:58,962][root][INFO] - Training Epoch: 2/2, step 5182/7134 completed (loss: 0.6935451030731201, acc: 0.8661417365074158)
[2024-12-17 02:52:59,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:59,233][root][INFO] - Training Epoch: 2/2, step 5183/7134 completed (loss: 0.29664433002471924, acc: 0.9411764740943909)
[2024-12-17 02:52:59,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:59,494][root][INFO] - Training Epoch: 2/2, step 5184/7134 completed (loss: 0.10626637190580368, acc: 0.9711538553237915)
[2024-12-17 02:52:59,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:59,775][root][INFO] - Training Epoch: 2/2, step 5185/7134 completed (loss: 0.18382155895233154, acc: 0.9504950642585754)
[2024-12-17 02:52:59,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:00,055][root][INFO] - Training Epoch: 2/2, step 5186/7134 completed (loss: 0.18619035184383392, acc: 0.9370078444480896)
[2024-12-17 02:53:00,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:00,322][root][INFO] - Training Epoch: 2/2, step 5187/7134 completed (loss: 0.07551207393407822, acc: 0.984000027179718)
[2024-12-17 02:53:00,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:00,601][root][INFO] - Training Epoch: 2/2, step 5188/7134 completed (loss: 0.14021001756191254, acc: 0.9637681245803833)
[2024-12-17 02:53:00,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:00,848][root][INFO] - Training Epoch: 2/2, step 5189/7134 completed (loss: 0.17075222730636597, acc: 0.9801980257034302)
[2024-12-17 02:53:00,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:01,101][root][INFO] - Training Epoch: 2/2, step 5190/7134 completed (loss: 0.0991206020116806, acc: 0.9727272987365723)
[2024-12-17 02:53:01,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:01,396][root][INFO] - Training Epoch: 2/2, step 5191/7134 completed (loss: 0.23138703405857086, acc: 0.9753086566925049)
[2024-12-17 02:53:01,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:01,684][root][INFO] - Training Epoch: 2/2, step 5192/7134 completed (loss: 0.15835440158843994, acc: 0.9848484992980957)
[2024-12-17 02:53:01,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:01,954][root][INFO] - Training Epoch: 2/2, step 5193/7134 completed (loss: 0.07921890169382095, acc: 0.9916666746139526)
[2024-12-17 02:53:02,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:02,248][root][INFO] - Training Epoch: 2/2, step 5194/7134 completed (loss: 0.1458319127559662, acc: 0.9617834687232971)
[2024-12-17 02:53:02,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:02,486][root][INFO] - Training Epoch: 2/2, step 5195/7134 completed (loss: 0.2851443588733673, acc: 0.9444444179534912)
[2024-12-17 02:53:02,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:02,774][root][INFO] - Training Epoch: 2/2, step 5196/7134 completed (loss: 0.3004591166973114, acc: 0.949999988079071)
[2024-12-17 02:53:02,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:03,037][root][INFO] - Training Epoch: 2/2, step 5197/7134 completed (loss: 0.14745737612247467, acc: 0.9841269850730896)
[2024-12-17 02:53:03,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:03,292][root][INFO] - Training Epoch: 2/2, step 5198/7134 completed (loss: 0.1991967260837555, acc: 0.9426229596138)
[2024-12-17 02:53:03,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:03,592][root][INFO] - Training Epoch: 2/2, step 5199/7134 completed (loss: 0.24542975425720215, acc: 0.9360465407371521)
[2024-12-17 02:53:03,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:03,867][root][INFO] - Training Epoch: 2/2, step 5200/7134 completed (loss: 0.09018661826848984, acc: 0.976190447807312)
[2024-12-17 02:53:04,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:04,150][root][INFO] - Training Epoch: 2/2, step 5201/7134 completed (loss: 0.16629381477832794, acc: 0.9613526463508606)
[2024-12-17 02:53:04,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:04,430][root][INFO] - Training Epoch: 2/2, step 5202/7134 completed (loss: 0.1749865561723709, acc: 0.96875)
[2024-12-17 02:53:04,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:04,711][root][INFO] - Training Epoch: 2/2, step 5203/7134 completed (loss: 0.07640288770198822, acc: 0.9890109896659851)
[2024-12-17 02:53:04,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:04,986][root][INFO] - Training Epoch: 2/2, step 5204/7134 completed (loss: 0.05297692120075226, acc: 0.9918032884597778)
[2024-12-17 02:53:05,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:05,249][root][INFO] - Training Epoch: 2/2, step 5205/7134 completed (loss: 0.11360674351453781, acc: 0.9759036302566528)
[2024-12-17 02:53:05,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:05,539][root][INFO] - Training Epoch: 2/2, step 5206/7134 completed (loss: 0.1114904135465622, acc: 0.988304078578949)
[2024-12-17 02:53:05,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:05,794][root][INFO] - Training Epoch: 2/2, step 5207/7134 completed (loss: 0.3552168011665344, acc: 0.920634925365448)
[2024-12-17 02:53:05,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:06,093][root][INFO] - Training Epoch: 2/2, step 5208/7134 completed (loss: 0.06567733734846115, acc: 0.982758641242981)
[2024-12-17 02:53:06,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:06,386][root][INFO] - Training Epoch: 2/2, step 5209/7134 completed (loss: 0.13699126243591309, acc: 0.9624060392379761)
[2024-12-17 02:53:06,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:06,675][root][INFO] - Training Epoch: 2/2, step 5210/7134 completed (loss: 0.1357930302619934, acc: 0.9704142212867737)
[2024-12-17 02:53:06,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:06,958][root][INFO] - Training Epoch: 2/2, step 5211/7134 completed (loss: 0.21237100660800934, acc: 0.9603174328804016)
[2024-12-17 02:53:07,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:07,200][root][INFO] - Training Epoch: 2/2, step 5212/7134 completed (loss: 0.12221154570579529, acc: 0.9740259647369385)
[2024-12-17 02:53:07,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:07,473][root][INFO] - Training Epoch: 2/2, step 5213/7134 completed (loss: 0.17525462806224823, acc: 0.9691358208656311)
[2024-12-17 02:53:07,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:07,735][root][INFO] - Training Epoch: 2/2, step 5214/7134 completed (loss: 0.21496549248695374, acc: 0.9411764740943909)
[2024-12-17 02:53:07,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:08,022][root][INFO] - Training Epoch: 2/2, step 5215/7134 completed (loss: 0.3761453926563263, acc: 0.9455445408821106)
[2024-12-17 02:53:08,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:08,243][root][INFO] - Training Epoch: 2/2, step 5216/7134 completed (loss: 0.19445161521434784, acc: 0.9305555820465088)
[2024-12-17 02:53:08,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:08,529][root][INFO] - Training Epoch: 2/2, step 5217/7134 completed (loss: 0.37884318828582764, acc: 0.9347826242446899)
[2024-12-17 02:53:08,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:08,789][root][INFO] - Training Epoch: 2/2, step 5218/7134 completed (loss: 0.21872155368328094, acc: 0.9306930899620056)
[2024-12-17 02:53:08,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:09,065][root][INFO] - Training Epoch: 2/2, step 5219/7134 completed (loss: 0.2589077651500702, acc: 0.9351851940155029)
[2024-12-17 02:53:09,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:09,303][root][INFO] - Training Epoch: 2/2, step 5220/7134 completed (loss: 0.1543370932340622, acc: 0.9589040875434875)
[2024-12-17 02:53:09,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:09,596][root][INFO] - Training Epoch: 2/2, step 5221/7134 completed (loss: 0.13895361125469208, acc: 0.9691358208656311)
[2024-12-17 02:53:09,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:09,879][root][INFO] - Training Epoch: 2/2, step 5222/7134 completed (loss: 0.15389585494995117, acc: 0.9404761791229248)
[2024-12-17 02:53:10,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:10,152][root][INFO] - Training Epoch: 2/2, step 5223/7134 completed (loss: 0.10920318961143494, acc: 0.9646017551422119)
[2024-12-17 02:53:10,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:10,437][root][INFO] - Training Epoch: 2/2, step 5224/7134 completed (loss: 0.1668277084827423, acc: 0.970370352268219)
[2024-12-17 02:53:10,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:10,719][root][INFO] - Training Epoch: 2/2, step 5225/7134 completed (loss: 0.17698262631893158, acc: 0.9736841917037964)
[2024-12-17 02:53:10,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:11,034][root][INFO] - Training Epoch: 2/2, step 5226/7134 completed (loss: 0.16336023807525635, acc: 0.9487179517745972)
[2024-12-17 02:53:11,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:11,338][root][INFO] - Training Epoch: 2/2, step 5227/7134 completed (loss: 0.149734228849411, acc: 0.9743589758872986)
[2024-12-17 02:53:11,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:11,619][root][INFO] - Training Epoch: 2/2, step 5228/7134 completed (loss: 0.0846472829580307, acc: 0.9714285731315613)
[2024-12-17 02:53:11,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:11,904][root][INFO] - Training Epoch: 2/2, step 5229/7134 completed (loss: 0.06335129588842392, acc: 0.9806451797485352)
[2024-12-17 02:53:12,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:12,188][root][INFO] - Training Epoch: 2/2, step 5230/7134 completed (loss: 0.09168840199708939, acc: 0.9834254384040833)
[2024-12-17 02:53:12,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:12,491][root][INFO] - Training Epoch: 2/2, step 5231/7134 completed (loss: 0.08508110791444778, acc: 0.9742268323898315)
[2024-12-17 02:53:12,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:12,797][root][INFO] - Training Epoch: 2/2, step 5232/7134 completed (loss: 0.0906725525856018, acc: 0.9830508232116699)
[2024-12-17 02:53:12,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:13,102][root][INFO] - Training Epoch: 2/2, step 5233/7134 completed (loss: 0.14842458069324493, acc: 0.9541284441947937)
[2024-12-17 02:53:13,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:13,440][root][INFO] - Training Epoch: 2/2, step 5234/7134 completed (loss: 0.09310311824083328, acc: 0.9736841917037964)
[2024-12-17 02:53:13,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:13,714][root][INFO] - Training Epoch: 2/2, step 5235/7134 completed (loss: 0.039364300668239594, acc: 0.9932432174682617)
[2024-12-17 02:53:13,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:14,007][root][INFO] - Training Epoch: 2/2, step 5236/7134 completed (loss: 0.05108322203159332, acc: 0.985401451587677)
[2024-12-17 02:53:14,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:14,292][root][INFO] - Training Epoch: 2/2, step 5237/7134 completed (loss: 0.07000473141670227, acc: 0.98591548204422)
[2024-12-17 02:53:14,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:14,573][root][INFO] - Training Epoch: 2/2, step 5238/7134 completed (loss: 0.07871077209711075, acc: 0.9850746393203735)
[2024-12-17 02:53:14,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:14,864][root][INFO] - Training Epoch: 2/2, step 5239/7134 completed (loss: 0.19891759753227234, acc: 0.9327731132507324)
[2024-12-17 02:53:14,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:15,143][root][INFO] - Training Epoch: 2/2, step 5240/7134 completed (loss: 0.06154100224375725, acc: 0.9825581312179565)
[2024-12-17 02:53:15,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:15,429][root][INFO] - Training Epoch: 2/2, step 5241/7134 completed (loss: 0.17701350152492523, acc: 0.9548386931419373)
[2024-12-17 02:53:15,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:15,719][root][INFO] - Training Epoch: 2/2, step 5242/7134 completed (loss: 0.07303471863269806, acc: 0.9868420958518982)
[2024-12-17 02:53:15,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:16,008][root][INFO] - Training Epoch: 2/2, step 5243/7134 completed (loss: 0.032390519976615906, acc: 0.9928571581840515)
[2024-12-17 02:53:16,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:16,273][root][INFO] - Training Epoch: 2/2, step 5244/7134 completed (loss: 0.1107998862862587, acc: 0.9709302186965942)
[2024-12-17 02:53:16,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:16,579][root][INFO] - Training Epoch: 2/2, step 5245/7134 completed (loss: 0.06593277305364609, acc: 1.0)
[2024-12-17 02:53:16,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:16,855][root][INFO] - Training Epoch: 2/2, step 5246/7134 completed (loss: 0.10852706432342529, acc: 0.9683544039726257)
[2024-12-17 02:53:16,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:17,139][root][INFO] - Training Epoch: 2/2, step 5247/7134 completed (loss: 0.13732454180717468, acc: 0.970370352268219)
[2024-12-17 02:53:17,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:17,410][root][INFO] - Training Epoch: 2/2, step 5248/7134 completed (loss: 0.13012312352657318, acc: 0.9770992398262024)
[2024-12-17 02:53:17,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:17,680][root][INFO] - Training Epoch: 2/2, step 5249/7134 completed (loss: 0.09360478818416595, acc: 0.9808917045593262)
[2024-12-17 02:53:17,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:17,973][root][INFO] - Training Epoch: 2/2, step 5250/7134 completed (loss: 0.12095242738723755, acc: 0.967391312122345)
[2024-12-17 02:53:18,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:18,253][root][INFO] - Training Epoch: 2/2, step 5251/7134 completed (loss: 0.09549937397241592, acc: 0.9791666865348816)
[2024-12-17 02:53:18,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:18,516][root][INFO] - Training Epoch: 2/2, step 5252/7134 completed (loss: 0.14658232033252716, acc: 0.9469026327133179)
[2024-12-17 02:53:18,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:18,789][root][INFO] - Training Epoch: 2/2, step 5253/7134 completed (loss: 0.05930151417851448, acc: 0.9791666865348816)
[2024-12-17 02:53:18,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:19,072][root][INFO] - Training Epoch: 2/2, step 5254/7134 completed (loss: 0.2674131989479065, acc: 0.9300699234008789)
[2024-12-17 02:53:19,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:19,366][root][INFO] - Training Epoch: 2/2, step 5255/7134 completed (loss: 0.12943996489048004, acc: 0.977011501789093)
[2024-12-17 02:53:19,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:19,655][root][INFO] - Training Epoch: 2/2, step 5256/7134 completed (loss: 0.2323593944311142, acc: 0.95333331823349)
[2024-12-17 02:53:19,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:19,983][root][INFO] - Training Epoch: 2/2, step 5257/7134 completed (loss: 0.320374459028244, acc: 0.9341317415237427)
[2024-12-17 02:53:20,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:20,267][root][INFO] - Training Epoch: 2/2, step 5258/7134 completed (loss: 0.21943236887454987, acc: 0.9470899701118469)
[2024-12-17 02:53:20,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:20,560][root][INFO] - Training Epoch: 2/2, step 5259/7134 completed (loss: 0.144310861825943, acc: 0.9640287756919861)
[2024-12-17 02:53:20,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:20,844][root][INFO] - Training Epoch: 2/2, step 5260/7134 completed (loss: 0.12716113030910492, acc: 0.9841269850730896)
[2024-12-17 02:53:20,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:21,127][root][INFO] - Training Epoch: 2/2, step 5261/7134 completed (loss: 0.24053046107292175, acc: 0.9510489702224731)
[2024-12-17 02:53:21,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:21,430][root][INFO] - Training Epoch: 2/2, step 5262/7134 completed (loss: 0.13423439860343933, acc: 0.9578313231468201)
[2024-12-17 02:53:21,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:21,702][root][INFO] - Training Epoch: 2/2, step 5263/7134 completed (loss: 0.13551761209964752, acc: 0.9718309640884399)
[2024-12-17 02:53:21,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:21,994][root][INFO] - Training Epoch: 2/2, step 5264/7134 completed (loss: 0.15199273824691772, acc: 0.9591836929321289)
[2024-12-17 02:53:22,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:22,273][root][INFO] - Training Epoch: 2/2, step 5265/7134 completed (loss: 0.20316004753112793, acc: 0.9453551769256592)
[2024-12-17 02:53:22,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:22,543][root][INFO] - Training Epoch: 2/2, step 5266/7134 completed (loss: 0.058356791734695435, acc: 0.9938271641731262)
[2024-12-17 02:53:22,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:22,808][root][INFO] - Training Epoch: 2/2, step 5267/7134 completed (loss: 0.312109112739563, acc: 0.9259259104728699)
[2024-12-17 02:53:22,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:23,082][root][INFO] - Training Epoch: 2/2, step 5268/7134 completed (loss: 0.2518300414085388, acc: 0.9224806427955627)
[2024-12-17 02:53:23,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:23,362][root][INFO] - Training Epoch: 2/2, step 5269/7134 completed (loss: 0.22208595275878906, acc: 0.9571428298950195)
[2024-12-17 02:53:23,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:23,651][root][INFO] - Training Epoch: 2/2, step 5270/7134 completed (loss: 0.12551210820674896, acc: 0.954023003578186)
[2024-12-17 02:53:23,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:23,935][root][INFO] - Training Epoch: 2/2, step 5271/7134 completed (loss: 0.09990359097719193, acc: 0.9784172773361206)
[2024-12-17 02:53:24,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:24,213][root][INFO] - Training Epoch: 2/2, step 5272/7134 completed (loss: 0.10709091275930405, acc: 0.9710982441902161)
[2024-12-17 02:53:24,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:24,499][root][INFO] - Training Epoch: 2/2, step 5273/7134 completed (loss: 0.15641747415065765, acc: 0.9791666865348816)
[2024-12-17 02:53:24,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:24,783][root][INFO] - Training Epoch: 2/2, step 5274/7134 completed (loss: 0.1592710167169571, acc: 0.9487179517745972)
[2024-12-17 02:53:24,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:25,051][root][INFO] - Training Epoch: 2/2, step 5275/7134 completed (loss: 0.07249189913272858, acc: 0.9837398529052734)
[2024-12-17 02:53:25,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:25,317][root][INFO] - Training Epoch: 2/2, step 5276/7134 completed (loss: 0.1789627969264984, acc: 0.9605262875556946)
[2024-12-17 02:53:25,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:25,580][root][INFO] - Training Epoch: 2/2, step 5277/7134 completed (loss: 0.07492155581712723, acc: 0.9808917045593262)
[2024-12-17 02:53:25,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:25,862][root][INFO] - Training Epoch: 2/2, step 5278/7134 completed (loss: 0.31590738892555237, acc: 0.9272727370262146)
[2024-12-17 02:53:25,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:26,145][root][INFO] - Training Epoch: 2/2, step 5279/7134 completed (loss: 0.03731214627623558, acc: 0.9837398529052734)
[2024-12-17 02:53:26,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:26,424][root][INFO] - Training Epoch: 2/2, step 5280/7134 completed (loss: 0.09393393993377686, acc: 0.9714285731315613)
[2024-12-17 02:53:26,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:26,703][root][INFO] - Training Epoch: 2/2, step 5281/7134 completed (loss: 0.14196257293224335, acc: 0.9710144996643066)
[2024-12-17 02:53:26,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:26,978][root][INFO] - Training Epoch: 2/2, step 5282/7134 completed (loss: 0.23260566592216492, acc: 0.9534883499145508)
[2024-12-17 02:53:27,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:27,258][root][INFO] - Training Epoch: 2/2, step 5283/7134 completed (loss: 0.11685387790203094, acc: 0.9617486596107483)
[2024-12-17 02:53:27,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:27,545][root][INFO] - Training Epoch: 2/2, step 5284/7134 completed (loss: 0.18317601084709167, acc: 0.9750000238418579)
[2024-12-17 02:53:27,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:27,829][root][INFO] - Training Epoch: 2/2, step 5285/7134 completed (loss: 0.1786084771156311, acc: 0.9516128897666931)
[2024-12-17 02:53:27,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:28,113][root][INFO] - Training Epoch: 2/2, step 5286/7134 completed (loss: 0.19464978575706482, acc: 0.9664429426193237)
[2024-12-17 02:53:28,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:28,393][root][INFO] - Training Epoch: 2/2, step 5287/7134 completed (loss: 0.19796228408813477, acc: 0.9545454382896423)
[2024-12-17 02:53:28,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:28,664][root][INFO] - Training Epoch: 2/2, step 5288/7134 completed (loss: 0.11384104192256927, acc: 0.9750000238418579)
[2024-12-17 02:53:28,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:28,950][root][INFO] - Training Epoch: 2/2, step 5289/7134 completed (loss: 0.10129889845848083, acc: 0.9715909361839294)
[2024-12-17 02:53:29,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:29,237][root][INFO] - Training Epoch: 2/2, step 5290/7134 completed (loss: 0.19162589311599731, acc: 0.9417989253997803)
[2024-12-17 02:53:29,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:29,559][root][INFO] - Training Epoch: 2/2, step 5291/7134 completed (loss: 0.09192612767219543, acc: 0.9729729890823364)
[2024-12-17 02:53:29,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:29,832][root][INFO] - Training Epoch: 2/2, step 5292/7134 completed (loss: 0.07518556714057922, acc: 0.9830508232116699)
[2024-12-17 02:53:29,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:30,110][root][INFO] - Training Epoch: 2/2, step 5293/7134 completed (loss: 0.10986362397670746, acc: 0.9745222926139832)
[2024-12-17 02:53:30,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:30,401][root][INFO] - Training Epoch: 2/2, step 5294/7134 completed (loss: 0.11984051018953323, acc: 0.9704142212867737)
[2024-12-17 02:53:30,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:30,665][root][INFO] - Training Epoch: 2/2, step 5295/7134 completed (loss: 0.08643817156553268, acc: 0.9767441749572754)
[2024-12-17 02:53:30,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:30,951][root][INFO] - Training Epoch: 2/2, step 5296/7134 completed (loss: 0.09182398021221161, acc: 0.9717513918876648)
[2024-12-17 02:53:31,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:31,230][root][INFO] - Training Epoch: 2/2, step 5297/7134 completed (loss: 0.11439035087823868, acc: 0.9638554453849792)
[2024-12-17 02:53:31,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:31,539][root][INFO] - Training Epoch: 2/2, step 5298/7134 completed (loss: 0.16362649202346802, acc: 0.957446813583374)
[2024-12-17 02:53:31,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:31,808][root][INFO] - Training Epoch: 2/2, step 5299/7134 completed (loss: 0.06794212758541107, acc: 0.9931507110595703)
[2024-12-17 02:53:31,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:32,090][root][INFO] - Training Epoch: 2/2, step 5300/7134 completed (loss: 0.05428927764296532, acc: 0.9879518151283264)
[2024-12-17 02:53:32,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:32,375][root][INFO] - Training Epoch: 2/2, step 5301/7134 completed (loss: 0.07580671459436417, acc: 0.9817073345184326)
[2024-12-17 02:53:32,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:32,656][root][INFO] - Training Epoch: 2/2, step 5302/7134 completed (loss: 0.19470487534999847, acc: 0.9608938694000244)
[2024-12-17 02:53:32,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:32,941][root][INFO] - Training Epoch: 2/2, step 5303/7134 completed (loss: 0.33975648880004883, acc: 0.9242424368858337)
[2024-12-17 02:53:33,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:33,220][root][INFO] - Training Epoch: 2/2, step 5304/7134 completed (loss: 0.4501246511936188, acc: 0.9178082346916199)
[2024-12-17 02:53:33,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:33,526][root][INFO] - Training Epoch: 2/2, step 5305/7134 completed (loss: 0.24475553631782532, acc: 0.9437500238418579)
[2024-12-17 02:53:33,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:33,798][root][INFO] - Training Epoch: 2/2, step 5306/7134 completed (loss: 0.12426898628473282, acc: 0.9555555582046509)
[2024-12-17 02:53:33,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:34,075][root][INFO] - Training Epoch: 2/2, step 5307/7134 completed (loss: 0.34905698895454407, acc: 0.9181286692619324)
[2024-12-17 02:53:34,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:34,348][root][INFO] - Training Epoch: 2/2, step 5308/7134 completed (loss: 0.1948143094778061, acc: 0.9567901492118835)
[2024-12-17 02:53:34,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:34,629][root][INFO] - Training Epoch: 2/2, step 5309/7134 completed (loss: 0.3318273723125458, acc: 0.9300699234008789)
[2024-12-17 02:53:34,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:34,918][root][INFO] - Training Epoch: 2/2, step 5310/7134 completed (loss: 0.35385212302207947, acc: 0.9147727489471436)
[2024-12-17 02:53:35,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:35,212][root][INFO] - Training Epoch: 2/2, step 5311/7134 completed (loss: 0.31970036029815674, acc: 0.9130434989929199)
[2024-12-17 02:53:35,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:35,468][root][INFO] - Training Epoch: 2/2, step 5312/7134 completed (loss: 0.14876490831375122, acc: 0.9682539701461792)
[2024-12-17 02:53:35,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:35,750][root][INFO] - Training Epoch: 2/2, step 5313/7134 completed (loss: 0.17273467779159546, acc: 0.9508196711540222)
[2024-12-17 02:53:35,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:36,026][root][INFO] - Training Epoch: 2/2, step 5314/7134 completed (loss: 0.1973290741443634, acc: 0.9428571462631226)
[2024-12-17 02:53:36,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:36,314][root][INFO] - Training Epoch: 2/2, step 5315/7134 completed (loss: 0.09474790096282959, acc: 0.9784172773361206)
[2024-12-17 02:53:36,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:36,589][root][INFO] - Training Epoch: 2/2, step 5316/7134 completed (loss: 0.10643565654754639, acc: 0.9666666388511658)
[2024-12-17 02:53:36,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:36,851][root][INFO] - Training Epoch: 2/2, step 5317/7134 completed (loss: 0.07863902300596237, acc: 0.9841269850730896)
[2024-12-17 02:53:36,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:37,114][root][INFO] - Training Epoch: 2/2, step 5318/7134 completed (loss: 0.054936446249485016, acc: 0.987261176109314)
[2024-12-17 02:53:37,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:37,397][root][INFO] - Training Epoch: 2/2, step 5319/7134 completed (loss: 0.16125629842281342, acc: 0.932330846786499)
[2024-12-17 02:53:37,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:37,687][root][INFO] - Training Epoch: 2/2, step 5320/7134 completed (loss: 0.2934468686580658, acc: 0.9245283007621765)
[2024-12-17 02:53:37,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:37,967][root][INFO] - Training Epoch: 2/2, step 5321/7134 completed (loss: 0.14450454711914062, acc: 0.948051929473877)
[2024-12-17 02:53:38,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:38,247][root][INFO] - Training Epoch: 2/2, step 5322/7134 completed (loss: 0.09796839952468872, acc: 0.9599999785423279)
[2024-12-17 02:53:38,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:38,538][root][INFO] - Training Epoch: 2/2, step 5323/7134 completed (loss: 0.14582115411758423, acc: 0.9530201554298401)
[2024-12-17 02:53:38,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:38,814][root][INFO] - Training Epoch: 2/2, step 5324/7134 completed (loss: 0.1224081739783287, acc: 0.9736841917037964)
[2024-12-17 02:53:38,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:39,100][root][INFO] - Training Epoch: 2/2, step 5325/7134 completed (loss: 0.06969819962978363, acc: 1.0)
[2024-12-17 02:53:39,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:39,379][root][INFO] - Training Epoch: 2/2, step 5326/7134 completed (loss: 0.16490259766578674, acc: 0.9586206674575806)
[2024-12-17 02:53:39,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:39,648][root][INFO] - Training Epoch: 2/2, step 5327/7134 completed (loss: 0.12799228727817535, acc: 0.9677419066429138)
[2024-12-17 02:53:39,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:39,908][root][INFO] - Training Epoch: 2/2, step 5328/7134 completed (loss: 0.12110570818185806, acc: 0.969924807548523)
[2024-12-17 02:53:40,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:40,189][root][INFO] - Training Epoch: 2/2, step 5329/7134 completed (loss: 0.07877656072378159, acc: 0.9800000190734863)
[2024-12-17 02:53:40,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:40,473][root][INFO] - Training Epoch: 2/2, step 5330/7134 completed (loss: 0.17013674974441528, acc: 0.9620253443717957)
[2024-12-17 02:53:40,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:40,738][root][INFO] - Training Epoch: 2/2, step 5331/7134 completed (loss: 0.1835923045873642, acc: 0.9259259104728699)
[2024-12-17 02:53:40,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:41,008][root][INFO] - Training Epoch: 2/2, step 5332/7134 completed (loss: 0.14071093499660492, acc: 0.9589040875434875)
[2024-12-17 02:53:41,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:41,267][root][INFO] - Training Epoch: 2/2, step 5333/7134 completed (loss: 0.1026037186384201, acc: 0.9802631735801697)
[2024-12-17 02:53:41,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:41,534][root][INFO] - Training Epoch: 2/2, step 5334/7134 completed (loss: 0.22799931466579437, acc: 0.9285714030265808)
[2024-12-17 02:53:41,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:41,799][root][INFO] - Training Epoch: 2/2, step 5335/7134 completed (loss: 0.10301835834980011, acc: 0.9798657894134521)
[2024-12-17 02:53:41,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:42,072][root][INFO] - Training Epoch: 2/2, step 5336/7134 completed (loss: 0.13382138311862946, acc: 0.9647887349128723)
[2024-12-17 02:53:42,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:42,354][root][INFO] - Training Epoch: 2/2, step 5337/7134 completed (loss: 0.16325965523719788, acc: 0.9485981464385986)
[2024-12-17 02:53:42,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:42,649][root][INFO] - Training Epoch: 2/2, step 5338/7134 completed (loss: 0.08260592073202133, acc: 0.9952606558799744)
[2024-12-17 02:53:42,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:42,904][root][INFO] - Training Epoch: 2/2, step 5339/7134 completed (loss: 0.13027173280715942, acc: 0.9615384340286255)
[2024-12-17 02:53:43,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:43,188][root][INFO] - Training Epoch: 2/2, step 5340/7134 completed (loss: 0.2045016884803772, acc: 0.9463087320327759)
[2024-12-17 02:53:43,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:43,453][root][INFO] - Training Epoch: 2/2, step 5341/7134 completed (loss: 0.14095744490623474, acc: 0.9850000143051147)
[2024-12-17 02:53:43,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:43,738][root][INFO] - Training Epoch: 2/2, step 5342/7134 completed (loss: 0.28034961223602295, acc: 0.9157894849777222)
[2024-12-17 02:53:43,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:44,018][root][INFO] - Training Epoch: 2/2, step 5343/7134 completed (loss: 0.17582948505878448, acc: 0.9621621370315552)
[2024-12-17 02:53:44,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:44,308][root][INFO] - Training Epoch: 2/2, step 5344/7134 completed (loss: 0.21979866921901703, acc: 0.9429824352264404)
[2024-12-17 02:53:44,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:44,585][root][INFO] - Training Epoch: 2/2, step 5345/7134 completed (loss: 0.17028994858264923, acc: 0.9494949579238892)
[2024-12-17 02:53:44,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:44,854][root][INFO] - Training Epoch: 2/2, step 5346/7134 completed (loss: 0.14514224231243134, acc: 0.9724770784378052)
[2024-12-17 02:53:45,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:45,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:46,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:46,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:46,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:46,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:46,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:47,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:47,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:47,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:47,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:48,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:48,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:48,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:48,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:49,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:49,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:49,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:49,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:50,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:50,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:50,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:50,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:51,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:51,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:51,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:52,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:52,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:52,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:52,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:53,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:53,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:54,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:54,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:54,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:54,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:55,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:55,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:55,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:55,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:56,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:56,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:56,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:56,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:57,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:57,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:58,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:58,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:58,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:59,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:59,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:59,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:59,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:00,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:00,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:00,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:01,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:01,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:01,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:01,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:02,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:02,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:02,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:03,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:03,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:03,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:03,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:04,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:04,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:04,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:05,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:05,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:05,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:05,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:06,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:06,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:06,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:07,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:07,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:07,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:07,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:08,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:08,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:08,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:09,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:09,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:09,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:09,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:10,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:10,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:10,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:11,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:11,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:11,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:12,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:12,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:12,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:12,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:13,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:13,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:13,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:14,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:14,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:14,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:14,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:15,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:15,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:15,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:15,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:16,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:16,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:16,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:17,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:17,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:17,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:18,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:18,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:18,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:18,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:19,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:19,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:19,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:19,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:20,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:20,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:20,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:20,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:21,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:21,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:21,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:22,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:22,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:22,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:22,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:23,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:23,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:23,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:24,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:24,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:24,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:24,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:25,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:25,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:25,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:25,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:26,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:26,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:26,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:26,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:27,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:27,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:27,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:28,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:28,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:28,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:28,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:29,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:29,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:29,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:29,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:30,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:30,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:30,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:31,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:31,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:31,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:31,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:32,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:32,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:32,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:32,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:33,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:33,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:33,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:34,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:34,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:34,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:35,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:35,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:35,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:35,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:36,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:36,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:36,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:37,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:37,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:37,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:37,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:38,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:38,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:38,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:39,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:39,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:39,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:40,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:40,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:40,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:40,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:41,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:41,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:41,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:42,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:42,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:42,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:42,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:43,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:43,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:43,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:44,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:44,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:44,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:45,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:45,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:45,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:45,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:46,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:46,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:46,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:47,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:47,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:47,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:47,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:48,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:48,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:49,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:49,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:49,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:49,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:50,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:50,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:50,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:51,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:51,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:51,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:51,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:52,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:52,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:52,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:53,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:53,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:53,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:53,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:54,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:54,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:54,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:55,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:55,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:56,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:56,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:56,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:57,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:57,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:57,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:58,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:58,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:58,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:58,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:59,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:59,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:59,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:59,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:00,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:00,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:00,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:01,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:01,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:01,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:01,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:02,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:02,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:02,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:02,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:03,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:03,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:03,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:04,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:04,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:04,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:05,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:05,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:05,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:05,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:06,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:06,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:07,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:07,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:07,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:08,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:08,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:08,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:09,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:09,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:09,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:10,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:10,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:10,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:11,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:11,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:11,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:11,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:12,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:12,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:12,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:13,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:13,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:13,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:14,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:14,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:14,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:14,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:15,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:15,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:15,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:15,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:16,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:16,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:16,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:17,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:17,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:17,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:17,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:18,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:18,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:18,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:19,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:19,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:19,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:20,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:20,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:20,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:21,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:21,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:21,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:21,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:22,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:22,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:22,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:22,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:23,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:23,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:23,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:24,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:24,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:24,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:25,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:25,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:26,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:26,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:26,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:27,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:27,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:27,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:27,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:28,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:28,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:28,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:29,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:29,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:29,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:29,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:30,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:30,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:31,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:31,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:32,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:32,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:32,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:33,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:33,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:33,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:34,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:34,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:34,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:34,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:35,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:35,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:35,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:35,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:36,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:36,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:36,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:37,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:37,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:37,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:38,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:38,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:38,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:38,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:39,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:39,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:39,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:39,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:40,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:40,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:40,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:41,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:41,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:41,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:41,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:42,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:42,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:43,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:43,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:43,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:43,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:44,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:44,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:44,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:44,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:45,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:45,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:45,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:46,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:46,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:46,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:46,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:47,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:47,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:47,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:47,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:48,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:48,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:48,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:49,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:49,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:49,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:49,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:50,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:50,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:50,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:51,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:51,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:51,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:51,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:52,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:52,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:52,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:52,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:53,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:53,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:53,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:53,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:54,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:54,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:54,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:54,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:55,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:55,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:55,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:56,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:56,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:56,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:56,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:56,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:57,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:57,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:57,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:58,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:58,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:58,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:58,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:59,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:59,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:59,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:00,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:00,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:00,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:01,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:01,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:01,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:01,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:02,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:02,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:02,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:02,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:03,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:03,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:03,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:04,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:04,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:04,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:05,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:05,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:05,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:05,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:06,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:06,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:06,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:07,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:07,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:07,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:08,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:08,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:08,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:09,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:09,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:09,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:10,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:10,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:10,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:10,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:11,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:11,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:11,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:12,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:12,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:12,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:12,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:13,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:13,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:13,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:13,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:14,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:14,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:14,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:15,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:15,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:15,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:16,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:16,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:16,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:17,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:17,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:17,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:17,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:18,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:18,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:18,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:18,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:19,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:19,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:19,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:19,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:20,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:20,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:20,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:21,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:21,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:21,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:22,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:22,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:22,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:22,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:22,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:23,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:23,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:23,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:24,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:24,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:24,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:25,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:25,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:25,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:25,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:26,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:26,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:26,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:27,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:27,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:27,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:27,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:28,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:28,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:28,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:29,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:29,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:29,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:29,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:30,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:30,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:30,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:30,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:31,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:31,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:31,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:32,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:32,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:32,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:32,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:33,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:33,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:34,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:34,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:34,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:35,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:35,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:35,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:36,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:36,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:36,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:37,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:37,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:37,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:38,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:38,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:38,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:38,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:39,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:39,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:39,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:39,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:40,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:40,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:40,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:41,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:41,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:41,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:41,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:42,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:42,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:42,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:43,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:43,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:43,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:44,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:44,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:44,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:44,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:45,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:45,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:45,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:46,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:46,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:46,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:47,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:47,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:48,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:48,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:48,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:49,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:49,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:49,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:50,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:50,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:50,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:51,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:51,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:51,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:52,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:52,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:52,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:52,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:53,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:53,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:53,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:54,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:54,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:54,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:55,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:55,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:55,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:56,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:56,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:56,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:57,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:57,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:57,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:57,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:58,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:58,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:58,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:58,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:59,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:59,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:59,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:00,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:00,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:00,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:00,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:01,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:01,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:01,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:02,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:02,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:02,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:03,480][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.2578, device='cuda:0') eval_epoch_loss=tensor(0.2293, device='cuda:0') eval_epoch_acc=tensor(0.9435, device='cuda:0')
[2024-12-17 02:57:03,482][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-12-17 02:57:03,482][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 02:57:03,696][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_2_step_5347_loss_0.22934000194072723/model.pt
[2024-12-17 02:57:03,700][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 0.22934000194072723
[2024-12-17 02:57:03,700][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.9435457587242126
[2024-12-17 02:57:03,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:04,035][root][INFO] - Training Epoch: 2/2, step 5347/7134 completed (loss: 0.18367624282836914, acc: 0.9569892287254333)
[2024-12-17 02:57:04,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:04,323][root][INFO] - Training Epoch: 2/2, step 5348/7134 completed (loss: 0.20861215889453888, acc: 0.9518072009086609)
[2024-12-17 02:57:04,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:04,609][root][INFO] - Training Epoch: 2/2, step 5349/7134 completed (loss: 0.265612930059433, acc: 0.9371428489685059)
[2024-12-17 02:57:04,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:04,885][root][INFO] - Training Epoch: 2/2, step 5350/7134 completed (loss: 0.1437913477420807, acc: 0.9470587968826294)
[2024-12-17 02:57:05,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:05,161][root][INFO] - Training Epoch: 2/2, step 5351/7134 completed (loss: 0.1894955039024353, acc: 0.9351351261138916)
[2024-12-17 02:57:05,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:05,442][root][INFO] - Training Epoch: 2/2, step 5352/7134 completed (loss: 0.15967807173728943, acc: 0.9580838084220886)
[2024-12-17 02:57:05,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:05,752][root][INFO] - Training Epoch: 2/2, step 5353/7134 completed (loss: 0.15633775293827057, acc: 0.9595959782600403)
[2024-12-17 02:57:05,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:06,047][root][INFO] - Training Epoch: 2/2, step 5354/7134 completed (loss: 0.1651751846075058, acc: 0.9490740895271301)
[2024-12-17 02:57:06,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:06,331][root][INFO] - Training Epoch: 2/2, step 5355/7134 completed (loss: 0.22308333218097687, acc: 0.9375)
[2024-12-17 02:57:06,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:06,630][root][INFO] - Training Epoch: 2/2, step 5356/7134 completed (loss: 0.20844705402851105, acc: 0.9468085169792175)
[2024-12-17 02:57:06,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:06,904][root][INFO] - Training Epoch: 2/2, step 5357/7134 completed (loss: 0.12522736191749573, acc: 0.9858155846595764)
[2024-12-17 02:57:07,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:07,196][root][INFO] - Training Epoch: 2/2, step 5358/7134 completed (loss: 0.32625284790992737, acc: 0.9120879173278809)
[2024-12-17 02:57:07,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:07,491][root][INFO] - Training Epoch: 2/2, step 5359/7134 completed (loss: 0.162522092461586, acc: 0.9556650519371033)
[2024-12-17 02:57:07,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:07,774][root][INFO] - Training Epoch: 2/2, step 5360/7134 completed (loss: 0.0818711444735527, acc: 0.977011501789093)
[2024-12-17 02:57:07,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:08,076][root][INFO] - Training Epoch: 2/2, step 5361/7134 completed (loss: 0.31709396839141846, acc: 0.9441624283790588)
[2024-12-17 02:57:08,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:08,372][root][INFO] - Training Epoch: 2/2, step 5362/7134 completed (loss: 0.27147844433784485, acc: 0.9324324131011963)
[2024-12-17 02:57:08,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:08,663][root][INFO] - Training Epoch: 2/2, step 5363/7134 completed (loss: 0.1505286693572998, acc: 0.9695122241973877)
[2024-12-17 02:57:08,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:08,959][root][INFO] - Training Epoch: 2/2, step 5364/7134 completed (loss: 0.09311574697494507, acc: 0.9826589822769165)
[2024-12-17 02:57:09,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:09,248][root][INFO] - Training Epoch: 2/2, step 5365/7134 completed (loss: 0.10075531154870987, acc: 0.9621211886405945)
[2024-12-17 02:57:09,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:09,537][root][INFO] - Training Epoch: 2/2, step 5366/7134 completed (loss: 0.283032089471817, acc: 0.9701492786407471)
[2024-12-17 02:57:09,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:09,835][root][INFO] - Training Epoch: 2/2, step 5367/7134 completed (loss: 0.2053072154521942, acc: 0.9510869383811951)
[2024-12-17 02:57:09,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:10,137][root][INFO] - Training Epoch: 2/2, step 5368/7134 completed (loss: 0.17184020578861237, acc: 0.9689922332763672)
[2024-12-17 02:57:10,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:10,405][root][INFO] - Training Epoch: 2/2, step 5369/7134 completed (loss: 0.23352354764938354, acc: 0.9661017060279846)
[2024-12-17 02:57:10,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:10,698][root][INFO] - Training Epoch: 2/2, step 5370/7134 completed (loss: 0.24424467980861664, acc: 0.9285714030265808)
[2024-12-17 02:57:10,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:10,998][root][INFO] - Training Epoch: 2/2, step 5371/7134 completed (loss: 0.3856147825717926, acc: 0.9200000166893005)
[2024-12-17 02:57:11,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:11,289][root][INFO] - Training Epoch: 2/2, step 5372/7134 completed (loss: 0.08438053727149963, acc: 0.9748427867889404)
[2024-12-17 02:57:11,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:11,568][root][INFO] - Training Epoch: 2/2, step 5373/7134 completed (loss: 0.08946387469768524, acc: 0.9920634627342224)
[2024-12-17 02:57:11,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:11,778][root][INFO] - Training Epoch: 2/2, step 5374/7134 completed (loss: 0.07428668439388275, acc: 0.988095223903656)
[2024-12-17 02:57:11,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:12,054][root][INFO] - Training Epoch: 2/2, step 5375/7134 completed (loss: 0.11050452291965485, acc: 0.9844961166381836)
[2024-12-17 02:57:12,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:12,325][root][INFO] - Training Epoch: 2/2, step 5376/7134 completed (loss: 0.055580075830221176, acc: 0.9864864945411682)
[2024-12-17 02:57:12,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:12,611][root][INFO] - Training Epoch: 2/2, step 5377/7134 completed (loss: 0.14712730050086975, acc: 0.9753086566925049)
[2024-12-17 02:57:12,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:12,909][root][INFO] - Training Epoch: 2/2, step 5378/7134 completed (loss: 0.05402349680662155, acc: 0.9894737005233765)
[2024-12-17 02:57:13,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:13,196][root][INFO] - Training Epoch: 2/2, step 5379/7134 completed (loss: 0.06932373344898224, acc: 0.984375)
[2024-12-17 02:57:13,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:13,481][root][INFO] - Training Epoch: 2/2, step 5380/7134 completed (loss: 0.07674545049667358, acc: 0.9851852059364319)
[2024-12-17 02:57:13,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:13,755][root][INFO] - Training Epoch: 2/2, step 5381/7134 completed (loss: 0.06393962353467941, acc: 0.9830508232116699)
[2024-12-17 02:57:13,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:14,021][root][INFO] - Training Epoch: 2/2, step 5382/7134 completed (loss: 0.050409331917762756, acc: 0.9927536249160767)
[2024-12-17 02:57:14,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:14,313][root][INFO] - Training Epoch: 2/2, step 5383/7134 completed (loss: 0.06669828295707703, acc: 0.9919354915618896)
[2024-12-17 02:57:14,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:14,612][root][INFO] - Training Epoch: 2/2, step 5384/7134 completed (loss: 0.08877424150705338, acc: 0.989847719669342)
[2024-12-17 02:57:14,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:14,889][root][INFO] - Training Epoch: 2/2, step 5385/7134 completed (loss: 0.10586745291948318, acc: 0.9767441749572754)
[2024-12-17 02:57:15,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:15,164][root][INFO] - Training Epoch: 2/2, step 5386/7134 completed (loss: 0.07345408946275711, acc: 0.9670329689979553)
[2024-12-17 02:57:15,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:15,455][root][INFO] - Training Epoch: 2/2, step 5387/7134 completed (loss: 0.04458211362361908, acc: 0.9836065769195557)
[2024-12-17 02:57:15,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:15,743][root][INFO] - Training Epoch: 2/2, step 5388/7134 completed (loss: 0.05516897886991501, acc: 0.9888268113136292)
[2024-12-17 02:57:15,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:16,015][root][INFO] - Training Epoch: 2/2, step 5389/7134 completed (loss: 0.06285261362791061, acc: 0.9863945841789246)
[2024-12-17 02:57:16,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:16,298][root][INFO] - Training Epoch: 2/2, step 5390/7134 completed (loss: 0.19021980464458466, acc: 0.955974817276001)
[2024-12-17 02:57:16,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:16,539][root][INFO] - Training Epoch: 2/2, step 5391/7134 completed (loss: 0.10101304203271866, acc: 0.971222996711731)
[2024-12-17 02:57:16,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:16,810][root][INFO] - Training Epoch: 2/2, step 5392/7134 completed (loss: 0.27756521105766296, acc: 0.9318181872367859)
[2024-12-17 02:57:16,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:17,103][root][INFO] - Training Epoch: 2/2, step 5393/7134 completed (loss: 0.09913789480924606, acc: 0.9750000238418579)
[2024-12-17 02:57:17,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:17,389][root][INFO] - Training Epoch: 2/2, step 5394/7134 completed (loss: 0.3151214122772217, acc: 0.921875)
[2024-12-17 02:57:17,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:17,669][root][INFO] - Training Epoch: 2/2, step 5395/7134 completed (loss: 0.08975274115800858, acc: 0.9594594836235046)
[2024-12-17 02:57:17,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:17,955][root][INFO] - Training Epoch: 2/2, step 5396/7134 completed (loss: 0.1149711012840271, acc: 0.9736841917037964)
[2024-12-17 02:57:18,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:18,235][root][INFO] - Training Epoch: 2/2, step 5397/7134 completed (loss: 0.10032506287097931, acc: 0.9716312289237976)
[2024-12-17 02:57:18,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:18,509][root][INFO] - Training Epoch: 2/2, step 5398/7134 completed (loss: 0.08609672635793686, acc: 0.9879518151283264)
[2024-12-17 02:57:18,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:18,796][root][INFO] - Training Epoch: 2/2, step 5399/7134 completed (loss: 0.11656149476766586, acc: 0.9657142758369446)
[2024-12-17 02:57:18,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:19,088][root][INFO] - Training Epoch: 2/2, step 5400/7134 completed (loss: 0.26856523752212524, acc: 0.9586206674575806)
[2024-12-17 02:57:19,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:19,377][root][INFO] - Training Epoch: 2/2, step 5401/7134 completed (loss: 0.08678187429904938, acc: 0.9930555820465088)
[2024-12-17 02:57:19,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:19,645][root][INFO] - Training Epoch: 2/2, step 5402/7134 completed (loss: 0.13596537709236145, acc: 0.9589040875434875)
[2024-12-17 02:57:19,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:19,918][root][INFO] - Training Epoch: 2/2, step 5403/7134 completed (loss: 0.1888968050479889, acc: 0.9672130942344666)
[2024-12-17 02:57:20,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:20,197][root][INFO] - Training Epoch: 2/2, step 5404/7134 completed (loss: 0.3436093032360077, acc: 0.9328858852386475)
[2024-12-17 02:57:20,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:20,486][root][INFO] - Training Epoch: 2/2, step 5405/7134 completed (loss: 0.09307853877544403, acc: 0.9739130139350891)
[2024-12-17 02:57:20,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:20,764][root][INFO] - Training Epoch: 2/2, step 5406/7134 completed (loss: 0.12335939705371857, acc: 0.954954981803894)
[2024-12-17 02:57:20,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:21,014][root][INFO] - Training Epoch: 2/2, step 5407/7134 completed (loss: 0.15475645661354065, acc: 0.9560439586639404)
[2024-12-17 02:57:21,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:21,286][root][INFO] - Training Epoch: 2/2, step 5408/7134 completed (loss: 0.3336108326911926, acc: 0.9432623982429504)
[2024-12-17 02:57:21,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:21,581][root][INFO] - Training Epoch: 2/2, step 5409/7134 completed (loss: 0.2948255240917206, acc: 0.9580419659614563)
[2024-12-17 02:57:21,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:21,875][root][INFO] - Training Epoch: 2/2, step 5410/7134 completed (loss: 0.07236073166131973, acc: 0.9819276928901672)
[2024-12-17 02:57:21,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:22,123][root][INFO] - Training Epoch: 2/2, step 5411/7134 completed (loss: 0.19283930957317352, acc: 0.9436619877815247)
[2024-12-17 02:57:22,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:22,402][root][INFO] - Training Epoch: 2/2, step 5412/7134 completed (loss: 0.2757652997970581, acc: 0.9380530714988708)
[2024-12-17 02:57:22,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:22,690][root][INFO] - Training Epoch: 2/2, step 5413/7134 completed (loss: 0.26809659600257874, acc: 0.9375)
[2024-12-17 02:57:22,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:22,972][root][INFO] - Training Epoch: 2/2, step 5414/7134 completed (loss: 0.37245994806289673, acc: 0.916167676448822)
[2024-12-17 02:57:23,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:23,245][root][INFO] - Training Epoch: 2/2, step 5415/7134 completed (loss: 0.33576902747154236, acc: 0.9415584206581116)
[2024-12-17 02:57:23,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:23,536][root][INFO] - Training Epoch: 2/2, step 5416/7134 completed (loss: 0.2639395594596863, acc: 0.9090909361839294)
[2024-12-17 02:57:23,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:23,816][root][INFO] - Training Epoch: 2/2, step 5417/7134 completed (loss: 0.09825306385755539, acc: 0.9743589758872986)
[2024-12-17 02:57:23,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:24,083][root][INFO] - Training Epoch: 2/2, step 5418/7134 completed (loss: 0.35466280579566956, acc: 0.9236111044883728)
[2024-12-17 02:57:24,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:24,356][root][INFO] - Training Epoch: 2/2, step 5419/7134 completed (loss: 0.4756394028663635, acc: 0.8613138794898987)
[2024-12-17 02:57:24,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:24,637][root][INFO] - Training Epoch: 2/2, step 5420/7134 completed (loss: 0.6117507815361023, acc: 0.8646616339683533)
[2024-12-17 02:57:24,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:24,917][root][INFO] - Training Epoch: 2/2, step 5421/7134 completed (loss: 0.4106619358062744, acc: 0.90625)
[2024-12-17 02:57:25,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:25,199][root][INFO] - Training Epoch: 2/2, step 5422/7134 completed (loss: 0.15123580396175385, acc: 0.9513888955116272)
[2024-12-17 02:57:25,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:25,443][root][INFO] - Training Epoch: 2/2, step 5423/7134 completed (loss: 0.11934427917003632, acc: 0.9624999761581421)
[2024-12-17 02:57:25,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:25,715][root][INFO] - Training Epoch: 2/2, step 5424/7134 completed (loss: 0.15902212262153625, acc: 0.9615384340286255)
[2024-12-17 02:57:25,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:26,003][root][INFO] - Training Epoch: 2/2, step 5425/7134 completed (loss: 0.1507064402103424, acc: 0.9453125)
[2024-12-17 02:57:26,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:26,287][root][INFO] - Training Epoch: 2/2, step 5426/7134 completed (loss: 0.15138885378837585, acc: 0.9754098653793335)
[2024-12-17 02:57:26,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:26,598][root][INFO] - Training Epoch: 2/2, step 5427/7134 completed (loss: 0.12240687757730484, acc: 0.9738562107086182)
[2024-12-17 02:57:26,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:26,891][root][INFO] - Training Epoch: 2/2, step 5428/7134 completed (loss: 0.14606520533561707, acc: 0.9586206674575806)
[2024-12-17 02:57:26,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:27,167][root][INFO] - Training Epoch: 2/2, step 5429/7134 completed (loss: 0.19067463278770447, acc: 0.9530201554298401)
[2024-12-17 02:57:27,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:27,470][root][INFO] - Training Epoch: 2/2, step 5430/7134 completed (loss: 0.21240518987178802, acc: 0.9675324559211731)
[2024-12-17 02:57:27,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:27,756][root][INFO] - Training Epoch: 2/2, step 5431/7134 completed (loss: 0.19701659679412842, acc: 0.9398496150970459)
[2024-12-17 02:57:27,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:28,033][root][INFO] - Training Epoch: 2/2, step 5432/7134 completed (loss: 0.08141549676656723, acc: 0.9765625)
[2024-12-17 02:57:28,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:28,299][root][INFO] - Training Epoch: 2/2, step 5433/7134 completed (loss: 0.19266168773174286, acc: 0.9831932783126831)
[2024-12-17 02:57:28,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:28,583][root][INFO] - Training Epoch: 2/2, step 5434/7134 completed (loss: 0.31438228487968445, acc: 0.9274193644523621)
[2024-12-17 02:57:28,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:28,859][root][INFO] - Training Epoch: 2/2, step 5435/7134 completed (loss: 0.16665266454219818, acc: 0.9520000219345093)
[2024-12-17 02:57:28,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:29,133][root][INFO] - Training Epoch: 2/2, step 5436/7134 completed (loss: 0.14794707298278809, acc: 0.9548386931419373)
[2024-12-17 02:57:29,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:29,412][root][INFO] - Training Epoch: 2/2, step 5437/7134 completed (loss: 0.12254868447780609, acc: 0.9849624037742615)
[2024-12-17 02:57:29,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:29,694][root][INFO] - Training Epoch: 2/2, step 5438/7134 completed (loss: 0.20270539820194244, acc: 0.9388889074325562)
[2024-12-17 02:57:29,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:29,980][root][INFO] - Training Epoch: 2/2, step 5439/7134 completed (loss: 0.355143278837204, acc: 0.9212121367454529)
[2024-12-17 02:57:30,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:30,267][root][INFO] - Training Epoch: 2/2, step 5440/7134 completed (loss: 0.2048373967409134, acc: 0.9444444179534912)
[2024-12-17 02:57:30,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:30,551][root][INFO] - Training Epoch: 2/2, step 5441/7134 completed (loss: 0.2219265103340149, acc: 0.9405405521392822)
[2024-12-17 02:57:30,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:30,833][root][INFO] - Training Epoch: 2/2, step 5442/7134 completed (loss: 0.1045379638671875, acc: 0.9702380895614624)
[2024-12-17 02:57:30,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:31,112][root][INFO] - Training Epoch: 2/2, step 5443/7134 completed (loss: 0.11797352880239487, acc: 0.9695122241973877)
[2024-12-17 02:57:31,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:31,399][root][INFO] - Training Epoch: 2/2, step 5444/7134 completed (loss: 0.1594298779964447, acc: 0.9558823704719543)
[2024-12-17 02:57:31,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:31,685][root][INFO] - Training Epoch: 2/2, step 5445/7134 completed (loss: 0.25803977251052856, acc: 0.9411764740943909)
[2024-12-17 02:57:31,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:31,969][root][INFO] - Training Epoch: 2/2, step 5446/7134 completed (loss: 0.11465640366077423, acc: 0.9570552110671997)
[2024-12-17 02:57:32,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:32,231][root][INFO] - Training Epoch: 2/2, step 5447/7134 completed (loss: 0.17068155109882355, acc: 0.9520547986030579)
[2024-12-17 02:57:32,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:32,526][root][INFO] - Training Epoch: 2/2, step 5448/7134 completed (loss: 0.21736212074756622, acc: 0.9285714030265808)
[2024-12-17 02:57:32,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:32,790][root][INFO] - Training Epoch: 2/2, step 5449/7134 completed (loss: 0.14552444219589233, acc: 0.9590163826942444)
[2024-12-17 02:57:32,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:33,082][root][INFO] - Training Epoch: 2/2, step 5450/7134 completed (loss: 0.1503026783466339, acc: 0.9555555582046509)
[2024-12-17 02:57:33,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:33,349][root][INFO] - Training Epoch: 2/2, step 5451/7134 completed (loss: 0.08462827652692795, acc: 0.9822485446929932)
[2024-12-17 02:57:33,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:33,629][root][INFO] - Training Epoch: 2/2, step 5452/7134 completed (loss: 0.1187492236495018, acc: 0.9704142212867737)
[2024-12-17 02:57:33,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:33,914][root][INFO] - Training Epoch: 2/2, step 5453/7134 completed (loss: 0.21170319616794586, acc: 0.9555555582046509)
[2024-12-17 02:57:34,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:34,201][root][INFO] - Training Epoch: 2/2, step 5454/7134 completed (loss: 0.20463037490844727, acc: 0.9619565010070801)
[2024-12-17 02:57:34,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:34,482][root][INFO] - Training Epoch: 2/2, step 5455/7134 completed (loss: 0.1816762387752533, acc: 0.9732620120048523)
[2024-12-17 02:57:34,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:34,768][root][INFO] - Training Epoch: 2/2, step 5456/7134 completed (loss: 0.1176537573337555, acc: 0.9784946441650391)
[2024-12-17 02:57:34,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:35,065][root][INFO] - Training Epoch: 2/2, step 5457/7134 completed (loss: 0.16510562598705292, acc: 0.9712643623352051)
[2024-12-17 02:57:35,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:35,351][root][INFO] - Training Epoch: 2/2, step 5458/7134 completed (loss: 0.1626361906528473, acc: 0.9723756909370422)
[2024-12-17 02:57:35,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:35,633][root][INFO] - Training Epoch: 2/2, step 5459/7134 completed (loss: 0.03195500001311302, acc: 0.9938650131225586)
[2024-12-17 02:57:35,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:35,905][root][INFO] - Training Epoch: 2/2, step 5460/7134 completed (loss: 0.09787706285715103, acc: 0.9704142212867737)
[2024-12-17 02:57:36,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:36,174][root][INFO] - Training Epoch: 2/2, step 5461/7134 completed (loss: 0.22573992609977722, acc: 0.9357798099517822)
[2024-12-17 02:57:36,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:36,459][root][INFO] - Training Epoch: 2/2, step 5462/7134 completed (loss: 0.08610019832849503, acc: 0.9631901979446411)
[2024-12-17 02:57:36,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:36,744][root][INFO] - Training Epoch: 2/2, step 5463/7134 completed (loss: 0.21482086181640625, acc: 0.9567901492118835)
[2024-12-17 02:57:36,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:37,029][root][INFO] - Training Epoch: 2/2, step 5464/7134 completed (loss: 0.198347270488739, acc: 0.9672130942344666)
[2024-12-17 02:57:37,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:37,308][root][INFO] - Training Epoch: 2/2, step 5465/7134 completed (loss: 0.07295222580432892, acc: 0.987500011920929)
[2024-12-17 02:57:37,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:37,596][root][INFO] - Training Epoch: 2/2, step 5466/7134 completed (loss: 0.0991031676530838, acc: 0.9800994992256165)
[2024-12-17 02:57:37,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:37,893][root][INFO] - Training Epoch: 2/2, step 5467/7134 completed (loss: 0.07684531062841415, acc: 0.9800994992256165)
[2024-12-17 02:57:38,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:38,178][root][INFO] - Training Epoch: 2/2, step 5468/7134 completed (loss: 0.07922061532735825, acc: 0.9738219976425171)
[2024-12-17 02:57:38,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:38,464][root][INFO] - Training Epoch: 2/2, step 5469/7134 completed (loss: 0.2209145873785019, acc: 0.9365079402923584)
[2024-12-17 02:57:38,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:38,754][root][INFO] - Training Epoch: 2/2, step 5470/7134 completed (loss: 0.037102095782756805, acc: 0.9900497794151306)
[2024-12-17 02:57:38,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:39,033][root][INFO] - Training Epoch: 2/2, step 5471/7134 completed (loss: 0.07001041620969772, acc: 0.9764705896377563)
[2024-12-17 02:57:39,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:39,318][root][INFO] - Training Epoch: 2/2, step 5472/7134 completed (loss: 0.09903234243392944, acc: 0.9832402467727661)
[2024-12-17 02:57:39,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:39,608][root][INFO] - Training Epoch: 2/2, step 5473/7134 completed (loss: 0.07344326376914978, acc: 0.9898989796638489)
[2024-12-17 02:57:39,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:39,889][root][INFO] - Training Epoch: 2/2, step 5474/7134 completed (loss: 0.1318744271993637, acc: 0.9636363387107849)
[2024-12-17 02:57:40,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:40,167][root][INFO] - Training Epoch: 2/2, step 5475/7134 completed (loss: 0.06670956313610077, acc: 0.9814814925193787)
[2024-12-17 02:57:40,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:40,437][root][INFO] - Training Epoch: 2/2, step 5476/7134 completed (loss: 0.06959372013807297, acc: 0.9870129823684692)
[2024-12-17 02:57:40,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:40,741][root][INFO] - Training Epoch: 2/2, step 5477/7134 completed (loss: 0.11510605365037918, acc: 0.9744898080825806)
[2024-12-17 02:57:40,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:41,061][root][INFO] - Training Epoch: 2/2, step 5478/7134 completed (loss: 0.11016064882278442, acc: 0.970370352268219)
[2024-12-17 02:57:41,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:41,374][root][INFO] - Training Epoch: 2/2, step 5479/7134 completed (loss: 0.16014179587364197, acc: 0.9729729890823364)
[2024-12-17 02:57:41,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:41,656][root][INFO] - Training Epoch: 2/2, step 5480/7134 completed (loss: 0.14836454391479492, acc: 0.9464285969734192)
[2024-12-17 02:57:41,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:41,949][root][INFO] - Training Epoch: 2/2, step 5481/7134 completed (loss: 0.13392052054405212, acc: 0.9672130942344666)
[2024-12-17 02:57:42,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:42,485][root][INFO] - Training Epoch: 2/2, step 5482/7134 completed (loss: 0.25068601965904236, acc: 0.938144326210022)
[2024-12-17 02:57:42,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:42,818][root][INFO] - Training Epoch: 2/2, step 5483/7134 completed (loss: 0.16470962762832642, acc: 0.9636363387107849)
[2024-12-17 02:57:42,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:43,097][root][INFO] - Training Epoch: 2/2, step 5484/7134 completed (loss: 0.13436128199100494, acc: 0.9691358208656311)
[2024-12-17 02:57:43,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:43,366][root][INFO] - Training Epoch: 2/2, step 5485/7134 completed (loss: 0.1669432371854782, acc: 0.9596773982048035)
[2024-12-17 02:57:43,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:43,656][root][INFO] - Training Epoch: 2/2, step 5486/7134 completed (loss: 0.1938541978597641, acc: 0.939393937587738)
[2024-12-17 02:57:43,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:43,932][root][INFO] - Training Epoch: 2/2, step 5487/7134 completed (loss: 0.13960866630077362, acc: 0.9659863710403442)
[2024-12-17 02:57:44,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:44,228][root][INFO] - Training Epoch: 2/2, step 5488/7134 completed (loss: 0.21723903715610504, acc: 0.916167676448822)
[2024-12-17 02:57:44,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:44,520][root][INFO] - Training Epoch: 2/2, step 5489/7134 completed (loss: 0.41282719373703003, acc: 0.9024389982223511)
[2024-12-17 02:57:44,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:44,789][root][INFO] - Training Epoch: 2/2, step 5490/7134 completed (loss: 0.1241687461733818, acc: 0.9696969985961914)
[2024-12-17 02:57:44,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:45,066][root][INFO] - Training Epoch: 2/2, step 5491/7134 completed (loss: 0.14067304134368896, acc: 0.9649122953414917)
[2024-12-17 02:57:45,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:45,356][root][INFO] - Training Epoch: 2/2, step 5492/7134 completed (loss: 0.2519497573375702, acc: 0.9402984976768494)
[2024-12-17 02:57:45,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:45,627][root][INFO] - Training Epoch: 2/2, step 5493/7134 completed (loss: 0.29139938950538635, acc: 0.9427083134651184)
[2024-12-17 02:57:45,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:45,912][root][INFO] - Training Epoch: 2/2, step 5494/7134 completed (loss: 0.11911199986934662, acc: 0.9748427867889404)
[2024-12-17 02:57:46,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:46,167][root][INFO] - Training Epoch: 2/2, step 5495/7134 completed (loss: 0.1753614842891693, acc: 0.9624060392379761)
[2024-12-17 02:57:46,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:46,442][root][INFO] - Training Epoch: 2/2, step 5496/7134 completed (loss: 0.26821836829185486, acc: 0.9365079402923584)
[2024-12-17 02:57:46,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:46,729][root][INFO] - Training Epoch: 2/2, step 5497/7134 completed (loss: 0.28846269845962524, acc: 0.9352940917015076)
[2024-12-17 02:57:46,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:46,997][root][INFO] - Training Epoch: 2/2, step 5498/7134 completed (loss: 0.17970594763755798, acc: 0.9468085169792175)
[2024-12-17 02:57:47,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:47,283][root][INFO] - Training Epoch: 2/2, step 5499/7134 completed (loss: 0.1646210104227066, acc: 0.954954981803894)
[2024-12-17 02:57:47,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:47,565][root][INFO] - Training Epoch: 2/2, step 5500/7134 completed (loss: 0.11409741640090942, acc: 0.9689119458198547)
[2024-12-17 02:57:47,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:47,848][root][INFO] - Training Epoch: 2/2, step 5501/7134 completed (loss: 0.1678646206855774, acc: 0.9545454382896423)
[2024-12-17 02:57:47,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:48,131][root][INFO] - Training Epoch: 2/2, step 5502/7134 completed (loss: 0.14264187216758728, acc: 0.9548022747039795)
[2024-12-17 02:57:48,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:48,410][root][INFO] - Training Epoch: 2/2, step 5503/7134 completed (loss: 0.39177975058555603, acc: 0.9230769276618958)
[2024-12-17 02:57:48,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:48,719][root][INFO] - Training Epoch: 2/2, step 5504/7134 completed (loss: 0.12588050961494446, acc: 0.9518072009086609)
[2024-12-17 02:57:48,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:49,001][root][INFO] - Training Epoch: 2/2, step 5505/7134 completed (loss: 0.3316058814525604, acc: 0.8863636255264282)
[2024-12-17 02:57:49,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:49,285][root][INFO] - Training Epoch: 2/2, step 5506/7134 completed (loss: 0.23656423389911652, acc: 0.9444444179534912)
[2024-12-17 02:57:49,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:49,561][root][INFO] - Training Epoch: 2/2, step 5507/7134 completed (loss: 0.17253786325454712, acc: 0.9649122953414917)
[2024-12-17 02:57:49,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:49,845][root][INFO] - Training Epoch: 2/2, step 5508/7134 completed (loss: 0.10680386424064636, acc: 0.9760765433311462)
[2024-12-17 02:57:49,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:50,130][root][INFO] - Training Epoch: 2/2, step 5509/7134 completed (loss: 0.19872677326202393, acc: 0.9668246507644653)
[2024-12-17 02:57:50,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:50,414][root][INFO] - Training Epoch: 2/2, step 5510/7134 completed (loss: 0.2886445224285126, acc: 0.9354838728904724)
[2024-12-17 02:57:50,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:50,725][root][INFO] - Training Epoch: 2/2, step 5511/7134 completed (loss: 0.2151719033718109, acc: 0.9320388436317444)
[2024-12-17 02:57:50,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:51,001][root][INFO] - Training Epoch: 2/2, step 5512/7134 completed (loss: 0.24649718403816223, acc: 0.9340659379959106)
[2024-12-17 02:57:51,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:51,276][root][INFO] - Training Epoch: 2/2, step 5513/7134 completed (loss: 0.23098935186862946, acc: 0.9289940595626831)
[2024-12-17 02:57:51,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:51,566][root][INFO] - Training Epoch: 2/2, step 5514/7134 completed (loss: 0.36988961696624756, acc: 0.9027777910232544)
[2024-12-17 02:57:51,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:51,836][root][INFO] - Training Epoch: 2/2, step 5515/7134 completed (loss: 0.2564559280872345, acc: 0.9285714030265808)
[2024-12-17 02:57:51,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:52,089][root][INFO] - Training Epoch: 2/2, step 5516/7134 completed (loss: 0.18687593936920166, acc: 0.9655172228813171)
[2024-12-17 02:57:52,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:52,352][root][INFO] - Training Epoch: 2/2, step 5517/7134 completed (loss: 0.12389832735061646, acc: 0.9776536226272583)
[2024-12-17 02:57:52,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:52,644][root][INFO] - Training Epoch: 2/2, step 5518/7134 completed (loss: 0.1758618801832199, acc: 0.9444444179534912)
[2024-12-17 02:57:52,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:52,945][root][INFO] - Training Epoch: 2/2, step 5519/7134 completed (loss: 0.11424119025468826, acc: 0.9629629850387573)
[2024-12-17 02:57:53,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:53,238][root][INFO] - Training Epoch: 2/2, step 5520/7134 completed (loss: 0.1483447104692459, acc: 0.9573459625244141)
[2024-12-17 02:57:53,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:53,522][root][INFO] - Training Epoch: 2/2, step 5521/7134 completed (loss: 0.1995110809803009, acc: 0.9581151604652405)
[2024-12-17 02:57:53,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:53,801][root][INFO] - Training Epoch: 2/2, step 5522/7134 completed (loss: 0.19293910264968872, acc: 0.9424083828926086)
[2024-12-17 02:57:53,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:54,085][root][INFO] - Training Epoch: 2/2, step 5523/7134 completed (loss: 0.16822564601898193, acc: 0.9560439586639404)
[2024-12-17 02:57:54,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:54,365][root][INFO] - Training Epoch: 2/2, step 5524/7134 completed (loss: 0.3193458616733551, acc: 0.8987341523170471)
[2024-12-17 02:57:54,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:54,648][root][INFO] - Training Epoch: 2/2, step 5525/7134 completed (loss: 0.1316981017589569, acc: 0.9695122241973877)
[2024-12-17 02:57:54,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:54,941][root][INFO] - Training Epoch: 2/2, step 5526/7134 completed (loss: 0.12279936671257019, acc: 0.9751552939414978)
[2024-12-17 02:57:55,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:55,240][root][INFO] - Training Epoch: 2/2, step 5527/7134 completed (loss: 0.16916394233703613, acc: 0.9510489702224731)
[2024-12-17 02:57:55,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:55,544][root][INFO] - Training Epoch: 2/2, step 5528/7134 completed (loss: 0.15588369965553284, acc: 0.939393937587738)
[2024-12-17 02:57:55,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:55,853][root][INFO] - Training Epoch: 2/2, step 5529/7134 completed (loss: 0.12412071228027344, acc: 0.9727272987365723)
[2024-12-17 02:57:55,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:56,145][root][INFO] - Training Epoch: 2/2, step 5530/7134 completed (loss: 0.08823048323392868, acc: 0.9863945841789246)
[2024-12-17 02:57:56,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:56,427][root][INFO] - Training Epoch: 2/2, step 5531/7134 completed (loss: 0.11236834526062012, acc: 0.9759036302566528)
[2024-12-17 02:57:56,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:56,717][root][INFO] - Training Epoch: 2/2, step 5532/7134 completed (loss: 0.14945760369300842, acc: 0.9491525292396545)
[2024-12-17 02:57:56,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:57,005][root][INFO] - Training Epoch: 2/2, step 5533/7134 completed (loss: 0.04395807161927223, acc: 1.0)
[2024-12-17 02:57:57,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:57,293][root][INFO] - Training Epoch: 2/2, step 5534/7134 completed (loss: 0.1516840159893036, acc: 0.966292142868042)
[2024-12-17 02:57:57,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:57,613][root][INFO] - Training Epoch: 2/2, step 5535/7134 completed (loss: 0.08654376119375229, acc: 0.9792746305465698)
[2024-12-17 02:57:57,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:57,893][root][INFO] - Training Epoch: 2/2, step 5536/7134 completed (loss: 0.12030655890703201, acc: 0.9726775884628296)
[2024-12-17 02:57:58,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:58,166][root][INFO] - Training Epoch: 2/2, step 5537/7134 completed (loss: 0.12787076830863953, acc: 0.9712643623352051)
[2024-12-17 02:57:58,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:58,455][root][INFO] - Training Epoch: 2/2, step 5538/7134 completed (loss: 0.1354028880596161, acc: 0.9790576100349426)
[2024-12-17 02:57:58,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:58,741][root][INFO] - Training Epoch: 2/2, step 5539/7134 completed (loss: 0.13123749196529388, acc: 0.9617486596107483)
[2024-12-17 02:57:58,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:59,014][root][INFO] - Training Epoch: 2/2, step 5540/7134 completed (loss: 0.15900318324565887, acc: 0.9578313231468201)
[2024-12-17 02:57:59,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:59,285][root][INFO] - Training Epoch: 2/2, step 5541/7134 completed (loss: 0.08119483292102814, acc: 0.9883720874786377)
[2024-12-17 02:57:59,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:59,545][root][INFO] - Training Epoch: 2/2, step 5542/7134 completed (loss: 0.02558871917426586, acc: 1.0)
[2024-12-17 02:57:59,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:59,830][root][INFO] - Training Epoch: 2/2, step 5543/7134 completed (loss: 0.09255136549472809, acc: 0.9893048405647278)
[2024-12-17 02:57:59,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:00,109][root][INFO] - Training Epoch: 2/2, step 5544/7134 completed (loss: 0.0639931857585907, acc: 0.9890710115432739)
[2024-12-17 02:58:00,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:00,384][root][INFO] - Training Epoch: 2/2, step 5545/7134 completed (loss: 0.09172195196151733, acc: 0.988095223903656)
[2024-12-17 02:58:00,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:00,664][root][INFO] - Training Epoch: 2/2, step 5546/7134 completed (loss: 0.09897480905056, acc: 0.9820359349250793)
[2024-12-17 02:58:00,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:00,953][root][INFO] - Training Epoch: 2/2, step 5547/7134 completed (loss: 0.12860378623008728, acc: 0.9613259434700012)
[2024-12-17 02:58:01,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:01,234][root][INFO] - Training Epoch: 2/2, step 5548/7134 completed (loss: 0.06844667345285416, acc: 0.9823529124259949)
[2024-12-17 02:58:01,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:01,489][root][INFO] - Training Epoch: 2/2, step 5549/7134 completed (loss: 0.12247263640165329, acc: 0.9664429426193237)
[2024-12-17 02:58:01,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:01,768][root][INFO] - Training Epoch: 2/2, step 5550/7134 completed (loss: 0.06930968165397644, acc: 0.9887640476226807)
[2024-12-17 02:58:01,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:02,027][root][INFO] - Training Epoch: 2/2, step 5551/7134 completed (loss: 0.17922616004943848, acc: 0.948387086391449)
[2024-12-17 02:58:02,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:02,304][root][INFO] - Training Epoch: 2/2, step 5552/7134 completed (loss: 0.06636805832386017, acc: 0.9693251252174377)
[2024-12-17 02:58:02,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:02,575][root][INFO] - Training Epoch: 2/2, step 5553/7134 completed (loss: 0.1457027941942215, acc: 0.9585798978805542)
[2024-12-17 02:58:02,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:02,842][root][INFO] - Training Epoch: 2/2, step 5554/7134 completed (loss: 0.08614979684352875, acc: 0.9808917045593262)
[2024-12-17 02:58:02,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:03,126][root][INFO] - Training Epoch: 2/2, step 5555/7134 completed (loss: 0.1403958797454834, acc: 0.9642857313156128)
[2024-12-17 02:58:03,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:03,413][root][INFO] - Training Epoch: 2/2, step 5556/7134 completed (loss: 0.18747557699680328, acc: 0.9441340565681458)
[2024-12-17 02:58:03,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:03,717][root][INFO] - Training Epoch: 2/2, step 5557/7134 completed (loss: 0.12423075735569, acc: 0.9627329111099243)
[2024-12-17 02:58:03,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:04,015][root][INFO] - Training Epoch: 2/2, step 5558/7134 completed (loss: 0.11604935675859451, acc: 0.9555555582046509)
[2024-12-17 02:58:04,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:04,312][root][INFO] - Training Epoch: 2/2, step 5559/7134 completed (loss: 0.19517426192760468, acc: 0.9553072452545166)
[2024-12-17 02:58:04,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:04,590][root][INFO] - Training Epoch: 2/2, step 5560/7134 completed (loss: 0.22359932959079742, acc: 0.9555555582046509)
[2024-12-17 02:58:04,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:04,866][root][INFO] - Training Epoch: 2/2, step 5561/7134 completed (loss: 0.17660507559776306, acc: 0.9754098653793335)
[2024-12-17 02:58:05,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:05,165][root][INFO] - Training Epoch: 2/2, step 5562/7134 completed (loss: 0.21583271026611328, acc: 0.9568345546722412)
[2024-12-17 02:58:05,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:05,496][root][INFO] - Training Epoch: 2/2, step 5563/7134 completed (loss: 0.06984284520149231, acc: 0.9722222089767456)
[2024-12-17 02:58:05,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:05,774][root][INFO] - Training Epoch: 2/2, step 5564/7134 completed (loss: 0.06752194464206696, acc: 0.9750000238418579)
[2024-12-17 02:58:05,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:06,062][root][INFO] - Training Epoch: 2/2, step 5565/7134 completed (loss: 0.03660169988870621, acc: 0.9866666793823242)
[2024-12-17 02:58:06,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:06,345][root][INFO] - Training Epoch: 2/2, step 5566/7134 completed (loss: 0.06596978008747101, acc: 0.9847715497016907)
[2024-12-17 02:58:06,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:06,645][root][INFO] - Training Epoch: 2/2, step 5567/7134 completed (loss: 0.0460556261241436, acc: 0.9900497794151306)
[2024-12-17 02:58:06,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:06,943][root][INFO] - Training Epoch: 2/2, step 5568/7134 completed (loss: 0.0421316884458065, acc: 0.9945054650306702)
[2024-12-17 02:58:07,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:07,239][root][INFO] - Training Epoch: 2/2, step 5569/7134 completed (loss: 0.029551981016993523, acc: 0.9947916865348816)
[2024-12-17 02:58:07,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:07,530][root][INFO] - Training Epoch: 2/2, step 5570/7134 completed (loss: 0.04547010362148285, acc: 0.9836956262588501)
[2024-12-17 02:58:07,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:07,793][root][INFO] - Training Epoch: 2/2, step 5571/7134 completed (loss: 0.059305306524038315, acc: 0.9873417615890503)
[2024-12-17 02:58:07,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:08,071][root][INFO] - Training Epoch: 2/2, step 5572/7134 completed (loss: 0.08688303828239441, acc: 0.987730085849762)
[2024-12-17 02:58:08,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:08,371][root][INFO] - Training Epoch: 2/2, step 5573/7134 completed (loss: 0.04120165854692459, acc: 0.9934640526771545)
[2024-12-17 02:58:08,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:08,654][root][INFO] - Training Epoch: 2/2, step 5574/7134 completed (loss: 0.0817367285490036, acc: 0.9861111044883728)
[2024-12-17 02:58:08,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:08,952][root][INFO] - Training Epoch: 2/2, step 5575/7134 completed (loss: 0.17631152272224426, acc: 0.9666666388511658)
[2024-12-17 02:58:09,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:09,262][root][INFO] - Training Epoch: 2/2, step 5576/7134 completed (loss: 0.06988886743783951, acc: 0.9821428656578064)
[2024-12-17 02:58:09,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:09,553][root][INFO] - Training Epoch: 2/2, step 5577/7134 completed (loss: 0.31219926476478577, acc: 0.9333333373069763)
[2024-12-17 02:58:09,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:09,843][root][INFO] - Training Epoch: 2/2, step 5578/7134 completed (loss: 0.1256294995546341, acc: 0.9556962251663208)
[2024-12-17 02:58:09,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:10,127][root][INFO] - Training Epoch: 2/2, step 5579/7134 completed (loss: 0.10027596354484558, acc: 0.9693251252174377)
[2024-12-17 02:58:10,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:10,408][root][INFO] - Training Epoch: 2/2, step 5580/7134 completed (loss: 0.06823404878377914, acc: 0.9777777791023254)
[2024-12-17 02:58:10,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:10,696][root][INFO] - Training Epoch: 2/2, step 5581/7134 completed (loss: 0.06482481956481934, acc: 0.9757575988769531)
[2024-12-17 02:58:10,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:10,988][root][INFO] - Training Epoch: 2/2, step 5582/7134 completed (loss: 0.08913309872150421, acc: 0.9613259434700012)
[2024-12-17 02:58:11,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:11,277][root][INFO] - Training Epoch: 2/2, step 5583/7134 completed (loss: 0.06401119381189346, acc: 0.9899497628211975)
[2024-12-17 02:58:11,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:11,560][root][INFO] - Training Epoch: 2/2, step 5584/7134 completed (loss: 0.2036486715078354, acc: 0.9556962251663208)
[2024-12-17 02:58:11,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:11,860][root][INFO] - Training Epoch: 2/2, step 5585/7134 completed (loss: 0.1626642793416977, acc: 0.9658536314964294)
[2024-12-17 02:58:11,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:12,132][root][INFO] - Training Epoch: 2/2, step 5586/7134 completed (loss: 0.08534698933362961, acc: 0.9863945841789246)
[2024-12-17 02:58:12,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:12,415][root][INFO] - Training Epoch: 2/2, step 5587/7134 completed (loss: 0.11451989412307739, acc: 0.9657142758369446)
[2024-12-17 02:58:12,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:12,701][root][INFO] - Training Epoch: 2/2, step 5588/7134 completed (loss: 0.06645030528306961, acc: 0.9753086566925049)
[2024-12-17 02:58:12,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:12,985][root][INFO] - Training Epoch: 2/2, step 5589/7134 completed (loss: 0.13021895289421082, acc: 0.9689440727233887)
[2024-12-17 02:58:13,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:13,283][root][INFO] - Training Epoch: 2/2, step 5590/7134 completed (loss: 0.17397187650203705, acc: 0.9479768872261047)
[2024-12-17 02:58:13,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:13,563][root][INFO] - Training Epoch: 2/2, step 5591/7134 completed (loss: 0.053530845791101456, acc: 0.9884393215179443)
[2024-12-17 02:58:13,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:13,832][root][INFO] - Training Epoch: 2/2, step 5592/7134 completed (loss: 0.07894104719161987, acc: 0.9825581312179565)
[2024-12-17 02:58:13,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:14,123][root][INFO] - Training Epoch: 2/2, step 5593/7134 completed (loss: 0.09541598707437515, acc: 0.9836956262588501)
[2024-12-17 02:58:14,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:14,406][root][INFO] - Training Epoch: 2/2, step 5594/7134 completed (loss: 0.07607503235340118, acc: 0.9829545617103577)
[2024-12-17 02:58:14,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:14,690][root][INFO] - Training Epoch: 2/2, step 5595/7134 completed (loss: 0.0862603709101677, acc: 0.9886363744735718)
[2024-12-17 02:58:14,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:14,962][root][INFO] - Training Epoch: 2/2, step 5596/7134 completed (loss: 0.05851760506629944, acc: 0.9820359349250793)
[2024-12-17 02:58:15,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:15,251][root][INFO] - Training Epoch: 2/2, step 5597/7134 completed (loss: 0.1171618402004242, acc: 0.9759036302566528)
[2024-12-17 02:58:15,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:15,552][root][INFO] - Training Epoch: 2/2, step 5598/7134 completed (loss: 0.12288869917392731, acc: 0.9710982441902161)
[2024-12-17 02:58:15,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:15,841][root][INFO] - Training Epoch: 2/2, step 5599/7134 completed (loss: 0.1504329890012741, acc: 0.9659863710403442)
[2024-12-17 02:58:15,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:16,129][root][INFO] - Training Epoch: 2/2, step 5600/7134 completed (loss: 0.09901098161935806, acc: 0.9857142567634583)
[2024-12-17 02:58:16,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:16,393][root][INFO] - Training Epoch: 2/2, step 5601/7134 completed (loss: 0.08101063221693039, acc: 0.9847328066825867)
[2024-12-17 02:58:16,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:16,675][root][INFO] - Training Epoch: 2/2, step 5602/7134 completed (loss: 0.1237381175160408, acc: 0.9788732528686523)
[2024-12-17 02:58:16,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:16,924][root][INFO] - Training Epoch: 2/2, step 5603/7134 completed (loss: 0.15370790660381317, acc: 0.9754098653793335)
[2024-12-17 02:58:17,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:17,193][root][INFO] - Training Epoch: 2/2, step 5604/7134 completed (loss: 0.1680285930633545, acc: 0.9430894255638123)
[2024-12-17 02:58:17,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:17,469][root][INFO] - Training Epoch: 2/2, step 5605/7134 completed (loss: 0.14631807804107666, acc: 0.960629940032959)
[2024-12-17 02:58:17,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:17,738][root][INFO] - Training Epoch: 2/2, step 5606/7134 completed (loss: 0.12475290894508362, acc: 0.9626168012619019)
[2024-12-17 02:58:17,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:18,006][root][INFO] - Training Epoch: 2/2, step 5607/7134 completed (loss: 0.07735556364059448, acc: 0.9784172773361206)
[2024-12-17 02:58:18,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:18,296][root][INFO] - Training Epoch: 2/2, step 5608/7134 completed (loss: 0.12420502305030823, acc: 0.9689922332763672)
[2024-12-17 02:58:18,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:18,601][root][INFO] - Training Epoch: 2/2, step 5609/7134 completed (loss: 0.15230785310268402, acc: 0.9583333134651184)
[2024-12-17 02:58:18,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:18,859][root][INFO] - Training Epoch: 2/2, step 5610/7134 completed (loss: 0.05224895477294922, acc: 0.9818181991577148)
[2024-12-17 02:58:18,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:19,154][root][INFO] - Training Epoch: 2/2, step 5611/7134 completed (loss: 0.12246420979499817, acc: 0.9626865386962891)
[2024-12-17 02:58:19,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:19,442][root][INFO] - Training Epoch: 2/2, step 5612/7134 completed (loss: 0.1241682767868042, acc: 0.9718309640884399)
[2024-12-17 02:58:19,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:19,712][root][INFO] - Training Epoch: 2/2, step 5613/7134 completed (loss: 0.13036121428012848, acc: 0.9642857313156128)
[2024-12-17 02:58:19,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:19,976][root][INFO] - Training Epoch: 2/2, step 5614/7134 completed (loss: 0.22862350940704346, acc: 0.9530201554298401)
[2024-12-17 02:58:20,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:20,250][root][INFO] - Training Epoch: 2/2, step 5615/7134 completed (loss: 0.08393605798482895, acc: 0.9714285731315613)
[2024-12-17 02:58:20,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:20,517][root][INFO] - Training Epoch: 2/2, step 5616/7134 completed (loss: 0.07521935552358627, acc: 0.9851852059364319)
[2024-12-17 02:58:20,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:20,781][root][INFO] - Training Epoch: 2/2, step 5617/7134 completed (loss: 0.07379473745822906, acc: 0.9767441749572754)
[2024-12-17 02:58:20,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:21,071][root][INFO] - Training Epoch: 2/2, step 5618/7134 completed (loss: 0.08200914412736893, acc: 0.9558823704719543)
[2024-12-17 02:58:21,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:21,340][root][INFO] - Training Epoch: 2/2, step 5619/7134 completed (loss: 0.20299196243286133, acc: 0.924369752407074)
[2024-12-17 02:58:21,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:21,623][root][INFO] - Training Epoch: 2/2, step 5620/7134 completed (loss: 0.1409967839717865, acc: 0.9739130139350891)
[2024-12-17 02:58:21,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:21,915][root][INFO] - Training Epoch: 2/2, step 5621/7134 completed (loss: 0.07070188224315643, acc: 0.9741935729980469)
[2024-12-17 02:58:22,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:22,208][root][INFO] - Training Epoch: 2/2, step 5622/7134 completed (loss: 0.1127946525812149, acc: 0.9679144620895386)
[2024-12-17 02:58:22,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:22,476][root][INFO] - Training Epoch: 2/2, step 5623/7134 completed (loss: 0.19596725702285767, acc: 0.9305555820465088)
[2024-12-17 02:58:22,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:22,756][root][INFO] - Training Epoch: 2/2, step 5624/7134 completed (loss: 0.12089058756828308, acc: 0.9738562107086182)
[2024-12-17 02:58:22,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:23,007][root][INFO] - Training Epoch: 2/2, step 5625/7134 completed (loss: 0.10908018052577972, acc: 0.9803921580314636)
[2024-12-17 02:58:23,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:23,289][root][INFO] - Training Epoch: 2/2, step 5626/7134 completed (loss: 0.06467393785715103, acc: 0.9793103337287903)
[2024-12-17 02:58:23,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:23,561][root][INFO] - Training Epoch: 2/2, step 5627/7134 completed (loss: 0.2812367379665375, acc: 0.925000011920929)
[2024-12-17 02:58:23,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:23,854][root][INFO] - Training Epoch: 2/2, step 5628/7134 completed (loss: 0.0682048425078392, acc: 1.0)
[2024-12-17 02:58:23,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:24,142][root][INFO] - Training Epoch: 2/2, step 5629/7134 completed (loss: 0.13217607140541077, acc: 0.9590163826942444)
[2024-12-17 02:58:24,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:24,424][root][INFO] - Training Epoch: 2/2, step 5630/7134 completed (loss: 0.08058924973011017, acc: 0.9803921580314636)
[2024-12-17 02:58:24,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:24,697][root][INFO] - Training Epoch: 2/2, step 5631/7134 completed (loss: 0.08597123622894287, acc: 0.9674796462059021)
[2024-12-17 02:58:24,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:24,992][root][INFO] - Training Epoch: 2/2, step 5632/7134 completed (loss: 0.16113391518592834, acc: 0.9615384340286255)
[2024-12-17 02:58:25,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:25,257][root][INFO] - Training Epoch: 2/2, step 5633/7134 completed (loss: 0.058782000094652176, acc: 1.0)
[2024-12-17 02:58:25,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:25,537][root][INFO] - Training Epoch: 2/2, step 5634/7134 completed (loss: 0.1034797877073288, acc: 0.9646017551422119)
[2024-12-17 02:58:25,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:25,823][root][INFO] - Training Epoch: 2/2, step 5635/7134 completed (loss: 0.09611304104328156, acc: 0.9765625)
[2024-12-17 02:58:25,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:26,116][root][INFO] - Training Epoch: 2/2, step 5636/7134 completed (loss: 0.10739178955554962, acc: 0.9615384340286255)
[2024-12-17 02:58:26,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:26,399][root][INFO] - Training Epoch: 2/2, step 5637/7134 completed (loss: 0.09973286837339401, acc: 0.9772727489471436)
[2024-12-17 02:58:26,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:26,694][root][INFO] - Training Epoch: 2/2, step 5638/7134 completed (loss: 0.05992016941308975, acc: 0.9912280440330505)
[2024-12-17 02:58:26,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:26,983][root][INFO] - Training Epoch: 2/2, step 5639/7134 completed (loss: 0.1144874095916748, acc: 0.9805194735527039)
[2024-12-17 02:58:27,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:27,255][root][INFO] - Training Epoch: 2/2, step 5640/7134 completed (loss: 0.1268002986907959, acc: 0.957446813583374)
[2024-12-17 02:58:27,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:27,521][root][INFO] - Training Epoch: 2/2, step 5641/7134 completed (loss: 0.14926236867904663, acc: 0.966292142868042)
[2024-12-17 02:58:27,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:27,785][root][INFO] - Training Epoch: 2/2, step 5642/7134 completed (loss: 0.2219044417142868, acc: 0.9650349617004395)
[2024-12-17 02:58:27,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:28,062][root][INFO] - Training Epoch: 2/2, step 5643/7134 completed (loss: 0.17737384140491486, acc: 0.9684210419654846)
[2024-12-17 02:58:28,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:28,362][root][INFO] - Training Epoch: 2/2, step 5644/7134 completed (loss: 0.1448121964931488, acc: 0.961904764175415)
[2024-12-17 02:58:28,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:28,640][root][INFO] - Training Epoch: 2/2, step 5645/7134 completed (loss: 0.06628760695457458, acc: 0.9861111044883728)
[2024-12-17 02:58:28,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:28,915][root][INFO] - Training Epoch: 2/2, step 5646/7134 completed (loss: 0.07467451691627502, acc: 0.9857142567634583)
[2024-12-17 02:58:29,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:29,200][root][INFO] - Training Epoch: 2/2, step 5647/7134 completed (loss: 0.18002301454544067, acc: 0.9444444179534912)
[2024-12-17 02:58:29,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:29,481][root][INFO] - Training Epoch: 2/2, step 5648/7134 completed (loss: 0.2558000981807709, acc: 0.9266666769981384)
[2024-12-17 02:58:29,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:29,753][root][INFO] - Training Epoch: 2/2, step 5649/7134 completed (loss: 0.20789368450641632, acc: 0.9189189076423645)
[2024-12-17 02:58:29,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:30,035][root][INFO] - Training Epoch: 2/2, step 5650/7134 completed (loss: 0.12865093350410461, acc: 0.9435483813285828)
[2024-12-17 02:58:30,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:30,319][root][INFO] - Training Epoch: 2/2, step 5651/7134 completed (loss: 0.08693572133779526, acc: 0.9795918464660645)
[2024-12-17 02:58:30,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:30,609][root][INFO] - Training Epoch: 2/2, step 5652/7134 completed (loss: 0.17471693456172943, acc: 0.9568345546722412)
[2024-12-17 02:58:30,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:30,883][root][INFO] - Training Epoch: 2/2, step 5653/7134 completed (loss: 0.14664030075073242, acc: 0.9610389471054077)
[2024-12-17 02:58:31,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:31,176][root][INFO] - Training Epoch: 2/2, step 5654/7134 completed (loss: 0.10339191555976868, acc: 0.96875)
[2024-12-17 02:58:31,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:31,459][root][INFO] - Training Epoch: 2/2, step 5655/7134 completed (loss: 0.08821889758110046, acc: 0.9813084006309509)
[2024-12-17 02:58:31,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:31,761][root][INFO] - Training Epoch: 2/2, step 5656/7134 completed (loss: 0.10854993760585785, acc: 0.9672130942344666)
[2024-12-17 02:58:31,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:32,038][root][INFO] - Training Epoch: 2/2, step 5657/7134 completed (loss: 0.19511494040489197, acc: 0.940397322177887)
[2024-12-17 02:58:32,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:32,326][root][INFO] - Training Epoch: 2/2, step 5658/7134 completed (loss: 0.12033888697624207, acc: 0.9738562107086182)
[2024-12-17 02:58:32,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:32,591][root][INFO] - Training Epoch: 2/2, step 5659/7134 completed (loss: 0.11465685814619064, acc: 0.9642857313156128)
[2024-12-17 02:58:32,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:32,856][root][INFO] - Training Epoch: 2/2, step 5660/7134 completed (loss: 0.06481979787349701, acc: 0.9921875)
[2024-12-17 02:58:32,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:33,138][root][INFO] - Training Epoch: 2/2, step 5661/7134 completed (loss: 0.07937370240688324, acc: 0.9831932783126831)
[2024-12-17 02:58:33,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:33,424][root][INFO] - Training Epoch: 2/2, step 5662/7134 completed (loss: 0.12944269180297852, acc: 0.971222996711731)
[2024-12-17 02:58:33,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:33,687][root][INFO] - Training Epoch: 2/2, step 5663/7134 completed (loss: 0.03548368439078331, acc: 1.0)
[2024-12-17 02:58:33,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:33,960][root][INFO] - Training Epoch: 2/2, step 5664/7134 completed (loss: 0.20524157583713531, acc: 0.9520547986030579)
[2024-12-17 02:58:34,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:34,227][root][INFO] - Training Epoch: 2/2, step 5665/7134 completed (loss: 0.07761744409799576, acc: 0.9931972622871399)
[2024-12-17 02:58:34,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:34,504][root][INFO] - Training Epoch: 2/2, step 5666/7134 completed (loss: 0.08355455100536346, acc: 0.9869281053543091)
[2024-12-17 02:58:34,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:34,755][root][INFO] - Training Epoch: 2/2, step 5667/7134 completed (loss: 0.1363670825958252, acc: 0.9756097793579102)
[2024-12-17 02:58:34,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:35,015][root][INFO] - Training Epoch: 2/2, step 5668/7134 completed (loss: 0.18170155584812164, acc: 0.9629629850387573)
[2024-12-17 02:58:35,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:35,292][root][INFO] - Training Epoch: 2/2, step 5669/7134 completed (loss: 0.16392676532268524, acc: 0.9363057613372803)
[2024-12-17 02:58:35,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:35,562][root][INFO] - Training Epoch: 2/2, step 5670/7134 completed (loss: 0.05397840589284897, acc: 0.976190447807312)
[2024-12-17 02:58:35,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:35,854][root][INFO] - Training Epoch: 2/2, step 5671/7134 completed (loss: 0.09574950486421585, acc: 0.966292142868042)
[2024-12-17 02:58:36,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:36,146][root][INFO] - Training Epoch: 2/2, step 5672/7134 completed (loss: 0.09316049516201019, acc: 0.9851852059364319)
[2024-12-17 02:58:36,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:36,401][root][INFO] - Training Epoch: 2/2, step 5673/7134 completed (loss: 0.06155533343553543, acc: 0.9931507110595703)
[2024-12-17 02:58:36,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:36,684][root][INFO] - Training Epoch: 2/2, step 5674/7134 completed (loss: 0.16425268352031708, acc: 0.9591836929321289)
[2024-12-17 02:58:36,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:36,959][root][INFO] - Training Epoch: 2/2, step 5675/7134 completed (loss: 0.20473307371139526, acc: 0.95333331823349)
[2024-12-17 02:58:37,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:37,242][root][INFO] - Training Epoch: 2/2, step 5676/7134 completed (loss: 0.20894525945186615, acc: 0.954023003578186)
[2024-12-17 02:58:37,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:37,525][root][INFO] - Training Epoch: 2/2, step 5677/7134 completed (loss: 0.2986227869987488, acc: 0.9285714030265808)
[2024-12-17 02:58:37,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:37,809][root][INFO] - Training Epoch: 2/2, step 5678/7134 completed (loss: 0.11634262651205063, acc: 0.9691358208656311)
[2024-12-17 02:58:37,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:38,103][root][INFO] - Training Epoch: 2/2, step 5679/7134 completed (loss: 0.29625144600868225, acc: 0.9367088675498962)
[2024-12-17 02:58:38,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:38,397][root][INFO] - Training Epoch: 2/2, step 5680/7134 completed (loss: 0.4438001811504364, acc: 0.9021739363670349)
[2024-12-17 02:58:38,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:38,682][root][INFO] - Training Epoch: 2/2, step 5681/7134 completed (loss: 0.3123883008956909, acc: 0.9212121367454529)
[2024-12-17 02:58:38,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:38,968][root][INFO] - Training Epoch: 2/2, step 5682/7134 completed (loss: 0.17421476542949677, acc: 0.9638554453849792)
[2024-12-17 02:58:39,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:39,258][root][INFO] - Training Epoch: 2/2, step 5683/7134 completed (loss: 0.2515246868133545, acc: 0.9444444179534912)
[2024-12-17 02:58:39,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:39,554][root][INFO] - Training Epoch: 2/2, step 5684/7134 completed (loss: 0.3467911183834076, acc: 0.9146341681480408)
[2024-12-17 02:58:39,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:39,823][root][INFO] - Training Epoch: 2/2, step 5685/7134 completed (loss: 0.284614235162735, acc: 0.9370078444480896)
[2024-12-17 02:58:39,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:40,107][root][INFO] - Training Epoch: 2/2, step 5686/7134 completed (loss: 0.22218535840511322, acc: 0.9136690497398376)
[2024-12-17 02:58:40,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:40,372][root][INFO] - Training Epoch: 2/2, step 5687/7134 completed (loss: 0.28669464588165283, acc: 0.9545454382896423)
[2024-12-17 02:58:40,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:40,676][root][INFO] - Training Epoch: 2/2, step 5688/7134 completed (loss: 0.29166898131370544, acc: 0.9444444179534912)
[2024-12-17 02:58:40,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:40,955][root][INFO] - Training Epoch: 2/2, step 5689/7134 completed (loss: 0.21310727298259735, acc: 0.957317054271698)
[2024-12-17 02:58:41,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:41,247][root][INFO] - Training Epoch: 2/2, step 5690/7134 completed (loss: 0.09539059549570084, acc: 0.9845361113548279)
[2024-12-17 02:58:41,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:41,508][root][INFO] - Training Epoch: 2/2, step 5691/7134 completed (loss: 0.21734677255153656, acc: 0.9398906826972961)
[2024-12-17 02:58:41,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:41,807][root][INFO] - Training Epoch: 2/2, step 5692/7134 completed (loss: 0.15778644382953644, acc: 0.9657142758369446)
[2024-12-17 02:58:41,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:42,088][root][INFO] - Training Epoch: 2/2, step 5693/7134 completed (loss: 0.04646502435207367, acc: 0.9874213933944702)
[2024-12-17 02:58:42,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:42,344][root][INFO] - Training Epoch: 2/2, step 5694/7134 completed (loss: 0.07305087894201279, acc: 0.9941860437393188)
[2024-12-17 02:58:42,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:42,624][root][INFO] - Training Epoch: 2/2, step 5695/7134 completed (loss: 0.17808736860752106, acc: 0.9447852969169617)
[2024-12-17 02:58:42,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:42,902][root][INFO] - Training Epoch: 2/2, step 5696/7134 completed (loss: 0.10529739409685135, acc: 0.9900990128517151)
[2024-12-17 02:58:43,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:43,185][root][INFO] - Training Epoch: 2/2, step 5697/7134 completed (loss: 0.1765143722295761, acc: 0.9636363387107849)
[2024-12-17 02:58:43,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:43,459][root][INFO] - Training Epoch: 2/2, step 5698/7134 completed (loss: 0.11125943064689636, acc: 0.9659090638160706)
[2024-12-17 02:58:43,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:43,750][root][INFO] - Training Epoch: 2/2, step 5699/7134 completed (loss: 0.30481186509132385, acc: 0.931034505367279)
[2024-12-17 02:58:43,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:44,030][root][INFO] - Training Epoch: 2/2, step 5700/7134 completed (loss: 0.09726602584123611, acc: 0.9745222926139832)
[2024-12-17 02:58:44,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:44,331][root][INFO] - Training Epoch: 2/2, step 5701/7134 completed (loss: 0.149812713265419, acc: 0.9729729890823364)
[2024-12-17 02:58:44,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:44,605][root][INFO] - Training Epoch: 2/2, step 5702/7134 completed (loss: 0.09196476638317108, acc: 0.9709302186965942)
[2024-12-17 02:58:44,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:44,869][root][INFO] - Training Epoch: 2/2, step 5703/7134 completed (loss: 0.06651484966278076, acc: 0.9811320900917053)
[2024-12-17 02:58:44,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:45,130][root][INFO] - Training Epoch: 2/2, step 5704/7134 completed (loss: 0.13461807370185852, acc: 0.9647058844566345)
[2024-12-17 02:58:45,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:45,348][root][INFO] - Training Epoch: 2/2, step 5705/7134 completed (loss: 0.040390972048044205, acc: 1.0)
[2024-12-17 02:58:45,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:45,674][root][INFO] - Training Epoch: 2/2, step 5706/7134 completed (loss: 0.08913318067789078, acc: 0.9851484894752502)
[2024-12-17 02:58:45,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:45,943][root][INFO] - Training Epoch: 2/2, step 5707/7134 completed (loss: 0.1307133287191391, acc: 0.9760000109672546)
[2024-12-17 02:58:46,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:46,210][root][INFO] - Training Epoch: 2/2, step 5708/7134 completed (loss: 0.03713500499725342, acc: 0.9935897588729858)
[2024-12-17 02:58:46,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:46,483][root][INFO] - Training Epoch: 2/2, step 5709/7134 completed (loss: 0.19938825070858002, acc: 0.9751552939414978)
[2024-12-17 02:58:46,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:46,764][root][INFO] - Training Epoch: 2/2, step 5710/7134 completed (loss: 0.12973183393478394, acc: 0.9599999785423279)
[2024-12-17 02:58:46,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:47,036][root][INFO] - Training Epoch: 2/2, step 5711/7134 completed (loss: 0.21909981966018677, acc: 0.9408602118492126)
[2024-12-17 02:58:47,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:47,306][root][INFO] - Training Epoch: 2/2, step 5712/7134 completed (loss: 0.06003394350409508, acc: 0.975806474685669)
[2024-12-17 02:58:47,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:47,596][root][INFO] - Training Epoch: 2/2, step 5713/7134 completed (loss: 0.13222548365592957, acc: 0.9775280952453613)
[2024-12-17 02:58:47,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:47,887][root][INFO] - Training Epoch: 2/2, step 5714/7134 completed (loss: 0.08504097908735275, acc: 0.989130437374115)
[2024-12-17 02:58:48,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:48,153][root][INFO] - Training Epoch: 2/2, step 5715/7134 completed (loss: 0.25741347670555115, acc: 0.9632353186607361)
[2024-12-17 02:58:48,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:48,422][root][INFO] - Training Epoch: 2/2, step 5716/7134 completed (loss: 0.16962474584579468, acc: 0.9513888955116272)
[2024-12-17 02:58:48,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:48,684][root][INFO] - Training Epoch: 2/2, step 5717/7134 completed (loss: 0.2692866325378418, acc: 0.9356725215911865)
[2024-12-17 02:58:48,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:48,945][root][INFO] - Training Epoch: 2/2, step 5718/7134 completed (loss: 0.11790955811738968, acc: 0.9539473652839661)
[2024-12-17 02:58:49,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:49,212][root][INFO] - Training Epoch: 2/2, step 5719/7134 completed (loss: 0.1170814037322998, acc: 0.9588235020637512)
[2024-12-17 02:58:49,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:49,493][root][INFO] - Training Epoch: 2/2, step 5720/7134 completed (loss: 0.23164288699626923, acc: 0.9551281929016113)
[2024-12-17 02:58:49,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:49,776][root][INFO] - Training Epoch: 2/2, step 5721/7134 completed (loss: 0.1837037205696106, acc: 0.9326424598693848)
[2024-12-17 02:58:49,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:50,019][root][INFO] - Training Epoch: 2/2, step 5722/7134 completed (loss: 0.06870586425065994, acc: 0.9727272987365723)
[2024-12-17 02:58:50,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:50,289][root][INFO] - Training Epoch: 2/2, step 5723/7134 completed (loss: 0.1737179011106491, acc: 0.9629629850387573)
[2024-12-17 02:58:50,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:50,548][root][INFO] - Training Epoch: 2/2, step 5724/7134 completed (loss: 0.20247432589530945, acc: 0.9575757384300232)
[2024-12-17 02:58:50,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:50,861][root][INFO] - Training Epoch: 2/2, step 5725/7134 completed (loss: 0.14367961883544922, acc: 0.9657142758369446)
[2024-12-17 02:58:50,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:51,150][root][INFO] - Training Epoch: 2/2, step 5726/7134 completed (loss: 0.28716379404067993, acc: 0.940119743347168)
[2024-12-17 02:58:51,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:51,441][root][INFO] - Training Epoch: 2/2, step 5727/7134 completed (loss: 0.04592510312795639, acc: 1.0)
[2024-12-17 02:58:51,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:51,726][root][INFO] - Training Epoch: 2/2, step 5728/7134 completed (loss: 0.03560376167297363, acc: 0.9926470518112183)
[2024-12-17 02:58:51,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:52,019][root][INFO] - Training Epoch: 2/2, step 5729/7134 completed (loss: 0.05438214913010597, acc: 0.9805194735527039)
[2024-12-17 02:58:52,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:52,290][root][INFO] - Training Epoch: 2/2, step 5730/7134 completed (loss: 0.1339334398508072, acc: 0.9481481313705444)
[2024-12-17 02:58:52,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:52,592][root][INFO] - Training Epoch: 2/2, step 5731/7134 completed (loss: 0.13416460156440735, acc: 0.9624999761581421)
[2024-12-17 02:58:52,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:52,866][root][INFO] - Training Epoch: 2/2, step 5732/7134 completed (loss: 0.6537006497383118, acc: 0.8433734774589539)
[2024-12-17 02:58:52,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:53,151][root][INFO] - Training Epoch: 2/2, step 5733/7134 completed (loss: 0.20100045204162598, acc: 0.9430379867553711)
[2024-12-17 02:58:53,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:53,427][root][INFO] - Training Epoch: 2/2, step 5734/7134 completed (loss: 0.283951073884964, acc: 0.9166666865348816)
[2024-12-17 02:58:53,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:53,699][root][INFO] - Training Epoch: 2/2, step 5735/7134 completed (loss: 0.23177239298820496, acc: 0.9536423683166504)
[2024-12-17 02:58:53,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:53,994][root][INFO] - Training Epoch: 2/2, step 5736/7134 completed (loss: 0.4267179071903229, acc: 0.9171270728111267)
[2024-12-17 02:58:54,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:54,269][root][INFO] - Training Epoch: 2/2, step 5737/7134 completed (loss: 0.1146344542503357, acc: 0.9766082167625427)
[2024-12-17 02:58:54,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:54,549][root][INFO] - Training Epoch: 2/2, step 5738/7134 completed (loss: 0.185628741979599, acc: 0.9646464586257935)
[2024-12-17 02:58:54,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:54,830][root][INFO] - Training Epoch: 2/2, step 5739/7134 completed (loss: 0.19202706217765808, acc: 0.949999988079071)
[2024-12-17 02:58:54,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:55,100][root][INFO] - Training Epoch: 2/2, step 5740/7134 completed (loss: 0.1347551792860031, acc: 0.96875)
[2024-12-17 02:58:55,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:55,376][root][INFO] - Training Epoch: 2/2, step 5741/7134 completed (loss: 0.12845280766487122, acc: 0.9545454382896423)
[2024-12-17 02:58:55,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:55,645][root][INFO] - Training Epoch: 2/2, step 5742/7134 completed (loss: 0.07423465698957443, acc: 0.9775280952453613)
[2024-12-17 02:58:55,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:55,932][root][INFO] - Training Epoch: 2/2, step 5743/7134 completed (loss: 0.10922329872846603, acc: 0.9791666865348816)
[2024-12-17 02:58:56,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:56,175][root][INFO] - Training Epoch: 2/2, step 5744/7134 completed (loss: 0.07817904651165009, acc: 0.9646017551422119)
[2024-12-17 02:58:56,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:56,462][root][INFO] - Training Epoch: 2/2, step 5745/7134 completed (loss: 0.1965625137090683, acc: 0.9606741666793823)
[2024-12-17 02:58:56,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:56,718][root][INFO] - Training Epoch: 2/2, step 5746/7134 completed (loss: 0.10645250976085663, acc: 0.9753086566925049)
[2024-12-17 02:58:56,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:56,993][root][INFO] - Training Epoch: 2/2, step 5747/7134 completed (loss: 0.22367268800735474, acc: 0.9454545378684998)
[2024-12-17 02:58:57,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:57,275][root][INFO] - Training Epoch: 2/2, step 5748/7134 completed (loss: 0.04239180311560631, acc: 0.9921259880065918)
[2024-12-17 02:58:57,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:57,558][root][INFO] - Training Epoch: 2/2, step 5749/7134 completed (loss: 0.1829739362001419, acc: 0.9644970297813416)
[2024-12-17 02:58:57,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:57,838][root][INFO] - Training Epoch: 2/2, step 5750/7134 completed (loss: 0.16929417848587036, acc: 0.9385474920272827)
[2024-12-17 02:58:57,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:58,114][root][INFO] - Training Epoch: 2/2, step 5751/7134 completed (loss: 0.18004073202610016, acc: 0.9668874144554138)
[2024-12-17 02:58:58,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:58,399][root][INFO] - Training Epoch: 2/2, step 5752/7134 completed (loss: 0.5735783576965332, acc: 0.8702290058135986)
[2024-12-17 02:58:58,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:58,663][root][INFO] - Training Epoch: 2/2, step 5753/7134 completed (loss: 0.18408973515033722, acc: 0.9664429426193237)
[2024-12-17 02:58:58,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:58,958][root][INFO] - Training Epoch: 2/2, step 5754/7134 completed (loss: 0.2389260232448578, acc: 0.959770143032074)
[2024-12-17 02:58:59,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:59,236][root][INFO] - Training Epoch: 2/2, step 5755/7134 completed (loss: 0.2345542162656784, acc: 0.948051929473877)
[2024-12-17 02:58:59,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:59,505][root][INFO] - Training Epoch: 2/2, step 5756/7134 completed (loss: 0.2628205716609955, acc: 0.9244186282157898)
[2024-12-17 02:58:59,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:59,807][root][INFO] - Training Epoch: 2/2, step 5757/7134 completed (loss: 0.2396453469991684, acc: 0.9438202381134033)
[2024-12-17 02:58:59,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:00,080][root][INFO] - Training Epoch: 2/2, step 5758/7134 completed (loss: 0.29441148042678833, acc: 0.9259259104728699)
[2024-12-17 02:59:00,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:00,375][root][INFO] - Training Epoch: 2/2, step 5759/7134 completed (loss: 0.5768519043922424, acc: 0.893203854560852)
[2024-12-17 02:59:00,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:00,682][root][INFO] - Training Epoch: 2/2, step 5760/7134 completed (loss: 0.20700198411941528, acc: 0.9545454382896423)
[2024-12-17 02:59:00,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:01,004][root][INFO] - Training Epoch: 2/2, step 5761/7134 completed (loss: 0.12779855728149414, acc: 0.9599999785423279)
[2024-12-17 02:59:01,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:01,295][root][INFO] - Training Epoch: 2/2, step 5762/7134 completed (loss: 0.1512460857629776, acc: 0.9689922332763672)
[2024-12-17 02:59:01,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:01,573][root][INFO] - Training Epoch: 2/2, step 5763/7134 completed (loss: 0.12684069573879242, acc: 0.9672130942344666)
[2024-12-17 02:59:01,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:01,846][root][INFO] - Training Epoch: 2/2, step 5764/7134 completed (loss: 0.07014010846614838, acc: 0.9923664331436157)
[2024-12-17 02:59:01,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:02,123][root][INFO] - Training Epoch: 2/2, step 5765/7134 completed (loss: 0.21392232179641724, acc: 0.9496855139732361)
[2024-12-17 02:59:02,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:02,414][root][INFO] - Training Epoch: 2/2, step 5766/7134 completed (loss: 0.08315975964069366, acc: 0.9935483932495117)
[2024-12-17 02:59:02,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:02,731][root][INFO] - Training Epoch: 2/2, step 5767/7134 completed (loss: 0.06813836842775345, acc: 0.9875776171684265)
[2024-12-17 02:59:02,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:03,032][root][INFO] - Training Epoch: 2/2, step 5768/7134 completed (loss: 0.07695607841014862, acc: 0.9750000238418579)
[2024-12-17 02:59:03,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:03,324][root][INFO] - Training Epoch: 2/2, step 5769/7134 completed (loss: 0.04126584157347679, acc: 0.9928571581840515)
[2024-12-17 02:59:03,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:03,614][root][INFO] - Training Epoch: 2/2, step 5770/7134 completed (loss: 0.052983175963163376, acc: 0.9891892075538635)
[2024-12-17 02:59:03,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:03,901][root][INFO] - Training Epoch: 2/2, step 5771/7134 completed (loss: 0.19977815449237823, acc: 0.9631901979446411)
[2024-12-17 02:59:04,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:04,181][root][INFO] - Training Epoch: 2/2, step 5772/7134 completed (loss: 0.050955746322870255, acc: 0.9916666746139526)
[2024-12-17 02:59:04,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:04,471][root][INFO] - Training Epoch: 2/2, step 5773/7134 completed (loss: 0.11577660590410233, acc: 0.9774436354637146)
[2024-12-17 02:59:04,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:04,779][root][INFO] - Training Epoch: 2/2, step 5774/7134 completed (loss: 0.08973175287246704, acc: 0.9691358208656311)
[2024-12-17 02:59:04,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:05,043][root][INFO] - Training Epoch: 2/2, step 5775/7134 completed (loss: 0.09943639487028122, acc: 0.9800000190734863)
[2024-12-17 02:59:05,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:05,321][root][INFO] - Training Epoch: 2/2, step 5776/7134 completed (loss: 0.1780964583158493, acc: 0.9438202381134033)
[2024-12-17 02:59:05,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:05,611][root][INFO] - Training Epoch: 2/2, step 5777/7134 completed (loss: 0.1753236949443817, acc: 0.9579439163208008)
[2024-12-17 02:59:05,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:05,899][root][INFO] - Training Epoch: 2/2, step 5778/7134 completed (loss: 0.3066694438457489, acc: 0.9207317233085632)
[2024-12-17 02:59:06,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:06,200][root][INFO] - Training Epoch: 2/2, step 5779/7134 completed (loss: 0.22892025113105774, acc: 0.9529411792755127)
[2024-12-17 02:59:06,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:06,493][root][INFO] - Training Epoch: 2/2, step 5780/7134 completed (loss: 0.13015016913414001, acc: 0.9601989984512329)
[2024-12-17 02:59:06,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:06,769][root][INFO] - Training Epoch: 2/2, step 5781/7134 completed (loss: 0.24168160557746887, acc: 0.9364162087440491)
[2024-12-17 02:59:06,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:07,048][root][INFO] - Training Epoch: 2/2, step 5782/7134 completed (loss: 0.10175883769989014, acc: 0.9779005646705627)
[2024-12-17 02:59:07,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:07,327][root][INFO] - Training Epoch: 2/2, step 5783/7134 completed (loss: 0.16612203419208527, acc: 0.9653179049491882)
[2024-12-17 02:59:07,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:07,614][root][INFO] - Training Epoch: 2/2, step 5784/7134 completed (loss: 0.12212789803743362, acc: 0.9604519605636597)
[2024-12-17 02:59:07,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:07,890][root][INFO] - Training Epoch: 2/2, step 5785/7134 completed (loss: 0.22110792994499207, acc: 0.9459459185600281)
[2024-12-17 02:59:07,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:08,150][root][INFO] - Training Epoch: 2/2, step 5786/7134 completed (loss: 0.07757800817489624, acc: 0.9841269850730896)
[2024-12-17 02:59:08,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:08,426][root][INFO] - Training Epoch: 2/2, step 5787/7134 completed (loss: 0.0897449404001236, acc: 0.9790576100349426)
[2024-12-17 02:59:08,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:08,689][root][INFO] - Training Epoch: 2/2, step 5788/7134 completed (loss: 0.045644331723451614, acc: 0.9868420958518982)
[2024-12-17 02:59:08,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:08,970][root][INFO] - Training Epoch: 2/2, step 5789/7134 completed (loss: 0.12887613475322723, acc: 0.9545454382896423)
[2024-12-17 02:59:09,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:09,259][root][INFO] - Training Epoch: 2/2, step 5790/7134 completed (loss: 0.13298113644123077, acc: 0.9642857313156128)
[2024-12-17 02:59:09,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:09,538][root][INFO] - Training Epoch: 2/2, step 5791/7134 completed (loss: 0.0979277491569519, acc: 0.9776119589805603)
[2024-12-17 02:59:09,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:09,828][root][INFO] - Training Epoch: 2/2, step 5792/7134 completed (loss: 0.4281194806098938, acc: 0.899328887462616)
[2024-12-17 02:59:09,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:10,116][root][INFO] - Training Epoch: 2/2, step 5793/7134 completed (loss: 0.22616291046142578, acc: 0.9386503100395203)
[2024-12-17 02:59:10,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:10,405][root][INFO] - Training Epoch: 2/2, step 5794/7134 completed (loss: 0.41754135489463806, acc: 0.9235668778419495)
[2024-12-17 02:59:10,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:10,698][root][INFO] - Training Epoch: 2/2, step 5795/7134 completed (loss: 0.39668387174606323, acc: 0.8947368264198303)
[2024-12-17 02:59:10,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:10,979][root][INFO] - Training Epoch: 2/2, step 5796/7134 completed (loss: 0.2136753499507904, acc: 0.9541984796524048)
[2024-12-17 02:59:11,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:11,259][root][INFO] - Training Epoch: 2/2, step 5797/7134 completed (loss: 0.22896993160247803, acc: 0.9194630980491638)
[2024-12-17 02:59:11,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:11,532][root][INFO] - Training Epoch: 2/2, step 5798/7134 completed (loss: 0.7458642721176147, acc: 0.8604651093482971)
[2024-12-17 02:59:11,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:11,808][root][INFO] - Training Epoch: 2/2, step 5799/7134 completed (loss: 0.2100433111190796, acc: 0.9448819160461426)
[2024-12-17 02:59:11,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:12,094][root][INFO] - Training Epoch: 2/2, step 5800/7134 completed (loss: 0.35714298486709595, acc: 0.9280575513839722)
[2024-12-17 02:59:12,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:12,371][root][INFO] - Training Epoch: 2/2, step 5801/7134 completed (loss: 0.3171713650226593, acc: 0.9197530746459961)
[2024-12-17 02:59:12,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:12,649][root][INFO] - Training Epoch: 2/2, step 5802/7134 completed (loss: 0.18194033205509186, acc: 0.9632353186607361)
[2024-12-17 02:59:12,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:12,938][root][INFO] - Training Epoch: 2/2, step 5803/7134 completed (loss: 0.07940822094678879, acc: 0.982758641242981)
[2024-12-17 02:59:13,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:13,221][root][INFO] - Training Epoch: 2/2, step 5804/7134 completed (loss: 0.27366045117378235, acc: 0.8980891704559326)
[2024-12-17 02:59:13,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:13,507][root][INFO] - Training Epoch: 2/2, step 5805/7134 completed (loss: 0.19440636038780212, acc: 0.9470198750495911)
[2024-12-17 02:59:13,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:13,793][root][INFO] - Training Epoch: 2/2, step 5806/7134 completed (loss: 0.14368024468421936, acc: 0.9636363387107849)
[2024-12-17 02:59:13,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:14,075][root][INFO] - Training Epoch: 2/2, step 5807/7134 completed (loss: 0.20709004998207092, acc: 0.9647887349128723)
[2024-12-17 02:59:14,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:14,368][root][INFO] - Training Epoch: 2/2, step 5808/7134 completed (loss: 0.08039387315511703, acc: 0.9873417615890503)
[2024-12-17 02:59:14,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:14,630][root][INFO] - Training Epoch: 2/2, step 5809/7134 completed (loss: 0.12072740495204926, acc: 0.9607843160629272)
[2024-12-17 02:59:14,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:14,908][root][INFO] - Training Epoch: 2/2, step 5810/7134 completed (loss: 0.09158216416835785, acc: 0.9834710955619812)
[2024-12-17 02:59:14,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:15,131][root][INFO] - Training Epoch: 2/2, step 5811/7134 completed (loss: 0.07558645308017731, acc: 0.9890109896659851)
[2024-12-17 02:59:15,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:15,391][root][INFO] - Training Epoch: 2/2, step 5812/7134 completed (loss: 0.037877943366765976, acc: 0.9926470518112183)
[2024-12-17 02:59:15,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:15,662][root][INFO] - Training Epoch: 2/2, step 5813/7134 completed (loss: 0.08798642456531525, acc: 0.9918032884597778)
[2024-12-17 02:59:15,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:16,005][root][INFO] - Training Epoch: 2/2, step 5814/7134 completed (loss: 0.06715237349271774, acc: 0.984000027179718)
[2024-12-17 02:59:16,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:16,281][root][INFO] - Training Epoch: 2/2, step 5815/7134 completed (loss: 0.10019431263208389, acc: 0.9655172228813171)
[2024-12-17 02:59:16,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:16,555][root][INFO] - Training Epoch: 2/2, step 5816/7134 completed (loss: 0.0301289614289999, acc: 0.9946523904800415)
[2024-12-17 02:59:16,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:16,833][root][INFO] - Training Epoch: 2/2, step 5817/7134 completed (loss: 0.14405280351638794, acc: 0.9904761910438538)
[2024-12-17 02:59:16,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:17,112][root][INFO] - Training Epoch: 2/2, step 5818/7134 completed (loss: 0.09420523047447205, acc: 0.9607843160629272)
[2024-12-17 02:59:17,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:17,371][root][INFO] - Training Epoch: 2/2, step 5819/7134 completed (loss: 0.05778825283050537, acc: 0.9788732528686523)
[2024-12-17 02:59:17,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:17,663][root][INFO] - Training Epoch: 2/2, step 5820/7134 completed (loss: 0.12607672810554504, acc: 0.9752066135406494)
[2024-12-17 02:59:17,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:17,953][root][INFO] - Training Epoch: 2/2, step 5821/7134 completed (loss: 0.05610646307468414, acc: 0.9862068891525269)
[2024-12-17 02:59:18,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:18,249][root][INFO] - Training Epoch: 2/2, step 5822/7134 completed (loss: 0.06209321692585945, acc: 0.9865771532058716)
[2024-12-17 02:59:18,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:18,518][root][INFO] - Training Epoch: 2/2, step 5823/7134 completed (loss: 0.0395294688642025, acc: 0.9931972622871399)
[2024-12-17 02:59:18,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:18,804][root][INFO] - Training Epoch: 2/2, step 5824/7134 completed (loss: 0.09249962121248245, acc: 0.9696969985961914)
[2024-12-17 02:59:18,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:19,079][root][INFO] - Training Epoch: 2/2, step 5825/7134 completed (loss: 0.1348036527633667, acc: 0.9618320465087891)
[2024-12-17 02:59:19,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:19,353][root][INFO] - Training Epoch: 2/2, step 5826/7134 completed (loss: 0.03405680134892464, acc: 1.0)
[2024-12-17 02:59:19,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:19,613][root][INFO] - Training Epoch: 2/2, step 5827/7134 completed (loss: 0.037583302706480026, acc: 1.0)
[2024-12-17 02:59:19,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:19,885][root][INFO] - Training Epoch: 2/2, step 5828/7134 completed (loss: 0.07039042562246323, acc: 0.9803921580314636)
[2024-12-17 02:59:19,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:20,168][root][INFO] - Training Epoch: 2/2, step 5829/7134 completed (loss: 0.09346289187669754, acc: 0.9756097793579102)
[2024-12-17 02:59:20,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:20,413][root][INFO] - Training Epoch: 2/2, step 5830/7134 completed (loss: 0.12364111840724945, acc: 0.984000027179718)
[2024-12-17 02:59:20,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:20,663][root][INFO] - Training Epoch: 2/2, step 5831/7134 completed (loss: 0.06323166191577911, acc: 0.9693877696990967)
[2024-12-17 02:59:20,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:20,939][root][INFO] - Training Epoch: 2/2, step 5832/7134 completed (loss: 0.1445232629776001, acc: 0.9694656729698181)
[2024-12-17 02:59:21,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:21,185][root][INFO] - Training Epoch: 2/2, step 5833/7134 completed (loss: 0.0696156769990921, acc: 0.9924812316894531)
[2024-12-17 02:59:21,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:21,461][root][INFO] - Training Epoch: 2/2, step 5834/7134 completed (loss: 0.18266254663467407, acc: 0.9532163739204407)
[2024-12-17 02:59:21,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:21,736][root][INFO] - Training Epoch: 2/2, step 5835/7134 completed (loss: 0.10026763379573822, acc: 0.9733333587646484)
[2024-12-17 02:59:21,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:22,011][root][INFO] - Training Epoch: 2/2, step 5836/7134 completed (loss: 0.2260138839483261, acc: 0.9617834687232971)
[2024-12-17 02:59:22,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:22,280][root][INFO] - Training Epoch: 2/2, step 5837/7134 completed (loss: 0.5148579478263855, acc: 0.8926174640655518)
[2024-12-17 02:59:22,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:22,564][root][INFO] - Training Epoch: 2/2, step 5838/7134 completed (loss: 0.23675546050071716, acc: 0.9496402740478516)
[2024-12-17 02:59:22,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:22,845][root][INFO] - Training Epoch: 2/2, step 5839/7134 completed (loss: 0.19647374749183655, acc: 0.9492753744125366)
[2024-12-17 02:59:22,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:23,111][root][INFO] - Training Epoch: 2/2, step 5840/7134 completed (loss: 0.0646647959947586, acc: 0.9860140085220337)
[2024-12-17 02:59:23,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:23,390][root][INFO] - Training Epoch: 2/2, step 5841/7134 completed (loss: 0.39860936999320984, acc: 0.90625)
[2024-12-17 02:59:23,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:23,653][root][INFO] - Training Epoch: 2/2, step 5842/7134 completed (loss: 0.05396724119782448, acc: 1.0)
[2024-12-17 02:59:23,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:23,923][root][INFO] - Training Epoch: 2/2, step 5843/7134 completed (loss: 0.18216995894908905, acc: 0.9702380895614624)
[2024-12-17 02:59:24,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:24,206][root][INFO] - Training Epoch: 2/2, step 5844/7134 completed (loss: 0.08955016732215881, acc: 0.9759036302566528)
[2024-12-17 02:59:24,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:24,485][root][INFO] - Training Epoch: 2/2, step 5845/7134 completed (loss: 0.09169886261224747, acc: 0.9870129823684692)
[2024-12-17 02:59:24,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:24,769][root][INFO] - Training Epoch: 2/2, step 5846/7134 completed (loss: 0.10640741884708405, acc: 0.976190447807312)
[2024-12-17 02:59:24,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:25,058][root][INFO] - Training Epoch: 2/2, step 5847/7134 completed (loss: 0.07281038165092468, acc: 0.9879518151283264)
[2024-12-17 02:59:25,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:25,318][root][INFO] - Training Epoch: 2/2, step 5848/7134 completed (loss: 0.09662826359272003, acc: 0.9729729890823364)
[2024-12-17 02:59:25,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:25,582][root][INFO] - Training Epoch: 2/2, step 5849/7134 completed (loss: 0.17121949791908264, acc: 0.948051929473877)
[2024-12-17 02:59:25,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:25,845][root][INFO] - Training Epoch: 2/2, step 5850/7134 completed (loss: 0.1000729650259018, acc: 0.9788732528686523)
[2024-12-17 02:59:25,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:26,099][root][INFO] - Training Epoch: 2/2, step 5851/7134 completed (loss: 0.18541786074638367, acc: 0.9452054500579834)
[2024-12-17 02:59:26,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:26,358][root][INFO] - Training Epoch: 2/2, step 5852/7134 completed (loss: 0.11239080876111984, acc: 0.9720279574394226)
[2024-12-17 02:59:26,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:26,640][root][INFO] - Training Epoch: 2/2, step 5853/7134 completed (loss: 0.16011300683021545, acc: 0.949438214302063)
[2024-12-17 02:59:26,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:26,902][root][INFO] - Training Epoch: 2/2, step 5854/7134 completed (loss: 0.24412281811237335, acc: 0.9307692050933838)
[2024-12-17 02:59:27,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:27,168][root][INFO] - Training Epoch: 2/2, step 5855/7134 completed (loss: 0.12196987122297287, acc: 0.9661017060279846)
[2024-12-17 02:59:27,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:27,440][root][INFO] - Training Epoch: 2/2, step 5856/7134 completed (loss: 0.07955803722143173, acc: 0.9929577708244324)
[2024-12-17 02:59:27,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:27,731][root][INFO] - Training Epoch: 2/2, step 5857/7134 completed (loss: 0.22858864068984985, acc: 0.9398496150970459)
[2024-12-17 02:59:27,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:27,976][root][INFO] - Training Epoch: 2/2, step 5858/7134 completed (loss: 0.11300791054964066, acc: 0.963302731513977)
[2024-12-17 02:59:28,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:28,247][root][INFO] - Training Epoch: 2/2, step 5859/7134 completed (loss: 0.0967368483543396, acc: 0.982758641242981)
[2024-12-17 02:59:28,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:28,512][root][INFO] - Training Epoch: 2/2, step 5860/7134 completed (loss: 0.1282491385936737, acc: 0.9545454382896423)
[2024-12-17 02:59:28,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:28,761][root][INFO] - Training Epoch: 2/2, step 5861/7134 completed (loss: 0.08696441352367401, acc: 0.9714285731315613)
[2024-12-17 02:59:28,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:29,034][root][INFO] - Training Epoch: 2/2, step 5862/7134 completed (loss: 0.1663748323917389, acc: 0.9322034120559692)
[2024-12-17 02:59:29,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:29,284][root][INFO] - Training Epoch: 2/2, step 5863/7134 completed (loss: 0.22583654522895813, acc: 0.9462365508079529)
[2024-12-17 02:59:29,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:29,565][root][INFO] - Training Epoch: 2/2, step 5864/7134 completed (loss: 0.2785608172416687, acc: 0.9356725215911865)
[2024-12-17 02:59:29,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:29,838][root][INFO] - Training Epoch: 2/2, step 5865/7134 completed (loss: 0.15593542158603668, acc: 0.9652777910232544)
[2024-12-17 02:59:29,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:30,123][root][INFO] - Training Epoch: 2/2, step 5866/7134 completed (loss: 0.04692470282316208, acc: 0.9835164546966553)
[2024-12-17 02:59:30,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:30,392][root][INFO] - Training Epoch: 2/2, step 5867/7134 completed (loss: 0.08954738825559616, acc: 0.9729729890823364)
[2024-12-17 02:59:30,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:30,670][root][INFO] - Training Epoch: 2/2, step 5868/7134 completed (loss: 0.1564265936613083, acc: 0.9542483687400818)
[2024-12-17 02:59:30,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:30,922][root][INFO] - Training Epoch: 2/2, step 5869/7134 completed (loss: 0.15849347412586212, acc: 0.9580838084220886)
[2024-12-17 02:59:31,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:31,228][root][INFO] - Training Epoch: 2/2, step 5870/7134 completed (loss: 0.1049434021115303, acc: 0.9814814925193787)
[2024-12-17 02:59:31,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:31,498][root][INFO] - Training Epoch: 2/2, step 5871/7134 completed (loss: 0.06052621454000473, acc: 0.963302731513977)
[2024-12-17 02:59:31,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:31,767][root][INFO] - Training Epoch: 2/2, step 5872/7134 completed (loss: 0.14015524089336395, acc: 0.9627329111099243)
[2024-12-17 02:59:31,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:32,071][root][INFO] - Training Epoch: 2/2, step 5873/7134 completed (loss: 0.20718346536159515, acc: 0.9518716335296631)
[2024-12-17 02:59:32,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:32,321][root][INFO] - Training Epoch: 2/2, step 5874/7134 completed (loss: 0.07025977969169617, acc: 0.9841269850730896)
[2024-12-17 02:59:32,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:32,599][root][INFO] - Training Epoch: 2/2, step 5875/7134 completed (loss: 0.1355717033147812, acc: 0.9545454382896423)
[2024-12-17 02:59:32,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:32,888][root][INFO] - Training Epoch: 2/2, step 5876/7134 completed (loss: 0.052497390657663345, acc: 0.9887640476226807)
[2024-12-17 02:59:33,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:33,163][root][INFO] - Training Epoch: 2/2, step 5877/7134 completed (loss: 0.10369598120450974, acc: 0.9720670580863953)
[2024-12-17 02:59:33,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:33,443][root][INFO] - Training Epoch: 2/2, step 5878/7134 completed (loss: 0.1912459433078766, acc: 0.9272727370262146)
[2024-12-17 02:59:33,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:33,697][root][INFO] - Training Epoch: 2/2, step 5879/7134 completed (loss: 0.07407477498054504, acc: 0.9777777791023254)
[2024-12-17 02:59:33,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:33,929][root][INFO] - Training Epoch: 2/2, step 5880/7134 completed (loss: 0.1543964147567749, acc: 0.9642857313156128)
[2024-12-17 02:59:34,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:34,187][root][INFO] - Training Epoch: 2/2, step 5881/7134 completed (loss: 0.09479771554470062, acc: 0.9658119678497314)
[2024-12-17 02:59:34,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:34,434][root][INFO] - Training Epoch: 2/2, step 5882/7134 completed (loss: 0.07601721584796906, acc: 0.970588207244873)
[2024-12-17 02:59:34,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:34,671][root][INFO] - Training Epoch: 2/2, step 5883/7134 completed (loss: 0.08700364083051682, acc: 0.9615384340286255)
[2024-12-17 02:59:34,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:34,942][root][INFO] - Training Epoch: 2/2, step 5884/7134 completed (loss: 0.1891973316669464, acc: 0.9682539701461792)
[2024-12-17 02:59:35,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:35,201][root][INFO] - Training Epoch: 2/2, step 5885/7134 completed (loss: 0.24222080409526825, acc: 0.9313725233078003)
[2024-12-17 02:59:35,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:35,452][root][INFO] - Training Epoch: 2/2, step 5886/7134 completed (loss: 0.03886745125055313, acc: 0.988095223903656)
[2024-12-17 02:59:35,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:35,711][root][INFO] - Training Epoch: 2/2, step 5887/7134 completed (loss: 0.06468354910612106, acc: 0.9833333492279053)
[2024-12-17 02:59:35,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:35,985][root][INFO] - Training Epoch: 2/2, step 5888/7134 completed (loss: 0.18994177877902985, acc: 0.936170220375061)
[2024-12-17 02:59:36,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:36,191][root][INFO] - Training Epoch: 2/2, step 5889/7134 completed (loss: 0.03205452114343643, acc: 1.0)
[2024-12-17 02:59:36,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:36,474][root][INFO] - Training Epoch: 2/2, step 5890/7134 completed (loss: 0.05416650325059891, acc: 0.9797297120094299)
[2024-12-17 02:59:36,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:36,751][root][INFO] - Training Epoch: 2/2, step 5891/7134 completed (loss: 0.21442830562591553, acc: 0.9714285731315613)
[2024-12-17 02:59:36,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:37,036][root][INFO] - Training Epoch: 2/2, step 5892/7134 completed (loss: 0.1349285989999771, acc: 0.9593023061752319)
[2024-12-17 02:59:37,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:37,305][root][INFO] - Training Epoch: 2/2, step 5893/7134 completed (loss: 0.042760830372571945, acc: 1.0)
[2024-12-17 02:59:37,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:37,534][root][INFO] - Training Epoch: 2/2, step 5894/7134 completed (loss: 0.039152178913354874, acc: 1.0)
[2024-12-17 02:59:37,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:37,831][root][INFO] - Training Epoch: 2/2, step 5895/7134 completed (loss: 0.07392944395542145, acc: 0.9791666865348816)
[2024-12-17 02:59:37,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:38,107][root][INFO] - Training Epoch: 2/2, step 5896/7134 completed (loss: 0.14091941714286804, acc: 0.9811320900917053)
[2024-12-17 02:59:38,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:38,384][root][INFO] - Training Epoch: 2/2, step 5897/7134 completed (loss: 0.06850581616163254, acc: 0.9772727489471436)
[2024-12-17 02:59:38,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:38,653][root][INFO] - Training Epoch: 2/2, step 5898/7134 completed (loss: 0.1393989771604538, acc: 0.9642857313156128)
[2024-12-17 02:59:38,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:38,942][root][INFO] - Training Epoch: 2/2, step 5899/7134 completed (loss: 0.025130784139037132, acc: 1.0)
[2024-12-17 02:59:39,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:39,216][root][INFO] - Training Epoch: 2/2, step 5900/7134 completed (loss: 0.05368182063102722, acc: 0.9876543283462524)
[2024-12-17 02:59:39,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:39,479][root][INFO] - Training Epoch: 2/2, step 5901/7134 completed (loss: 0.2691763937473297, acc: 0.9587628841400146)
[2024-12-17 02:59:39,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:39,771][root][INFO] - Training Epoch: 2/2, step 5902/7134 completed (loss: 0.052720483392477036, acc: 0.9795918464660645)
[2024-12-17 02:59:39,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:40,041][root][INFO] - Training Epoch: 2/2, step 5903/7134 completed (loss: 0.06892657279968262, acc: 0.982300877571106)
[2024-12-17 02:59:40,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:40,327][root][INFO] - Training Epoch: 2/2, step 5904/7134 completed (loss: 0.19365881383419037, acc: 0.9507042169570923)
[2024-12-17 02:59:40,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:40,593][root][INFO] - Training Epoch: 2/2, step 5905/7134 completed (loss: 0.09593480080366135, acc: 0.9864864945411682)
[2024-12-17 02:59:40,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:40,888][root][INFO] - Training Epoch: 2/2, step 5906/7134 completed (loss: 0.12778010964393616, acc: 0.9738562107086182)
[2024-12-17 02:59:41,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:41,200][root][INFO] - Training Epoch: 2/2, step 5907/7134 completed (loss: 0.06994211673736572, acc: 0.9861111044883728)
[2024-12-17 02:59:41,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:41,505][root][INFO] - Training Epoch: 2/2, step 5908/7134 completed (loss: 0.08117537200450897, acc: 0.9740259647369385)
[2024-12-17 02:59:41,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:41,918][root][INFO] - Training Epoch: 2/2, step 5909/7134 completed (loss: 0.11940829455852509, acc: 0.9635036587715149)
[2024-12-17 02:59:42,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:42,231][root][INFO] - Training Epoch: 2/2, step 5910/7134 completed (loss: 0.1735457330942154, acc: 0.940397322177887)
[2024-12-17 02:59:42,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:42,519][root][INFO] - Training Epoch: 2/2, step 5911/7134 completed (loss: 0.16310647130012512, acc: 0.95652174949646)
[2024-12-17 02:59:42,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:42,809][root][INFO] - Training Epoch: 2/2, step 5912/7134 completed (loss: 0.03846737742424011, acc: 1.0)
[2024-12-17 02:59:42,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:43,114][root][INFO] - Training Epoch: 2/2, step 5913/7134 completed (loss: 0.13594591617584229, acc: 0.9644970297813416)
[2024-12-17 02:59:43,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:43,381][root][INFO] - Training Epoch: 2/2, step 5914/7134 completed (loss: 0.15207639336585999, acc: 0.9714285731315613)
[2024-12-17 02:59:43,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:43,688][root][INFO] - Training Epoch: 2/2, step 5915/7134 completed (loss: 0.24159292876720428, acc: 0.9541984796524048)
[2024-12-17 02:59:43,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:43,969][root][INFO] - Training Epoch: 2/2, step 5916/7134 completed (loss: 0.18877659738063812, acc: 0.9536423683166504)
[2024-12-17 02:59:44,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:44,215][root][INFO] - Training Epoch: 2/2, step 5917/7134 completed (loss: 0.043023549020290375, acc: 0.9919999837875366)
[2024-12-17 02:59:44,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:44,502][root][INFO] - Training Epoch: 2/2, step 5918/7134 completed (loss: 0.2893635630607605, acc: 0.9440559148788452)
[2024-12-17 02:59:44,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:44,779][root][INFO] - Training Epoch: 2/2, step 5919/7134 completed (loss: 0.049104414880275726, acc: 0.9925373196601868)
[2024-12-17 02:59:44,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:45,051][root][INFO] - Training Epoch: 2/2, step 5920/7134 completed (loss: 0.07746923714876175, acc: 0.9925373196601868)
[2024-12-17 02:59:45,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:45,317][root][INFO] - Training Epoch: 2/2, step 5921/7134 completed (loss: 0.17006546258926392, acc: 0.9568965435028076)
[2024-12-17 02:59:45,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:45,603][root][INFO] - Training Epoch: 2/2, step 5922/7134 completed (loss: 0.6261910200119019, acc: 0.8589743375778198)
[2024-12-17 02:59:45,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:45,888][root][INFO] - Training Epoch: 2/2, step 5923/7134 completed (loss: 0.21814541518688202, acc: 0.9240506291389465)
[2024-12-17 02:59:45,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:46,163][root][INFO] - Training Epoch: 2/2, step 5924/7134 completed (loss: 0.13276153802871704, acc: 0.9711538553237915)
[2024-12-17 02:59:46,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:46,404][root][INFO] - Training Epoch: 2/2, step 5925/7134 completed (loss: 0.5495442152023315, acc: 0.8888888955116272)
[2024-12-17 02:59:46,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:46,675][root][INFO] - Training Epoch: 2/2, step 5926/7134 completed (loss: 0.3257361054420471, acc: 0.9144737124443054)
[2024-12-17 02:59:46,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:46,934][root][INFO] - Training Epoch: 2/2, step 5927/7134 completed (loss: 0.2590107023715973, acc: 0.9642857313156128)
[2024-12-17 02:59:47,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:47,171][root][INFO] - Training Epoch: 2/2, step 5928/7134 completed (loss: 0.7843596339225769, acc: 0.837837815284729)
[2024-12-17 02:59:47,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:47,446][root][INFO] - Training Epoch: 2/2, step 5929/7134 completed (loss: 0.3139709234237671, acc: 0.9274193644523621)
[2024-12-17 02:59:47,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:47,713][root][INFO] - Training Epoch: 2/2, step 5930/7134 completed (loss: 0.5482659935951233, acc: 0.8842975497245789)
[2024-12-17 02:59:47,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:47,971][root][INFO] - Training Epoch: 2/2, step 5931/7134 completed (loss: 0.21460384130477905, acc: 0.9487179517745972)
[2024-12-17 02:59:48,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:48,244][root][INFO] - Training Epoch: 2/2, step 5932/7134 completed (loss: 0.474738210439682, acc: 0.8776978254318237)
[2024-12-17 02:59:48,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:48,491][root][INFO] - Training Epoch: 2/2, step 5933/7134 completed (loss: 0.40344297885894775, acc: 0.8970588445663452)
[2024-12-17 02:59:48,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:48,763][root][INFO] - Training Epoch: 2/2, step 5934/7134 completed (loss: 0.19209139049053192, acc: 0.9428571462631226)
[2024-12-17 02:59:48,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:49,022][root][INFO] - Training Epoch: 2/2, step 5935/7134 completed (loss: 0.11582442373037338, acc: 0.9672130942344666)
[2024-12-17 02:59:49,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:49,282][root][INFO] - Training Epoch: 2/2, step 5936/7134 completed (loss: 0.3512997031211853, acc: 0.9325153231620789)
[2024-12-17 02:59:49,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:49,559][root][INFO] - Training Epoch: 2/2, step 5937/7134 completed (loss: 0.11935509741306305, acc: 0.9718309640884399)
[2024-12-17 02:59:49,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:49,829][root][INFO] - Training Epoch: 2/2, step 5938/7134 completed (loss: 0.09648910164833069, acc: 0.969924807548523)
[2024-12-17 02:59:49,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:50,079][root][INFO] - Training Epoch: 2/2, step 5939/7134 completed (loss: 0.8860620856285095, acc: 0.8275862336158752)
[2024-12-17 02:59:50,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:50,370][root][INFO] - Training Epoch: 2/2, step 5940/7134 completed (loss: 0.27512866258621216, acc: 0.9254658222198486)
[2024-12-17 02:59:50,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:50,628][root][INFO] - Training Epoch: 2/2, step 5941/7134 completed (loss: 0.23518019914627075, acc: 0.9285714030265808)
[2024-12-17 02:59:50,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:50,889][root][INFO] - Training Epoch: 2/2, step 5942/7134 completed (loss: 0.05704638361930847, acc: 0.9760000109672546)
[2024-12-17 02:59:50,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:51,154][root][INFO] - Training Epoch: 2/2, step 5943/7134 completed (loss: 0.11091909557580948, acc: 0.9631901979446411)
[2024-12-17 02:59:51,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:51,441][root][INFO] - Training Epoch: 2/2, step 5944/7134 completed (loss: 0.1467919498682022, acc: 0.9744898080825806)
[2024-12-17 02:59:51,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:51,736][root][INFO] - Training Epoch: 2/2, step 5945/7134 completed (loss: 0.10458486527204514, acc: 0.9822485446929932)
[2024-12-17 02:59:51,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:52,003][root][INFO] - Training Epoch: 2/2, step 5946/7134 completed (loss: 0.16482143104076385, acc: 0.9652777910232544)
[2024-12-17 02:59:52,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:52,285][root][INFO] - Training Epoch: 2/2, step 5947/7134 completed (loss: 0.1951536238193512, acc: 0.932692289352417)
[2024-12-17 02:59:52,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:52,558][root][INFO] - Training Epoch: 2/2, step 5948/7134 completed (loss: 0.31545698642730713, acc: 0.934959352016449)
[2024-12-17 02:59:52,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:52,832][root][INFO] - Training Epoch: 2/2, step 5949/7134 completed (loss: 0.11582692712545395, acc: 0.9722222089767456)
[2024-12-17 02:59:52,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:53,098][root][INFO] - Training Epoch: 2/2, step 5950/7134 completed (loss: 0.22035357356071472, acc: 0.9405940771102905)
[2024-12-17 02:59:53,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:53,374][root][INFO] - Training Epoch: 2/2, step 5951/7134 completed (loss: 0.30651092529296875, acc: 0.9345238208770752)
[2024-12-17 02:59:53,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:53,666][root][INFO] - Training Epoch: 2/2, step 5952/7134 completed (loss: 0.5413362383842468, acc: 0.9013158082962036)
[2024-12-17 02:59:53,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:53,945][root][INFO] - Training Epoch: 2/2, step 5953/7134 completed (loss: 0.13515518605709076, acc: 0.9716981053352356)
[2024-12-17 02:59:54,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:54,214][root][INFO] - Training Epoch: 2/2, step 5954/7134 completed (loss: 0.0636725202202797, acc: 0.9801980257034302)
[2024-12-17 02:59:54,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:54,421][root][INFO] - Training Epoch: 2/2, step 5955/7134 completed (loss: 0.1034632995724678, acc: 0.9814814925193787)
[2024-12-17 02:59:54,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:54,674][root][INFO] - Training Epoch: 2/2, step 5956/7134 completed (loss: 0.1778595745563507, acc: 0.9666666388511658)
[2024-12-17 02:59:54,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:54,934][root][INFO] - Training Epoch: 2/2, step 5957/7134 completed (loss: 0.15700167417526245, acc: 0.957317054271698)
[2024-12-17 02:59:55,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:55,221][root][INFO] - Training Epoch: 2/2, step 5958/7134 completed (loss: 0.2244827002286911, acc: 0.9314285516738892)
[2024-12-17 02:59:55,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:55,508][root][INFO] - Training Epoch: 2/2, step 5959/7134 completed (loss: 0.1402784138917923, acc: 0.9627659320831299)
[2024-12-17 02:59:55,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:55,784][root][INFO] - Training Epoch: 2/2, step 5960/7134 completed (loss: 0.012885716743767262, acc: 0.9940476417541504)
[2024-12-17 02:59:55,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:56,035][root][INFO] - Training Epoch: 2/2, step 5961/7134 completed (loss: 0.2638966739177704, acc: 0.9444444179534912)
[2024-12-17 02:59:56,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:56,315][root][INFO] - Training Epoch: 2/2, step 5962/7134 completed (loss: 0.09040191769599915, acc: 0.9724137783050537)
[2024-12-17 02:59:56,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:56,603][root][INFO] - Training Epoch: 2/2, step 5963/7134 completed (loss: 0.07000156491994858, acc: 0.9885714054107666)
[2024-12-17 02:59:56,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:56,874][root][INFO] - Training Epoch: 2/2, step 5964/7134 completed (loss: 0.05659117549657822, acc: 0.9842519760131836)
[2024-12-17 02:59:56,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:57,158][root][INFO] - Training Epoch: 2/2, step 5965/7134 completed (loss: 0.07536158710718155, acc: 0.9679487347602844)
[2024-12-17 02:59:57,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:57,454][root][INFO] - Training Epoch: 2/2, step 5966/7134 completed (loss: 0.10679028183221817, acc: 0.97826087474823)
[2024-12-17 02:59:57,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:57,726][root][INFO] - Training Epoch: 2/2, step 5967/7134 completed (loss: 0.07808244228363037, acc: 0.9791666865348816)
[2024-12-17 02:59:57,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:57,993][root][INFO] - Training Epoch: 2/2, step 5968/7134 completed (loss: 0.1369428038597107, acc: 0.9800000190734863)
[2024-12-17 02:59:58,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:58,260][root][INFO] - Training Epoch: 2/2, step 5969/7134 completed (loss: 0.11197450757026672, acc: 0.9741935729980469)
[2024-12-17 02:59:58,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:58,537][root][INFO] - Training Epoch: 2/2, step 5970/7134 completed (loss: 0.10592415183782578, acc: 0.9765625)
[2024-12-17 02:59:58,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:58,810][root][INFO] - Training Epoch: 2/2, step 5971/7134 completed (loss: 0.035003911703825, acc: 0.9894737005233765)
[2024-12-17 02:59:58,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:59,083][root][INFO] - Training Epoch: 2/2, step 5972/7134 completed (loss: 0.19997914135456085, acc: 0.9631901979446411)
[2024-12-17 02:59:59,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:59,384][root][INFO] - Training Epoch: 2/2, step 5973/7134 completed (loss: 0.15256230533123016, acc: 0.9714285731315613)
[2024-12-17 02:59:59,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:59,678][root][INFO] - Training Epoch: 2/2, step 5974/7134 completed (loss: 0.09164858609437943, acc: 0.9852941036224365)
[2024-12-17 02:59:59,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:59,930][root][INFO] - Training Epoch: 2/2, step 5975/7134 completed (loss: 0.06588345766067505, acc: 0.9756097793579102)
[2024-12-17 03:00:00,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:00,209][root][INFO] - Training Epoch: 2/2, step 5976/7134 completed (loss: 0.10711641609668732, acc: 0.9803921580314636)
[2024-12-17 03:00:00,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:00,482][root][INFO] - Training Epoch: 2/2, step 5977/7134 completed (loss: 0.11303684860467911, acc: 0.9800000190734863)
[2024-12-17 03:00:00,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:00,760][root][INFO] - Training Epoch: 2/2, step 5978/7134 completed (loss: 0.15716196596622467, acc: 0.9627329111099243)
[2024-12-17 03:00:00,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:01,003][root][INFO] - Training Epoch: 2/2, step 5979/7134 completed (loss: 0.22399447858333588, acc: 0.9578947424888611)
[2024-12-17 03:00:01,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:01,273][root][INFO] - Training Epoch: 2/2, step 5980/7134 completed (loss: 0.07830794900655746, acc: 0.97826087474823)
[2024-12-17 03:00:01,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:01,557][root][INFO] - Training Epoch: 2/2, step 5981/7134 completed (loss: 0.12243494391441345, acc: 0.9796954393386841)
[2024-12-17 03:00:01,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:01,830][root][INFO] - Training Epoch: 2/2, step 5982/7134 completed (loss: 0.0740375965833664, acc: 0.9838709831237793)
[2024-12-17 03:00:01,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:02,103][root][INFO] - Training Epoch: 2/2, step 5983/7134 completed (loss: 0.17230188846588135, acc: 0.9425287246704102)
[2024-12-17 03:00:02,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:02,376][root][INFO] - Training Epoch: 2/2, step 5984/7134 completed (loss: 0.08730224519968033, acc: 0.9636363387107849)
[2024-12-17 03:00:02,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:02,656][root][INFO] - Training Epoch: 2/2, step 5985/7134 completed (loss: 0.08314528316259384, acc: 0.9775280952453613)
[2024-12-17 03:00:02,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:02,952][root][INFO] - Training Epoch: 2/2, step 5986/7134 completed (loss: 0.1306798756122589, acc: 0.9735449552536011)
[2024-12-17 03:00:03,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:03,243][root][INFO] - Training Epoch: 2/2, step 5987/7134 completed (loss: 0.15291912853717804, acc: 0.9609755873680115)
[2024-12-17 03:00:03,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:03,510][root][INFO] - Training Epoch: 2/2, step 5988/7134 completed (loss: 0.03956318274140358, acc: 0.9944444298744202)
[2024-12-17 03:00:03,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:03,785][root][INFO] - Training Epoch: 2/2, step 5989/7134 completed (loss: 0.11481214314699173, acc: 0.9769230484962463)
[2024-12-17 03:00:03,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:04,084][root][INFO] - Training Epoch: 2/2, step 5990/7134 completed (loss: 0.13323277235031128, acc: 0.9668508172035217)
[2024-12-17 03:00:04,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:04,277][root][INFO] - Training Epoch: 2/2, step 5991/7134 completed (loss: 0.17925414443016052, acc: 0.9431818127632141)
[2024-12-17 03:00:04,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:04,567][root][INFO] - Training Epoch: 2/2, step 5992/7134 completed (loss: 0.06579488515853882, acc: 0.9846938848495483)
[2024-12-17 03:00:04,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:04,830][root][INFO] - Training Epoch: 2/2, step 5993/7134 completed (loss: 0.11047405004501343, acc: 0.9775280952453613)
[2024-12-17 03:00:04,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:05,091][root][INFO] - Training Epoch: 2/2, step 5994/7134 completed (loss: 0.030697185546159744, acc: 0.9917355179786682)
[2024-12-17 03:00:05,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:05,374][root][INFO] - Training Epoch: 2/2, step 5995/7134 completed (loss: 0.07861685007810593, acc: 0.9826589822769165)
[2024-12-17 03:00:05,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:05,661][root][INFO] - Training Epoch: 2/2, step 5996/7134 completed (loss: 0.10545454174280167, acc: 0.9800000190734863)
[2024-12-17 03:00:05,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:05,953][root][INFO] - Training Epoch: 2/2, step 5997/7134 completed (loss: 0.12416446954011917, acc: 0.9659090638160706)
[2024-12-17 03:00:06,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:06,248][root][INFO] - Training Epoch: 2/2, step 5998/7134 completed (loss: 0.12547744810581207, acc: 0.9629629850387573)
[2024-12-17 03:00:06,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:06,523][root][INFO] - Training Epoch: 2/2, step 5999/7134 completed (loss: 0.08494163304567337, acc: 0.9855072498321533)
[2024-12-17 03:00:06,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:06,797][root][INFO] - Training Epoch: 2/2, step 6000/7134 completed (loss: 0.07253187149763107, acc: 0.9788732528686523)
[2024-12-17 03:00:06,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:07,075][root][INFO] - Training Epoch: 2/2, step 6001/7134 completed (loss: 0.03418169543147087, acc: 1.0)
[2024-12-17 03:00:07,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:07,345][root][INFO] - Training Epoch: 2/2, step 6002/7134 completed (loss: 0.13806039094924927, acc: 0.9669421315193176)
[2024-12-17 03:00:07,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:07,653][root][INFO] - Training Epoch: 2/2, step 6003/7134 completed (loss: 0.11427583545446396, acc: 0.9805194735527039)
[2024-12-17 03:00:07,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:07,940][root][INFO] - Training Epoch: 2/2, step 6004/7134 completed (loss: 0.3576692044734955, acc: 0.9248554706573486)
[2024-12-17 03:00:08,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:08,220][root][INFO] - Training Epoch: 2/2, step 6005/7134 completed (loss: 0.20285014808177948, acc: 0.9470198750495911)
[2024-12-17 03:00:08,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:08,499][root][INFO] - Training Epoch: 2/2, step 6006/7134 completed (loss: 0.19622935354709625, acc: 0.9599999785423279)
[2024-12-17 03:00:08,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:08,783][root][INFO] - Training Epoch: 2/2, step 6007/7134 completed (loss: 0.11692947894334793, acc: 0.9558823704719543)
[2024-12-17 03:00:08,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:09,059][root][INFO] - Training Epoch: 2/2, step 6008/7134 completed (loss: 0.15010598301887512, acc: 0.9440559148788452)
[2024-12-17 03:00:09,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:09,347][root][INFO] - Training Epoch: 2/2, step 6009/7134 completed (loss: 0.15036967396736145, acc: 0.969924807548523)
[2024-12-17 03:00:09,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:09,633][root][INFO] - Training Epoch: 2/2, step 6010/7134 completed (loss: 0.1965528130531311, acc: 0.9430379867553711)
[2024-12-17 03:00:09,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:09,922][root][INFO] - Training Epoch: 2/2, step 6011/7134 completed (loss: 0.29662951827049255, acc: 0.9285714030265808)
[2024-12-17 03:00:10,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:10,202][root][INFO] - Training Epoch: 2/2, step 6012/7134 completed (loss: 0.1240939199924469, acc: 0.9575757384300232)
[2024-12-17 03:00:10,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:10,482][root][INFO] - Training Epoch: 2/2, step 6013/7134 completed (loss: 0.24717943370342255, acc: 0.9382022619247437)
[2024-12-17 03:00:10,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:10,772][root][INFO] - Training Epoch: 2/2, step 6014/7134 completed (loss: 0.17079751193523407, acc: 0.9448819160461426)
[2024-12-17 03:00:10,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:11,075][root][INFO] - Training Epoch: 2/2, step 6015/7134 completed (loss: 0.20156413316726685, acc: 0.9639639854431152)
[2024-12-17 03:00:11,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:11,366][root][INFO] - Training Epoch: 2/2, step 6016/7134 completed (loss: 0.15624547004699707, acc: 0.9324324131011963)
[2024-12-17 03:00:11,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:11,649][root][INFO] - Training Epoch: 2/2, step 6017/7134 completed (loss: 0.11868102848529816, acc: 0.9807692170143127)
[2024-12-17 03:00:11,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:11,925][root][INFO] - Training Epoch: 2/2, step 6018/7134 completed (loss: 0.12029580026865005, acc: 1.0)
[2024-12-17 03:00:12,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:12,162][root][INFO] - Training Epoch: 2/2, step 6019/7134 completed (loss: 0.17213457822799683, acc: 0.9444444179534912)
[2024-12-17 03:00:12,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:12,408][root][INFO] - Training Epoch: 2/2, step 6020/7134 completed (loss: 0.04034871608018875, acc: 0.9841269850730896)
[2024-12-17 03:00:12,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:12,636][root][INFO] - Training Epoch: 2/2, step 6021/7134 completed (loss: 0.06673088669776917, acc: 1.0)
[2024-12-17 03:00:12,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:12,892][root][INFO] - Training Epoch: 2/2, step 6022/7134 completed (loss: 0.09214410930871964, acc: 0.9736841917037964)
[2024-12-17 03:00:12,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:13,119][root][INFO] - Training Epoch: 2/2, step 6023/7134 completed (loss: 0.02758384495973587, acc: 0.9886363744735718)
[2024-12-17 03:00:13,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:13,401][root][INFO] - Training Epoch: 2/2, step 6024/7134 completed (loss: 0.00612130481749773, acc: 1.0)
[2024-12-17 03:00:13,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:13,677][root][INFO] - Training Epoch: 2/2, step 6025/7134 completed (loss: 0.12628410756587982, acc: 0.9590163826942444)
[2024-12-17 03:00:13,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:13,935][root][INFO] - Training Epoch: 2/2, step 6026/7134 completed (loss: 0.25723883509635925, acc: 0.9322034120559692)
[2024-12-17 03:00:14,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:14,193][root][INFO] - Training Epoch: 2/2, step 6027/7134 completed (loss: 0.03990931063890457, acc: 0.9887640476226807)
[2024-12-17 03:00:14,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:14,450][root][INFO] - Training Epoch: 2/2, step 6028/7134 completed (loss: 0.12263596802949905, acc: 0.9666666388511658)
[2024-12-17 03:00:14,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:14,707][root][INFO] - Training Epoch: 2/2, step 6029/7134 completed (loss: 0.13609369099140167, acc: 0.9577465057373047)
[2024-12-17 03:00:14,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:14,966][root][INFO] - Training Epoch: 2/2, step 6030/7134 completed (loss: 0.03980434313416481, acc: 0.9848484992980957)
[2024-12-17 03:00:15,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:15,233][root][INFO] - Training Epoch: 2/2, step 6031/7134 completed (loss: 0.1292143166065216, acc: 0.9651162624359131)
[2024-12-17 03:00:15,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:15,482][root][INFO] - Training Epoch: 2/2, step 6032/7134 completed (loss: 0.04874445125460625, acc: 0.9801980257034302)
[2024-12-17 03:00:15,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:15,750][root][INFO] - Training Epoch: 2/2, step 6033/7134 completed (loss: 0.13238905370235443, acc: 0.939393937587738)
[2024-12-17 03:00:15,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:15,956][root][INFO] - Training Epoch: 2/2, step 6034/7134 completed (loss: 0.19946715235710144, acc: 0.9552238583564758)
[2024-12-17 03:00:16,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:16,247][root][INFO] - Training Epoch: 2/2, step 6035/7134 completed (loss: 0.34263554215431213, acc: 0.9248826503753662)
[2024-12-17 03:00:16,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:16,551][root][INFO] - Training Epoch: 2/2, step 6036/7134 completed (loss: 0.3073037266731262, acc: 0.932584285736084)
[2024-12-17 03:00:16,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:16,831][root][INFO] - Training Epoch: 2/2, step 6037/7134 completed (loss: 0.18431106209754944, acc: 0.9432623982429504)
[2024-12-17 03:00:16,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:17,114][root][INFO] - Training Epoch: 2/2, step 6038/7134 completed (loss: 0.18491166830062866, acc: 0.9460784196853638)
[2024-12-17 03:00:17,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:17,396][root][INFO] - Training Epoch: 2/2, step 6039/7134 completed (loss: 0.26062697172164917, acc: 0.9317073225975037)
[2024-12-17 03:00:17,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:17,675][root][INFO] - Training Epoch: 2/2, step 6040/7134 completed (loss: 0.15897208452224731, acc: 0.9559471607208252)
[2024-12-17 03:00:17,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:17,941][root][INFO] - Training Epoch: 2/2, step 6041/7134 completed (loss: 0.23250728845596313, acc: 0.9408602118492126)
[2024-12-17 03:00:18,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:18,217][root][INFO] - Training Epoch: 2/2, step 6042/7134 completed (loss: 0.08706561475992203, acc: 0.9724770784378052)
[2024-12-17 03:00:18,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:18,497][root][INFO] - Training Epoch: 2/2, step 6043/7134 completed (loss: 0.18946292996406555, acc: 0.9462365508079529)
[2024-12-17 03:00:18,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:18,772][root][INFO] - Training Epoch: 2/2, step 6044/7134 completed (loss: 0.09356747567653656, acc: 0.9809523820877075)
[2024-12-17 03:00:18,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:19,047][root][INFO] - Training Epoch: 2/2, step 6045/7134 completed (loss: 0.13757990300655365, acc: 0.9617224931716919)
[2024-12-17 03:00:19,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:19,328][root][INFO] - Training Epoch: 2/2, step 6046/7134 completed (loss: 0.2748740017414093, acc: 0.9109588861465454)
[2024-12-17 03:00:19,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:19,606][root][INFO] - Training Epoch: 2/2, step 6047/7134 completed (loss: 0.31122222542762756, acc: 0.9319728016853333)
[2024-12-17 03:00:19,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:19,883][root][INFO] - Training Epoch: 2/2, step 6048/7134 completed (loss: 0.17655061185359955, acc: 0.9430894255638123)
[2024-12-17 03:00:19,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:20,140][root][INFO] - Training Epoch: 2/2, step 6049/7134 completed (loss: 0.11402703821659088, acc: 0.9790209531784058)
[2024-12-17 03:00:20,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:20,401][root][INFO] - Training Epoch: 2/2, step 6050/7134 completed (loss: 0.2675532102584839, acc: 0.9190751314163208)
[2024-12-17 03:00:20,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:20,690][root][INFO] - Training Epoch: 2/2, step 6051/7134 completed (loss: 0.27976319193840027, acc: 0.9261363744735718)
[2024-12-17 03:00:20,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:20,971][root][INFO] - Training Epoch: 2/2, step 6052/7134 completed (loss: 0.31860408186912537, acc: 0.9266666769981384)
[2024-12-17 03:00:21,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:21,252][root][INFO] - Training Epoch: 2/2, step 6053/7134 completed (loss: 0.2783324718475342, acc: 0.9380530714988708)
[2024-12-17 03:00:21,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:21,526][root][INFO] - Training Epoch: 2/2, step 6054/7134 completed (loss: 0.1536516547203064, acc: 0.9481865167617798)
[2024-12-17 03:00:21,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:21,785][root][INFO] - Training Epoch: 2/2, step 6055/7134 completed (loss: 0.15463605523109436, acc: 0.9415584206581116)
[2024-12-17 03:00:21,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:22,066][root][INFO] - Training Epoch: 2/2, step 6056/7134 completed (loss: 0.2496655434370041, acc: 0.9189189076423645)
[2024-12-17 03:00:22,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:22,333][root][INFO] - Training Epoch: 2/2, step 6057/7134 completed (loss: 0.08168074488639832, acc: 0.9740259647369385)
[2024-12-17 03:00:22,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:22,594][root][INFO] - Training Epoch: 2/2, step 6058/7134 completed (loss: 0.05665912479162216, acc: 0.9830508232116699)
[2024-12-17 03:00:22,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:22,852][root][INFO] - Training Epoch: 2/2, step 6059/7134 completed (loss: 0.13958650827407837, acc: 0.9589040875434875)
[2024-12-17 03:00:22,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:23,130][root][INFO] - Training Epoch: 2/2, step 6060/7134 completed (loss: 0.13513334095478058, acc: 0.9629629850387573)
[2024-12-17 03:00:23,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:23,414][root][INFO] - Training Epoch: 2/2, step 6061/7134 completed (loss: 0.28015273809432983, acc: 0.9436619877815247)
[2024-12-17 03:00:23,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:23,714][root][INFO] - Training Epoch: 2/2, step 6062/7134 completed (loss: 0.2590274214744568, acc: 0.9365079402923584)
[2024-12-17 03:00:23,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:23,988][root][INFO] - Training Epoch: 2/2, step 6063/7134 completed (loss: 0.16055969893932343, acc: 0.9745762944221497)
[2024-12-17 03:00:24,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:24,270][root][INFO] - Training Epoch: 2/2, step 6064/7134 completed (loss: 0.2159752994775772, acc: 0.9378882050514221)
[2024-12-17 03:00:24,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:24,550][root][INFO] - Training Epoch: 2/2, step 6065/7134 completed (loss: 0.16908197104930878, acc: 0.9695431590080261)
[2024-12-17 03:00:24,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:24,822][root][INFO] - Training Epoch: 2/2, step 6066/7134 completed (loss: 0.2215021699666977, acc: 0.9333333373069763)
[2024-12-17 03:00:24,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:25,108][root][INFO] - Training Epoch: 2/2, step 6067/7134 completed (loss: 0.2572762966156006, acc: 0.9342105388641357)
[2024-12-17 03:00:25,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:25,457][root][INFO] - Training Epoch: 2/2, step 6068/7134 completed (loss: 0.36078083515167236, acc: 0.8972973227500916)
[2024-12-17 03:00:25,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:25,744][root][INFO] - Training Epoch: 2/2, step 6069/7134 completed (loss: 0.24769362807273865, acc: 0.929411768913269)
[2024-12-17 03:00:25,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:26,050][root][INFO] - Training Epoch: 2/2, step 6070/7134 completed (loss: 0.2092590481042862, acc: 0.9371428489685059)
[2024-12-17 03:00:26,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:26,321][root][INFO] - Training Epoch: 2/2, step 6071/7134 completed (loss: 0.22265121340751648, acc: 0.9289940595626831)
[2024-12-17 03:00:26,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:26,548][root][INFO] - Training Epoch: 2/2, step 6072/7134 completed (loss: 0.4614538848400116, acc: 0.8916666507720947)
[2024-12-17 03:00:26,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:26,818][root][INFO] - Training Epoch: 2/2, step 6073/7134 completed (loss: 0.23091179132461548, acc: 0.9171974658966064)
[2024-12-17 03:00:26,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:27,086][root][INFO] - Training Epoch: 2/2, step 6074/7134 completed (loss: 0.3745119869709015, acc: 0.9354838728904724)
[2024-12-17 03:00:27,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:27,362][root][INFO] - Training Epoch: 2/2, step 6075/7134 completed (loss: 0.19599898159503937, acc: 0.9578947424888611)
[2024-12-17 03:00:27,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:27,639][root][INFO] - Training Epoch: 2/2, step 6076/7134 completed (loss: 0.30990827083587646, acc: 0.9144384860992432)
[2024-12-17 03:00:27,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:27,913][root][INFO] - Training Epoch: 2/2, step 6077/7134 completed (loss: 0.1417158544063568, acc: 0.9585798978805542)
[2024-12-17 03:00:28,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:28,187][root][INFO] - Training Epoch: 2/2, step 6078/7134 completed (loss: 0.3129984736442566, acc: 0.9322034120559692)
[2024-12-17 03:00:28,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:28,475][root][INFO] - Training Epoch: 2/2, step 6079/7134 completed (loss: 0.12655778229236603, acc: 0.9621211886405945)
[2024-12-17 03:00:28,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:28,739][root][INFO] - Training Epoch: 2/2, step 6080/7134 completed (loss: 0.14693006873130798, acc: 0.977011501789093)
[2024-12-17 03:00:28,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:29,015][root][INFO] - Training Epoch: 2/2, step 6081/7134 completed (loss: 0.27419513463974, acc: 0.9324324131011963)
[2024-12-17 03:00:29,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:29,281][root][INFO] - Training Epoch: 2/2, step 6082/7134 completed (loss: 0.11406642198562622, acc: 0.9664429426193237)
[2024-12-17 03:00:29,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:29,569][root][INFO] - Training Epoch: 2/2, step 6083/7134 completed (loss: 0.09281112253665924, acc: 0.9792746305465698)
[2024-12-17 03:00:29,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:29,840][root][INFO] - Training Epoch: 2/2, step 6084/7134 completed (loss: 0.16392113268375397, acc: 0.9599999785423279)
[2024-12-17 03:00:29,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:30,121][root][INFO] - Training Epoch: 2/2, step 6085/7134 completed (loss: 0.13401377201080322, acc: 0.9791666865348816)
[2024-12-17 03:00:30,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:30,418][root][INFO] - Training Epoch: 2/2, step 6086/7134 completed (loss: 0.07548258453607559, acc: 0.9781420826911926)
[2024-12-17 03:00:30,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:30,703][root][INFO] - Training Epoch: 2/2, step 6087/7134 completed (loss: 0.26893702149391174, acc: 0.9558823704719543)
[2024-12-17 03:00:30,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:30,969][root][INFO] - Training Epoch: 2/2, step 6088/7134 completed (loss: 0.20476612448692322, acc: 0.9513513445854187)
[2024-12-17 03:00:31,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:31,258][root][INFO] - Training Epoch: 2/2, step 6089/7134 completed (loss: 0.13549329340457916, acc: 0.954285740852356)
[2024-12-17 03:00:31,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:31,541][root][INFO] - Training Epoch: 2/2, step 6090/7134 completed (loss: 0.08107993751764297, acc: 0.9839572310447693)
[2024-12-17 03:00:31,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:31,814][root][INFO] - Training Epoch: 2/2, step 6091/7134 completed (loss: 0.12489136308431625, acc: 0.9745222926139832)
[2024-12-17 03:00:31,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:32,084][root][INFO] - Training Epoch: 2/2, step 6092/7134 completed (loss: 0.161180779337883, acc: 0.9636363387107849)
[2024-12-17 03:00:32,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:32,357][root][INFO] - Training Epoch: 2/2, step 6093/7134 completed (loss: 0.19218388199806213, acc: 0.9552238583564758)
[2024-12-17 03:00:32,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:32,618][root][INFO] - Training Epoch: 2/2, step 6094/7134 completed (loss: 0.3431403934955597, acc: 0.8977272510528564)
[2024-12-17 03:00:32,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:32,891][root][INFO] - Training Epoch: 2/2, step 6095/7134 completed (loss: 0.1211315244436264, acc: 0.9631901979446411)
[2024-12-17 03:00:33,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:33,186][root][INFO] - Training Epoch: 2/2, step 6096/7134 completed (loss: 0.21846650540828705, acc: 0.9441624283790588)
[2024-12-17 03:00:33,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:33,482][root][INFO] - Training Epoch: 2/2, step 6097/7134 completed (loss: 0.20962654054164886, acc: 0.9378882050514221)
[2024-12-17 03:00:33,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:33,762][root][INFO] - Training Epoch: 2/2, step 6098/7134 completed (loss: 0.17446483671665192, acc: 0.9649122953414917)
[2024-12-17 03:00:33,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:34,046][root][INFO] - Training Epoch: 2/2, step 6099/7134 completed (loss: 0.09782600402832031, acc: 0.9795918464660645)
[2024-12-17 03:00:34,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:34,272][root][INFO] - Training Epoch: 2/2, step 6100/7134 completed (loss: 0.24077393114566803, acc: 0.9615384340286255)
[2024-12-17 03:00:34,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:34,571][root][INFO] - Training Epoch: 2/2, step 6101/7134 completed (loss: 0.07328513264656067, acc: 0.9861111044883728)
[2024-12-17 03:00:34,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:34,850][root][INFO] - Training Epoch: 2/2, step 6102/7134 completed (loss: 0.23309090733528137, acc: 0.9296875)
[2024-12-17 03:00:34,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:35,110][root][INFO] - Training Epoch: 2/2, step 6103/7134 completed (loss: 0.1521921008825302, acc: 0.9454545378684998)
[2024-12-17 03:00:35,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:35,359][root][INFO] - Training Epoch: 2/2, step 6104/7134 completed (loss: 0.252240926027298, acc: 0.9054054021835327)
[2024-12-17 03:00:35,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:35,640][root][INFO] - Training Epoch: 2/2, step 6105/7134 completed (loss: 0.5357105731964111, acc: 0.8969696760177612)
[2024-12-17 03:00:35,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:35,932][root][INFO] - Training Epoch: 2/2, step 6106/7134 completed (loss: 0.15745975077152252, acc: 0.960629940032959)
[2024-12-17 03:00:36,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:36,208][root][INFO] - Training Epoch: 2/2, step 6107/7134 completed (loss: 0.08698904514312744, acc: 0.9829059839248657)
[2024-12-17 03:00:36,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:36,465][root][INFO] - Training Epoch: 2/2, step 6108/7134 completed (loss: 0.23268426954746246, acc: 0.942148745059967)
[2024-12-17 03:00:36,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:36,719][root][INFO] - Training Epoch: 2/2, step 6109/7134 completed (loss: 0.06987614184617996, acc: 0.9739130139350891)
[2024-12-17 03:00:36,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:36,998][root][INFO] - Training Epoch: 2/2, step 6110/7134 completed (loss: 0.34738367795944214, acc: 0.9453125)
[2024-12-17 03:00:37,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:37,252][root][INFO] - Training Epoch: 2/2, step 6111/7134 completed (loss: 0.31829729676246643, acc: 0.945652186870575)
[2024-12-17 03:00:37,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:37,534][root][INFO] - Training Epoch: 2/2, step 6112/7134 completed (loss: 0.23933818936347961, acc: 0.9542483687400818)
[2024-12-17 03:00:37,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:37,813][root][INFO] - Training Epoch: 2/2, step 6113/7134 completed (loss: 0.27966853976249695, acc: 0.9634146094322205)
[2024-12-17 03:00:37,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:38,072][root][INFO] - Training Epoch: 2/2, step 6114/7134 completed (loss: 0.14728429913520813, acc: 0.9790209531784058)
[2024-12-17 03:00:38,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:38,318][root][INFO] - Training Epoch: 2/2, step 6115/7134 completed (loss: 0.15507908165454865, acc: 0.9520000219345093)
[2024-12-17 03:00:38,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:38,544][root][INFO] - Training Epoch: 2/2, step 6116/7134 completed (loss: 0.3107961118221283, acc: 0.9516128897666931)
[2024-12-17 03:00:38,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:38,823][root][INFO] - Training Epoch: 2/2, step 6117/7134 completed (loss: 0.27318987250328064, acc: 0.9341317415237427)
[2024-12-17 03:00:38,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:39,108][root][INFO] - Training Epoch: 2/2, step 6118/7134 completed (loss: 0.09521026164293289, acc: 0.9841269850730896)
[2024-12-17 03:00:39,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:39,394][root][INFO] - Training Epoch: 2/2, step 6119/7134 completed (loss: 0.16391170024871826, acc: 0.9567567706108093)
[2024-12-17 03:00:39,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:39,664][root][INFO] - Training Epoch: 2/2, step 6120/7134 completed (loss: 0.09419761598110199, acc: 0.9772727489471436)
[2024-12-17 03:00:39,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:39,945][root][INFO] - Training Epoch: 2/2, step 6121/7134 completed (loss: 0.22477014362812042, acc: 0.9527559280395508)
[2024-12-17 03:00:40,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:40,222][root][INFO] - Training Epoch: 2/2, step 6122/7134 completed (loss: 0.08406607061624527, acc: 0.975806474685669)
[2024-12-17 03:00:40,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:40,494][root][INFO] - Training Epoch: 2/2, step 6123/7134 completed (loss: 0.200281023979187, acc: 0.9658119678497314)
[2024-12-17 03:00:40,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:40,760][root][INFO] - Training Epoch: 2/2, step 6124/7134 completed (loss: 0.07470323890447617, acc: 0.9831932783126831)
[2024-12-17 03:00:40,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:41,055][root][INFO] - Training Epoch: 2/2, step 6125/7134 completed (loss: 0.4494490325450897, acc: 0.9345794320106506)
[2024-12-17 03:00:41,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:41,329][root][INFO] - Training Epoch: 2/2, step 6126/7134 completed (loss: 0.24768710136413574, acc: 0.9536423683166504)
[2024-12-17 03:00:41,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:41,565][root][INFO] - Training Epoch: 2/2, step 6127/7134 completed (loss: 0.03962205722928047, acc: 1.0)
[2024-12-17 03:00:41,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:41,829][root][INFO] - Training Epoch: 2/2, step 6128/7134 completed (loss: 0.13572537899017334, acc: 0.9831932783126831)
[2024-12-17 03:00:41,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:42,121][root][INFO] - Training Epoch: 2/2, step 6129/7134 completed (loss: 0.20067083835601807, acc: 0.9408283829689026)
[2024-12-17 03:00:42,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:42,423][root][INFO] - Training Epoch: 2/2, step 6130/7134 completed (loss: 0.22308887541294098, acc: 0.9253731369972229)
[2024-12-17 03:00:42,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:42,711][root][INFO] - Training Epoch: 2/2, step 6131/7134 completed (loss: 0.3135593831539154, acc: 0.9368932247161865)
[2024-12-17 03:00:42,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:42,990][root][INFO] - Training Epoch: 2/2, step 6132/7134 completed (loss: 0.2539713978767395, acc: 0.9294871687889099)
[2024-12-17 03:00:43,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:43,289][root][INFO] - Training Epoch: 2/2, step 6133/7134 completed (loss: 0.19850684702396393, acc: 0.9519230723381042)
[2024-12-17 03:00:43,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:43,567][root][INFO] - Training Epoch: 2/2, step 6134/7134 completed (loss: 0.2916978895664215, acc: 0.9306358098983765)
[2024-12-17 03:00:43,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:43,850][root][INFO] - Training Epoch: 2/2, step 6135/7134 completed (loss: 0.10934514552354813, acc: 0.9767441749572754)
[2024-12-17 03:00:43,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:44,144][root][INFO] - Training Epoch: 2/2, step 6136/7134 completed (loss: 0.20476412773132324, acc: 0.940119743347168)
[2024-12-17 03:00:44,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:44,413][root][INFO] - Training Epoch: 2/2, step 6137/7134 completed (loss: 0.24346640706062317, acc: 0.9350649118423462)
[2024-12-17 03:00:44,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:44,684][root][INFO] - Training Epoch: 2/2, step 6138/7134 completed (loss: 0.16927312314510345, acc: 0.9693251252174377)
[2024-12-17 03:00:44,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:44,964][root][INFO] - Training Epoch: 2/2, step 6139/7134 completed (loss: 0.26197391748428345, acc: 0.918367326259613)
[2024-12-17 03:00:45,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:45,264][root][INFO] - Training Epoch: 2/2, step 6140/7134 completed (loss: 0.16452330350875854, acc: 0.9692307710647583)
[2024-12-17 03:00:45,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:45,517][root][INFO] - Training Epoch: 2/2, step 6141/7134 completed (loss: 0.33090585470199585, acc: 0.8985507488250732)
[2024-12-17 03:00:45,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:45,796][root][INFO] - Training Epoch: 2/2, step 6142/7134 completed (loss: 0.14596673846244812, acc: 0.9714285731315613)
[2024-12-17 03:00:45,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:46,069][root][INFO] - Training Epoch: 2/2, step 6143/7134 completed (loss: 0.1471889317035675, acc: 0.9757575988769531)
[2024-12-17 03:00:46,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:46,329][root][INFO] - Training Epoch: 2/2, step 6144/7134 completed (loss: 0.15518707036972046, acc: 0.9520547986030579)
[2024-12-17 03:00:46,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:46,612][root][INFO] - Training Epoch: 2/2, step 6145/7134 completed (loss: 0.2707568407058716, acc: 0.9398906826972961)
[2024-12-17 03:00:46,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:46,874][root][INFO] - Training Epoch: 2/2, step 6146/7134 completed (loss: 0.22998076677322388, acc: 0.9457831382751465)
[2024-12-17 03:00:47,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:47,154][root][INFO] - Training Epoch: 2/2, step 6147/7134 completed (loss: 0.10506442934274673, acc: 0.9763779640197754)
[2024-12-17 03:00:47,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:47,445][root][INFO] - Training Epoch: 2/2, step 6148/7134 completed (loss: 0.1579442322254181, acc: 0.9379310607910156)
[2024-12-17 03:00:47,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:47,729][root][INFO] - Training Epoch: 2/2, step 6149/7134 completed (loss: 0.18904218077659607, acc: 0.9536423683166504)
[2024-12-17 03:00:47,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:48,010][root][INFO] - Training Epoch: 2/2, step 6150/7134 completed (loss: 0.16462582349777222, acc: 0.9370629191398621)
[2024-12-17 03:00:48,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:48,295][root][INFO] - Training Epoch: 2/2, step 6151/7134 completed (loss: 0.08968201279640198, acc: 0.993630588054657)
[2024-12-17 03:00:48,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:48,578][root][INFO] - Training Epoch: 2/2, step 6152/7134 completed (loss: 0.26578277349472046, acc: 0.9599999785423279)
[2024-12-17 03:00:48,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:48,860][root][INFO] - Training Epoch: 2/2, step 6153/7134 completed (loss: 0.11117173731327057, acc: 0.9691358208656311)
[2024-12-17 03:00:49,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:49,161][root][INFO] - Training Epoch: 2/2, step 6154/7134 completed (loss: 0.17468737065792084, acc: 0.9613259434700012)
[2024-12-17 03:00:49,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:49,450][root][INFO] - Training Epoch: 2/2, step 6155/7134 completed (loss: 0.13701939582824707, acc: 0.976331353187561)
[2024-12-17 03:00:49,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:49,715][root][INFO] - Training Epoch: 2/2, step 6156/7134 completed (loss: 0.09850213676691055, acc: 0.9810126423835754)
[2024-12-17 03:00:49,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:50,008][root][INFO] - Training Epoch: 2/2, step 6157/7134 completed (loss: 0.15101076662540436, acc: 0.9620253443717957)
[2024-12-17 03:00:50,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:50,297][root][INFO] - Training Epoch: 2/2, step 6158/7134 completed (loss: 0.1832585632801056, acc: 0.9385964870452881)
[2024-12-17 03:00:50,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:50,582][root][INFO] - Training Epoch: 2/2, step 6159/7134 completed (loss: 0.19449034333229065, acc: 0.9702380895614624)
[2024-12-17 03:00:50,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:50,863][root][INFO] - Training Epoch: 2/2, step 6160/7134 completed (loss: 0.3109298348426819, acc: 0.9108280539512634)
[2024-12-17 03:00:50,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:51,149][root][INFO] - Training Epoch: 2/2, step 6161/7134 completed (loss: 0.18034397065639496, acc: 0.9685039520263672)
[2024-12-17 03:00:51,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:51,437][root][INFO] - Training Epoch: 2/2, step 6162/7134 completed (loss: 0.3510068655014038, acc: 0.9230769276618958)
[2024-12-17 03:00:51,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:51,715][root][INFO] - Training Epoch: 2/2, step 6163/7134 completed (loss: 0.36458978056907654, acc: 0.9147287011146545)
[2024-12-17 03:00:51,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:52,010][root][INFO] - Training Epoch: 2/2, step 6164/7134 completed (loss: 0.23748525977134705, acc: 0.9390243887901306)
[2024-12-17 03:00:52,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:52,263][root][INFO] - Training Epoch: 2/2, step 6165/7134 completed (loss: 0.22493772208690643, acc: 0.9389312863349915)
[2024-12-17 03:00:52,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:52,525][root][INFO] - Training Epoch: 2/2, step 6166/7134 completed (loss: 0.15650755167007446, acc: 0.970802903175354)
[2024-12-17 03:00:52,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:52,791][root][INFO] - Training Epoch: 2/2, step 6167/7134 completed (loss: 0.08137207478284836, acc: 0.9883720874786377)
[2024-12-17 03:00:52,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:53,071][root][INFO] - Training Epoch: 2/2, step 6168/7134 completed (loss: 0.11423754692077637, acc: 0.9784946441650391)
[2024-12-17 03:00:53,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:53,342][root][INFO] - Training Epoch: 2/2, step 6169/7134 completed (loss: 0.14523157477378845, acc: 0.9819276928901672)
[2024-12-17 03:00:53,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:53,614][root][INFO] - Training Epoch: 2/2, step 6170/7134 completed (loss: 0.17660114169120789, acc: 0.9496402740478516)
[2024-12-17 03:00:53,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:53,895][root][INFO] - Training Epoch: 2/2, step 6171/7134 completed (loss: 0.056277453899383545, acc: 0.9890109896659851)
[2024-12-17 03:00:53,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:54,149][root][INFO] - Training Epoch: 2/2, step 6172/7134 completed (loss: 0.09565267711877823, acc: 0.96875)
[2024-12-17 03:00:54,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:54,415][root][INFO] - Training Epoch: 2/2, step 6173/7134 completed (loss: 0.12012434005737305, acc: 0.9551281929016113)
[2024-12-17 03:00:54,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:54,694][root][INFO] - Training Epoch: 2/2, step 6174/7134 completed (loss: 0.08293846994638443, acc: 0.9757575988769531)
[2024-12-17 03:00:54,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:54,967][root][INFO] - Training Epoch: 2/2, step 6175/7134 completed (loss: 0.13623575866222382, acc: 0.9691358208656311)
[2024-12-17 03:00:55,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:55,236][root][INFO] - Training Epoch: 2/2, step 6176/7134 completed (loss: 0.1038258969783783, acc: 0.9817073345184326)
[2024-12-17 03:00:55,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:55,511][root][INFO] - Training Epoch: 2/2, step 6177/7134 completed (loss: 0.08562576025724411, acc: 0.9780219793319702)
[2024-12-17 03:00:55,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:55,784][root][INFO] - Training Epoch: 2/2, step 6178/7134 completed (loss: 0.12126524746417999, acc: 0.9673202633857727)
[2024-12-17 03:00:55,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:56,058][root][INFO] - Training Epoch: 2/2, step 6179/7134 completed (loss: 0.17274460196495056, acc: 0.95333331823349)
[2024-12-17 03:00:56,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:56,337][root][INFO] - Training Epoch: 2/2, step 6180/7134 completed (loss: 0.5636150240898132, acc: 0.8723404407501221)
[2024-12-17 03:00:56,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:56,632][root][INFO] - Training Epoch: 2/2, step 6181/7134 completed (loss: 0.715446949005127, acc: 0.7777777910232544)
[2024-12-17 03:00:56,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:56,923][root][INFO] - Training Epoch: 2/2, step 6182/7134 completed (loss: 0.34783661365509033, acc: 0.9224806427955627)
[2024-12-17 03:00:57,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:57,203][root][INFO] - Training Epoch: 2/2, step 6183/7134 completed (loss: 0.49176648259162903, acc: 0.8765432238578796)
[2024-12-17 03:00:57,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:57,471][root][INFO] - Training Epoch: 2/2, step 6184/7134 completed (loss: 0.5647311806678772, acc: 0.886956512928009)
[2024-12-17 03:00:57,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:57,743][root][INFO] - Training Epoch: 2/2, step 6185/7134 completed (loss: 0.19909292459487915, acc: 0.9435483813285828)
[2024-12-17 03:00:57,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:58,001][root][INFO] - Training Epoch: 2/2, step 6186/7134 completed (loss: 0.13736391067504883, acc: 0.9694656729698181)
[2024-12-17 03:00:58,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:58,311][root][INFO] - Training Epoch: 2/2, step 6187/7134 completed (loss: 0.18499286472797394, acc: 0.9532163739204407)
[2024-12-17 03:00:58,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:58,596][root][INFO] - Training Epoch: 2/2, step 6188/7134 completed (loss: 0.20424233376979828, acc: 0.9542483687400818)
[2024-12-17 03:00:58,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:58,878][root][INFO] - Training Epoch: 2/2, step 6189/7134 completed (loss: 0.2769899368286133, acc: 0.9510489702224731)
[2024-12-17 03:00:59,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:59,155][root][INFO] - Training Epoch: 2/2, step 6190/7134 completed (loss: 0.359822541475296, acc: 0.9571428298950195)
[2024-12-17 03:00:59,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:59,428][root][INFO] - Training Epoch: 2/2, step 6191/7134 completed (loss: 0.15552471578121185, acc: 0.9512194991111755)
[2024-12-17 03:00:59,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:59,716][root][INFO] - Training Epoch: 2/2, step 6192/7134 completed (loss: 0.1451287865638733, acc: 0.9560975432395935)
[2024-12-17 03:00:59,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:59,998][root][INFO] - Training Epoch: 2/2, step 6193/7134 completed (loss: 0.2106301337480545, acc: 0.939393937587738)
[2024-12-17 03:01:00,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:00,269][root][INFO] - Training Epoch: 2/2, step 6194/7134 completed (loss: 0.1351621299982071, acc: 0.9590163826942444)
[2024-12-17 03:01:00,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:00,532][root][INFO] - Training Epoch: 2/2, step 6195/7134 completed (loss: 0.11705924570560455, acc: 0.9622641801834106)
[2024-12-17 03:01:00,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:00,806][root][INFO] - Training Epoch: 2/2, step 6196/7134 completed (loss: 0.10351138561964035, acc: 0.9506173133850098)
[2024-12-17 03:01:00,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:01,080][root][INFO] - Training Epoch: 2/2, step 6197/7134 completed (loss: 0.23501630127429962, acc: 0.9375)
[2024-12-17 03:01:01,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:01,338][root][INFO] - Training Epoch: 2/2, step 6198/7134 completed (loss: 0.12454590946435928, acc: 0.9469026327133179)
[2024-12-17 03:01:01,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:01,620][root][INFO] - Training Epoch: 2/2, step 6199/7134 completed (loss: 0.12753376364707947, acc: 0.9788359999656677)
[2024-12-17 03:01:01,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:01,898][root][INFO] - Training Epoch: 2/2, step 6200/7134 completed (loss: 0.07247202098369598, acc: 0.9846153855323792)
[2024-12-17 03:01:02,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:02,189][root][INFO] - Training Epoch: 2/2, step 6201/7134 completed (loss: 0.14319950342178345, acc: 0.9521530866622925)
[2024-12-17 03:01:02,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:02,457][root][INFO] - Training Epoch: 2/2, step 6202/7134 completed (loss: 0.18040169775485992, acc: 0.9714285731315613)
[2024-12-17 03:01:02,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:02,742][root][INFO] - Training Epoch: 2/2, step 6203/7134 completed (loss: 0.09637866169214249, acc: 0.9651162624359131)
[2024-12-17 03:01:02,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:03,024][root][INFO] - Training Epoch: 2/2, step 6204/7134 completed (loss: 0.036978013813495636, acc: 1.0)
[2024-12-17 03:01:03,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:03,294][root][INFO] - Training Epoch: 2/2, step 6205/7134 completed (loss: 0.09635195881128311, acc: 0.9784172773361206)
[2024-12-17 03:01:03,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:03,554][root][INFO] - Training Epoch: 2/2, step 6206/7134 completed (loss: 0.06191528961062431, acc: 0.9813664555549622)
[2024-12-17 03:01:03,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:03,885][root][INFO] - Training Epoch: 2/2, step 6207/7134 completed (loss: 0.4739523231983185, acc: 0.8787878751754761)
[2024-12-17 03:01:04,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:04,172][root][INFO] - Training Epoch: 2/2, step 6208/7134 completed (loss: 0.10826776176691055, acc: 0.96875)
[2024-12-17 03:01:04,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:04,486][root][INFO] - Training Epoch: 2/2, step 6209/7134 completed (loss: 0.10615392029285431, acc: 0.976190447807312)
[2024-12-17 03:01:04,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:04,826][root][INFO] - Training Epoch: 2/2, step 6210/7134 completed (loss: 0.1835351288318634, acc: 0.9358288645744324)
[2024-12-17 03:01:04,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:05,113][root][INFO] - Training Epoch: 2/2, step 6211/7134 completed (loss: 0.13200131058692932, acc: 0.9757575988769531)
[2024-12-17 03:01:05,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:05,375][root][INFO] - Training Epoch: 2/2, step 6212/7134 completed (loss: 0.07593217492103577, acc: 0.9829059839248657)
[2024-12-17 03:01:05,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:05,660][root][INFO] - Training Epoch: 2/2, step 6213/7134 completed (loss: 0.07216446846723557, acc: 0.9909090995788574)
[2024-12-17 03:01:05,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:05,948][root][INFO] - Training Epoch: 2/2, step 6214/7134 completed (loss: 0.08788207173347473, acc: 0.9774011373519897)
[2024-12-17 03:01:06,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:06,260][root][INFO] - Training Epoch: 2/2, step 6215/7134 completed (loss: 0.15196233987808228, acc: 0.9420289993286133)
[2024-12-17 03:01:06,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:06,531][root][INFO] - Training Epoch: 2/2, step 6216/7134 completed (loss: 0.049423180520534515, acc: 1.0)
[2024-12-17 03:01:06,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:06,798][root][INFO] - Training Epoch: 2/2, step 6217/7134 completed (loss: 0.053795043379068375, acc: 0.9873417615890503)
[2024-12-17 03:01:06,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:07,093][root][INFO] - Training Epoch: 2/2, step 6218/7134 completed (loss: 0.0926947072148323, acc: 0.9612902998924255)
[2024-12-17 03:01:07,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:07,374][root][INFO] - Training Epoch: 2/2, step 6219/7134 completed (loss: 0.11873235553503036, acc: 0.9673202633857727)
[2024-12-17 03:01:07,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:07,651][root][INFO] - Training Epoch: 2/2, step 6220/7134 completed (loss: 0.06577307730913162, acc: 1.0)
[2024-12-17 03:01:07,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:07,936][root][INFO] - Training Epoch: 2/2, step 6221/7134 completed (loss: 0.0230354443192482, acc: 0.9925373196601868)
[2024-12-17 03:01:08,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:08,202][root][INFO] - Training Epoch: 2/2, step 6222/7134 completed (loss: 0.26008450984954834, acc: 0.9397590160369873)
[2024-12-17 03:01:08,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:08,484][root][INFO] - Training Epoch: 2/2, step 6223/7134 completed (loss: 0.2693544328212738, acc: 0.9270833134651184)
[2024-12-17 03:01:08,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:08,770][root][INFO] - Training Epoch: 2/2, step 6224/7134 completed (loss: 0.08439462631940842, acc: 0.9594594836235046)
[2024-12-17 03:01:08,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:09,060][root][INFO] - Training Epoch: 2/2, step 6225/7134 completed (loss: 0.12367215752601624, acc: 0.9720670580863953)
[2024-12-17 03:01:09,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:09,336][root][INFO] - Training Epoch: 2/2, step 6226/7134 completed (loss: 0.2528683543205261, acc: 0.9510869383811951)
[2024-12-17 03:01:09,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:09,614][root][INFO] - Training Epoch: 2/2, step 6227/7134 completed (loss: 0.059128619730472565, acc: 0.9750000238418579)
[2024-12-17 03:01:09,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:09,892][root][INFO] - Training Epoch: 2/2, step 6228/7134 completed (loss: 0.1519138664007187, acc: 0.957446813583374)
[2024-12-17 03:01:10,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:10,181][root][INFO] - Training Epoch: 2/2, step 6229/7134 completed (loss: 0.3292017877101898, acc: 0.9317073225975037)
[2024-12-17 03:01:10,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:10,471][root][INFO] - Training Epoch: 2/2, step 6230/7134 completed (loss: 0.21571364998817444, acc: 0.936170220375061)
[2024-12-17 03:01:10,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:10,739][root][INFO] - Training Epoch: 2/2, step 6231/7134 completed (loss: 0.118781678378582, acc: 0.9707602262496948)
[2024-12-17 03:01:10,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:11,034][root][INFO] - Training Epoch: 2/2, step 6232/7134 completed (loss: 0.18141430616378784, acc: 0.9505494236946106)
[2024-12-17 03:01:11,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:11,313][root][INFO] - Training Epoch: 2/2, step 6233/7134 completed (loss: 0.12241405993700027, acc: 0.954023003578186)
[2024-12-17 03:01:11,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:11,602][root][INFO] - Training Epoch: 2/2, step 6234/7134 completed (loss: 0.19332700967788696, acc: 0.9555555582046509)
[2024-12-17 03:01:11,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:11,881][root][INFO] - Training Epoch: 2/2, step 6235/7134 completed (loss: 0.06390847265720367, acc: 0.9940476417541504)
[2024-12-17 03:01:12,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:12,166][root][INFO] - Training Epoch: 2/2, step 6236/7134 completed (loss: 0.17153453826904297, acc: 0.9553072452545166)
[2024-12-17 03:01:12,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:12,456][root][INFO] - Training Epoch: 2/2, step 6237/7134 completed (loss: 0.23322783410549164, acc: 0.9435028433799744)
[2024-12-17 03:01:12,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:12,733][root][INFO] - Training Epoch: 2/2, step 6238/7134 completed (loss: 0.13567887246608734, acc: 0.9735099077224731)
[2024-12-17 03:01:12,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:13,018][root][INFO] - Training Epoch: 2/2, step 6239/7134 completed (loss: 0.12287775427103043, acc: 0.9585492014884949)
[2024-12-17 03:01:13,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:13,293][root][INFO] - Training Epoch: 2/2, step 6240/7134 completed (loss: 0.03479357063770294, acc: 0.9939758777618408)
[2024-12-17 03:01:13,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:13,596][root][INFO] - Training Epoch: 2/2, step 6241/7134 completed (loss: 0.0723491981625557, acc: 0.9866666793823242)
[2024-12-17 03:01:13,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:13,872][root][INFO] - Training Epoch: 2/2, step 6242/7134 completed (loss: 0.08699972182512283, acc: 0.9591836929321289)
[2024-12-17 03:01:14,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:14,150][root][INFO] - Training Epoch: 2/2, step 6243/7134 completed (loss: 0.1785666048526764, acc: 0.9463087320327759)
[2024-12-17 03:01:14,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:14,424][root][INFO] - Training Epoch: 2/2, step 6244/7134 completed (loss: 0.14699223637580872, acc: 0.970059871673584)
[2024-12-17 03:01:14,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:14,704][root][INFO] - Training Epoch: 2/2, step 6245/7134 completed (loss: 0.12343605607748032, acc: 0.9644970297813416)
[2024-12-17 03:01:14,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:15,047][root][INFO] - Training Epoch: 2/2, step 6246/7134 completed (loss: 0.0448375940322876, acc: 0.9893048405647278)
[2024-12-17 03:01:15,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:15,340][root][INFO] - Training Epoch: 2/2, step 6247/7134 completed (loss: 0.13640522956848145, acc: 0.9728260636329651)
[2024-12-17 03:01:15,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:15,648][root][INFO] - Training Epoch: 2/2, step 6248/7134 completed (loss: 0.3309486508369446, acc: 0.9281437397003174)
[2024-12-17 03:01:15,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:15,917][root][INFO] - Training Epoch: 2/2, step 6249/7134 completed (loss: 0.012393859215080738, acc: 1.0)
[2024-12-17 03:01:16,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:16,204][root][INFO] - Training Epoch: 2/2, step 6250/7134 completed (loss: 0.011336637660861015, acc: 1.0)
[2024-12-17 03:01:16,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:16,494][root][INFO] - Training Epoch: 2/2, step 6251/7134 completed (loss: 0.12983541190624237, acc: 0.9668874144554138)
[2024-12-17 03:01:16,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:16,778][root][INFO] - Training Epoch: 2/2, step 6252/7134 completed (loss: 0.03324555605649948, acc: 0.9928571581840515)
[2024-12-17 03:01:16,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:17,081][root][INFO] - Training Epoch: 2/2, step 6253/7134 completed (loss: 0.05255848541855812, acc: 0.9860140085220337)
[2024-12-17 03:01:17,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:17,343][root][INFO] - Training Epoch: 2/2, step 6254/7134 completed (loss: 0.18350453674793243, acc: 0.9552238583564758)
[2024-12-17 03:01:17,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:17,624][root][INFO] - Training Epoch: 2/2, step 6255/7134 completed (loss: 0.11162600666284561, acc: 0.9602272510528564)
[2024-12-17 03:01:17,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:17,903][root][INFO] - Training Epoch: 2/2, step 6256/7134 completed (loss: 0.06477247923612595, acc: 0.9887005686759949)
[2024-12-17 03:01:18,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:18,193][root][INFO] - Training Epoch: 2/2, step 6257/7134 completed (loss: 0.07698515802621841, acc: 0.9822485446929932)
[2024-12-17 03:01:18,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:18,469][root][INFO] - Training Epoch: 2/2, step 6258/7134 completed (loss: 0.05769797042012215, acc: 0.9866666793823242)
[2024-12-17 03:01:18,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:18,754][root][INFO] - Training Epoch: 2/2, step 6259/7134 completed (loss: 0.04804978892207146, acc: 0.9875776171684265)
[2024-12-17 03:01:18,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:19,030][root][INFO] - Training Epoch: 2/2, step 6260/7134 completed (loss: 0.08410551398992538, acc: 0.9745222926139832)
[2024-12-17 03:01:19,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:19,346][root][INFO] - Training Epoch: 2/2, step 6261/7134 completed (loss: 0.05834177881479263, acc: 0.9813664555549622)
[2024-12-17 03:01:19,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:19,646][root][INFO] - Training Epoch: 2/2, step 6262/7134 completed (loss: 0.03513716161251068, acc: 0.9938271641731262)
[2024-12-17 03:01:19,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:19,943][root][INFO] - Training Epoch: 2/2, step 6263/7134 completed (loss: 0.024373013526201248, acc: 0.9935897588729858)
[2024-12-17 03:01:20,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:20,227][root][INFO] - Training Epoch: 2/2, step 6264/7134 completed (loss: 0.03624768927693367, acc: 0.9931507110595703)
[2024-12-17 03:01:20,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:20,519][root][INFO] - Training Epoch: 2/2, step 6265/7134 completed (loss: 0.04408472403883934, acc: 0.987730085849762)
[2024-12-17 03:01:20,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:20,784][root][INFO] - Training Epoch: 2/2, step 6266/7134 completed (loss: 0.021626973524689674, acc: 1.0)
[2024-12-17 03:01:20,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:21,061][root][INFO] - Training Epoch: 2/2, step 6267/7134 completed (loss: 0.047543060034513474, acc: 0.9934210777282715)
[2024-12-17 03:01:21,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:21,354][root][INFO] - Training Epoch: 2/2, step 6268/7134 completed (loss: 0.10402841866016388, acc: 0.9813664555549622)
[2024-12-17 03:01:21,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:21,640][root][INFO] - Training Epoch: 2/2, step 6269/7134 completed (loss: 0.055577535182237625, acc: 0.9910714030265808)
[2024-12-17 03:01:21,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:21,938][root][INFO] - Training Epoch: 2/2, step 6270/7134 completed (loss: 0.03789746016263962, acc: 0.9868420958518982)
[2024-12-17 03:01:22,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:22,217][root][INFO] - Training Epoch: 2/2, step 6271/7134 completed (loss: 0.11140773445367813, acc: 0.9829545617103577)
[2024-12-17 03:01:22,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:22,512][root][INFO] - Training Epoch: 2/2, step 6272/7134 completed (loss: 0.02011408843100071, acc: 0.9938650131225586)
[2024-12-17 03:01:22,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:22,800][root][INFO] - Training Epoch: 2/2, step 6273/7134 completed (loss: 0.029103334993124008, acc: 0.9881656765937805)
[2024-12-17 03:01:22,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:23,077][root][INFO] - Training Epoch: 2/2, step 6274/7134 completed (loss: 0.013010342605412006, acc: 1.0)
[2024-12-17 03:01:23,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:23,356][root][INFO] - Training Epoch: 2/2, step 6275/7134 completed (loss: 0.04094124957919121, acc: 1.0)
[2024-12-17 03:01:23,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:23,641][root][INFO] - Training Epoch: 2/2, step 6276/7134 completed (loss: 0.12203555554151535, acc: 0.9674796462059021)
[2024-12-17 03:01:23,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:23,921][root][INFO] - Training Epoch: 2/2, step 6277/7134 completed (loss: 0.2500518262386322, acc: 0.9245283007621765)
[2024-12-17 03:01:24,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:24,197][root][INFO] - Training Epoch: 2/2, step 6278/7134 completed (loss: 0.08840496093034744, acc: 0.970588207244873)
[2024-12-17 03:01:24,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:24,471][root][INFO] - Training Epoch: 2/2, step 6279/7134 completed (loss: 0.0711561068892479, acc: 0.9846153855323792)
[2024-12-17 03:01:24,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:24,743][root][INFO] - Training Epoch: 2/2, step 6280/7134 completed (loss: 0.07904697209596634, acc: 0.9776119589805603)
[2024-12-17 03:01:24,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:25,024][root][INFO] - Training Epoch: 2/2, step 6281/7134 completed (loss: 0.03804894536733627, acc: 0.9926470518112183)
[2024-12-17 03:01:25,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:25,310][root][INFO] - Training Epoch: 2/2, step 6282/7134 completed (loss: 0.05625849962234497, acc: 0.9861111044883728)
[2024-12-17 03:01:25,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:25,613][root][INFO] - Training Epoch: 2/2, step 6283/7134 completed (loss: 0.05716414377093315, acc: 0.991304337978363)
[2024-12-17 03:01:25,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:25,881][root][INFO] - Training Epoch: 2/2, step 6284/7134 completed (loss: 0.13251613080501556, acc: 0.9636363387107849)
[2024-12-17 03:01:26,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:26,160][root][INFO] - Training Epoch: 2/2, step 6285/7134 completed (loss: 0.15419435501098633, acc: 0.9473684430122375)
[2024-12-17 03:01:26,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:26,431][root][INFO] - Training Epoch: 2/2, step 6286/7134 completed (loss: 0.06528909504413605, acc: 0.9791666865348816)
[2024-12-17 03:01:26,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:26,707][root][INFO] - Training Epoch: 2/2, step 6287/7134 completed (loss: 0.04211018979549408, acc: 0.9924242496490479)
[2024-12-17 03:01:26,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:26,999][root][INFO] - Training Epoch: 2/2, step 6288/7134 completed (loss: 0.043281543999910355, acc: 0.9858155846595764)
[2024-12-17 03:01:27,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:27,280][root][INFO] - Training Epoch: 2/2, step 6289/7134 completed (loss: 0.045221030712127686, acc: 0.9848484992980957)
[2024-12-17 03:01:27,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:27,564][root][INFO] - Training Epoch: 2/2, step 6290/7134 completed (loss: 0.055801764130592346, acc: 0.9925373196601868)
[2024-12-17 03:01:27,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:27,843][root][INFO] - Training Epoch: 2/2, step 6291/7134 completed (loss: 0.03301549702882767, acc: 0.9924242496490479)
[2024-12-17 03:01:27,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:28,116][root][INFO] - Training Epoch: 2/2, step 6292/7134 completed (loss: 0.10813788324594498, acc: 0.9821428656578064)
[2024-12-17 03:01:28,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:28,403][root][INFO] - Training Epoch: 2/2, step 6293/7134 completed (loss: 0.11707773804664612, acc: 0.9575757384300232)
[2024-12-17 03:01:28,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:28,696][root][INFO] - Training Epoch: 2/2, step 6294/7134 completed (loss: 0.1945539265871048, acc: 0.9605262875556946)
[2024-12-17 03:01:28,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:28,967][root][INFO] - Training Epoch: 2/2, step 6295/7134 completed (loss: 0.05149051919579506, acc: 0.9924242496490479)
[2024-12-17 03:01:29,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:29,223][root][INFO] - Training Epoch: 2/2, step 6296/7134 completed (loss: 0.18485479056835175, acc: 0.9640287756919861)
[2024-12-17 03:01:29,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:29,497][root][INFO] - Training Epoch: 2/2, step 6297/7134 completed (loss: 0.14183950424194336, acc: 0.9624060392379761)
[2024-12-17 03:01:29,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:29,782][root][INFO] - Training Epoch: 2/2, step 6298/7134 completed (loss: 0.16065025329589844, acc: 0.9583333134651184)
[2024-12-17 03:01:29,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:30,074][root][INFO] - Training Epoch: 2/2, step 6299/7134 completed (loss: 0.1573760211467743, acc: 0.9605262875556946)
[2024-12-17 03:01:30,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:30,362][root][INFO] - Training Epoch: 2/2, step 6300/7134 completed (loss: 0.13423503935337067, acc: 0.9802631735801697)
[2024-12-17 03:01:30,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:30,656][root][INFO] - Training Epoch: 2/2, step 6301/7134 completed (loss: 0.03372769430279732, acc: 0.9907407164573669)
[2024-12-17 03:01:30,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:30,939][root][INFO] - Training Epoch: 2/2, step 6302/7134 completed (loss: 0.058113083243370056, acc: 0.9832402467727661)
[2024-12-17 03:01:31,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:31,236][root][INFO] - Training Epoch: 2/2, step 6303/7134 completed (loss: 0.06127139925956726, acc: 0.9730941653251648)
[2024-12-17 03:01:31,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:31,508][root][INFO] - Training Epoch: 2/2, step 6304/7134 completed (loss: 0.04420117288827896, acc: 0.9829545617103577)
[2024-12-17 03:01:31,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:31,779][root][INFO] - Training Epoch: 2/2, step 6305/7134 completed (loss: 0.1133584976196289, acc: 0.9794520735740662)
[2024-12-17 03:01:31,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:32,076][root][INFO] - Training Epoch: 2/2, step 6306/7134 completed (loss: 0.08737161010503769, acc: 0.971563994884491)
[2024-12-17 03:01:32,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:32,356][root][INFO] - Training Epoch: 2/2, step 6307/7134 completed (loss: 0.1555270105600357, acc: 0.9694656729698181)
[2024-12-17 03:01:32,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:32,640][root][INFO] - Training Epoch: 2/2, step 6308/7134 completed (loss: 0.10201166570186615, acc: 0.9792746305465698)
[2024-12-17 03:01:32,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:32,920][root][INFO] - Training Epoch: 2/2, step 6309/7134 completed (loss: 0.058485548943281174, acc: 0.9881656765937805)
[2024-12-17 03:01:33,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:33,198][root][INFO] - Training Epoch: 2/2, step 6310/7134 completed (loss: 0.24659723043441772, acc: 0.9385964870452881)
[2024-12-17 03:01:33,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:33,481][root][INFO] - Training Epoch: 2/2, step 6311/7134 completed (loss: 0.08424901217222214, acc: 0.96875)
[2024-12-17 03:01:33,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:33,753][root][INFO] - Training Epoch: 2/2, step 6312/7134 completed (loss: 0.060409076511859894, acc: 0.987261176109314)
[2024-12-17 03:01:33,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:34,048][root][INFO] - Training Epoch: 2/2, step 6313/7134 completed (loss: 0.05439842492341995, acc: 0.9837837815284729)
[2024-12-17 03:01:34,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:34,333][root][INFO] - Training Epoch: 2/2, step 6314/7134 completed (loss: 0.04336882755160332, acc: 0.9892473220825195)
[2024-12-17 03:01:34,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:34,606][root][INFO] - Training Epoch: 2/2, step 6315/7134 completed (loss: 0.1772642582654953, acc: 0.9664429426193237)
[2024-12-17 03:01:34,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:34,891][root][INFO] - Training Epoch: 2/2, step 6316/7134 completed (loss: 0.03842553496360779, acc: 0.9931034445762634)
[2024-12-17 03:01:35,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:35,194][root][INFO] - Training Epoch: 2/2, step 6317/7134 completed (loss: 0.047498881816864014, acc: 0.9932432174682617)
[2024-12-17 03:01:35,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:35,469][root][INFO] - Training Epoch: 2/2, step 6318/7134 completed (loss: 0.05438493564724922, acc: 0.9868420958518982)
[2024-12-17 03:01:35,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:35,754][root][INFO] - Training Epoch: 2/2, step 6319/7134 completed (loss: 0.05450790375471115, acc: 0.9733333587646484)
[2024-12-17 03:01:35,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:36,052][root][INFO] - Training Epoch: 2/2, step 6320/7134 completed (loss: 0.06311438232660294, acc: 0.9797297120094299)
[2024-12-17 03:01:36,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:36,328][root][INFO] - Training Epoch: 2/2, step 6321/7134 completed (loss: 0.03629935905337334, acc: 0.9857142567634583)
[2024-12-17 03:01:36,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:36,611][root][INFO] - Training Epoch: 2/2, step 6322/7134 completed (loss: 0.09286549687385559, acc: 0.9681528806686401)
[2024-12-17 03:01:36,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:36,900][root][INFO] - Training Epoch: 2/2, step 6323/7134 completed (loss: 0.07263661921024323, acc: 0.987500011920929)
[2024-12-17 03:01:37,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:37,221][root][INFO] - Training Epoch: 2/2, step 6324/7134 completed (loss: 0.15408603847026825, acc: 0.9672130942344666)
[2024-12-17 03:01:37,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:37,505][root][INFO] - Training Epoch: 2/2, step 6325/7134 completed (loss: 0.2026209533214569, acc: 0.9516128897666931)
[2024-12-17 03:01:37,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:37,803][root][INFO] - Training Epoch: 2/2, step 6326/7134 completed (loss: 0.1377192884683609, acc: 0.955974817276001)
[2024-12-17 03:01:37,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:38,076][root][INFO] - Training Epoch: 2/2, step 6327/7134 completed (loss: 0.03426321595907211, acc: 1.0)
[2024-12-17 03:01:38,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:38,367][root][INFO] - Training Epoch: 2/2, step 6328/7134 completed (loss: 0.12784989178180695, acc: 0.95652174949646)
[2024-12-17 03:01:38,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:38,653][root][INFO] - Training Epoch: 2/2, step 6329/7134 completed (loss: 0.0850394070148468, acc: 0.9807692170143127)
[2024-12-17 03:01:38,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:38,935][root][INFO] - Training Epoch: 2/2, step 6330/7134 completed (loss: 0.11070867627859116, acc: 0.9716981053352356)
[2024-12-17 03:01:39,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:39,217][root][INFO] - Training Epoch: 2/2, step 6331/7134 completed (loss: 0.022520843893289566, acc: 1.0)
[2024-12-17 03:01:39,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:39,515][root][INFO] - Training Epoch: 2/2, step 6332/7134 completed (loss: 0.15683740377426147, acc: 0.9432623982429504)
[2024-12-17 03:01:39,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:39,795][root][INFO] - Training Epoch: 2/2, step 6333/7134 completed (loss: 0.16385981440544128, acc: 0.9482758641242981)
[2024-12-17 03:01:39,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:40,064][root][INFO] - Training Epoch: 2/2, step 6334/7134 completed (loss: 0.04506124556064606, acc: 0.9852941036224365)
[2024-12-17 03:01:40,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:40,367][root][INFO] - Training Epoch: 2/2, step 6335/7134 completed (loss: 0.031120333820581436, acc: 0.993630588054657)
[2024-12-17 03:01:40,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:40,664][root][INFO] - Training Epoch: 2/2, step 6336/7134 completed (loss: 0.08397343754768372, acc: 0.9649122953414917)
[2024-12-17 03:01:40,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:40,958][root][INFO] - Training Epoch: 2/2, step 6337/7134 completed (loss: 0.05200014263391495, acc: 0.9860140085220337)
[2024-12-17 03:01:41,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:41,259][root][INFO] - Training Epoch: 2/2, step 6338/7134 completed (loss: 0.08437094837427139, acc: 0.9811320900917053)
[2024-12-17 03:01:41,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:41,560][root][INFO] - Training Epoch: 2/2, step 6339/7134 completed (loss: 0.04806866869330406, acc: 1.0)
[2024-12-17 03:01:41,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:41,864][root][INFO] - Training Epoch: 2/2, step 6340/7134 completed (loss: 0.041360195726156235, acc: 0.987730085849762)
[2024-12-17 03:01:41,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:42,149][root][INFO] - Training Epoch: 2/2, step 6341/7134 completed (loss: 0.0889669731259346, acc: 0.9842519760131836)
[2024-12-17 03:01:42,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:42,463][root][INFO] - Training Epoch: 2/2, step 6342/7134 completed (loss: 0.07127518206834793, acc: 0.9826589822769165)
[2024-12-17 03:01:42,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:42,770][root][INFO] - Training Epoch: 2/2, step 6343/7134 completed (loss: 0.11630609631538391, acc: 0.9726027250289917)
[2024-12-17 03:01:42,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:43,090][root][INFO] - Training Epoch: 2/2, step 6344/7134 completed (loss: 0.11817681044340134, acc: 0.9723756909370422)
[2024-12-17 03:01:43,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:43,403][root][INFO] - Training Epoch: 2/2, step 6345/7134 completed (loss: 0.10007762908935547, acc: 0.9728260636329651)
[2024-12-17 03:01:43,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:43,683][root][INFO] - Training Epoch: 2/2, step 6346/7134 completed (loss: 0.2787570655345917, acc: 0.9476743936538696)
[2024-12-17 03:01:43,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:43,950][root][INFO] - Training Epoch: 2/2, step 6347/7134 completed (loss: 0.18387532234191895, acc: 0.9579831957817078)
[2024-12-17 03:01:44,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:44,235][root][INFO] - Training Epoch: 2/2, step 6348/7134 completed (loss: 0.0644611120223999, acc: 0.9861111044883728)
[2024-12-17 03:01:44,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:44,513][root][INFO] - Training Epoch: 2/2, step 6349/7134 completed (loss: 0.05798393115401268, acc: 0.9848484992980957)
[2024-12-17 03:01:44,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:44,800][root][INFO] - Training Epoch: 2/2, step 6350/7134 completed (loss: 0.19386251270771027, acc: 0.9417989253997803)
[2024-12-17 03:01:44,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:45,095][root][INFO] - Training Epoch: 2/2, step 6351/7134 completed (loss: 0.18551002442836761, acc: 0.940119743347168)
[2024-12-17 03:01:45,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:45,386][root][INFO] - Training Epoch: 2/2, step 6352/7134 completed (loss: 0.30812063813209534, acc: 0.913294792175293)
[2024-12-17 03:01:45,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:45,687][root][INFO] - Training Epoch: 2/2, step 6353/7134 completed (loss: 0.16547691822052002, acc: 0.9570552110671997)
[2024-12-17 03:01:45,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:46,009][root][INFO] - Training Epoch: 2/2, step 6354/7134 completed (loss: 0.0907517597079277, acc: 0.982758641242981)
[2024-12-17 03:01:46,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:46,312][root][INFO] - Training Epoch: 2/2, step 6355/7134 completed (loss: 0.02989681251347065, acc: 0.9933333396911621)
[2024-12-17 03:01:46,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:46,593][root][INFO] - Training Epoch: 2/2, step 6356/7134 completed (loss: 0.08336293697357178, acc: 0.9681528806686401)
[2024-12-17 03:01:46,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:46,879][root][INFO] - Training Epoch: 2/2, step 6357/7134 completed (loss: 0.08656853437423706, acc: 0.9757575988769531)
[2024-12-17 03:01:46,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:47,174][root][INFO] - Training Epoch: 2/2, step 6358/7134 completed (loss: 0.1516859531402588, acc: 0.9707602262496948)
[2024-12-17 03:01:47,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:47,448][root][INFO] - Training Epoch: 2/2, step 6359/7134 completed (loss: 0.17261330783367157, acc: 0.9720670580863953)
[2024-12-17 03:01:47,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:47,722][root][INFO] - Training Epoch: 2/2, step 6360/7134 completed (loss: 0.13218814134597778, acc: 0.9591836929321289)
[2024-12-17 03:01:47,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:48,011][root][INFO] - Training Epoch: 2/2, step 6361/7134 completed (loss: 0.1747824102640152, acc: 0.9640287756919861)
[2024-12-17 03:01:48,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:48,315][root][INFO] - Training Epoch: 2/2, step 6362/7134 completed (loss: 0.08123551309108734, acc: 0.9870967864990234)
[2024-12-17 03:01:48,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:48,601][root][INFO] - Training Epoch: 2/2, step 6363/7134 completed (loss: 0.18046502768993378, acc: 0.9644970297813416)
[2024-12-17 03:01:48,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:48,888][root][INFO] - Training Epoch: 2/2, step 6364/7134 completed (loss: 0.08244860917329788, acc: 0.9745222926139832)
[2024-12-17 03:01:49,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:49,157][root][INFO] - Training Epoch: 2/2, step 6365/7134 completed (loss: 0.06571102887392044, acc: 1.0)
[2024-12-17 03:01:49,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:49,441][root][INFO] - Training Epoch: 2/2, step 6366/7134 completed (loss: 0.16630229353904724, acc: 0.9704142212867737)
[2024-12-17 03:01:49,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:49,720][root][INFO] - Training Epoch: 2/2, step 6367/7134 completed (loss: 0.0964561402797699, acc: 0.961240291595459)
[2024-12-17 03:01:49,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:50,001][root][INFO] - Training Epoch: 2/2, step 6368/7134 completed (loss: 0.11335039883852005, acc: 0.9819276928901672)
[2024-12-17 03:01:50,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:50,289][root][INFO] - Training Epoch: 2/2, step 6369/7134 completed (loss: 0.12836052477359772, acc: 0.9702380895614624)
[2024-12-17 03:01:50,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:50,584][root][INFO] - Training Epoch: 2/2, step 6370/7134 completed (loss: 0.3226144015789032, acc: 0.9186046719551086)
[2024-12-17 03:01:50,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:50,858][root][INFO] - Training Epoch: 2/2, step 6371/7134 completed (loss: 0.20382004976272583, acc: 0.9477124214172363)
[2024-12-17 03:01:50,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:51,131][root][INFO] - Training Epoch: 2/2, step 6372/7134 completed (loss: 0.26172664761543274, acc: 0.9137930870056152)
[2024-12-17 03:01:51,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:51,393][root][INFO] - Training Epoch: 2/2, step 6373/7134 completed (loss: 0.3181016743183136, acc: 0.8951612710952759)
[2024-12-17 03:01:51,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:51,688][root][INFO] - Training Epoch: 2/2, step 6374/7134 completed (loss: 0.10376288741827011, acc: 0.9831932783126831)
[2024-12-17 03:01:51,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:51,990][root][INFO] - Training Epoch: 2/2, step 6375/7134 completed (loss: 0.1303415298461914, acc: 0.9668508172035217)
[2024-12-17 03:01:52,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:52,262][root][INFO] - Training Epoch: 2/2, step 6376/7134 completed (loss: 0.05355921760201454, acc: 0.9756097793579102)
[2024-12-17 03:01:52,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:52,532][root][INFO] - Training Epoch: 2/2, step 6377/7134 completed (loss: 0.10967104136943817, acc: 0.9760000109672546)
[2024-12-17 03:01:52,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:52,823][root][INFO] - Training Epoch: 2/2, step 6378/7134 completed (loss: 0.17248089611530304, acc: 0.9488372206687927)
[2024-12-17 03:01:52,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:53,093][root][INFO] - Training Epoch: 2/2, step 6379/7134 completed (loss: 0.13996906578540802, acc: 0.9736841917037964)
[2024-12-17 03:01:53,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:53,390][root][INFO] - Training Epoch: 2/2, step 6380/7134 completed (loss: 0.11626537144184113, acc: 0.981249988079071)
[2024-12-17 03:01:53,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:53,661][root][INFO] - Training Epoch: 2/2, step 6381/7134 completed (loss: 0.03334526717662811, acc: 0.9932432174682617)
[2024-12-17 03:01:53,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:53,945][root][INFO] - Training Epoch: 2/2, step 6382/7134 completed (loss: 0.0846329852938652, acc: 0.9615384340286255)
[2024-12-17 03:01:54,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:54,222][root][INFO] - Training Epoch: 2/2, step 6383/7134 completed (loss: 0.27235904335975647, acc: 0.9479768872261047)
[2024-12-17 03:01:54,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:54,489][root][INFO] - Training Epoch: 2/2, step 6384/7134 completed (loss: 0.06738759577274323, acc: 0.9873417615890503)
[2024-12-17 03:01:54,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:54,781][root][INFO] - Training Epoch: 2/2, step 6385/7134 completed (loss: 0.16545814275741577, acc: 0.9609755873680115)
[2024-12-17 03:01:54,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:55,071][root][INFO] - Training Epoch: 2/2, step 6386/7134 completed (loss: 0.14026561379432678, acc: 0.9623655676841736)
[2024-12-17 03:01:55,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:55,345][root][INFO] - Training Epoch: 2/2, step 6387/7134 completed (loss: 0.10131378471851349, acc: 0.9878787994384766)
[2024-12-17 03:01:55,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:55,647][root][INFO] - Training Epoch: 2/2, step 6388/7134 completed (loss: 0.13320934772491455, acc: 0.9683544039726257)
[2024-12-17 03:01:55,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:55,960][root][INFO] - Training Epoch: 2/2, step 6389/7134 completed (loss: 0.14260868728160858, acc: 0.9711538553237915)
[2024-12-17 03:01:56,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:56,256][root][INFO] - Training Epoch: 2/2, step 6390/7134 completed (loss: 0.10697714984416962, acc: 0.97826087474823)
[2024-12-17 03:01:56,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:56,520][root][INFO] - Training Epoch: 2/2, step 6391/7134 completed (loss: 0.19928160309791565, acc: 0.9593023061752319)
[2024-12-17 03:01:56,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:56,809][root][INFO] - Training Epoch: 2/2, step 6392/7134 completed (loss: 0.22512027621269226, acc: 0.95652174949646)
[2024-12-17 03:01:56,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:57,095][root][INFO] - Training Epoch: 2/2, step 6393/7134 completed (loss: 0.09579212218523026, acc: 0.9768518805503845)
[2024-12-17 03:01:57,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:57,368][root][INFO] - Training Epoch: 2/2, step 6394/7134 completed (loss: 0.20395328104496002, acc: 0.9666666388511658)
[2024-12-17 03:01:57,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:57,654][root][INFO] - Training Epoch: 2/2, step 6395/7134 completed (loss: 0.13370196521282196, acc: 0.9702970385551453)
[2024-12-17 03:01:57,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:57,931][root][INFO] - Training Epoch: 2/2, step 6396/7134 completed (loss: 0.08338693529367447, acc: 0.9760765433311462)
[2024-12-17 03:01:58,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:58,214][root][INFO] - Training Epoch: 2/2, step 6397/7134 completed (loss: 0.07449747622013092, acc: 0.9800994992256165)
[2024-12-17 03:01:58,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:58,500][root][INFO] - Training Epoch: 2/2, step 6398/7134 completed (loss: 0.08340530097484589, acc: 0.9931034445762634)
[2024-12-17 03:01:58,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:58,780][root][INFO] - Training Epoch: 2/2, step 6399/7134 completed (loss: 0.10379084199666977, acc: 0.9775280952453613)
[2024-12-17 03:01:58,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:59,068][root][INFO] - Training Epoch: 2/2, step 6400/7134 completed (loss: 0.057708486914634705, acc: 0.9759036302566528)
[2024-12-17 03:01:59,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:59,369][root][INFO] - Training Epoch: 2/2, step 6401/7134 completed (loss: 0.06760741770267487, acc: 0.9857142567634583)
[2024-12-17 03:01:59,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:59,675][root][INFO] - Training Epoch: 2/2, step 6402/7134 completed (loss: 0.19002573192119598, acc: 0.9646464586257935)
[2024-12-17 03:01:59,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:59,956][root][INFO] - Training Epoch: 2/2, step 6403/7134 completed (loss: 0.025205574929714203, acc: 1.0)
[2024-12-17 03:02:00,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:00,259][root][INFO] - Training Epoch: 2/2, step 6404/7134 completed (loss: 0.07491965591907501, acc: 0.9822485446929932)
[2024-12-17 03:02:00,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:00,630][root][INFO] - Training Epoch: 2/2, step 6405/7134 completed (loss: 0.10329453647136688, acc: 0.9759615659713745)
[2024-12-17 03:02:00,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:00,929][root][INFO] - Training Epoch: 2/2, step 6406/7134 completed (loss: 0.1329050362110138, acc: 0.9599999785423279)
[2024-12-17 03:02:01,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:01,247][root][INFO] - Training Epoch: 2/2, step 6407/7134 completed (loss: 0.103682741522789, acc: 0.9722222089767456)
[2024-12-17 03:02:01,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:01,534][root][INFO] - Training Epoch: 2/2, step 6408/7134 completed (loss: 0.24766388535499573, acc: 0.9166666865348816)
[2024-12-17 03:02:01,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:01,804][root][INFO] - Training Epoch: 2/2, step 6409/7134 completed (loss: 0.1604030430316925, acc: 0.9817073345184326)
[2024-12-17 03:02:01,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:02,077][root][INFO] - Training Epoch: 2/2, step 6410/7134 completed (loss: 0.20833037793636322, acc: 0.949999988079071)
[2024-12-17 03:02:02,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:02,331][root][INFO] - Training Epoch: 2/2, step 6411/7134 completed (loss: 0.18572162091732025, acc: 0.9689922332763672)
[2024-12-17 03:02:02,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:02,593][root][INFO] - Training Epoch: 2/2, step 6412/7134 completed (loss: 0.06091316416859627, acc: 0.9741935729980469)
[2024-12-17 03:02:02,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:02,881][root][INFO] - Training Epoch: 2/2, step 6413/7134 completed (loss: 0.17684820294380188, acc: 0.9798657894134521)
[2024-12-17 03:02:03,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:03,136][root][INFO] - Training Epoch: 2/2, step 6414/7134 completed (loss: 0.06879245489835739, acc: 0.9736841917037964)
[2024-12-17 03:02:03,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:03,439][root][INFO] - Training Epoch: 2/2, step 6415/7134 completed (loss: 0.06793314963579178, acc: 0.9772727489471436)
[2024-12-17 03:02:03,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:03,730][root][INFO] - Training Epoch: 2/2, step 6416/7134 completed (loss: 0.19600260257720947, acc: 0.95652174949646)
[2024-12-17 03:02:03,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:04,011][root][INFO] - Training Epoch: 2/2, step 6417/7134 completed (loss: 0.304365873336792, acc: 0.9534883499145508)
[2024-12-17 03:02:04,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:04,297][root][INFO] - Training Epoch: 2/2, step 6418/7134 completed (loss: 0.47772544622421265, acc: 0.8791946172714233)
[2024-12-17 03:02:04,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:04,588][root][INFO] - Training Epoch: 2/2, step 6419/7134 completed (loss: 0.2659464478492737, acc: 0.9350649118423462)
[2024-12-17 03:02:04,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:04,874][root][INFO] - Training Epoch: 2/2, step 6420/7134 completed (loss: 0.18584345281124115, acc: 0.9430379867553711)
[2024-12-17 03:02:04,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:05,144][root][INFO] - Training Epoch: 2/2, step 6421/7134 completed (loss: 0.1862577348947525, acc: 0.9638554453849792)
[2024-12-17 03:02:05,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:05,424][root][INFO] - Training Epoch: 2/2, step 6422/7134 completed (loss: 0.1892075091600418, acc: 0.9497206807136536)
[2024-12-17 03:02:05,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:05,708][root][INFO] - Training Epoch: 2/2, step 6423/7134 completed (loss: 0.2176380455493927, acc: 0.9487179517745972)
[2024-12-17 03:02:05,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:05,999][root][INFO] - Training Epoch: 2/2, step 6424/7134 completed (loss: 0.18091578781604767, acc: 0.9468085169792175)
[2024-12-17 03:02:06,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:06,291][root][INFO] - Training Epoch: 2/2, step 6425/7134 completed (loss: 0.15689346194267273, acc: 0.9553072452545166)
[2024-12-17 03:02:06,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:06,584][root][INFO] - Training Epoch: 2/2, step 6426/7134 completed (loss: 0.15227057039737701, acc: 0.9720670580863953)
[2024-12-17 03:02:06,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:06,863][root][INFO] - Training Epoch: 2/2, step 6427/7134 completed (loss: 0.17015917599201202, acc: 0.9490445852279663)
[2024-12-17 03:02:07,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:07,152][root][INFO] - Training Epoch: 2/2, step 6428/7134 completed (loss: 0.10507448762655258, acc: 0.9745222926139832)
[2024-12-17 03:02:07,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:07,426][root][INFO] - Training Epoch: 2/2, step 6429/7134 completed (loss: 0.055033762007951736, acc: 0.9935483932495117)
[2024-12-17 03:02:07,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:07,713][root][INFO] - Training Epoch: 2/2, step 6430/7134 completed (loss: 0.22280196845531464, acc: 0.956250011920929)
[2024-12-17 03:02:07,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:07,989][root][INFO] - Training Epoch: 2/2, step 6431/7134 completed (loss: 0.252108633518219, acc: 0.9351351261138916)
[2024-12-17 03:02:08,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:08,258][root][INFO] - Training Epoch: 2/2, step 6432/7134 completed (loss: 0.7072397470474243, acc: 0.85161292552948)
[2024-12-17 03:02:08,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:08,547][root][INFO] - Training Epoch: 2/2, step 6433/7134 completed (loss: 0.3485639989376068, acc: 0.9261363744735718)
[2024-12-17 03:02:08,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:08,826][root][INFO] - Training Epoch: 2/2, step 6434/7134 completed (loss: 0.06044977158308029, acc: 0.9942196607589722)
[2024-12-17 03:02:08,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:09,110][root][INFO] - Training Epoch: 2/2, step 6435/7134 completed (loss: 0.08816904574632645, acc: 0.9710144996643066)
[2024-12-17 03:02:09,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:09,395][root][INFO] - Training Epoch: 2/2, step 6436/7134 completed (loss: 0.15426485240459442, acc: 0.9597315192222595)
[2024-12-17 03:02:09,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:09,714][root][INFO] - Training Epoch: 2/2, step 6437/7134 completed (loss: 0.2674165666103363, acc: 0.9473684430122375)
[2024-12-17 03:02:09,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:10,012][root][INFO] - Training Epoch: 2/2, step 6438/7134 completed (loss: 0.30007922649383545, acc: 0.9223300814628601)
[2024-12-17 03:02:10,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:10,303][root][INFO] - Training Epoch: 2/2, step 6439/7134 completed (loss: 0.11324414610862732, acc: 0.9627329111099243)
[2024-12-17 03:02:10,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:10,613][root][INFO] - Training Epoch: 2/2, step 6440/7134 completed (loss: 0.1532055288553238, acc: 0.9519230723381042)
[2024-12-17 03:02:10,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:10,887][root][INFO] - Training Epoch: 2/2, step 6441/7134 completed (loss: 0.09786656498908997, acc: 0.9748427867889404)
[2024-12-17 03:02:11,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:11,186][root][INFO] - Training Epoch: 2/2, step 6442/7134 completed (loss: 0.09474273025989532, acc: 0.9757281541824341)
[2024-12-17 03:02:11,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:11,470][root][INFO] - Training Epoch: 2/2, step 6443/7134 completed (loss: 0.05269937589764595, acc: 0.9901960492134094)
[2024-12-17 03:02:11,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:11,762][root][INFO] - Training Epoch: 2/2, step 6444/7134 completed (loss: 0.17077572643756866, acc: 0.949999988079071)
[2024-12-17 03:02:11,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:12,050][root][INFO] - Training Epoch: 2/2, step 6445/7134 completed (loss: 0.22720050811767578, acc: 0.9556650519371033)
[2024-12-17 03:02:12,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:12,329][root][INFO] - Training Epoch: 2/2, step 6446/7134 completed (loss: 0.08412204682826996, acc: 0.9803921580314636)
[2024-12-17 03:02:12,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:12,623][root][INFO] - Training Epoch: 2/2, step 6447/7134 completed (loss: 0.15558810532093048, acc: 0.9583333134651184)
[2024-12-17 03:02:12,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:12,894][root][INFO] - Training Epoch: 2/2, step 6448/7134 completed (loss: 0.3936004340648651, acc: 0.9096774458885193)
[2024-12-17 03:02:12,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:13,174][root][INFO] - Training Epoch: 2/2, step 6449/7134 completed (loss: 0.13293927907943726, acc: 0.9792746305465698)
[2024-12-17 03:02:13,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:13,455][root][INFO] - Training Epoch: 2/2, step 6450/7134 completed (loss: 0.17596815526485443, acc: 0.9653179049491882)
[2024-12-17 03:02:13,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:13,777][root][INFO] - Training Epoch: 2/2, step 6451/7134 completed (loss: 0.1860964000225067, acc: 0.9495798349380493)
[2024-12-17 03:02:13,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:14,049][root][INFO] - Training Epoch: 2/2, step 6452/7134 completed (loss: 0.049992069602012634, acc: 0.9846938848495483)
[2024-12-17 03:02:14,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:14,322][root][INFO] - Training Epoch: 2/2, step 6453/7134 completed (loss: 0.12553614377975464, acc: 0.9693251252174377)
[2024-12-17 03:02:14,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:14,611][root][INFO] - Training Epoch: 2/2, step 6454/7134 completed (loss: 0.14333677291870117, acc: 0.9726775884628296)
[2024-12-17 03:02:14,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:14,882][root][INFO] - Training Epoch: 2/2, step 6455/7134 completed (loss: 0.25306132435798645, acc: 0.9399999976158142)
[2024-12-17 03:02:15,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:15,182][root][INFO] - Training Epoch: 2/2, step 6456/7134 completed (loss: 0.28896620869636536, acc: 0.940119743347168)
[2024-12-17 03:02:15,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:15,474][root][INFO] - Training Epoch: 2/2, step 6457/7134 completed (loss: 0.12408342212438583, acc: 0.9724770784378052)
[2024-12-17 03:02:15,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:15,732][root][INFO] - Training Epoch: 2/2, step 6458/7134 completed (loss: 0.05485464259982109, acc: 0.9864864945411682)
[2024-12-17 03:02:15,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:15,988][root][INFO] - Training Epoch: 2/2, step 6459/7134 completed (loss: 0.01877124235033989, acc: 0.9938650131225586)
[2024-12-17 03:02:16,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:16,267][root][INFO] - Training Epoch: 2/2, step 6460/7134 completed (loss: 0.052048251032829285, acc: 0.9897959232330322)
[2024-12-17 03:02:16,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:16,535][root][INFO] - Training Epoch: 2/2, step 6461/7134 completed (loss: 0.05453653261065483, acc: 0.9826589822769165)
[2024-12-17 03:02:16,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:16,792][root][INFO] - Training Epoch: 2/2, step 6462/7134 completed (loss: 0.08519978076219559, acc: 0.978723406791687)
[2024-12-17 03:02:16,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:17,080][root][INFO] - Training Epoch: 2/2, step 6463/7134 completed (loss: 0.09980258345603943, acc: 0.9708737730979919)
[2024-12-17 03:02:17,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:17,354][root][INFO] - Training Epoch: 2/2, step 6464/7134 completed (loss: 0.07470981031656265, acc: 0.9832402467727661)
[2024-12-17 03:02:17,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:17,624][root][INFO] - Training Epoch: 2/2, step 6465/7134 completed (loss: 0.03939779847860336, acc: 0.994535505771637)
[2024-12-17 03:02:17,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:17,914][root][INFO] - Training Epoch: 2/2, step 6466/7134 completed (loss: 0.09166993945837021, acc: 0.9629629850387573)
[2024-12-17 03:02:18,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:18,206][root][INFO] - Training Epoch: 2/2, step 6467/7134 completed (loss: 0.15269432961940765, acc: 0.9578313231468201)
[2024-12-17 03:02:18,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:18,500][root][INFO] - Training Epoch: 2/2, step 6468/7134 completed (loss: 0.08323363959789276, acc: 0.9926470518112183)
[2024-12-17 03:02:18,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:18,799][root][INFO] - Training Epoch: 2/2, step 6469/7134 completed (loss: 0.2032652348279953, acc: 0.9672897458076477)
[2024-12-17 03:02:18,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:19,075][root][INFO] - Training Epoch: 2/2, step 6470/7134 completed (loss: 0.14086462557315826, acc: 0.9509803652763367)
[2024-12-17 03:02:19,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:19,365][root][INFO] - Training Epoch: 2/2, step 6471/7134 completed (loss: 0.06764090806245804, acc: 0.9856114983558655)
[2024-12-17 03:02:19,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:19,661][root][INFO] - Training Epoch: 2/2, step 6472/7134 completed (loss: 0.1472591757774353, acc: 0.9599999785423279)
[2024-12-17 03:02:19,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:19,957][root][INFO] - Training Epoch: 2/2, step 6473/7134 completed (loss: 0.06074679642915726, acc: 0.9944444298744202)
[2024-12-17 03:02:20,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:20,238][root][INFO] - Training Epoch: 2/2, step 6474/7134 completed (loss: 0.1110195443034172, acc: 0.9677419066429138)
[2024-12-17 03:02:20,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:20,488][root][INFO] - Training Epoch: 2/2, step 6475/7134 completed (loss: 0.11598964780569077, acc: 0.9642857313156128)
[2024-12-17 03:02:20,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:20,742][root][INFO] - Training Epoch: 2/2, step 6476/7134 completed (loss: 0.06954757124185562, acc: 0.9666666388511658)
[2024-12-17 03:02:20,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:21,001][root][INFO] - Training Epoch: 2/2, step 6477/7134 completed (loss: 0.1137857437133789, acc: 0.9826086759567261)
[2024-12-17 03:02:21,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:21,278][root][INFO] - Training Epoch: 2/2, step 6478/7134 completed (loss: 0.09306024760007858, acc: 0.9710144996643066)
[2024-12-17 03:02:21,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:21,562][root][INFO] - Training Epoch: 2/2, step 6479/7134 completed (loss: 0.08532649278640747, acc: 0.9664429426193237)
[2024-12-17 03:02:21,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:21,832][root][INFO] - Training Epoch: 2/2, step 6480/7134 completed (loss: 0.07543209940195084, acc: 0.9928571581840515)
[2024-12-17 03:02:21,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:22,101][root][INFO] - Training Epoch: 2/2, step 6481/7134 completed (loss: 0.03913693130016327, acc: 0.9928571581840515)
[2024-12-17 03:02:22,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:22,368][root][INFO] - Training Epoch: 2/2, step 6482/7134 completed (loss: 0.023060068488121033, acc: 1.0)
[2024-12-17 03:02:22,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:22,642][root][INFO] - Training Epoch: 2/2, step 6483/7134 completed (loss: 0.19892671704292297, acc: 0.9722222089767456)
[2024-12-17 03:02:22,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:22,910][root][INFO] - Training Epoch: 2/2, step 6484/7134 completed (loss: 0.13224869966506958, acc: 0.9649122953414917)
[2024-12-17 03:02:23,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:23,204][root][INFO] - Training Epoch: 2/2, step 6485/7134 completed (loss: 0.05814775452017784, acc: 0.9747899174690247)
[2024-12-17 03:02:23,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:23,505][root][INFO] - Training Epoch: 2/2, step 6486/7134 completed (loss: 0.404339998960495, acc: 0.8985507488250732)
[2024-12-17 03:02:23,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:23,770][root][INFO] - Training Epoch: 2/2, step 6487/7134 completed (loss: 0.2586817145347595, acc: 0.9264705777168274)
[2024-12-17 03:02:23,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:24,036][root][INFO] - Training Epoch: 2/2, step 6488/7134 completed (loss: 0.18762949109077454, acc: 0.9469696879386902)
[2024-12-17 03:02:24,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:24,302][root][INFO] - Training Epoch: 2/2, step 6489/7134 completed (loss: 0.3093683421611786, acc: 0.9316239356994629)
[2024-12-17 03:02:24,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:24,559][root][INFO] - Training Epoch: 2/2, step 6490/7134 completed (loss: 0.3814452886581421, acc: 0.9029850959777832)
[2024-12-17 03:02:24,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:24,838][root][INFO] - Training Epoch: 2/2, step 6491/7134 completed (loss: 0.23055772483348846, acc: 0.9220778942108154)
[2024-12-17 03:02:24,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:25,094][root][INFO] - Training Epoch: 2/2, step 6492/7134 completed (loss: 0.08580440282821655, acc: 0.9806451797485352)
[2024-12-17 03:02:25,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:25,375][root][INFO] - Training Epoch: 2/2, step 6493/7134 completed (loss: 0.22879673540592194, acc: 0.9345238208770752)
[2024-12-17 03:02:25,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:25,622][root][INFO] - Training Epoch: 2/2, step 6494/7134 completed (loss: 0.2583106458187103, acc: 0.9469026327133179)
[2024-12-17 03:02:25,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:25,890][root][INFO] - Training Epoch: 2/2, step 6495/7134 completed (loss: 0.18266452848911285, acc: 0.9506173133850098)
[2024-12-17 03:02:26,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:26,174][root][INFO] - Training Epoch: 2/2, step 6496/7134 completed (loss: 0.15720656514167786, acc: 0.9537572264671326)
[2024-12-17 03:02:26,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:26,445][root][INFO] - Training Epoch: 2/2, step 6497/7134 completed (loss: 0.30785128474235535, acc: 0.9444444179534912)
[2024-12-17 03:02:26,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:26,737][root][INFO] - Training Epoch: 2/2, step 6498/7134 completed (loss: 0.19789931178092957, acc: 0.9529411792755127)
[2024-12-17 03:02:26,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:27,017][root][INFO] - Training Epoch: 2/2, step 6499/7134 completed (loss: 0.1737397313117981, acc: 0.9468085169792175)
[2024-12-17 03:02:27,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:27,322][root][INFO] - Training Epoch: 2/2, step 6500/7134 completed (loss: 0.3212638199329376, acc: 0.9367815852165222)
[2024-12-17 03:02:27,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:27,596][root][INFO] - Training Epoch: 2/2, step 6501/7134 completed (loss: 0.47992032766342163, acc: 0.9020618796348572)
[2024-12-17 03:02:27,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:27,927][root][INFO] - Training Epoch: 2/2, step 6502/7134 completed (loss: 0.1697940230369568, acc: 0.9747474789619446)
[2024-12-17 03:02:28,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:28,193][root][INFO] - Training Epoch: 2/2, step 6503/7134 completed (loss: 0.21452584862709045, acc: 0.9503105878829956)
[2024-12-17 03:02:28,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:28,446][root][INFO] - Training Epoch: 2/2, step 6504/7134 completed (loss: 0.2260531634092331, acc: 0.9383561611175537)
[2024-12-17 03:02:28,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:28,714][root][INFO] - Training Epoch: 2/2, step 6505/7134 completed (loss: 0.2176227569580078, acc: 0.9200000166893005)
[2024-12-17 03:02:28,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:28,998][root][INFO] - Training Epoch: 2/2, step 6506/7134 completed (loss: 0.2508589029312134, acc: 0.9536082744598389)
[2024-12-17 03:02:29,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:29,277][root][INFO] - Training Epoch: 2/2, step 6507/7134 completed (loss: 0.2949218153953552, acc: 0.9386503100395203)
[2024-12-17 03:02:29,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:29,556][root][INFO] - Training Epoch: 2/2, step 6508/7134 completed (loss: 0.10870472341775894, acc: 0.9722222089767456)
[2024-12-17 03:02:29,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:29,826][root][INFO] - Training Epoch: 2/2, step 6509/7134 completed (loss: 0.11191604286432266, acc: 0.969072163105011)
[2024-12-17 03:02:29,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:30,126][root][INFO] - Training Epoch: 2/2, step 6510/7134 completed (loss: 0.13622815907001495, acc: 0.9563106894493103)
[2024-12-17 03:02:30,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:30,392][root][INFO] - Training Epoch: 2/2, step 6511/7134 completed (loss: 0.15538330376148224, acc: 0.9626865386962891)
[2024-12-17 03:02:30,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:30,636][root][INFO] - Training Epoch: 2/2, step 6512/7134 completed (loss: 0.10570795834064484, acc: 0.9818181991577148)
[2024-12-17 03:02:30,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:30,883][root][INFO] - Training Epoch: 2/2, step 6513/7134 completed (loss: 0.08796387910842896, acc: 0.9777777791023254)
[2024-12-17 03:02:30,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:31,139][root][INFO] - Training Epoch: 2/2, step 6514/7134 completed (loss: 0.316146582365036, acc: 0.9444444179534912)
[2024-12-17 03:02:31,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:31,429][root][INFO] - Training Epoch: 2/2, step 6515/7134 completed (loss: 0.10531188547611237, acc: 0.9890109896659851)
[2024-12-17 03:02:31,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:31,708][root][INFO] - Training Epoch: 2/2, step 6516/7134 completed (loss: 0.18959546089172363, acc: 0.9588235020637512)
[2024-12-17 03:02:31,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:31,984][root][INFO] - Training Epoch: 2/2, step 6517/7134 completed (loss: 0.0720294788479805, acc: 0.9875776171684265)
[2024-12-17 03:02:32,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:32,265][root][INFO] - Training Epoch: 2/2, step 6518/7134 completed (loss: 0.05558575317263603, acc: 0.9880239367485046)
[2024-12-17 03:02:32,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:32,547][root][INFO] - Training Epoch: 2/2, step 6519/7134 completed (loss: 0.11633294075727463, acc: 0.9842519760131836)
[2024-12-17 03:02:32,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:32,835][root][INFO] - Training Epoch: 2/2, step 6520/7134 completed (loss: 0.09243279695510864, acc: 0.9675324559211731)
[2024-12-17 03:02:32,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:33,130][root][INFO] - Training Epoch: 2/2, step 6521/7134 completed (loss: 0.10300859808921814, acc: 0.9783783555030823)
[2024-12-17 03:02:33,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:33,412][root][INFO] - Training Epoch: 2/2, step 6522/7134 completed (loss: 0.14308102428913116, acc: 0.9607843160629272)
[2024-12-17 03:02:33,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:33,681][root][INFO] - Training Epoch: 2/2, step 6523/7134 completed (loss: 0.3092549443244934, acc: 0.9236111044883728)
[2024-12-17 03:02:33,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:33,962][root][INFO] - Training Epoch: 2/2, step 6524/7134 completed (loss: 0.1841682344675064, acc: 0.9779005646705627)
[2024-12-17 03:02:34,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:34,237][root][INFO] - Training Epoch: 2/2, step 6525/7134 completed (loss: 0.05698457360267639, acc: 0.9834710955619812)
[2024-12-17 03:02:34,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:34,532][root][INFO] - Training Epoch: 2/2, step 6526/7134 completed (loss: 0.18141894042491913, acc: 0.9593908786773682)
[2024-12-17 03:02:34,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:34,809][root][INFO] - Training Epoch: 2/2, step 6527/7134 completed (loss: 0.17441324889659882, acc: 0.949367105960846)
[2024-12-17 03:02:34,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:35,066][root][INFO] - Training Epoch: 2/2, step 6528/7134 completed (loss: 0.18958315253257751, acc: 0.9637681245803833)
[2024-12-17 03:02:35,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:35,324][root][INFO] - Training Epoch: 2/2, step 6529/7134 completed (loss: 0.38750553131103516, acc: 0.9160305261611938)
[2024-12-17 03:02:35,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:35,606][root][INFO] - Training Epoch: 2/2, step 6530/7134 completed (loss: 0.18862700462341309, acc: 0.9558011293411255)
[2024-12-17 03:02:35,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:35,880][root][INFO] - Training Epoch: 2/2, step 6531/7134 completed (loss: 0.14681604504585266, acc: 0.9512194991111755)
[2024-12-17 03:02:36,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:36,191][root][INFO] - Training Epoch: 2/2, step 6532/7134 completed (loss: 0.29759806394577026, acc: 0.9615384340286255)
[2024-12-17 03:02:36,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:36,479][root][INFO] - Training Epoch: 2/2, step 6533/7134 completed (loss: 0.05651792883872986, acc: 0.9805194735527039)
[2024-12-17 03:02:36,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:36,753][root][INFO] - Training Epoch: 2/2, step 6534/7134 completed (loss: 0.21457195281982422, acc: 0.9595375657081604)
[2024-12-17 03:02:36,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:37,023][root][INFO] - Training Epoch: 2/2, step 6535/7134 completed (loss: 0.10539920628070831, acc: 0.9528301954269409)
[2024-12-17 03:02:37,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:37,291][root][INFO] - Training Epoch: 2/2, step 6536/7134 completed (loss: 0.07341829687356949, acc: 0.9739130139350891)
[2024-12-17 03:02:37,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:37,550][root][INFO] - Training Epoch: 2/2, step 6537/7134 completed (loss: 0.11986172199249268, acc: 0.9642857313156128)
[2024-12-17 03:02:37,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:37,825][root][INFO] - Training Epoch: 2/2, step 6538/7134 completed (loss: 0.2571287751197815, acc: 0.9452054500579834)
[2024-12-17 03:02:37,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:38,057][root][INFO] - Training Epoch: 2/2, step 6539/7134 completed (loss: 0.03935929760336876, acc: 1.0)
[2024-12-17 03:02:38,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:38,322][root][INFO] - Training Epoch: 2/2, step 6540/7134 completed (loss: 0.874904453754425, acc: 0.8863636255264282)
[2024-12-17 03:02:38,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:38,611][root][INFO] - Training Epoch: 2/2, step 6541/7134 completed (loss: 0.10176757723093033, acc: 0.9779005646705627)
[2024-12-17 03:02:38,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:38,901][root][INFO] - Training Epoch: 2/2, step 6542/7134 completed (loss: 0.17236876487731934, acc: 0.9642857313156128)
[2024-12-17 03:02:39,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:39,195][root][INFO] - Training Epoch: 2/2, step 6543/7134 completed (loss: 0.1093452200293541, acc: 0.9736841917037964)
[2024-12-17 03:02:39,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:39,469][root][INFO] - Training Epoch: 2/2, step 6544/7134 completed (loss: 0.15063700079917908, acc: 0.9639639854431152)
[2024-12-17 03:02:39,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:39,750][root][INFO] - Training Epoch: 2/2, step 6545/7134 completed (loss: 0.07221227139234543, acc: 0.9917355179786682)
[2024-12-17 03:02:39,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:40,006][root][INFO] - Training Epoch: 2/2, step 6546/7134 completed (loss: 0.17154397070407867, acc: 0.9710144996643066)
[2024-12-17 03:02:40,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:40,276][root][INFO] - Training Epoch: 2/2, step 6547/7134 completed (loss: 0.2734641432762146, acc: 0.9637681245803833)
[2024-12-17 03:02:40,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:40,547][root][INFO] - Training Epoch: 2/2, step 6548/7134 completed (loss: 0.09078958630561829, acc: 0.9714285731315613)
[2024-12-17 03:02:40,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:40,821][root][INFO] - Training Epoch: 2/2, step 6549/7134 completed (loss: 0.3638576865196228, acc: 0.9389312863349915)
[2024-12-17 03:02:40,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:41,081][root][INFO] - Training Epoch: 2/2, step 6550/7134 completed (loss: 0.222654327750206, acc: 0.9617834687232971)
[2024-12-17 03:02:41,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:41,361][root][INFO] - Training Epoch: 2/2, step 6551/7134 completed (loss: 0.13414974510669708, acc: 0.9593908786773682)
[2024-12-17 03:02:41,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:41,668][root][INFO] - Training Epoch: 2/2, step 6552/7134 completed (loss: 0.2909564971923828, acc: 0.9471365809440613)
[2024-12-17 03:02:41,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:41,950][root][INFO] - Training Epoch: 2/2, step 6553/7134 completed (loss: 0.1782863736152649, acc: 0.9444444179534912)
[2024-12-17 03:02:42,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:42,238][root][INFO] - Training Epoch: 2/2, step 6554/7134 completed (loss: 0.165043443441391, acc: 0.9719626307487488)
[2024-12-17 03:02:42,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:42,524][root][INFO] - Training Epoch: 2/2, step 6555/7134 completed (loss: 0.20558375120162964, acc: 0.9396551847457886)
[2024-12-17 03:02:42,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:42,789][root][INFO] - Training Epoch: 2/2, step 6556/7134 completed (loss: 0.20363953709602356, acc: 0.9638009071350098)
[2024-12-17 03:02:42,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:43,077][root][INFO] - Training Epoch: 2/2, step 6557/7134 completed (loss: 0.1744167059659958, acc: 0.9639639854431152)
[2024-12-17 03:02:43,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:43,375][root][INFO] - Training Epoch: 2/2, step 6558/7134 completed (loss: 0.22643254697322845, acc: 0.9579439163208008)
[2024-12-17 03:02:43,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:43,653][root][INFO] - Training Epoch: 2/2, step 6559/7134 completed (loss: 0.1510063260793686, acc: 0.9638554453849792)
[2024-12-17 03:02:43,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:43,999][root][INFO] - Training Epoch: 2/2, step 6560/7134 completed (loss: 0.1077655702829361, acc: 0.9685863852500916)
[2024-12-17 03:02:44,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:44,285][root][INFO] - Training Epoch: 2/2, step 6561/7134 completed (loss: 0.08518008142709732, acc: 0.9738219976425171)
[2024-12-17 03:02:44,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:44,563][root][INFO] - Training Epoch: 2/2, step 6562/7134 completed (loss: 0.13307684659957886, acc: 0.9685534834861755)
[2024-12-17 03:02:44,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:44,853][root][INFO] - Training Epoch: 2/2, step 6563/7134 completed (loss: 0.13139696419239044, acc: 0.9696969985961914)
[2024-12-17 03:02:44,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:45,130][root][INFO] - Training Epoch: 2/2, step 6564/7134 completed (loss: 0.13043823838233948, acc: 0.9638554453849792)
[2024-12-17 03:02:45,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:45,429][root][INFO] - Training Epoch: 2/2, step 6565/7134 completed (loss: 0.18236231803894043, acc: 0.9414414167404175)
[2024-12-17 03:02:45,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:45,739][root][INFO] - Training Epoch: 2/2, step 6566/7134 completed (loss: 0.16222161054611206, acc: 0.9556451439857483)
[2024-12-17 03:02:45,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:46,043][root][INFO] - Training Epoch: 2/2, step 6567/7134 completed (loss: 0.16082972288131714, acc: 0.9644444584846497)
[2024-12-17 03:02:46,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:46,332][root][INFO] - Training Epoch: 2/2, step 6568/7134 completed (loss: 0.10446303337812424, acc: 0.9615384340286255)
[2024-12-17 03:02:46,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:46,597][root][INFO] - Training Epoch: 2/2, step 6569/7134 completed (loss: 0.1237577572464943, acc: 0.9746192693710327)
[2024-12-17 03:02:46,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:46,878][root][INFO] - Training Epoch: 2/2, step 6570/7134 completed (loss: 0.14020484685897827, acc: 0.9556650519371033)
[2024-12-17 03:02:46,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:47,133][root][INFO] - Training Epoch: 2/2, step 6571/7134 completed (loss: 0.08507627248764038, acc: 0.9878787994384766)
[2024-12-17 03:02:47,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:47,426][root][INFO] - Training Epoch: 2/2, step 6572/7134 completed (loss: 0.13017487525939941, acc: 0.9512194991111755)
[2024-12-17 03:02:47,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:47,717][root][INFO] - Training Epoch: 2/2, step 6573/7134 completed (loss: 0.05648157000541687, acc: 0.9854369163513184)
[2024-12-17 03:02:47,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:48,003][root][INFO] - Training Epoch: 2/2, step 6574/7134 completed (loss: 0.07286088913679123, acc: 0.9741379022598267)
[2024-12-17 03:02:48,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:48,310][root][INFO] - Training Epoch: 2/2, step 6575/7134 completed (loss: 0.151537224650383, acc: 0.9530516266822815)
[2024-12-17 03:02:48,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:48,585][root][INFO] - Training Epoch: 2/2, step 6576/7134 completed (loss: 0.08887255191802979, acc: 0.9862385392189026)
[2024-12-17 03:02:48,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:48,854][root][INFO] - Training Epoch: 2/2, step 6577/7134 completed (loss: 0.1375076025724411, acc: 0.9575757384300232)
[2024-12-17 03:02:48,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:49,228][root][INFO] - Training Epoch: 2/2, step 6578/7134 completed (loss: 0.08445151895284653, acc: 0.9877049326896667)
[2024-12-17 03:02:49,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:49,481][root][INFO] - Training Epoch: 2/2, step 6579/7134 completed (loss: 0.3120655119419098, acc: 0.9473684430122375)
[2024-12-17 03:02:49,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:49,786][root][INFO] - Training Epoch: 2/2, step 6580/7134 completed (loss: 0.1351243108510971, acc: 0.9631578922271729)
[2024-12-17 03:02:49,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:50,073][root][INFO] - Training Epoch: 2/2, step 6581/7134 completed (loss: 0.21427084505558014, acc: 0.9459459185600281)
[2024-12-17 03:02:50,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:50,353][root][INFO] - Training Epoch: 2/2, step 6582/7134 completed (loss: 0.33662375807762146, acc: 0.9210526347160339)
[2024-12-17 03:02:50,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:50,638][root][INFO] - Training Epoch: 2/2, step 6583/7134 completed (loss: 0.18231891095638275, acc: 0.9597989916801453)
[2024-12-17 03:02:50,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:50,930][root][INFO] - Training Epoch: 2/2, step 6584/7134 completed (loss: 0.16401226818561554, acc: 0.9569892287254333)
[2024-12-17 03:02:51,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:51,202][root][INFO] - Training Epoch: 2/2, step 6585/7134 completed (loss: 0.1461631953716278, acc: 0.9527027010917664)
[2024-12-17 03:02:51,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:51,475][root][INFO] - Training Epoch: 2/2, step 6586/7134 completed (loss: 0.11669854819774628, acc: 0.9693251252174377)
[2024-12-17 03:02:51,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:51,744][root][INFO] - Training Epoch: 2/2, step 6587/7134 completed (loss: 0.24705870449543, acc: 0.969072163105011)
[2024-12-17 03:02:51,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:52,013][root][INFO] - Training Epoch: 2/2, step 6588/7134 completed (loss: 0.22307631373405457, acc: 0.9418604373931885)
[2024-12-17 03:02:52,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:52,303][root][INFO] - Training Epoch: 2/2, step 6589/7134 completed (loss: 0.17397287487983704, acc: 0.9440993666648865)
[2024-12-17 03:02:52,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:52,590][root][INFO] - Training Epoch: 2/2, step 6590/7134 completed (loss: 0.15241186320781708, acc: 0.957446813583374)
[2024-12-17 03:02:52,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:52,880][root][INFO] - Training Epoch: 2/2, step 6591/7134 completed (loss: 0.12984375655651093, acc: 0.9590643048286438)
[2024-12-17 03:02:53,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:53,177][root][INFO] - Training Epoch: 2/2, step 6592/7134 completed (loss: 0.1547120064496994, acc: 0.9605911374092102)
[2024-12-17 03:02:53,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:53,462][root][INFO] - Training Epoch: 2/2, step 6593/7134 completed (loss: 0.13278311491012573, acc: 0.9666666388511658)
[2024-12-17 03:02:53,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:53,743][root][INFO] - Training Epoch: 2/2, step 6594/7134 completed (loss: 0.16208267211914062, acc: 0.9458128213882446)
[2024-12-17 03:02:53,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:54,040][root][INFO] - Training Epoch: 2/2, step 6595/7134 completed (loss: 0.10694081336259842, acc: 0.9629629850387573)
[2024-12-17 03:02:54,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:54,309][root][INFO] - Training Epoch: 2/2, step 6596/7134 completed (loss: 0.16199751198291779, acc: 0.9457831382751465)
[2024-12-17 03:02:54,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:54,609][root][INFO] - Training Epoch: 2/2, step 6597/7134 completed (loss: 0.12439921498298645, acc: 0.963350772857666)
[2024-12-17 03:02:54,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:54,899][root][INFO] - Training Epoch: 2/2, step 6598/7134 completed (loss: 0.15419352054595947, acc: 0.9617486596107483)
[2024-12-17 03:02:55,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:55,211][root][INFO] - Training Epoch: 2/2, step 6599/7134 completed (loss: 0.13027893006801605, acc: 0.9756097793579102)
[2024-12-17 03:02:55,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:55,499][root][INFO] - Training Epoch: 2/2, step 6600/7134 completed (loss: 0.27392008900642395, acc: 0.9382022619247437)
[2024-12-17 03:02:55,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:55,800][root][INFO] - Training Epoch: 2/2, step 6601/7134 completed (loss: 0.23683416843414307, acc: 0.9411764740943909)
[2024-12-17 03:02:55,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:56,082][root][INFO] - Training Epoch: 2/2, step 6602/7134 completed (loss: 0.17560452222824097, acc: 0.9405940771102905)
[2024-12-17 03:02:56,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:56,366][root][INFO] - Training Epoch: 2/2, step 6603/7134 completed (loss: 0.16163213551044464, acc: 0.9685534834861755)
[2024-12-17 03:02:56,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:56,608][root][INFO] - Training Epoch: 2/2, step 6604/7134 completed (loss: 0.2033739984035492, acc: 0.9032257795333862)
[2024-12-17 03:02:56,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:56,877][root][INFO] - Training Epoch: 2/2, step 6605/7134 completed (loss: 0.2843441963195801, acc: 0.9086021780967712)
[2024-12-17 03:02:57,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:57,181][root][INFO] - Training Epoch: 2/2, step 6606/7134 completed (loss: 0.17205099761486053, acc: 0.9497206807136536)
[2024-12-17 03:02:57,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:57,467][root][INFO] - Training Epoch: 2/2, step 6607/7134 completed (loss: 0.2601797878742218, acc: 0.948387086391449)
[2024-12-17 03:02:57,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:57,753][root][INFO] - Training Epoch: 2/2, step 6608/7134 completed (loss: 0.047818928956985474, acc: 0.9931507110595703)
[2024-12-17 03:02:57,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:58,036][root][INFO] - Training Epoch: 2/2, step 6609/7134 completed (loss: 0.14342772960662842, acc: 0.9622641801834106)
[2024-12-17 03:02:58,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:58,309][root][INFO] - Training Epoch: 2/2, step 6610/7134 completed (loss: 0.22447514533996582, acc: 0.9333333373069763)
[2024-12-17 03:02:58,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:58,577][root][INFO] - Training Epoch: 2/2, step 6611/7134 completed (loss: 0.18404337763786316, acc: 0.9383561611175537)
[2024-12-17 03:02:58,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:58,882][root][INFO] - Training Epoch: 2/2, step 6612/7134 completed (loss: 0.3476201295852661, acc: 0.892307698726654)
[2024-12-17 03:02:59,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:59,218][root][INFO] - Training Epoch: 2/2, step 6613/7134 completed (loss: 0.15262599289417267, acc: 0.9597315192222595)
[2024-12-17 03:02:59,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:59,510][root][INFO] - Training Epoch: 2/2, step 6614/7134 completed (loss: 0.14352673292160034, acc: 0.9725274443626404)
[2024-12-17 03:02:59,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:59,798][root][INFO] - Training Epoch: 2/2, step 6615/7134 completed (loss: 0.12811121344566345, acc: 0.9729729890823364)
[2024-12-17 03:02:59,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:00,093][root][INFO] - Training Epoch: 2/2, step 6616/7134 completed (loss: 0.16320693492889404, acc: 0.9636363387107849)
[2024-12-17 03:03:00,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:00,395][root][INFO] - Training Epoch: 2/2, step 6617/7134 completed (loss: 0.10881350934505463, acc: 0.9629629850387573)
[2024-12-17 03:03:00,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:00,682][root][INFO] - Training Epoch: 2/2, step 6618/7134 completed (loss: 0.029617249965667725, acc: 1.0)
[2024-12-17 03:03:00,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:00,974][root][INFO] - Training Epoch: 2/2, step 6619/7134 completed (loss: 0.07002860307693481, acc: 0.9774011373519897)
[2024-12-17 03:03:01,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:01,257][root][INFO] - Training Epoch: 2/2, step 6620/7134 completed (loss: 0.1786983460187912, acc: 0.9513888955116272)
[2024-12-17 03:03:01,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:01,532][root][INFO] - Training Epoch: 2/2, step 6621/7134 completed (loss: 0.1479211449623108, acc: 0.9657142758369446)
[2024-12-17 03:03:01,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:01,808][root][INFO] - Training Epoch: 2/2, step 6622/7134 completed (loss: 0.10667388886213303, acc: 0.9807692170143127)
[2024-12-17 03:03:01,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:02,103][root][INFO] - Training Epoch: 2/2, step 6623/7134 completed (loss: 0.13174407184123993, acc: 0.976047933101654)
[2024-12-17 03:03:02,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:02,384][root][INFO] - Training Epoch: 2/2, step 6624/7134 completed (loss: 0.06739681959152222, acc: 0.987261176109314)
[2024-12-17 03:03:02,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:02,655][root][INFO] - Training Epoch: 2/2, step 6625/7134 completed (loss: 0.07163890451192856, acc: 0.9801324605941772)
[2024-12-17 03:03:02,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:02,949][root][INFO] - Training Epoch: 2/2, step 6626/7134 completed (loss: 0.10408130288124084, acc: 0.977142870426178)
[2024-12-17 03:03:03,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:03,243][root][INFO] - Training Epoch: 2/2, step 6627/7134 completed (loss: 0.09108240902423859, acc: 0.9838709831237793)
[2024-12-17 03:03:03,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:03,530][root][INFO] - Training Epoch: 2/2, step 6628/7134 completed (loss: 0.09338314831256866, acc: 0.976190447807312)
[2024-12-17 03:03:03,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:03,806][root][INFO] - Training Epoch: 2/2, step 6629/7134 completed (loss: 0.194602832198143, acc: 0.96875)
[2024-12-17 03:03:03,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:04,108][root][INFO] - Training Epoch: 2/2, step 6630/7134 completed (loss: 0.0988389328122139, acc: 0.9895833134651184)
[2024-12-17 03:03:04,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:04,390][root][INFO] - Training Epoch: 2/2, step 6631/7134 completed (loss: 0.07432558387517929, acc: 0.9751552939414978)
[2024-12-17 03:03:04,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:04,772][root][INFO] - Training Epoch: 2/2, step 6632/7134 completed (loss: 0.07410860806703568, acc: 0.9847715497016907)
[2024-12-17 03:03:04,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:05,058][root][INFO] - Training Epoch: 2/2, step 6633/7134 completed (loss: 0.11598885804414749, acc: 0.9780219793319702)
[2024-12-17 03:03:05,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:05,345][root][INFO] - Training Epoch: 2/2, step 6634/7134 completed (loss: 0.11645760387182236, acc: 0.969924807548523)
[2024-12-17 03:03:05,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:05,618][root][INFO] - Training Epoch: 2/2, step 6635/7134 completed (loss: 0.3342406749725342, acc: 0.9150000214576721)
[2024-12-17 03:03:05,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:05,909][root][INFO] - Training Epoch: 2/2, step 6636/7134 completed (loss: 0.1489044725894928, acc: 0.9658536314964294)
[2024-12-17 03:03:06,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:06,180][root][INFO] - Training Epoch: 2/2, step 6637/7134 completed (loss: 0.11116550117731094, acc: 0.9624999761581421)
[2024-12-17 03:03:06,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:06,452][root][INFO] - Training Epoch: 2/2, step 6638/7134 completed (loss: 0.1060960590839386, acc: 0.9670329689979553)
[2024-12-17 03:03:06,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:06,728][root][INFO] - Training Epoch: 2/2, step 6639/7134 completed (loss: 0.24773536622524261, acc: 0.9520958065986633)
[2024-12-17 03:03:06,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:07,015][root][INFO] - Training Epoch: 2/2, step 6640/7134 completed (loss: 0.10650040954351425, acc: 0.9808917045593262)
[2024-12-17 03:03:07,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:07,297][root][INFO] - Training Epoch: 2/2, step 6641/7134 completed (loss: 0.31432321667671204, acc: 0.9380530714988708)
[2024-12-17 03:03:07,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:07,579][root][INFO] - Training Epoch: 2/2, step 6642/7134 completed (loss: 0.22916464507579803, acc: 0.9457831382751465)
[2024-12-17 03:03:07,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:07,870][root][INFO] - Training Epoch: 2/2, step 6643/7134 completed (loss: 0.15078596770763397, acc: 0.9623655676841736)
[2024-12-17 03:03:07,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:08,150][root][INFO] - Training Epoch: 2/2, step 6644/7134 completed (loss: 0.1849556416273117, acc: 0.9668049812316895)
[2024-12-17 03:03:08,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:08,430][root][INFO] - Training Epoch: 2/2, step 6645/7134 completed (loss: 0.12092697620391846, acc: 0.9735449552536011)
[2024-12-17 03:03:08,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:08,728][root][INFO] - Training Epoch: 2/2, step 6646/7134 completed (loss: 0.20866918563842773, acc: 0.960698664188385)
[2024-12-17 03:03:08,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:09,007][root][INFO] - Training Epoch: 2/2, step 6647/7134 completed (loss: 0.0941668376326561, acc: 0.9647058844566345)
[2024-12-17 03:03:09,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:09,299][root][INFO] - Training Epoch: 2/2, step 6648/7134 completed (loss: 0.11327966302633286, acc: 0.9677419066429138)
[2024-12-17 03:03:09,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:09,592][root][INFO] - Training Epoch: 2/2, step 6649/7134 completed (loss: 0.21032769978046417, acc: 0.9613526463508606)
[2024-12-17 03:03:09,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:09,893][root][INFO] - Training Epoch: 2/2, step 6650/7134 completed (loss: 0.13330835103988647, acc: 0.9727272987365723)
[2024-12-17 03:03:10,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:10,193][root][INFO] - Training Epoch: 2/2, step 6651/7134 completed (loss: 0.1762082725763321, acc: 0.9488636255264282)
[2024-12-17 03:03:10,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:10,489][root][INFO] - Training Epoch: 2/2, step 6652/7134 completed (loss: 0.25258058309555054, acc: 0.9411764740943909)
[2024-12-17 03:03:10,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:10,772][root][INFO] - Training Epoch: 2/2, step 6653/7134 completed (loss: 0.33278846740722656, acc: 0.9136363863945007)
[2024-12-17 03:03:10,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:11,047][root][INFO] - Training Epoch: 2/2, step 6654/7134 completed (loss: 0.21128082275390625, acc: 0.9303797483444214)
[2024-12-17 03:03:11,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:11,323][root][INFO] - Training Epoch: 2/2, step 6655/7134 completed (loss: 0.09300338476896286, acc: 0.9809523820877075)
[2024-12-17 03:03:11,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:11,612][root][INFO] - Training Epoch: 2/2, step 6656/7134 completed (loss: 0.16257163882255554, acc: 0.942105233669281)
[2024-12-17 03:03:11,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:11,896][root][INFO] - Training Epoch: 2/2, step 6657/7134 completed (loss: 0.208028182387352, acc: 0.957446813583374)
[2024-12-17 03:03:12,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:12,198][root][INFO] - Training Epoch: 2/2, step 6658/7134 completed (loss: 0.0940941646695137, acc: 0.9796954393386841)
[2024-12-17 03:03:12,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:12,508][root][INFO] - Training Epoch: 2/2, step 6659/7134 completed (loss: 0.1482311636209488, acc: 0.9617486596107483)
[2024-12-17 03:03:12,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:12,797][root][INFO] - Training Epoch: 2/2, step 6660/7134 completed (loss: 0.0996163859963417, acc: 0.9754098653793335)
[2024-12-17 03:03:12,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:13,091][root][INFO] - Training Epoch: 2/2, step 6661/7134 completed (loss: 0.2233712077140808, acc: 0.9154228568077087)
[2024-12-17 03:03:13,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:13,375][root][INFO] - Training Epoch: 2/2, step 6662/7134 completed (loss: 0.36243098974227905, acc: 0.9064748287200928)
[2024-12-17 03:03:13,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:13,660][root][INFO] - Training Epoch: 2/2, step 6663/7134 completed (loss: 0.14913730323314667, acc: 0.948051929473877)
[2024-12-17 03:03:13,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:13,929][root][INFO] - Training Epoch: 2/2, step 6664/7134 completed (loss: 0.20738278329372406, acc: 0.949999988079071)
[2024-12-17 03:03:14,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:14,192][root][INFO] - Training Epoch: 2/2, step 6665/7134 completed (loss: 0.27806589007377625, acc: 0.9245283007621765)
[2024-12-17 03:03:14,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:14,481][root][INFO] - Training Epoch: 2/2, step 6666/7134 completed (loss: 0.08843464404344559, acc: 0.9757575988769531)
[2024-12-17 03:03:14,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:14,764][root][INFO] - Training Epoch: 2/2, step 6667/7134 completed (loss: 0.23140405118465424, acc: 0.9115646481513977)
[2024-12-17 03:03:14,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:15,027][root][INFO] - Training Epoch: 2/2, step 6668/7134 completed (loss: 0.07041547447443008, acc: 0.9781022071838379)
[2024-12-17 03:03:15,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:15,307][root][INFO] - Training Epoch: 2/2, step 6669/7134 completed (loss: 0.06008078530430794, acc: 0.9861111044883728)
[2024-12-17 03:03:15,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:15,603][root][INFO] - Training Epoch: 2/2, step 6670/7134 completed (loss: 0.08325652033090591, acc: 0.9784172773361206)
[2024-12-17 03:03:15,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:15,889][root][INFO] - Training Epoch: 2/2, step 6671/7134 completed (loss: 0.0626467764377594, acc: 0.9878048896789551)
[2024-12-17 03:03:16,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:16,178][root][INFO] - Training Epoch: 2/2, step 6672/7134 completed (loss: 0.039228662848472595, acc: 0.9919999837875366)
[2024-12-17 03:03:16,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:16,466][root][INFO] - Training Epoch: 2/2, step 6673/7134 completed (loss: 0.06209288910031319, acc: 0.9685534834861755)
[2024-12-17 03:03:16,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:16,751][root][INFO] - Training Epoch: 2/2, step 6674/7134 completed (loss: 0.0564439482986927, acc: 0.9830508232116699)
[2024-12-17 03:03:16,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:17,051][root][INFO] - Training Epoch: 2/2, step 6675/7134 completed (loss: 0.13359881937503815, acc: 0.970588207244873)
[2024-12-17 03:03:17,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:17,342][root][INFO] - Training Epoch: 2/2, step 6676/7134 completed (loss: 0.034154798835515976, acc: 0.9900000095367432)
[2024-12-17 03:03:17,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:17,620][root][INFO] - Training Epoch: 2/2, step 6677/7134 completed (loss: 0.09270539879798889, acc: 0.9770992398262024)
[2024-12-17 03:03:17,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:17,900][root][INFO] - Training Epoch: 2/2, step 6678/7134 completed (loss: 0.06045689061284065, acc: 0.9851852059364319)
[2024-12-17 03:03:18,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:18,175][root][INFO] - Training Epoch: 2/2, step 6679/7134 completed (loss: 0.05370645970106125, acc: 0.991150438785553)
[2024-12-17 03:03:18,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:18,454][root][INFO] - Training Epoch: 2/2, step 6680/7134 completed (loss: 0.022577520459890366, acc: 1.0)
[2024-12-17 03:03:18,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:18,743][root][INFO] - Training Epoch: 2/2, step 6681/7134 completed (loss: 0.030850064009428024, acc: 0.9921875)
[2024-12-17 03:03:18,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:19,020][root][INFO] - Training Epoch: 2/2, step 6682/7134 completed (loss: 0.22419297695159912, acc: 0.9611650705337524)
[2024-12-17 03:03:19,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:19,282][root][INFO] - Training Epoch: 2/2, step 6683/7134 completed (loss: 0.2061273455619812, acc: 0.977011501789093)
[2024-12-17 03:03:19,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:19,561][root][INFO] - Training Epoch: 2/2, step 6684/7134 completed (loss: 0.1371767818927765, acc: 0.9685039520263672)
[2024-12-17 03:03:19,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:19,830][root][INFO] - Training Epoch: 2/2, step 6685/7134 completed (loss: 0.10580681264400482, acc: 0.9679999947547913)
[2024-12-17 03:03:19,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:20,107][root][INFO] - Training Epoch: 2/2, step 6686/7134 completed (loss: 0.20056645572185516, acc: 0.982758641242981)
[2024-12-17 03:03:20,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:20,383][root][INFO] - Training Epoch: 2/2, step 6687/7134 completed (loss: 0.1261052042245865, acc: 0.9883720874786377)
[2024-12-17 03:03:20,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:20,681][root][INFO] - Training Epoch: 2/2, step 6688/7134 completed (loss: 0.2125425785779953, acc: 0.935251772403717)
[2024-12-17 03:03:20,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:20,963][root][INFO] - Training Epoch: 2/2, step 6689/7134 completed (loss: 0.19390030205249786, acc: 0.9537037014961243)
[2024-12-17 03:03:21,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:21,230][root][INFO] - Training Epoch: 2/2, step 6690/7134 completed (loss: 0.2230445295572281, acc: 0.9411764740943909)
[2024-12-17 03:03:21,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:21,512][root][INFO] - Training Epoch: 2/2, step 6691/7134 completed (loss: 0.09890468418598175, acc: 0.9652777910232544)
[2024-12-17 03:03:21,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:21,782][root][INFO] - Training Epoch: 2/2, step 6692/7134 completed (loss: 0.34356722235679626, acc: 0.9158878326416016)
[2024-12-17 03:03:21,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:22,047][root][INFO] - Training Epoch: 2/2, step 6693/7134 completed (loss: 0.11722871661186218, acc: 0.970370352268219)
[2024-12-17 03:03:22,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:22,331][root][INFO] - Training Epoch: 2/2, step 6694/7134 completed (loss: 0.1415276974439621, acc: 0.9668874144554138)
[2024-12-17 03:03:22,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:22,611][root][INFO] - Training Epoch: 2/2, step 6695/7134 completed (loss: 0.13279269635677338, acc: 0.9715909361839294)
[2024-12-17 03:03:22,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:22,893][root][INFO] - Training Epoch: 2/2, step 6696/7134 completed (loss: 0.2421276867389679, acc: 0.9444444179534912)
[2024-12-17 03:03:23,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:23,168][root][INFO] - Training Epoch: 2/2, step 6697/7134 completed (loss: 0.3148368000984192, acc: 0.8999999761581421)
[2024-12-17 03:03:23,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:23,461][root][INFO] - Training Epoch: 2/2, step 6698/7134 completed (loss: 0.11741987615823746, acc: 0.9731543660163879)
[2024-12-17 03:03:23,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:23,753][root][INFO] - Training Epoch: 2/2, step 6699/7134 completed (loss: 0.13213621079921722, acc: 0.9714285731315613)
[2024-12-17 03:03:23,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:24,046][root][INFO] - Training Epoch: 2/2, step 6700/7134 completed (loss: 0.31451770663261414, acc: 0.8814814686775208)
[2024-12-17 03:03:24,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:24,323][root][INFO] - Training Epoch: 2/2, step 6701/7134 completed (loss: 0.4060825705528259, acc: 0.8731343150138855)
[2024-12-17 03:03:24,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:24,598][root][INFO] - Training Epoch: 2/2, step 6702/7134 completed (loss: 0.25137239694595337, acc: 0.9304347634315491)
[2024-12-17 03:03:24,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:24,885][root][INFO] - Training Epoch: 2/2, step 6703/7134 completed (loss: 0.2137407511472702, acc: 0.95652174949646)
[2024-12-17 03:03:25,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:25,169][root][INFO] - Training Epoch: 2/2, step 6704/7134 completed (loss: 0.3233884274959564, acc: 0.9252873659133911)
[2024-12-17 03:03:25,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:25,449][root][INFO] - Training Epoch: 2/2, step 6705/7134 completed (loss: 0.13426758348941803, acc: 0.9768785834312439)
[2024-12-17 03:03:25,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:25,744][root][INFO] - Training Epoch: 2/2, step 6706/7134 completed (loss: 0.09043227881193161, acc: 0.9909090995788574)
[2024-12-17 03:03:25,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:26,009][root][INFO] - Training Epoch: 2/2, step 6707/7134 completed (loss: 0.1429549604654312, acc: 0.9658119678497314)
[2024-12-17 03:03:26,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:26,294][root][INFO] - Training Epoch: 2/2, step 6708/7134 completed (loss: 0.2067180573940277, acc: 0.9312977194786072)
[2024-12-17 03:03:26,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:26,571][root][INFO] - Training Epoch: 2/2, step 6709/7134 completed (loss: 0.17966602742671967, acc: 0.957317054271698)
[2024-12-17 03:03:26,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:26,853][root][INFO] - Training Epoch: 2/2, step 6710/7134 completed (loss: 0.28178322315216064, acc: 0.9473684430122375)
[2024-12-17 03:03:26,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:27,145][root][INFO] - Training Epoch: 2/2, step 6711/7134 completed (loss: 0.11998384445905685, acc: 0.9810126423835754)
[2024-12-17 03:03:27,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:27,407][root][INFO] - Training Epoch: 2/2, step 6712/7134 completed (loss: 0.30829983949661255, acc: 0.9241379499435425)
[2024-12-17 03:03:27,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:27,755][root][INFO] - Training Epoch: 2/2, step 6713/7134 completed (loss: 0.3444470465183258, acc: 0.9386503100395203)
[2024-12-17 03:03:27,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:28,048][root][INFO] - Training Epoch: 2/2, step 6714/7134 completed (loss: 0.19484420120716095, acc: 0.9537572264671326)
[2024-12-17 03:03:28,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:28,329][root][INFO] - Training Epoch: 2/2, step 6715/7134 completed (loss: 0.33661165833473206, acc: 0.9324324131011963)
[2024-12-17 03:03:28,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:28,605][root][INFO] - Training Epoch: 2/2, step 6716/7134 completed (loss: 0.14013709127902985, acc: 0.9589040875434875)
[2024-12-17 03:03:28,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:28,870][root][INFO] - Training Epoch: 2/2, step 6717/7134 completed (loss: 0.1704142987728119, acc: 0.9527027010917664)
[2024-12-17 03:03:29,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:29,150][root][INFO] - Training Epoch: 2/2, step 6718/7134 completed (loss: 0.17357118427753448, acc: 0.9655172228813171)
[2024-12-17 03:03:29,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:29,430][root][INFO] - Training Epoch: 2/2, step 6719/7134 completed (loss: 0.16939623653888702, acc: 0.9664429426193237)
[2024-12-17 03:03:29,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:29,711][root][INFO] - Training Epoch: 2/2, step 6720/7134 completed (loss: 0.2805362641811371, acc: 0.9252873659133911)
[2024-12-17 03:03:29,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:29,953][root][INFO] - Training Epoch: 2/2, step 6721/7134 completed (loss: 0.35335129499435425, acc: 0.9235668778419495)
[2024-12-17 03:03:30,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:30,206][root][INFO] - Training Epoch: 2/2, step 6722/7134 completed (loss: 0.2905140221118927, acc: 0.9020978808403015)
[2024-12-17 03:03:30,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:30,489][root][INFO] - Training Epoch: 2/2, step 6723/7134 completed (loss: 0.11270967870950699, acc: 0.9672130942344666)
[2024-12-17 03:03:30,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:30,761][root][INFO] - Training Epoch: 2/2, step 6724/7134 completed (loss: 0.22213461995124817, acc: 0.9496855139732361)
[2024-12-17 03:03:30,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:31,015][root][INFO] - Training Epoch: 2/2, step 6725/7134 completed (loss: 0.16106583178043365, acc: 0.9539473652839661)
[2024-12-17 03:03:31,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:31,283][root][INFO] - Training Epoch: 2/2, step 6726/7134 completed (loss: 0.297891229391098, acc: 0.9504132270812988)
[2024-12-17 03:03:31,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:31,552][root][INFO] - Training Epoch: 2/2, step 6727/7134 completed (loss: 0.2646116614341736, acc: 0.9208633303642273)
[2024-12-17 03:03:31,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:31,831][root][INFO] - Training Epoch: 2/2, step 6728/7134 completed (loss: 0.25220978260040283, acc: 0.9290322661399841)
[2024-12-17 03:03:31,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:32,107][root][INFO] - Training Epoch: 2/2, step 6729/7134 completed (loss: 0.07614307850599289, acc: 0.9810126423835754)
[2024-12-17 03:03:32,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:32,415][root][INFO] - Training Epoch: 2/2, step 6730/7134 completed (loss: 0.22668051719665527, acc: 0.931034505367279)
[2024-12-17 03:03:32,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:32,719][root][INFO] - Training Epoch: 2/2, step 6731/7134 completed (loss: 0.18947389721870422, acc: 0.9457831382751465)
[2024-12-17 03:03:32,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:33,001][root][INFO] - Training Epoch: 2/2, step 6732/7134 completed (loss: 0.14093166589736938, acc: 0.9615384340286255)
[2024-12-17 03:03:33,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:33,278][root][INFO] - Training Epoch: 2/2, step 6733/7134 completed (loss: 0.10684533417224884, acc: 0.9856114983558655)
[2024-12-17 03:03:33,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:33,545][root][INFO] - Training Epoch: 2/2, step 6734/7134 completed (loss: 0.2073388248682022, acc: 0.9650349617004395)
[2024-12-17 03:03:33,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:33,836][root][INFO] - Training Epoch: 2/2, step 6735/7134 completed (loss: 0.24136634171009064, acc: 0.9230769276618958)
[2024-12-17 03:03:33,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:34,158][root][INFO] - Training Epoch: 2/2, step 6736/7134 completed (loss: 0.18790532648563385, acc: 0.9444444179534912)
[2024-12-17 03:03:34,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:34,444][root][INFO] - Training Epoch: 2/2, step 6737/7134 completed (loss: 0.31632116436958313, acc: 0.9139072895050049)
[2024-12-17 03:03:34,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:34,724][root][INFO] - Training Epoch: 2/2, step 6738/7134 completed (loss: 0.1408870816230774, acc: 0.9632353186607361)
[2024-12-17 03:03:34,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:35,003][root][INFO] - Training Epoch: 2/2, step 6739/7134 completed (loss: 0.16254977881908417, acc: 0.9357143044471741)
[2024-12-17 03:03:35,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:35,287][root][INFO] - Training Epoch: 2/2, step 6740/7134 completed (loss: 0.1883901059627533, acc: 0.9527027010917664)
[2024-12-17 03:03:35,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:35,564][root][INFO] - Training Epoch: 2/2, step 6741/7134 completed (loss: 0.046502768993377686, acc: 0.9939758777618408)
[2024-12-17 03:03:35,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:35,843][root][INFO] - Training Epoch: 2/2, step 6742/7134 completed (loss: 0.04377271234989166, acc: 0.9941176176071167)
[2024-12-17 03:03:35,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:36,139][root][INFO] - Training Epoch: 2/2, step 6743/7134 completed (loss: 0.058261822909116745, acc: 0.9774011373519897)
[2024-12-17 03:03:36,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:36,414][root][INFO] - Training Epoch: 2/2, step 6744/7134 completed (loss: 0.05386313423514366, acc: 0.9797297120094299)
[2024-12-17 03:03:36,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:36,697][root][INFO] - Training Epoch: 2/2, step 6745/7134 completed (loss: 0.04034558683633804, acc: 0.9883720874786377)
[2024-12-17 03:03:36,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:37,018][root][INFO] - Training Epoch: 2/2, step 6746/7134 completed (loss: 0.0904468446969986, acc: 0.9925373196601868)
[2024-12-17 03:03:37,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:37,298][root][INFO] - Training Epoch: 2/2, step 6747/7134 completed (loss: 0.05485038459300995, acc: 0.9790576100349426)
[2024-12-17 03:03:37,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:37,592][root][INFO] - Training Epoch: 2/2, step 6748/7134 completed (loss: 0.09371548146009445, acc: 0.9754902124404907)
[2024-12-17 03:03:37,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:37,897][root][INFO] - Training Epoch: 2/2, step 6749/7134 completed (loss: 0.11114398390054703, acc: 0.9688888788223267)
[2024-12-17 03:03:38,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:38,199][root][INFO] - Training Epoch: 2/2, step 6750/7134 completed (loss: 0.12469508498907089, acc: 0.9653465151786804)
[2024-12-17 03:03:38,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:38,496][root][INFO] - Training Epoch: 2/2, step 6751/7134 completed (loss: 0.06868670880794525, acc: 0.9800994992256165)
[2024-12-17 03:03:38,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:38,777][root][INFO] - Training Epoch: 2/2, step 6752/7134 completed (loss: 0.11941474676132202, acc: 0.9693251252174377)
[2024-12-17 03:03:38,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:39,067][root][INFO] - Training Epoch: 2/2, step 6753/7134 completed (loss: 0.055841367691755295, acc: 0.9797979593276978)
[2024-12-17 03:03:39,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:39,336][root][INFO] - Training Epoch: 2/2, step 6754/7134 completed (loss: 0.075876884162426, acc: 0.9895287752151489)
[2024-12-17 03:03:39,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:39,618][root][INFO] - Training Epoch: 2/2, step 6755/7134 completed (loss: 0.19078104197978973, acc: 0.9685863852500916)
[2024-12-17 03:03:39,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:39,892][root][INFO] - Training Epoch: 2/2, step 6756/7134 completed (loss: 0.039408259093761444, acc: 0.9887640476226807)
[2024-12-17 03:03:40,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:40,162][root][INFO] - Training Epoch: 2/2, step 6757/7134 completed (loss: 0.03511691093444824, acc: 0.9935483932495117)
[2024-12-17 03:03:40,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:40,444][root][INFO] - Training Epoch: 2/2, step 6758/7134 completed (loss: 0.07427571713924408, acc: 0.9896373152732849)
[2024-12-17 03:03:40,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:40,734][root][INFO] - Training Epoch: 2/2, step 6759/7134 completed (loss: 0.11628667265176773, acc: 0.9866071343421936)
[2024-12-17 03:03:40,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:41,020][root][INFO] - Training Epoch: 2/2, step 6760/7134 completed (loss: 0.1395581215620041, acc: 0.9680851101875305)
[2024-12-17 03:03:41,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:41,310][root][INFO] - Training Epoch: 2/2, step 6761/7134 completed (loss: 0.16496354341506958, acc: 0.961904764175415)
[2024-12-17 03:03:41,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:41,603][root][INFO] - Training Epoch: 2/2, step 6762/7134 completed (loss: 0.04492836445569992, acc: 0.9900000095367432)
[2024-12-17 03:03:41,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:41,886][root][INFO] - Training Epoch: 2/2, step 6763/7134 completed (loss: 0.04395207390189171, acc: 0.9893048405647278)
[2024-12-17 03:03:42,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:42,161][root][INFO] - Training Epoch: 2/2, step 6764/7134 completed (loss: 0.05279453471302986, acc: 0.9823529124259949)
[2024-12-17 03:03:42,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:42,489][root][INFO] - Training Epoch: 2/2, step 6765/7134 completed (loss: 0.0666978731751442, acc: 0.9725274443626404)
[2024-12-17 03:03:42,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:42,767][root][INFO] - Training Epoch: 2/2, step 6766/7134 completed (loss: 0.10708551853895187, acc: 0.977142870426178)
[2024-12-17 03:03:42,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:43,035][root][INFO] - Training Epoch: 2/2, step 6767/7134 completed (loss: 0.12622198462486267, acc: 0.9732142686843872)
[2024-12-17 03:03:43,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:43,326][root][INFO] - Training Epoch: 2/2, step 6768/7134 completed (loss: 0.03157550469040871, acc: 1.0)
[2024-12-17 03:03:43,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:43,617][root][INFO] - Training Epoch: 2/2, step 6769/7134 completed (loss: 0.3077232539653778, acc: 0.9230769276618958)
[2024-12-17 03:03:43,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:43,919][root][INFO] - Training Epoch: 2/2, step 6770/7134 completed (loss: 0.17142949998378754, acc: 0.9526315927505493)
[2024-12-17 03:03:44,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:44,245][root][INFO] - Training Epoch: 2/2, step 6771/7134 completed (loss: 0.10783542692661285, acc: 0.9766082167625427)
[2024-12-17 03:03:44,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:44,541][root][INFO] - Training Epoch: 2/2, step 6772/7134 completed (loss: 0.3636019825935364, acc: 0.9160839319229126)
[2024-12-17 03:03:44,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:44,802][root][INFO] - Training Epoch: 2/2, step 6773/7134 completed (loss: 0.17557094991207123, acc: 0.9444444179534912)
[2024-12-17 03:03:44,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:45,086][root][INFO] - Training Epoch: 2/2, step 6774/7134 completed (loss: 0.26165613532066345, acc: 0.9289940595626831)
[2024-12-17 03:03:45,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:45,360][root][INFO] - Training Epoch: 2/2, step 6775/7134 completed (loss: 0.1319836974143982, acc: 0.9586206674575806)
[2024-12-17 03:03:45,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:45,643][root][INFO] - Training Epoch: 2/2, step 6776/7134 completed (loss: 0.13035772740840912, acc: 0.9599999785423279)
[2024-12-17 03:03:45,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:45,951][root][INFO] - Training Epoch: 2/2, step 6777/7134 completed (loss: 0.19216559827327728, acc: 0.977142870426178)
[2024-12-17 03:03:46,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:46,245][root][INFO] - Training Epoch: 2/2, step 6778/7134 completed (loss: 0.0937943384051323, acc: 0.9659090638160706)
[2024-12-17 03:03:46,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:46,520][root][INFO] - Training Epoch: 2/2, step 6779/7134 completed (loss: 0.10783826559782028, acc: 0.9642857313156128)
[2024-12-17 03:03:46,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:46,809][root][INFO] - Training Epoch: 2/2, step 6780/7134 completed (loss: 0.03410935029387474, acc: 0.9940119981765747)
[2024-12-17 03:03:46,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:47,095][root][INFO] - Training Epoch: 2/2, step 6781/7134 completed (loss: 0.03956291452050209, acc: 0.988304078578949)
[2024-12-17 03:03:47,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:47,385][root][INFO] - Training Epoch: 2/2, step 6782/7134 completed (loss: 0.04595474898815155, acc: 0.9870967864990234)
[2024-12-17 03:03:47,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:47,670][root][INFO] - Training Epoch: 2/2, step 6783/7134 completed (loss: 0.11972873657941818, acc: 0.9862068891525269)
[2024-12-17 03:03:47,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:47,966][root][INFO] - Training Epoch: 2/2, step 6784/7134 completed (loss: 0.04556904733181, acc: 0.9873417615890503)
[2024-12-17 03:03:48,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:48,273][root][INFO] - Training Epoch: 2/2, step 6785/7134 completed (loss: 0.05120610073208809, acc: 0.9803921580314636)
[2024-12-17 03:03:48,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:48,579][root][INFO] - Training Epoch: 2/2, step 6786/7134 completed (loss: 0.04633920267224312, acc: 0.9830508232116699)
[2024-12-17 03:03:48,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:48,871][root][INFO] - Training Epoch: 2/2, step 6787/7134 completed (loss: 0.09027665853500366, acc: 0.9672130942344666)
[2024-12-17 03:03:48,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:49,147][root][INFO] - Training Epoch: 2/2, step 6788/7134 completed (loss: 0.06636214256286621, acc: 0.9856114983558655)
[2024-12-17 03:03:49,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:49,417][root][INFO] - Training Epoch: 2/2, step 6789/7134 completed (loss: 0.08633250743150711, acc: 0.978723406791687)
[2024-12-17 03:03:49,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:49,710][root][INFO] - Training Epoch: 2/2, step 6790/7134 completed (loss: 0.2030533254146576, acc: 0.9772727489471436)
[2024-12-17 03:03:49,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:49,994][root][INFO] - Training Epoch: 2/2, step 6791/7134 completed (loss: 0.07122401893138885, acc: 0.9743589758872986)
[2024-12-17 03:03:50,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:50,290][root][INFO] - Training Epoch: 2/2, step 6792/7134 completed (loss: 0.07821875065565109, acc: 0.9850746393203735)
[2024-12-17 03:03:50,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:50,583][root][INFO] - Training Epoch: 2/2, step 6793/7134 completed (loss: 0.07797715812921524, acc: 0.9736841917037964)
[2024-12-17 03:03:50,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:50,897][root][INFO] - Training Epoch: 2/2, step 6794/7134 completed (loss: 0.08367520570755005, acc: 0.9863945841789246)
[2024-12-17 03:03:51,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:51,172][root][INFO] - Training Epoch: 2/2, step 6795/7134 completed (loss: 0.05182927846908569, acc: 0.9942857027053833)
[2024-12-17 03:03:51,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:51,454][root][INFO] - Training Epoch: 2/2, step 6796/7134 completed (loss: 0.02548590674996376, acc: 1.0)
[2024-12-17 03:03:51,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:51,743][root][INFO] - Training Epoch: 2/2, step 6797/7134 completed (loss: 0.1469019651412964, acc: 0.9634146094322205)
[2024-12-17 03:03:51,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:52,016][root][INFO] - Training Epoch: 2/2, step 6798/7134 completed (loss: 0.09138072282075882, acc: 0.9759036302566528)
[2024-12-17 03:03:52,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:52,302][root][INFO] - Training Epoch: 2/2, step 6799/7134 completed (loss: 0.04689934477210045, acc: 1.0)
[2024-12-17 03:03:52,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:52,589][root][INFO] - Training Epoch: 2/2, step 6800/7134 completed (loss: 0.11221518367528915, acc: 0.9620253443717957)
[2024-12-17 03:03:52,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:52,872][root][INFO] - Training Epoch: 2/2, step 6801/7134 completed (loss: 0.057521358132362366, acc: 0.9856114983558655)
[2024-12-17 03:03:53,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:53,155][root][INFO] - Training Epoch: 2/2, step 6802/7134 completed (loss: 0.04029318317770958, acc: 1.0)
[2024-12-17 03:03:53,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:53,449][root][INFO] - Training Epoch: 2/2, step 6803/7134 completed (loss: 0.0892520397901535, acc: 0.9722222089767456)
[2024-12-17 03:03:53,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:53,759][root][INFO] - Training Epoch: 2/2, step 6804/7134 completed (loss: 0.1672593057155609, acc: 0.9530201554298401)
[2024-12-17 03:03:53,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:54,064][root][INFO] - Training Epoch: 2/2, step 6805/7134 completed (loss: 0.16743098199367523, acc: 0.9629629850387573)
[2024-12-17 03:03:54,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:54,347][root][INFO] - Training Epoch: 2/2, step 6806/7134 completed (loss: 0.08503410220146179, acc: 0.9719101190567017)
[2024-12-17 03:03:54,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:54,635][root][INFO] - Training Epoch: 2/2, step 6807/7134 completed (loss: 0.09756749123334885, acc: 0.9750000238418579)
[2024-12-17 03:03:54,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:54,914][root][INFO] - Training Epoch: 2/2, step 6808/7134 completed (loss: 0.10516110062599182, acc: 0.9731543660163879)
[2024-12-17 03:03:55,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:55,190][root][INFO] - Training Epoch: 2/2, step 6809/7134 completed (loss: 0.12925148010253906, acc: 0.9807692170143127)
[2024-12-17 03:03:55,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:55,465][root][INFO] - Training Epoch: 2/2, step 6810/7134 completed (loss: 0.044472843408584595, acc: 1.0)
[2024-12-17 03:03:55,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:55,767][root][INFO] - Training Epoch: 2/2, step 6811/7134 completed (loss: 0.06778237968683243, acc: 0.9825581312179565)
[2024-12-17 03:03:55,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:56,075][root][INFO] - Training Epoch: 2/2, step 6812/7134 completed (loss: 0.07335209101438522, acc: 0.9777777791023254)
[2024-12-17 03:03:56,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:56,352][root][INFO] - Training Epoch: 2/2, step 6813/7134 completed (loss: 0.07050259411334991, acc: 0.981249988079071)
[2024-12-17 03:03:56,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:56,638][root][INFO] - Training Epoch: 2/2, step 6814/7134 completed (loss: 0.044719476252794266, acc: 0.9885714054107666)
[2024-12-17 03:03:56,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:56,934][root][INFO] - Training Epoch: 2/2, step 6815/7134 completed (loss: 0.055801715701818466, acc: 0.9823529124259949)
[2024-12-17 03:03:57,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:57,215][root][INFO] - Training Epoch: 2/2, step 6816/7134 completed (loss: 0.09541958570480347, acc: 0.9652777910232544)
[2024-12-17 03:03:57,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:57,509][root][INFO] - Training Epoch: 2/2, step 6817/7134 completed (loss: 0.2529155910015106, acc: 0.9366196990013123)
[2024-12-17 03:03:57,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:57,795][root][INFO] - Training Epoch: 2/2, step 6818/7134 completed (loss: 0.05237194150686264, acc: 0.9863945841789246)
[2024-12-17 03:03:57,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:58,084][root][INFO] - Training Epoch: 2/2, step 6819/7134 completed (loss: 0.11668814718723297, acc: 0.970802903175354)
[2024-12-17 03:03:58,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:58,368][root][INFO] - Training Epoch: 2/2, step 6820/7134 completed (loss: 0.11012335866689682, acc: 0.9781022071838379)
[2024-12-17 03:03:58,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:58,627][root][INFO] - Training Epoch: 2/2, step 6821/7134 completed (loss: 0.017267417162656784, acc: 1.0)
[2024-12-17 03:03:58,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:58,909][root][INFO] - Training Epoch: 2/2, step 6822/7134 completed (loss: 0.2400962859392166, acc: 0.9457364082336426)
[2024-12-17 03:03:59,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:59,189][root][INFO] - Training Epoch: 2/2, step 6823/7134 completed (loss: 0.14271299540996552, acc: 0.9578313231468201)
[2024-12-17 03:03:59,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:59,456][root][INFO] - Training Epoch: 2/2, step 6824/7134 completed (loss: 0.24951961636543274, acc: 0.9430894255638123)
[2024-12-17 03:03:59,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:59,715][root][INFO] - Training Epoch: 2/2, step 6825/7134 completed (loss: 0.12408227473497391, acc: 0.9677419066429138)
[2024-12-17 03:03:59,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:59,986][root][INFO] - Training Epoch: 2/2, step 6826/7134 completed (loss: 0.19582879543304443, acc: 0.9275362491607666)
[2024-12-17 03:04:00,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:00,271][root][INFO] - Training Epoch: 2/2, step 6827/7134 completed (loss: 0.3182006776332855, acc: 0.9322916865348816)
[2024-12-17 03:04:00,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:00,557][root][INFO] - Training Epoch: 2/2, step 6828/7134 completed (loss: 0.3650490641593933, acc: 0.922535240650177)
[2024-12-17 03:04:00,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:00,838][root][INFO] - Training Epoch: 2/2, step 6829/7134 completed (loss: 0.2569277882575989, acc: 0.9349112510681152)
[2024-12-17 03:04:00,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:01,094][root][INFO] - Training Epoch: 2/2, step 6830/7134 completed (loss: 0.1143718808889389, acc: 0.9729729890823364)
[2024-12-17 03:04:01,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:01,371][root][INFO] - Training Epoch: 2/2, step 6831/7134 completed (loss: 0.14972424507141113, acc: 0.9664804339408875)
[2024-12-17 03:04:01,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:01,648][root][INFO] - Training Epoch: 2/2, step 6832/7134 completed (loss: 0.15165388584136963, acc: 0.9583333134651184)
[2024-12-17 03:04:01,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:01,921][root][INFO] - Training Epoch: 2/2, step 6833/7134 completed (loss: 0.15993116796016693, acc: 0.9554139971733093)
[2024-12-17 03:04:02,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:02,175][root][INFO] - Training Epoch: 2/2, step 6834/7134 completed (loss: 0.22352971136569977, acc: 0.9328858852386475)
[2024-12-17 03:04:02,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:02,436][root][INFO] - Training Epoch: 2/2, step 6835/7134 completed (loss: 0.18611811101436615, acc: 0.9542483687400818)
[2024-12-17 03:04:02,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:02,706][root][INFO] - Training Epoch: 2/2, step 6836/7134 completed (loss: 0.1925429254770279, acc: 0.9478672742843628)
[2024-12-17 03:04:02,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:02,995][root][INFO] - Training Epoch: 2/2, step 6837/7134 completed (loss: 0.126051127910614, acc: 0.9696969985961914)
[2024-12-17 03:04:03,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:03,264][root][INFO] - Training Epoch: 2/2, step 6838/7134 completed (loss: 0.28654125332832336, acc: 0.9337349534034729)
[2024-12-17 03:04:03,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:03,543][root][INFO] - Training Epoch: 2/2, step 6839/7134 completed (loss: 0.2889249622821808, acc: 0.9333333373069763)
[2024-12-17 03:04:03,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:03,816][root][INFO] - Training Epoch: 2/2, step 6840/7134 completed (loss: 0.31080082058906555, acc: 0.9299362897872925)
[2024-12-17 03:04:03,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:04,087][root][INFO] - Training Epoch: 2/2, step 6841/7134 completed (loss: 0.12630309164524078, acc: 0.9756097793579102)
[2024-12-17 03:04:04,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:04,376][root][INFO] - Training Epoch: 2/2, step 6842/7134 completed (loss: 0.21989570558071136, acc: 0.9560439586639404)
[2024-12-17 03:04:04,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:04,670][root][INFO] - Training Epoch: 2/2, step 6843/7134 completed (loss: 0.1518595665693283, acc: 0.9637305736541748)
[2024-12-17 03:04:04,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:04,951][root][INFO] - Training Epoch: 2/2, step 6844/7134 completed (loss: 0.2749425768852234, acc: 0.926174521446228)
[2024-12-17 03:04:05,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:05,244][root][INFO] - Training Epoch: 2/2, step 6845/7134 completed (loss: 0.16460683941841125, acc: 0.9384615421295166)
[2024-12-17 03:04:05,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:05,518][root][INFO] - Training Epoch: 2/2, step 6846/7134 completed (loss: 0.22204655408859253, acc: 0.9444444179534912)
[2024-12-17 03:04:05,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:05,801][root][INFO] - Training Epoch: 2/2, step 6847/7134 completed (loss: 0.1855476051568985, acc: 0.9312499761581421)
[2024-12-17 03:04:05,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:06,056][root][INFO] - Training Epoch: 2/2, step 6848/7134 completed (loss: 0.17336121201515198, acc: 0.9550561904907227)
[2024-12-17 03:04:06,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:06,340][root][INFO] - Training Epoch: 2/2, step 6849/7134 completed (loss: 0.14168702065944672, acc: 0.9571428298950195)
[2024-12-17 03:04:06,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:06,612][root][INFO] - Training Epoch: 2/2, step 6850/7134 completed (loss: 0.1150236427783966, acc: 0.961904764175415)
[2024-12-17 03:04:06,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:06,904][root][INFO] - Training Epoch: 2/2, step 6851/7134 completed (loss: 0.20375113189220428, acc: 0.9558011293411255)
[2024-12-17 03:04:07,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:07,183][root][INFO] - Training Epoch: 2/2, step 6852/7134 completed (loss: 0.1465085744857788, acc: 0.9642857313156128)
[2024-12-17 03:04:07,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:07,486][root][INFO] - Training Epoch: 2/2, step 6853/7134 completed (loss: 0.18596194684505463, acc: 0.9479768872261047)
[2024-12-17 03:04:07,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:07,763][root][INFO] - Training Epoch: 2/2, step 6854/7134 completed (loss: 0.12551051378250122, acc: 0.9491525292396545)
[2024-12-17 03:04:07,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:08,046][root][INFO] - Training Epoch: 2/2, step 6855/7134 completed (loss: 0.05453019216656685, acc: 0.9906542301177979)
[2024-12-17 03:04:08,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:08,323][root][INFO] - Training Epoch: 2/2, step 6856/7134 completed (loss: 0.023533180356025696, acc: 1.0)
[2024-12-17 03:04:08,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:08,618][root][INFO] - Training Epoch: 2/2, step 6857/7134 completed (loss: 0.03252773731946945, acc: 0.9821428656578064)
[2024-12-17 03:04:08,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:08,876][root][INFO] - Training Epoch: 2/2, step 6858/7134 completed (loss: 0.018665460869669914, acc: 1.0)
[2024-12-17 03:04:09,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:09,168][root][INFO] - Training Epoch: 2/2, step 6859/7134 completed (loss: 0.037113599479198456, acc: 0.9887640476226807)
[2024-12-17 03:04:09,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:09,460][root][INFO] - Training Epoch: 2/2, step 6860/7134 completed (loss: 0.053269509226083755, acc: 0.9862068891525269)
[2024-12-17 03:04:09,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:09,743][root][INFO] - Training Epoch: 2/2, step 6861/7134 completed (loss: 0.015397423878312111, acc: 1.0)
[2024-12-17 03:04:09,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:10,033][root][INFO] - Training Epoch: 2/2, step 6862/7134 completed (loss: 0.0796961560845375, acc: 0.9848484992980957)
[2024-12-17 03:04:10,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:10,309][root][INFO] - Training Epoch: 2/2, step 6863/7134 completed (loss: 0.0676724836230278, acc: 0.9823529124259949)
[2024-12-17 03:04:10,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:10,591][root][INFO] - Training Epoch: 2/2, step 6864/7134 completed (loss: 0.02614828571677208, acc: 1.0)
[2024-12-17 03:04:10,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:10,874][root][INFO] - Training Epoch: 2/2, step 6865/7134 completed (loss: 0.11423352360725403, acc: 0.9593495726585388)
[2024-12-17 03:04:10,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:11,132][root][INFO] - Training Epoch: 2/2, step 6866/7134 completed (loss: 0.05732361227273941, acc: 0.9869281053543091)
[2024-12-17 03:04:11,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:11,406][root][INFO] - Training Epoch: 2/2, step 6867/7134 completed (loss: 0.010128352791070938, acc: 1.0)
[2024-12-17 03:04:11,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:11,638][root][INFO] - Training Epoch: 2/2, step 6868/7134 completed (loss: 0.01630081608891487, acc: 1.0)
[2024-12-17 03:04:11,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:11,891][root][INFO] - Training Epoch: 2/2, step 6869/7134 completed (loss: 0.06100191920995712, acc: 0.9816513657569885)
[2024-12-17 03:04:12,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:12,177][root][INFO] - Training Epoch: 2/2, step 6870/7134 completed (loss: 0.08089245110750198, acc: 0.9746835231781006)
[2024-12-17 03:04:12,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:12,458][root][INFO] - Training Epoch: 2/2, step 6871/7134 completed (loss: 0.02566954493522644, acc: 0.9920634627342224)
[2024-12-17 03:04:12,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:12,725][root][INFO] - Training Epoch: 2/2, step 6872/7134 completed (loss: 0.0614352822303772, acc: 0.9886363744735718)
[2024-12-17 03:04:12,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:12,995][root][INFO] - Training Epoch: 2/2, step 6873/7134 completed (loss: 0.06473656743764877, acc: 0.9882352948188782)
[2024-12-17 03:04:13,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:13,256][root][INFO] - Training Epoch: 2/2, step 6874/7134 completed (loss: 0.020100101828575134, acc: 1.0)
[2024-12-17 03:04:13,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:13,539][root][INFO] - Training Epoch: 2/2, step 6875/7134 completed (loss: 0.145992249250412, acc: 0.9530201554298401)
[2024-12-17 03:04:13,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:13,795][root][INFO] - Training Epoch: 2/2, step 6876/7134 completed (loss: 0.06293494999408722, acc: 0.9770992398262024)
[2024-12-17 03:04:13,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:14,076][root][INFO] - Training Epoch: 2/2, step 6877/7134 completed (loss: 0.05668098106980324, acc: 0.9882352948188782)
[2024-12-17 03:04:14,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:14,355][root][INFO] - Training Epoch: 2/2, step 6878/7134 completed (loss: 0.10691877454519272, acc: 0.9803921580314636)
[2024-12-17 03:04:14,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:14,612][root][INFO] - Training Epoch: 2/2, step 6879/7134 completed (loss: 0.10353293269872665, acc: 0.9741379022598267)
[2024-12-17 03:04:14,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:14,907][root][INFO] - Training Epoch: 2/2, step 6880/7134 completed (loss: 0.03191813826560974, acc: 0.9949238300323486)
[2024-12-17 03:04:15,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:15,193][root][INFO] - Training Epoch: 2/2, step 6881/7134 completed (loss: 0.17624172568321228, acc: 0.9734042286872864)
[2024-12-17 03:04:15,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:15,443][root][INFO] - Training Epoch: 2/2, step 6882/7134 completed (loss: 0.2896430194377899, acc: 0.9436619877815247)
[2024-12-17 03:04:15,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:15,710][root][INFO] - Training Epoch: 2/2, step 6883/7134 completed (loss: 0.06338948011398315, acc: 0.9779411554336548)
[2024-12-17 03:04:15,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:15,986][root][INFO] - Training Epoch: 2/2, step 6884/7134 completed (loss: 0.18762917816638947, acc: 0.9715909361839294)
[2024-12-17 03:04:16,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:16,244][root][INFO] - Training Epoch: 2/2, step 6885/7134 completed (loss: 0.0439310297369957, acc: 0.9906542301177979)
[2024-12-17 03:04:16,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:16,516][root][INFO] - Training Epoch: 2/2, step 6886/7134 completed (loss: 0.13772593438625336, acc: 0.9729729890823364)
[2024-12-17 03:04:16,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:16,772][root][INFO] - Training Epoch: 2/2, step 6887/7134 completed (loss: 0.13708777725696564, acc: 0.95652174949646)
[2024-12-17 03:04:16,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:17,059][root][INFO] - Training Epoch: 2/2, step 6888/7134 completed (loss: 0.12994925677776337, acc: 0.9666666388511658)
[2024-12-17 03:04:17,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:17,335][root][INFO] - Training Epoch: 2/2, step 6889/7134 completed (loss: 0.05652930215001106, acc: 0.9934640526771545)
[2024-12-17 03:04:17,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:17,619][root][INFO] - Training Epoch: 2/2, step 6890/7134 completed (loss: 0.17633339762687683, acc: 0.9569892287254333)
[2024-12-17 03:04:17,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:17,891][root][INFO] - Training Epoch: 2/2, step 6891/7134 completed (loss: 0.07055093348026276, acc: 0.9876543283462524)
[2024-12-17 03:04:18,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:18,181][root][INFO] - Training Epoch: 2/2, step 6892/7134 completed (loss: 0.155421182513237, acc: 0.9623655676841736)
[2024-12-17 03:04:18,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:18,459][root][INFO] - Training Epoch: 2/2, step 6893/7134 completed (loss: 0.2193518429994583, acc: 0.932692289352417)
[2024-12-17 03:04:18,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:18,738][root][INFO] - Training Epoch: 2/2, step 6894/7134 completed (loss: 0.16189368069171906, acc: 0.9739583134651184)
[2024-12-17 03:04:18,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:19,018][root][INFO] - Training Epoch: 2/2, step 6895/7134 completed (loss: 0.14653964340686798, acc: 0.9704433679580688)
[2024-12-17 03:04:19,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:19,272][root][INFO] - Training Epoch: 2/2, step 6896/7134 completed (loss: 0.24601048231124878, acc: 0.9364162087440491)
[2024-12-17 03:04:19,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:19,554][root][INFO] - Training Epoch: 2/2, step 6897/7134 completed (loss: 0.10614046454429626, acc: 0.9752475023269653)
[2024-12-17 03:04:19,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:19,832][root][INFO] - Training Epoch: 2/2, step 6898/7134 completed (loss: 0.1864592283964157, acc: 0.9421965479850769)
[2024-12-17 03:04:19,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:20,116][root][INFO] - Training Epoch: 2/2, step 6899/7134 completed (loss: 0.141903355717659, acc: 0.9627659320831299)
[2024-12-17 03:04:20,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:20,397][root][INFO] - Training Epoch: 2/2, step 6900/7134 completed (loss: 0.28252342343330383, acc: 0.9306358098983765)
[2024-12-17 03:04:20,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:20,682][root][INFO] - Training Epoch: 2/2, step 6901/7134 completed (loss: 0.1934276521205902, acc: 0.9621621370315552)
[2024-12-17 03:04:20,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:20,984][root][INFO] - Training Epoch: 2/2, step 6902/7134 completed (loss: 0.0484275184571743, acc: 0.9887640476226807)
[2024-12-17 03:04:21,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:21,267][root][INFO] - Training Epoch: 2/2, step 6903/7134 completed (loss: 0.1324964165687561, acc: 0.9707317352294922)
[2024-12-17 03:04:21,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:21,555][root][INFO] - Training Epoch: 2/2, step 6904/7134 completed (loss: 0.09435590356588364, acc: 0.984455943107605)
[2024-12-17 03:04:21,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:21,857][root][INFO] - Training Epoch: 2/2, step 6905/7134 completed (loss: 0.11324113607406616, acc: 0.96517413854599)
[2024-12-17 03:04:21,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:22,150][root][INFO] - Training Epoch: 2/2, step 6906/7134 completed (loss: 0.13370731472969055, acc: 0.970588207244873)
[2024-12-17 03:04:22,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:22,440][root][INFO] - Training Epoch: 2/2, step 6907/7134 completed (loss: 0.0974331721663475, acc: 0.9792746305465698)
[2024-12-17 03:04:22,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:22,723][root][INFO] - Training Epoch: 2/2, step 6908/7134 completed (loss: 0.1569676548242569, acc: 0.961904764175415)
[2024-12-17 03:04:22,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:23,003][root][INFO] - Training Epoch: 2/2, step 6909/7134 completed (loss: 0.15514524281024933, acc: 0.9672130942344666)
[2024-12-17 03:04:23,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:23,285][root][INFO] - Training Epoch: 2/2, step 6910/7134 completed (loss: 0.07769148051738739, acc: 0.9739583134651184)
[2024-12-17 03:04:23,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:23,564][root][INFO] - Training Epoch: 2/2, step 6911/7134 completed (loss: 0.33081814646720886, acc: 0.9060773253440857)
[2024-12-17 03:04:23,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:23,850][root][INFO] - Training Epoch: 2/2, step 6912/7134 completed (loss: 0.17758271098136902, acc: 0.9609755873680115)
[2024-12-17 03:04:24,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:24,198][root][INFO] - Training Epoch: 2/2, step 6913/7134 completed (loss: 0.1628960818052292, acc: 0.9710144996643066)
[2024-12-17 03:04:24,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:24,474][root][INFO] - Training Epoch: 2/2, step 6914/7134 completed (loss: 0.26518571376800537, acc: 0.9542483687400818)
[2024-12-17 03:04:24,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:24,759][root][INFO] - Training Epoch: 2/2, step 6915/7134 completed (loss: 0.1091013178229332, acc: 0.9783783555030823)
[2024-12-17 03:04:24,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:25,044][root][INFO] - Training Epoch: 2/2, step 6916/7134 completed (loss: 0.15170393884181976, acc: 0.9658536314964294)
[2024-12-17 03:04:25,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:25,338][root][INFO] - Training Epoch: 2/2, step 6917/7134 completed (loss: 0.21094506978988647, acc: 0.9639175534248352)
[2024-12-17 03:04:25,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:25,599][root][INFO] - Training Epoch: 2/2, step 6918/7134 completed (loss: 0.14050422608852386, acc: 0.9587628841400146)
[2024-12-17 03:04:25,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:25,884][root][INFO] - Training Epoch: 2/2, step 6919/7134 completed (loss: 0.18501734733581543, acc: 0.9644669890403748)
[2024-12-17 03:04:26,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:26,153][root][INFO] - Training Epoch: 2/2, step 6920/7134 completed (loss: 0.04563568904995918, acc: 0.9880239367485046)
[2024-12-17 03:04:26,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:26,436][root][INFO] - Training Epoch: 2/2, step 6921/7134 completed (loss: 0.16482198238372803, acc: 0.9754902124404907)
[2024-12-17 03:04:26,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:26,711][root][INFO] - Training Epoch: 2/2, step 6922/7134 completed (loss: 0.13405442237854004, acc: 0.9615384340286255)
[2024-12-17 03:04:26,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:27,002][root][INFO] - Training Epoch: 2/2, step 6923/7134 completed (loss: 0.13025592267513275, acc: 0.9649122953414917)
[2024-12-17 03:04:27,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:27,286][root][INFO] - Training Epoch: 2/2, step 6924/7134 completed (loss: 0.09497716277837753, acc: 0.9818181991577148)
[2024-12-17 03:04:27,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:27,566][root][INFO] - Training Epoch: 2/2, step 6925/7134 completed (loss: 0.09264693409204483, acc: 0.9647058844566345)
[2024-12-17 03:04:27,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:27,832][root][INFO] - Training Epoch: 2/2, step 6926/7134 completed (loss: 0.12009397149085999, acc: 0.9682539701461792)
[2024-12-17 03:04:27,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:28,113][root][INFO] - Training Epoch: 2/2, step 6927/7134 completed (loss: 0.09918247908353806, acc: 0.9702970385551453)
[2024-12-17 03:04:28,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:28,377][root][INFO] - Training Epoch: 2/2, step 6928/7134 completed (loss: 0.18909156322479248, acc: 0.9375)
[2024-12-17 03:04:28,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:28,678][root][INFO] - Training Epoch: 2/2, step 6929/7134 completed (loss: 0.07739978283643723, acc: 0.9772727489471436)
[2024-12-17 03:04:28,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:28,963][root][INFO] - Training Epoch: 2/2, step 6930/7134 completed (loss: 0.06426171213388443, acc: 0.9895833134651184)
[2024-12-17 03:04:29,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:29,259][root][INFO] - Training Epoch: 2/2, step 6931/7134 completed (loss: 0.14984048902988434, acc: 0.9629629850387573)
[2024-12-17 03:04:29,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:29,545][root][INFO] - Training Epoch: 2/2, step 6932/7134 completed (loss: 0.17551806569099426, acc: 0.946107804775238)
[2024-12-17 03:04:29,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:29,872][root][INFO] - Training Epoch: 2/2, step 6933/7134 completed (loss: 0.240478053689003, acc: 0.9580838084220886)
[2024-12-17 03:04:30,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:30,238][root][INFO] - Training Epoch: 2/2, step 6934/7134 completed (loss: 0.20857228338718414, acc: 0.9551281929016113)
[2024-12-17 03:04:30,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:30,546][root][INFO] - Training Epoch: 2/2, step 6935/7134 completed (loss: 0.14286966621875763, acc: 0.9734042286872864)
[2024-12-17 03:04:30,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:30,853][root][INFO] - Training Epoch: 2/2, step 6936/7134 completed (loss: 0.07111342996358871, acc: 0.9784946441650391)
[2024-12-17 03:04:30,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:31,151][root][INFO] - Training Epoch: 2/2, step 6937/7134 completed (loss: 0.24223917722702026, acc: 0.9520547986030579)
[2024-12-17 03:04:31,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:31,467][root][INFO] - Training Epoch: 2/2, step 6938/7134 completed (loss: 0.3606853783130646, acc: 0.9195402264595032)
[2024-12-17 03:04:31,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:31,808][root][INFO] - Training Epoch: 2/2, step 6939/7134 completed (loss: 0.17534507811069489, acc: 0.9523809552192688)
[2024-12-17 03:04:31,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:32,068][root][INFO] - Training Epoch: 2/2, step 6940/7134 completed (loss: 0.3201070725917816, acc: 0.9448275566101074)
[2024-12-17 03:04:32,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:32,306][root][INFO] - Training Epoch: 2/2, step 6941/7134 completed (loss: 0.06882285326719284, acc: 0.9852941036224365)
[2024-12-17 03:04:32,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:32,565][root][INFO] - Training Epoch: 2/2, step 6942/7134 completed (loss: 0.20688626170158386, acc: 0.9426751732826233)
[2024-12-17 03:04:32,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:32,818][root][INFO] - Training Epoch: 2/2, step 6943/7134 completed (loss: 0.18066588044166565, acc: 0.9469026327133179)
[2024-12-17 03:04:32,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:33,091][root][INFO] - Training Epoch: 2/2, step 6944/7134 completed (loss: 0.14855583012104034, acc: 0.9586206674575806)
[2024-12-17 03:04:33,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:33,326][root][INFO] - Training Epoch: 2/2, step 6945/7134 completed (loss: 0.21334007382392883, acc: 0.9765625)
[2024-12-17 03:04:33,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:33,606][root][INFO] - Training Epoch: 2/2, step 6946/7134 completed (loss: 0.18343915045261383, acc: 0.9569892287254333)
[2024-12-17 03:04:33,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:33,884][root][INFO] - Training Epoch: 2/2, step 6947/7134 completed (loss: 0.12738651037216187, acc: 0.9734513163566589)
[2024-12-17 03:04:34,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:34,163][root][INFO] - Training Epoch: 2/2, step 6948/7134 completed (loss: 0.32894274592399597, acc: 0.9071428775787354)
[2024-12-17 03:04:34,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:34,433][root][INFO] - Training Epoch: 2/2, step 6949/7134 completed (loss: 0.17930357158184052, acc: 0.947826087474823)
[2024-12-17 03:04:34,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:34,682][root][INFO] - Training Epoch: 2/2, step 6950/7134 completed (loss: 0.12524822354316711, acc: 0.9746835231781006)
[2024-12-17 03:04:34,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:34,966][root][INFO] - Training Epoch: 2/2, step 6951/7134 completed (loss: 0.19403600692749023, acc: 0.9375)
[2024-12-17 03:04:35,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:35,210][root][INFO] - Training Epoch: 2/2, step 6952/7134 completed (loss: 0.24367164075374603, acc: 0.9142857193946838)
[2024-12-17 03:04:35,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:35,476][root][INFO] - Training Epoch: 2/2, step 6953/7134 completed (loss: 0.11789108067750931, acc: 0.9774436354637146)
[2024-12-17 03:04:35,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:35,750][root][INFO] - Training Epoch: 2/2, step 6954/7134 completed (loss: 0.2773708403110504, acc: 0.9482758641242981)
[2024-12-17 03:04:35,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:36,029][root][INFO] - Training Epoch: 2/2, step 6955/7134 completed (loss: 0.07465511560440063, acc: 0.987500011920929)
[2024-12-17 03:04:36,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:36,308][root][INFO] - Training Epoch: 2/2, step 6956/7134 completed (loss: 0.06835256516933441, acc: 0.985401451587677)
[2024-12-17 03:04:36,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:36,592][root][INFO] - Training Epoch: 2/2, step 6957/7134 completed (loss: 0.14048300683498383, acc: 0.9599999785423279)
[2024-12-17 03:04:36,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:36,855][root][INFO] - Training Epoch: 2/2, step 6958/7134 completed (loss: 0.2650332450866699, acc: 0.9487179517745972)
[2024-12-17 03:04:36,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:37,128][root][INFO] - Training Epoch: 2/2, step 6959/7134 completed (loss: 0.3036751449108124, acc: 0.9357798099517822)
[2024-12-17 03:04:37,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:37,418][root][INFO] - Training Epoch: 2/2, step 6960/7134 completed (loss: 0.14441902935504913, acc: 0.9513888955116272)
[2024-12-17 03:04:37,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:37,718][root][INFO] - Training Epoch: 2/2, step 6961/7134 completed (loss: 0.10375123471021652, acc: 0.9572649598121643)
[2024-12-17 03:04:37,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:38,020][root][INFO] - Training Epoch: 2/2, step 6962/7134 completed (loss: 0.108696348965168, acc: 0.97826087474823)
[2024-12-17 03:04:38,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:38,326][root][INFO] - Training Epoch: 2/2, step 6963/7134 completed (loss: 0.1323288232088089, acc: 0.9735099077224731)
[2024-12-17 03:04:38,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:38,611][root][INFO] - Training Epoch: 2/2, step 6964/7134 completed (loss: 0.05588115379214287, acc: 0.9848484992980957)
[2024-12-17 03:04:38,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:38,900][root][INFO] - Training Epoch: 2/2, step 6965/7134 completed (loss: 0.056104518473148346, acc: 0.971222996711731)
[2024-12-17 03:04:39,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:39,167][root][INFO] - Training Epoch: 2/2, step 6966/7134 completed (loss: 0.08754846453666687, acc: 0.9809523820877075)
[2024-12-17 03:04:39,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:39,451][root][INFO] - Training Epoch: 2/2, step 6967/7134 completed (loss: 0.05880538746714592, acc: 0.9863945841789246)
[2024-12-17 03:04:39,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:39,724][root][INFO] - Training Epoch: 2/2, step 6968/7134 completed (loss: 0.11624318361282349, acc: 0.9664429426193237)
[2024-12-17 03:04:39,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:40,001][root][INFO] - Training Epoch: 2/2, step 6969/7134 completed (loss: 0.20852257311344147, acc: 0.9354838728904724)
[2024-12-17 03:04:40,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:40,282][root][INFO] - Training Epoch: 2/2, step 6970/7134 completed (loss: 0.24049189686775208, acc: 0.9482758641242981)
[2024-12-17 03:04:40,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:40,574][root][INFO] - Training Epoch: 2/2, step 6971/7134 completed (loss: 0.18525731563568115, acc: 0.9305555820465088)
[2024-12-17 03:04:40,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:40,868][root][INFO] - Training Epoch: 2/2, step 6972/7134 completed (loss: 0.12823699414730072, acc: 0.9767441749572754)
[2024-12-17 03:04:40,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:41,135][root][INFO] - Training Epoch: 2/2, step 6973/7134 completed (loss: 0.24656584858894348, acc: 0.9741379022598267)
[2024-12-17 03:04:41,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:41,416][root][INFO] - Training Epoch: 2/2, step 6974/7134 completed (loss: 0.2362573891878128, acc: 0.9477124214172363)
[2024-12-17 03:04:41,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:41,690][root][INFO] - Training Epoch: 2/2, step 6975/7134 completed (loss: 0.17234285175800323, acc: 0.9743589758872986)
[2024-12-17 03:04:41,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:41,972][root][INFO] - Training Epoch: 2/2, step 6976/7134 completed (loss: 0.138768270611763, acc: 0.9571428298950195)
[2024-12-17 03:04:42,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:42,252][root][INFO] - Training Epoch: 2/2, step 6977/7134 completed (loss: 0.1741393655538559, acc: 0.9465649127960205)
[2024-12-17 03:04:42,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:42,533][root][INFO] - Training Epoch: 2/2, step 6978/7134 completed (loss: 0.1497458815574646, acc: 0.9556962251663208)
[2024-12-17 03:04:42,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:42,817][root][INFO] - Training Epoch: 2/2, step 6979/7134 completed (loss: 0.14697767794132233, acc: 0.940397322177887)
[2024-12-17 03:04:42,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:43,110][root][INFO] - Training Epoch: 2/2, step 6980/7134 completed (loss: 0.4464006721973419, acc: 0.8926553726196289)
[2024-12-17 03:04:43,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:43,405][root][INFO] - Training Epoch: 2/2, step 6981/7134 completed (loss: 0.22555036842823029, acc: 0.9329897165298462)
[2024-12-17 03:04:43,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:43,694][root][INFO] - Training Epoch: 2/2, step 6982/7134 completed (loss: 0.3593447208404541, acc: 0.9214659929275513)
[2024-12-17 03:04:43,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:43,977][root][INFO] - Training Epoch: 2/2, step 6983/7134 completed (loss: 0.3926466107368469, acc: 0.8910256624221802)
[2024-12-17 03:04:44,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:44,254][root][INFO] - Training Epoch: 2/2, step 6984/7134 completed (loss: 0.15889225900173187, acc: 0.9395349025726318)
[2024-12-17 03:04:44,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:44,555][root][INFO] - Training Epoch: 2/2, step 6985/7134 completed (loss: 0.31730392575263977, acc: 0.9270386099815369)
[2024-12-17 03:04:44,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:44,835][root][INFO] - Training Epoch: 2/2, step 6986/7134 completed (loss: 0.175455704331398, acc: 0.9567901492118835)
[2024-12-17 03:04:44,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:45,129][root][INFO] - Training Epoch: 2/2, step 6987/7134 completed (loss: 0.20075854659080505, acc: 0.9380165338516235)
[2024-12-17 03:04:45,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:45,384][root][INFO] - Training Epoch: 2/2, step 6988/7134 completed (loss: 0.11803797632455826, acc: 0.9842519760131836)
[2024-12-17 03:04:45,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:45,635][root][INFO] - Training Epoch: 2/2, step 6989/7134 completed (loss: 0.20399688184261322, acc: 0.9594594836235046)
[2024-12-17 03:04:45,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:45,889][root][INFO] - Training Epoch: 2/2, step 6990/7134 completed (loss: 0.02936866693198681, acc: 1.0)
[2024-12-17 03:04:46,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:46,163][root][INFO] - Training Epoch: 2/2, step 6991/7134 completed (loss: 0.3288990557193756, acc: 0.9504950642585754)
[2024-12-17 03:04:46,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:46,453][root][INFO] - Training Epoch: 2/2, step 6992/7134 completed (loss: 0.13157925009727478, acc: 0.9729729890823364)
[2024-12-17 03:04:46,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:46,721][root][INFO] - Training Epoch: 2/2, step 6993/7134 completed (loss: 0.18699686229228973, acc: 0.9490445852279663)
[2024-12-17 03:04:46,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:47,005][root][INFO] - Training Epoch: 2/2, step 6994/7134 completed (loss: 0.37732088565826416, acc: 0.9133333563804626)
[2024-12-17 03:04:47,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:47,281][root][INFO] - Training Epoch: 2/2, step 6995/7134 completed (loss: 0.12033203989267349, acc: 0.9593023061752319)
[2024-12-17 03:04:47,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:47,550][root][INFO] - Training Epoch: 2/2, step 6996/7134 completed (loss: 0.09051021188497543, acc: 0.9794520735740662)
[2024-12-17 03:04:47,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:47,813][root][INFO] - Training Epoch: 2/2, step 6997/7134 completed (loss: 0.08011756092309952, acc: 0.9806451797485352)
[2024-12-17 03:04:47,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:48,066][root][INFO] - Training Epoch: 2/2, step 6998/7134 completed (loss: 0.257059246301651, acc: 0.9263157844543457)
[2024-12-17 03:04:48,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:48,337][root][INFO] - Training Epoch: 2/2, step 6999/7134 completed (loss: 0.06690332293510437, acc: 0.9717513918876648)
[2024-12-17 03:04:48,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:48,560][root][INFO] - Training Epoch: 2/2, step 7000/7134 completed (loss: 0.18315209448337555, acc: 0.9454545378684998)
[2024-12-17 03:04:48,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:48,835][root][INFO] - Training Epoch: 2/2, step 7001/7134 completed (loss: 0.32866349816322327, acc: 0.9610389471054077)
[2024-12-17 03:04:48,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:49,119][root][INFO] - Training Epoch: 2/2, step 7002/7134 completed (loss: 0.08345065265893936, acc: 0.9831932783126831)
[2024-12-17 03:04:49,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:49,392][root][INFO] - Training Epoch: 2/2, step 7003/7134 completed (loss: 0.04883691668510437, acc: 0.984455943107605)
[2024-12-17 03:04:49,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:49,680][root][INFO] - Training Epoch: 2/2, step 7004/7134 completed (loss: 0.1873120367527008, acc: 0.9756097793579102)
[2024-12-17 03:04:49,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:49,969][root][INFO] - Training Epoch: 2/2, step 7005/7134 completed (loss: 0.14530208706855774, acc: 0.9638554453849792)
[2024-12-17 03:04:50,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:50,251][root][INFO] - Training Epoch: 2/2, step 7006/7134 completed (loss: 0.07546258717775345, acc: 0.9751552939414978)
[2024-12-17 03:04:50,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:50,530][root][INFO] - Training Epoch: 2/2, step 7007/7134 completed (loss: 0.15650686621665955, acc: 0.9419354796409607)
[2024-12-17 03:04:50,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:50,793][root][INFO] - Training Epoch: 2/2, step 7008/7134 completed (loss: 0.07695335894823074, acc: 0.9944751262664795)
[2024-12-17 03:04:50,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:51,076][root][INFO] - Training Epoch: 2/2, step 7009/7134 completed (loss: 0.13655197620391846, acc: 0.9791666865348816)
[2024-12-17 03:04:51,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:51,348][root][INFO] - Training Epoch: 2/2, step 7010/7134 completed (loss: 0.07176342606544495, acc: 0.9870967864990234)
[2024-12-17 03:04:51,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:51,625][root][INFO] - Training Epoch: 2/2, step 7011/7134 completed (loss: 0.1485268920660019, acc: 0.9581151604652405)
[2024-12-17 03:04:51,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:51,886][root][INFO] - Training Epoch: 2/2, step 7012/7134 completed (loss: 0.11695467680692673, acc: 0.9638554453849792)
[2024-12-17 03:04:51,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:52,170][root][INFO] - Training Epoch: 2/2, step 7013/7134 completed (loss: 0.052591919898986816, acc: 0.993630588054657)
[2024-12-17 03:04:52,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:52,443][root][INFO] - Training Epoch: 2/2, step 7014/7134 completed (loss: 0.18290236592292786, acc: 0.9527027010917664)
[2024-12-17 03:04:52,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:52,703][root][INFO] - Training Epoch: 2/2, step 7015/7134 completed (loss: 0.08221093565225601, acc: 0.9850746393203735)
[2024-12-17 03:04:52,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:53,005][root][INFO] - Training Epoch: 2/2, step 7016/7134 completed (loss: 0.15090443193912506, acc: 0.9551281929016113)
[2024-12-17 03:04:53,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:53,262][root][INFO] - Training Epoch: 2/2, step 7017/7134 completed (loss: 0.14870572090148926, acc: 0.9557521939277649)
[2024-12-17 03:04:53,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:53,555][root][INFO] - Training Epoch: 2/2, step 7018/7134 completed (loss: 0.15689001977443695, acc: 0.9629629850387573)
[2024-12-17 03:04:53,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:53,830][root][INFO] - Training Epoch: 2/2, step 7019/7134 completed (loss: 0.27952566742897034, acc: 0.9367088675498962)
[2024-12-17 03:04:53,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:54,095][root][INFO] - Training Epoch: 2/2, step 7020/7134 completed (loss: 0.08863982558250427, acc: 0.9819276928901672)
[2024-12-17 03:04:54,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:54,397][root][INFO] - Training Epoch: 2/2, step 7021/7134 completed (loss: 0.15088099241256714, acc: 0.9481481313705444)
[2024-12-17 03:04:54,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:54,657][root][INFO] - Training Epoch: 2/2, step 7022/7134 completed (loss: 0.2977786064147949, acc: 0.9305555820465088)
[2024-12-17 03:04:54,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:54,940][root][INFO] - Training Epoch: 2/2, step 7023/7134 completed (loss: 0.1531740427017212, acc: 0.9638554453849792)
[2024-12-17 03:04:55,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:55,223][root][INFO] - Training Epoch: 2/2, step 7024/7134 completed (loss: 0.11106674373149872, acc: 0.9855072498321533)
[2024-12-17 03:04:55,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:55,508][root][INFO] - Training Epoch: 2/2, step 7025/7134 completed (loss: 0.20001496374607086, acc: 0.9428571462631226)
[2024-12-17 03:04:55,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:55,771][root][INFO] - Training Epoch: 2/2, step 7026/7134 completed (loss: 0.2615305185317993, acc: 0.9375)
[2024-12-17 03:04:55,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:56,030][root][INFO] - Training Epoch: 2/2, step 7027/7134 completed (loss: 0.19358943402767181, acc: 0.9577465057373047)
[2024-12-17 03:04:56,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:56,305][root][INFO] - Training Epoch: 2/2, step 7028/7134 completed (loss: 0.04771123081445694, acc: 0.9890109896659851)
[2024-12-17 03:04:56,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:56,586][root][INFO] - Training Epoch: 2/2, step 7029/7134 completed (loss: 0.08168953657150269, acc: 0.9887640476226807)
[2024-12-17 03:04:56,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:56,855][root][INFO] - Training Epoch: 2/2, step 7030/7134 completed (loss: 0.14271456003189087, acc: 0.95652174949646)
[2024-12-17 03:04:56,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:57,141][root][INFO] - Training Epoch: 2/2, step 7031/7134 completed (loss: 0.20924504101276398, acc: 0.9876543283462524)
[2024-12-17 03:04:57,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:57,403][root][INFO] - Training Epoch: 2/2, step 7032/7134 completed (loss: 0.23981007933616638, acc: 0.9264705777168274)
[2024-12-17 03:04:57,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:57,663][root][INFO] - Training Epoch: 2/2, step 7033/7134 completed (loss: 0.3653271198272705, acc: 0.9135802388191223)
[2024-12-17 03:04:57,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:57,931][root][INFO] - Training Epoch: 2/2, step 7034/7134 completed (loss: 0.16493554413318634, acc: 0.953125)
[2024-12-17 03:04:58,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:58,200][root][INFO] - Training Epoch: 2/2, step 7035/7134 completed (loss: 0.3529500663280487, acc: 0.9365079402923584)
[2024-12-17 03:04:58,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:58,452][root][INFO] - Training Epoch: 2/2, step 7036/7134 completed (loss: 0.2017660290002823, acc: 0.9682539701461792)
[2024-12-17 03:04:58,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:58,714][root][INFO] - Training Epoch: 2/2, step 7037/7134 completed (loss: 0.05103708431124687, acc: 1.0)
[2024-12-17 03:04:58,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:58,984][root][INFO] - Training Epoch: 2/2, step 7038/7134 completed (loss: 0.41804808378219604, acc: 0.8734177350997925)
[2024-12-17 03:04:59,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:59,252][root][INFO] - Training Epoch: 2/2, step 7039/7134 completed (loss: 0.21105369925498962, acc: 0.9555555582046509)
[2024-12-17 03:04:59,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:59,508][root][INFO] - Training Epoch: 2/2, step 7040/7134 completed (loss: 0.32840782403945923, acc: 0.9466666579246521)
[2024-12-17 03:04:59,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:59,781][root][INFO] - Training Epoch: 2/2, step 7041/7134 completed (loss: 0.19375905394554138, acc: 0.9375)
[2024-12-17 03:04:59,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:00,052][root][INFO] - Training Epoch: 2/2, step 7042/7134 completed (loss: 0.17016199231147766, acc: 0.98591548204422)
[2024-12-17 03:05:00,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:00,318][root][INFO] - Training Epoch: 2/2, step 7043/7134 completed (loss: 0.2308918535709381, acc: 0.9466666579246521)
[2024-12-17 03:05:00,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:00,580][root][INFO] - Training Epoch: 2/2, step 7044/7134 completed (loss: 0.17414923012256622, acc: 0.9436619877815247)
[2024-12-17 03:05:00,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:00,845][root][INFO] - Training Epoch: 2/2, step 7045/7134 completed (loss: 0.18246997892856598, acc: 0.951724112033844)
[2024-12-17 03:05:00,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:01,135][root][INFO] - Training Epoch: 2/2, step 7046/7134 completed (loss: 0.30319949984550476, acc: 0.9341317415237427)
[2024-12-17 03:05:01,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:01,416][root][INFO] - Training Epoch: 2/2, step 7047/7134 completed (loss: 0.30949121713638306, acc: 0.934272289276123)
[2024-12-17 03:05:01,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:01,698][root][INFO] - Training Epoch: 2/2, step 7048/7134 completed (loss: 0.027165697887539864, acc: 0.9948453903198242)
[2024-12-17 03:05:01,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:01,962][root][INFO] - Training Epoch: 2/2, step 7049/7134 completed (loss: 0.15397310256958008, acc: 0.9653179049491882)
[2024-12-17 03:05:02,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:02,239][root][INFO] - Training Epoch: 2/2, step 7050/7134 completed (loss: 0.12499096244573593, acc: 0.9714285731315613)
[2024-12-17 03:05:02,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:02,521][root][INFO] - Training Epoch: 2/2, step 7051/7134 completed (loss: 0.08959908038377762, acc: 0.97826087474823)
[2024-12-17 03:05:02,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:02,810][root][INFO] - Training Epoch: 2/2, step 7052/7134 completed (loss: 0.06783656030893326, acc: 0.9826589822769165)
[2024-12-17 03:05:02,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:03,095][root][INFO] - Training Epoch: 2/2, step 7053/7134 completed (loss: 0.0720473974943161, acc: 0.994535505771637)
[2024-12-17 03:05:03,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:03,402][root][INFO] - Training Epoch: 2/2, step 7054/7134 completed (loss: 0.1956418752670288, acc: 0.9806451797485352)
[2024-12-17 03:05:03,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:03,687][root][INFO] - Training Epoch: 2/2, step 7055/7134 completed (loss: 0.14112599194049835, acc: 0.9725274443626404)
[2024-12-17 03:05:03,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:03,981][root][INFO] - Training Epoch: 2/2, step 7056/7134 completed (loss: 0.11430107802152634, acc: 0.9666666388511658)
[2024-12-17 03:05:04,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:04,274][root][INFO] - Training Epoch: 2/2, step 7057/7134 completed (loss: 0.5168021321296692, acc: 0.9281768202781677)
[2024-12-17 03:05:04,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:04,562][root][INFO] - Training Epoch: 2/2, step 7058/7134 completed (loss: 0.20022979378700256, acc: 0.9689922332763672)
[2024-12-17 03:05:04,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:04,860][root][INFO] - Training Epoch: 2/2, step 7059/7134 completed (loss: 0.09520029276609421, acc: 0.9807692170143127)
[2024-12-17 03:05:04,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:05,130][root][INFO] - Training Epoch: 2/2, step 7060/7134 completed (loss: 0.23132120072841644, acc: 0.9436619877815247)
[2024-12-17 03:05:05,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:05,418][root][INFO] - Training Epoch: 2/2, step 7061/7134 completed (loss: 0.1986977905035019, acc: 0.9301075339317322)
[2024-12-17 03:05:05,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:05,695][root][INFO] - Training Epoch: 2/2, step 7062/7134 completed (loss: 0.19476071000099182, acc: 0.9406779408454895)
[2024-12-17 03:05:05,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:05,969][root][INFO] - Training Epoch: 2/2, step 7063/7134 completed (loss: 0.32312312722206116, acc: 0.929729700088501)
[2024-12-17 03:05:06,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:06,274][root][INFO] - Training Epoch: 2/2, step 7064/7134 completed (loss: 0.19931469857692719, acc: 0.9819276928901672)
[2024-12-17 03:05:06,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:06,555][root][INFO] - Training Epoch: 2/2, step 7065/7134 completed (loss: 0.14206181466579437, acc: 0.9797979593276978)
[2024-12-17 03:05:06,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:06,831][root][INFO] - Training Epoch: 2/2, step 7066/7134 completed (loss: 0.15110059082508087, acc: 0.9685863852500916)
[2024-12-17 03:05:06,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:07,105][root][INFO] - Training Epoch: 2/2, step 7067/7134 completed (loss: 0.18339332938194275, acc: 0.9682539701461792)
[2024-12-17 03:05:07,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:07,390][root][INFO] - Training Epoch: 2/2, step 7068/7134 completed (loss: 0.08882488310337067, acc: 0.9756097793579102)
[2024-12-17 03:05:07,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:07,682][root][INFO] - Training Epoch: 2/2, step 7069/7134 completed (loss: 0.1485680192708969, acc: 0.9696969985961914)
[2024-12-17 03:05:07,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:07,957][root][INFO] - Training Epoch: 2/2, step 7070/7134 completed (loss: 0.11758317798376083, acc: 0.9768785834312439)
[2024-12-17 03:05:08,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:08,239][root][INFO] - Training Epoch: 2/2, step 7071/7134 completed (loss: 0.13488487899303436, acc: 0.9831932783126831)
[2024-12-17 03:05:08,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:08,513][root][INFO] - Training Epoch: 2/2, step 7072/7134 completed (loss: 0.10387749969959259, acc: 0.9646464586257935)
[2024-12-17 03:05:08,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:08,808][root][INFO] - Training Epoch: 2/2, step 7073/7134 completed (loss: 0.10551289469003677, acc: 0.9597989916801453)
[2024-12-17 03:05:08,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:09,088][root][INFO] - Training Epoch: 2/2, step 7074/7134 completed (loss: 0.43831485509872437, acc: 0.8861788511276245)
[2024-12-17 03:05:09,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:09,377][root][INFO] - Training Epoch: 2/2, step 7075/7134 completed (loss: 0.23092374205589294, acc: 0.9426751732826233)
[2024-12-17 03:05:09,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:09,640][root][INFO] - Training Epoch: 2/2, step 7076/7134 completed (loss: 0.28084301948547363, acc: 0.915730357170105)
[2024-12-17 03:05:09,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:09,897][root][INFO] - Training Epoch: 2/2, step 7077/7134 completed (loss: 0.22580860555171967, acc: 0.9452054500579834)
[2024-12-17 03:05:09,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:10,166][root][INFO] - Training Epoch: 2/2, step 7078/7134 completed (loss: 0.12248766422271729, acc: 0.9862068891525269)
[2024-12-17 03:05:10,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:10,430][root][INFO] - Training Epoch: 2/2, step 7079/7134 completed (loss: 0.07967977225780487, acc: 0.9802631735801697)
[2024-12-17 03:05:10,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:10,693][root][INFO] - Training Epoch: 2/2, step 7080/7134 completed (loss: 0.1738540679216385, acc: 0.9319728016853333)
[2024-12-17 03:05:10,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:10,977][root][INFO] - Training Epoch: 2/2, step 7081/7134 completed (loss: 0.09209727495908737, acc: 0.9653179049491882)
[2024-12-17 03:05:11,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:11,250][root][INFO] - Training Epoch: 2/2, step 7082/7134 completed (loss: 0.23444895446300507, acc: 0.9210526347160339)
[2024-12-17 03:05:11,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:11,530][root][INFO] - Training Epoch: 2/2, step 7083/7134 completed (loss: 0.07027515023946762, acc: 0.978723406791687)
[2024-12-17 03:05:11,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:11,815][root][INFO] - Training Epoch: 2/2, step 7084/7134 completed (loss: 0.12628932297229767, acc: 0.959770143032074)
[2024-12-17 03:05:11,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:12,084][root][INFO] - Training Epoch: 2/2, step 7085/7134 completed (loss: 0.20984609425067902, acc: 0.9466666579246521)
[2024-12-17 03:05:12,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:12,372][root][INFO] - Training Epoch: 2/2, step 7086/7134 completed (loss: 0.12885256111621857, acc: 0.9741935729980469)
[2024-12-17 03:05:12,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:12,641][root][INFO] - Training Epoch: 2/2, step 7087/7134 completed (loss: 0.21031267940998077, acc: 0.961240291595459)
[2024-12-17 03:05:12,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:12,922][root][INFO] - Training Epoch: 2/2, step 7088/7134 completed (loss: 0.1705847829580307, acc: 0.957446813583374)
[2024-12-17 03:05:13,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:13,201][root][INFO] - Training Epoch: 2/2, step 7089/7134 completed (loss: 0.22259922325611115, acc: 0.948387086391449)
[2024-12-17 03:05:13,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:13,491][root][INFO] - Training Epoch: 2/2, step 7090/7134 completed (loss: 0.15224778652191162, acc: 0.976190447807312)
[2024-12-17 03:05:13,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:13,763][root][INFO] - Training Epoch: 2/2, step 7091/7134 completed (loss: 0.04756626486778259, acc: 0.9878787994384766)
[2024-12-17 03:05:13,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:14,048][root][INFO] - Training Epoch: 2/2, step 7092/7134 completed (loss: 0.15006649494171143, acc: 0.9774436354637146)
[2024-12-17 03:05:14,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:14,312][root][INFO] - Training Epoch: 2/2, step 7093/7134 completed (loss: 0.2129206657409668, acc: 0.94017094373703)
[2024-12-17 03:05:14,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:14,572][root][INFO] - Training Epoch: 2/2, step 7094/7134 completed (loss: 0.09924560785293579, acc: 0.9583333134651184)
[2024-12-17 03:05:14,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:14,846][root][INFO] - Training Epoch: 2/2, step 7095/7134 completed (loss: 0.16179250180721283, acc: 0.9830508232116699)
[2024-12-17 03:05:14,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:15,113][root][INFO] - Training Epoch: 2/2, step 7096/7134 completed (loss: 0.07888980209827423, acc: 0.98591548204422)
[2024-12-17 03:05:15,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:15,409][root][INFO] - Training Epoch: 2/2, step 7097/7134 completed (loss: 0.2485509216785431, acc: 0.9230769276618958)
[2024-12-17 03:05:15,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:15,687][root][INFO] - Training Epoch: 2/2, step 7098/7134 completed (loss: 0.10793968290090561, acc: 0.9580419659614563)
[2024-12-17 03:05:15,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:15,944][root][INFO] - Training Epoch: 2/2, step 7099/7134 completed (loss: 0.21806319057941437, acc: 0.9420289993286133)
[2024-12-17 03:05:16,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:16,224][root][INFO] - Training Epoch: 2/2, step 7100/7134 completed (loss: 0.18973954021930695, acc: 0.970059871673584)
[2024-12-17 03:05:16,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:16,475][root][INFO] - Training Epoch: 2/2, step 7101/7134 completed (loss: 0.17356471717357635, acc: 0.9496402740478516)
[2024-12-17 03:05:16,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:16,760][root][INFO] - Training Epoch: 2/2, step 7102/7134 completed (loss: 0.176527202129364, acc: 0.9576271176338196)
[2024-12-17 03:05:16,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:17,039][root][INFO] - Training Epoch: 2/2, step 7103/7134 completed (loss: 0.08670221269130707, acc: 0.96875)
[2024-12-17 03:05:17,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:17,312][root][INFO] - Training Epoch: 2/2, step 7104/7134 completed (loss: 0.0571616105735302, acc: 0.9912280440330505)
[2024-12-17 03:05:17,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:17,591][root][INFO] - Training Epoch: 2/2, step 7105/7134 completed (loss: 0.12705929577350616, acc: 0.9722222089767456)
[2024-12-17 03:05:17,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:17,845][root][INFO] - Training Epoch: 2/2, step 7106/7134 completed (loss: 0.06521349400281906, acc: 0.9851852059364319)
[2024-12-17 03:05:17,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:18,122][root][INFO] - Training Epoch: 2/2, step 7107/7134 completed (loss: 0.07510685175657272, acc: 0.9689440727233887)
[2024-12-17 03:05:18,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:18,391][root][INFO] - Training Epoch: 2/2, step 7108/7134 completed (loss: 0.0720919594168663, acc: 0.985401451587677)
[2024-12-17 03:05:18,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:18,665][root][INFO] - Training Epoch: 2/2, step 7109/7134 completed (loss: 0.31916117668151855, acc: 0.9259259104728699)
[2024-12-17 03:05:18,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:18,950][root][INFO] - Training Epoch: 2/2, step 7110/7134 completed (loss: 0.03672134503722191, acc: 1.0)
[2024-12-17 03:05:19,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:19,218][root][INFO] - Training Epoch: 2/2, step 7111/7134 completed (loss: 0.1527893990278244, acc: 0.9629629850387573)
[2024-12-17 03:05:19,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:19,491][root][INFO] - Training Epoch: 2/2, step 7112/7134 completed (loss: 0.16182143986225128, acc: 0.954954981803894)
[2024-12-17 03:05:19,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:19,788][root][INFO] - Training Epoch: 2/2, step 7113/7134 completed (loss: 0.24391458928585052, acc: 0.9235668778419495)
[2024-12-17 03:05:19,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:20,051][root][INFO] - Training Epoch: 2/2, step 7114/7134 completed (loss: 0.13184525072574615, acc: 0.963302731513977)
[2024-12-17 03:05:20,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:20,321][root][INFO] - Training Epoch: 2/2, step 7115/7134 completed (loss: 0.15796560049057007, acc: 0.9541984796524048)
[2024-12-17 03:05:20,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:20,582][root][INFO] - Training Epoch: 2/2, step 7116/7134 completed (loss: 0.24637088179588318, acc: 0.9411764740943909)
[2024-12-17 03:05:20,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:20,839][root][INFO] - Training Epoch: 2/2, step 7117/7134 completed (loss: 0.20807693898677826, acc: 0.9370078444480896)
[2024-12-17 03:05:20,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:21,116][root][INFO] - Training Epoch: 2/2, step 7118/7134 completed (loss: 0.12483562529087067, acc: 0.9571428298950195)
[2024-12-17 03:05:21,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:21,384][root][INFO] - Training Epoch: 2/2, step 7119/7134 completed (loss: 0.09289234131574631, acc: 0.9655172228813171)
[2024-12-17 03:05:21,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:21,646][root][INFO] - Training Epoch: 2/2, step 7120/7134 completed (loss: 0.11305481195449829, acc: 0.9708737730979919)
[2024-12-17 03:05:21,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:21,909][root][INFO] - Training Epoch: 2/2, step 7121/7134 completed (loss: 0.05615747720003128, acc: 0.9769230484962463)
[2024-12-17 03:05:22,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:22,159][root][INFO] - Training Epoch: 2/2, step 7122/7134 completed (loss: 0.2277267575263977, acc: 0.9462365508079529)
[2024-12-17 03:05:22,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:22,430][root][INFO] - Training Epoch: 2/2, step 7123/7134 completed (loss: 0.0502425879240036, acc: 0.9898989796638489)
[2024-12-17 03:05:22,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:22,736][root][INFO] - Training Epoch: 2/2, step 7124/7134 completed (loss: 0.12407974153757095, acc: 0.9754098653793335)
[2024-12-17 03:05:22,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:22,980][root][INFO] - Training Epoch: 2/2, step 7125/7134 completed (loss: 0.0887538492679596, acc: 0.9694656729698181)
[2024-12-17 03:05:23,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:23,243][root][INFO] - Training Epoch: 2/2, step 7126/7134 completed (loss: 0.3210711181163788, acc: 0.9270073175430298)
[2024-12-17 03:05:23,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:23,495][root][INFO] - Training Epoch: 2/2, step 7127/7134 completed (loss: 0.17783254384994507, acc: 0.9629629850387573)
[2024-12-17 03:05:23,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:23,759][root][INFO] - Training Epoch: 2/2, step 7128/7134 completed (loss: 0.12960442900657654, acc: 0.9520547986030579)
[2024-12-17 03:05:23,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:24,039][root][INFO] - Training Epoch: 2/2, step 7129/7134 completed (loss: 0.5601773262023926, acc: 0.8682170510292053)
[2024-12-17 03:05:24,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:25,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:25,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:25,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:26,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:26,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:26,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:26,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:27,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:27,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:27,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:28,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:28,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:28,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:28,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:29,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:29,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:29,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:30,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:30,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:30,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:31,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:31,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:31,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:31,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:32,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:32,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:32,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:32,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:33,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:33,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:34,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:34,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:34,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:34,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:35,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:35,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:35,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:35,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:36,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:36,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:36,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:37,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:37,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:37,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:38,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:38,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:38,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:39,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:39,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:39,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:39,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:40,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:40,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:40,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:40,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:41,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:41,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:41,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:42,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:42,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:42,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:42,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:43,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:43,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:43,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:44,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:44,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:44,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:44,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:45,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:45,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:45,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:46,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:46,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:46,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:46,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:47,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:47,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:47,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:48,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:48,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:48,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:48,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:49,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:49,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:49,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:50,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:50,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:50,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:51,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:51,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:51,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:51,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:51,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:52,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:52,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:52,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:52,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:53,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:53,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:53,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:53,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:54,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:54,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:54,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:55,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:55,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:55,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:55,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:56,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:56,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:56,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:57,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:57,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:57,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:57,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:58,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:58,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:58,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:59,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:59,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:59,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:59,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:00,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:00,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:00,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:00,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:01,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:01,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:01,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:01,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:02,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:02,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:02,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:03,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:03,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:03,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:03,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:04,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:04,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:04,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:04,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:05,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:05,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:05,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:06,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:06,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:06,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:06,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:06,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:07,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:07,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:07,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:07,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:08,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:08,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:08,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:08,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:09,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:09,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:09,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:09,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:10,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:10,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:10,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:11,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:11,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:11,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:12,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:12,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:12,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:13,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:13,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:13,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:14,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:14,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:14,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:14,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:15,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:15,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:15,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:15,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:16,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:16,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:16,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:17,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:17,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:17,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:18,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:18,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:18,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:19,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:19,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:19,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:20,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:20,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:20,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:20,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:21,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:21,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:21,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:22,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:22,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:22,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:23,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:23,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:23,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:23,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:24,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:24,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:25,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:25,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:25,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:25,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:26,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:26,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:26,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:27,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:27,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:27,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:27,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:28,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:28,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:28,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:29,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:29,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:29,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:29,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:30,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:30,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:30,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:31,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:31,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:31,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:31,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:32,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:32,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:32,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:33,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:33,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:33,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:34,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:34,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:34,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:34,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:35,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:35,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:36,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:36,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:36,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:37,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:37,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:37,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:38,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:38,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:38,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:38,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:39,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:39,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:39,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:39,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:40,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:40,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:40,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:40,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:41,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:41,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:41,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:42,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:42,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:42,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:43,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:43,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:43,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:43,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:44,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:44,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:44,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:45,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:45,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:45,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:46,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:46,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:46,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:47,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:47,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:47,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:48,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:48,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:48,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:49,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:49,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:49,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:50,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:50,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:50,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:51,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:51,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:51,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:52,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:52,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:52,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:52,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:53,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:53,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:53,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:54,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:54,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:54,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:55,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:55,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:55,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:56,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:56,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:56,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:56,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:57,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:57,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:58,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:58,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:58,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:58,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:59,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:59,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:00,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:00,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:00,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:01,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:01,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:01,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:02,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:02,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:02,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:03,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:03,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:03,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:04,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:04,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:04,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:04,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:05,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:05,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:05,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:06,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:06,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:06,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:07,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:07,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:07,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:08,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:08,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:08,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:08,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:09,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:09,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:09,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:10,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:10,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:10,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:11,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:11,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:12,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:12,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:13,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:13,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:14,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:14,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:14,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:14,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:15,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:15,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:15,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:16,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:16,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:16,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:16,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:17,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:17,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:17,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:17,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:18,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:18,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:18,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:19,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:19,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:19,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:19,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:20,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:20,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:20,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:20,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:21,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:21,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:21,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:22,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:22,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:22,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:22,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:23,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:23,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:23,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:23,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:24,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:24,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:24,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:25,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:25,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:25,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:25,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:26,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:26,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:26,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:26,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:27,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:27,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:27,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:28,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:28,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:28,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:28,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:29,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:29,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:29,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:29,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:30,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:30,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:30,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:31,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:31,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:31,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:32,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:32,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:32,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:32,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:33,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:33,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:33,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:34,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:34,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:34,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:35,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:35,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:35,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:36,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:36,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:36,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:37,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:37,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:37,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:38,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:38,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:38,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:38,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:39,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:39,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:39,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:40,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:40,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:40,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:41,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:41,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:41,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:41,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:42,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:42,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:42,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:43,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:43,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:43,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:43,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:44,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:44,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:44,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:44,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:45,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:45,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:45,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:46,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:46,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:46,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:47,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:47,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:47,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:48,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:48,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:48,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:49,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:49,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:49,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:50,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:50,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:50,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:50,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:51,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:51,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:51,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:52,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:52,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:52,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:52,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:53,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:53,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:54,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:54,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:54,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:55,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:55,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:55,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:55,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:56,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:56,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:56,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:57,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:57,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:57,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:57,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:58,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:58,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:58,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:59,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:59,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:59,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:00,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:00,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:00,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:00,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:01,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:01,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:01,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:02,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:02,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:02,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:02,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:03,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:03,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:03,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:04,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:04,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:04,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:05,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:05,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:05,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:05,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:06,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:06,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:06,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:07,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:07,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:07,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:08,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:08,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:08,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:08,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:09,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:09,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:09,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:10,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:10,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:10,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:11,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:11,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:11,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:12,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:12,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:12,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:13,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:13,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:13,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:14,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:14,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:14,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:15,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:15,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:15,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:16,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:16,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:16,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:16,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:17,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:17,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:17,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:18,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:18,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:18,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:19,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:19,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:19,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:19,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:20,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:20,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:20,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:21,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:21,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:21,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:21,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:22,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:22,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:22,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:22,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:23,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:23,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:23,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:24,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:24,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:24,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:24,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:25,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:25,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:25,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:25,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:26,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:26,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:26,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:27,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:27,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:27,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:27,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:27,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:28,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:28,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:28,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:29,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:29,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:29,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:30,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:30,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:31,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:31,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:31,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:32,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:32,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:32,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:33,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:33,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:33,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:34,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:34,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:34,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:35,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:35,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:35,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:36,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:36,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:36,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:36,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:36,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:37,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:37,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:37,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:38,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:38,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:38,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:39,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:39,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:39,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:40,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:40,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:40,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:40,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:41,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:41,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:41,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:42,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:42,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:42,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:43,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:43,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:43,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:43,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:44,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:44,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:44,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:44,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:45,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:45,918][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.2632, device='cuda:0') eval_epoch_loss=tensor(0.2337, device='cuda:0') eval_epoch_acc=tensor(0.9461, device='cuda:0')
[2024-12-17 03:08:45,920][slam_llm.utils.train_utils][INFO] - llm is frozen, we are about to save other parts.
[2024-12-17 03:08:45,920][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 03:08:46,105][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_freeze_llm/asr_epoch_2_step_7130_loss_0.23368018865585327/model.pt
[2024-12-17 03:08:46,108][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.946131706237793
[2024-12-17 03:08:46,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:46,440][root][INFO] - Training Epoch: 2/2, step 7130/7134 completed (loss: 0.7361928820610046, acc: 0.8333333134651184)
[2024-12-17 03:08:46,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:46,698][root][INFO] - Training Epoch: 2/2, step 7131/7134 completed (loss: 0.16371160745620728, acc: 0.9622641801834106)
[2024-12-17 03:08:46,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:46,908][root][INFO] - Training Epoch: 2/2, step 7132/7134 completed (loss: 0.05103002116084099, acc: 0.9852941036224365)
[2024-12-17 03:08:46,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:47,165][root][INFO] - Training Epoch: 2/2, step 7133/7134 completed (loss: 0.1357215940952301, acc: 0.9849624037742615)
[2024-12-17 03:08:47,560][slam_llm.utils.train_utils][INFO] - Epoch 2: train_perplexity=1.2263, train_epoch_loss=0.2040, epoch time 2812.7136008664966s
[2024-12-17 03:08:47,561][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 11 GB
[2024-12-17 03:08:47,561][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 21 GB
[2024-12-17 03:08:47,561][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 11 GB
[2024-12-17 03:08:47,561][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 0
[2024-12-17 03:08:47,561][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-12-17 03:08:47,563][root][INFO] - Key: avg_train_prep, Value: 5.142276287078857
[2024-12-17 03:08:47,564][root][INFO] - Key: avg_train_loss, Value: 1.2038244009017944
[2024-12-17 03:08:47,565][root][INFO] - Key: avg_train_acc, Value: 0.7784746289253235
[2024-12-17 03:08:47,565][root][INFO] - Key: avg_eval_prep, Value: 8.34425163269043
[2024-12-17 03:08:47,565][root][INFO] - Key: avg_eval_loss, Value: 0.8320586681365967
[2024-12-17 03:08:47,565][root][INFO] - Key: avg_eval_acc, Value: 0.8361508250236511
[2024-12-17 03:08:47,565][root][INFO] - Key: avg_epoch_time, Value: 2858.2528591938317
[2024-12-17 03:08:47,565][root][INFO] - Key: avg_checkpoint_time, Value: 0.21481852559372783
