[2025-02-08 19:24:14,652][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'resume_step': 0, 'resume_epoch': 0, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 10, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': False, 'save_embedding': False}
[2025-02-08 19:24:14,653][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2025-02-08 19:24:14,653][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'repetition_penalty', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'dual', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': 'w2v2', 'encoder2_dim': 1024, 'encoder2_path': 'vitouphy/wav2vec2-xls-r-300m-timit-phoneme', 'identifier': 'psst_phoneme_wavlm_llama32_1b_dual_peft'}
[2025-02-08 19:24:16,335][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2025-02-08 19:24:23,633][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-02-08 19:24:23,636][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2025-02-08 19:24:23,639][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-02-08 19:24:23,640][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2025-02-08 19:24:24,190][slam_llm.utils.train_utils][INFO] - --> Module w2v2
[2025-02-08 19:24:24,197][slam_llm.utils.train_utils][INFO] - --> w2v2 has 315.43872 Million params

[2025-02-08 19:24:24,197][slam_llm.utils.train_utils][INFO] - --> Module w2v2
[2025-02-08 19:24:24,198][slam_llm.utils.train_utils][INFO] - --> w2v2 has 315.43872 Million params

[2025-02-08 19:24:30,299][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-08 19:24:30,302][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2025-02-08 19:24:30,304][slam_llm.models.slam_model][INFO] - setup peft...
[2025-02-08 19:24:30,441][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-08 19:24:30,443][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2025-02-08 19:24:30,640][slam_llm.utils.train_utils][INFO] - --> Module dual
[2025-02-08 19:24:30,640][slam_llm.utils.train_utils][INFO] - --> dual has 25.16992 Million params

[2025-02-08 19:24:30,640][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_peft/asr_epoch_4_step_137_loss_0.7482238411903381/model.pt
[2025-02-08 19:24:30,982][slam_llm.utils.train_utils][INFO] - --> Model asr
[2025-02-08 19:24:30,991][slam_llm.utils.train_utils][INFO] - --> asr has 346.244736 Million params

[2025-02-08 19:24:36,456][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': None, 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/test.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': True, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2025-02-08 19:24:36,989][root][INFO] - --> Training Set Length = 652
[2025-02-08 19:24:36,989][root][INFO] - =====================================
[2025-02-08 19:24:38,914][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:24:40,673][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:24:50,211][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:25:03,316][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:25:12,453][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:25:22,725][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:25:31,548][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:25:40,245][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:25:41,703][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:25:42,711][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:25:51,146][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:25:59,205][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:26:00,545][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:26:01,705][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:26:03,255][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:26:04,872][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:26:13,300][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:26:15,015][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:26:17,123][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:26:22,051][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:26:33,404][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:26:34,462][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:26:36,984][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:26:47,414][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:26:49,589][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:26:59,775][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:27:10,186][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:27:11,935][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:27:14,076][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:27:17,366][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:27:25,892][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:27:37,355][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:27:48,566][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:27:59,179][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:28:00,207][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:28:02,676][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:28:17,867][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:28:32,515][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:28:36,661][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:28:40,024][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:28:52,513][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:28:53,330][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:28:54,427][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:28:56,799][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:28:57,808][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:28:59,645][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:29:08,092][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:29:16,496][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:29:17,564][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:29:18,916][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:29:27,784][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:29:35,474][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:29:36,606][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:29:38,346][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:29:40,932][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:29:49,008][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:29:50,864][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:29:52,149][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:29:54,302][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:29:55,716][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:29:58,578][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:30:14,144][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:30:25,555][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:30:26,677][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:30:29,978][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:30:43,685][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-08 19:30:44,655][root][INFO] - Predictions written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_peft/decode_test_beam4_pred_20250208_192436
[2025-02-08 19:30:44,655][root][INFO] - Ground truth written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_peft/decode_test_beam4_gt_20250208_192436
[2025-02-09 03:33:40,788][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'resume_step': 0, 'resume_epoch': 0, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 10, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': False, 'save_embedding': False}
[2025-02-09 03:33:40,788][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2025-02-09 03:33:40,788][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'repetition_penalty', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'dual', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': 'w2v2', 'encoder2_dim': 1024, 'encoder2_path': 'vitouphy/wav2vec2-xls-r-300m-timit-phoneme', 'identifier': 'psst_phoneme_wavlm_llama32_1b_dual_peft'}
[2025-02-09 03:33:42,132][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2025-02-09 03:33:47,813][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-02-09 03:33:47,815][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2025-02-09 03:33:47,817][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-02-09 03:33:47,818][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2025-02-09 03:33:48,257][slam_llm.utils.train_utils][INFO] - --> Module w2v2
[2025-02-09 03:33:48,258][slam_llm.utils.train_utils][INFO] - --> w2v2 has 315.43872 Million params

[2025-02-09 03:33:48,258][slam_llm.utils.train_utils][INFO] - --> Module w2v2
[2025-02-09 03:33:48,259][slam_llm.utils.train_utils][INFO] - --> w2v2 has 315.43872 Million params

[2025-02-09 03:33:53,347][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-09 03:33:53,347][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2025-02-09 03:33:53,349][slam_llm.models.slam_model][INFO] - setup peft...
[2025-02-09 03:33:53,467][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-09 03:33:53,469][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2025-02-09 03:33:53,653][slam_llm.utils.train_utils][INFO] - --> Module dual
[2025-02-09 03:33:53,654][slam_llm.utils.train_utils][INFO] - --> dual has 25.16992 Million params

[2025-02-09 03:33:53,654][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_peft/asr_epoch_4_step_137_loss_0.7482238411903381/model.pt
[2025-02-09 03:33:53,898][slam_llm.utils.train_utils][INFO] - --> Model asr
[2025-02-09 03:33:53,904][slam_llm.utils.train_utils][INFO] - --> asr has 346.244736 Million params

[2025-02-09 03:33:56,485][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': None, 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/test.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': True, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2025-02-09 03:33:56,946][root][INFO] - --> Training Set Length = 652
[2025-02-09 03:33:56,948][root][INFO] - =====================================
[2025-02-09 03:33:58,660][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:33:59,992][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:34:09,420][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:34:22,331][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:34:31,488][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:34:41,867][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:34:50,710][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:34:59,502][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:35:00,944][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:35:01,919][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:35:10,471][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:35:18,432][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:35:19,779][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:35:20,943][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:35:22,452][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:35:24,076][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:35:32,520][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:35:34,237][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:35:36,347][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:35:41,302][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:35:52,801][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:35:53,846][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:35:56,363][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:36:06,818][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:36:08,985][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:36:19,187][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:36:29,601][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:36:31,349][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:36:33,500][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:36:36,790][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:36:45,295][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:36:56,731][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:37:07,930][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:37:18,647][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:37:19,666][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:37:22,122][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:37:37,354][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:37:52,011][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:37:56,157][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:37:59,531][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:38:12,080][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:38:12,888][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:38:13,930][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:38:16,259][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:38:17,227][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:38:19,106][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:38:27,550][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:38:35,970][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:38:37,046][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:38:38,395][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:38:47,622][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:38:55,927][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:38:57,157][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:38:59,009][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:39:01,649][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:39:10,281][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:39:12,335][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:39:13,755][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:39:16,121][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:39:17,689][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:39:20,680][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:39:36,530][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:39:48,185][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:39:49,378][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:39:52,798][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:40:06,728][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-09 03:40:07,795][root][INFO] - Predictions written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_peft/decode_test_beam4_pred_20250209_033356
[2025-02-09 03:40:07,796][root][INFO] - Ground truth written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_peft/decode_test_beam4_gt_20250209_033356
[2025-02-10 06:16:31,901][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'resume_step': 0, 'resume_epoch': 0, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 10, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': False, 'save_embedding': False}
[2025-02-10 06:16:31,902][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2025-02-10 06:16:31,902][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'repetition_penalty', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'dual', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': 'w2v2', 'encoder2_dim': 1024, 'encoder2_path': 'vitouphy/wav2vec2-xls-r-300m-timit-phoneme', 'identifier': 'psst_phoneme_wavlm_llama32_1b_dual_peft'}
[2025-02-10 06:16:32,986][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2025-02-10 06:16:37,910][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-02-10 06:16:37,912][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2025-02-10 06:16:37,914][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-02-10 06:16:37,915][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2025-02-10 06:16:38,440][slam_llm.utils.train_utils][INFO] - --> Module w2v2
[2025-02-10 06:16:38,441][slam_llm.utils.train_utils][INFO] - --> w2v2 has 315.43872 Million params

[2025-02-10 06:16:38,441][slam_llm.utils.train_utils][INFO] - --> Module w2v2
[2025-02-10 06:16:38,442][slam_llm.utils.train_utils][INFO] - --> w2v2 has 315.43872 Million params

[2025-02-10 06:16:41,942][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-10 06:16:41,943][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2025-02-10 06:16:41,944][slam_llm.models.slam_model][INFO] - setup peft...
[2025-02-10 06:16:42,064][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-10 06:16:42,066][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2025-02-10 06:16:42,240][slam_llm.utils.train_utils][INFO] - --> Module dual
[2025-02-10 06:16:42,241][slam_llm.utils.train_utils][INFO] - --> dual has 25.16992 Million params

[2025-02-10 06:16:42,241][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_peft/asr_epoch_4_step_137_loss_0.7482238411903381/model.pt
[2025-02-10 06:16:42,523][slam_llm.utils.train_utils][INFO] - --> Model asr
[2025-02-10 06:16:42,528][slam_llm.utils.train_utils][INFO] - --> asr has 346.244736 Million params

[2025-02-10 06:16:44,890][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': None, 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/test.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': True, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2025-02-10 06:16:45,709][root][INFO] - --> Training Set Length = 652
[2025-02-10 06:16:45,709][root][INFO] - =====================================
[2025-02-10 06:16:47,429][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:16:48,755][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:16:58,203][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:17:11,247][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:17:20,508][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:17:30,820][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:17:39,666][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:17:48,481][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:17:49,935][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:17:50,924][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:17:59,477][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:18:07,510][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:18:08,928][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:18:10,108][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:18:11,640][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:18:13,282][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:18:21,854][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:18:23,601][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:18:25,755][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:18:30,762][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:18:42,232][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:18:43,300][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:18:45,852][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:18:56,335][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:18:58,521][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:19:08,819][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:19:19,249][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:19:21,019][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:19:23,196][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:19:26,574][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:19:35,093][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:19:46,518][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:19:57,796][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:20:08,495][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:20:09,532][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:20:12,019][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:20:27,362][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:20:42,101][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:20:46,322][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:20:49,725][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:21:02,316][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:21:03,129][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:21:04,181][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:21:06,533][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:21:07,516][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:21:09,370][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:21:17,840][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:21:26,345][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:21:27,412][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:21:28,771][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:21:37,699][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:21:45,394][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:21:46,641][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:21:48,409][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:21:51,028][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:21:59,196][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:22:01,073][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:22:02,356][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:22:04,521][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:22:05,950][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:22:08,852][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:22:24,567][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:22:36,036][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:22:37,161][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:22:40,513][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:22:54,269][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:22:55,111][root][INFO] - Predictions written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_peft/decode_test_beam4_pred_20250210_061645
[2025-02-10 06:22:55,112][root][INFO] - Ground truth written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_peft/decode_test_beam4_gt_20250210_061645
[2025-02-10 06:23:13,971][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'resume_step': 0, 'resume_epoch': 0, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 10, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': False, 'save_embedding': False}
[2025-02-10 06:23:13,971][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2025-02-10 06:23:13,971][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'repetition_penalty', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'dual', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': 'w2v2', 'encoder2_dim': 1024, 'encoder2_path': 'vitouphy/wav2vec2-xls-r-300m-timit-phoneme', 'identifier': 'psst_phoneme_wavlm_llama32_1b_dual_peft'}
[2025-02-10 06:23:15,047][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2025-02-10 06:23:19,960][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-02-10 06:23:19,962][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2025-02-10 06:23:19,964][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-02-10 06:23:19,965][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2025-02-10 06:23:20,396][slam_llm.utils.train_utils][INFO] - --> Module w2v2
[2025-02-10 06:23:20,397][slam_llm.utils.train_utils][INFO] - --> w2v2 has 315.43872 Million params

[2025-02-10 06:23:20,397][slam_llm.utils.train_utils][INFO] - --> Module w2v2
[2025-02-10 06:23:20,398][slam_llm.utils.train_utils][INFO] - --> w2v2 has 315.43872 Million params

[2025-02-10 06:23:23,797][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-10 06:23:23,798][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2025-02-10 06:23:23,799][slam_llm.models.slam_model][INFO] - setup peft...
[2025-02-10 06:23:23,916][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-10 06:23:23,918][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2025-02-10 06:23:24,092][slam_llm.utils.train_utils][INFO] - --> Module dual
[2025-02-10 06:23:24,092][slam_llm.utils.train_utils][INFO] - --> dual has 25.16992 Million params

[2025-02-10 06:23:24,092][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_peft/asr_epoch_10_step_554_loss_0.9401524662971497/model.pt
[2025-02-10 06:23:24,368][slam_llm.utils.train_utils][INFO] - --> Model asr
[2025-02-10 06:23:24,374][slam_llm.utils.train_utils][INFO] - --> asr has 346.244736 Million params

[2025-02-10 06:23:26,732][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': None, 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/test.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': True, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2025-02-10 06:23:27,754][root][INFO] - --> Training Set Length = 652
[2025-02-10 06:23:27,755][root][INFO] - =====================================
[2025-02-10 06:23:29,096][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:23:31,433][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:23:34,044][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:23:39,083][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:23:48,154][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:23:58,279][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:24:07,075][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:24:09,928][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:24:18,176][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:24:19,129][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:24:20,932][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:24:22,207][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:24:23,624][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:24:24,887][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:24:26,338][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:24:28,199][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:24:29,893][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:24:31,620][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:24:34,329][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:24:39,749][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:24:43,689][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:24:51,609][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:24:54,065][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:24:57,288][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:25:06,476][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:25:09,844][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:25:20,136][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:25:21,990][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:25:24,084][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:25:27,479][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:25:29,168][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:25:40,590][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:25:51,987][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:25:55,734][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:25:56,794][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:25:59,410][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:26:14,505][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:26:21,051][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:26:25,180][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:26:28,375][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:26:40,961][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:26:42,515][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:26:43,540][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:26:45,793][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:26:46,786][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:26:55,195][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:26:56,913][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:26:58,432][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:26:59,503][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:27:00,739][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:27:02,981][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:27:04,640][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:27:05,750][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:27:14,371][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:27:17,022][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:27:18,330][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:27:20,342][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:27:28,222][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:27:36,593][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:27:38,047][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:27:40,755][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:27:50,178][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:27:53,340][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:28:01,374][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:28:04,751][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:28:18,606][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-10 06:28:19,396][root][INFO] - Predictions written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_peft/decode_test_beam4_pred_20250210_062327
[2025-02-10 06:28:19,396][root][INFO] - Ground truth written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_dual_peft/decode_test_beam4_gt_20250210_062327
